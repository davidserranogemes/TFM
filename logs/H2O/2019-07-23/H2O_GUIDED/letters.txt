Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmpul3sv1dd
  JVM stdout: /tmp/tmpul3sv1dd/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmpul3sv1dd/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    7 days, 15 hours and 30 minutes
H2O cluster name:           H2O_from_python_davidserranogemes_6u4h8t
H2O cluster total nodes:    1
H2O cluster free memory:    1.922 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Guided  mode.

deeplearning Grid Build progress: |███████████████████████████████████████| 100%
deeplearning prediction progress: |███████████████████████████████████████| 100%
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_82

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019123132948806187  0.0004989493172615767  0.0         -0.00928725810321751  0.17186594009399414  0.2755773039080321    0.1341521143913269
    3        26       Softmax                      0.0   0.0   0.0100191351110215     0.050038352608680725   0.0         -0.21759379811585033  0.3920884132385254   -0.47910449074945566  0.09447801113128662


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.10866992179125644
RMSE: 0.3296512123309369
LogLoss: 0.36329064511937237
Mean Per-Class Error: 0.10424077439440606
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    3.0    4.0    3.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    3.0    0.0    0.0    1.0    4.0    3.0    0.07088607594936709   28 / 395
0.0    353.0  0.0    4.0    2.0    0.0    2.0    5.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    6.0    3.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.0783289817232376    30 / 383
0.0    0.0    335.0  0.0    6.0    0.0    8.0    1.0    0.0    0.0    7.0    1.0    1.0    0.0    6.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.08967391304347826   33 / 368
0.0    11.0   0.0    354.0  0.0    0.0    0.0    4.0    0.0    4.0    1.0    0.0    5.0    5.0    2.0    2.0    0.0    5.0    0.0    0.0    2.0    0.0    0.0    4.0    0.0    4.0    0.12158808933002481   49 / 403
0.0    5.0    1.0    0.0    326.0  3.0    17.0   1.0    0.0    0.0    3.0    8.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    3.0    0.0    0.0    0.0    4.0    0.0    7.0    0.15104166666666666   58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    356.0  0.0    0.0    0.0    0.050666666666666665  19 / 375
0.0    1.0    0.0    4.0    3.0    0.0    0.0    0.0    3.0    3.0    8.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    359.0  2.0    5.0    0.08883248730964467   35 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    13.0   1.0    3.0    1.0    0.0    367.0  0.0    0.06615776081424936   26 / 393
1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    5.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    1.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    341.0  0.06830601092896176   25 / 366
379.0  453.0  353.0  408.0  371.0  390.0  381.0  294.0  352.0  386.0  377.0  393.0  405.0  387.0  392.0  373.0  364.0  408.0  363.0  403.0  416.0  363.0  395.0  413.0  393.0  391.0  0.10376886933919824   1,038 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.896231
2    0.951914
3    0.971509
4    0.980906
5    0.986404
6    0.989703
7    0.992902
8    0.994102
9    0.995501
10   0.996801

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11019573361905684
RMSE: 0.33195742741962686
LogLoss: 0.3711320890758745
Mean Per-Class Error: 0.10182297748491884
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11     12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0    1.0   0.0449438202247191    4 / 89
0.0   93.0   0.0   0.0    1.0   0.0   2.0   1.0   0.0   0.0    1.0    0.0    0.0   0.0    0.0   1.0    0.0   4.0    1.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0   0.12264150943396226   13 / 106
0.0   0.0    76.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.07317073170731707   6 / 82
0.0   1.0    0.0   99.0   0.0   0.0   0.0   2.0   0.0   1.0    1.0    0.0    2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    2.0   0.11607142857142858   13 / 112
0.0   0.0    0.0   0.0    83.0  1.0   6.0   0.0   0.0   0.0    0.0    2.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   0.14432989690721648   14 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   90.0   0.0   0.0    0.0   0.021739130434782608  2 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0   1.0   0.0    6.0    2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    86.0  0.0    2.0   0.14                  14 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   4.0   0.0    1.0   1.0    0.0   99.0   0.0   0.07476635514018691   8 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0    2.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    80.0  0.08045977011494253   7 / 87
87.0  112.0  78.0  113.0  93.0  90.0  94.0  72.0  88.0  110.0  102.0  100.0  86.0  102.0  84.0  106.0  98.0  104.0  87.0  94.0  106.0  79.0  100.0  98.0  108.0  99.0  0.10200803212851406   254 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.897992
2    0.95261
3    0.971486
4    0.97992
5    0.984739
6    0.989157
7    0.993574
8    0.994378
9    0.995582
10   0.996787
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:54  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:55  3 min 33.216 sec  18260 obs/sec     1         1             10007      0.509581         0.873653            0.995385       0.241628                         0.512001           0.885899              0.995329         0.250201
    2019-07-23 13:34:59  3 min 37.695 sec  20236 obs/sec     10        10            100070     0.329651         0.363291            0.998068       0.103769                         0.331957           0.371132              0.998036         0.102008
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0871732
C13         0.906551               0.906551             0.0790269
C9          0.882034               0.882034             0.0768897
C8          0.873272               0.873272             0.0761259
C12         0.768827               0.768827             0.0670211
C7          0.765063               0.765063             0.066693
C10         0.752344               0.752344             0.0655842
C5          0.724515               0.724515             0.0631583
C11         0.708189               0.708189             0.0617351
C6          0.655476               0.655476             0.0571399
C14         0.638567               0.638567             0.0556659
C16         0.632532               0.632532             0.0551398
C4          0.593834               0.593834             0.0517664
C3          0.554247               0.554247             0.0483155
C2          0.535345               0.535345             0.0466677
C1          0.480623               0.480623             0.0418974
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_41

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0020370365157589276  0.0004991786554455757  0.0         -0.00829047756161394  0.17471855878829956  0.272849797900678     0.12194505333900452
    3        26       Softmax                      0.0   0.0   0.010677073223125543   0.046736761927604675   0.0         -0.21066124264741531  0.39277195930480957  -0.48087352593203564  0.09435436129570007


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11001988678346265
RMSE: 0.3316924581347346
LogLoss: 0.36916842886310947
Mean Per-Class Error: 0.10811483854235461
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
372.0  0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    2.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    1.0    2.0    0.0    0.0    3.0    1.0    0.05822784810126582  23 / 395
0.0    334.0  0.0    12.0   4.0    0.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    2.0    17.0   4.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.1279373368146214   49 / 383
0.0    0.0    340.0  0.0    7.0    0.0    6.0    1.0    0.0    0.0    4.0    1.0    0.0    0.0    3.0    0.0    1.0    1.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.07608695652173914  28 / 368
0.0    2.0    0.0    379.0  0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    6.0    4.0    1.0    0.0    0.0    4.0    2.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.05955334987593052  24 / 403
0.0    0.0    2.0    0.0    344.0  2.0    12.0   0.0    0.0    0.0    2.0    4.0    0.0    0.0    0.0    1.0    3.0    3.0    1.0    1.0    1.0    0.0    0.0    2.0    0.0    6.0    0.10416666666666667  40 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    12.0   1.0    2.0    0.0    0.0    6.0    0.0    0.0    5.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    0.0    0.0    5.0    4.0    1.0    0.0    1.0    2.0    4.0    12.0   2.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    353.0  1.0    2.0    0.09948979591836735  39 / 392
0.0    1.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    12.0   1.0    16.0   1.0    0.0    351.0  0.0    0.10687022900763359  42 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    0.0    334.0  0.08991825613079019  33 / 367
394.0  386.0  373.0  464.0  416.0  379.0  349.0  281.0  333.0  370.0  388.0  363.0  404.0  377.0  384.0  395.0  385.0  481.0  405.0  378.0  423.0  374.0  374.0  387.0  379.0  361.0  0.10756772968109567  1,076 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.892432
2    0.947916
3    0.96841
4    0.978406
5    0.985504
6    0.990103
7    0.992902
8    0.994402
9    0.996001
10   0.997201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11128352632194762
RMSE: 0.3335918558987129
LogLoss: 0.3763900887768799
Mean Per-Class Error: 0.10490783886341913
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   89.0   0.0   4.0    3.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   6.0    1.0   0.0   0.0    0.0   1.0   1.0   0.0    0.0   0.16037735849056603   17 / 106
0.0   0.0    74.0  0.0    2.0    0.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0975609756097561    8 / 82
0.0   1.0    0.0   105.0  0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.0625                7 / 112
0.0   0.0    0.0   0.0    88.0   1.0   4.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.09278350515463918   9 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782   6 / 92
0.0   0.0    0.0   2.0    2.0    1.0   0.0   0.0   0.0   1.0    6.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   88.0  0.0    0.0   0.12                  12 / 100
0.0   1.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   3.0   0.0    6.0   1.0   0.0   94.0   0.0   0.12149532710280374   13 / 107
1.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    81.0  0.06896551724137931   6 / 87
87.0  100.0  78.0  130.0  106.0  88.0  90.0  68.0  78.0  108.0  97.0  95.0  87.0  103.0  81.0  110.0  98.0  119.0  98.0  89.0  107.0  85.0  94.0  96.0  109.0  89.0  0.10481927710843374   261 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.895181
2    0.950201
3    0.96747
4    0.976305
5    0.982731
6    0.989157
7    0.992369
8    0.993976
9    0.995582
10   0.997189
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:11  1 min 49.576 sec  19097 obs/sec     1         1             10007      0.507457         0.861813            0.995423       0.244027                         0.50972            0.871214              0.99537          0.248996
    2019-07-23 13:33:16  1 min 54.057 sec  20339 obs/sec     10        10            100070     0.331692         0.369168            0.998045       0.107568                         0.333592           0.37639               0.998017         0.104819
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0827235
C13         0.940094               0.940094             0.0777678
C9          0.900557               0.900557             0.0744972
C8          0.880198               0.880198             0.072813
C12         0.844169               0.844169             0.0698326
C10         0.78339                0.78339              0.0648047
C7          0.77971                0.77971              0.0645003
C5          0.763943               0.763943             0.063196
C11         0.734384               0.734384             0.0607508
C6          0.722625               0.722625             0.059778
C14         0.703408               0.703408             0.0581883
C16         0.670886               0.670886             0.055498
C3          0.629468               0.629468             0.0520717
C4          0.612905               0.612905             0.0507016
C1          0.585326               0.585326             0.0484202
C2          0.537407               0.537407             0.0444562
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_21

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.001891257290651538  0.00048667716328054667  0.0         -0.006683420587180855  0.16748565435409546  0.2776333103274262    0.11756816506385803
    3        26       Softmax                      0.0   0.0   0.009721778980904743  0.04335962235927582     0.0         -0.21845018348689066   0.3936750888824463   -0.47278762020230336  0.09558606147766113


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1123667447312117
RMSE: 0.33521149254047317
LogLoss: 0.3770147061123588
Mean Per-Class Error: 0.1086768676517904
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    6.0    0.0    0.0    1.0    0.0    2.0    1.0    2.0    0.0    1.0    2.0    1.0    3.0    2.0    0.07088607594936709  28 / 395
0.0    336.0  0.0    9.0    3.0    0.0    0.0    9.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    5.0    5.0    4.0    0.0    0.0    2.0    0.0    3.0    1.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    327.0  1.0    9.0    0.0    11.0   2.0    0.0    0.0    6.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    3.0    2.0    4.0    0.0    0.0    0.0    0.0    0.0    0.11141304347826086  41 / 368
1.0    5.0    0.0    371.0  0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    5.0    6.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0794044665012407   32 / 403
0.0    7.0    2.0    0.0    327.0  2.0    21.0   1.0    0.0    0.0    3.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    5.0    0.0    0.0    0.0    3.0    0.0    7.0    0.1484375            57 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    4.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    350.0  0.0    0.0    0.0    0.06666666666666667  25 / 375
0.0    0.0    0.0    5.0    3.0    2.0    0.0    1.0    2.0    4.0    8.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    0.0    357.0  1.0    4.0    0.09390862944162437  37 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    0.0    1.0    13.0   2.0    12.0   2.0    0.0    350.0  0.0    0.10941475826972011  43 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    8.0    3.0    0.0    0.0    0.0    0.0    0.0    331.0  0.09809264305177112  36 / 367
383.0  413.0  349.0  438.0  386.0  375.0  408.0  358.0  343.0  383.0  360.0  356.0  425.0  379.0  373.0  414.0  373.0  397.0  378.0  410.0  413.0  374.0  385.0  400.0  370.0  360.0  0.10806757972608218  1,081 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.891932
2    0.947616
3    0.968709
4    0.978107
5    0.985404
6    0.989703
7    0.992302
8    0.994302
9    0.995301
10   0.997001

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11453574595091985
RMSE: 0.3384313016712843
LogLoss: 0.3870429506735884
Mean Per-Class Error: 0.11006539768609049
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   1.0    0.0   2.0    1.0   0.0898876404494382    8 / 89
0.0   87.0   0.0   2.0    2.0   0.0   0.0    2.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    2.0   4.0    1.0   0.0   0.0    2.0   0.0    1.0   1.0    0.0   0.1792452830188679    19 / 106
0.0   0.0    71.0  0.0    2.0   0.0   2.0    1.0   0.0   0.0    1.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    2.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.13414634146341464   11 / 82
1.0   1.0    0.0   103.0  0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   2.0   2.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.08035714285714286   9 / 112
0.0   1.0    0.0   0.0    82.0  1.0   6.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   2.0   0.0    0.0   0.0    1.0   0.0    2.0   0.15463917525773196   15 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   91.0   0.0   0.0    0.0   0.010869565217391304  1 / 92
0.0   0.0    0.0   3.0    1.0   0.0   0.0    0.0   0.0   1.0    5.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    88.0  0.0    2.0   0.12                  12 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   3.0    1.0   0.0    0.0   4.0   0.0    4.0   1.0    0.0   93.0   0.0   0.1308411214953271    14 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    79.0  0.09195402298850575   8 / 87
85.0  100.0  77.0  124.0  95.0  88.0  101.0  89.0  81.0  112.0  91.0  93.0  92.0  99.0  76.0  116.0  95.0  100.0  96.0  99.0  104.0  86.0  102.0  98.0  103.0  88.0  0.11004016064257029   274 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.88996
2    0.950602
3    0.96747
4    0.977912
5    0.984739
6    0.989157
7    0.991566
8    0.993574
9    0.994779
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:22  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:23  1 min  1.443 sec  18739 obs/sec     1         1             10007      0.508635         0.876646            0.995403       0.247626                         0.509992           0.887158              0.995366         0.248193
    2019-07-23 13:32:28  1 min  6.048 sec  19804 obs/sec     10        10            100070     0.335211         0.377015            0.998003       0.108068                         0.338431           0.387043              0.997959         0.11004
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0865165
C13         0.925206               0.925206             0.0800456
C8          0.878506               0.878506             0.0760053
C12         0.824982               0.824982             0.0713745
C9          0.811774               0.811774             0.0702318
C5          0.739721               0.739721             0.063998
C10         0.727942               0.727942             0.062979
C7          0.717666               0.717666             0.0620899
C11         0.698331               0.698331             0.0604171
C6          0.65409                0.65409              0.0565896
C14         0.652397               0.652397             0.0564431
C16         0.649304               0.649304             0.0561755
C4          0.637715               0.637715             0.0551729
C3          0.582674               0.582674             0.0504109
C1          0.53543                0.53543              0.0463236
C2          0.522754               0.522754             0.0452269
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_112

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018492664034113204  0.00047362223267555237  0.0         -0.008781646171263091  0.16879230737686157  0.29290133519267375  0.11871644854545593
    3        26       Softmax                      0.0   0.0   0.008132992156762296   0.0370015949010849      0.0         -0.21596171416632395   0.39381134510040283  -0.4753369474654783  0.09415751695632935


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11290944224825167
RMSE: 0.33602000275021077
LogLoss: 0.37910727848894066
Mean Per-Class Error: 0.1089545851210274
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
370.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    1.0    2.0    0.0    0.0    1.0    0.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    2.0    3.0    0.06091370558375635  24 / 394
0.0    355.0  1.0    4.0    2.0    0.0    1.0    3.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    6.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.07068062827225131  27 / 382
0.0    0.0    334.0  0.0    6.0    0.0    4.0    1.0    0.0    0.0    7.0    1.0    0.0    0.0    6.0    0.0    1.0    1.0    0.0    3.0    4.0    0.0    0.0    0.0    0.0    0.0    0.09239130434782608  34 / 368
0.0    11.0   0.0    367.0  0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    6.0    4.0    1.0    0.0    1.0    5.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.08706467661691543  35 / 402
0.0    6.0    2.0    0.0    330.0  7.0    14.0   1.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    0.0    3.0    2.0    3.0    4.0    0.0    0.0    0.0    2.0    0.0    3.0    0.140625             54 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    3.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    1.0    0.0    4.0    3.0    1.0    0.0    2.0    2.0    4.0    4.0    2.0    0.0    0.0    3.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    0.0    358.0  1.0    3.0    0.089058524173028    35 / 393
0.0    0.0    0.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    11.0   1.0    4.0    1.0    1.0    364.0  0.0    0.0737913486005089   29 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    18.0   1.0    0.0    0.0    0.0    1.0    0.0    322.0  0.1226158038147139   45 / 367
392.0  455.0  366.0  430.0  393.0  374.0  344.0  308.0  348.0  381.0  368.0  364.0  425.0  366.0  400.0  411.0  359.0  410.0  425.0  395.0  408.0  369.0  385.0  398.0  385.0  344.0  0.10836748975307407  1,084 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.891633
2    0.948615
3    0.969809
4    0.978307
5    0.986204
6    0.989403
7    0.992402
8    0.995101
9    0.996401
10   0.997701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11420802364946951
RMSE: 0.33794677635608467
LogLoss: 0.3886003901946542
Mean Per-Class Error: 0.10553180088800507
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18     19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
86.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.033707865168539325  3 / 89
0.0   97.0   0.0   0.0    2.0   0.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.08490566037735849   9 / 106
0.0   0.0    74.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0    2.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0975609756097561    8 / 82
0.0   2.0    0.0   103.0  0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.08035714285714286   9 / 112
0.0   0.0    0.0   0.0    79.0  5.0   6.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0    2.0    1.0   0.0    0.0   0.0   1.0   0.0    0.0   0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0    1.0   87.0  0.0   0.0    0.0   0.05434782608695652   5 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0   1.0   0.0   1.0    2.0   1.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   88.0  0.0    1.0   0.12                  12 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0    3.0   0.0    1.0   1.0   0.0   100.0  0.0   0.06542056074766354   7 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   1.0   0.0    78.0  0.10344827586206896   9 / 87
93.0  113.0  78.0  119.0  93.0  88.0  90.0  72.0  83.0  114.0  96.0  93.0  93.0  97.0  88.0  114.0  95.0  100.0  103.0  94.0  106.0  80.0  95.0  98.0  111.0  84.0  0.10481927710843374   261 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.895181
2    0.951406
3    0.969478
4    0.976707
5    0.984739
6    0.987952
7    0.993173
8    0.994779
9    0.995582
10   0.996787
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:14  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:14  4 min 52.858 sec  16989 obs/sec     1         1             10007      0.510801         0.877767            0.995361       0.247526                         0.511878           0.888024              0.995331         0.246185
    2019-07-23 13:36:19  4 min 57.324 sec  20248 obs/sec     10        10            100070     0.33602          0.379107            0.997992       0.108367                         0.337947           0.3886                0.997965         0.104819
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.087461
C9          0.846053               0.846053             0.0739967
C8          0.834447               0.834447             0.0729816
C13         0.801541               0.801541             0.0701036
C12         0.797229               0.797229             0.0697264
C10         0.741916               0.741916             0.0648887
C7          0.737883               0.737883             0.064536
C5          0.724654               0.724654             0.063379
C11         0.69419                0.69419              0.0607146
C6          0.686224               0.686224             0.0600178
C14         0.641016               0.641016             0.0560639
C16         0.638199               0.638199             0.0558176
C4          0.621093               0.621093             0.0543214
C3          0.59148                0.59148              0.0517314
C2          0.546401               0.546401             0.0477887
C1          0.531341               0.531341             0.0464717
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_17

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.001923768102827239  0.0005002045072615147  0.0         -0.008526011325127758  0.17013537883758545  0.28427651313238     0.1101553738117218
    3        26       Softmax                      0.0   0.0   0.009090683069364157  0.04037110507488251    0.0         -0.21911772691564124   0.39218711853027344  -0.4716119691109616  0.07333996891975403


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11204279048168705
RMSE: 0.33472793501840725
LogLoss: 0.3791618947255171
Mean Per-Class Error: 0.11047879696614982
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
368.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    3.0    6.0    0.0    0.0    0.0    0.0    2.0    1.0    1.0    2.0    1.0    2.0    0.0    2.0    3.0    0.06835443037974684  27 / 395
0.0    342.0  0.0    5.0    2.0    4.0    2.0    8.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    11.0   2.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.10704960835509138  41 / 383
0.0    0.0    337.0  0.0    4.0    0.0    12.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    1.0    4.0    0.0    1.0    0.0    0.0    0.0    0.08423913043478261  31 / 368
0.0    15.0   0.0    363.0  0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    6.0    5.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.09925558312655088  40 / 403
0.0    8.0    3.0    0.0    328.0  5.0    18.0   0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    3.0    2.0    3.0    0.0    0.0    0.0    5.0    0.0    4.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    17.0   0.0    3.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    1.0    0.0    4.0    4.0    1.0    0.0    1.0    2.0    3.0    6.0    1.0    0.0    0.0    2.0    0.0    3.0    0.0    2.0    4.0    1.0    0.0    0.0    350.0  3.0    6.0    0.1116751269035533   44 / 394
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    1.0    4.0    3.0    6.0    1.0    1.0    371.0  0.0    0.05597964376590331  22 / 393
2.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    4.0    2.0    0.0    0.0    0.0    2.0    0.0    338.0  0.07901907356948229  29 / 367
379.0  436.0  369.0  422.0  387.0  396.0  398.0  370.0  345.0  360.0  347.0  361.0  422.0  375.0  401.0  371.0  384.0  416.0  341.0  388.0  407.0  358.0  378.0  403.0  406.0  383.0  0.10996700989703088  1,100 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.890033
2    0.947416
3    0.96771
4    0.977207
5    0.983305
6    0.988304
7    0.991403
8    0.993802
9    0.995001
10   0.996601

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11448837268945584
RMSE: 0.3383613049529391
LogLoss: 0.389559671798665
Mean Per-Class Error: 0.11247214837467615
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   1.0   0.0    2.0    1.0   0.07865168539325842  7 / 89
0.0   88.0   0.0   0.0    1.0   1.0   2.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   6.0    1.0   0.0   0.0    1.0   0.0   1.0    1.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    75.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0    0.0    0.0   0.08536585365853659  7 / 82
0.0   2.0    0.0   102.0  0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.08928571428571429  10 / 112
0.0   2.0    1.0   0.0    79.0  3.0   6.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0   2.0    0.0    1.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   89.0   0.0    3.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   0.0   0.0    1.0   1.0   0.0    102.0  0.0   0.04672897196261682  5 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   1.0    0.0    79.0  0.09195402298850575  8 / 87
85.0  107.0  84.0  115.0  93.0  94.0  99.0  90.0  81.0  105.0  87.0  93.0  92.0  98.0  89.0  106.0  97.0  111.0  84.0  88.0  104.0  77.0  94.0  105.0  117.0  95.0  0.11285140562248996  281 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.887149
2    0.950201
3    0.968273
4    0.97751
5    0.982329
6    0.986345
7    0.990763
8    0.992771
9    0.993976
10   0.997189
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:13  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:14  52.003 sec  19355 obs/sec     1         1             10007      0.502113         0.85714             0.99552        0.235229                         0.502736           0.854835              0.995496         0.238956
    2019-07-23 13:32:18  56.592 sec  19906 obs/sec     10        10            100070     0.334728         0.379162            0.998009       0.109967                         0.338361           0.38956               0.99796          0.112851
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0845487
C13         0.948579               0.948579             0.0802012
C8          0.900369               0.900369             0.076125
C9          0.889562               0.889562             0.0752113
C12         0.807728               0.807728             0.0682924
C10         0.770736               0.770736             0.0651648
C7          0.758312               0.758312             0.0641143
C5          0.758101               0.758101             0.0640965
C6          0.710332               0.710332             0.0600577
C11         0.679309               0.679309             0.0574347
C14         0.644514               0.644514             0.0544928
C16         0.63426                0.63426              0.0536259
C4          0.60784                0.60784              0.0513921
C3          0.591357               0.591357             0.0499985
C1          0.585654               0.585654             0.0495163
C2          0.540844               0.540844             0.0457277
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_4

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.001964431845181025  0.0005136760883033276  0.0         -0.008191090463013806  0.16746127605438232  0.2718360727183585   0.12267017364501953
    3        26       Softmax                      0.0   0.0   0.009602916032594503  0.041873499751091      0.0         -0.21312763805098728   0.39087677001953125  -0.4809130006638286  0.09869027137756348


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11407609838440835
RMSE: 0.33775153350415504
LogLoss: 0.3812221010408186
Mean Per-Class Error: 0.11145914185874911
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    6.0    3.0    1.0    4.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    1.0    4.0    1.0    1.0    4.0    1.0    0.0810126582278481   32 / 395
0.0    336.0  1.0    4.0    1.0    2.0    2.0    6.0    1.0    0.0    2.0    1.0    0.0    0.0    0.0    2.0    0.0    10.0   11.0   0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    324.0  0.0    9.0    0.0    9.0    2.0    0.0    0.0    8.0    4.0    0.0    0.0    2.0    0.0    0.0    1.0    4.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    0.11956521739130435  44 / 368
1.0    11.0   0.0    358.0  0.0    0.0    0.0    1.0    0.0    5.0    2.0    0.0    2.0    9.0    1.0    0.0    0.0    6.0    3.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.11166253101736973  45 / 403
0.0    2.0    1.0    0.0    326.0  5.0    18.0   0.0    0.0    0.0    5.0    8.0    0.0    0.0    0.0    1.0    1.0    2.0    2.0    3.0    0.0    0.0    0.0    4.0    0.0    6.0    0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    355.0  0.0    0.0    0.0    0.05333333333333334  20 / 375
0.0    0.0    0.0    3.0    1.0    0.0    0.0    2.0    2.0    4.0    7.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    361.0  1.0    5.0    0.08375634517766498  33 / 394
0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    14.0   2.0    14.0   1.0    1.0    352.0  0.0    0.10432569974554708  41 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    9.0    1.0    0.0    0.0    0.0    3.0    0.0    331.0  0.09809264305177112  36 / 367
380.0  408.0  352.0  410.0  368.0  409.0  400.0  338.0  339.0  393.0  389.0  382.0  389.0  414.0  361.0  384.0  358.0  382.0  428.0  373.0  411.0  375.0  393.0  420.0  381.0  366.0  0.1110666799960012   1,111 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.888933
2    0.948315
3    0.969409
4    0.978107
5    0.985604
6    0.989803
7    0.992802
8    0.994402
9    0.995701
10   0.997101

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11701890746058982
RMSE: 0.34208026464645663
LogLoss: 0.39442694007075924
Mean Per-Class Error: 0.11444501109633376
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17    18     19    20     21    22    23    24     25    Error                 Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   86.0  1.0   0.0    1.0   2.0   2.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   1.0    0.0   6.0   3.0    0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.18867924528301888   20 / 106
0.0   0.0   69.0  0.0    2.0   0.0   1.0   1.0   0.0   0.0    2.0    2.0   0.0   0.0    1.0   0.0    0.0   0.0   3.0    1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.15853658536585366   13 / 82
1.0   1.0   0.0   99.0   0.0   0.0   0.0   1.0   0.0   2.0    1.0    0.0   0.0   3.0    0.0   0.0    0.0   0.0   1.0    0.0   1.0    0.0   0.0   2.0   0.0    0.0   0.11607142857142858   13 / 112
0.0   0.0   0.0   0.0    81.0  4.0   5.0   0.0   0.0   0.0    2.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.16494845360824742   16 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0   89.0  0.0   0.0    0.0   0.03260869565217391   3 / 92
0.0   0.0   0.0   2.0    1.0   0.0   0.0   1.0   0.0   1.0    3.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   88.0  0.0    2.0   0.12                  12 / 100
0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    4.0   0.0    5.0   1.0   0.0   96.0   0.0   0.102803738317757     11 / 107
1.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   1.0   0.0    78.0  0.10344827586206896   9 / 87
87.0  97.0  74.0  117.0  95.0  98.0  99.0  84.0  83.0  114.0  100.0  98.0  81.0  110.0  76.0  112.0  95.0  98.0  106.0  85.0  106.0  83.0  95.0  99.0  111.0  87.0  0.1140562248995984    284 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.885944
2    0.946988
3    0.966667
4    0.9751
5    0.982731
6    0.988755
7    0.993173
8    0.994779
9    0.994779
10   0.996787
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:38  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:38  16.695 sec  16218 obs/sec     1         1             10007      0.497724         0.851557            0.995598       0.229931                         0.499318           0.852838              0.995558         0.234538
    2019-07-23 13:31:43  21.247 sec  19835 obs/sec     10        10            100070     0.337752         0.381222            0.997973       0.111067                         0.34208            0.394427              0.997915         0.114056
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0865522
C13         0.914075               0.914075             0.0791152
C9          0.867059               0.867059             0.0750459
C8          0.834358               0.834358             0.0722156
C12         0.77932                0.77932              0.0674519
C7          0.7601                 0.7601               0.0657884
C10         0.740364               0.740364             0.0640801
C5          0.72366                0.72366              0.0626344
C11         0.705339               0.705339             0.0610487
C6          0.68505                0.68505              0.0592926
C14         0.658747               0.658747             0.0570161
C16         0.657516               0.657516             0.0569094
C3          0.58749                0.58749              0.0508486
C4          0.580387               0.580387             0.0502338
C2          0.536027               0.536027             0.0463943
C1          0.524225               0.524225             0.0453728
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_88

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018708788441443858  0.00047435984015464783  0.0         -0.009770237656718361  0.1666836142539978   0.18349221798126375  0.11412841081619263
    3        26       Softmax                      0.0   0.0   0.010946731096964868   0.04107306897640228     0.0         -0.20680924347895002   0.39925146102905273  -0.6353410060939317  0.1429755687713623


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13028484907553226
RMSE: 0.36094992599463466
LogLoss: 0.4257031571449003
Mean Per-Class Error: 0.12396541944568429
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    8.0    1.0    1.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    2.0    2.0    1.0    1.0    3.0    4.0    0.08607594936708861  34 / 395
0.0    347.0  0.0    7.0    3.0    1.0    1.0    4.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    7.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.09399477806788512  36 / 383
0.0    0.0    323.0  1.0    10.0   0.0    2.0    1.0    0.0    0.0    19.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    2.0    2.0    0.0    2.0    0.0    0.0    0.0    0.12228260869565218  45 / 368
1.0    12.0   0.0    361.0  0.0    0.0    0.0    2.0    0.0    2.0    2.0    0.0    6.0    4.0    1.0    0.0    0.0    6.0    2.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.10199004975124377  41 / 402
0.0    6.0    3.0    0.0    329.0  3.0    13.0   1.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    5.0    3.0    4.0    1.0    0.0    0.0    0.0    3.0    0.0    10.0   0.14322916666666666  55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    9.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    1.0    0.0    6.0    2.0    1.0    0.0    2.0    2.0    4.0    11.0   1.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.0    353.0  1.0    4.0    0.10406091370558376  41 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    2.0    3.0    1.0    7.0    1.0    0.0    367.0  0.0    0.06615776081424936  26 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    13.0   2.0    0.0    0.0    0.0    1.0    0.0    330.0  0.09836065573770492  36 / 366
386.0  457.0  371.0  437.0  406.0  364.0  334.0  310.0  345.0  371.0  408.0  352.0  401.0  380.0  396.0  413.0  357.0  405.0  393.0  380.0  412.0  369.0  386.0  399.0  403.0  368.0  0.1233629911026692   1,234 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876637
2    0.940418
3    0.963711
4    0.975407
5    0.982205
6    0.986204
7    0.990003
8    0.993402
9    0.995401
10   0.996501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1319387506529775
RMSE: 0.3632337410717478
LogLoss: 0.435255020125103
Mean Per-Class Error: 0.12489436978496503
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   90.0   0.0   2.0    2.0   0.0   1.0   1.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   4.0    1.0   0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    70.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    0.0   2.0   0.0    0.0   1.0   0.0   0.0    0.0   0.14634146341463414  12 / 82
1.0   1.0    0.0   100.0  0.0   0.0   0.0   2.0   0.0   1.0    1.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.10714285714285714  12 / 112
0.0   0.0    0.0   0.0    84.0  1.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0   0.0   0.0    0.0   0.0   1.0   0.0    3.0   0.13402061855670103  13 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   89.0  0.0   0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    1.0   1.0   0.0   1.0   0.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   88.0  0.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0   0.0    0.0   0.0   0.0    2.0   1.0   0.0   99.0   0.0   0.07476635514018691  8 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0   0.0    80.0  0.08045977011494253  7 / 87
91.0  111.0  79.0  123.0  99.0  80.0  84.0  77.0  82.0  110.0  99.0  89.0  89.0  102.0  79.0  119.0  95.0  105.0  96.0  91.0  105.0  82.0  97.0  99.0  117.0  90.0  0.12329317269076305  307 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876707
2    0.941767
3    0.961847
4    0.972691
5    0.981526
6    0.985542
7    0.989157
8    0.992771
9    0.994779
10   0.996386
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:10  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:10  3 min 48.855 sec  22794 obs/sec     1         1             10007      0.523264         0.905171            0.995134       0.249525                         0.522677           0.90906               0.995132         0.253012
    2019-07-23 13:35:14  3 min 52.662 sec  24235 obs/sec     10        10            100070     0.36095          0.425703            0.997685       0.123363                         0.363234           0.435255              0.997649         0.123293
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0845071
C13         0.944741               0.944741             0.0798373
C8          0.859803               0.859803             0.0726594
C9          0.852312               0.852312             0.0720264
C7          0.824727               0.824727             0.0696953
C12         0.808602               0.808602             0.0683326
C5          0.756757               0.756757             0.0639513
C11         0.744218               0.744218             0.0628917
C10         0.726979               0.726979             0.0614349
C6          0.697736               0.697736             0.0589636
C14         0.663735               0.663735             0.0560903
C16         0.642902               0.642902             0.0543298
C3          0.620697               0.620697             0.0524533
C4          0.609657               0.609657             0.0515204
C1          0.573058               0.573058             0.0484275
C2          0.507403               0.507403             0.0428792
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_97

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018111822849959935  0.000470105092972517  0.0         -0.009822741686051017  0.16979122161865234  0.17714762523516372  0.12391102313995361
    3        26       Softmax                      0.0   0.0   0.009881842811138925   0.04279845952987671   0.0         -0.2054982460061209    0.3995535373687744   -0.6551039428445034  0.19834059476852417


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13038416831785746
RMSE: 0.36108748014554237
LogLoss: 0.4240344193246335
Mean Per-Class Error: 0.12199291278126333
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
368.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    4.0    3.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    1.0    2.0    1.0    0.0    3.0    1.0    0.06598984771573604  26 / 394
0.0    344.0  0.0    8.0    3.0    2.0    1.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    5.0    4.0    5.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.10182767624020887  39 / 383
0.0    0.0    320.0  0.0    10.0   1.0    5.0    1.0    0.0    0.0    12.0   2.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    3.0    8.0    0.0    1.0    0.0    0.0    0.0    0.13043478260869565  48 / 368
1.0    10.0   0.0    367.0  0.0    1.0    0.0    1.0    0.0    4.0    0.0    0.0    7.0    4.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.08933002481389578  36 / 403
0.0    5.0    6.0    0.0    311.0  6.0    15.0   0.0    0.0    0.0    4.0    7.0    0.0    0.0    0.0    0.0    3.0    3.0    4.0    6.0    0.0    0.0    0.0    3.0    0.0    11.0   0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    354.0  0.0    0.0    0.0    0.05851063829787234  22 / 376
0.0    1.0    0.0    4.0    1.0    0.0    0.0    2.0    2.0    4.0    5.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    0.0    361.0  2.0    3.0    0.08375634517766498  33 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    5.0    2.0    17.0   1.0    0.0    357.0  0.0    0.0916030534351145   36 / 393
1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    11.0   1.0    0.0    0.0    0.0    1.0    0.0    333.0  0.09264305177111716  34 / 367
391.0  442.0  350.0  446.0  361.0  399.0  356.0  291.0  357.0  379.0  375.0  396.0  406.0  377.0  362.0  384.0  393.0  406.0  373.0  365.0  417.0  386.0  406.0  413.0  398.0  374.0  0.12136359092272318  1,214 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878636
2    0.941218
3    0.96501
4    0.974808
5    0.981706
6    0.986704
7    0.990403
8    0.993002
9    0.994802
10   0.996401

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13422649826655172
RMSE: 0.3663693467889361
LogLoss: 0.43576534595803446
Mean Per-Class Error: 0.12344188282485259
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16     17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    1.0   0.0    0.0    2.0    0.0   0.0449438202247191    4 / 89
0.0   89.0   0.0   2.0    2.0   1.0   1.0   0.0   1.0   0.0    1.0   0.0    0.0   0.0    0.0   1.0    1.0    3.0    2.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.16037735849056603   17 / 106
0.0   0.0    70.0  0.0    1.0   0.0   1.0   0.0   0.0   0.0    3.0   1.0    0.0   0.0    2.0   0.0    0.0    0.0    0.0   2.0   1.0    0.0   1.0    0.0    0.0    0.0   0.14634146341463414   12 / 82
1.0   1.0    0.0   101.0  0.0   1.0   0.0   0.0   0.0   2.0    0.0   0.0    3.0   1.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0   0.09821428571428571   11 / 112
0.0   0.0    0.0   0.0    75.0  4.0   4.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   0.0    1.0    1.0    3.0   2.0   0.0    0.0   0.0    1.0    0.0    4.0   0.2268041237113402    22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0    0.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   1.0   0.0   1.0    3.0   1.0    0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    89.0   1.0    1.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0    0.0   1.0   0.0    8.0   1.0    0.0    95.0   0.0   0.11214953271028037   12 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    80.0  0.08045977011494253   7 / 87
94.0  111.0  74.0  122.0  87.0  92.0  88.0  69.0  87.0  109.0  95.0  103.0  89.0  100.0  79.0  108.0  100.0  101.0  92.0  83.0  104.0  90.0  100.0  101.0  119.0  93.0  0.12329317269076305   307 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876707
2    0.944578
3    0.964659
4    0.975904
5    0.981928
6    0.987952
7    0.991566
8    0.993574
9    0.994378
10   0.995582
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:34  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:34  4 min 12.966 sec  23713 obs/sec     1         1             10007      0.526205         0.903002            0.99508        0.246526                         0.527252           0.902364              0.995047         0.245783
    2019-07-23 13:35:38  4 min 16.748 sec  24277 obs/sec     10        10            100070     0.361087         0.424034            0.997683       0.121364                         0.366369           0.435765              0.997608         0.123293
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0832371
C13         0.945204               0.945204             0.0786761
C7          0.891615               0.891615             0.0742155
C9          0.88054                0.88054              0.0732936
C8          0.861757               0.861757             0.0717302
C12         0.834925               0.834925             0.0694967
C11         0.786441               0.786441             0.0654611
C5          0.751215               0.751215             0.062529
C10         0.727692               0.727692             0.060571
C6          0.69523                0.69523              0.057869
C14         0.660648               0.660648             0.0549904
C4          0.640556               0.640556             0.053318
C3          0.632898               0.632898             0.0526806
C16         0.632156               0.632156             0.0526189
C1          0.559622               0.559622             0.0465813
C2          0.513372               0.513372             0.0427316
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_49

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018283530642690948  0.00047057936899363995  0.0         -0.007853119011030252  0.16798484325408936  0.18118774861497605  0.12028709053993225
    3        26       Softmax                      0.0   0.0   0.009956767214799375   0.03788129985332489     0.0         -0.1967016013032037    0.39835798740386963  -0.6533522929117814  0.19400322437286377


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12981359548524365
RMSE: 0.3602965382643076
LogLoss: 0.4271784853833402
Mean Per-Class Error: 0.11910623870198418
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
368.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    3.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    4.0    1.0    2.0    0.0    4.0    1.0    0.06835443037974684  27 / 395
0.0    351.0  0.0    5.0    2.0    0.0    1.0    7.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    5.0    5.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0835509138381201   32 / 383
0.0    0.0    314.0  0.0    10.0   1.0    8.0    1.0    0.0    0.0    11.0   3.0    0.0    0.0    2.0    0.0    1.0    0.0    6.0    2.0    7.0    0.0    2.0    0.0    0.0    0.0    0.14673913043478262  54 / 368
0.0    18.0   0.0    354.0  0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    6.0    4.0    1.0    1.0    0.0    3.0    2.0    0.0    1.0    0.0    0.0    3.0    0.0    3.0    0.12158808933002481  49 / 403
0.0    2.0    1.0    0.0    321.0  5.0    18.0   0.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    0.0    4.0    3.0    5.0    7.0    0.0    0.0    0.0    4.0    0.0    7.0    0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    1.0    0.0    4.0    2.0    2.0    0.0    1.0    2.0    1.0    10.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    4.0    1.0    0.0    0.0    356.0  4.0    2.0    0.09644670050761421  38 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    3.0    3.0    7.0    1.0    0.0    365.0  0.0    0.07124681933842239  28 / 393
3.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    13.0   2.0    0.0    0.0    0.0    0.0    0.0    327.0  0.10899182561307902  40 / 367
398.0  455.0  330.0  409.0  385.0  376.0  387.0  340.0  333.0  373.0  369.0  370.0  404.0  393.0  383.0  397.0  387.0  408.0  385.0  396.0  422.0  359.0  393.0  397.0  394.0  360.0  0.11836449065280416  1,184 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.881636
2    0.938818
3    0.962311
4    0.973808
5    0.980006
6    0.985704
7    0.989503
8    0.992302
9    0.994602
10   0.996001

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13278287858814075
RMSE: 0.3643938509197716
LogLoss: 0.43743234374541595
Mean Per-Class Error: 0.11572692559026523
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0   1.0    0.0   1.0   0.0   2.0    0.0   0.06741573033707865   6 / 89
0.0   92.0   0.0   1.0    1.0   0.0   1.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0    2.0    2.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.1320754716981132    14 / 106
0.0   0.0    68.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    2.0   0.0    0.0    0.0    3.0   1.0   1.0    0.0   1.0   0.0   0.0    0.0   0.17073170731707318   14 / 82
0.0   2.0    0.0   100.0  0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   2.0   1.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   0.0   2.0   0.0    1.0   0.10714285714285714   12 / 112
0.0   0.0    0.0   0.0    79.0  3.0   5.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    0.0   0.0    0.0    1.0    3.0   3.0   0.0    0.0   0.0   1.0   0.0    0.0   0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   88.0  0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   1.0   0.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   90.0  0.0    0.0   0.1                   10 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0    0.0   1.0   0.0    3.0   1.0   0.0   99.0   0.0   0.07476635514018691   8 / 107
2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218   10 / 87
95.0  110.0  72.0  116.0  90.0  90.0  99.0  85.0  79.0  109.0  93.0  95.0  88.0  102.0  83.0  109.0  100.0  105.0  99.0  95.0  106.0  80.0  98.0  97.0  110.0  85.0  0.11485943775100402   286 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.885141
2    0.938153
3    0.959438
4    0.972691
5    0.980723
6    0.986747
7    0.98996
8    0.990763
9    0.993574
10   0.995582
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:34  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:34  2 min 12.881 sec  22237 obs/sec     1         1             10007      0.519138         0.90132             0.995211       0.242227                         0.518951           0.90098               0.995201         0.248193
    2019-07-23 13:33:38  2 min 16.728 sec  23747 obs/sec     10        10            100070     0.360297         0.427178            0.997693       0.118364                         0.364394           0.437432              0.997634         0.114859
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0869531
C13         0.926471               0.926471             0.0805595
C8          0.833719               0.833719             0.0724944
C9          0.824391               0.824391             0.0716833
C12         0.81332                0.81332              0.0707207
C7          0.7583                 0.7583               0.0659365
C10         0.743724               0.743724             0.0646691
C5          0.723243               0.723243             0.0628882
C6          0.699227               0.699227             0.0608
C11         0.686818               0.686818             0.0597209
C14         0.672694               0.672694             0.0584928
C3          0.625379               0.625379             0.0543786
C4          0.597718               0.597718             0.0519734
C16         0.595075               0.595075             0.0517436
C1          0.505285               0.505285             0.0439361
C2          0.495091               0.495091             0.0430497
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_1

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.001868011596130259  0.0004502048250287771  0.0         -0.010130094204241047  0.16760104894638062  0.1717107080263594   0.12931108474731445
    3        26       Softmax                      0.0   0.0   0.01110751075276102   0.043673187494277954   0.0         -0.1983881634346653    0.39771509170532227  -0.6476142760647522  0.15135657787322998


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13114171069007796
RMSE: 0.3621349343685002
LogLoss: 0.4301668326293323
Mean Per-Class Error: 0.12550071929211812
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    5.0    0.0    0.0    0.0    0.0    2.0    5.0    3.0    3.0    2.0    1.0    0.0    4.0    0.0    0.0810126582278481   32 / 395
0.0    347.0  0.0    5.0    2.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    7.0    6.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.09399477806788512  36 / 383
0.0    0.0    324.0  0.0    12.0   0.0    3.0    1.0    0.0    0.0    9.0    1.0    2.0    0.0    5.0    0.0    1.0    1.0    1.0    2.0    5.0    0.0    1.0    0.0    0.0    0.0    0.11956521739130435  44 / 368
1.0    11.0   0.0    357.0  0.0    1.0    0.0    4.0    0.0    0.0    2.0    0.0    6.0    7.0    0.0    0.0    0.0    7.0    2.0    1.0    0.0    0.0    0.0    2.0    0.0    1.0    0.11194029850746269  45 / 402
0.0    6.0    3.0    0.0    324.0  4.0    17.0   1.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    0.0    3.0    3.0    4.0    5.0    0.0    0.0    0.0    4.0    0.0    3.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    14.0   1.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    4.0    5.0    1.0    0.0    1.0    2.0    4.0    6.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    0.0    360.0  1.0    1.0    0.08629441624365482  34 / 394
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    3.0    0.0    2.0    7.0    2.0    26.0   1.0    0.0    339.0  0.0    0.13520408163265307  53 / 392
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    32.0   2.0    0.0    0.0    0.0    2.0    0.0    306.0  0.16621253405994552  61 / 367
382.0  454.0  368.0  404.0  391.0  404.0  342.0  336.0  336.0  361.0  367.0  360.0  429.0  389.0  378.0  397.0  360.0  423.0  474.0  366.0  405.0  398.0  389.0  405.0  361.0  324.0  0.12496251124662601  1,250 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875038
2    0.939018
3    0.963211
4    0.974008
5    0.981506
6    0.987204
7    0.990903
8    0.993102
9    0.994802
10   0.995801

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1322507042846656
RMSE: 0.3636628992414068
LogLoss: 0.4377204479635536
Mean Per-Class Error: 0.12219947155581315
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   1.0   0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   94.0   0.0   1.0    1.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   3.0    1.0    0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.11320754716981132  12 / 106
0.0   0.0    70.0  0.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0    2.0   0.0    0.0   1.0   0.0   0.0    0.0   0.14634146341463414  12 / 82
1.0   1.0    0.0   100.0  0.0   1.0   0.0   2.0   0.0   0.0    1.0   0.0   2.0   2.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.10714285714285714  12 / 112
0.0   1.0    1.0   0.0    80.0  2.0   5.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0    3.0   0.0    0.0   0.0   1.0   0.0    1.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   2.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0   1.0   0.0   0.0   0.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   91.0  0.0    0.0   0.09                 9 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0    1.0   0.0    7.0   1.0   0.0   92.0   0.0   0.14018691588785046  15 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    6.0    0.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
90.0  117.0  79.0  112.0  96.0  98.0  85.0  84.0  81.0  106.0  94.0  93.0  96.0  99.0  82.0  116.0  94.0  105.0  110.0  88.0  102.0  88.0  96.0  99.0  101.0  79.0  0.12208835341365462  304 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877912
2    0.940562
3    0.963052
4    0.972691
5    0.978715
6    0.985141
7    0.98996
8    0.991165
9    0.993574
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:22  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:23  1.995 sec   17194 obs/sec     1         1             10007      0.529387         0.915407            0.995019       0.263321                         0.528748           0.920314              0.995018         0.270683
    2019-07-23 13:31:28  6.183 sec   22071 obs/sec     10        10            100070     0.362135         0.430167            0.997669       0.124963                         0.363663           0.43772               0.997643         0.122088
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.083745
C13         0.963797               0.963797             0.0807132
C8          0.856105               0.856105             0.0716946
C9          0.85083                0.85083              0.0712528
C12         0.837392               0.837392             0.0701275
C7          0.836551               0.836551             0.070057
C5          0.773914               0.773914             0.0648115
C11         0.757828               0.757828             0.0634643
C10         0.756151               0.756151             0.0633239
C6          0.684226               0.684226             0.0573005
C16         0.671672               0.671672             0.0562492
C14         0.635802               0.635802             0.0532453
C4          0.635533               0.635533             0.0532228
C3          0.61828                0.61828              0.0517779
C2          0.539638               0.539638             0.045192
C1          0.523285               0.523285             0.0438225
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_26

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0017787193663707512  0.00045008270535618067  0.0         -0.009720706312577043  0.16771316528320312  0.18906687166145209  0.11796420812606812
    3        26       Softmax                      0.0   0.0   0.009717976204473625   0.04070053994655609     0.0         -0.19793260420043277   0.39643967151641846  -0.6392273627107011  0.17885971069335938


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13167013343607842
RMSE: 0.3628637946062936
LogLoss: 0.4291681999006831
Mean Per-Class Error: 0.12513366783414998
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    7.0    1.0    1.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    1.0    2.0    2.0    0.0    3.0    2.0    0.07106598984771574  28 / 394
0.0    335.0  0.0    4.0    1.0    1.0    0.0    1.0    2.0    0.0    3.0    1.0    0.0    0.0    0.0    2.0    0.0    18.0   7.0    0.0    0.0    5.0    0.0    2.0    1.0    0.0    0.12532637075718014  48 / 383
0.0    0.0    325.0  0.0    8.0    0.0    4.0    1.0    0.0    0.0    14.0   2.0    0.0    0.0    6.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    3.0    1.0    0.0    0.0    0.11684782608695653  43 / 368
0.0    16.0   0.0    350.0  0.0    2.0    0.0    2.0    0.0    5.0    3.0    0.0    7.0    4.0    1.0    2.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.1315136476426799   53 / 403
0.0    4.0    2.0    0.0    318.0  6.0    17.0   0.0    0.0    0.0    5.0    3.0    0.0    0.0    0.0    0.0    1.0    4.0    7.0    3.0    0.0    0.0    0.0    4.0    0.0    10.0   0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    357.0  0.0    0.0    0.0    0.05053191489361702  19 / 376
0.0    1.0    0.0    5.0    3.0    0.0    0.0    1.0    2.0    4.0    13.0   0.0    0.0    0.0    2.0    0.0    0.0    1.0    1.0    3.0    1.0    0.0    0.0    352.0  3.0    2.0    0.1065989847715736   42 / 394
1.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    14.0   2.0    5.0    1.0    0.0    363.0  0.0    0.07633587786259542  30 / 393
1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    12.0   2.0    0.0    0.0    0.0    0.0    0.0    330.0  0.09836065573770492  36 / 366
395.0  443.0  362.0  414.0  381.0  402.0  326.0  284.0  343.0  382.0  419.0  372.0  401.0  382.0  399.0  382.0  340.0  446.0  387.0  392.0  403.0  371.0  410.0  405.0  397.0  365.0  0.12466260121963411  1,247 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875337
2    0.939518
3    0.962911
4    0.974108
5    0.981306
6    0.986704
7    0.990003
8    0.993002
9    0.994602
10   0.996101

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1336066709199077
RMSE: 0.36552246294845914
LogLoss: 0.4392988053848215
Mean Per-Class Error: 0.12588827597753635
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   1.0    0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   86.0   0.0   1.0    1.0   1.0   0.0   0.0   1.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0   7.0    2.0    0.0   0.0    3.0   0.0    1.0   1.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    69.0  0.0    1.0   0.0   1.0   0.0   0.0   0.0    3.0    1.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0    2.0   0.0    0.0   1.0    0.0   0.0    0.0   0.15853658536585366   13 / 82
0.0   2.0    0.0   98.0   0.0   1.0   0.0   1.0   0.0   3.0    1.0    0.0   3.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.125                 14 / 112
0.0   0.0    0.0   0.0    75.0  3.0   5.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    4.0    1.0   0.0    0.0   0.0    2.0   0.0    4.0   0.2268041237113402    22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   89.0   0.0   0.0    0.0   0.03260869565217391   3 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   0.0   0.0   1.0    7.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0    85.0  1.0    0.0   0.15                  15 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0    4.0   0.0    1.0   1.0    0.0   99.0   0.0   0.07476635514018691   8 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0    0.0   0.0    78.0  0.10344827586206896   9 / 87
91.0  105.0  75.0  113.0  88.0  96.0  83.0  69.0  81.0  115.0  105.0  97.0  92.0  99.0  89.0  108.0  90.0  115.0  100.0  93.0  101.0  82.0  101.0  96.0  118.0  88.0  0.12610441767068273   314 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873896
2    0.942972
3    0.959839
4    0.974297
5    0.980723
6    0.98514
7    0.989157
8    0.991566
9    0.993574
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:38  1 min 16.042 sec  22589 obs/sec     1         1             10007      0.522755         0.903588            0.995142       0.244427                         0.521592           0.900826              0.995152         0.24498
    2019-07-23 13:32:41  1 min 19.864 sec  23928 obs/sec     10        10            100070     0.362864         0.429168            0.99766        0.124663                         0.365522           0.439299              0.997619         0.126104
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0866312
C13         0.903287               0.903287             0.0782528
C9          0.835492               0.835492             0.0723797
C8          0.826693               0.826693             0.0716174
C7          0.806769               0.806769             0.0698913
C12         0.793091               0.793091             0.0687065
C11         0.744358               0.744358             0.0644846
C10         0.723539               0.723539             0.062681
C5          0.720482               0.720482             0.0624162
C6          0.67874                0.67874              0.0588001
C14         0.659262               0.659262             0.0571127
C16         0.635661               0.635661             0.0550681
C3          0.604495               0.604495             0.0523681
C4          0.597274               0.597274             0.0517426
C2          0.523794               0.523794             0.0453769
C1          0.490249               0.490249             0.0424709
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_13

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms         mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -----------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0025417088449728453  0.0007446212694048882  0.0         -0.001001590127827967  0.244886577129364  0.009866794805955875  0.2591649293899536
    3        26       Softmax                 0.0   0.0   0.003652508461527759   0.0017988434992730618  0.0         -0.004721773544882415  0.351814866065979  -0.5833524322468606   0.10843169689178467


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1298393977837357
RMSE: 0.3603323435160043
LogLoss: 0.43039850793953477
Mean Per-Class Error: 0.12477826710886902
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
374.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    4.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    0.0    3.0    4.0    0.053164556962025315  21 / 395
0.0    300.0  0.0    10.0   3.0    3.0    2.0    17.0   2.0    2.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    13.0   11.0   0.0    0.0    0.0    1.0    11.0   1.0    3.0    0.21671018276762402   83 / 383
0.0    0.0    322.0  1.0    4.0    1.0    10.0   2.0    0.0    0.0    8.0    2.0    0.0    0.0    2.0    0.0    3.0    1.0    4.0    5.0    3.0    0.0    0.0    0.0    0.0    0.0    0.125                 46 / 368
1.0    9.0    0.0    349.0  0.0    0.0    0.0    6.0    2.0    1.0    2.0    0.0    1.0    7.0    2.0    0.0    0.0    7.0    2.0    0.0    4.0    0.0    0.0    4.0    0.0    5.0    0.1318407960199005    53 / 402
0.0    1.0    4.0    0.0    326.0  7.0    19.0   1.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    1.0    0.0    3.0    1.0    3.0    1.0    0.0    0.0    2.0    0.0    10.0   0.15104166666666666   58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    9.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    348.0  0.0    0.0    1.0    0.072                 27 / 375
0.0    0.0    0.0    5.0    4.0    3.0    0.0    5.0    4.0    2.0    11.0   3.0    0.0    0.0    0.0    0.0    7.0    1.0    0.0    7.0    1.0    0.0    0.0    331.0  3.0    6.0    0.15776081424936386   62 / 393
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    7.0    1.0    18.0   1.0    0.0    353.0  0.0    0.10178117048346055   40 / 393
3.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    348.0  0.051771117166212535  19 / 367
399.0  358.0  341.0  411.0  381.0  387.0  379.0  400.0  355.0  363.0  362.0  355.0  395.0  385.0  381.0  405.0  409.0  409.0  361.0  406.0  424.0  369.0  384.0  382.0  383.0  419.0  0.12426272118364491   1,243 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875737
2    0.939618
3    0.962911
4    0.975008
5    0.981905
6    0.986004
7    0.988503
8    0.991603
9    0.993602
10   0.995301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13212862645138643
RMSE: 0.3634950157173911
LogLoss: 0.4427564394164619
Mean Per-Class Error: 0.12949589261561484
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7      8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25     Error                 Rate
----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  -----  --------------------  -----------
84.0  0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   2.0    1.0    0.056179775280898875  5 / 89
0.0   77.0  0.0   5.0    2.0   1.0   2.0   6.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   6.0    2.0   0.0   0.0    0.0   1.0   3.0   1.0    0.0    0.27358490566037735   29 / 106
0.0   0.0   73.0  0.0    1.0   0.0   1.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0   2.0   0.0    0.0   0.0   0.0   0.0    0.0    0.10975609756097561   9 / 82
1.0   1.0   0.0   96.0   0.0   0.0   0.0   3.0    1.0   0.0    1.0   0.0   0.0   3.0    1.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0    2.0    0.14285714285714285   16 / 112
0.0   0.0   1.0   0.0    79.0  5.0   5.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0   0.0   0.0    3.0    0.18556701030927836   18 / 97
---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---    ---                   ---
0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    2.0   87.0  0.0   0.0    0.0    0.05434782608695652   5 / 92
0.0   0.0   0.0   2.0    2.0   0.0   0.0   3.0    1.0   0.0    4.0   2.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   82.0  0.0    3.0    0.18                  18 / 100
0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   1.0   0.0    8.0   1.0   0.0   93.0   0.0    0.1308411214953271    14 / 107
1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    82.0   0.05747126436781609   5 / 87
90.0  85.0  76.0  116.0  91.0  92.0  95.0  108.0  86.0  105.0  89.0  95.0  84.0  102.0  81.0  114.0  99.0  104.0  86.0  97.0  108.0  84.0  97.0  95.0  109.0  102.0  0.12971887550200803   323 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.870281
2    0.942169
3    0.961847
4    0.973092
5    0.981526
6    0.985141
7    0.98755
8    0.989157
9    0.99237
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:00  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:01  39.235 sec  15587 obs/sec     1         1             10007      0.520632         0.921055            0.995182       0.255123                         0.522843           0.932172              0.995129         0.259438
    2019-07-23 13:32:06  44.573 sec  15296 obs/sec     9         9             90063      0.373099         0.461049            0.997526       0.137059                         0.376384           0.472495              0.997476         0.141767
    2019-07-23 13:32:07  45.267 sec  15435 obs/sec     10        10            100070     0.360332         0.430399            0.997692       0.124263                         0.363495           0.442756              0.997646         0.129719
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0856842
C15         0.993814               0.993814             0.0851541
C9          0.933468               0.933468             0.0799834
C12         0.928368               0.928368             0.0795464
C8          0.859894               0.859894             0.0736793
C10         0.775519               0.775519             0.0664497
C7          0.757051               0.757051             0.0648673
C11         0.748747               0.748747             0.0641558
C16         0.705527               0.705527             0.0604525
C6          0.66818                0.66818              0.0572524
C5          0.66226                0.66226              0.0567452
C14         0.648006               0.648006             0.0555239
C3          0.542451               0.542451             0.0464795
C4          0.529577               0.529577             0.0453764
C1          0.461564               0.461564             0.0395487
C2          0.456341               0.456341             0.0391012
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_27

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013597779973792967  0.0003659977810457349  0.0         -0.008188369236421522  0.20402950048446655  0.23476374018274365  0.14581257104873657
    3        26       Softmax                      0.0   0.0   0.008379248408748307   0.042597755789756775   0.0         -0.2616484503669898    0.5117318630218506   -0.4933213134062611  0.18635344505310059


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1337920518058387
RMSE: 0.36577595848529837
LogLoss: 0.44121608358254083
Mean Per-Class Error: 0.12763322359605517
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    4.0    2.0    3.0    0.0    1.0    0.0    0.0    1.0    2.0    0.0    2.0    4.0    2.0    1.0    4.0    0.0    0.07341772151898734  29 / 395
0.0    339.0  0.0    2.0    2.0    0.0    1.0    9.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    1.0    8.0    7.0    1.0    0.0    2.0    1.0    2.0    1.0    0.0    0.11488250652741515  44 / 383
0.0    0.0    324.0  0.0    9.0    1.0    8.0    0.0    0.0    0.0    8.0    2.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    3.0    0.0    0.0    0.0    0.11716621253405994  43 / 367
2.0    17.0   0.0    355.0  0.0    0.0    0.0    3.0    0.0    4.0    2.0    0.0    6.0    4.0    1.0    1.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.11910669975186104  48 / 403
0.0    2.0    0.0    0.0    310.0  4.0    11.0   4.0    0.0    0.0    5.0    4.0    0.0    0.0    0.0    1.0    8.0    3.0    6.0    5.0    0.0    0.0    0.0    7.0    0.0    14.0   0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
2.0    2.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    354.0  0.0    0.0    0.0    0.05851063829787234  22 / 376
0.0    2.0    0.0    4.0    4.0    0.0    0.0    2.0    3.0    3.0    13.0   2.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    3.0    1.0    0.0    0.0    346.0  3.0    3.0    0.1218274111675127   48 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    1.0    7.0    2.0    0.0    371.0  0.0    0.05597964376590331  22 / 393
2.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    8.0    2.0    0.0    0.0    0.0    1.0    0.0    333.0  0.09016393442622951  33 / 366
397.0  428.0  351.0  414.0  387.0  390.0  379.0  373.0  354.0  383.0  362.0  361.0  399.0  369.0  398.0  387.0  393.0  403.0  326.0  373.0  423.0  362.0  417.0  392.0  406.0  376.0  0.12716185144456663  1,272 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.872838
2    0.936119
3    0.959212
4    0.972008
5    0.979906
6    0.985904
7    0.989503
8    0.991203
9    0.993302
10   0.995401

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1342523995532613
RMSE: 0.3664046936834479
LogLoss: 0.4468889205766348
Mean Per-Class Error: 0.12129933654075396
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    1.0   1.0   0.0   2.0    0.0   0.06741573033707865   6 / 89
0.0   90.0   0.0   1.0    1.0   0.0   1.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    5.0    2.0   0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.1509433962264151    16 / 106
0.0   0.0    74.0  0.0    1.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0   3.0   0.0    0.0    0.0    0.0   2.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0975609756097561    8 / 82
1.0   3.0    0.0   99.0   0.0   0.0   0.0    2.0   0.0   0.0    1.0   0.0   2.0   1.0   0.0   0.0    0.0    0.0    0.0   0.0   1.0    0.0   0.0   1.0   0.0    1.0   0.11607142857142858   13 / 112
0.0   0.0    0.0   0.0    75.0  3.0   3.0    1.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    3.0    1.0    3.0   1.0   0.0    0.0   0.0   2.0   0.0    4.0   0.2268041237113402    22 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782   6 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0    1.0   0.0   1.0    4.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   86.0  1.0    1.0   0.14                  14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.0   0.0    2.0   1.0   0.0   103.0  0.0   0.037383177570093455  4 / 107
2.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    81.0  0.06896551724137931   6 / 87
91.0  106.0  79.0  113.0  90.0  90.0  100.0  94.0  83.0  107.0  87.0  96.0  87.0  99.0  91.0  108.0  101.0  102.0  84.0  85.0  107.0  84.0  97.0  96.0  117.0  96.0  0.1216867469879518    303 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878313
2    0.937349
3    0.957831
4    0.969478
5    0.978313
6    0.983936
7    0.988755
8    0.991165
9    0.993574
10   0.995582
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:41  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:42  1 min 20.205 sec  36655 obs/sec     1         1             10007      0.534943         0.926795            0.994914       0.251924                         0.534902           0.928821              0.994902         0.251807
    2019-07-23 13:32:44  1 min 22.522 sec  39366 obs/sec     10        10            100070     0.365776         0.441216            0.997622       0.127162                         0.366405           0.446889              0.997608         0.121687
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0798234
C8          0.995327               0.995327             0.0794504
C15         0.97373                0.97373              0.0777264
C12         0.94464                0.94464              0.0754044
C9          0.912589               0.912589             0.072846
C7          0.829726               0.829726             0.0662315
C5          0.807928               0.807928             0.0644916
C11         0.798715               0.798715             0.0637561
C10         0.792028               0.792028             0.0632223
C6          0.699819               0.699819             0.0558619
C14         0.690957               0.690957             0.0551545
C4          0.672657               0.672657             0.0536938
C16         0.653632               0.653632             0.0521751
C3          0.613996               0.613996             0.0490112
C1          0.606778               0.606778             0.0484351
C2          0.535136               0.535136             0.0427164
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_78

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0014458427549470798  0.0003829741617664695  0.0         -0.015136724014000902  0.2043687105178833  0.26349632920184163  0.157193124294281
    3        26       Softmax                      0.0   0.0   0.008762805787980072   0.03773294389247894    0.0         -0.25142188940359106   0.5180251598358154  -0.4873430691262162  0.16961324214935303


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13276080202446622
RMSE: 0.36436355748684063
LogLoss: 0.44115841352480517
Mean Per-Class Error: 0.12610320125246363
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    1.0    0.0    1.0    0.0    0.0    3.0    4.0    4.0    1.0    1.0    2.0    0.0    6.0    1.0    0.0810126582278481   32 / 395
0.0    331.0  0.0    2.0    2.0    0.0    1.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    25.0   5.0    0.0    0.0    2.0    0.0    3.0    1.0    0.0    0.13577023498694518  52 / 383
0.0    0.0    324.0  0.0    5.0    0.0    9.0    1.0    0.0    0.0    15.0   0.0    0.0    0.0    4.0    0.0    2.0    0.0    1.0    2.0    2.0    1.0    2.0    0.0    0.0    0.0    0.11956521739130435  44 / 368
1.0    14.0   0.0    354.0  0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    6.0    3.0    5.0    0.0    0.0    4.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    3.0    0.12158808933002481  49 / 403
0.0    6.0    4.0    0.0    324.0  6.0    15.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    3.0    5.0    0.0    2.0    1.0    0.0    0.0    4.0    0.0    11.0   0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    357.0  0.0    0.0    0.0    0.05053191489361702  19 / 376
0.0    1.0    0.0    3.0    4.0    0.0    0.0    2.0    2.0    3.0    5.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    2.0    1.0    0.0    0.0    362.0  2.0    4.0    0.08121827411167512  32 / 394
0.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    4.0    0.0    3.0    7.0    0.0    9.0    1.0    0.0    361.0  0.0    0.07908163265306123  31 / 392
1.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    12.0   2.0    0.0    0.0    0.0    4.0    0.0    330.0  0.1008174386920981   37 / 367
384.0  414.0  354.0  392.0  387.0  367.0  381.0  325.0  332.0  366.0  375.0  347.0  387.0  381.0  411.0  379.0  378.0  465.0  360.0  391.0  417.0  363.0  414.0  429.0  407.0  397.0  0.1254623612916125   1,255 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.874538
2    0.937019
3    0.960712
4    0.971109
5    0.979306
6    0.984605
7    0.989103
8    0.991403
9    0.993402
10   0.995401

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13502216827227917
RMSE: 0.36745362737667886
LogLoss: 0.4503980997565001
Mean Per-Class Error: 0.12302054970828132
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25     Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0    0.0    3.0    0.0    0.06741573033707865   6 / 89
0.0   86.0   0.0   0.0    2.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   8.0    2.0   0.0   0.0    2.0   0.0    2.0    1.0    0.0    0.18867924528301888   20 / 106
0.0   0.0    69.0  0.0    1.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    0.0   2.0   0.0    0.0   1.0    0.0    0.0    0.0    0.15853658536585366   13 / 82
1.0   1.0    0.0   99.0   0.0   0.0   0.0   2.0   0.0   1.0    0.0   0.0   2.0   1.0    1.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    0.0    0.11607142857142858   13 / 112
0.0   1.0    1.0   0.0    78.0  4.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    0.0   1.0   0.0    0.0   0.0    1.0    0.0    5.0    0.1958762886597938    19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   89.0   0.0    0.0    0.0    0.03260869565217391   3 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   1.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    88.0   1.0    1.0    0.12                  12 / 100
0.0   0.0    1.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   0.0   0.0    1.0   1.0    0.0    101.0  0.0    0.056074766355140186  6 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0    0.0    81.0   0.06896551724137931   6 / 87
90.0  100.0  74.0  110.0  89.0  92.0  96.0  82.0  76.0  110.0  95.0  92.0  84.0  101.0  89.0  103.0  97.0  118.0  84.0  90.0  104.0  80.0  101.0  106.0  121.0  106.0  0.12329317269076305   307 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876707
2    0.939759
3    0.961044
4    0.969879
5    0.979518
6    0.984337
7    0.988353
8    0.991165
9    0.993574
10   0.995582
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:44  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:44  3 min 22.247 sec  35996 obs/sec     1         1             10007      0.538058         0.926057            0.994855       0.251325                         0.537041           0.918419              0.994861         0.253012
    2019-07-23 13:34:46  3 min 24.596 sec  38801 obs/sec     10        10            100070     0.364364         0.441158            0.997641       0.125462                         0.367454           0.450398              0.997594         0.123293
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0858511
C13         0.951247               0.951247             0.0816656
C9          0.831444               0.831444             0.0713804
C12         0.822165               0.822165             0.0705837
C8          0.789134               0.789134             0.067748
C7          0.770017               0.770017             0.0661068
C11         0.75135                0.75135              0.0645042
C10         0.745971               0.745971             0.0640424
C5          0.741949               0.741949             0.0636971
C16         0.6682                 0.6682               0.0573657
C14         0.666269               0.666269             0.0571999
C6          0.655228               0.655228             0.056252
C4          0.62781                0.62781              0.0538982
C3          0.60176                0.60176              0.0516617
C1          0.538796               0.538796             0.0462562
C2          0.48674                0.48674              0.0417871
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_33

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013058424158884918  0.00036738114431500435  0.0         -0.0041472698463245194  0.20178097486495972  0.2520951078984253   0.15059316158294678
    3        26       Softmax                      0.0   0.0   0.008004580136685036   0.03938069939613342     0.0         -0.24604785765393664    0.5159609317779541   -0.4753647991138103  0.13819372653961182


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1336124342540706
RMSE: 0.3655303465569864
LogLoss: 0.4456018588870562
Mean Per-Class Error: 0.12616951919991934
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    2.0    2.0    0.0    1.0    0.0    0.0    2.0    6.0    1.0    2.0    2.0    1.0    2.0    4.0    0.0    0.0759493670886076   30 / 395
0.0    342.0  0.0    7.0    1.0    0.0    5.0    4.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    2.0    0.0    5.0    7.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.10471204188481675  40 / 382
0.0    0.0    310.0  0.0    14.0   0.0    11.0   0.0    0.0    0.0    9.0    2.0    0.0    1.0    6.0    0.0    0.0    0.0    5.0    1.0    6.0    0.0    1.0    1.0    0.0    0.0    0.1553133514986376   57 / 367
1.0    18.0   0.0    356.0  0.0    1.0    2.0    2.0    0.0    1.0    2.0    0.0    4.0    5.0    1.0    1.0    0.0    3.0    1.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    0.11662531017369727  47 / 403
0.0    5.0    1.0    0.0    326.0  2.0    19.0   1.0    0.0    0.0    2.0    3.0    0.0    0.0    0.0    1.0    4.0    3.0    3.0    6.0    0.0    0.0    0.0    2.0    0.0    6.0    0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    13.0   1.0    3.0    0.0    0.0    3.0    0.0    1.0    5.0    1.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    1.0    0.0    4.0    7.0    1.0    0.0    2.0    2.0    3.0    10.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    353.0  1.0    4.0    0.10406091370558376  41 / 394
0.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    6.0    0.0    6.0    1.0    0.0    370.0  0.0    0.05612244897959184  22 / 392
0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    7.0    7.0    0.0    0.0    0.0    1.0    0.0    331.0  0.09809264305177112  36 / 367
394.0  452.0  325.0  423.0  394.0  340.0  412.0  303.0  340.0  371.0  384.0  356.0  402.0  375.0  437.0  398.0  361.0  402.0  367.0  388.0  424.0  369.0  380.0  405.0  432.0  369.0  0.12556233130060981  1,256 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.874438
2    0.937919
3    0.960112
4    0.970309
5    0.978706
6    0.984405
7    0.988403
8    0.992102
9    0.994502
10   0.995901

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1367141230285301
RMSE: 0.36974872958338895
LogLoss: 0.45388386484197046
Mean Per-Class Error: 0.1258899947062967
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   92.0   0.0   1.0    1.0   0.0   1.0    1.0   1.0   0.0    1.0    0.0   0.0   0.0   2.0   0.0    0.0   3.0    1.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.1320754716981132   14 / 106
0.0   0.0    64.0  0.0    3.0   0.0   5.0    0.0   0.0   0.0    3.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.21951219512195122  18 / 82
1.0   3.0    0.0   98.0   0.0   1.0   0.0    1.0   0.0   1.0    1.0    0.0   1.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0    0.0   0.125                14 / 112
0.0   0.0    0.0   0.0    80.0  1.0   6.0    0.0   0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    1.0   1.0    1.0   3.0   0.0    0.0   0.0   1.0   0.0    1.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   3.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0    1.0   0.0   0.0    6.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   87.0  0.0    1.0   0.13                 13 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   0.0    2.0   1.0   0.0   102.0  0.0   0.04672897196261682  5 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   4.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   3.0   0.0    0.0   0.0   0.0   0.0    76.0  0.12643678160919541  11 / 87
87.0  114.0  65.0  118.0  95.0  82.0  105.0  74.0  82.0  109.0  102.0  95.0  87.0  99.0  92.0  108.0  94.0  103.0  94.0  95.0  107.0  83.0  95.0  99.0  121.0  85.0  0.1248995983935743   311 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.8751
2    0.936145
3    0.95743
4    0.969879
5    0.976707
6    0.983132
7    0.986747
8    0.991165
9    0.991968
10   0.994377
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:55  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:55  1 min 33.613 sec  35739 obs/sec     1         1             10007      0.532357         0.918291            0.994962       0.244327                         0.534281           0.926024              0.994914         0.248996
    2019-07-23 13:32:57  1 min 35.948 sec  38952 obs/sec     10        10            100070     0.36553          0.445602            0.997625       0.125562                         0.369749           0.453884              0.997564         0.1249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0860093
C15         0.941053               0.941053             0.0809392
C8          0.887196               0.887196             0.0763071
C9          0.843264               0.843264             0.0725285
C12         0.83598                0.83598              0.071902
C7          0.770607               0.770607             0.0662793
C10         0.726589               0.726589             0.0624934
C11         0.720685               0.720685             0.0619856
C5          0.688248               0.688248             0.0591957
C6          0.674347               0.674347             0.0580001
C14         0.670144               0.670144             0.0576386
C16         0.622869               0.622869             0.0535725
C4          0.618784               0.618784             0.0532211
C3          0.597864               0.597864             0.0514218
C1          0.52388                0.52388              0.0450585
C2          0.505147               0.505147             0.0434473
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_70

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013343416347595394  0.00036197551526129246  0.0         -0.009037393806799798  0.20208215713500977  0.25083094580738496  0.17415279150009155
    3        26       Softmax                      0.0   0.0   0.007489950405915107   0.033279940485954285    0.0         -0.25568274356394866   0.5191285610198975   -0.4971677939813564  0.14270079135894775


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1340022435087353
RMSE: 0.3660631687410457
LogLoss: 0.44499463607456513
Mean Per-Class Error: 0.12750143040434075
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    1.0    6.0    0.0    0.0    0.0    0.0    1.0    2.0    3.0    4.0    0.0    1.0    1.0    5.0    1.0    0.07614213197969544  30 / 394
0.0    347.0  0.0    5.0    2.0    4.0    1.0    2.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    0.0    10.0   4.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.09399477806788512  36 / 383
0.0    0.0    313.0  0.0    10.0   0.0    7.0    1.0    0.0    0.0    13.0   3.0    0.0    0.0    5.0    0.0    0.0    1.0    2.0    3.0    6.0    0.0    3.0    0.0    0.0    0.0    0.14713896457765668  54 / 367
0.0    10.0   0.0    359.0  0.0    0.0    0.0    1.0    0.0    1.0    0.0    1.0    5.0    5.0    1.0    1.0    0.0    10.0   3.0    0.0    1.0    0.0    0.0    3.0    0.0    2.0    0.10918114143920596  44 / 403
0.0    4.0    1.0    0.0    323.0  6.0    17.0   1.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    1.0    1.0    3.0    2.0    2.0    0.0    0.0    0.0    2.0    0.0    14.0   0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    11.0   0.0    3.0    0.0    0.0    1.0    0.0    0.0    6.0    2.0    347.0  0.0    0.0    0.0    0.07466666666666667  28 / 375
0.0    0.0    0.0    5.0    4.0    0.0    0.0    1.0    2.0    3.0    6.0    4.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    1.0    0.0    0.0    357.0  1.0    5.0    0.09390862944162437  37 / 394
1.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    20.0   1.0    15.0   1.0    0.0    344.0  0.0    0.12244897959183673  48 / 392
3.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    5.0    0.0    4.0    0.0    0.0    0.0    0.0    3.0    0.0    11.0   2.0    0.0    0.0    0.0    0.0    0.0    332.0  0.09536784741144415  35 / 367
388.0  446.0  339.0  431.0  394.0  413.0  363.0  299.0  352.0  366.0  385.0  393.0  401.0  388.0  411.0  370.0  326.0  426.0  363.0  387.0  416.0  384.0  392.0  412.0  376.0  382.0  0.12696191142657204  1,270 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873038
2    0.935919
3    0.960112
4    0.972108
5    0.980206
6    0.985004
7    0.988104
8    0.990803
9    0.993002
10   0.995201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13744413520532303
RMSE: 0.3707345886282032
LogLoss: 0.4553700564650325
Mean Per-Class Error: 0.1291633307573919
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11     12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   2.0    0.0   0.0   0.0   2.0    0.0   0.07865168539325842   7 / 89
0.0   87.0   0.0   0.0    1.0   1.0    1.0   1.0   0.0   0.0    1.0    0.0    0.0   0.0    0.0   1.0    0.0   8.0    1.0   0.0   0.0    3.0   0.0   1.0   0.0    0.0   0.1792452830188679    19 / 106
0.0   0.0    67.0  0.0    2.0   0.0    2.0   0.0   0.0   0.0    3.0    0.0    0.0   0.0    3.0   0.0    0.0   0.0    1.0   2.0   1.0    0.0   1.0   0.0   0.0    0.0   0.18292682926829268   15 / 82
0.0   0.0    0.0   101.0  0.0   0.0    0.0   1.0   0.0   1.0    0.0    0.0    1.0   2.0    0.0   0.0    0.0   0.0    2.0   0.0   1.0    0.0   0.0   2.0   0.0    1.0   0.09821428571428571   11 / 112
0.0   1.0    0.0   0.0    77.0  4.0    5.0   0.0   0.0   0.0    1.0    2.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0   1.0   0.0    3.0   0.20618556701030927   20 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0   88.0  0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    2.0   0.0    0.0   0.0   0.0   0.0    4.0    3.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   86.0  0.0    3.0   0.14                  14 / 100
0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   5.0   0.0    4.0   1.0   0.0   95.0   0.0   0.11214953271028037   12 / 107
1.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0   0.0   1.0    0.0    3.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    79.0  0.09195402298850575   8 / 87
86.0  106.0  72.0  120.0  92.0  100.0  94.0  72.0  86.0  105.0  103.0  104.0  87.0  102.0  88.0  104.0  87.0  112.0  91.0  92.0  105.0  84.0  99.0  97.0  108.0  94.0  0.12971887550200803   323 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.870281
2    0.934538
3    0.959036
4    0.971486
5    0.979518
6    0.985944
7    0.988353
8    0.990763
9    0.993976
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:23  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:24  3 min  2.027 sec  30790 obs/sec     1         1             10007      0.536707         0.93991             0.994878       0.252724                         0.538448           0.940802              0.994834         0.255422
    2019-07-23 13:34:26  3 min  4.417 sec  37507 obs/sec     10        10            100070     0.366063         0.444995            0.997617       0.126962                         0.370735           0.45537               0.997551         0.129719
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0833477
C13         0.942234               0.942234             0.078533
C8          0.896374               0.896374             0.0747107
C7          0.834308               0.834308             0.0695376
C9          0.829823               0.829823             0.0691638
C12         0.826057               0.826057             0.06885
C10         0.791776               0.791776             0.0659927
C5          0.764891               0.764891             0.0637519
C11         0.761061               0.761061             0.0634326
C6          0.700651               0.700651             0.0583976
C14         0.661703               0.661703             0.0551514
C3          0.637056               0.637056             0.0530971
C4          0.615753               0.615753             0.0513216
C16         0.609275               0.609275             0.0507816
C1          0.599708               0.599708             0.0499843
C2          0.527268               0.527268             0.0439466
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_29

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013983265323247451  0.00034612766467034817  0.0         -0.011108420933098273  0.2050495743751526  0.24688314530028055   0.14878469705581665
    3        26       Softmax                      0.0   0.0   0.00838741728282982    0.04471766948699951     0.0         -0.24284225058163253   0.5160481929779053  -0.49412526113920396  0.1591302752494812


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1346790299600867
RMSE: 0.3669864165879804
LogLoss: 0.44201463911352934
Mean Per-Class Error: 0.12984905672527997
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    3.0    3.0    5.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    1.0    3.0    1.0    0.0    3.0    0.0    0.08607594936708861  34 / 395
0.0    317.0  1.0    5.0    2.0    7.0    1.0    8.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    7.0    14.0   11.0   0.0    0.0    2.0    0.0    2.0    2.0    0.0    0.17232375979112272  66 / 383
0.0    0.0    322.0  0.0    9.0    2.0    3.0    1.0    0.0    0.0    7.0    2.0    0.0    0.0    4.0    0.0    1.0    1.0    6.0    1.0    5.0    0.0    4.0    0.0    0.0    0.0    0.125                46 / 368
0.0    4.0    0.0    362.0  0.0    1.0    0.0    4.0    1.0    2.0    0.0    2.0    5.0    4.0    0.0    0.0    0.0    4.0    2.0    0.0    2.0    0.0    0.0    4.0    0.0    6.0    0.10173697270471464  41 / 403
0.0    4.0    2.0    1.0    326.0  5.0    13.0   2.0    0.0    0.0    3.0    8.0    0.0    0.0    0.0    1.0    5.0    3.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    6.0    0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    17.0   1.0    1.0    0.0    0.0    3.0    0.0    0.0    2.0    1.0    347.0  0.0    0.0    0.0    0.07466666666666667  28 / 375
0.0    1.0    0.0    4.0    5.0    1.0    0.0    2.0    2.0    0.0    8.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    0.0    356.0  1.0    2.0    0.09414758269720101  37 / 393
0.0    0.0    0.0    2.0    0.0    14.0   0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    0.0    1.0    11.0   1.0    13.0   1.0    0.0    344.0  0.0    0.12468193384223919  49 / 393
2.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    16.0   1.0    0.0    0.0    0.0    1.0    0.0    317.0  0.1362397820163488   50 / 367
387.0  395.0  356.0  437.0  397.0  462.0  355.0  336.0  344.0  371.0  382.0  385.0  434.0  377.0  381.0  378.0  378.0  405.0  420.0  351.0  395.0  384.0  382.0  401.0  362.0  348.0  0.12936119164250726  1,294 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.870639
2    0.936319
3    0.959712
4    0.972108
5    0.980206
6    0.985604
7    0.990303
8    0.992802
9    0.994802
10   0.996501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13736651872832592
RMSE: 0.37062989454215095
LogLoss: 0.4556649388665165
Mean Per-Class Error: 0.12812367703198332
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11    12     13     14    15     16     17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.0    0.0    0.0    1.0    0.0   0.0    1.0   0.0   0.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   80.0   0.0   0.0    2.0   2.0    1.0   2.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0   1.0    2.0    7.0    3.0    0.0   0.0    2.0   0.0   1.0    2.0    0.0   0.24528301886792453  26 / 106
0.0   0.0    68.0  0.0    2.0   1.0    0.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0    2.0   0.0    0.0    0.0    3.0    0.0   2.0    0.0   1.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
0.0   2.0    0.0   99.0   0.0   0.0    0.0   2.0   1.0   0.0    0.0   1.0   2.0    1.0    0.0   0.0    0.0    0.0    0.0    0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.11607142857142858  13 / 112
0.0   1.0    0.0   0.0    79.0  3.0    4.0   0.0   0.0   0.0    0.0   2.0   0.0    0.0    0.0   0.0    1.0    1.0    3.0    0.0   0.0    0.0   0.0   1.0    0.0    2.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   4.0    0.0    0.0   0.0    0.0    1.0    0.0    0.0   0.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   1.0    0.0   1.0   0.0   0.0    4.0   1.0   0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   88.0   0.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   2.0    1.0    0.0    0.0    3.0   0.0    3.0   1.0   0.0    93.0   0.0   0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    6.0   0.0    0.0   0.0   0.0   2.0    0.0   1.0   0.0    0.0    0.0   0.0    0.0    0.0    2.0    0.0   0.0    0.0   0.0   0.0    0.0    75.0  0.13793103448275862  12 / 87
88.0  100.0  73.0  118.0  96.0  112.0  89.0  85.0  83.0  107.0  97.0  98.0  101.0  100.0  77.0  107.0  102.0  102.0  103.0  85.0  100.0  86.0  94.0  100.0  102.0  85.0  0.12811244979919678  319 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871888
2    0.932932
3    0.958233
4    0.971084
5    0.978715
6    0.983133
7    0.987952
8    0.991566
9    0.993574
10   0.995582
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:46  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:47  1 min 25.226 sec  33135 obs/sec     1         1             10007      0.530979         0.919361            0.994989       0.248326                         0.531317           0.91895               0.99497          0.250602
    2019-07-23 13:32:49  1 min 27.572 sec  38607 obs/sec     10        10            100070     0.366986         0.442015            0.997606       0.129361                         0.37063            0.455665              0.997552         0.128112
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0890044
C13         0.907086               0.907086             0.0807346
C9          0.843692               0.843692             0.0750923
C8          0.828248               0.828248             0.0737177
C7          0.794059               0.794059             0.0706747
C12         0.776016               0.776016             0.0690688
C5          0.729521               0.729521             0.0649306
C10         0.717815               0.717815             0.0638887
C11         0.6827                 0.6827               0.0607633
C14         0.615479               0.615479             0.0547803
C6          0.604866               0.604866             0.0538358
C4          0.581512               0.581512             0.0517571
C16         0.571806               0.571806             0.0508932
C3          0.554134               0.554134             0.0493204
C2          0.529385               0.529385             0.0471176
C1          0.499084               0.499084             0.0444206
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_25

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.001927327718107108   0.0005618657451122999  0.0         -0.0015104299479880012  0.3389878273010254  0.03630689509434223  0.3764960765838623
    3        26       Softmax                 0.0   0.0   0.0029431881060610556  0.0010648425668478012  0.0         -0.01213329940859882    0.4420759677886963  -0.5353328930658445  0.17815637588500977


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1364409318662761
RMSE: 0.36937911671651946
LogLoss: 0.45846400312130337
Mean Per-Class Error: 0.13082829590478068
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    5.0    1.0    3.0    0.0    0.0    0.0    0.0    2.0    6.0    2.0    1.0    1.0    2.0    1.0    3.0    0.0    0.08860759493670886  35 / 395
0.0    327.0  0.0    11.0   4.0    0.0    1.0    10.0   1.0    0.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    12.0   7.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    0.1462140992167102   56 / 383
0.0    0.0    326.0  1.0    6.0    1.0    5.0    0.0    0.0    0.0    13.0   1.0    1.0    0.0    3.0    0.0    2.0    1.0    4.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.11171662125340599  41 / 367
0.0    6.0    0.0    362.0  0.0    1.0    0.0    4.0    1.0    5.0    0.0    0.0    6.0    3.0    0.0    1.0    0.0    7.0    0.0    0.0    1.0    0.0    0.0    4.0    0.0    2.0    0.10173697270471464  41 / 403
0.0    1.0    2.0    0.0    331.0  4.0    11.0   2.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    7.0    2.0    9.0    1.0    1.0    0.0    0.0    4.0    0.0    4.0    0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    16.0   0.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    0.0    0.0    6.0    8.0    1.0    0.0    2.0    6.0    5.0    6.0    2.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    3.0    1.0    0.0    0.0    344.0  2.0    3.0    0.12690355329949238  50 / 394
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    9.0    1.0    7.0    1.0    1.0    362.0  0.0    0.07888040712468193  31 / 393
0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    1.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    23.0   3.0    0.0    0.0    0.0    0.0    0.0    320.0  0.12806539509536785  47 / 367
383.0  424.0  353.0  446.0  399.0  400.0  355.0  326.0  349.0  383.0  393.0  361.0  415.0  374.0  380.0  381.0  372.0  420.0  406.0  381.0  413.0  367.0  386.0  400.0  387.0  349.0  0.13016095171448566  1,302 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869839
2    0.93312
3    0.958612
4    0.970309
5    0.978806
6    0.983605
7    0.987304
8    0.989603
9    0.992502
10   0.994002

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.137814509080094
RMSE: 0.37123376608290093
LogLoss: 0.4607308998783082
Mean Per-Class Error: 0.13237832226856508
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   1.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   87.0   0.0   5.0    3.0   0.0   1.0   2.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   4.0    1.0    0.0   0.0    0.0   1.0   1.0   0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    72.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.12195121951219512  10 / 82
0.0   1.0    0.0   98.0   0.0   0.0   0.0   2.0   1.0   2.0    0.0   0.0   3.0   1.0    0.0   1.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.125                14 / 112
0.0   0.0    1.0   0.0    78.0  3.0   3.0   0.0   1.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    4.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    1.0   0.0    0.0   0.0    0.0    0.0   2.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    4.0   0.0   0.0   1.0   0.0   1.0    1.0   2.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0   85.0  1.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    3.0   0.0    5.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0    1.0   0.0    0.0   0.0   0.0   0.0    78.0  0.10344827586206896  9 / 87
88.0  111.0  77.0  125.0  93.0  94.0  87.0  81.0  83.0  108.0  97.0  96.0  90.0  100.0  81.0  111.0  94.0  105.0  106.0  86.0  107.0  85.0  96.0  95.0  107.0  87.0  0.13253012048192772  330 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86747
2    0.940161
3    0.963052
4    0.971888
5    0.978715
6    0.983133
7    0.987149
8    0.988755
9    0.99237
10   0.994378
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:34  1 min 12.139 sec  24587 obs/sec     1         1             10007      0.538211         0.951567            0.994853       0.254324                         0.537378           0.945943              0.994854         0.260241
    2019-07-23 13:32:37  1 min 15.482 sec  27075 obs/sec     10        10            100070     0.369379         0.458464            0.997575       0.130161                         0.371234           0.460731              0.997544         0.13253
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0895051
C13         0.940038               0.940038             0.0841382
C9          0.868712               0.868712             0.0777542
C8          0.860657               0.860657             0.0770332
C12         0.830724               0.830724             0.0743541
C7          0.765405               0.765405             0.0685077
C10         0.755673               0.755673             0.0676366
C11         0.713395               0.713395             0.0638526
C16         0.669487               0.669487             0.0599225
C14         0.638223               0.638223             0.0571242
C5          0.621043               0.621043             0.0555866
C6          0.606662               0.606662             0.0542993
C2          0.496994               0.496994             0.0444835
C4          0.486551               0.486551             0.0435488
C3          0.473017               0.473017             0.0423375
C1          0.44596                0.44596              0.0399157
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_89

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0020045018301004802  0.0005198225844651461  0.0         0.0014261315913302042  0.3429701328277588   0.016620144286826868  0.38364744186401367
    3        26       Softmax                 0.0   0.0   0.0031470355646398764  0.0013714926317334175  0.0         -0.01747244964594084   0.45075833797454834  -0.5387786165677138   0.14376789331436157


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1371354321104775
RMSE: 0.3703180148338418
LogLoss: 0.4573204451069791
Mean Per-Class Error: 0.1305562487299473
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
369.0  0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    1.0    4.0    2.0    3.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    1.0    1.0    1.0    1.0    3.0    1.0    0.06582278481012659  26 / 395
0.0    326.0  0.0    8.0    3.0    3.0    1.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    2.0    14.0   10.0   0.0    0.0    3.0    0.0    2.0    1.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    320.0  1.0    5.0    1.0    9.0    2.0    0.0    0.0    13.0   0.0    0.0    0.0    2.0    0.0    2.0    0.0    6.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    0.13043478260869565  48 / 368
1.0    13.0   0.0    349.0  0.0    4.0    0.0    4.0    1.0    4.0    0.0    0.0    4.0    6.0    2.0    1.0    0.0    4.0    5.0    0.0    1.0    0.0    0.0    4.0    0.0    0.0    0.13399503722084366  54 / 403
0.0    1.0    3.0    0.0    321.0  8.0    15.0   0.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    1.0    2.0    6.0    10.0   4.0    0.0    1.0    0.0    2.0    0.0    5.0    0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    16.0   0.0    4.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    1.0    0.0    2.0    5.0    2.0    0.0    1.0    4.0    3.0    7.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    1.0    0.0    0.0    353.0  4.0    4.0    0.10406091370558376  41 / 394
0.0    1.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    2.0    10.0   1.0    20.0   1.0    2.0    343.0  0.0    0.1272264631043257   50 / 393
2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    22.0   2.0    0.0    0.0    0.0    6.0    0.0    310.0  0.15300546448087432  56 / 366
401.0  420.0  342.0  409.0  381.0  403.0  374.0  287.0  343.0  374.0  385.0  374.0  418.0  382.0  406.0  404.0  361.0  424.0  435.0  374.0  403.0  385.0  389.0  417.0  376.0  336.0  0.12986104168749374  1,299 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.870139
2    0.93382
3    0.957813
4    0.971209
5    0.978606
6    0.985004
7    0.988004
8    0.989903
9    0.992502
10   0.994402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14180785663729736
RMSE: 0.37657383955513607
LogLoss: 0.47733961788872087
Mean Per-Class Error: 0.1330868982377068
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.07865168539325842  7 / 89
0.0   84.0   0.0   3.0    2.0   1.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0   5.0    3.0    0.0   0.0    3.0   0.0   1.0   0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    71.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.13414634146341464  11 / 82
1.0   1.0    0.0   96.0   0.0   0.0   0.0   3.0   1.0   2.0    0.0   0.0   1.0   2.0    0.0   1.0    0.0   0.0    2.0    0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    78.0  5.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0    1.0   0.0    1.0   0.0   1.0   0.0    1.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0   0.0    1.0   0.0    0.0   0.0    0.0    0.0   0.0    1.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    3.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   87.0  1.0    1.0   0.13                 13 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0    1.0   0.0    7.0   1.0   0.0   93.0   0.0   0.1308411214953271   14 / 107
2.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0    0.0   0.0    0.0   0.0   1.0   0.0    73.0  0.16091954022988506  14 / 87
92.0  104.0  72.0  114.0  91.0  98.0  93.0  75.0  86.0  108.0  98.0  99.0  90.0  101.0  87.0  116.0  95.0  106.0  110.0  86.0  102.0  92.0  93.0  96.0  108.0  78.0  0.13293172690763053  331 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.867068
2    0.93253
3    0.956627
4    0.969076
5    0.975502
6    0.982731
7    0.985944
8    0.989558
9    0.99237
10   0.994378
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:14  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:15  3 min 53.109 sec  26473 obs/sec     1         1             10007      0.539942         0.957888            0.994818       0.261022                         0.538102           0.950025              0.994841         0.263454
    2019-07-23 13:35:18  3 min 56.387 sec  27797 obs/sec     10        10            100070     0.370318         0.45732             0.997563       0.129861                         0.376574           0.47734               0.997473         0.132932
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0874787
C15         0.978281               0.978281             0.0855787
C8          0.861555               0.861555             0.0753677
C12         0.842572               0.842572             0.0737071
C9          0.840929               0.840929             0.0735634
C7          0.797021               0.797021             0.0697223
C11         0.740113               0.740113             0.0647441
C14         0.736844               0.736844             0.0644581
C10         0.736143               0.736143             0.0643968
C6          0.6708                 0.6708               0.0586807
C16         0.668263               0.668263             0.0584587
C5          0.648538               0.648538             0.0567333
C3          0.527568               0.527568             0.046151
C4          0.517952               0.517952             0.0453098
C2          0.437428               0.437428             0.0382656
C1          0.42735                0.42735              0.0373841
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_24

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0018620944547080853  0.0005260189063847065  0.0         0.014652390896216616    0.3320190906524658   0.0058577175153211244  0.3650491237640381
    3        26       Softmax                 0.0   0.0   0.0028864558991629633  0.0010364968329668045  0.0         -0.0016832513756963425  0.44812262058258057  -0.5446053539535524    0.17630505561828613


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1402088537884352
RMSE: 0.37444472728085676
LogLoss: 0.46923684291207673
Mean Per-Class Error: 0.13206009160072713
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    1.0    1.0    5.0    0.0    0.0    0.0    0.0    1.0    3.0    4.0    2.0    0.0    0.0    2.0    4.0    2.0    0.07848101265822785  31 / 395
0.0    328.0  0.0    8.0    2.0    0.0    1.0    6.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    14.0   5.0    1.0    0.0    9.0    0.0    3.0    0.0    0.0    0.14136125654450263  54 / 382
0.0    0.0    317.0  1.0    10.0   1.0    7.0    1.0    0.0    0.0    9.0    3.0    0.0    0.0    8.0    0.0    1.0    1.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.13858695652173914  51 / 368
1.0    15.0   0.0    356.0  0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    3.0    5.0    1.0    0.0    0.0    7.0    1.0    0.0    2.0    0.0    0.0    4.0    0.0    1.0    0.11662531017369727  47 / 403
0.0    1.0    4.0    0.0    330.0  4.0    14.0   0.0    0.0    0.0    2.0    3.0    0.0    0.0    0.0    1.0    5.0    4.0    2.0    4.0    1.0    0.0    0.0    3.0    0.0    6.0    0.140625             54 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    7.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    4.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    0.0    0.0    4.0    3.0    1.0    0.0    2.0    3.0    3.0    5.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    0.0    0.0    360.0  5.0    3.0    0.08629441624365482  34 / 394
0.0    0.0    0.0    2.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    1.0    9.0    3.0    10.0   1.0    0.0    357.0  0.0    0.0916030534351145   36 / 393
0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    11.0   0.0    3.0    0.0    0.0    0.0    0.0    5.0    0.0    9.0    5.0    0.0    0.0    0.0    1.0    0.0    325.0  0.11444141689373297  42 / 367
402.0  488.0  337.0  427.0  383.0  360.0  382.0  305.0  342.0  383.0  349.0  376.0  386.0  386.0  387.0  381.0  378.0  428.0  309.0  404.0  422.0  378.0  395.0  423.0  408.0  384.0  0.13126062181345596  1,313 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.868739
2    0.931021
3    0.956113
4    0.968609
5    0.977307
6    0.982405
7    0.987104
8    0.990503
9    0.992502
10   0.994202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1448377080995048
RMSE: 0.3805754959262417
LogLoss: 0.48315236694703295
Mean Per-Class Error: 0.13320114876193861
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0   0.0    0.0   0.0    0.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   87.0   0.0   3.0    2.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    5.0    1.0   1.0   0.0    4.0   0.0    1.0    0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    70.0  0.0    2.0   1.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    2.0   0.0   1.0    0.0   0.0    0.0    0.0    0.0   0.14634146341463414  12 / 82
1.0   2.0    0.0   97.0   0.0   0.0   0.0   3.0   0.0   1.0    0.0   0.0   1.0   1.0    0.0   0.0    0.0    1.0    1.0   0.0   1.0    0.0   0.0    2.0    0.0    1.0   0.13392857142857142  15 / 112
0.0   0.0    1.0   0.0    80.0  2.0   3.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    0.0   0.0    1.0    1.0    2.0   3.0   0.0    0.0   0.0    1.0    0.0    1.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   89.0   0.0    0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   1.0    1.0   0.0   0.0   1.0   0.0   1.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    91.0   1.0    1.0   0.09                 9 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0    0.0    0.0   2.0   0.0    3.0   1.0    0.0    96.0   0.0   0.102803738317757    11 / 107
0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   3.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0    0.0    79.0  0.09195402298850575  8 / 87
94.0  119.0  76.0  115.0  90.0  83.0  95.0  82.0  84.0  114.0  86.0  93.0  85.0  100.0  78.0  105.0  100.0  109.0  85.0  96.0  105.0  82.0  103.0  104.0  113.0  94.0  0.1321285140562249   329 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.867871
2    0.929719
3    0.95502
4    0.966667
5    0.977912
6    0.981526
7    0.986345
8    0.990763
9    0.992771
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:29  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:30  1 min  8.270 sec  28268 obs/sec     1         1             10007      0.537139         0.946661            0.994872       0.252524                         0.536379           0.950467              0.994874         0.253815
    2019-07-23 13:32:33  1 min 11.659 sec  27356 obs/sec     10        10            100070     0.374445         0.469237            0.997508       0.131261                         0.380575           0.483152              0.997419         0.132129
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0917301
C15         0.979355               0.979355             0.0898364
C9          0.835856               0.835856             0.0766732
C12         0.809436               0.809436             0.0742497
C8          0.783956               0.783956             0.0719123
C10         0.740781               0.740781             0.067952
C7          0.738032               0.738032             0.0676997
C11         0.705821               0.705821             0.064745
C16         0.660102               0.660102             0.0605512
C14         0.613741               0.613741             0.0562986
C6          0.595249               0.595249             0.0546023
C5          0.578288               0.578288             0.0530464
C3          0.549146               0.549146             0.0503732
C4          0.476072               0.476072             0.0436701
C2          0.435218               0.435218             0.0399226
C1          0.400491               0.400491             0.0367371
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_104

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0021793530797538097  0.0006251761224120855  0.0         0.000960290037042455   0.30402541160583496  -0.007033824156987348  0.3507634401321411
    3        26       Softmax                 0.0   0.0   0.002707717078954794   0.0012340666726231575  0.0         -8.33574643508246e-05  0.3231236934661865   -0.5608247740722605    0.14353853464126587


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13901315470022155
RMSE: 0.3728446790557987
LogLoss: 0.47027801167886873
Mean Per-Class Error: 0.13997641273245856
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
368.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    3.0    2.0    3.0    1.0    2.0    0.0    3.0    4.0    0.06835443037974684   27 / 395
0.0    333.0  0.0    7.0    4.0    0.0    1.0    7.0    1.0    0.0    2.0    0.0    0.0    0.0    3.0    0.0    2.0    7.0    4.0    0.0    0.0    10.0   0.0    1.0    0.0    1.0    0.13054830287206268   50 / 383
0.0    1.0    316.0  1.0    12.0   0.0    8.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    7.0    0.0    2.0    1.0    1.0    3.0    3.0    0.0    2.0    0.0    0.0    0.0    0.14130434782608695   52 / 368
1.0    10.0   0.0    353.0  0.0    0.0    0.0    4.0    0.0    5.0    0.0    0.0    3.0    4.0    4.0    1.0    0.0    7.0    0.0    0.0    4.0    0.0    0.0    4.0    0.0    3.0    0.12406947890818859   50 / 403
0.0    0.0    1.0    0.0    322.0  6.0    14.0   0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    6.0    3.0    2.0    6.0    0.0    0.0    0.0    1.0    0.0    19.0   0.16145833333333334   62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    7.0    0.0    7.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    353.0  0.0    0.0    0.0    0.061170212765957445  23 / 376
0.0    2.0    0.0    6.0    7.0    1.0    0.0    1.0    4.0    2.0    13.0   1.0    0.0    0.0    2.0    0.0    5.0    1.0    0.0    3.0    1.0    0.0    0.0    338.0  1.0    6.0    0.14213197969543148   56 / 394
0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    1.0    4.0    1.0    17.0   1.0    1.0    361.0  0.0    0.08142493638676845   32 / 393
2.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    12.0   4.0    0.0    0.0    0.0    0.0    0.0    329.0  0.10354223433242507   38 / 367
399.0  428.0  329.0  419.0  420.0  372.0  386.0  304.0  341.0  381.0  382.0  356.0  391.0  377.0  422.0  374.0  400.0  392.0  276.0  392.0  425.0  403.0  406.0  389.0  410.0  429.0  0.13915825252424271   1,392 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.860842
2    0.927922
3    0.954914
4    0.96831
5    0.977207
6    0.982305
7    0.987804
8    0.990803
9    0.992302
10   0.994002

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14283249906613005
RMSE: 0.37793187093195785
LogLoss: 0.48445761961230077
Mean Per-Class Error: 0.14258731371021416
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16     17    18    19    20     21    22    23    24     25     Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  -----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0   0.0   1.0    0.0   1.0   0.0   2.0    0.0    0.056179775280898875  5 / 89
0.0   85.0   0.0   3.0    3.0   0.0   1.0    2.0   0.0   0.0    1.0   0.0   0.0   0.0    1.0   0.0    0.0    2.0   1.0   0.0   0.0    6.0   0.0   1.0   0.0    0.0    0.19811320754716982   21 / 106
0.0   0.0    70.0  0.0    3.0   0.0   1.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0   1.0   2.0   0.0    0.0   1.0   0.0   0.0    0.0    0.14634146341463414   12 / 82
1.0   1.0    0.0   98.0   0.0   0.0   0.0    2.0   0.0   1.0    0.0   0.0   1.0   2.0    1.0   1.0    0.0    1.0   0.0   0.0   1.0    0.0   0.0   1.0   0.0    1.0    0.125                 14 / 112
0.0   0.0    0.0   0.0    75.0  4.0   3.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0   1.0   3.0   0.0    0.0   0.0   0.0   0.0    7.0    0.2268041237113402    22 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   1.0    0.0   87.0  0.0   0.0    0.0    0.05434782608695652   5 / 92
0.0   0.0    0.0   3.0    4.0   0.0   0.0    0.0   0.0   0.0    5.0   0.0   0.0   0.0    0.0   0.0    1.0    1.0   0.0   0.0   0.0    0.0   0.0   83.0  0.0    3.0    0.17                  17 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0    0.0   0.0   0.0   0.0    5.0   1.0   0.0   99.0   0.0    0.07476635514018691   8 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0    80.0   0.08045977011494253   7 / 87
90.0  102.0  72.0  119.0  95.0  86.0  100.0  81.0  82.0  107.0  98.0  94.0  88.0  101.0  92.0  105.0  100.0  98.0  67.0  92.0  105.0  97.0  97.0  92.0  118.0  112.0  0.142570281124498     355 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.85743
2    0.928916
3    0.951406
4    0.96747
5    0.973494
6    0.97992
7    0.987149
8    0.990362
9    0.99237
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:55  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:55  4 min 33.717 sec  16324 obs/sec     1         1             10007      0.522653         0.923765            0.995146       0.257523                         0.524849           0.932036              0.995092         0.265462
    2019-07-23 13:36:01  4 min 39.407 sec  16124 obs/sec     10        10            100070     0.372845         0.470278            0.99753        0.139158                         0.377932           0.484458              0.997455         0.14257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0880809
C13         0.991406               0.991406             0.0873239
C12         0.873939               0.873939             0.0769773
C9          0.84165                0.84165              0.0741333
C8          0.833872               0.833872             0.0734482
C11         0.752308               0.752308             0.066264
C7          0.742656               0.742656             0.0654138
C10         0.732824               0.732824             0.0645477
C5          0.68286                0.68286              0.0601469
C14         0.658274               0.658274             0.0579814
C16         0.644318               0.644318             0.0567521
C6          0.605163               0.605163             0.0533033
C3          0.589988               0.589988             0.0519666
C4          0.506283               0.506283             0.0445939
C2          0.459777               0.459777             0.0404975
C1          0.437883               0.437883             0.0385692
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_96

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0022892590630050336  0.0005975936073809862  0.0         -0.0027920742144937893  0.3019794225692749   -0.0059158032846230125  0.3639075756072998
    3        26       Softmax                 0.0   0.0   0.0027616382459690124  0.0009575590956956148  0.0         0.004169107140143069    0.31576621532440186  -0.5537723722049587     0.14949500560760498


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1425897404023901
RMSE: 0.37761056712225377
LogLoss: 0.48748904746751326
Mean Per-Class Error: 0.14315072243652677
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    1.0    7.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    2.0    1.0    0.0    3.0    6.0    2.0    0.0810126582278481   32 / 395
0.0    330.0  0.0    3.0    3.0    0.0    1.0    6.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    24.0   8.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.13838120104438642  53 / 383
0.0    0.0    313.0  1.0    7.0    0.0    6.0    0.0    0.0    0.0    14.0   1.0    0.0    0.0    5.0    0.0    2.0    2.0    3.0    5.0    8.0    0.0    1.0    0.0    0.0    0.0    0.14945652173913043  55 / 368
1.0    17.0   0.0    338.0  0.0    0.0    0.0    8.0    1.0    3.0    0.0    0.0    6.0    3.0    1.0    3.0    0.0    14.0   1.0    0.0    1.0    0.0    0.0    3.0    0.0    3.0    0.16129032258064516  65 / 403
0.0    6.0    1.0    0.0    312.0  7.0    13.0   0.0    0.0    0.0    5.0    3.0    0.0    0.0    0.0    1.0    6.0    4.0    8.0    7.0    0.0    0.0    0.0    4.0    0.0    7.0    0.1875               72 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    15.0   0.0    3.0    1.0    0.0    1.0    0.0    0.0    2.0    1.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    1.0    0.0    2.0    5.0    0.0    0.0    2.0    6.0    2.0    10.0   0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    1.0    1.0    0.0    0.0    352.0  4.0    2.0    0.1065989847715736   42 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    4.0    3.0    0.0    1.0    13.0   1.0    5.0    1.0    1.0    355.0  0.0    0.09438775510204081  37 / 392
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    16.0   3.0    0.0    0.0    0.0    0.0    0.0    318.0  0.1335149863760218   49 / 367
396.0  474.0  333.0  386.0  377.0  361.0  346.0  315.0  353.0  380.0  371.0  367.0  431.0  365.0  392.0  405.0  368.0  474.0  342.0  404.0  412.0  370.0  390.0  423.0  407.0  361.0  0.14245726282115365  1,425 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.857543
2    0.925222
3    0.952314
4    0.96661
5    0.976907
6    0.982805
7    0.986604
8    0.989203
9    0.991603
10   0.993702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14447684617990755
RMSE: 0.38010109994566915
LogLoss: 0.496767680757655
Mean Per-Class Error: 0.1442539300751235
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0    0.0   3.0    0.0   0.07865168539325842   7 / 89
0.0   85.0   0.0   1.0    2.0   0.0   1.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   8.0    2.0   0.0   0.0    1.0   0.0    1.0   1.0    0.0   0.19811320754716982   21 / 106
0.0   0.0    67.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0   2.0   2.0    0.0   1.0    0.0   0.0    0.0   0.18292682926829268   15 / 82
1.0   1.0    0.0   94.0   0.0   0.0   0.0   3.0   1.0   1.0    0.0   0.0   2.0   1.0   0.0   2.0    0.0   2.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    1.0   0.16071428571428573   18 / 112
0.0   1.0    0.0   0.0    73.0  5.0   3.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    2.0   1.0    3.0   3.0   0.0    0.0   0.0    0.0   0.0    2.0   0.24742268041237114   24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   1.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    89.0  1.0    1.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   2.0   0.0    2.0   1.0    0.0   99.0   0.0   0.07476635514018691   8 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0    77.0  0.11494252873563218   10 / 87
90.0  113.0  70.0  108.0  88.0  87.0  87.0  81.0  86.0  112.0  92.0  99.0  93.0  98.0  82.0  117.0  96.0  117.0  84.0  92.0  106.0  84.0  100.0  99.0  122.0  87.0  0.14337349397590363   357 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.856626
2    0.9249
3    0.951807
4    0.966667
5    0.97751
6    0.982731
7    0.986747
8    0.988755
9    0.990361
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:26  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:27  4 min  5.149 sec  17135 obs/sec     1         1             10007      0.52193          0.928776            0.995159       0.251625                         0.51996            0.924608              0.995183         0.248996
    2019-07-23 13:35:33  4 min 11.232 sec  14127 obs/sec     9         9             90063      0.391591         0.52592             0.997275       0.158552                         0.394248           0.537174              0.99723          0.161044
    2019-07-23 13:35:34  4 min 12.450 sec  13355 obs/sec     10        10            100070     0.377611         0.487489            0.997466       0.142457                         0.380101           0.496768              0.997426         0.143373
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0879705
C13         0.980521               0.980521             0.086257
C12         0.88944                0.88944              0.0782445
C9          0.86964                0.86964              0.0765027
C8          0.786334               0.786334             0.0691742
C7          0.762144               0.762144             0.0670463
C11         0.744496               0.744496             0.0654937
C10         0.73028                0.73028              0.0642431
C14         0.672294               0.672294             0.0591421
C5          0.653802               0.653802             0.0575153
C6          0.6282                 0.6282               0.0552631
C16         0.626971               0.626971             0.055155
C3          0.567915               0.567915             0.0499598
C4          0.534124               0.534124             0.0469872
C2          0.475354               0.475354             0.0418171
C1          0.445928               0.445928             0.0392285
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_51

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0023885477587555215  0.0006476535927504301  0.0         -0.0011064251192050567  0.30982232093811035  -0.034119986692375946  0.3754134178161621
    3        26       Softmax                 0.0   0.0   0.0028274887878734054  0.0010625235736370087  0.0         0.0004673729849462059   0.30979394912719727  -0.555284462743787     0.15856289863586426


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14241691806170154
RMSE: 0.37738166100342174
LogLoss: 0.4843765809834152
Mean Per-Class Error: 0.14261545947160048
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    2.0    1.0    10.0   1.0    0.0    0.0    0.0    3.0    2.0    1.0    1.0    1.0    1.0    1.0    4.0    4.0    0.09873417721518987  39 / 395
0.0    320.0  0.0    6.0    4.0    0.0    1.0    11.0   2.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    13.0   13.0   0.0    0.0    2.0    0.0    2.0    3.0    1.0    0.16449086161879894  63 / 383
0.0    1.0    311.0  1.0    5.0    0.0    6.0    1.0    0.0    0.0    21.0   1.0    1.0    0.0    6.0    0.0    0.0    0.0    7.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
1.0    15.0   0.0    344.0  0.0    1.0    0.0    7.0    2.0    3.0    1.0    0.0    7.0    3.0    2.0    1.0    0.0    7.0    2.0    0.0    1.0    0.0    0.0    3.0    0.0    2.0    0.14427860696517414  58 / 402
0.0    0.0    0.0    0.0    325.0  7.0    18.0   0.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    3.0    3.0    6.0    4.0    0.0    0.0    0.0    1.0    0.0    8.0    0.1514360313315927   58 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    20.0   0.0    4.0    0.0    0.0    2.0    0.0    0.0    2.0    2.0    341.0  0.0    0.0    0.0    0.09066666666666667  34 / 375
0.0    0.0    0.0    5.0    6.0    1.0    0.0    3.0    4.0    3.0    15.0   1.0    0.0    0.0    2.0    0.0    4.0    0.0    4.0    1.0    1.0    0.0    0.0    336.0  5.0    3.0    0.14720812182741116  58 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    4.0    0.0    1.0    5.0    0.0    15.0   1.0    1.0    354.0  0.0    0.09923664122137404  39 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    14.0   3.0    0.0    0.0    0.0    0.0    0.0    327.0  0.10899182561307902  40 / 367
375.0  415.0  340.0  422.0  410.0  401.0  355.0  310.0  361.0  364.0  419.0  358.0  451.0  386.0  413.0  386.0  359.0  407.0  394.0  369.0  396.0  371.0  384.0  390.0  389.0  378.0  0.14205738278516444  1,421 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.857943
2    0.924823
3    0.952714
4    0.96571
5    0.975008
6    0.982305
7    0.986104
8    0.988304
9    0.991403
10   0.993602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14533940760187716
RMSE: 0.38123405881672895
LogLoss: 0.49984871273305437
Mean Per-Class Error: 0.1464849276037018
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13     14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0    1.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.10112359550561797  9 / 89
0.0   86.0   0.0   3.0    2.0   0.0   1.0   5.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   4.0    1.0    0.0   0.0    2.0   0.0   1.0   1.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    66.0  0.0    1.0   0.0   1.0   1.0   0.0   0.0    4.0    0.0   0.0    0.0    4.0   0.0    0.0   0.0    3.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.1951219512195122   16 / 82
1.0   1.0    0.0   96.0   0.0   0.0   0.0   3.0   1.0   1.0    1.0    0.0   3.0    1.0    0.0   1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   2.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    76.0  4.0   5.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0    0.0   0.0    0.0   1.0    4.0    2.0   0.0    0.0   0.0   0.0   0.0    2.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   5.0    0.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0    2.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   1.0    7.0    1.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   82.0  1.0    1.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   2.0    1.0   0.0    0.0    0.0   0.0    6.0   1.0   0.0   96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0    78.0  0.10344827586206896  9 / 87
86.0  108.0  69.0  118.0  97.0  94.0  90.0  82.0  90.0  104.0  108.0  93.0  100.0  102.0  86.0  108.0  91.0  103.0  100.0  84.0  100.0  85.0  95.0  93.0  112.0  92.0  0.1465863453815261   365 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853414
2    0.918875
3    0.951004
4    0.965863
5    0.9751
6    0.981526
7    0.98514
8    0.987952
9    0.991165
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:40  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:41  2 min 19.525 sec  17253 obs/sec     1         1             10007      0.520693         0.919941            0.995181       0.250425                         0.520177           0.922847              0.995179         0.256627
    2019-07-23 13:33:47  2 min 25.203 sec  16378 obs/sec     10        10            100070     0.377382         0.484377            0.997469       0.142057                         0.381234           0.499849              0.99741          0.146586
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.082826
C15         0.999888               0.999888             0.0828168
C9          0.911712               0.911712             0.0755135
C12         0.906079               0.906079             0.0750469
C8          0.88538                0.88538              0.0733325
C7          0.816756               0.816756             0.0676486
C11         0.805137               0.805137             0.0666863
C10         0.792534               0.792534             0.0656424
C16         0.70959                0.70959              0.0587725
C14         0.705152               0.705152             0.0584049
C5          0.698862               0.698862             0.0578839
C6          0.661076               0.661076             0.0547543
C3          0.613954               0.613954             0.0508513
C4          0.577147               0.577147             0.0478027
C1          0.50239                0.50239              0.041611
C2          0.487848               0.487848             0.0404065
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_45

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002320026735347369   0.0006224631797522306  0.0         0.0005592325259367037  0.30470359325408936  0.02228428942636261  0.3774813413619995
    3        26       Softmax                 0.0   0.0   0.0028174448266152187  0.0012181391939520836  0.0         0.006400438287246201   0.31335532665252686  -0.5678879592237768  0.14726197719573975


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14232521066364415
RMSE: 0.37726013659495505
LogLoss: 0.49092749321065005
Mean Per-Class Error: 0.14651131167703463
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    4.0    1.0    3.0    0.0    0.0    0.0    1.0    2.0    0.0    4.0    3.0    1.0    2.0    0.0    3.0    5.0    0.07848101265822785   31 / 395
0.0    297.0  0.0    17.0   5.0    2.0    1.0    20.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    20.0   9.0    0.0    0.0    2.0    0.0    3.0    0.0    2.0    0.22251308900523561   85 / 382
0.0    0.0    319.0  1.0    3.0    0.0    9.0    2.0    0.0    0.0    14.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    2.0    5.0    6.0    0.0    2.0    0.0    0.0    0.0    0.1331521739130435    49 / 368
1.0    7.0    0.0    356.0  0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    2.0    3.0    2.0    2.0    0.0    9.0    2.0    1.0    4.0    0.0    0.0    2.0    0.0    4.0    0.11662531017369727   47 / 403
0.0    4.0    2.0    0.0    326.0  4.0    16.0   1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    4.0    3.0    1.0    6.0    1.0    0.0    0.0    5.0    0.0    8.0    0.15104166666666666   58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    6.0    0.0    5.0    0.0    0.0    3.0    0.0    0.0    6.0    2.0    347.0  0.0    0.0    0.0    0.07712765957446809   29 / 376
0.0    0.0    0.0    6.0    4.0    1.0    0.0    3.0    3.0    1.0    11.0   1.0    0.0    0.0    0.0    0.0    7.0    1.0    2.0    5.0    3.0    0.0    0.0    336.0  5.0    5.0    0.14720812182741116   58 / 394
0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    1.0    3.0    2.0    4.0    1.0    1.0    370.0  0.0    0.058524173027989825  23 / 393
2.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    11.0   3.0    0.0    0.0    0.0    0.0    0.0    329.0  0.10354223433242507   38 / 367
389.0  358.0  350.0  440.0  407.0  392.0  391.0  376.0  345.0  344.0  358.0  342.0  380.0  378.0  395.0  365.0  402.0  469.0  318.0  401.0  440.0  338.0  394.0  392.0  438.0  401.0  0.14555633310007      1,456 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854444
2    0.923323
3    0.952814
4    0.96701
5    0.975607
6    0.981206
7    0.985604
8    0.988503
9    0.990603
10   0.992702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14574479681202868
RMSE: 0.38176536879610845
LogLoss: 0.5042610314803945
Mean Per-Class Error: 0.1476686088143282
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4      5     6     7      8     9      10    11    12    13     14    15     16     17     18    19    20     21    22    23    24     25    Error                 Rate
----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
83.0  0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   1.0    0.0   1.0   0.0   2.0    1.0   0.06741573033707865   6 / 89
0.0   77.0  0.0   6.0    2.0    0.0   1.0   7.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    8.0    2.0   0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.27358490566037735   29 / 106
0.0   0.0   72.0  0.0    0.0    0.0   0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    1.0   2.0   0.0    0.0   1.0   0.0   0.0    0.0   0.12195121951219512   10 / 82
1.0   1.0   0.0   96.0   0.0    0.0   0.0   4.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   2.0    0.0    1.0    1.0   0.0   1.0    0.0   0.0   2.0   0.0    1.0   0.14285714285714285   16 / 112
0.0   0.0   1.0   0.0    80.0   3.0   6.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   3.0   0.0    0.0   0.0   1.0   0.0    1.0   0.17525773195876287   17 / 97
---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0   4.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782   6 / 92
0.0   0.0   0.0   2.0    3.0    0.0   0.0   2.0    1.0   0.0    5.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   1.0   0.0    0.0   0.0   79.0  2.0    3.0   0.21                  21 / 100
0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0    0.0    0.0   1.0   0.0    0.0   1.0   0.0   101.0  0.0   0.056074766355140186  6 / 107
1.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   0.0   0.0   0.0    80.0  0.08045977011494253   7 / 87
88.0  84.0  77.0  119.0  100.0  86.0  92.0  107.0  84.0  100.0  89.0  94.0  82.0  102.0  84.0  106.0  103.0  120.0  78.0  98.0  113.0  74.0  97.0  92.0  124.0  97.0  0.14738955823293173   367 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.85261
2    0.9249
3    0.956225
4    0.96747
5    0.975502
6    0.981526
7    0.986747
8    0.989558
9    0.990763
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:20  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:20  1 min 58.968 sec  16734 obs/sec     1         1             10007      0.520887         0.921119            0.995178       0.248425                         0.522857           0.920505              0.995129         0.254618
    2019-07-23 13:33:26  2 min  4.647 sec  16255 obs/sec     10        10            100070     0.37726          0.490927            0.997471       0.145556                         0.381765           0.504261              0.997403         0.14739
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0877602
C13         0.986242               0.986242             0.0865528
C9          0.880008               0.880008             0.0772296
C8          0.832114               0.832114             0.0730264
C12         0.829767               0.829767             0.0728205
C10         0.736559               0.736559             0.0646406
C11         0.734719               0.734719             0.064479
C7          0.709574               0.709574             0.0622723
C5          0.664248               0.664248             0.0582945
C14         0.659299               0.659299             0.0578602
C16         0.63306                0.63306              0.0555574
C6          0.622695               0.622695             0.0546478
C3          0.590423               0.590423             0.0518156
C4          0.567373               0.567373             0.0497928
C2          0.481071               0.481071             0.0422189
C1          0.467539               0.467539             0.0410313
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_77

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0019014449150347446  0.0005373270250856876  0.0         -0.0033848240199034763  0.33592236042022705  -0.008572810377639581  0.35187435150146484
    3        26       Softmax                 0.0   0.0   0.002965261551672973   0.001437363214790821   0.0         -0.0014289668699125112  0.44073641300201416  -0.5291847379537757    0.1195870041847229


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1467727517158783
RMSE: 0.38310932084181704
LogLoss: 0.49029690487140276
Mean Per-Class Error: 0.14447318152309033
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    4.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    3.0    3.0    2.0    0.0    1.0    0.0    3.0    3.0    0.0810126582278481   32 / 395
0.0    335.0  0.0    6.0    2.0    1.0    2.0    14.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    8.0    3.0    0.0    0.0    1.0    1.0    2.0    2.0    2.0    0.12532637075718014  48 / 383
0.0    0.0    321.0  1.0    10.0   0.0    9.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    4.0    0.0    2.0    0.0    2.0    0.0    5.0    0.0    3.0    0.0    0.0    0.0    0.12771739130434784  47 / 368
1.0    15.0   0.0    353.0  0.0    1.0    0.0    8.0    0.0    2.0    1.0    0.0    5.0    3.0    2.0    0.0    0.0    4.0    1.0    0.0    2.0    0.0    0.0    3.0    0.0    2.0    0.12406947890818859  50 / 403
0.0    5.0    5.0    0.0    315.0  6.0    19.0   2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    1.0    5.0    1.0    0.0    0.0    2.0    0.0    17.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    7.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    351.0  0.0    0.0    0.0    0.06648936170212766  25 / 376
0.0    1.0    0.0    4.0    9.0    7.0    0.0    6.0    3.0    4.0    9.0    1.0    0.0    0.0    0.0    0.0    8.0    3.0    0.0    3.0    1.0    0.0    0.0    328.0  3.0    4.0    0.16751269035532995  66 / 394
0.0    0.0    0.0    3.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    6.0    0.0    1.0    5.0    2.0    8.0    2.0    0.0    358.0  0.0    0.089058524173028    35 / 393
1.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    9.0    3.0    0.0    0.0    0.0    0.0    0.0    336.0  0.08196721311475409  30 / 366
389.0  423.0  352.0  432.0  410.0  385.0  394.0  400.0  347.0  357.0  361.0  344.0  407.0  364.0  391.0  379.0  426.0  392.0  266.0  402.0  408.0  353.0  411.0  381.0  404.0  425.0  0.14375687293811856  1,438 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.856243
2    0.924922
3    0.952514
4    0.96511
5    0.973108
6    0.980106
7    0.984705
8    0.988004
9    0.991203
10   0.993302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1515229043767314
RMSE: 0.38925943068438484
LogLoss: 0.5061229593429812
Mean Per-Class Error: 0.15191094438094693
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7      8     9      10    11    12    13    14    15     16     17     18    19    20     21    22    23    24     25     Error                Rate
----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  -----  -------------------  -----------
82.0  0.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0    0.07865168539325842  7 / 89
0.0   84.0  0.0   3.0    2.0   0.0   2.0   5.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    4.0    1.0   0.0   0.0    1.0   1.0   1.0   1.0    1.0    0.20754716981132076  22 / 106
0.0   0.0   71.0  0.0    3.0   0.0   2.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0    0.13414634146341464  11 / 82
1.0   1.0   0.0   98.0   0.0   1.0   0.0   3.0    0.0   1.0    0.0   0.0   2.0   1.0   1.0   0.0    0.0    1.0    0.0   0.0   1.0    0.0   0.0   1.0   0.0    0.0    0.125                14 / 112
0.0   0.0   1.0   0.0    75.0  3.0   5.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   3.0   0.0    0.0   0.0   0.0   0.0    8.0    0.2268041237113402   22 / 97
---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---    ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   2.0    1.0   85.0  0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   0.0   0.0   1.0    4.0   1.0   0.0   3.0    0.0   1.0    3.0   1.0   0.0   0.0   0.0   0.0    1.0    2.0    0.0   0.0   0.0    0.0   0.0   82.0  0.0    1.0    0.18                 18 / 100
0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    3.0    0.0    0.0   1.0   0.0    1.0   1.0   0.0   98.0   0.0    0.08411214953271028  9 / 107
1.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    79.0   0.09195402298850575  8 / 87
88.0  99.0  76.0  118.0  98.0  83.0  96.0  111.0  87.0  101.0  90.0  92.0  89.0  98.0  85.0  109.0  102.0  100.0  72.0  96.0  103.0  80.0  98.0  96.0  117.0  106.0  0.15140562248995984  377 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.848594
2    0.922892
3    0.951807
4    0.965863
5    0.973092
6    0.980321
7    0.984337
8    0.987148
9    0.990361
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:40  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:40  3 min 18.679 sec  26543 obs/sec     1         1             10007      0.536766         0.95598             0.99488        0.250125                         0.537112           0.960229              0.99486          0.255823
    2019-07-23 13:34:43  3 min 21.902 sec  28220 obs/sec     10        10            100070     0.383109         0.490297            0.997392       0.143757                         0.389259           0.506123              0.9973           0.151406
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0884968
C13         0.985437               0.985437             0.087208
C12         0.863185               0.863185             0.0763891
C9          0.848932               0.848932             0.0751277
C8          0.829556               0.829556             0.073413
C10         0.750292               0.750292             0.0663985
C11         0.748079               0.748079             0.0662026
C7          0.721267               0.721267             0.0638298
C14         0.662734               0.662734             0.0586498
C16         0.642341               0.642341             0.0568451
C6          0.641864               0.641864             0.0568029
C5          0.631644               0.631644             0.0558985
C3          0.533297               0.533297             0.0471951
C4          0.487654               0.487654             0.0431558
C1          0.481893               0.481893             0.0426459
C2          0.471671               0.471671             0.0417414
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_93

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias           bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013216713037422778  0.0003347555175423622  0.0         -0.01117224006148021  0.20161253213882446  0.1463924053974693  0.18010061979293823
    3        26       Softmax                      0.0   0.0   0.009596100573879504   0.04388710856437683    0.0         -0.22372802386775867  0.5284645557403564   -0.62338138104275   0.23482322692871094


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1587787997353994
RMSE: 0.3984705757460636
LogLoss: 0.5095559371031928
Mean Per-Class Error: 0.14723467185650746
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    5.0    1.0    3.0    0.0    1.0    0.0    0.0    4.0    5.0    1.0    4.0    1.0    1.0    3.0    4.0    1.0    0.09873417721518987  39 / 395
0.0    345.0  0.0    3.0    2.0    1.0    0.0    9.0    2.0    0.0    1.0    0.0    0.0    0.0    4.0    2.0    0.0    7.0    4.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.09921671018276762  38 / 383
0.0    0.0    315.0  1.0    10.0   0.0    8.0    1.0    0.0    0.0    18.0   1.0    0.0    0.0    7.0    0.0    1.0    0.0    1.0    2.0    1.0    0.0    2.0    0.0    0.0    0.0    0.14402173913043478  53 / 368
0.0    19.0   0.0    358.0  0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    6.0    5.0    1.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.10945273631840796  44 / 402
0.0    5.0    0.0    0.0    323.0  6.0    10.0   0.0    0.0    0.0    3.0    1.0    0.0    0.0    1.0    1.0    9.0    3.0    5.0    6.0    0.0    0.0    0.0    2.0    0.0    9.0    0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    1.0    0.0    5.0    6.0    0.0    0.0    1.0    0.0    3.0    7.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    2.0    1.0    0.0    0.0    358.0  2.0    3.0    0.09137055837563451  36 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    2.0    10.0   0.0    24.0   1.0    0.0    340.0  0.0    0.13486005089058525  53 / 393
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    1.0    10.0   0.0    3.0    0.0    0.0    0.0    0.0    4.0    0.0    15.0   3.0    0.0    0.0    0.0    0.0    0.0    315.0  0.14168937329700274  52 / 367
385.0  480.0  363.0  413.0  413.0  345.0  336.0  352.0  334.0  361.0  376.0  358.0  417.0  386.0  415.0  403.0  362.0  396.0  392.0  389.0  403.0  381.0  394.0  414.0  374.0  361.0  0.14655603319004298  1,466 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853444
2    0.924423
3    0.953114
4    0.96641
5    0.976707
6    0.982105
7    0.986904
8    0.989503
9    0.992702
10   0.994902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16154167850048837
RMSE: 0.40192247822246563
LogLoss: 0.5170599787661931
Mean Per-Class Error: 0.14972777376340446
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17    18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0   1.0   0.0   1.0    1.0   0.0   1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   91.0   0.0   0.0    1.0   0.0   0.0   5.0   1.0   0.0    1.0   0.0   0.0   0.0    2.0   1.0    0.0   1.0   1.0   0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.14150943396226415  15 / 106
0.0   0.0    68.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0   1.0   2.0   0.0    0.0   0.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
0.0   2.0    0.0   98.0   0.0   0.0   0.0   2.0   0.0   2.0    0.0   0.0   2.0   2.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.125                14 / 112
0.0   1.0    0.0   0.0    77.0  5.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0   2.0   3.0   0.0    0.0   0.0   1.0    0.0    2.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   3.0    3.0   0.0   0.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0    0.0   0.0   87.0   0.0    1.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0   0.0   0.0   3.0   0.0    8.0   1.0   0.0    90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0   1.0   0.0    0.0   0.0   0.0    0.0    75.0  0.13793103448275862  12 / 87
90.0  122.0  78.0  110.0  95.0  83.0  81.0  88.0  79.0  104.0  89.0  94.0  96.0  101.0  92.0  114.0  94.0  99.0  98.0  97.0  102.0  90.0  97.0  101.0  105.0  91.0  0.14899598393574298  371 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.851004
2    0.927309
3    0.953815
4    0.96747
5    0.976707
6    0.981124
7    0.986345
8    0.990361
9    0.992771
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:21  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:22  4 min  0.000 sec  36521 obs/sec     1         1             10007      0.568293         1.00494             0.994261       0.269819                         0.568303           1.00643               0.994245         0.268675
    2019-07-23 13:35:23  4 min  1.917 sec  47136 obs/sec     10        10            100070     0.398471         0.509556            0.997179       0.146556                         0.401922           0.51706               0.997122         0.148996
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0887573
C13         0.965665               0.965665             0.0857098
C8          0.865401               0.865401             0.0768106
C9          0.835154               0.835154             0.074126
C12         0.83087                0.83087              0.0737457
C7          0.772175               0.772175             0.0685362
C10         0.704377               0.704377             0.0625186
C6          0.685092               0.685092             0.0608069
C11         0.675816               0.675816             0.0599836
C5          0.666775               0.666775             0.0591812
C14         0.622196               0.622196             0.0552245
C16         0.595912               0.595912             0.0528915
C3          0.575379               0.575379             0.0510691
C4          0.561451               0.561451             0.0498328
C1          0.456563               0.456563             0.0405233
C2          0.453855               0.453855             0.0402829
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_85

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.001274197727155979  0.00035164097789675   0.0         -0.012515043384851765  0.20245379209518433  0.13672717460734904  0.1595468521118164
    3        26       Softmax                      0.0   0.0   0.008461792114583378  0.028645038604736328  0.0         -0.24540511276623314   0.5259475708007812   -0.6242670636306897  0.2993124723434448


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16079532793120163
RMSE: 0.4009929275326457
LogLoss: 0.5143225200657484
Mean Per-Class Error: 0.15053756194352927
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    3.0    2.0    5.0    0.0    1.0    0.0    0.0    1.0    6.0    0.0    3.0    0.0    2.0    3.0    4.0    0.0    0.09137055837563451  36 / 394
1.0    336.0  0.0    4.0    2.0    1.0    1.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    3.0    7.0    8.0    0.0    0.0    8.0    0.0    2.0    4.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    301.0  0.0    15.0   1.0    8.0    0.0    0.0    0.0    13.0   5.0    1.0    0.0    7.0    0.0    2.0    1.0    2.0    4.0    2.0    0.0    6.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
2.0    18.0   0.0    346.0  0.0    2.0    0.0    0.0    0.0    4.0    2.0    0.0    6.0    4.0    2.0    0.0    0.0    10.0   0.0    1.0    2.0    0.0    0.0    3.0    0.0    1.0    0.141439205955335    57 / 403
0.0    4.0    1.0    0.0    312.0  4.0    18.0   1.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    0.0    4.0    3.0    9.0    6.0    0.0    0.0    0.0    4.0    0.0    13.0   0.1875               72 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    10.0   0.0    5.0    0.0    0.0    3.0    0.0    0.0    5.0    2.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    4.0    4.0    0.0    0.0    2.0    2.0    4.0    6.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    2.0    2.0    0.0    0.0    356.0  5.0    1.0    0.09644670050761421  38 / 394
0.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    3.0    0.0    2.0    4.0    1.0    8.0    1.0    0.0    368.0  0.0    0.06361323155216285  25 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    19.0   2.0    0.0    0.0    0.0    0.0    0.0    315.0  0.14168937329700274  52 / 367
393.0  469.0  335.0  407.0  390.0  365.0  375.0  281.0  340.0  380.0  356.0  376.0  405.0  377.0  411.0  369.0  343.0  428.0  364.0  388.0  430.0  379.0  420.0  414.0  436.0  372.0  0.1496551034689593   1,497 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850345
2    0.922023
3    0.951815
4    0.96621
5    0.976807
6    0.983305
7    0.986904
8    0.990903
9    0.993002
10   0.994902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16220181218661076
RMSE: 0.4027428611243292
LogLoss: 0.5175997822028726
Mean Per-Class Error: 0.14632711798295578
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   1.0    1.0   1.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0   1.0   1.0    0.0   4.0    2.0   0.0   0.0    5.0   0.0    1.0    1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    64.0  0.0    4.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0   2.0   1.0    0.0   2.0    0.0    0.0    0.0   0.21951219512195122  18 / 82
2.0   2.0    0.0   97.0   0.0   1.0   0.0   0.0   0.0   1.0    1.0   0.0   2.0   1.0   0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0   0.0    2.0    0.0    0.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    73.0  2.0   6.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    3.0   3.0   0.0    0.0   0.0    2.0    0.0    6.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    89.0   2.0    0.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   1.0   0.0    1.0   1.0    0.0    102.0  0.0   0.04672897196261682  5 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0    0.0    0.0    75.0  0.13793103448275862  12 / 87
93.0  111.0  70.0  114.0  91.0  87.0  95.0  68.0  83.0  105.0  88.0  96.0  92.0  99.0  86.0  107.0  94.0  109.0  88.0  96.0  107.0  87.0  100.0  101.0  127.0  96.0  0.14538152610441768  362 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854618
2    0.925703
3    0.95261
4    0.965863
5    0.977912
6    0.984739
7    0.988755
8    0.99237
9    0.993976
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:04  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:05  3 min 43.029 sec  45076 obs/sec     1         1             10007      0.566587         1.01441             0.994294       0.271119                         0.566294           1.00872               0.994286         0.274699
    2019-07-23 13:35:07  3 min 45.042 sec  45735 obs/sec     10        10            100070     0.400993         0.514323            0.997142       0.149655                         0.402743           0.5176                0.99711          0.145382
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.08752
C13         0.987761               0.987761             0.0864489
C8          0.821793               0.821793             0.0719234
C9          0.820181               0.820181             0.0717822
C7          0.799632               0.799632             0.0699838
C12         0.791993               0.791993             0.0693152
C11         0.751668               0.751668             0.065786
C5          0.723961               0.723961             0.0633611
C10         0.699805               0.699805             0.061247
C6          0.676746               0.676746             0.0592288
C14         0.631083               0.631083             0.0552324
C4          0.608814               0.608814             0.0532834
C3          0.594469               0.594469             0.0520279
C16         0.57647                0.57647              0.0504526
C1          0.482288               0.482288             0.0422099
C2          0.459295               0.459295             0.0401975
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_28

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013492264390322362  0.0003593849251046777  0.0         -0.01494459200943865  0.20114648342132568  0.14143114739340254  0.12543010711669922
    3        26       Softmax                      0.0   0.0   0.009311533276559203   0.042344868183135986   0.0         -0.26053594628415194  0.5296967029571533   -0.6358816872230704  0.2640054225921631


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1613940436807188
RMSE: 0.4017387754259213
LogLoss: 0.5191207482834025
Mean Per-Class Error: 0.14734990142797344
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    8.0    1.0    2.0    1.0    2.0    0.0    4.0    0.0    0.08354430379746836  33 / 395
0.0    330.0  0.0    6.0    3.0    1.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    5.0    2.0    17.0   7.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    0.13838120104438642  53 / 383
0.0    0.0    307.0  0.0    10.0   1.0    17.0   0.0    0.0    0.0    13.0   2.0    1.0    0.0    2.0    0.0    0.0    0.0    6.0    2.0    4.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
2.0    14.0   0.0    349.0  0.0    2.0    0.0    3.0    0.0    8.0    2.0    0.0    7.0    2.0    2.0    1.0    0.0    3.0    0.0    1.0    1.0    0.0    0.0    3.0    0.0    3.0    0.13399503722084366  54 / 403
0.0    1.0    2.0    0.0    321.0  4.0    14.0   1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    7.0    4.0    9.0    3.0    0.0    0.0    0.0    4.0    0.0    13.0   0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    3.0    0.0    0.0    3.0    0.0    351.0  0.0    0.0    0.0    0.06648936170212766  25 / 376
0.0    1.0    0.0    3.0    4.0    1.0    0.0    2.0    2.0    5.0    8.0    3.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    4.0    2.0    0.0    0.0    348.0  2.0    5.0    0.116751269035533    46 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    7.0    3.0    5.0    1.0    0.0    367.0  0.0    0.06615776081424936  26 / 393
2.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    21.0   2.0    0.0    0.0    0.0    0.0    0.0    318.0  0.1335149863760218   49 / 367
399.0  454.0  331.0  414.0  380.0  387.0  391.0  290.0  333.0  391.0  350.0  382.0  413.0  379.0  401.0  380.0  340.0  433.0  387.0  372.0  415.0  367.0  418.0  406.0  416.0  374.0  0.14655603319004298  1,466 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853444
2    0.920924
3    0.950815
4    0.964411
5    0.973208
6    0.980106
7    0.984705
8    0.989503
9    0.992002
10   0.994602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1635982565393798
RMSE: 0.4044728131029078
LogLoss: 0.5239629131554563
Mean Per-Class Error: 0.15293541085095574
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   82.0   0.0   0.0    2.0   1.0   1.0   0.0   1.0   0.0    1.0   0.0    0.0   0.0   2.0   2.0    0.0   8.0    2.0   0.0   0.0    3.0   0.0    1.0   0.0    0.0   0.22641509433962265   24 / 106
0.0   0.0    66.0  0.0    1.0   0.0   7.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0   0.1951219512195122    16 / 82
2.0   3.0    0.0   94.0   0.0   1.0   0.0   1.0   0.0   3.0    1.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    0.0   0.16071428571428573   18 / 112
0.0   0.0    0.0   0.0    79.0  2.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    4.0   1.0   0.0    0.0   0.0    1.0   0.0    4.0   0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   1.0    1.0   0.0   0.0   1.0   0.0   1.0    4.0   3.0    0.0   0.0   0.0   0.0    0.0   2.0    0.0   1.0   0.0    0.0   0.0    85.0  0.0    1.0   0.15                  15 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0    1.0   0.0    0.0   2.0   1.0    1.0   1.0    0.0   100.0  0.0   0.06542056074766354   7 / 107
2.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0   0.0    0.0   0.0    75.0  0.13793103448275862   12 / 87
94.0  116.0  71.0  108.0  89.0  90.0  96.0  73.0  78.0  116.0  91.0  100.0  94.0  99.0  85.0  107.0  90.0  114.0  96.0  87.0  101.0  84.0  100.0  97.0  122.0  92.0  0.1530120481927711    381 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.846988
2    0.920884
3    0.954618
4    0.96747
5    0.974699
6    0.981928
7    0.98755
8    0.98996
9    0.992771
10   0.995582
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:44  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:44  1 min 22.832 sec  41351 obs/sec     1         1             10007      0.576501         1.04503             0.994094       0.277617                         0.575835           1.03996               0.994092         0.279116
    2019-07-23 13:32:46  1 min 24.840 sec  45424 obs/sec     10        10            100070     0.401739         0.519121            0.997132       0.146556                         0.404473           0.523963              0.997085         0.153012
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0882891
C15         0.989224               0.989224             0.0873377
C8          0.842236               0.842236             0.0743603
C9          0.829578               0.829578             0.0732427
C12         0.793484               0.793484             0.070056
C7          0.790402               0.790402             0.0697839
C10         0.715876               0.715876             0.063204
C5          0.712498               0.712498             0.0629058
C11         0.707955               0.707955             0.0625047
C6          0.61547                0.61547              0.0543393
C3          0.613756               0.613756             0.0541879
C14         0.60748                0.60748              0.0536339
C4          0.600562               0.600562             0.0530231
C16         0.570779               0.570779             0.0503936
C1          0.485796               0.485796             0.0428905
C2          0.451332               0.451332             0.0398477
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_11

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0012742932438527532  0.00034377770498394966  0.0         -0.008642192109034497  0.20084595680236816  0.1366491377534647   0.15578508377075195
    3        26       Softmax                      0.0   0.0   0.008915862460018896   0.03362672030925751     0.0         -0.2321141389073292    0.5231513977050781   -0.6330916209418765  0.26931536197662354


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16366860033098396
RMSE: 0.4045597611367002
LogLoss: 0.5271525360287079
Mean Per-Class Error: 0.14981015595499939
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    5.0    1.0    5.0    0.0    1.0    0.0    0.0    2.0    6.0    0.0    1.0    2.0    2.0    2.0    6.0    0.0    0.09873417721518987  39 / 395
0.0    336.0  0.0    5.0    3.0    1.0    0.0    3.0    2.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    3.0    15.0   7.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    307.0  0.0    13.0   1.0    8.0    2.0    0.0    0.0    18.0   1.0    1.0    0.0    2.0    0.0    2.0    0.0    5.0    2.0    1.0    0.0    4.0    0.0    0.0    0.0    0.16348773841961853  60 / 367
1.0    23.0   0.0    342.0  0.0    1.0    0.0    4.0    0.0    4.0    0.0    0.0    6.0    4.0    1.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.1513647642679901   61 / 403
0.0    7.0    1.0    0.0    323.0  2.0    17.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    4.0    5.0    9.0    1.0    1.0    0.0    0.0    1.0    0.0    10.0   0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    16.0   2.0    3.0    0.0    0.0    7.0    0.0    0.0    3.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    2.0    0.0    5.0    3.0    1.0    0.0    2.0    3.0    3.0    6.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    0.0    354.0  4.0    4.0    0.10152284263959391  40 / 394
1.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    5.0    0.0    29.0   1.0    0.0    339.0  0.0    0.13740458015267176  54 / 393
1.0    0.0    0.0    0.0    20.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    28.0   1.0    0.0    0.0    0.0    0.0    0.0    304.0  0.17166212534059946  63 / 367
391.0  459.0  337.0  417.0  405.0  419.0  351.0  317.0  346.0  369.0  382.0  364.0  435.0  389.0  394.0  374.0  351.0  456.0  419.0  337.0  385.0  391.0  386.0  403.0  387.0  339.0  0.1492552234329701   1,493 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850745
2    0.922923
3    0.949215
4    0.963111
5    0.973308
6    0.979606
7    0.985504
8    0.988603
9    0.992002
10   0.993702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16479424563629794
RMSE: 0.40594857511302823
LogLoss: 0.5320315731364251
Mean Per-Class Error: 0.1457707019629986
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5      6     7     8     9      10    11    12    13     14    15     16    17     18     19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   1.0   1.0   0.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   86.0   0.0   1.0    2.0    1.0    0.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0   7.0    3.0    0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    66.0  0.0    3.0    0.0    4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0    1.0   0.0   0.0   1.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
1.0   1.0    0.0   100.0  0.0    1.0    0.0   2.0   0.0   1.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.10714285714285714  12 / 112
0.0   1.0    0.0   0.0    81.0   1.0    5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0    1.0   0.0   0.0   0.0   0.0    0.0    3.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   3.0   1.0    0.0   0.0    0.0   2.0    0.0    0.0   1.0   0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0    1.0    0.0   1.0   0.0   1.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0   89.0   0.0    1.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0    1.0   0.0   11.0  1.0   0.0    89.0   0.0   0.16822429906542055  18 / 107
1.0   0.0    0.0   0.0    5.0    0.0    0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    0.0    74.0  0.14942528735632185  13 / 87
91.0  107.0  71.0  124.0  100.0  101.0  92.0  76.0  86.0  104.0  96.0  94.0  95.0  101.0  83.0  107.0  89.0  115.0  102.0  78.0  97.0  91.0  95.0  102.0  106.0  87.0  0.14578313253012049  363 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854217
2    0.925703
3    0.94739
4    0.962651
5    0.974297
6    0.981526
7    0.987149
8    0.98996
9    0.993173
10   0.993976
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:56  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:57  35.155 sec  32073 obs/sec     1         1             10007      0.565776         1.01294             0.994311       0.270719                         0.565424           1.01073               0.994303         0.26988
    2019-07-23 13:31:59  37.095 sec  45861 obs/sec     10        10            100070     0.40456          0.527153            0.997091       0.149255                         0.405949           0.532032              0.997064         0.145783
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0873907
C15         0.994381               0.994381             0.0868997
C9          0.833219               0.833219             0.0728156
C8          0.826734               0.826734             0.0722489
C7          0.78318                0.78318              0.0684427
C12         0.778212               0.778212             0.0680085
C5          0.736734               0.736734             0.0643837
C11         0.724999               0.724999             0.0633582
C10         0.682017               0.682017             0.059602
C14         0.673471               0.673471             0.0588551
C6          0.663254               0.663254             0.0579622
C3          0.61742                0.61742              0.0539568
C4          0.582096               0.582096             0.0508698
C16         0.573351               0.573351             0.0501055
C1          0.509991               0.509991             0.0445685
C2          0.463803               0.463803             0.0405321
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_101

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.001642490117944817   0.0004230384947732091  0.0         -0.021056415589441713  0.46706998348236084  -0.02940696465627714  0.5029292106628418
    3        26       Softmax                 0.0   0.0   0.0021158500992966697  0.0005040382966399193  0.0         0.00408834178213624    0.4124457836151123   -0.4894854361226093   0.1453838348388672


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16081942013578204
RMSE: 0.4010229670926368
LogLoss: 0.5433206785556053
Mean Per-Class Error: 0.15887111719177024
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    3.0    1.0    3.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    2.0    1.0    1.0    1.0    7.0    2.0    0.0759493670886076   30 / 395
1.0    338.0  0.0    2.0    1.0    0.0    1.0    5.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    14.0   8.0    1.0    1.0    1.0    0.0    2.0    1.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    308.0  1.0    12.0   1.0    9.0    1.0    0.0    0.0    19.0   0.0    0.0    0.0    4.0    1.0    1.0    0.0    3.0    0.0    5.0    0.0    3.0    0.0    0.0    0.0    0.16304347826086957  60 / 368
5.0    21.0   0.0    324.0  0.0    0.0    0.0    5.0    0.0    6.0    0.0    0.0    4.0    4.0    5.0    2.0    2.0    8.0    1.0    4.0    4.0    0.0    0.0    6.0    0.0    1.0    0.19402985074626866  78 / 402
0.0    5.0    0.0    0.0    317.0  4.0    12.0   0.0    1.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    10.0   5.0    4.0    7.0    1.0    0.0    0.0    3.0    0.0    10.0   0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    4.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    8.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    3.0    0.0    3.0    6.0    2.0    1.0    1.0    2.0    0.0    6.0    2.0    0.0    1.0    0.0    0.0    5.0    0.0    5.0    5.0    1.0    0.0    0.0    344.0  2.0    4.0    0.12468193384223919  49 / 393
1.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    0.0    1.0    2.0    1.0    9.0    1.0    1.0    363.0  0.0    0.07633587786259542  30 / 393
3.0    0.0    0.0    0.0    11.0   0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    25.0   3.0    0.0    0.0    0.0    1.0    0.0    312.0  0.14986376021798364  55 / 367
404.0  477.0  326.0  376.0  391.0  343.0  350.0  328.0  328.0  365.0  367.0  339.0  384.0  377.0  395.0  402.0  409.0  451.0  371.0  413.0  435.0  360.0  408.0  415.0  415.0  374.0  0.15795261421573528  1,580 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842047
2    0.915925
3    0.943817
4    0.961711
5    0.972508
6    0.979006
7    0.984205
8    0.987504
9    0.989403
10   0.991502

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16365707420806294
RMSE: 0.40454551561976676
LogLoss: 0.5487662795512535
Mean Per-Class Error: 0.16280360687958867
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19     20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  -----  -----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0    0.0    0.0   1.0    0.0    4.0    0.0   0.06741573033707865  6 / 89
0.0   88.0   0.0   0.0    1.0   0.0   1.0   3.0   1.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    1.0    4.0    2.0   0.0    1.0    1.0   0.0    1.0    0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    67.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   3.0   1.0    0.0    0.0    2.0   0.0    0.0    0.0   1.0    0.0    0.0    0.0   0.18292682926829268  15 / 82
3.0   2.0    0.0   90.0   0.0   0.0   0.0   2.0   0.0   2.0    0.0   0.0   1.0   1.0   3.0   2.0    0.0    2.0    1.0   0.0    2.0    0.0   0.0    1.0    0.0    0.0   0.19642857142857142  22 / 112
0.0   1.0    0.0   0.0    77.0  2.0   5.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    2.0    1.0    1.0   2.0    0.0    0.0   0.0    0.0    0.0    4.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---    ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    3.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    2.0   1.0   0.0   1.0   0.0   0.0    2.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0    0.0   0.0    87.0   1.0    1.0   0.13                 13 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0   0.0    0.0    3.0   1.0    0.0    98.0   0.0   0.08411214953271028  9 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    5.0   1.0    0.0    0.0   0.0    0.0    0.0    74.0  0.14942528735632185  13 / 87
96.0  117.0  70.0  105.0  90.0  75.0  91.0  85.0  78.0  108.0  92.0  90.0  82.0  98.0  88.0  118.0  102.0  112.0  97.0  100.0  109.0  80.0  100.0  100.0  117.0  90.0  0.1614457831325301   402 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838554
2    0.914859
3    0.946185
4    0.963454
5    0.972289
6    0.97751
7    0.983132
8    0.98755
9    0.991165
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:44  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:44  4 min 22.757 sec  25992 obs/sec     1         1             10007      0.542134         0.966193            0.994777       0.258422                         0.540861           0.963258              0.994788         0.259839
    2019-07-23 13:35:47  4 min 25.784 sec  29800 obs/sec     10        10            100070     0.401023         0.543321            0.997142       0.157953                         0.404546           0.548766              0.997084         0.161446
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0912362
C13         0.920137               0.920137             0.0839498
C9          0.837556               0.837556             0.0764154
C12         0.834538               0.834538             0.0761401
C7          0.76055                0.76055              0.0693897
C8          0.725423               0.725423             0.0661848
C10         0.699553               0.699553             0.0638245
C11         0.69666                0.69666              0.0635606
C14         0.664415               0.664415             0.0606187
C16         0.624326               0.624326             0.0569611
C5          0.608905               0.608905             0.0555541
C6          0.594177               0.594177             0.0542104
C3          0.590954               0.590954             0.0539164
C4          0.505102               0.505102             0.0460836
C2          0.461496               0.461496             0.0421051
C1          0.436772               0.436772             0.0398494
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_66

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0010427218469999389  0.00025801651645451784  0.0         -0.019001893043139262  0.24775022268295288  0.24932331181916337   0.20459789037704468
    3        26       Softmax                      0.0   0.0   0.006853814377266714   0.032313913106918335    0.0         -0.2937119355508895    0.7082643508911133   -0.47984423428426626  0.21560364961624146


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1689686697570039
RMSE: 0.41105798831430573
LogLoss: 0.5486747868187519
Mean Per-Class Error: 0.15976075860987887
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    9.0    6.0    1.0    3.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    3.0    1.0    3.0    4.0    0.0    0.09620253164556962  38 / 395
2.0    335.0  0.0    8.0    2.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    1.0    10.0   8.0    0.0    0.0    3.0    0.0    3.0    1.0    0.0    0.12532637075718014  48 / 383
0.0    0.0    309.0  0.0    15.0   0.0    7.0    1.0    0.0    0.0    20.0   0.0    0.0    0.0    9.0    0.0    0.0    0.0    4.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
2.0    19.0   0.0    350.0  0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    3.0    9.0    2.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.1315136476426799   53 / 403
0.0    3.0    1.0    0.0    324.0  3.0    11.0   2.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    6.0    4.0    12.0   1.0    1.0    0.0    0.0    5.0    0.0    7.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    13.0   1.0    4.0    0.0    0.0    4.0    0.0    0.0    3.0    3.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    2.0    0.0    4.0    6.0    0.0    0.0    2.0    5.0    4.0    7.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    3.0    3.0    1.0    0.0    0.0    346.0  3.0    3.0    0.1218274111675127   48 / 394
0.0    1.0    0.0    3.0    0.0    10.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    4.0    0.0    2.0    14.0   1.0    43.0   0.0    0.0    312.0  0.0    0.20610687022900764  81 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    1.0    9.0    0.0    3.0    0.0    0.0    0.0    0.0    3.0    0.0    16.0   2.0    0.0    0.0    0.0    3.0    0.0    318.0  0.1335149863760218   49 / 367
389.0  467.0  348.0  443.0  395.0  371.0  352.0  333.0  349.0  370.0  387.0  358.0  399.0  401.0  382.0  394.0  334.0  446.0  398.0  365.0  387.0  413.0  394.0  422.0  352.0  354.0  0.1592522243327002   1,593 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840748
2    0.917025
3    0.945116
4    0.960412
5    0.972208
6    0.979306
7    0.984505
8    0.988304
9    0.991702
10   0.993802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17274709039085315
RMSE: 0.4156285485753513
LogLoss: 0.5585175629105469
Mean Per-Class Error: 0.160336153925145
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20    21    22    23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   1.0   0.0   1.0    3.0   0.0   0.07865168539325842  7 / 89
1.0   87.0   0.0   3.0    2.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    1.0   3.0    2.0    0.0   0.0   2.0   0.0   1.0    0.0   0.0   0.1792452830188679   19 / 106
0.0   0.0    68.0  0.0    3.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.17073170731707318  14 / 82
1.0   4.0    0.0   97.0   0.0   0.0   0.0   0.0   0.0   2.0    1.0   0.0   1.0   3.0    1.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    77.0  2.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    5.0    1.0   0.0   0.0   0.0   1.0    0.0   3.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   86.0  0.0    0.0   0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    2.0   0.0   0.0   1.0   0.0   1.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   2.0    1.0    0.0   0.0   0.0   0.0   88.0   0.0   1.0   0.12                 12 / 100
0.0   1.0    0.0   2.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    2.0   0.0    0.0    5.0   0.0   12.0  0.0   0.0    82.0  0.0   0.2336448598130841   25 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   75.0  0.13793103448275862  12 / 87
88.0  114.0  75.0  128.0  90.0  87.0  88.0  87.0  84.0  105.0  98.0  96.0  84.0  106.0  77.0  114.0  93.0  111.0  100.0  88.0  95.0  95.0  96.0  106.0  97.0  88.0  0.1598393574297189   398 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840161
2    0.914458
3    0.946988
4    0.958233
5    0.970683
6    0.977912
7    0.982731
8    0.987149
9    0.991165
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:10  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:10  2 min 48.439 sec  52947 obs/sec     1         1             10007      0.59968          1.10589             0.99361        0.298111                         0.600487           1.09917               0.993575         0.303213
    2019-07-23 13:34:11  2 min 49.718 sec  69493 obs/sec     10        10            100070     0.411058         0.548675            0.996998       0.159252                         0.415629           0.558518              0.996922         0.159839
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0826431
C13         0.97309                0.97309              0.0804191
C8          0.93922                0.93922              0.07762
C9          0.895931               0.895931             0.0740425
C12         0.855435               0.855435             0.0706958
C7          0.795792               0.795792             0.0657667
C11         0.786865               0.786865             0.065029
C5          0.7609                 0.7609               0.0628831
C14         0.760016               0.760016             0.0628101
C10         0.751117               0.751117             0.0620746
C4          0.685823               0.685823             0.0566785
C6          0.685223               0.685223             0.0566289
C16         0.655436               0.655436             0.0541672
C3          0.553299               0.553299             0.0457264
C2          0.519128               0.519128             0.0429023
C1          0.482952               0.482952             0.0399126
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_55

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0018991671814774236  0.00047603773418813944  0.0         0.019680029016967637   0.4475715160369873  0.014174651534266633  0.4816470146179199
    3        26       Softmax                 0.0   0.0   0.0024413513951213437  0.0007759733125567436   0.0         -0.009473486489726977  0.4154869318008423  -0.4775539394543289   0.1530819535255432


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16227438907744585
RMSE: 0.40283295430916005
LogLoss: 0.5520917100034571
Mean Per-Class Error: 0.16582115399404057
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    3.0    2.0    7.0    1.0    0.0    0.0    1.0    4.0    2.0    1.0    2.0    1.0    2.0    1.0    5.0    3.0    0.09873417721518987  39 / 395
0.0    335.0  0.0    6.0    2.0    3.0    1.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    9.0    12.0   0.0    0.0    3.0    0.0    3.0    3.0    1.0    0.12532637075718014  48 / 383
0.0    0.0    305.0  1.0    14.0   0.0    7.0    3.0    0.0    0.0    17.0   0.0    1.0    0.0    11.0   0.0    1.0    0.0    2.0    1.0    2.0    0.0    3.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
1.0    25.0   0.0    333.0  0.0    4.0    0.0    6.0    0.0    2.0    1.0    0.0    5.0    4.0    3.0    1.0    0.0    8.0    1.0    0.0    2.0    0.0    0.0    6.0    0.0    1.0    0.17369727047146402  70 / 403
0.0    9.0    1.0    0.0    309.0  5.0    9.0    1.0    1.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    10.0   3.0    6.0    2.0    1.0    0.0    0.0    3.0    1.0    16.0   0.1953125            75 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    21.0   0.0    3.0    1.0    0.0    0.0    0.0    0.0    1.0    5.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    4.0    0.0    5.0    5.0    1.0    0.0    1.0    2.0    0.0    8.0    1.0    0.0    0.0    2.0    0.0    5.0    1.0    6.0    4.0    1.0    0.0    0.0    341.0  4.0    3.0    0.13451776649746192  53 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    25.0   1.0    11.0   1.0    0.0    347.0  0.0    0.11704834605597965  46 / 393
2.0    0.0    0.0    0.0    13.0   1.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    23.0   3.0    0.0    0.0    0.0    4.0    0.0    307.0  0.16348773841961853  60 / 367
388.0  525.0  330.0  400.0  386.0  397.0  336.0  306.0  338.0  361.0  392.0  352.0  437.0  377.0  391.0  381.0  374.0  432.0  360.0  393.0  405.0  377.0  382.0  421.0  400.0  362.0  0.16505048485454363  1,651 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83495
2    0.914626
3    0.943917
4    0.959912
5    0.969909
6    0.976007
7    0.982305
8    0.986004
9    0.989403
10   0.991702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1649401187435185
RMSE: 0.4061282048116315
LogLoss: 0.559516127301416
Mean Per-Class Error: 0.16904548162505992
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   1.0   1.0   4.0    0.0   0.10112359550561797  9 / 89
0.0   89.0   0.0   1.0    1.0   2.0   1.0   0.0   1.0   0.0    1.0    0.0   0.0   0.0    1.0   0.0    0.0   3.0    2.0   0.0   0.0    2.0   0.0   1.0   1.0    0.0   0.16037735849056603  17 / 106
0.0   0.0    67.0  0.0    1.0   0.0   1.0   1.0   0.0   0.0    4.0    0.0   0.0   0.0    5.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.18292682926829268  15 / 82
1.0   5.0    0.0   93.0   0.0   1.0   0.0   3.0   0.0   0.0    1.0    0.0   2.0   1.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0    0.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    77.0  4.0   4.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    3.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   5.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    2.0   0.0   0.0   1.0   0.0   0.0    4.0    1.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   0.0   0.0    0.0   0.0   81.0  1.0    2.0   0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   7.0   0.0    4.0   1.0   0.0   93.0   0.0   0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    4.0   1.0   0.0   0.0   0.0   2.0    0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   0.0   0.0    0.0   0.0   1.0   0.0    71.0  0.1839080459770115   16 / 87
89.0  130.0  71.0  112.0  91.0  96.0  85.0  74.0  81.0  105.0  102.0  94.0  95.0  103.0  83.0  106.0  95.0  107.0  92.0  96.0  103.0  84.0  97.0  98.0  114.0  87.0  0.1682730923694779   419 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.831727
2    0.919679
3    0.943373
4    0.959438
5    0.967871
6    0.974297
7    0.97992
8    0.985944
9    0.98996
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:50  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:51  2 min 29.142 sec  27643 obs/sec     1         1             10007      0.551889         1.00264             0.994589       0.272118                         0.551616           0.993492              0.994578         0.278313
    2019-07-23 13:33:54  2 min 32.345 sec  28575 obs/sec     10        10            100070     0.402833         0.552092            0.997117       0.16505                          0.406128           0.559516              0.997061         0.168273
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0924218
C13         0.851598               0.851598             0.0787063
C12         0.819416               0.819416             0.0757319
C9          0.787375               0.787375             0.0727706
C11         0.761865               0.761865             0.0704129
C7          0.760973               0.760973             0.0703305
C8          0.756317               0.756317             0.0699002
C14         0.700266               0.700266             0.0647199
C10         0.699777               0.699777             0.0646747
C16         0.652903               0.652903             0.0603425
C6          0.630134               0.630134             0.0582381
C5          0.5796                 0.5796               0.0535677
C4          0.506239               0.506239             0.0467876
C3          0.491159               0.491159             0.0453938
C2          0.424302               0.424302             0.0392147
C1          0.398031               0.398031             0.0367867
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_16

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017267659868878127  0.0004440068732947111  0.0         -0.00865565134972357   0.45692551136016846  0.014579036947001502  0.4929569959640503
    3        26       Softmax                 0.0   0.0   0.0024057081116622544  0.0009303949773311615  0.0         0.0022808393303338247  0.41377174854278564  -0.48197043664123973  0.2047695517539978


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16160304135319564
RMSE: 0.4019988076514601
LogLoss: 0.5546792736872359
Mean Per-Class Error: 0.1613696232390678
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    2.0    3.0    1.0    1.0    0.0    0.0    4.0    2.0    1.0    1.0    1.0    1.0    0.0    4.0    3.0    0.08354430379746836   33 / 395
0.0    338.0  0.0    8.0    4.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    19.0   4.0    0.0    0.0    2.0    0.0    1.0    1.0    2.0    0.1174934725848564    45 / 383
0.0    0.0    315.0  1.0    14.0   0.0    12.0   0.0    0.0    0.0    12.0   2.0    0.0    0.0    4.0    0.0    0.0    0.0    2.0    1.0    2.0    0.0    3.0    0.0    0.0    0.0    0.14402173913043478   53 / 368
1.0    20.0   0.0    345.0  0.0    0.0    0.0    8.0    0.0    3.0    1.0    0.0    2.0    5.0    3.0    2.0    0.0    2.0    0.0    0.0    3.0    0.0    1.0    3.0    0.0    4.0    0.14392059553349876   58 / 403
0.0    4.0    0.0    0.0    325.0  4.0    17.0   0.0    0.0    0.0    2.0    3.0    0.0    0.0    0.0    0.0    4.0    4.0    2.0    5.0    0.0    0.0    0.0    4.0    0.0    10.0   0.15364583333333334   59 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    1.0    0.0    0.0    1.0    0.0    1.0    5.0    0.0    0.0    1.0    0.0    5.0    1.0    2.0    0.0    0.0    2.0    0.0    0.0    3.0    1.0    353.0  0.0    0.0    0.0    0.061170212765957445  23 / 376
0.0    1.0    0.0    8.0    8.0    0.0    0.0    4.0    2.0    2.0    6.0    3.0    0.0    0.0    2.0    1.0    3.0    2.0    3.0    6.0    1.0    0.0    0.0    333.0  5.0    3.0    0.15267175572519084   60 / 393
0.0    1.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    1.0    14.0   1.0    7.0    1.0    1.0    355.0  1.0    0.09438775510204081   37 / 392
2.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    11.0   5.0    0.0    0.0    0.0    1.0    0.0    317.0  0.1362397820163488    50 / 367
405.0  505.0  345.0  433.0  439.0  342.0  393.0  306.0  343.0  365.0  364.0  358.0  379.0  388.0  395.0  401.0  353.0  438.0  273.0  398.0  403.0  347.0  420.0  394.0  405.0  411.0  0.1605518344496651    1,606 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839448
2    0.912926
3    0.941617
4    0.958113
5    0.968309
6    0.976207
7    0.982205
8    0.985904
9    0.988703
10   0.991203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1642299599862157
RMSE: 0.4052529580227832
LogLoss: 0.5651593698078907
Mean Per-Class Error: 0.1670175060943506
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0    1.0    0.06741573033707865   6 / 89
0.0   88.0   0.0   3.0    3.0    0.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   6.0    1.0   0.0   0.0    2.0   0.0    1.0   0.0    0.0    0.16981132075471697   18 / 106
0.0   0.0    67.0  0.0    3.0    0.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0    0.18292682926829268   15 / 82
1.0   2.0    0.0   96.0   0.0    0.0   0.0   4.0   0.0   1.0    0.0   0.0   0.0   1.0    1.0   1.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0    2.0    0.14285714285714285   16 / 112
0.0   0.0    0.0   0.0    76.0   3.0   4.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    2.0   1.0    1.0   3.0   0.0    0.0   0.0    1.0   0.0    5.0    0.21649484536082475   21 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   88.0   0.0   0.0    0.0    0.043478260869565216  4 / 92
0.0   0.0    0.0   3.0    4.0    0.0   0.0   2.0   0.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    82.0  3.0    1.0    0.18                  18 / 100
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   4.0   0.0    2.0   1.0    0.0   98.0   0.0    0.08411214953271028   9 / 107
1.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   2.0   0.0    0.0   0.0    0.0   0.0    73.0   0.16091954022988506   14 / 87
93.0  121.0  73.0  127.0  102.0  76.0  96.0  80.0  82.0  102.0  92.0  94.0  83.0  105.0  77.0  115.0  98.0  106.0  70.0  99.0  101.0  77.0  103.0  96.0  117.0  105.0  0.1650602409638554    411 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83494
2    0.913655
3    0.941767
4    0.959839
5    0.968675
6    0.977109
7    0.982329
8    0.985944
9    0.987952
10   0.990763
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:09  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:10  48.166 sec  29606 obs/sec     1         1             10007      0.545196         0.974591            0.994716       0.262521                         0.54539            0.970163              0.9947           0.271486
    2019-07-23 13:32:13  51.384 sec  28575 obs/sec     10        10            100070     0.401999         0.554679            0.997127       0.160552                         0.405253           0.565159              0.997074         0.16506
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0853903
C13         0.998681               0.998681             0.0852776
C9          0.910173               0.910173             0.0777199
C12         0.883935               0.883935             0.0754794
C7          0.858086               0.858086             0.0732722
C8          0.84005                0.84005              0.0717321
C11         0.751226               0.751226             0.0641474
C10         0.721502               0.721502             0.0616092
C6          0.673065               0.673065             0.0574732
C14         0.66524                0.66524              0.056805
C5          0.638696               0.638696             0.0545385
C16         0.623787               0.623787             0.0532653
C3          0.596882               0.596882             0.0509679
C4          0.559387               0.559387             0.0477662
C1          0.497826               0.497826             0.0425095
C2          0.492401               0.492401             0.0420462
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_108

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017282288547164626  0.0004374964628368616  0.0         0.005487042381474794  0.4674478769302368  0.003933212241159155  0.5211865901947021
    3        26       Softmax                 0.0   0.0   0.0021915668883663716  0.00051070936024189    0.0         -0.00407172170598467  0.4103506803512573  -0.47826846115550986  0.19541460275650024


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1663661018964538
RMSE: 0.4078800091895333
LogLoss: 0.5620285421253065
Mean Per-Class Error: 0.1659565025723648
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    1.0    3.0    0.0    1.0    0.0    0.0    2.0    3.0    3.0    2.0    0.0    2.0    3.0    6.0    2.0    0.09113924050632911  36 / 395
0.0    335.0  0.0    4.0    5.0    0.0    1.0    3.0    2.0    0.0    2.0    0.0    1.0    0.0    0.0    1.0    0.0    20.0   7.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.12532637075718014  48 / 383
1.0    0.0    306.0  1.0    16.0   0.0    12.0   1.0    0.0    0.0    11.0   2.0    0.0    0.0    2.0    0.0    2.0    0.0    3.0    4.0    4.0    0.0    3.0    0.0    0.0    0.0    0.16847826086956522  62 / 368
2.0    19.0   0.0    334.0  0.0    0.0    0.0    2.0    1.0    4.0    0.0    0.0    4.0    6.0    7.0    1.0    0.0    10.0   0.0    0.0    2.0    0.0    0.0    3.0    0.0    7.0    0.1691542288557214   68 / 402
0.0    2.0    2.0    0.0    320.0  2.0    12.0   0.0    1.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    5.0    5.0    7.0    0.0    1.0    0.0    0.0    3.0    0.0    16.0   0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    1.0    0.0    12.0   0.0    7.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    340.0  0.0    0.0    0.0    0.09333333333333334  35 / 375
0.0    5.0    0.0    7.0    9.0    1.0    0.0    1.0    5.0    1.0    4.0    0.0    0.0    0.0    2.0    0.0    5.0    3.0    2.0    1.0    3.0    2.0    0.0    334.0  2.0    7.0    0.15228426395939088  60 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    3.0    8.0    2.0    16.0   1.0    2.0    347.0  0.0    0.11704834605597965  46 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    7.0    0.0    14.0   3.0    0.0    0.0    0.0    0.0    0.0    319.0  0.1307901907356948   48 / 367
400.0  529.0  344.0  414.0  421.0  359.0  353.0  318.0  344.0  356.0  346.0  352.0  409.0  376.0  397.0  386.0  364.0  460.0  314.0  383.0  419.0  360.0  385.0  392.0  404.0  418.0  0.16515045486354094  1,652 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83485
2    0.911127
3    0.939718
4    0.957013
5    0.968709
6    0.975507
7    0.980506
8    0.984405
9    0.987904
10   0.990003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16758560306321219
RMSE: 0.40937220602186974
LogLoss: 0.566603964871582
Mean Per-Class Error: 0.16215488825089414
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0   1.0   3.0    0.0    0.0898876404494382   8 / 89
0.0   90.0   0.0   0.0    1.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0   1.0   0.0   0.0   1.0    0.0   9.0    1.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0    0.1509433962264151   16 / 106
0.0   0.0    68.0  0.0    4.0   0.0   1.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    1.0   2.0   1.0    0.0   1.0   0.0   0.0    0.0    0.17073170731707318  14 / 82
1.0   1.0    0.0   96.0   0.0   0.0   0.0   1.0   1.0   0.0    0.0   0.0   2.0   1.0   2.0   1.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0    2.0    0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    76.0  1.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    3.0   0.0   0.0    0.0   0.0   1.0   0.0    6.0    0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---    ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   86.0  0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    3.0   0.0   0.0   0.0   2.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    1.0   3.0    0.0   0.0   0.0    0.0   0.0   82.0  1.0    2.0    0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   0.0    6.0   1.0   0.0   95.0   0.0    0.11214953271028037  12 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   5.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0   0.0    76.0   0.12643678160919541  11 / 87
91.0  128.0  74.0  115.0  98.0  86.0  86.0  76.0  85.0  103.0  92.0  95.0  92.0  99.0  85.0  109.0  91.0  114.0  81.0  87.0  108.0  82.0  97.0  95.0  117.0  104.0  0.16184738955823294  403 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838153
2    0.913253
3    0.94257
4    0.957831
5    0.969076
6    0.975502
7    0.978715
8    0.983132
9    0.987148
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:04  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:05  4 min 43.200 sec  29432 obs/sec     1         1             10007      0.546788         0.976245            0.994686       0.272018                         0.543336           0.959822              0.99474          0.271888
    2019-07-23 13:36:08  4 min 46.546 sec  27575 obs/sec     10        10            100070     0.40788          0.562029            0.997043       0.16515                          0.409372           0.566604              0.997014         0.161847
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0881553
C13         0.978154               0.978154             0.0862295
C9          0.90406                0.90406              0.0796976
C12         0.847734               0.847734             0.0747322
C8          0.774573               0.774573             0.0682827
C7          0.765464               0.765464             0.0674797
C11         0.73024                0.73024              0.0643745
C14         0.68961                0.68961              0.0607928
C10         0.679469               0.679469             0.0598987
C6          0.639042               0.639042             0.0563349
C5          0.622748               0.622748             0.0548985
C16         0.62099                0.62099              0.0547435
C3          0.602198               0.602198             0.0530869
C4          0.545053               0.545053             0.0480493
C2          0.481516               0.481516             0.0424482
C1          0.46277                0.46277              0.0407956
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_7

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017757088861003467  0.0004682418657466769  0.0         -0.010920899983574373   0.45419859886169434  -0.05803826972774732  0.4907587766647339
    3        26       Softmax                 0.0   0.0   0.0022315159752417037  0.0005258652381598949  0.0         -0.0013435029906251937  0.41321659088134766  -0.4856450296411262   0.18932557106018066


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16428713058226468
RMSE: 0.40532348881142416
LogLoss: 0.5545201266328097
Mean Per-Class Error: 0.16595369951261463
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    4.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    1.0    0.0    2.0    1.0    8.0    1.0    0.08354430379746836  33 / 395
0.0    315.0  0.0    8.0    2.0    1.0    1.0    6.0    1.0    0.0    4.0    1.0    0.0    0.0    1.0    1.0    0.0    22.0   10.0   0.0    0.0    4.0    0.0    1.0    5.0    0.0    0.17754569190600522  68 / 383
0.0    0.0    303.0  1.0    10.0   1.0    9.0    0.0    0.0    0.0    19.0   2.0    0.0    0.0    7.0    0.0    2.0    2.0    3.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
1.0    18.0   0.0    344.0  0.0    1.0    0.0    6.0    1.0    4.0    2.0    0.0    6.0    3.0    1.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    4.0    0.14640198511166252  59 / 403
0.0    2.0    0.0    0.0    306.0  3.0    18.0   1.0    1.0    0.0    9.0    4.0    0.0    0.0    0.0    0.0    0.0    4.0    10.0   1.0    0.0    0.0    0.0    6.0    0.0    19.0   0.203125             78 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    25.0   0.0    10.0   0.0    0.0    2.0    0.0    0.0    4.0    0.0    331.0  0.0    1.0    0.0    0.1196808510638298   45 / 376
0.0    2.0    0.0    4.0    4.0    1.0    0.0    2.0    2.0    1.0    11.0   2.0    0.0    0.0    2.0    0.0    4.0    0.0    6.0    1.0    1.0    2.0    0.0    344.0  3.0    2.0    0.12690355329949238  50 / 394
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    2.0    15.0   0.0    13.0   1.0    1.0    346.0  0.0    0.11959287531806616  47 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    27.0   4.0    0.0    0.0    0.0    3.0    0.0    305.0  0.16666666666666666  61 / 366
389.0  430.0  327.0  429.0  385.0  390.0  350.0  290.0  333.0  377.0  423.0  365.0  444.0  363.0  408.0  370.0  349.0  470.0  395.0  364.0  412.0  372.0  372.0  408.0  422.0  366.0  0.16515045486354094  1,652 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83485
2    0.911826
3    0.942917
4    0.958213
5    0.968509
6    0.976307
7    0.982105
8    0.986804
9    0.989603
10   0.991703

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1670153570645332
RMSE: 0.4086751241078091
LogLoss: 0.56794197530291
Mean Per-Class Error: 0.1658343335067682
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   1.0   0.0   3.0    1.0   0.0898876404494382   8 / 89
0.0   83.0   0.0   2.0    2.0   0.0   1.0   4.0   0.0   0.0    1.0    0.0   0.0   0.0   1.0   0.0    0.0   4.0    2.0    0.0   0.0    3.0   0.0   1.0   2.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    65.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0    2.0    0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.2073170731707317   17 / 82
1.0   3.0    0.0   92.0   0.0   0.0   0.0   2.0   1.0   1.0    1.0    0.0   3.0   1.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   0.0   2.0   0.0    3.0   0.17857142857142858  20 / 112
0.0   0.0    0.0   0.0    75.0  2.0   4.0   0.0   0.0   0.0    3.0    1.0   0.0   0.0   0.0   0.0    0.0   1.0    3.0    0.0   0.0    0.0   0.0   0.0   0.0    8.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   5.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0   1.0   0.0   0.0    5.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   86.0  0.0    1.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0    3.0   0.0    5.0   1.0   0.0   94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    1.0   0.0    0.0   0.0   1.0   0.0    73.0  0.16091954022988506  14 / 87
87.0  108.0  69.0  114.0  93.0  92.0  87.0  76.0  78.0  111.0  107.0  96.0  96.0  96.0  82.0  108.0  89.0  119.0  104.0  84.0  102.0  85.0  96.0  99.0  119.0  93.0  0.16546184738955824  412 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.834538
2    0.910442
3    0.940161
4    0.957831
5    0.968273
6    0.975904
7    0.982329
8    0.988353
9    0.98996
10   0.991968
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:45  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:45  23.959 sec  25924 obs/sec     1         1             10007      0.555257         1.00415             0.99452        0.280116                         0.555749           1.00455               0.994497         0.289157
    2019-07-23 13:31:49  27.107 sec  28764 obs/sec     10        10            100070     0.405323         0.55452             0.99708        0.16515                          0.408675           0.567942              0.997024         0.165462
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0879381
C13         0.970927               0.970927             0.0853814
C12         0.888401               0.888401             0.0781243
C9          0.825384               0.825384             0.0725827
C8          0.794374               0.794374             0.0698557
C7          0.757118               0.757118             0.0665795
C11         0.744184               0.744184             0.0654421
C10         0.685973               0.685973             0.0603232
C14         0.671131               0.671131             0.059018
C5          0.65455                0.65455              0.0575599
C16         0.64478                0.64478              0.0567007
C6          0.622326               0.622326             0.0547261
C3          0.602786               0.602786             0.0530078
C4          0.54707                0.54707              0.0481083
C2          0.490339               0.490339             0.0431194
C1          0.472294               0.472294             0.0415326
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_10

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0014960226059201887  0.0003870106302201748  0.0         -0.01677106968060116   0.4467899799346924  0.07522631978395851  0.42787086963653564
    3        26       Softmax                 0.0   0.0   0.0024699161008706703  0.0007343410979956388  0.0         -0.022665193744684915  0.563711404800415   -0.5289282623039662  0.19259029626846313


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16975075394380404
RMSE: 0.41200819645221143
LogLoss: 0.5725183145238686
Mean Per-Class Error: 0.16323784503119862
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    5.0    2.0    2.0    5.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    2.0    2.0    2.0    0.0    5.0    1.0    0.08860759493670886  35 / 395
0.0    339.0  3.0    4.0    3.0    0.0    2.0    4.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    18.0   1.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    0.11488250652741515  44 / 383
1.0    0.0    313.0  0.0    14.0   1.0    2.0    0.0    0.0    0.0    19.0   3.0    0.0    0.0    8.0    0.0    1.0    0.0    2.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.14945652173913043  55 / 368
2.0    11.0   0.0    339.0  0.0    1.0    0.0    1.0    0.0    4.0    1.0    0.0    6.0    3.0    6.0    1.0    1.0    16.0   2.0    0.0    2.0    0.0    1.0    3.0    0.0    2.0    0.15671641791044777  63 / 402
0.0    6.0    1.0    1.0    324.0  3.0    15.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    1.0    8.0    5.0    7.0    4.0    0.0    0.0    0.0    0.0    0.0    6.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    2.0    0.0    4.0    7.0    1.0    0.0    0.0    3.0    3.0    8.0    5.0    0.0    0.0    2.0    1.0    4.0    4.0    0.0    1.0    1.0    0.0    0.0    342.0  3.0    3.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    2.0    8.0    3.0    18.0   1.0    1.0    346.0  0.0    0.11959287531806616  47 / 393
2.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    21.0   3.0    0.0    0.0    0.0    0.0    4.0    312.0  0.14986376021798364  55 / 367
397.0  464.0  359.0  421.0  422.0  389.0  314.0  287.0  328.0  371.0  368.0  363.0  401.0  384.0  404.0  367.0  383.0  485.0  319.0  379.0  407.0  381.0  417.0  413.0  418.0  362.0  0.16245126462061382  1,625 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837549
2    0.910527
3    0.938419
4    0.953814
5    0.96671
6    0.973208
7    0.979106
8    0.983205
9    0.987004
10   0.990803

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16945884381165333
RMSE: 0.41165379120281803
LogLoss: 0.5708600946126858
Mean Per-Class Error: 0.1615223457536979
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.06741573033707865  6 / 89
0.0   88.0   1.0   2.0    2.0    0.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   5.0    0.0   0.0   0.0    1.0   0.0    2.0   0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    69.0  0.0    3.0    0.0   0.0   0.0   0.0   0.0    4.0   1.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   0.0    0.0   96.0   0.0    0.0   0.0   0.0   0.0   2.0    1.0   0.0   2.0   1.0    2.0   1.0    0.0   3.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   1.0    1.0   0.0    78.0   2.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    3.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   89.0   0.0   0.0    0.0   0.03260869565217391  3 / 92
0.0   1.0    0.0   2.0    3.0    0.0   0.0   0.0   0.0   0.0    3.0   2.0   0.0   0.0    0.0   0.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0    82.0  2.0    1.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   1.0   0.0    5.0   1.0    0.0   97.0   0.0   0.09345794392523364  10 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0   1.0   0.0    0.0   0.0    0.0   3.0    73.0  0.16091954022988506  14 / 87
92.0  113.0  79.0  125.0  101.0  90.0  71.0  72.0  75.0  104.0  93.0  97.0  86.0  100.0  88.0  105.0  96.0  121.0  85.0  93.0  105.0  85.0  103.0  98.0  125.0  88.0  0.1606425702811245   400 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839357
2    0.908835
3    0.941365
4    0.955422
5    0.969076
6    0.9751
7    0.980321
8    0.983936
9    0.987952
10   0.991165
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:54  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:54  32.854 sec  39089 obs/sec     1         1             10007      0.573805         1.0518              0.99415        0.282115                         0.572585           1.04556               0.994158         0.285542
    2019-07-23 13:31:56  34.756 sec  47314 obs/sec     10        10            100070     0.412008         0.572518            0.996984       0.162451                         0.411654           0.57086               0.99698          0.160643
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0930252
C15         0.98825                0.98825              0.0919322
C9          0.840635               0.840635             0.0782003
C12         0.826152               0.826152             0.076853
C8          0.788082               0.788082             0.0733115
C11         0.764353               0.764353             0.0711041
C7          0.714654               0.714654             0.0664809
C10         0.664438               0.664438             0.0618095
C6          0.649917               0.649917             0.0604587
C16         0.632205               0.632205             0.058811
C14         0.625195               0.625195             0.0581589
C5          0.558653               0.558653             0.0519689
C3          0.474632               0.474632             0.0441528
C4          0.460389               0.460389             0.0428278
C1          0.381925               0.381925             0.0355287
C2          0.380291               0.380291             0.0353766
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_95

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009720780282123087  0.0002428102307021618  0.0         -0.009305440850681634  0.2402246594429016  0.22877109935865053  0.2024276852607727
    3        26       Softmax                      0.0   0.0   0.007005171244600206   0.03030618280172348    0.0         -0.31297121436014447   0.7276136875152588  -0.4944908484860972  0.22649550437927246


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1700754557883391
RMSE: 0.4124020559943162
LogLoss: 0.5550400272048909
Mean Per-Class Error: 0.15962017062525619
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    12.0   2.0    0.0    9.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    1.0    3.0    2.0    5.0    3.0    0.0    0.1189873417721519   47 / 395
0.0    329.0  0.0    5.0    3.0    0.0    0.0    11.0   2.0    0.0    2.0    0.0    0.0    0.0    4.0    9.0    0.0    9.0    4.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.1387434554973822   53 / 382
0.0    0.0    311.0  1.0    11.0   0.0    5.0    0.0    0.0    0.0    25.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    5.0    1.0    1.0    0.0    4.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
0.0    16.0   0.0    340.0  0.0    1.0    1.0    3.0    1.0    4.0    2.0    0.0    6.0    4.0    4.0    0.0    0.0    7.0    7.0    0.0    2.0    0.0    0.0    4.0    0.0    1.0    0.15632754342431762  63 / 403
0.0    7.0    5.0    1.0    306.0  5.0    13.0   0.0    0.0    0.0    8.0    5.0    0.0    0.0    0.0    0.0    9.0    4.0    6.0    4.0    0.0    0.0    0.0    4.0    0.0    7.0    0.203125             78 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    2.0    0.0    15.0   1.0    3.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    2.0    0.0    5.0    4.0    0.0    1.0    3.0    3.0    1.0    9.0    2.0    0.0    0.0    2.0    0.0    5.0    0.0    10.0   2.0    1.0    0.0    0.0    336.0  2.0    5.0    0.1450381679389313   57 / 393
2.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    1.0    0.0    1.0    0.0    1.0    0.0    1.0    5.0    0.0    2.0    6.0    3.0    14.0   1.0    0.0    345.0  0.0    0.12213740458015267  48 / 393
0.0    1.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    8.0    0.0    4.0    0.0    0.0    0.0    0.0    4.0    0.0    22.0   2.0    0.0    0.0    0.0    0.0    0.0    313.0  0.14713896457765668  54 / 367
374.0  439.0  360.0  424.0  378.0  396.0  347.0  363.0  349.0  363.0  416.0  362.0  419.0  382.0  392.0  407.0  369.0  382.0  421.0  353.0  383.0  374.0  419.0  395.0  390.0  346.0  0.1591522543237029   1,592 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840848
2    0.914126
3    0.942517
4    0.958712
5    0.970909
6    0.978206
7    0.982105
8    0.987404
9    0.991003
10   0.993602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17442983718476157
RMSE: 0.4176479823784159
LogLoss: 0.5714687983100238
Mean Per-Class Error: 0.16513513014631237
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16     17    18     19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
77.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   0.0   1.0   1.0    3.0    2.0    0.0   0.1348314606741573   12 / 89
0.0   85.0   0.0   1.0    2.0   0.0   0.0   3.0   1.0   0.0    1.0    0.0   0.0   0.0    2.0   2.0    0.0    5.0   1.0    0.0   0.0   1.0   0.0    1.0    1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    65.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    2.0   0.0    1.0    0.0   3.0    1.0   0.0   0.0   1.0    0.0    0.0    0.0   0.2073170731707317   17 / 82
0.0   2.0    0.0   96.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0    0.0   2.0   2.0    0.0   0.0    0.0    0.0   3.0    0.0   1.0   0.0   0.0    2.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   1.0    0.0   0.0    74.0  2.0   3.0   0.0   0.0   0.0    3.0    2.0   0.0   0.0    0.0   0.0    3.0    1.0   3.0    2.0   0.0   0.0   0.0    1.0    0.0    2.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   5.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    1.0   0.0   1.0   2.0   0.0   0.0    5.0    2.0   0.0   0.0    0.0   0.0    1.0    0.0   3.0    0.0   0.0   0.0   0.0    82.0   1.0    1.0   0.18                 18 / 100
1.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0    0.0   1.0    2.0    0.0   0.0    2.0   0.0   3.0   1.0    0.0    94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0    3.0   0.0   0.0    0.0   0.0    0.0    0.0   4.0    0.0   0.0   0.0   0.0    0.0    0.0    75.0  0.13793103448275862  12 / 87
82.0  104.0  75.0  119.0  87.0  91.0  89.0  90.0  84.0  102.0  104.0  99.0  97.0  103.0  75.0  114.0  105.0  95.0  105.0  80.0  97.0  85.0  104.0  101.0  117.0  86.0  0.1642570281124498   409 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835743
2    0.917269
3    0.94498
4    0.958233
5    0.969478
6    0.974699
7    0.978715
8    0.986747
9    0.991165
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:24  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:25  4 min  3.075 sec  64980 obs/sec     1         1             10007      0.589216         1.09397             0.993829       0.291513                         0.589612           1.10069               0.993806         0.294779
    2019-07-23 13:35:26  4 min  4.443 sec  67161 obs/sec     10        10            100070     0.412402         0.55504             0.996977       0.159152                         0.417648           0.571469              0.996892         0.164257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0843775
C13         0.964789               0.964789             0.0814065
C9          0.889012               0.889012             0.0750126
C8          0.877329               0.877329             0.0740269
C12         0.8034                 0.8034               0.0677889
C5          0.75881                0.75881              0.0640265
C11         0.740827               0.740827             0.0625092
C7          0.727158               0.727158             0.0613558
C6          0.717171               0.717171             0.0605131
C10         0.705207               0.705207             0.0595036
C3          0.696434               0.696434             0.0587634
C4          0.676524               0.676524             0.0570834
C14         0.673649               0.673649             0.0568408
C16         0.6065                 0.6065               0.051175
C1          0.523834               0.523834             0.0441998
C2          0.490854               0.490854             0.0414171
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_109

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017362914291112475  0.00040803104639053345  0.0         -0.010076021575375904  0.17850595712661743  0.14044201291951014  0.12368825078010559
    3        26       Softmax                      0.0   0.0   0.008790988814465751   0.031183145940303802    0.0         -0.18330244438368098   0.40104544162750244  -0.9196638947063094  0.29509425163269043


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1774198618477145
RMSE: 0.42121237143240997
LogLoss: 0.5675947995108795
Mean Per-Class Error: 0.15620593925334614
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    1.0    3.0    0.0    5.0    0.0    0.0    0.0    5.0    1.0    2.0    0.0    2.0    2.0    5.0    0.0    0.0810126582278481   32 / 395
0.0    328.0  0.0    6.0    2.0    1.0    2.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    1.0    14.0   11.0   0.0    0.0    2.0    0.0    4.0    2.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    312.0  0.0    14.0   0.0    5.0    1.0    0.0    0.0    17.0   0.0    0.0    0.0    4.0    0.0    1.0    0.0    3.0    2.0    4.0    0.0    5.0    0.0    0.0    0.0    0.15217391304347827  56 / 368
2.0    15.0   0.0    353.0  0.0    1.0    0.0    3.0    0.0    4.0    0.0    0.0    5.0    5.0    1.0    0.0    0.0    8.0    0.0    1.0    1.0    0.0    0.0    3.0    0.0    1.0    0.12406947890818859  50 / 403
0.0    3.0    1.0    0.0    319.0  3.0    15.0   0.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    1.0    3.0    4.0    9.0    5.0    0.0    0.0    0.0    5.0    0.0    12.0   0.16927083333333334  65 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    10.0   1.0    0.0    0.0    0.0    3.0    0.0    0.0    5.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    1.0    0.0    4.0    4.0    0.0    0.0    1.0    2.0    3.0    6.0    1.0    0.0    0.0    2.0    0.0    0.0    1.0    2.0    1.0    1.0    0.0    0.0    357.0  4.0    4.0    0.09390862944162437  37 / 394
1.0    0.0    0.0    3.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    12.0   0.0    13.0   1.0    0.0    348.0  0.0    0.11450381679389313  45 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    16.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    20.0   3.0    0.0    0.0    0.0    0.0    0.0    312.0  0.14986376021798364  55 / 367
403.0  441.0  361.0  442.0  394.0  387.0  347.0  296.0  350.0  365.0  364.0  371.0  396.0  382.0  390.0  369.0  349.0  442.0  415.0  377.0  398.0  365.0  419.0  433.0  393.0  354.0  0.15545336399080276  1,555 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.844547
2    0.915325
3    0.944917
4    0.961012
5    0.972008
6    0.979206
7    0.983705
8    0.987204
9    0.990103
10   0.992802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17930590405211058
RMSE: 0.4234452786985711
LogLoss: 0.5736941417520978
Mean Per-Class Error: 0.15965167641615258
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   1.0    1.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   82.0   0.0   1.0    1.0   0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    3.0   1.0    0.0   8.0    3.0    0.0   0.0    2.0   0.0    2.0    0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    67.0  0.0    3.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0    1.0   1.0    0.0   1.0    0.0    0.0    0.0   0.18292682926829268  15 / 82
2.0   4.0    0.0   96.0   0.0   0.0   0.0   2.0   0.0   2.0    0.0   0.0   1.0   2.0    0.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   0.0    2.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    78.0  2.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0    1.0   0.0    0.0   0.0    1.0    0.0    5.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   2.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0    88.0   1.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0    3.0   0.0    4.0   1.0    0.0    94.0   0.0   0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0    1.0   0.0    0.0   0.0    0.0    0.0    75.0  0.13793103448275862  12 / 87
95.0  105.0  76.0  122.0  92.0  93.0  88.0  69.0  85.0  104.0  90.0  98.0  88.0  101.0  84.0  105.0  91.0  119.0  102.0  89.0  102.0  83.0  100.0  109.0  111.0  89.0  0.15943775100401605  397 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840562
2    0.915663
3    0.943373
4    0.959036
5    0.970683
6    0.977108
7    0.984337
8    0.988755
9    0.98996
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:08  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:08  4 min 46.969 sec  31271 obs/sec     1         1             10007      0.597994         1.08868             0.993646       0.286914                         0.597028           1.08355               0.993649         0.285542
    2019-07-23 13:36:11  4 min 49.761 sec  33059 obs/sec     10        10            100070     0.421212         0.567595            0.996848       0.155453                         0.423445           0.573694              0.996805         0.159438
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0867274
C13         0.966517               0.966517             0.0838235
C8          0.847338               0.847338             0.0734874
C12         0.837178               0.837178             0.0726063
C9          0.83538                0.83538              0.0724503
C7          0.834551               0.834551             0.0723785
C11         0.74186                0.74186              0.0643396
C5          0.706127               0.706127             0.0612405
C10         0.698371               0.698371             0.0605679
C14         0.665083               0.665083             0.0576809
C6          0.65471                0.65471              0.0567813
C3          0.613502               0.613502             0.0532074
C4          0.611742               0.611742             0.0530548
C16         0.58959                0.58959              0.0511336
C2          0.489591               0.489591             0.042461
C1          0.43884                0.43884              0.0380595
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_48

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0010110685311701673  0.00027432339265942574  0.0         -0.00988344046109546  0.23566126823425293  0.2668052351903721   0.19871819019317627
    3        26       Softmax                      0.0   0.0   0.007710384136211919   0.035592079162597656    0.0         -0.2758353779644879   0.7246749401092529   -0.4793411509151066  0.18260318040847778


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17242393492261254
RMSE: 0.4152396114565812
LogLoss: 0.5706627348757094
Mean Per-Class Error: 0.16294892502947708
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
360.0  0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    4.0    0.0    4.0    0.0    1.0    2.0    4.0    1.0    0.08860759493670886   35 / 395
0.0    343.0  0.0    7.0    2.0    0.0    2.0    4.0    2.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    13.0   4.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.10443864229765012   40 / 383
0.0    0.0    300.0  1.0    16.0   0.0    9.0    3.0    0.0    0.0    18.0   0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    3.0    8.0    0.0    2.0    0.0    0.0    0.0    0.18478260869565216   68 / 368
1.0    19.0   0.0    344.0  0.0    0.0    0.0    5.0    0.0    5.0    0.0    1.0    4.0    3.0    2.0    0.0    1.0    8.0    0.0    0.0    3.0    0.0    0.0    4.0    0.0    3.0    0.14640198511166252   59 / 403
0.0    6.0    2.0    0.0    325.0  3.0    16.0   1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    9.0    3.0    1.0    0.0    0.0    5.0    0.0    5.0    0.15364583333333334   59 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    0.0    3.0    0.0    0.0    5.0    0.0    353.0  0.0    0.0    0.0    0.061170212765957445  23 / 376
0.0    2.0    0.0    3.0    7.0    0.0    0.0    2.0    2.0    2.0    8.0    0.0    0.0    0.0    2.0    1.0    1.0    0.0    1.0    2.0    2.0    0.0    0.0    354.0  1.0    4.0    0.10152284263959391   40 / 394
0.0    0.0    0.0    3.0    0.0    5.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    22.0   0.0    9.0    1.0    0.0    344.0  1.0    0.12244897959183673   48 / 392
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    16.0   2.0    0.0    0.0    0.0    3.0    0.0    319.0  0.1307901907356948    48 / 367
400.0  515.0  341.0  417.0  450.0  322.0  355.0  328.0  338.0  358.0  363.0  358.0  390.0  395.0  383.0  398.0  344.0  421.0  323.0  390.0  433.0  360.0  410.0  432.0  404.0  375.0  0.16205138458462462   1,621 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837949
2    0.912126
3    0.940118
4    0.956713
5    0.968809
6    0.976607
7    0.982305
8    0.985604
9    0.989003
10   0.991802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17335325557090206
RMSE: 0.4163571250391928
LogLoss: 0.5744717742754969
Mean Per-Class Error: 0.16202014863160244
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25     Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  --------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0   1.0    2.0    0.0    0.0898876404494382    8 / 89
0.0   90.0   0.0   1.0    1.0    0.0   1.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0   6.0    0.0   0.0   0.0    2.0   0.0   1.0    0.0    0.0    0.1509433962264151    16 / 106
0.0   0.0    64.0  0.0    3.0    0.0   3.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0    0.0   2.0   2.0    0.0   1.0   0.0    0.0    0.0    0.21951219512195122   18 / 82
0.0   3.0    0.0   96.0   0.0    0.0   0.0   2.0   0.0   2.0    0.0   0.0   2.0   2.0    1.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0    1.0    0.14285714285714285   16 / 112
0.0   0.0    0.0   0.0    82.0   1.0   4.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0   1.0   0.0    0.0   0.0   0.0    0.0    2.0    0.15463917525773196   15 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0   88.0  0.0    0.0    0.0    0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   89.0   0.0    1.0    0.11                  11 / 100
0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0   6.0   0.0    3.0   1.0   0.0    93.0   0.0    0.1308411214953271    14 / 107
0.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0    0.0    80.0   0.08045977011494253   7 / 87
92.0  125.0  72.0  114.0  104.0  73.0  94.0  78.0  81.0  106.0  91.0  95.0  91.0  103.0  83.0  116.0  91.0  102.0  81.0  90.0  108.0  85.0  99.0  104.0  110.0  102.0  0.1602409638554217    399 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839759
2    0.915663
3    0.940964
4    0.956225
5    0.968273
6    0.977108
7    0.982731
8    0.985141
9    0.986747
10   0.990763
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:32  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:33  2 min 10.949 sec  61018 obs/sec     1         1             10007      0.603299         1.15166             0.993531       0.309607                         0.602375           1.14539               0.993534         0.316867
    2019-07-23 13:33:34  2 min 12.331 sec  65922 obs/sec     10        10            100070     0.41524          0.570663            0.996936       0.162051                         0.416357           0.574472              0.996911         0.160241
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0902136
C13         0.974176               0.974176             0.087884
C8          0.851285               0.851285             0.0767976
C9          0.835808               0.835808             0.0754012
C7          0.832351               0.832351             0.0750895
C5          0.724111               0.724111             0.0653247
C12         0.721363               0.721363             0.0650768
C11         0.682839               0.682839             0.0616014
C10         0.661949               0.661949             0.0597168
C6          0.617869               0.617869             0.0557402
C14         0.591769               0.591769             0.0533857
C4          0.581867               0.581867             0.0524923
C3          0.541403               0.541403             0.0488419
C16         0.525742               0.525742             0.0474291
C1          0.510815               0.510815             0.0460825
C2          0.43145                0.43145              0.0389227
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_9

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017166639533456873  0.00041601911652833223  0.0         -0.009524969943552758  0.17840707302093506  0.1360921248319832   0.11874893307685852
    3        26       Softmax                      0.0   0.0   0.009402985023738299   0.03361499309539795     0.0         -0.17530344753289412   0.4035313129425049   -0.9051429807829993  0.38019001483917236


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17716857623823484
RMSE: 0.4209139772426604
LogLoss: 0.5643508009176011
Mean Per-Class Error: 0.15988135152665953
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    6.0    2.0    2.0    0.0    1.0    0.0    0.0    0.0    4.0    1.0    1.0    3.0    2.0    2.0    3.0    3.0    0.08354430379746836  33 / 395
0.0    332.0  0.0    3.0    2.0    0.0    5.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    22.0   6.0    0.0    0.0    1.0    0.0    4.0    0.0    1.0    0.13315926892950392  51 / 383
0.0    0.0    302.0  0.0    14.0   0.0    8.0    1.0    0.0    0.0    22.0   3.0    0.0    0.0    6.0    0.0    2.0    0.0    1.0    4.0    1.0    0.0    3.0    0.0    0.0    0.0    0.1771117166212534   65 / 367
3.0    23.0   0.0    340.0  0.0    0.0    1.0    5.0    0.0    5.0    0.0    0.0    6.0    4.0    2.0    1.0    0.0    5.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    2.0    0.15632754342431762  63 / 403
0.0    4.0    1.0    0.0    317.0  2.0    19.0   0.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    8.0    5.0    0.0    0.0    0.0    4.0    0.0    14.0   0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    1.0    0.0    9.0    1.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    4.0    5.0    0.0    0.0    2.0    2.0    2.0    4.0    4.0    0.0    0.0    0.0    0.0    5.0    2.0    0.0    3.0    1.0    0.0    0.0    351.0  1.0    6.0    0.10913705583756345  43 / 394
0.0    1.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    18.0   2.0    10.0   1.0    0.0    350.0  0.0    0.10941475826972011  43 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    16.0   3.0    0.0    0.0    0.0    0.0    0.0    319.0  0.1284153005464481   47 / 366
401.0  486.0  334.0  407.0  399.0  362.0  387.0  314.0  347.0  361.0  373.0  378.0  389.0  378.0  393.0  373.0  349.0  439.0  322.0  393.0  400.0  365.0  418.0  429.0  396.0  410.0  0.15905228431470558  1,591 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840948
2    0.915125
3    0.946016
4    0.962211
5    0.973208
6    0.979506
7    0.983705
8    0.987104
9    0.990703
10   0.992402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17961024704244669
RMSE: 0.42380449153170463
LogLoss: 0.5749159303605711
Mean Per-Class Error: 0.16157616789686297
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   1.0    1.0    2.0    0.0    0.07865168539325842  7 / 89
0.0   89.0   0.0   0.0    1.0   0.0   2.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    0.0   8.0    1.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0    0.16037735849056603  17 / 106
0.0   0.0    63.0  0.0    2.0   0.0   3.0    0.0   0.0   0.0    5.0   0.0    0.0   0.0    3.0   0.0    1.0   0.0    1.0   2.0   1.0    0.0   1.0    0.0    0.0    0.0    0.23170731707317074  19 / 82
3.0   4.0    0.0   93.0   0.0   0.0   1.0    3.0   0.0   2.0    0.0   0.0    3.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0    0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    75.0  1.0   5.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   1.0    3.0   2.0   0.0    0.0   0.0    2.0    0.0    7.0    0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   87.0   0.0    0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0    1.0   0.0   0.0    2.0   3.0    0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    84.0   0.0    3.0    0.16                 16 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   3.0   0.0    3.0   1.0    0.0    98.0   0.0    0.08411214953271028  9 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   4.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0    0.0    0.0    76.0   0.12643678160919541  11 / 87
92.0  122.0  67.0  109.0  92.0  82.0  101.0  80.0  86.0  106.0  92.0  101.0  87.0  100.0  82.0  105.0  92.0  109.0  81.0  95.0  100.0  83.0  102.0  103.0  114.0  107.0  0.1606425702811245   400 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839357
2    0.916466
3    0.947791
4    0.962249
5    0.973896
6    0.979116
7    0.982329
8    0.985944
9    0.98996
10   0.991968
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:51  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:51  29.677 sec  29961 obs/sec     1         1             10007      0.593734         1.0841              0.993734       0.287214                         0.593058           1.08525               0.993733         0.289558
    2019-07-23 13:31:54  32.529 sec  32606 obs/sec     10        10            100070     0.420914         0.564351            0.996851       0.159052                         0.423804           0.574916              0.9968           0.160643
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0900003
C13         0.894666               0.894666             0.0805202
C8          0.862554               0.862554             0.0776301
C9          0.84301                0.84301              0.0758712
C12         0.831723               0.831723             0.0748553
C7          0.776049               0.776049             0.0698447
C5          0.699275               0.699275             0.062935
C11         0.694867               0.694867             0.0625383
C10         0.643601               0.643601             0.0579243
C6          0.627591               0.627591             0.0564834
C4          0.610719               0.610719             0.0549649
C14         0.59953                0.59953              0.0539579
C3          0.593604               0.593604             0.0534246
C16         0.570561               0.570561             0.0513506
C2          0.4532                 0.4532               0.0407881
C1          0.41012                0.41012              0.036911
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_73

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.001000265962602498  0.00025331228971481323  0.0         -0.007984002211770758  0.23707044124603271  0.2181206694319798    0.20619279146194458
    3        26       Softmax                      0.0   0.0   0.006932673153886963  0.021103329956531525    0.0         -0.3078564505285263    0.726794958114624    -0.49530883293460337  0.25880587100982666


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17303111100328597
RMSE: 0.41597008426482546
LogLoss: 0.5691117921925639
Mean Per-Class Error: 0.16494061238218455
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    5.0    7.0    1.0    1.0    1.0    2.0    0.0    0.0    1.0    2.0    0.0    1.0    4.0    1.0    0.0    6.0    0.0    0.08354430379746836  33 / 395
1.0    340.0  0.0    5.0    3.0    0.0    1.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    5.0    8.0    9.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    307.0  0.0    13.0   0.0    6.0    0.0    0.0    0.0    26.0   0.0    1.0    0.0    6.0    0.0    1.0    0.0    4.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.16348773841961853  60 / 367
4.0    14.0   0.0    344.0  0.0    0.0    1.0    1.0    1.0    2.0    0.0    0.0    7.0    4.0    2.0    2.0    0.0    11.0   1.0    1.0    0.0    0.0    0.0    7.0    0.0    1.0    0.14640198511166252  59 / 403
0.0    3.0    6.0    0.0    321.0  3.0    9.0    0.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    10.0   3.0    8.0    4.0    0.0    0.0    0.0    5.0    0.0    7.0    0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    1.0    0.0    9.0    3.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    2.0    0.0    5.0    7.0    0.0    0.0    1.0    2.0    2.0    6.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    4.0    2.0    0.0    0.0    349.0  3.0    5.0    0.11421319796954314  45 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    7.0    0.0    2.0    11.0   0.0    9.0    0.0    0.0    353.0  0.0    0.10178117048346055  40 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    27.0   3.0    0.0    0.0    0.0    2.0    2.0    301.0  0.17983651226158037  66 / 367
405.0  487.0  345.0  435.0  430.0  325.0  343.0  285.0  334.0  364.0  378.0  361.0  400.0  399.0  402.0  423.0  380.0  418.0  361.0  385.0  399.0  359.0  407.0  424.0  398.0  356.0  0.16395081475557333  1,640 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836049
2    0.913526
3    0.940518
4    0.958013
5    0.968609
6    0.976107
7    0.981106
8    0.986104
9    0.989103
10   0.992002

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1750905959019231
RMSE: 0.4184382820702751
LogLoss: 0.5758734745299966
Mean Per-Class Error: 0.16538076897619902
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   2.0   1.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
1.0   87.0   0.0   1.0    2.0    0.0   1.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    1.0   3.0    3.0   0.0   0.0   0.0   1.0    1.0    0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    65.0  0.0    3.0    0.0   2.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   1.0    0.0    0.0    0.0   0.2073170731707317   17 / 82
3.0   0.0    0.0   98.0   0.0    0.0   1.0   1.0   0.0   1.0    0.0   0.0   3.0   1.0    0.0   2.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.125                14 / 112
0.0   0.0    2.0   0.0    79.0   1.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   1.0   0.0   0.0   0.0    1.0    0.0    2.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   1.0   1.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    3.0    0.0   0.0   1.0   0.0   0.0    4.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    85.0   0.0    2.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    1.0   0.0    2.0   0.0    0.0   3.0   0.0   4.0   0.0    0.0    96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    3.0   0.0   0.0   0.0   0.0    1.0    2.0    72.0  0.1724137931034483   15 / 87
97.0  112.0  73.0  124.0  103.0  75.0  95.0  69.0  78.0  109.0  98.0  95.0  86.0  108.0  80.0  121.0  99.0  107.0  85.0  90.0  99.0  82.0  100.0  102.0  111.0  92.0  0.1634538152610442   407 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836546
2    0.913253
3    0.938554
4    0.957831
5    0.970281
6    0.9751
7    0.980321
8    0.984739
9    0.989558
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:30  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:30  3 min  8.914 sec  55594 obs/sec     1         1             10007      0.592764         1.09863             0.993756       0.296211                         0.594682           1.11171               0.993699         0.301205
    2019-07-23 13:34:32  3 min 10.190 sec  70175 obs/sec     10        10            100070     0.41597          0.569112            0.996925       0.163951                         0.418438           0.575873              0.99688          0.163454
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0898679
C15         0.94236                0.94236              0.0846879
C12         0.873019               0.873019             0.0784564
C7          0.782326               0.782326             0.070306
C8          0.772947               0.772947             0.0694632
C9          0.767566               0.767566             0.0689795
C5          0.734677               0.734677             0.0660239
C6          0.685011               0.685011             0.0615605
C11         0.654419               0.654419             0.0588113
C10         0.623881               0.623881             0.0560669
C16         0.61424                0.61424              0.0552005
C14         0.596939               0.596939             0.0536457
C4          0.591189               0.591189             0.0531289
C3          0.553695               0.553695             0.0497594
C2          0.469248               0.469248             0.0421704
C1          0.465924               0.465924             0.0418716
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_74

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009629068567846844  0.00023468455765396357  0.0         -0.014834558387434527  0.23600518703460693  0.2421104961241262   0.17731636762619019
    3        26       Softmax                      0.0   0.0   0.006481416181416604   0.0302928164601326      0.0         -0.2915944104080644    0.7364709377288818   -0.4733681806849769  0.22732597589492798


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17235787929392607
RMSE: 0.4151600646665405
LogLoss: 0.5680737177809161
Mean Per-Class Error: 0.16291927163882583
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    2.0    4.0    0.0    5.0    0.0    0.0    4.0    5.0    1.0    2.0    3.0    1.0    2.0    3.0    1.0    0.09873417721518987  39 / 395
0.0    341.0  0.0    5.0    1.0    1.0    4.0    2.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    11.0   6.0    0.0    0.0    2.0    0.0    4.0    0.0    1.0    0.10966057441253264  42 / 383
0.0    0.0    307.0  0.0    17.0   0.0    4.0    2.0    0.0    0.0    10.0   7.0    3.0    1.0    7.0    0.0    1.0    0.0    2.0    5.0    1.0    0.0    1.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
0.0    24.0   0.0    339.0  0.0    0.0    0.0    4.0    0.0    7.0    3.0    0.0    6.0    4.0    2.0    0.0    1.0    8.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.1588089330024814   64 / 403
0.0    16.0   0.0    0.0    317.0  3.0    12.0   0.0    0.0    0.0    4.0    4.0    0.0    0.0    0.0    0.0    5.0    5.0    1.0    2.0    0.0    0.0    0.0    6.0    0.0    8.0    0.17232375979112272  66 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    14.0   0.0    1.0    0.0    0.0    8.0    0.0    0.0    2.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    5.0    0.0    7.0    4.0    0.0    0.0    0.0    2.0    2.0    6.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    4.0    6.0    1.0    0.0    0.0    343.0  7.0    2.0    0.12944162436548223  51 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    3.0    19.0   2.0    10.0   1.0    0.0    347.0  0.0    0.11704834605597965  46 / 393
0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    19.0   0.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    19.0   4.0    0.0    0.0    0.0    0.0    1.0    305.0  0.16893732970027248  62 / 367
385.0  523.0  348.0  412.0  393.0  385.0  327.0  304.0  339.0  369.0  368.0  399.0  423.0  387.0  407.0  364.0  350.0  440.0  349.0  384.0  399.0  369.0  383.0  415.0  408.0  373.0  0.1622513246026192   1,623 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837749
2    0.912326
3    0.942817
4    0.959612
5    0.969509
6    0.977107
7    0.983105
8    0.986804
9    0.989403
10   0.991503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1739191512660704
RMSE: 0.417036151030184
LogLoss: 0.576145499677919
Mean Per-Class Error: 0.15965655046851682
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   2.0    1.0   0.0   0.0   1.0   1.0   1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   87.0   0.0   1.0    1.0   1.0   2.0   1.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   5.0    3.0   0.0   0.0   2.0   0.0   2.0    0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    66.0  0.0    4.0   0.0   1.0   1.0   0.0   0.0    2.0   2.0    0.0   0.0    3.0   0.0    0.0   0.0    1.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
0.0   5.0    0.0   94.0   0.0   0.0   0.0   3.0   0.0   2.0    2.0   0.0    2.0   2.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.16071428571428573  18 / 112
0.0   4.0    0.0   0.0    76.0  3.0   2.0   0.0   0.0   0.0    2.0   1.0    0.0   0.0    0.0   0.0    2.0   1.0    1.0   1.0   0.0   0.0   0.0   2.0    0.0    2.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   3.0    0.0   3.0    1.0   0.0   0.0   0.0   0.0   0.0    4.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   85.0   2.0    0.0   0.15                 15 / 100
0.0   0.0    0.0   2.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   5.0   0.0   3.0   1.0   0.0    94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   5.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    1.0    74.0  0.14942528735632185  13 / 87
88.0  126.0  75.0  114.0  92.0  92.0  84.0  82.0  85.0  102.0  97.0  104.0  90.0  102.0  84.0  105.0  93.0  109.0  87.0  89.0  98.0  85.0  96.0  102.0  116.0  93.0  0.1598393574297189   398 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840161
2    0.916867
3    0.942169
4    0.959438
5    0.968273
6    0.973092
7    0.980321
8    0.985944
9    0.987952
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:32  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:32  3 min 10.388 sec  65405 obs/sec     1         1             10007      0.598617         1.12099             0.993632       0.304909                         0.599915           1.12066               0.993587         0.313655
    2019-07-23 13:34:33  3 min 11.781 sec  66052 obs/sec     10        10            100070     0.41516          0.568074            0.996937       0.162251                         0.417036           0.576145              0.996901         0.159839
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0875323
C13         0.960589               0.960589             0.0840826
C9          0.854939               0.854939             0.0748348
C8          0.824031               0.824031             0.0721294
C12         0.750082               0.750082             0.0656565
C10         0.734236               0.734236             0.0642694
C7          0.733465               0.733465             0.0642019
C6          0.720574               0.720574             0.0630735
C5          0.719915               0.719915             0.0630159
C11         0.679936               0.679936             0.0595164
C4          0.665683               0.665683             0.0582688
C3          0.598237               0.598237             0.0523651
C14         0.578723               0.578723             0.050657
C16         0.559263               0.559263             0.0489536
C2          0.556364               0.556364             0.0486998
C1          0.488311               0.488311             0.042743
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_80

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0018143219934927401  0.0004460216732695699  0.0         0.004404326474912068   0.4511067867279053   0.06876300999809594  0.49635374546051025
    3        26       Softmax                 0.0   0.0   0.0022996261286607478  0.0005778365302830935  0.0         -0.009576431586866035  0.41115689277648926  -0.4952121235967167  0.17969143390655518


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16750969866267276
RMSE: 0.40927948722440605
LogLoss: 0.5691825202525054
Mean Per-Class Error: 0.1711318288494748
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    7.0    1.0    2.0    1.0    1.0    0.0    0.0    4.0    3.0    0.0    1.0    3.0    1.0    2.0    7.0    0.0    0.10126582278481013  40 / 395
0.0    317.0  0.0    6.0    3.0    1.0    1.0    10.0   2.0    0.0    1.0    0.0    0.0    0.0    2.0    4.0    1.0    23.0   8.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.17232375979112272  66 / 383
0.0    0.0    303.0  0.0    14.0   1.0    6.0    1.0    0.0    0.0    15.0   3.0    0.0    0.0    11.0   1.0    0.0    0.0    1.0    3.0    6.0    0.0    3.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
1.0    17.0   0.0    336.0  0.0    1.0    0.0    6.0    0.0    2.0    2.0    1.0    6.0    4.0    3.0    1.0    0.0    13.0   2.0    1.0    0.0    0.0    0.0    6.0    0.0    1.0    0.1662531017369727   67 / 403
0.0    1.0    4.0    0.0    312.0  4.0    6.0    3.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    14.0   2.0    14.0   1.0    0.0    0.0    0.0    5.0    2.0    8.0    0.1875               72 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    17.0   1.0    5.0    0.0    0.0    7.0    0.0    0.0    5.0    3.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    3.0    0.0    6.0    7.0    0.0    0.0    1.0    5.0    2.0    10.0   0.0    0.0    0.0    2.0    0.0    4.0    1.0    4.0    1.0    2.0    0.0    0.0    340.0  4.0    2.0    0.13705583756345177  54 / 394
0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    3.0    20.0   3.0    37.0   1.0    1.0    308.0  0.0    0.21628498727735368  85 / 393
1.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    10.0   0.0    3.0    0.0    0.0    0.0    0.0    6.0    0.0    31.0   2.0    0.0    0.0    0.0    6.0    1.0    289.0  0.2125340599455041   78 / 367
384.0  440.0  336.0  408.0  409.0  400.0  313.0  301.0  343.0  379.0  388.0  360.0  448.0  381.0  410.0  370.0  372.0  485.0  393.0  386.0  401.0  423.0  368.0  419.0  362.0  324.0  0.17034889533140057  1,704 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.829651
2    0.909527
3    0.944217
4    0.960612
5    0.969009
6    0.977707
7    0.982305
8    0.985804
9    0.989003
10   0.991703

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16981342267498106
RMSE: 0.41208424220659184
LogLoss: 0.579901941258707
Mean Per-Class Error: 0.17251078393503433
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21     22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  -----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    2.0    0.0   0.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   83.0   0.0   1.0    2.0    1.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0   7.0    1.0    0.0   0.0    2.0    0.0   1.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    64.0  0.0    4.0    0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    5.0   1.0    0.0   0.0    1.0    1.0   1.0    0.0    1.0   0.0    0.0    0.0   0.21951219512195122  18 / 82
1.0   2.0    0.0   92.0   0.0    0.0   0.0   3.0   0.0   1.0    1.0   1.0   2.0   2.0    0.0   1.0    0.0   3.0    1.0    0.0   0.0    0.0    0.0   2.0    0.0    0.0   0.17857142857142858  20 / 112
0.0   0.0    1.0   0.0    77.0   3.0   1.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    4.0   1.0    4.0    0.0   0.0    0.0    0.0   1.0    0.0    3.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---    ---   ---    ---    ---   ---                  ---
1.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   2.0    0.0    84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   1.0    0.0   3.0    3.0    0.0   0.0   1.0   1.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   1.0    0.0    0.0   81.0   2.0    1.0   0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0    4.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0   0.0    0.0    4.0   0.0    10.0   1.0   0.0    84.0   0.0   0.21495327102803738  23 / 107
1.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   2.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0    0.0   0.0    0.0    0.0   2.0    0.0    70.0  0.19540229885057472  17 / 87
88.0  105.0  69.0  114.0  100.0  97.0  81.0  74.0  82.0  106.0  97.0  98.0  98.0  106.0  88.0  109.0  96.0  121.0  100.0  88.0  100.0  100.0  88.0  100.0  106.0  79.0  0.17309236947791165  431 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826908
2    0.909237
3    0.942972
4    0.958635
5    0.969076
6    0.976707
7    0.982731
8    0.986747
9    0.989157
10   0.991968
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:48  3 min 26.114 sec  27341 obs/sec     1         1             10007      0.550033         0.989071            0.994625       0.262121                         0.549193           0.983491              0.994626         0.268675
    2019-07-23 13:34:51  3 min 29.164 sec  29765 obs/sec     10        10            100070     0.409279         0.569183            0.997024       0.170349                         0.412084           0.579902              0.996974         0.173092
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0856738
C13         0.977114               0.977114             0.083713
C12         0.875826               0.875826             0.0750353
C9          0.842716               0.842716             0.0721986
C7          0.815135               0.815135             0.0698357
C8          0.814899               0.814899             0.0698155
C11         0.758694               0.758694             0.0650001
C10         0.744246               0.744246             0.0637623
C14         0.698251               0.698251             0.0598218
C6          0.67627                0.67627              0.0579386
C5          0.662314               0.662314             0.0567429
C16         0.64801                0.64801              0.0555175
C3          0.64141                0.64141              0.054952
C4          0.547971               0.547971             0.0469468
C1          0.512655               0.512655             0.0439211
C2          0.456677               0.456677             0.0391252
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_84

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017097684660001278  0.00040716666262596846  0.0         -0.01023846943399409  0.17630118131637573  0.1390937386885311   0.11154115200042725
    3        26       Softmax                      0.0   0.0   0.008476339501778686   0.030868597328662872    0.0         -0.1758033897571614   0.4022643566131592   -0.9146887485176374  0.3585855960845947


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17927732488909515
RMSE: 0.42341153136056076
LogLoss: 0.5754535948130028
Mean Per-Class Error: 0.16261723759357516
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    10.0   5.0    2.0    5.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    2.0    0.0    2.0    3.0    5.0    0.0    0.10379746835443038  41 / 395
0.0    333.0  0.0    6.0    4.0    0.0    2.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    2.0    1.0    16.0   10.0   0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.13054830287206268  50 / 383
0.0    0.0    301.0  1.0    17.0   0.0    8.0    0.0    0.0    0.0    20.0   1.0    0.0    0.0    7.0    0.0    2.0    0.0    4.0    1.0    1.0    0.0    5.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
2.0    22.0   0.0    347.0  0.0    0.0    0.0    5.0    0.0    5.0    2.0    0.0    7.0    2.0    1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.13681592039800994  55 / 402
0.0    4.0    1.0    0.0    322.0  4.0    16.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    2.0    4.0    8.0    1.0    0.0    0.0    0.0    2.0    0.0    17.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    2.0    0.0    12.0   0.0    1.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    3.0    0.0    4.0    5.0    0.0    0.0    3.0    2.0    2.0    5.0    4.0    0.0    0.0    2.0    0.0    4.0    2.0    5.0    3.0    1.0    0.0    0.0    343.0  3.0    3.0    0.12944162436548223  51 / 394
1.0    0.0    0.0    2.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    5.0    0.0    3.0    13.0   1.0    14.0   1.0    0.0    344.0  0.0    0.12468193384223919  49 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    24.0   2.0    0.0    0.0    0.0    2.0    0.0    309.0  0.15803814713896458  58 / 367
391.0  460.0  346.0  431.0  419.0  373.0  353.0  324.0  338.0  367.0  392.0  373.0  417.0  364.0  403.0  384.0  331.0  427.0  415.0  371.0  382.0  366.0  418.0  392.0  390.0  376.0  0.1619514145756273   1,620 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838049
2    0.911327
3    0.943717
4    0.959612
5    0.970809
6    0.977407
7    0.983505
8    0.986604
9    0.989103
10   0.992202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18163357956677717
RMSE: 0.42618491241100637
LogLoss: 0.583177320273733
Mean Per-Class Error: 0.16530040042538582
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0    0.0898876404494382   8 / 89
0.0   82.0   0.0   1.0    3.0   0.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    2.0   0.0    0.0   8.0    3.0   0.0   0.0   2.0   0.0    1.0   1.0    0.0    0.22641509433962265  24 / 106
0.0   0.0    64.0  0.0    3.0   0.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    2.0   1.0   0.0   0.0   1.0    0.0   0.0    0.0    0.21951219512195122  18 / 82
2.0   4.0    0.0   95.0   0.0   0.0   0.0   2.0   0.0   1.0    1.0   0.0   3.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    1.0    0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    78.0  1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   0.0   0.0   0.0   0.0    1.0   0.0    9.0    0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    2.0   0.0   0.0   2.0   0.0   0.0    3.0   3.0   0.0   0.0    0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0   0.0    82.0  0.0    2.0    0.18                 18 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   4.0   0.0   4.0   1.0    0.0   93.0   0.0    0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0    1.0   0.0    75.0   0.13793103448275862  12 / 87
92.0  106.0  73.0  118.0  98.0  88.0  92.0  75.0  81.0  108.0  98.0  99.0  95.0  100.0  85.0  109.0  91.0  113.0  95.0  86.0  97.0  84.0  100.0  96.0  109.0  102.0  0.1650602409638554   411 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83494
2    0.908434
3    0.942972
4    0.960643
5    0.970683
6    0.976707
7    0.981124
8    0.985542
9    0.987952
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:01  3 min 39.900 sec  30509 obs/sec     1         1             10007      0.594084         1.09032             0.993728       0.277817                         0.592316           1.08536               0.993749         0.278313
    2019-07-23 13:35:04  3 min 42.742 sec  32437 obs/sec     10        10            100070     0.423412         0.575454            0.996814       0.161951                         0.426185           0.583177              0.996764         0.16506
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0860382
C13         0.968955               0.968955             0.0833672
C8          0.908556               0.908556             0.0781705
C9          0.862334               0.862334             0.0741937
C12         0.84934                0.84934              0.0730757
C7          0.818348               0.818348             0.0704092
C5          0.732087               0.732087             0.0629874
C11         0.714145               0.714145             0.0614437
C10         0.684411               0.684411             0.0588855
C14         0.669982               0.669982             0.0576441
C6          0.654135               0.654135             0.0562806
C3          0.62925                0.62925              0.0541396
C4          0.602402               0.602402             0.0518296
C16         0.598978               0.598978             0.051535
C2          0.470956               0.470956             0.0405202
C1          0.458861               0.458861             0.0394796
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_38

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001549088880040017  0.00039318331982940435  0.0         0.003790417623747544  0.42841875553131104  -0.0119471544049904  0.49718332290649414
    3        26       Softmax                 0.0   0.0   0.002754299774376425  0.0008765680249780416   0.0         -0.02559192037752977  0.5634369850158691   -0.5203296492492192  0.18394780158996582


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17152243180677568
RMSE: 0.41415266726990385
LogLoss: 0.569273341195362
Mean Per-Class Error: 0.1682452210927263
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    0.0    2.0    4.0    0.0    0.0    0.0    2.0    1.0    0.0    1.0    4.0    0.0    1.0    3.0    5.0    4.0    0.07848101265822785  31 / 395
0.0    317.0  0.0    7.0    3.0    4.0    2.0    9.0    2.0    0.0    5.0    1.0    0.0    0.0    2.0    4.0    5.0    10.0   2.0    1.0    0.0    6.0    0.0    2.0    1.0    0.0    0.17232375979112272  66 / 383
0.0    2.0    309.0  0.0    14.0   1.0    10.0   2.0    0.0    0.0    12.0   2.0    0.0    0.0    3.0    0.0    3.0    1.0    2.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
1.0    13.0   0.0    340.0  0.0    1.0    0.0    5.0    1.0    5.0    2.0    3.0    3.0    4.0    4.0    3.0    0.0    5.0    3.0    0.0    2.0    0.0    0.0    5.0    0.0    2.0    0.15422885572139303  62 / 402
0.0    13.0   7.0    0.0    306.0  4.0    18.0   1.0    0.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    3.0    2.0    1.0    3.0    1.0    0.0    0.0    7.0    0.0    12.0   0.203125             78 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    1.0    0.0    6.0    5.0    3.0    0.0    0.0    0.0    0.0    0.0    9.0    1.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    3.0    0.0    4.0    8.0    2.0    0.0    1.0    1.0    1.0    5.0    0.0    0.0    0.0    2.0    0.0    2.0    1.0    3.0    2.0    2.0    0.0    0.0    350.0  3.0    3.0    0.10941475826972011  43 / 393
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    5.0    4.0    0.0    0.0    10.0   1.0    19.0   0.0    0.0    348.0  1.0    0.11450381679389313  45 / 393
1.0    0.0    0.0    0.0    15.0   1.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    30.0   5.0    0.0    0.0    0.0    1.0    0.0    306.0  0.16621253405994552  61 / 367
387.0  462.0  358.0  412.0  409.0  348.0  364.0  357.0  328.0  364.0  352.0  370.0  384.0  397.0  394.0  423.0  352.0  429.0  314.0  390.0  422.0  377.0  381.0  428.0  402.0  399.0  0.16724982505248426  1,673 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83275
2    0.909627
3    0.939318
4    0.957313
5    0.96821
6    0.976507
7    0.981606
8    0.985504
9    0.988104
10   0.990703

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17746009195386864
RMSE: 0.42126012385920014
LogLoss: 0.5846547821542996
Mean Per-Class Error: 0.17306741405737916
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   1.0   1.0    2.0    1.0   0.06741573033707865  6 / 89
0.0   83.0   0.0   2.0    2.0   0.0   1.0   5.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    1.0   2.0    0.0   0.0   0.0    4.0   0.0   1.0    1.0    0.0   0.2169811320754717   23 / 106
0.0   1.0    68.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    2.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
1.0   2.0    0.0   93.0   0.0   1.0   0.0   0.0   1.0   2.0    0.0   3.0   1.0   3.0    0.0   2.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   1.0    0.0    1.0   0.16964285714285715  19 / 112
0.0   2.0    3.0   0.0    73.0  2.0   3.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    2.0   1.0    1.0   1.0   0.0    0.0   0.0   2.0    0.0    4.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   3.0    1.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   1.0    0.0   2.0    4.0   1.0   0.0   1.0   0.0   1.0    1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   1.0   1.0    0.0   0.0   84.0   1.0    0.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   3.0    2.0   0.0    0.0   1.0   0.0    5.0   0.0   0.0    95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0   1.0   0.0    0.0   0.0   1.0    0.0    74.0  0.14942528735632185  13 / 87
89.0  120.0  80.0  109.0  96.0  79.0  85.0  90.0  78.0  105.0  87.0  99.0  83.0  107.0  81.0  127.0  93.0  107.0  82.0  86.0  105.0  92.0  91.0  104.0  117.0  98.0  0.17269076305220885  430 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827309
2    0.906426
3    0.940161
4    0.95743
5    0.969076
6    0.976707
7    0.980321
8    0.984337
9    0.98755
10   0.989157
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:06  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:06  1 min 44.829 sec  49295 obs/sec     1         1             10007      0.587308         1.09644             0.993869       0.291413                         0.585722           1.09054               0.993887         0.293574
    2019-07-23 13:33:08  1 min 46.826 sec  46179 obs/sec     10        10            100070     0.414153         0.569273            0.996951       0.16725                          0.42126            0.584655              0.996838         0.172691
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0923218
C13         0.976514               0.976514             0.0901535
C12         0.954442               0.954442             0.0881158
C9          0.848424               0.848424             0.078328
C8          0.839137               0.839137             0.0774706
C11         0.754007               0.754007             0.0696112
C10         0.727125               0.727125             0.0671294
C6          0.65055                0.65055              0.06006
C7          0.642711               0.642711             0.0593362
C16         0.62938                0.62938              0.0581055
C14         0.614033               0.614033             0.0566886
C5          0.55381                0.55381              0.0511287
C4          0.475798               0.475798             0.0439265
C3          0.458346               0.458346             0.0423153
C1          0.382718               0.382718             0.0353332
C2          0.324689               0.324689             0.0299759
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_81

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017088946472512134  0.0003986787050962448  0.0         -0.010422115065822357  0.17600774765014648  0.14913926005659892  0.1195993423461914
    3        26       Softmax                      0.0   0.0   0.008005299613562155   0.024335235357284546   0.0         -0.18313466220266014   0.40361976623535156  -0.8973694713525904  0.3223687410354614


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1788566951376779
RMSE: 0.4229145246236855
LogLoss: 0.5731186587368131
Mean Per-Class Error: 0.16026057279460382
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    3.0    2.0    7.0    0.0    2.0    0.0    0.0    2.0    6.0    0.0    1.0    0.0    2.0    2.0    6.0    0.0    0.10126582278481013  40 / 395
0.0    327.0  0.0    5.0    3.0    0.0    1.0    8.0    4.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    3.0    15.0   7.0    0.0    0.0    2.0    0.0    2.0    1.0    0.0    0.1462140992167102   56 / 383
0.0    0.0    300.0  0.0    10.0   0.0    9.0    1.0    0.0    0.0    25.0   1.0    0.0    0.0    7.0    0.0    1.0    0.0    5.0    1.0    3.0    0.0    4.0    0.0    0.0    0.0    0.18256130790190736  67 / 367
0.0    21.0   0.0    350.0  0.0    0.0    0.0    2.0    0.0    5.0    1.0    0.0    7.0    3.0    2.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.1315136476426799   53 / 403
0.0    6.0    0.0    0.0    321.0  4.0    17.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    1.0    1.0    4.0    10.0   2.0    0.0    0.0    0.0    3.0    0.0    11.0   0.1618798955613577   62 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    1.0    0.0    13.0   1.0    2.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    2.0    0.0    5.0    4.0    0.0    0.0    2.0    2.0    2.0    5.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    2.0    1.0    0.0    0.0    356.0  3.0    5.0    0.09644670050761421  38 / 394
1.0    0.0    0.0    1.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    11.0   1.0    8.0    1.0    0.0    358.0  0.0    0.089058524173028    35 / 393
0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    15.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    19.0   2.0    0.0    0.0    0.0    1.0    0.0    310.0  0.1553133514986376   57 / 367
398.0  470.0  340.0  429.0  408.0  369.0  343.0  338.0  348.0  369.0  397.0  370.0  417.0  381.0  399.0  386.0  336.0  417.0  376.0  367.0  393.0  355.0  399.0  423.0  412.0  363.0  0.15945216435069479  1,595 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840548
2    0.913226
3    0.942717
4    0.959012
5    0.970509
6    0.978307
7    0.982705
8    0.987404
9    0.990303
10   0.993002

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18221950933207628
RMSE: 0.42687177153341527
LogLoss: 0.5847381974336101
Mean Per-Class Error: 0.16486781675474138
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17    18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   1.0    1.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   84.0   0.0   0.0    2.0   0.0   1.0   3.0   1.0   0.0    1.0    0.0   0.0   0.0   1.0   1.0    1.0   6.0   2.0   0.0   0.0   2.0   0.0    1.0    0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    62.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   3.0   0.0    0.0   0.0   2.0   1.0   1.0   0.0   1.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
0.0   4.0    0.0   96.0   0.0   0.0   0.0   2.0   0.0   2.0    1.0    0.0   3.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    2.0    0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    77.0  3.0   6.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   4.0   1.0   0.0   0.0   0.0    1.0    0.0    4.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   0.0    3.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0    88.0   0.0    2.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    1.0   0.0   0.0   3.0   0.0   2.0   1.0    0.0    99.0   0.0   0.07476635514018691  8 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   5.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
90.0  115.0  71.0  117.0  95.0  88.0  88.0  85.0  85.0  106.0  103.0  98.0  98.0  97.0  83.0  110.0  87.0  98.0  93.0  88.0  99.0  79.0  102.0  104.0  116.0  95.0  0.163855421686747    408 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836145
2    0.914458
3    0.945783
4    0.958634
5    0.971084
6    0.977108
7    0.981526
8    0.985542
9    0.989558
10   0.992369
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:51  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:51  3 min 29.671 sec  27192 obs/sec     1         1             10007      0.587928         1.07328             0.993857       0.277417                         0.591688           1.08186               0.993762         0.28996
    2019-07-23 13:34:54  3 min 32.574 sec  31399 obs/sec     10        10            100070     0.422915         0.573119            0.996822       0.159452                         0.426872           0.584738              0.996753         0.163855
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.090372
C13         0.906671               0.906671             0.0819377
C8          0.812263               0.812263             0.0734059
C12         0.796358               0.796358             0.0719685
C9          0.778879               0.778879             0.0703888
C7          0.756094               0.756094             0.0683297
C6          0.704151               0.704151             0.0636355
C5          0.693789               0.693789             0.0626991
C11         0.691674               0.691674             0.062508
C10         0.638066               0.638066             0.0576633
C14         0.608591               0.608591             0.0549996
C3          0.607539               0.607539             0.0549045
C4          0.594978               0.594978             0.0537694
C16         0.585796               0.585796             0.0529396
C1          0.446322               0.446322             0.040335
C2          0.444201               0.444201             0.0401434
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_61

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0016774111373649703  0.000426005688495934   0.0         0.010031745832371541   0.4800381660461426  -0.016630204822074036  0.4982883930206299
    3        26       Softmax                 0.0   0.0   0.002131150372546332   0.0004781571915373206  0.0         -0.004714830528611786  0.408764123916626   -0.47866048336548445   0.1760278344154358


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1647574566510781
RMSE: 0.40590326021242806
LogLoss: 0.5628189773003383
Mean Per-Class Error: 0.16420970783642802
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  2.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    6.0    3.0    1.0    5.0    0.0    1.0    0.0    0.0    2.0    3.0    1.0    2.0    0.0    1.0    2.0    5.0    0.0    0.09113924050632911  36 / 395
0.0    326.0  0.0    6.0    2.0    3.0    1.0    3.0    2.0    0.0    9.0    0.0    0.0    0.0    0.0    3.0    0.0    19.0   3.0    0.0    0.0    0.0    1.0    2.0    3.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    307.0  0.0    8.0    1.0    12.0   1.0    0.0    0.0    10.0   8.0    0.0    0.0    6.0    0.0    0.0    0.0    2.0    6.0    2.0    0.0    5.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
2.0    18.0   0.0    349.0  0.0    2.0    0.0    2.0    2.0    1.0    1.0    0.0    6.0    3.0    1.0    1.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    8.0    0.0    1.0    0.1318407960199005   53 / 402
0.0    4.0    1.0    0.0    310.0  3.0    18.0   1.0    1.0    0.0    9.0    9.0    0.0    0.0    0.0    1.0    1.0    3.0    1.0    4.0    0.0    0.0    0.0    4.0    0.0    14.0   0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    5.0    0.0    0.0    2.0    0.0    0.0    5.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    1.0    0.0    5.0    3.0    2.0    0.0    3.0    2.0    0.0    10.0   2.0    0.0    0.0    2.0    0.0    4.0    1.0    1.0    1.0    1.0    0.0    0.0    344.0  6.0    6.0    0.12690355329949238  50 / 394
1.0    1.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    6.0    0.0    1.0    16.0   0.0    13.0   1.0    1.0    346.0  0.0    0.11959287531806616  47 / 393
0.0    1.0    0.0    0.0    11.0   1.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    24.0   4.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
392.0  507.0  344.0  423.0  379.0  383.0  376.0  287.0  347.0  362.0  399.0  377.0  427.0  380.0  404.0  375.0  345.0  415.0  324.0  395.0  402.0  365.0  405.0  420.0  401.0  369.0  0.16335099470158954  1,634 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836649
2    0.908727
3    0.940518
4    0.957813
5    0.969009
6    0.976007
7    0.980406
8    0.984605
9    0.987004
10   0.990003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16908180562517353
RMSE: 0.41119558074616214
LogLoss: 0.5848612112889876
Mean Per-Class Error: 0.16109046610907668
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   1.0    0.0   0.0   1.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   2.0    2.0   1.0   1.0   0.0   1.0   0.0    1.0    0.0   0.0   0.0    0.0   2.0    0.0   7.0    2.0   0.0   0.0    0.0   1.0   1.0   1.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    69.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0    2.0   0.0   0.0    4.0   0.0    0.0   0.0    1.0   2.0   0.0    0.0   2.0   0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   2.0    0.0   101.0  0.0   0.0   0.0   0.0   1.0   0.0    0.0    0.0   3.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.09821428571428571  11 / 112
0.0   1.0    0.0   0.0    73.0  1.0   5.0   0.0   0.0   0.0    3.0    3.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   2.0   0.0    0.0   0.0   1.0   0.0    6.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   0.0    4.0    2.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   83.0  3.0    2.0   0.17                 17 / 100
1.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   3.0   0.0    4.0   1.0   0.0   94.0   0.0   0.12149532710280374  13 / 107
0.0   1.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   0.0   0.0   0.0    74.0  0.14942528735632185  13 / 87
91.0  124.0  72.0  124.0  87.0  88.0  97.0  70.0  83.0  104.0  100.0  99.0  96.0  101.0  82.0  106.0  91.0  104.0  89.0  94.0  104.0  82.0  98.0  97.0  114.0  93.0  0.1602409638554217   399 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839759
2    0.907631
3    0.936546
4    0.955422
5    0.965462
6    0.973092
7    0.979116
8    0.984739
9    0.98755
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:02  2 min 40.585 sec  26973 obs/sec     1         1             10007      0.54925          0.987415            0.994639       0.264721                         0.548098           0.983723              0.994647         0.265863
    2019-07-23 13:34:05  2 min 43.848 sec  28078 obs/sec     10        10            100070     0.405903         0.562819            0.997072       0.163351                         0.411196           0.584861              0.996987         0.160241
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0841746
C15         0.993173               0.993173             0.0836
C12         0.908814               0.908814             0.0764991
C9          0.89059                0.89059              0.0749651
C8          0.881217               0.881217             0.0741761
C7          0.827749               0.827749             0.0696754
C11         0.791095               0.791095             0.0665902
C14         0.703086               0.703086             0.059182
C10         0.692495               0.692495             0.0582905
C6          0.667967               0.667967             0.0562259
C5          0.655914               0.655914             0.0552113
C16         0.643123               0.643123             0.0541346
C3          0.642454               0.642454             0.0540783
C4          0.569668               0.569668             0.0479516
C2          0.520117               0.520117             0.0437807
C1          0.492599               0.492599             0.0414644
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_32

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009725098976787194  0.00026368163526058197  0.0         -0.004735329122638632  0.23244035243988037  0.2537499981125333    0.19293081760406494
    3        26       Softmax                      0.0   0.0   0.006222707892412962   0.027140282094478607    0.0         -0.29101291417562325   0.7135262489318848   -0.49155504442264836  0.21036297082901


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17804198942374813
RMSE: 0.42195022149982114
LogLoss: 0.5812361464425756
Mean Per-Class Error: 0.17067654062222049
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    4.0    2.0    6.0    1.0    0.0    0.0    0.0    1.0    5.0    2.0    1.0    4.0    2.0    6.0    2.0    1.0    0.11139240506329114  44 / 395
0.0    322.0  0.0    7.0    3.0    0.0    0.0    4.0    1.0    0.0    8.0    0.0    0.0    0.0    3.0    2.0    1.0    6.0    19.0   0.0    0.0    3.0    0.0    3.0    0.0    0.0    0.15706806282722513  60 / 382
0.0    0.0    295.0  0.0    15.0   2.0    12.0   1.0    0.0    0.0    13.0   2.0    1.0    0.0    7.0    0.0    2.0    1.0    2.0    4.0    5.0    0.0    5.0    0.0    0.0    0.0    0.19618528610354224  72 / 367
1.0    14.0   0.0    351.0  0.0    2.0    0.0    2.0    0.0    6.0    2.0    0.0    7.0    2.0    2.0    2.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.12903225806451613  52 / 403
0.0    4.0    2.0    0.0    311.0  4.0    17.0   0.0    0.0    0.0    2.0    7.0    0.0    0.0    0.0    1.0    2.0    4.0    9.0    3.0    0.0    0.0    0.0    5.0    0.0    13.0   0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    16.0   0.0    3.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    3.0    0.0    4.0    4.0    1.0    0.0    2.0    3.0    2.0    8.0    6.0    0.0    0.0    2.0    1.0    0.0    0.0    6.0    1.0    1.0    0.0    0.0    345.0  1.0    4.0    0.12436548223350254  49 / 394
2.0    0.0    0.0    1.0    0.0    23.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    2.0    14.0   0.0    21.0   1.0    1.0    323.0  0.0    0.178117048346056    70 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    24.0   3.0    0.0    0.0    0.0    3.0    0.0    305.0  0.16893732970027248  62 / 367
402.0  427.0  334.0  427.0  411.0  444.0  355.0  316.0  340.0  379.0  403.0  385.0  430.0  367.0  400.0  361.0  309.0  412.0  400.0  370.0  407.0  388.0  400.0  426.0  360.0  350.0  0.17004898530440868  1,701 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.829951
2    0.907628
3    0.939018
4    0.958612
5    0.971209
6    0.977807
7    0.983105
8    0.988503
9    0.991203
10   0.994302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17998298583065167
RMSE: 0.42424401684720514
LogLoss: 0.5884046435054205
Mean Per-Class Error: 0.17406641670361817
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11     12    13    14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  -----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    2.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    1.0   1.0   3.0   2.0    0.0   0.12359550561797752  11 / 89
0.0   83.0   0.0   1.0    2.0   0.0    0.0   1.0   0.0   0.0    2.0    0.0    0.0   0.0   2.0   1.0    0.0   4.0    6.0    0.0   0.0    3.0   0.0   1.0   0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    61.0  0.0    3.0   0.0    5.0   0.0   0.0   0.0    3.0    0.0    0.0   0.0   3.0   0.0    1.0   0.0    1.0    2.0   1.0    0.0   2.0   0.0   0.0    0.0   0.25609756097560976  21 / 82
1.0   4.0    0.0   97.0   0.0   0.0    0.0   1.0   0.0   1.0    1.0    0.0    3.0   1.0   0.0   1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    72.0  3.0    5.0   0.0   0.0   0.0    1.0    2.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0    1.0   0.0    0.0   0.0   2.0   0.0    7.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---    ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    4.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   87.0  0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   1.0    0.0   2.0    2.0   1.0    0.0   1.0   0.0   0.0    4.0    3.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   83.0  0.0    1.0   0.17                 17 / 100
1.0   0.0    0.0   0.0    0.0   6.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0   1.0    1.0   0.0    0.0    3.0   0.0    9.0   1.0   0.0   85.0   0.0   0.205607476635514    22 / 107
0.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0   0.0   5.0    0.0    1.0    0.0   0.0   0.0   0.0    1.0   0.0    3.0    1.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
92.0  105.0  68.0  118.0  94.0  105.0  92.0  81.0  81.0  112.0  104.0  104.0  96.0  97.0  84.0  103.0  84.0  102.0  100.0  89.0  103.0  92.0  97.0  96.0  101.0  90.0  0.1742971887550201   434 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.825703
2    0.906827
3    0.938554
4    0.958634
5    0.969879
6    0.976305
7    0.983132
8    0.987952
9    0.98996
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:53  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:53  1 min 31.874 sec  57511 obs/sec     1         1             10007      0.603496         1.1447              0.993527       0.302409                         0.600454           1.13486               0.993576         0.298394
    2019-07-23 13:32:55  1 min 33.267 sec  65022 obs/sec     10        10            100070     0.42195          0.581236            0.996836       0.170049                         0.424244           0.588405              0.996793         0.174297
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0910668
C13         0.939261               0.939261             0.0855355
C9          0.81034                0.81034              0.0737951
C8          0.8043                 0.8043               0.073245
C7          0.796132               0.796132             0.0725012
C12         0.773688               0.773688             0.0704573
C11         0.711603               0.711603             0.0648034
C5          0.705785               0.705785             0.0642736
C3          0.628587               0.628587             0.0572434
C6          0.598737               0.598737             0.054525
C16         0.574754               0.574754             0.052341
C10         0.572732               0.572732             0.0521569
C4          0.560156               0.560156             0.0510116
C14         0.555351               0.555351             0.050574
C1          0.486899               0.486899             0.0443404
C2          0.462628               0.462628             0.04213
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_36

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009544881937415539  0.0002328318660147488  0.0         -0.01892063034263458  0.23654919862747192  0.24802847949890444  0.1989964246749878
    3        26       Softmax                      0.0   0.0   0.00603659936814438    0.014114711433649063   0.0         -0.31619107628828785  0.7261919975280762   -0.4922794912607295  0.2303035855293274


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1731586087447205
RMSE: 0.4161233095426409
LogLoss: 0.5737358400869303
Mean Per-Class Error: 0.1620148810480713
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  1.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    3.0    6.0    1.0    3.0    0.0    4.0    0.0    2.0    4.0    5.0    1.0    3.0    0.0    1.0    2.0    3.0    0.0    0.11392405063291139  45 / 395
0.0    334.0  0.0    4.0    1.0    1.0    1.0    4.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    17.0   11.0   0.0    0.0    1.0    0.0    1.0    3.0    0.0    0.1279373368146214   49 / 383
0.0    0.0    315.0  0.0    9.0    0.0    3.0    0.0    0.0    0.0    20.0   1.0    0.0    0.0    6.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.14402173913043478  53 / 368
0.0    16.0   0.0    347.0  0.0    0.0    0.0    3.0    0.0    3.0    3.0    1.0    7.0    4.0    1.0    2.0    0.0    9.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.13895781637717122  56 / 403
0.0    10.0   3.0    0.0    312.0  8.0    14.0   0.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    1.0    8.0    4.0    7.0    2.0    0.0    0.0    0.0    4.0    0.0    6.0    0.1875               72 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0    3.0    0.0    5.0    0.0    2.0    0.0    0.0    5.0    0.0    0.0    8.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
1.0    2.0    0.0    4.0    10.0   0.0    0.0    4.0    1.0    2.0    4.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    350.0  2.0    2.0    0.10941475826972011  43 / 393
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    0.0    3.0    13.0   3.0    10.0   1.0    0.0    349.0  0.0    0.11195928753180662  44 / 393
2.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    0.0    36.0   3.0    0.0    0.0    0.0    4.0    0.0    297.0  0.1907356948228883   70 / 367
388.0  466.0  372.0  424.0  403.0  353.0  307.0  336.0  352.0  368.0  408.0  356.0  405.0  399.0  386.0  420.0  360.0  420.0  423.0  366.0  387.0  355.0  414.0  410.0  389.0  336.0  0.1613515945216435   1,614 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838648
2    0.914326
3    0.941717
4    0.958213
5    0.968309
6    0.976407
7    0.981506
8    0.985604
9    0.988803
10   0.991203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17730568139829253
RMSE: 0.42107681175563744
LogLoss: 0.5886634391539219
Mean Per-Class Error: 0.16506419654868634
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.10112359550561797  9 / 89
0.0   85.0   0.0   1.0    1.0   1.0   1.0   2.0   1.0   0.0    1.0    0.0   0.0   0.0    0.0   1.0    0.0   5.0    4.0    0.0   0.0   1.0   0.0    1.0   1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    66.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0    3.0   0.0    1.0   0.0    3.0    0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.1951219512195122   16 / 82
0.0   2.0    0.0   96.0   0.0   0.0   0.0   3.0   0.0   1.0    1.0    1.0   3.0   1.0    0.0   0.0    0.0   2.0    1.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.14285714285714285  16 / 112
0.0   2.0    0.0   0.0    74.0  5.0   3.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0    0.0   0.0    3.0   1.0    3.0    1.0   0.0   0.0   0.0    1.0   0.0    3.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   2.0   0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    5.0   0.0   0.0   2.0   0.0   1.0    2.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0    84.0  0.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0    2.0   0.0   2.0   1.0    0.0   100.0  0.0   0.06542056074766354  7 / 107
2.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0    1.0   0.0   0.0   0.0    2.0   0.0    69.0  0.20689655172413793  18 / 87
92.0  116.0  77.0  120.0  93.0  81.0  77.0  89.0  81.0  107.0  106.0  93.0  92.0  101.0  79.0  121.0  95.0  101.0  109.0  85.0  96.0  79.0  101.0  96.0  119.0  84.0  0.16305220883534136  406 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836948
2    0.911647
3    0.938153
4    0.957028
5    0.966265
6    0.974699
7    0.979518
8    0.983936
9    0.987952
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:02  1 min 40.112 sec  64147 obs/sec     1         1             10007      0.594218         1.11945             0.993725       0.290813                         0.593089           1.11751               0.993732         0.289558
    2019-07-23 13:33:03  1 min 41.487 sec  66847 obs/sec     10        10            100070     0.416123         0.573736            0.996923       0.161352                         0.421077           0.588663              0.996841         0.163052
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0897741
C13         0.891019               0.891019             0.0799905
C12         0.855085               0.855085             0.0767646
C8          0.785279               0.785279             0.0704978
C7          0.7431                 0.7431               0.0667111
C9          0.741186               0.741186             0.0665393
C11         0.738217               0.738217             0.0662728
C5          0.681869               0.681869             0.0612142
C14         0.671168               0.671168             0.0602535
C6          0.670044               0.670044             0.0601526
C10         0.651086               0.651086             0.0584507
C3          0.587367               0.587367             0.0527303
C16         0.569684               0.569684             0.0511429
C4          0.550097               0.550097             0.0493845
C2          0.502051               0.502051             0.0450712
C1          0.501811               0.501811             0.0450497
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_56

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001530489878462049   0.000426997896283865   0.0         0.013471544649775069    0.4381800889968872  0.02244639562823675  0.44930291175842285
    3        26       Softmax                 0.0   0.0   0.0025550131436270582  0.0007237843237817287  0.0         -0.0026157831919573046  0.5699934959411621  -0.5262765207517991  0.20796823501586914


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17291428897952021
RMSE: 0.41582963937112544
LogLoss: 0.5886226811854082
Mean Per-Class Error: 0.16665172101103862
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    2.0    2.0    1.0    6.0    0.0    3.0    1.0    2.0    0.0    0.0    0.0    3.0    0.0    1.0    1.0    6.0    3.0    0.08607594936708861  34 / 395
0.0    318.0  0.0    7.0    5.0    5.0    2.0    6.0    4.0    1.0    0.0    0.0    0.0    0.0    3.0    7.0    1.0    13.0   6.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.16971279373368145  65 / 383
0.0    0.0    310.0  0.0    14.0   3.0    10.0   1.0    0.0    0.0    7.0    2.0    0.0    0.0    1.0    0.0    2.0    0.0    9.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.15760869565217392  58 / 368
1.0    13.0   0.0    347.0  0.0    1.0    0.0    6.0    0.0    1.0    2.0    0.0    5.0    6.0    6.0    4.0    0.0    5.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.13895781637717122  56 / 403
0.0    5.0    2.0    0.0    304.0  5.0    13.0   0.0    1.0    0.0    6.0    4.0    0.0    0.0    0.0    1.0    6.0    4.0    11.0   5.0    0.0    0.0    0.0    4.0    0.0    12.0   0.206266318537859    79 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    0.0    3.0    0.0    8.0    1.0    0.0    4.0    0.0    3.0    0.0    0.0    1.0    1.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    1.0    0.0    4.0    8.0    1.0    0.0    3.0    7.0    3.0    15.0   3.0    0.0    0.0    0.0    0.0    5.0    2.0    17.0   6.0    1.0    0.0    0.0    310.0  5.0    3.0    0.2131979695431472   84 / 394
1.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    1.0    12.0   0.0    11.0   1.0    1.0    359.0  0.0    0.08651399491094147  34 / 393
2.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    10.0   0.0    3.0    0.0    0.0    0.0    0.0    3.0    1.0    27.0   6.0    0.0    0.0    0.0    0.0    0.0    302.0  0.17486338797814208  64 / 366
395.0  478.0  345.0  429.0  396.0  399.0  362.0  303.0  341.0  369.0  388.0  371.0  406.0  387.0  381.0  398.0  351.0  413.0  409.0  371.0  401.0  374.0  397.0  369.0  428.0  342.0  0.16595021493551934  1,660 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83405
2    0.910827
3    0.939318
4    0.955213
5    0.96701
6    0.974308
7    0.979406
8    0.983405
9    0.986604
10   0.988503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17701076644926025
RMSE: 0.42072647462366836
LogLoss: 0.6025989147845927
Mean Per-Class Error: 0.16929220544660037
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   1.0    0.0   3.0    1.0   0.056179775280898875  5 / 89
0.0   86.0   0.0   0.0    2.0   1.0   2.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   3.0    0.0   3.0    2.0    0.0   0.0    1.0   0.0    2.0   0.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    70.0  0.0    0.0   1.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    3.0    0.0   1.0    0.0   1.0    0.0   0.0    0.0   0.14634146341463414   12 / 82
1.0   1.0    0.0   95.0   0.0   0.0   0.0   4.0   0.0   0.0    1.0   0.0   2.0   2.0    2.0   2.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.15178571428571427   17 / 112
0.0   0.0    0.0   0.0    73.0  4.0   6.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0    3.0   0.0    0.0   0.0    0.0   0.0    5.0   0.24742268041237114   24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   2.0    0.0   1.0    0.0    0.0   0.0    0.0   87.0   0.0   0.0    0.0   0.05434782608695652   5 / 92
0.0   1.0    0.0   2.0    3.0   0.0   0.0   2.0   2.0   1.0    6.0   2.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0    0.0   0.0    0.0   0.0    75.0  1.0    1.0   0.25                  25 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0    3.0   0.0    4.0   1.0    0.0   96.0   0.0   0.102803738317757     11 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0    2.0   0.0    0.0   0.0    0.0   0.0    74.0  0.14942528735632185   13 / 87
97.0  120.0  75.0  118.0  85.0  97.0  94.0  83.0  87.0  102.0  94.0  96.0  87.0  102.0  80.0  117.0  82.0  102.0  101.0  87.0  101.0  85.0  100.0  89.0  120.0  89.0  0.16907630522088354   421 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830924
2    0.906024
3    0.93253
4    0.953815
5    0.966265
6    0.975502
7    0.979518
8    0.983132
9    0.986747
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:54  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:54  2 min 32.618 sec  45076 obs/sec     1         1             10007      0.588248         1.11251             0.993849       0.290613                         0.584639           1.09694               0.99391          0.284337
    2019-07-23 13:33:56  2 min 34.564 sec  47091 obs/sec     10        10            100070     0.41583          0.588623            0.996927       0.16595                          0.420726           0.602599              0.996846         0.169076
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.088955
C13         0.947455               0.947455             0.0842809
C12         0.937645               0.937645             0.0834082
C9          0.860587               0.860587             0.0765535
C8          0.809498               0.809498             0.0720089
C7          0.801935               0.801935             0.0713361
C11         0.755756               0.755756             0.0672283
C10         0.71341                0.71341              0.0634614
C14         0.703359               0.703359             0.0625673
C6          0.656646               0.656646             0.058412
C16         0.643731               0.643731             0.0572631
C5          0.574552               0.574552             0.0511093
C3          0.544337               0.544337             0.0484215
C4          0.460585               0.460585             0.0409713
C1          0.450704               0.450704             0.0400924
C2          0.381436               0.381436             0.0339307
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_100

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0015221487463463745  0.00041419046465307474  0.0         -0.023559335553369642  0.42461228370666504  -0.12160924614998311  0.4254155158996582
    3        26       Softmax                 0.0   0.0   0.002633412793259665   0.0007932214066386223   0.0         0.03692799315887477    0.5661106109619141   -0.5424292037182941   0.19145053625106812


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17424658766934703
RMSE: 0.4174285419917366
LogLoss: 0.5905930150604297
Mean Per-Class Error: 0.1698865543737913
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    2.0    1.0    7.0    1.0    1.0    0.0    1.0    0.0    6.0    0.0    0.0759493670886076   30 / 395
0.0    323.0  0.0    5.0    1.0    0.0    5.0    10.0   2.0    0.0    0.0    1.0    0.0    0.0    0.0    5.0    1.0    14.0   11.0   0.0    0.0    0.0    1.0    1.0    1.0    2.0    0.1566579634464752   60 / 383
0.0    0.0    313.0  0.0    13.0   1.0    6.0    0.0    0.0    0.0    18.0   1.0    3.0    0.0    6.0    0.0    0.0    0.0    1.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    0.14945652173913043  55 / 368
4.0    23.0   0.0    314.0  0.0    0.0    1.0    8.0    1.0    4.0    3.0    0.0    7.0    6.0    3.0    9.0    0.0    8.0    5.0    0.0    1.0    0.0    0.0    2.0    0.0    4.0    0.22084367245657568  89 / 403
0.0    4.0    0.0    0.0    328.0  4.0    13.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    2.0    4.0    8.0    4.0    0.0    0.0    0.0    5.0    0.0    9.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    2.0    4.0    0.0    0.0    6.0    3.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    7.0    0.0    5.0    8.0    3.0    0.0    0.0    1.0    3.0    9.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    7.0    2.0    1.0    0.0    0.0    332.0  6.0    1.0    0.15736040609137056  62 / 394
2.0    1.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    6.0    0.0    3.0    5.0    3.0    7.0    1.0    0.0    355.0  0.0    0.09669211195928754  38 / 393
1.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    8.0    0.0    31.0   4.0    0.0    0.0    0.0    2.0    0.0    295.0  0.19618528610354224  72 / 367
416.0  504.0  346.0  383.0  432.0  367.0  354.0  316.0  329.0  353.0  373.0  342.0  431.0  373.0  387.0  413.0  378.0  435.0  362.0  368.0  405.0  347.0  405.0  407.0  417.0  360.0  0.16904928521443566  1,691 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830951
2    0.905528
3    0.938918
4    0.957313
5    0.96811
6    0.976407
7    0.980506
8    0.983905
9    0.986204
10   0.988004

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17936434211905766
RMSE: 0.42351427616912474
LogLoss: 0.603394943809409
Mean Per-Class Error: 0.17758714751275692
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13    14    15     16    17     18    19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    0.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   82.0   0.0   2.0    1.0    0.0   1.0   5.0   1.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    1.0   5.0    5.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    67.0  0.0    3.0    0.0   2.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0   2.0   0.0   0.0   1.0    0.0   0.0    0.0   0.18292682926829268  15 / 82
3.0   3.0    0.0   86.0   0.0    0.0   0.0   3.0   1.0   1.0    2.0    0.0   3.0   1.0   0.0   2.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.23214285714285715  26 / 112
0.0   1.0    0.0   0.0    79.0   3.0   5.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0   1.0   0.0   0.0   0.0    1.0   0.0    4.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    1.0   2.0    0.0   0.0   1.0   1.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   4.0    0.0   1.0    4.0    0.0   0.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0   0.0   0.0    1.0   1.0    1.0   0.0   0.0   0.0   0.0    80.0  2.0    1.0   0.2                  20 / 100
2.0   1.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0   0.0   2.0    1.0   0.0    0.0   1.0   0.0   2.0   1.0    0.0   95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0   0.0   0.0    1.0   0.0    4.0   1.0   0.0   0.0   0.0    0.0   0.0    72.0  0.1724137931034483   15 / 87
99.0  124.0  71.0  105.0  101.0  84.0  90.0  81.0  81.0  102.0  101.0  91.0  93.0  99.0  81.0  113.0  97.0  110.0  93.0  84.0  99.0  81.0  100.0  93.0  120.0  97.0  0.17751004016064256  442 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.82249
2    0.904016
3    0.934538
4    0.953414
5    0.965462
6    0.976707
7    0.982731
8    0.986747
9    0.98755
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:42  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:42  4 min 20.349 sec  43890 obs/sec     1         1             10007      0.590244         1.10382             0.993809       0.295211                         0.590304           1.10268               0.993791         0.298795
    2019-07-23 13:35:44  4 min 22.266 sec  47449 obs/sec     10        10            100070     0.417429         0.590593            0.996904       0.169049                         0.423514           0.603395              0.996804         0.17751
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0885225
C12         0.956899               0.956899             0.0847071
C15         0.954575               0.954575             0.0845014
C8          0.906572               0.906572             0.080252
C9          0.826443               0.826443             0.0731588
C7          0.788926               0.788926             0.0698377
C11         0.768244               0.768244             0.0680069
C10         0.72811                0.72811              0.0644541
C16         0.706439               0.706439             0.0625358
C14         0.663379               0.663379             0.0587239
C6          0.621965               0.621965             0.0550579
C5          0.570884               0.570884             0.050536
C3          0.504341               0.504341             0.0446455
C4          0.493178               0.493178             0.0436573
C2          0.405706               0.405706             0.0359141
C1          0.400903               0.400903             0.0354889
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_76

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0020943222168341435  0.0004837258020415902  0.0         -0.00883308433281016   0.42502641677856445  0.005776062421114251  0.49468564987182617
    3        26       Softmax                 0.0   0.0   0.002201229781313976   0.0006059401202946901  0.0         -0.004153675283593936  0.29110217094421387  -0.6291890911824027   0.27052319049835205


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17131526057682342
RMSE: 0.4139024771329877
LogLoss: 0.594961562369553
Mean Per-Class Error: 0.17353259306113106
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    1.0    4.0    0.0    2.0    0.0    0.0    2.0    3.0    1.0    2.0    0.0    2.0    2.0    5.0    3.0    0.08860759493670886  35 / 395
0.0    316.0  0.0    9.0    4.0    2.0    5.0    4.0    3.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    18.0   15.0   0.0    0.0    2.0    0.0    2.0    1.0    0.0    0.17493472584856398  67 / 383
0.0    0.0    303.0  1.0    11.0   1.0    8.0    1.0    0.0    0.0    20.0   1.0    0.0    0.0    4.0    0.0    3.0    0.0    4.0    3.0    4.0    0.0    4.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
1.0    12.0   0.0    353.0  0.0    2.0    0.0    2.0    1.0    2.0    1.0    0.0    5.0    3.0    3.0    2.0    0.0    3.0    0.0    1.0    3.0    0.0    0.0    6.0    0.0    3.0    0.12406947890818859  50 / 403
0.0    4.0    2.0    0.0    320.0  3.0    12.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    1.0    8.0    4.0    9.0    6.0    0.0    0.0    0.0    4.0    0.0    6.0    0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    2.0    7.0    0.0    0.0    0.0    0.0    10.0   0.0    3.0    0.0    0.0    2.0    0.0    0.0    2.0    3.0    345.0  0.0    0.0    0.0    0.08                 30 / 375
0.0    2.0    0.0    4.0    7.0    1.0    0.0    3.0    4.0    1.0    9.0    2.0    0.0    0.0    2.0    0.0    6.0    1.0    2.0    5.0    1.0    0.0    0.0    332.0  9.0    3.0    0.15736040609137056  62 / 394
0.0    0.0    0.0    1.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    6.0    5.0    37.0   1.0    0.0    329.0  0.0    0.1628498727735369   64 / 393
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    17.0   0.0    3.0    0.0    0.0    0.0    0.0    5.0    1.0    21.0   4.0    0.0    0.0    0.0    0.0    1.0    298.0  0.1880108991825613   69 / 367
405.0  446.0  356.0  443.0  400.0  394.0  351.0  294.0  331.0  371.0  375.0  360.0  408.0  358.0  372.0  365.0  367.0  456.0  369.0  381.0  425.0  392.0  420.0  419.0  402.0  343.0  0.1726482055383385   1,727 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827352
2    0.905228
3    0.936719
4    0.953414
5    0.96721
6    0.974108
7    0.979906
8    0.984505
9    0.987204
10   0.989903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17464362688493495
RMSE: 0.41790384885154497
LogLoss: 0.6079440479853899
Mean Per-Class Error: 0.1762381014919695
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   83.0   0.0   2.0    3.0   0.0   2.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   6.0    5.0   0.0   0.0    2.0   0.0    1.0   0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    66.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   2.0    0.0   0.0    0.0   0.1951219512195122   16 / 82
1.0   1.0    0.0   95.0   0.0   1.0   0.0   2.0   1.0   0.0    0.0   0.0   2.0   1.0   0.0   2.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    2.0   0.15178571428571427  17 / 112
0.0   1.0    0.0   0.0    79.0  2.0   4.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    2.0   1.0    1.0   3.0   0.0    0.0   0.0    1.0   0.0    1.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   2.0   0.0   0.0    4.0   2.0   0.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0   0.0    0.0   0.0    78.0  4.0    2.0   0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0   1.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0   1.0   0.0    11.0  1.0    0.0   90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   1.0   0.0    0.0   0.0    0.0   1.0    70.0  0.19540229885057472  17 / 87
95.0  109.0  75.0  123.0  98.0  95.0  86.0  73.0  81.0  103.0  93.0  97.0  94.0  98.0  76.0  102.0  92.0  116.0  98.0  89.0  103.0  92.0  103.0  99.0  117.0  83.0  0.17630522088353415  439 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.823695
2    0.904016
3    0.937751
4    0.953815
5    0.967068
6    0.971888
7    0.979116
8    0.984337
9    0.987149
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:34  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:35  3 min 13.352 sec  18810 obs/sec     1         1             10007      0.544857         0.983548            0.994724       0.26662                          0.54385            0.972239              0.99473          0.274297
    2019-07-23 13:34:40  3 min 18.223 sec  18985 obs/sec     10        10            100070     0.413902         0.594962            0.996956       0.172648                         0.417904           0.607944              0.996888         0.176305
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0891284
C13         0.942211               0.942211             0.0839777
C12         0.908764               0.908764             0.0809967
C9          0.852911               0.852911             0.0760186
C7          0.790979               0.790979             0.0704987
C11         0.763962               0.763962             0.0680907
C8          0.750362               0.750362             0.0668785
C10         0.65816                0.65816              0.0586607
C14         0.651596               0.651596             0.0580757
C6          0.617432               0.617432             0.0550307
C3          0.612165               0.612165             0.0545613
C16         0.610895               0.610895             0.054448
C5          0.596698               0.596698             0.0531827
C4          0.557384               0.557384             0.0496787
C2          0.454187               0.454187             0.040481
C1          0.452065               0.452065             0.0402918
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_102

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0019116709512161378  0.00047538510989397764  0.0         0.0015229658805111512  0.41944706439971924  0.02354303234145936  0.47946596145629883
    3        26       Softmax                 0.0   0.0   0.0021250984929723086  0.0005580454599112272   0.0         -0.007557776127441684  0.2920560836791992   -0.5900002435914528  0.22269821166992188


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17123963551788604
RMSE: 0.4138111109164253
LogLoss: 0.5999411114112579
Mean Per-Class Error: 0.1735093050571513
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    0.0    4.0    0.0    1.0    0.0    0.0    1.0    4.0    0.0    1.0    0.0    2.0    3.0    6.0    2.0    0.0759493670886076   30 / 395
0.0    325.0  0.0    9.0    3.0    0.0    1.0    9.0    3.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    0.0    19.0   3.0    0.0    0.0    1.0    0.0    3.0    2.0    1.0    0.1514360313315927   58 / 383
0.0    0.0    287.0  0.0    14.0   1.0    14.0   2.0    0.0    0.0    21.0   3.0    0.0    0.0    4.0    0.0    2.0    0.0    4.0    7.0    5.0    0.0    4.0    0.0    0.0    0.0    0.22010869565217392  81 / 368
2.0    16.0   0.0    343.0  0.0    1.0    0.0    5.0    2.0    7.0    0.0    0.0    3.0    6.0    4.0    2.0    0.0    1.0    0.0    1.0    2.0    0.0    0.0    4.0    0.0    4.0    0.1488833746898263   60 / 403
0.0    11.0   0.0    0.0    315.0  2.0    17.0   0.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    3.0    4.0    7.0    7.0    0.0    0.0    0.0    2.0    0.0    12.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    3.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    7.0    0.0    8.0    0.0    0.0    2.0    0.0    0.0    4.0    1.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    3.0    0.0    5.0    3.0    0.0    0.0    4.0    3.0    2.0    8.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    2.0    6.0    2.0    0.0    0.0    335.0  9.0    2.0    0.1475826972010178   58 / 393
1.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    2.0    17.0   0.0    13.0   1.0    1.0    345.0  0.0    0.11989795918367346  47 / 392
2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    18.0   3.0    0.0    0.0    0.0    0.0    0.0    311.0  0.15258855585831063  56 / 367
419.0  472.0  311.0  415.0  402.0  353.0  361.0  316.0  343.0  377.0  368.0  359.0  399.0  377.0  404.0  395.0  382.0  419.0  310.0  406.0  422.0  360.0  433.0  406.0  415.0  379.0  0.1725482355293412   1,726 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827452
2    0.902329
3    0.93312
4    0.951415
5    0.964811
6    0.972908
7    0.979006
8    0.982705
9    0.986404
10   0.989903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1755933550017431
RMSE: 0.41903860800854986
LogLoss: 0.6147208999908145
Mean Per-Class Error: 0.18432516451513
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0   0.06741573033707865  6 / 89
0.0   84.0   0.0   4.0    2.0   0.0   1.0   2.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0    6.0    1.0   0.0   0.0    1.0   0.0    1.0   1.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    59.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    2.0   0.0    1.0    0.0    2.0   2.0   1.0    0.0   2.0    0.0   0.0    0.0   0.2804878048780488   23 / 82
1.0   1.0    0.0   94.0   0.0   1.0   0.0   3.0   1.0   2.0    0.0   0.0   1.0   3.0    1.0   2.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.16071428571428573  18 / 112
0.0   2.0    0.0   0.0    78.0  1.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    1.0    2.0   3.0   0.0    0.0   0.0    0.0   0.0    4.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
1.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   1.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   2.0    2.0   0.0   0.0   2.0   0.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    1.0    1.0    0.0   1.0   1.0    0.0   0.0    80.0  4.0    1.0   0.2                  20 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    3.0    0.0    0.0   3.0   0.0    4.0   1.0    0.0   93.0   0.0   0.1308411214953271   14 / 107
2.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    72.0  0.1724137931034483   15 / 87
96.0  117.0  63.0  113.0  98.0  75.0  89.0  80.0  84.0  109.0  94.0  98.0  88.0  107.0  82.0  116.0  100.0  106.0  79.0  97.0  105.0  80.0  104.0  95.0  123.0  92.0  0.1823293172690763   454 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.817671
2    0.9
3    0.936145
4    0.951406
5    0.96506
6    0.973494
7    0.976707
8    0.981928
9    0.986345
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:48  4 min 26.411 sec  19776 obs/sec     1         1             10007      0.545711         0.984034            0.994707       0.264521                         0.545601           0.98408               0.994696         0.268273
    2019-07-23 13:35:53  4 min 31.216 sec  19192 obs/sec     10        10            100070     0.413811         0.599941            0.996957       0.172548                         0.419039           0.614721              0.996871         0.182329
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0875815
C13         0.989787               0.989787             0.086687
C9          0.903072               0.903072             0.0790924
C12         0.851227               0.851227             0.0745517
C7          0.831947               0.831947             0.0728632
C11         0.790404               0.790404             0.0692247
C8          0.781252               0.781252             0.0684232
C10         0.681273               0.681273             0.0596669
C14         0.678945               0.678945             0.0594631
C6          0.643165               0.643165             0.0563293
C5          0.639167               0.639167             0.0559792
C16         0.601553               0.601553             0.0526849
C3          0.586405               0.586405             0.0513582
C4          0.564002               0.564002             0.0493962
C1          0.453935               0.453935             0.0397563
C2          0.4218                 0.4218               0.0369419
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_69

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight              weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  -----------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0020140022536878632  0.00045075127854943275  0.0         0.008944274457782564     0.4214770793914795  0.07588305962895299  0.4812406301498413
    3        26       Softmax                 0.0   0.0   0.0022087277533710922  0.0005444593261927366   0.0         -0.00033487606313494704  0.2903362512588501  -0.5998226459990562  0.22029447555541992


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17287808428334328
RMSE: 0.4157861040046231
LogLoss: 0.601149602367167
Mean Per-Class Error: 0.17446947269717142
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    6.0    2.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    1.0    2.0    2.0    5.0    2.0    0.0810126582278481   32 / 395
0.0    333.0  0.0    6.0    4.0    0.0    1.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    19.0   6.0    0.0    0.0    2.0    0.0    2.0    1.0    1.0    0.13054830287206268  50 / 383
0.0    0.0    299.0  1.0    15.0   1.0    9.0    0.0    0.0    0.0    21.0   1.0    1.0    0.0    2.0    0.0    2.0    0.0    8.0    2.0    2.0    0.0    4.0    0.0    0.0    0.0    0.1875               69 / 368
1.0    12.0   0.0    360.0  0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    7.0    4.0    1.0    2.0    0.0    3.0    2.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.10669975186104218  43 / 403
0.0    9.0    1.0    0.0    312.0  4.0    10.0   0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    2.0    8.0    4.0    13.0   4.0    0.0    0.0    0.0    3.0    0.0    9.0    0.185378590078329    71 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    1.0    0.0    22.0   0.0    4.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    3.0    0.0    7.0    6.0    1.0    0.0    4.0    3.0    1.0    9.0    1.0    0.0    0.0    2.0    0.0    5.0    1.0    3.0    2.0    1.0    0.0    0.0    336.0  6.0    3.0    0.14720812182741116  58 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    2.0    23.0   3.0    9.0    1.0    1.0    338.0  0.0    0.13994910941475827  55 / 393
2.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    7.0    1.0    22.0   3.0    0.0    0.0    0.0    0.0    0.0    311.0  0.15027322404371585  55 / 366
403.0  513.0  347.0  461.0  394.0  375.0  323.0  292.0  341.0  354.0  382.0  357.0  464.0  401.0  369.0  371.0  378.0  409.0  370.0  397.0  401.0  372.0  378.0  400.0  390.0  361.0  0.17344796561031692  1,735 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826552
2    0.901929
3    0.93502
4    0.953314
5    0.96591
6    0.973508
7    0.979806
8    0.983605
9    0.987604
10   0.989903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1777586021517554
RMSE: 0.42161428124739253
LogLoss: 0.6178042440563459
Mean Per-Class Error: 0.18146481710874487
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0   1.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   87.0   0.0   1.0    3.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   7.0    2.0   0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    63.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0   4.0   0.0   0.0    0.0    2.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   2.0   0.0   0.0    0.0   0.23170731707317074  19 / 82
1.0   2.0    0.0   98.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   3.0    1.0    0.0   2.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.125                14 / 112
0.0   1.0    0.0   0.0    73.0  3.0   3.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0    3.0   1.0    4.0   2.0   0.0    0.0   0.0   1.0   0.0    4.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   6.0    0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   2.0    3.0   0.0   0.0   2.0   0.0   0.0   4.0   1.0   0.0    0.0    0.0   0.0    1.0   1.0    1.0   0.0   0.0    0.0   0.0   81.0  2.0    1.0   0.19                 19 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0    3.0   0.0    0.0   5.0   0.0    3.0   1.0   0.0   92.0   0.0   0.14018691588785046  15 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0   0.0   2.0   0.0    0.0    0.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   0.0   0.0   0.0    75.0  0.13793103448275862  12 / 87
97.0  125.0  73.0  124.0  91.0  90.0  83.0  76.0  83.0  99.0  95.0  94.0  105.0  105.0  74.0  105.0  98.0  103.0  93.0  93.0  100.0  85.0  99.0  94.0  112.0  94.0  0.18072289156626506  450 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.819277
2    0.901205
3    0.93494
4    0.952209
5    0.964659
6    0.972691
7    0.980723
8    0.984337
9    0.988353
10   0.990763
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:18  2 min 56.596 sec  19097 obs/sec     1         1             10007      0.544114         0.980486            0.994738       0.271019                         0.544494           0.979782              0.994717         0.276707
    2019-07-23 13:34:23  3 min  1.626 sec  18381 obs/sec     10        10            100070     0.415786         0.60115             0.996927       0.173448                         0.421614           0.617804              0.996833         0.180723
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0898204
C15         0.994699               0.994699             0.0893443
C12         0.866585               0.866585             0.077837
C9          0.857501               0.857501             0.0770211
C8          0.794236               0.794236             0.0713386
C7          0.783499               0.783499             0.0703742
C11         0.763997               0.763997             0.0686226
C14         0.665199               0.665199             0.0597485
C10         0.649629               0.649629             0.0583499
C6          0.622229               0.622229             0.0558889
C16         0.599892               0.599892             0.0538825
C3          0.57373                0.57373              0.0515327
C5          0.559801               0.559801             0.0502816
C4          0.551586               0.551586             0.0495437
C2          0.435794               0.435794             0.0391432
C1          0.414946               0.414946             0.0372706
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_2

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.002097221535166227  0.0005103910807520151  0.0         0.002340935488522433    0.41870594024658203  0.02063295773136809  0.4865967035293579
    3        26       Softmax                 0.0   0.0   0.002167215956100895  0.0005278440658003092  0.0         5.8285554938099544e-05  0.2897831201553345   -0.6205401752569091  0.25943946838378906


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1764108828986774
RMSE: 0.4200129556319393
LogLoss: 0.6161081958098225
Mean Per-Class Error: 0.18078796448124632
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    6.0    3.0    1.0    4.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    1.0    0.0    2.0    2.0    7.0    0.0    0.08354430379746836  33 / 395
0.0    319.0  0.0    3.0    4.0    0.0    3.0    3.0    4.0    0.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    22.0   14.0   0.0    0.0    2.0    0.0    2.0    2.0    1.0    0.1671018276762402   64 / 383
0.0    0.0    294.0  0.0    17.0   2.0    15.0   0.0    0.0    0.0    13.0   2.0    0.0    0.0    5.0    0.0    0.0    0.0    7.0    1.0    9.0    0.0    2.0    0.0    0.0    0.0    0.1989100817438692   73 / 367
1.0    25.0   0.0    331.0  0.0    0.0    1.0    3.0    1.0    5.0    0.0    1.0    7.0    5.0    4.0    2.0    0.0    10.0   0.0    0.0    1.0    0.0    0.0    6.0    0.0    0.0    0.17866004962779156  72 / 403
0.0    7.0    0.0    0.0    320.0  2.0    16.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    1.0    5.0    14.0   5.0    0.0    0.0    0.0    3.0    0.0    8.0    0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    11.0   0.0    3.0    0.0    0.0    3.0    0.0    0.0    5.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    2.0    0.0    3.0    10.0   2.0    0.0    2.0    3.0    3.0    5.0    4.0    0.0    0.0    0.0    0.0    7.0    3.0    1.0    2.0    1.0    0.0    0.0    338.0  5.0    3.0    0.14213197969543148  56 / 394
0.0    0.0    0.0    3.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    9.0    2.0    13.0   1.0    1.0    348.0  0.0    0.11450381679389313  45 / 393
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    17.0   0.0    3.0    0.0    0.0    0.0    0.0    4.0    1.0    24.0   4.0    0.0    0.0    0.0    0.0    0.0    297.0  0.1907356948228883   70 / 367
398.0  473.0  338.0  415.0  446.0  368.0  358.0  282.0  342.0  385.0  329.0  388.0  412.0  376.0  406.0  366.0  325.0  474.0  372.0  375.0  414.0  356.0  431.0  408.0  429.0  337.0  0.17984604618614417  1,799 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.820154
2    0.896731
3    0.93242
4    0.950315
5    0.964411
6    0.972608
7    0.978706
8    0.983405
9    0.987104
10   0.989103

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18116408873590795
RMSE: 0.42563374952640676
LogLoss: 0.6347161197261316
Mean Per-Class Error: 0.18562906288573996
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.06741573033707865  6 / 89
0.0   83.0   0.0   0.0    3.0    0.0   1.0   1.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0    0.0   7.0    4.0   0.0   0.0    2.0   0.0    1.0   1.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    61.0  0.0    3.0    0.0   6.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    3.0   1.0   2.0    0.0   1.0    0.0   0.0    0.0   0.25609756097560976  21 / 82
1.0   4.0    0.0   93.0   0.0    0.0   1.0   2.0   1.0   1.0    0.0   0.0    3.0   1.0    0.0   2.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    79.0   1.0   5.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    4.0   2.0   0.0    0.0   0.0    0.0   0.0    3.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   1.0    5.0    0.0   0.0   1.0   0.0   1.0    2.0   2.0    0.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0    83.0  1.0    1.0   0.17                 17 / 100
0.0   0.0    0.0   1.0    0.0    1.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    2.0   0.0    0.0   3.0   0.0    4.0   1.0    0.0   94.0   0.0   0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   5.0    0.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    70.0  0.19540229885057472  17 / 87
89.0  116.0  69.0  121.0  107.0  86.0  92.0  71.0  82.0  109.0  84.0  106.0  92.0  101.0  83.0  104.0  84.0  121.0  98.0  89.0  102.0  81.0  104.0  94.0  122.0  83.0  0.18514056224899597  461 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814859
2    0.89759
3    0.931727
4    0.949799
5    0.964257
6    0.971888
7    0.978313
8    0.982329
9    0.986345
10   0.988353
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:28  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:31  9.555 sec   13652 obs/sec     1         1             10007      0.548333         0.995429            0.994657       0.273318                         0.547156           0.989622              0.994665         0.280723
    2019-07-23 13:31:36  14.546 sec  17869 obs/sec     10        10            100070     0.420013         0.616108            0.996865       0.179846                         0.425634           0.634716              0.996772         0.185141
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0887808
C13         0.997066               0.997066             0.0885203
C9          0.869615               0.869615             0.0772052
C12         0.856374               0.856374             0.0760296
C8          0.795072               0.795072             0.0705871
C7          0.772836               0.772836             0.068613
C11         0.740634               0.740634             0.0657541
C10         0.681829               0.681829             0.0605334
C14         0.647083               0.647083             0.0574486
C6          0.634037               0.634037             0.0562904
C3          0.605454               0.605454             0.0537527
C5          0.603189               0.603189             0.0535516
C4          0.570416               0.570416             0.050642
C16         0.563604               0.563604             0.0500372
C2          0.468237               0.468237             0.0415705
C1          0.458247               0.458247             0.0406835
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_58

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009498439941353354  0.00023608055198565125  0.0         -0.010987479548710155  0.2389422059059143  0.11114097492143142  0.19418400526046753
    3        26       Softmax                      0.0   0.0   0.006450949651864973   0.018457762897014618    0.0         -0.3127824170284769    0.7369239330291748  -0.5937118181024547  0.36683642864227295


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2024235333990783
RMSE: 0.4499150290878026
LogLoss: 0.6447178803911702
Mean Per-Class Error: 0.17886440016317584
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    3.0    1.0    7.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    5.0    1.0    1.0    0.0    4.0    0.0    0.08860759493670886  35 / 395
0.0    313.0  0.0    8.0    2.0    0.0    1.0    9.0    2.0    0.0    3.0    1.0    0.0    0.0    1.0    4.0    7.0    19.0   7.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.1806282722513089   69 / 382
0.0    0.0    303.0  0.0    10.0   0.0    5.0    2.0    0.0    0.0    26.0   0.0    0.0    0.0    1.0    0.0    7.0    0.0    4.0    1.0    5.0    0.0    4.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
1.0    17.0   0.0    342.0  0.0    0.0    0.0    3.0    0.0    5.0    2.0    0.0    6.0    6.0    3.0    1.0    0.0    6.0    1.0    1.0    1.0    0.0    0.0    8.0    0.0    0.0    0.1513647642679901   61 / 403
0.0    10.0   0.0    0.0    302.0  2.0    15.0   0.0    1.0    0.0    9.0    3.0    0.0    0.0    0.0    0.0    7.0    4.0    11.0   5.0    0.0    0.0    0.0    2.0    0.0    12.0   0.21148825065274152  81 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    1.0    0.0    17.0   1.0    0.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    3.0    1.0    2.0    8.0    0.0    0.0    2.0    3.0    2.0    8.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    9.0    0.0    1.0    0.0    0.0    342.0  4.0    2.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    7.0    0.0    7.0    10.0   2.0    11.0   1.0    1.0    338.0  0.0    0.1377551020408163   54 / 392
2.0    0.0    0.0    1.0    13.0   0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    25.0   1.0    0.0    0.0    0.0    1.0    0.0    306.0  0.16621253405994552  61 / 367
400.0  461.0  353.0  418.0  397.0  346.0  307.0  334.0  341.0  367.0  420.0  355.0  432.0  392.0  386.0  383.0  378.0  417.0  439.0  352.0  420.0  360.0  410.0  406.0  382.0  347.0  0.17804658602419274  1,781 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.821953
2    0.897731
3    0.93262
4    0.952914
5    0.96501
6    0.974008
7    0.979406
8    0.984305
9    0.988403
10   0.990803

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20345570573719213
RMSE: 0.45106064529860296
LogLoss: 0.6468428253409165
Mean Per-Class Error: 0.17920337434818107
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16     17     18     19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  -----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0    0.0    1.0    0.0   1.0    1.0   1.0    0.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   82.0   0.0   2.0    2.0   0.0   1.0   2.0   1.0   0.0    1.0    0.0   0.0   0.0    1.0   1.0    2.0    6.0    3.0    0.0   0.0    0.0   1.0    1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    62.0  0.0    2.0   0.0   3.0   1.0   0.0   0.0    6.0    0.0   0.0   0.0    1.0   0.0    2.0    0.0    3.0    0.0   1.0    0.0   1.0    0.0   0.0    0.0   0.24390243902439024  20 / 82
1.0   3.0    0.0   98.0   0.0   0.0   0.0   1.0   0.0   1.0    1.0    0.0   3.0   1.0    1.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.125                14 / 112
0.0   2.0    0.0   0.0    73.0  1.0   5.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   0.0    2.0    1.0    3.0    2.0   0.0    0.0   0.0    1.0   0.0    5.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---    ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0    2.0    0.0    0.0   0.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    5.0   0.0   0.0   1.0   0.0   0.0    3.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    4.0    0.0   0.0    0.0   0.0    84.0  1.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   2.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   2.0    3.0    0.0    0.0    3.0   0.0    3.0   1.0    0.0   92.0   0.0   0.14018691588785046  15 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0    0.0    3.0    0.0   0.0    0.0   0.0    0.0   0.0    74.0  0.14942528735632185  13 / 87
94.0  106.0  71.0  125.0  93.0  80.0  82.0  86.0  79.0  104.0  107.0  94.0  96.0  101.0  77.0  108.0  103.0  103.0  114.0  83.0  105.0  78.0  103.0  95.0  113.0  90.0  0.17791164658634537  443 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822088
2    0.899197
3    0.933735
4    0.951807
5    0.963855
6    0.972289
7    0.977912
8    0.983534
9    0.986747
10   0.990362
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:58  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:58  2 min 36.857 sec  58864 obs/sec     1         1             10007      0.665775         1.3381              0.992121       0.357693                         0.66488            1.33583               0.992123         0.355422
    2019-07-23 13:34:00  2 min 37.971 sec  80248 obs/sec     10        10            100070     0.449915         0.644718            0.996402       0.178047                         0.451061           0.646843              0.996375         0.177912
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0953643
C13         0.921713               0.921713             0.0878985
C9          0.783054               0.783054             0.0746754
C7          0.757544               0.757544             0.0722426
C12         0.734753               0.734753             0.0700692
C8          0.722488               0.722488             0.0688995
C5          0.6896                 0.6896               0.0657632
C11         0.660983               0.660983             0.0630342
C6          0.607514               0.607514             0.0579351
C10         0.595276               0.595276             0.0567681
C14         0.58306                0.58306              0.0556031
C3          0.549037               0.549037             0.0523585
C4          0.534703               0.534703             0.0509915
C16         0.514936               0.514936             0.0491065
C2          0.44796                0.44796              0.0427193
C1          0.383488               0.383488             0.036571
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_52

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009371157311761635  0.0002211270621046424  0.0         -0.014859944028785321  0.2383398413658142  0.11425810052055213  0.17139804363250732
    3        26       Softmax                      0.0   0.0   0.007025262030590686   0.029464691877365112   0.0         -0.29448351938494327   0.7402024269104004  -0.6088452939538158  0.34404802322387695


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2022897320304903
RMSE: 0.4497663082429478
LogLoss: 0.6426322797192231
Mean Per-Class Error: 0.17912026760402167
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    3.0    0.0    5.0    0.0    1.0    0.0    0.0    1.0    7.0    1.0    1.0    0.0    3.0    0.0    8.0    0.0    0.09113924050632911  36 / 395
2.0    318.0  0.0    5.0    8.0    4.0    1.0    6.0    2.0    0.0    3.0    0.0    1.0    0.0    0.0    4.0    3.0    12.0   7.0    0.0    0.0    1.0    1.0    5.0    0.0    0.0    0.16971279373368145  65 / 383
0.0    1.0    307.0  0.0    14.0   1.0    3.0    1.0    0.0    0.0    19.0   2.0    1.0    0.0    4.0    0.0    3.0    0.0    6.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
2.0    13.0   0.0    342.0  0.0    0.0    1.0    4.0    0.0    5.0    0.0    1.0    6.0    2.0    3.0    3.0    0.0    5.0    5.0    0.0    1.0    0.0    0.0    8.0    0.0    1.0    0.14925373134328357  60 / 402
0.0    4.0    7.0    0.0    302.0  5.0    9.0    0.0    0.0    0.0    7.0    1.0    0.0    0.0    2.0    0.0    6.0    3.0    15.0   4.0    0.0    0.0    0.0    8.0    0.0    11.0   0.21354166666666666  82 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    14.0   1.0    2.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    340.0  0.0    1.0    0.0    0.09333333333333334  35 / 375
0.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    2.0    2.0    10.0   2.0    0.0    0.0    2.0    0.0    0.0    0.0    5.0    2.0    1.0    0.0    0.0    356.0  1.0    4.0    0.09644670050761421  38 / 394
0.0    0.0    0.0    2.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    14.0   0.0    2.0    17.0   2.0    41.0   0.0    0.0    304.0  0.0    0.22646310432569974  89 / 393
0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    28.0   2.0    0.0    0.0    0.0    0.0    0.0    306.0  0.16393442622950818  60 / 366
402.0  422.0  361.0  419.0  396.0  389.0  324.0  335.0  352.0  373.0  407.0  369.0  434.0  388.0  405.0  378.0  342.0  404.0  382.0  379.0  385.0  389.0  392.0  447.0  367.0  362.0  0.17844646606018194  1,785 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.821554
2    0.89873
3    0.928621
4    0.950615
5    0.964111
6    0.974008
7    0.980106
8    0.984505
9    0.987604
10   0.989603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20469219393896343
RMSE: 0.45242921428546523
LogLoss: 0.6470316663769959
Mean Per-Class Error: 0.18117005663648897
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11     12    13     14    15     16    17    18    19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0    4.0    0.0   0.0898876404494382   8 / 89
0.0   83.0   0.0   1.0    4.0   2.0   1.0   3.0   1.0   0.0    1.0    0.0    0.0   0.0    0.0   0.0    3.0   4.0   1.0   0.0   0.0   0.0   1.0   1.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    68.0  0.0    3.0   1.0   0.0   0.0   0.0   0.0    3.0    0.0    0.0   0.0    2.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
2.0   1.0    0.0   96.0   0.0   0.0   0.0   2.0   0.0   1.0    0.0    1.0    3.0   1.0    1.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   0.0    1.0   0.0    74.0  3.0   1.0   0.0   0.0   0.0    2.0    1.0    0.0   0.0    0.0   0.0    3.0   1.0   5.0   1.0   0.0   0.0   0.0   2.0    0.0    3.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0    5.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   85.0  0.0    1.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0   0.0    3.0    1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   90.0   0.0    2.0   0.1                  10 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   1.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   1.0    7.0   0.0   0.0   3.0   0.0   13.0  0.0   0.0    81.0   0.0   0.24299065420560748  26 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0    1.0    0.0   0.0    0.0   0.0    1.0   0.0   4.0   1.0   0.0   0.0   0.0   0.0    0.0    73.0  0.16091954022988506  14 / 87
97.0  100.0  79.0  116.0  96.0  96.0  76.0  90.0  89.0  103.0  101.0  100.0  98.0  102.0  84.0  104.0  97.0  99.0  94.0  87.0  94.0  88.0  96.0  109.0  103.0  92.0  0.18152610441767067  452 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818474
2    0.904016
3    0.929317
4    0.949799
5    0.963052
6    0.973494
7    0.980723
8    0.985542
9    0.98755
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:47  2 min 25.411 sec  64561 obs/sec     1         1             10007      0.650349         1.27937             0.992482       0.326802                         0.649861           1.27708               0.992475         0.324498
    2019-07-23 13:33:48  2 min 26.529 sec  80571 obs/sec     10        10            100070     0.449766         0.642632            0.996404       0.178446                         0.452429           0.647032              0.996353         0.181526
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0898282
C13         0.87803                0.87803              0.0788718
C9          0.859306               0.859306             0.0771899
C11         0.80927                0.80927              0.0726953
C8          0.808448               0.808448             0.0726214
C7          0.801623               0.801623             0.0720083
C12         0.760298               0.760298             0.0682961
C5          0.691037               0.691037             0.0620746
C6          0.683134               0.683134             0.0613646
C10         0.634936               0.634936             0.0570351
C14         0.616593               0.616593             0.0553874
C4          0.569485               0.569485             0.0511558
C16         0.562871               0.562871             0.0505617
C3          0.55215                0.55215              0.0495986
C2          0.479641               0.479641             0.0430852
C1          0.425544               0.425544             0.0382258
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_44

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009718050741014395  0.0002400398370809853  0.0         -0.011028301810320329  0.2383400797843933  0.13685645732789276  0.19382375478744507
    3        26       Softmax                      0.0   0.0   0.006659015085215987   0.020769678056240082   0.0         -0.27710962050734733   0.7187139987945557  -0.5836008955275201  0.38649725914001465


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20381368518681053
RMSE: 0.45145729054564016
LogLoss: 0.6558527128103778
Mean Per-Class Error: 0.18134079772617862
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    6.0    1.0    4.0    0.0    5.0    0.0    0.0    0.0    2.0    0.0    4.0    0.0    3.0    3.0    3.0    3.0    0.10152284263959391  40 / 394
1.0    329.0  0.0    7.0    2.0    0.0    7.0    2.0    2.0    0.0    1.0    0.0    1.0    0.0    1.0    1.0    0.0    14.0   11.0   0.0    0.0    2.0    1.0    1.0    0.0    0.0    0.1409921671018277   54 / 383
0.0    0.0    303.0  0.0    26.0   0.0    5.0    1.0    0.0    0.0    13.0   0.0    0.0    0.0    5.0    0.0    1.0    0.0    3.0    3.0    5.0    0.0    3.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
2.0    22.0   0.0    344.0  0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    4.0    3.0    3.0    0.0    1.0    6.0    1.0    0.0    2.0    0.0    0.0    6.0    0.0    1.0    0.14427860696517414  58 / 402
0.0    11.0   1.0    0.0    326.0  2.0    16.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    5.0    1.0    0.0    0.0    4.0    0.0    9.0    0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    20.0   0.0    1.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    6.0    0.0    4.0    11.0   0.0    1.0    3.0    1.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    8.0    3.0    2.0    0.0    0.0    336.0  3.0    2.0    0.14720812182741116  58 / 394
1.0    0.0    0.0    0.0    0.0    8.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    11.0   0.0    3.0    17.0   2.0    7.0    1.0    0.0    338.0  0.0    0.1377551020408163   54 / 392
1.0    0.0    0.0    0.0    13.0   0.0    1.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    28.0   3.0    0.0    0.0    0.0    2.0    0.0    305.0  0.16893732970027248  62 / 367
400.0  542.0  349.0  421.0  447.0  327.0  341.0  311.0  337.0  339.0  366.0  333.0  421.0  380.0  392.0  378.0  360.0  426.0  376.0  402.0  411.0  349.0  439.0  402.0  393.0  361.0  0.18044586624012796  1,805 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.819554
2    0.895731
3    0.926922
4    0.946616
5    0.958612
6    0.970609
7    0.977507
8    0.981805
9    0.985404
10   0.988603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.205361361633103
RMSE: 0.4531681383693066
LogLoss: 0.6560956426402058
Mean Per-Class Error: 0.1833003893221415
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12    13     14    15     16     17     18    19     20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0    1.0    0.0   1.0    1.0   2.0    0.0   0.0898876404494382   8 / 89
1.0   82.0   0.0   1.0    2.0    0.0   2.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    6.0    5.0   0.0    0.0    2.0   1.0    1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    62.0  0.0    5.0    0.0   1.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0    1.0    0.0    2.0   2.0    1.0    0.0   2.0    0.0   0.0    0.0   0.24390243902439024  20 / 82
2.0   4.0    0.0   98.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   2.0    0.0   0.0    1.0    0.0    0.0   0.0    1.0    0.0   0.0    2.0   0.0    0.0   0.125                14 / 112
0.0   1.0    0.0   0.0    80.0   1.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   3.0    0.0    0.0   0.0    1.0   0.0    4.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---    ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   5.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0    0.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   3.0    0.0   2.0    4.0    0.0   1.0   2.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    2.0    0.0    3.0   0.0    0.0    0.0   0.0    79.0  2.0    1.0   0.21                 21 / 100
1.0   0.0    0.0   0.0    0.0    2.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0    0.0    0.0   4.0    1.0    3.0   1.0    0.0   87.0   0.0   0.18691588785046728  20 / 107
0.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   4.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    4.0   1.0    0.0    0.0   0.0    0.0   0.0    74.0  0.14942528735632185  13 / 87
96.0  127.0  73.0  120.0  106.0  74.0  86.0  78.0  82.0  99.0  87.0  91.0  95.0  104.0  80.0  109.0  100.0  103.0  97.0  102.0  104.0  82.0  106.0  95.0  102.0  92.0  0.18152610441767067  452 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818474
2    0.893976
3    0.927711
4    0.947389
5    0.959839
6    0.971486
7    0.978313
8    0.981124
9    0.983936
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:19  1 min 57.055 sec  75240 obs/sec     1         1             10007      0.655419         1.28966             0.992363       0.339598                         0.654059           1.28187               0.992377         0.341365
    2019-07-23 13:33:20  1 min 58.253 sec  76858 obs/sec     10        10            100070     0.451457         0.655853            0.996377       0.180446                         0.453168           0.656096              0.996341         0.181526
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0899432
C15         0.947342               0.947342             0.085207
C8          0.850973               0.850973             0.0765393
C7          0.836559               0.836559             0.0752428
C9          0.802956               0.802956             0.0722205
C5          0.782157               0.782157             0.0703497
C12         0.772956               0.772956             0.0695222
C11         0.720689               0.720689             0.0648211
C10         0.680718               0.680718             0.0612259
C14         0.617284               0.617284             0.0555206
C3          0.608025               0.608025             0.0546877
C6          0.583817               0.583817             0.0525104
C4          0.572136               0.572136             0.0514597
C16         0.52473                0.52473              0.0471959
C2          0.430634               0.430634             0.0387326
C1          0.387147               0.387147             0.0348213
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_3

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009322890340115464  0.00021782174007967114  0.0         -0.017539629603401607  0.23451852798461914  0.12344920758286229  0.1730143427848816
    3        26       Softmax                      0.0   0.0   0.006084918591568567   0.011852629482746124    0.0         -0.29005809046430175   0.740602970123291    -0.5999413930391801  0.393337607383728


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2093763945996098
RMSE: 0.45757665434286504
LogLoss: 0.6655256826815514
Mean Per-Class Error: 0.185915622230797
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    2.0    3.0    0.0    5.0    0.0    0.0    0.0    8.0    0.0    1.0    1.0    2.0    3.0    5.0    1.0    0.09620253164556962  38 / 395
0.0    316.0  0.0    10.0   2.0    3.0    4.0    3.0    2.0    0.0    2.0    1.0    0.0    0.0    5.0    5.0    0.0    13.0   9.0    0.0    0.0    0.0    1.0    4.0    3.0    0.0    0.17493472584856398  67 / 383
0.0    0.0    309.0  1.0    14.0   0.0    7.0    1.0    0.0    0.0    14.0   0.0    2.0    0.0    2.0    0.0    3.0    0.0    8.0    2.0    2.0    0.0    3.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
2.0    12.0   0.0    340.0  0.0    4.0    1.0    5.0    0.0    2.0    0.0    0.0    6.0    3.0    4.0    0.0    0.0    9.0    6.0    0.0    0.0    0.0    0.0    3.0    0.0    6.0    0.15632754342431762  63 / 403
0.0    5.0    0.0    0.0    317.0  2.0    14.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    2.0    4.0    13.0   4.0    0.0    0.0    0.0    2.0    0.0    14.0   0.17232375979112272  66 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    13.0   0.0    0.0    0.0    0.0    9.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    3.0    0.0    6.0    8.0    0.0    1.0    3.0    2.0    1.0    7.0    1.0    0.0    0.0    2.0    1.0    4.0    0.0    7.0    1.0    1.0    0.0    0.0    333.0  7.0    6.0    0.1548223350253807   61 / 394
0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    5.0    8.0    0.0    3.0    14.0   1.0    15.0   2.0    0.0    331.0  0.0    0.15776081424936386  62 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    42.0   1.0    0.0    0.0    0.0    1.0    0.0    303.0  0.17438692098092642  64 / 367
394.0  476.0  367.0  424.0  415.0  371.0  333.0  330.0  336.0  339.0  375.0  346.0  430.0  367.0  420.0  404.0  332.0  428.0  443.0  363.0  376.0  352.0  413.0  407.0  387.0  375.0  0.1852444266719984   1,853 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814756
2    0.896131
3    0.926322
4    0.948315
5    0.960712
6    0.970409
7    0.977307
8    0.982905
9    0.986204
10   0.990203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21104115592469402
RMSE: 0.4593921591893946
LogLoss: 0.67237325330137
Mean Per-Class Error: 0.1886137048380165
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17     18     19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   1.0    1.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   80.0   0.0   3.0    1.0   1.0   1.0   1.0   1.0   0.0    2.0    0.0   0.0    0.0   3.0   2.0    0.0   4.0    3.0    0.0   0.0   0.0   1.0    2.0    1.0    0.0   0.24528301886792453  26 / 106
0.0   0.0    64.0  0.0    2.0   0.0   3.0   1.0   0.0   0.0    4.0    0.0   0.0    0.0   1.0   0.0    1.0   0.0    3.0    1.0   1.0   0.0   1.0    0.0    0.0    0.0   0.21951219512195122  18 / 82
2.0   1.0    0.0   94.0   0.0   1.0   1.0   1.0   0.0   1.0    0.0    0.0   3.0    1.0   1.0   0.0    0.0   1.0    2.0    0.0   0.0   0.0   0.0    2.0    0.0    1.0   0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    73.0  2.0   4.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0   0.0   1.0    1.0   1.0    5.0    2.0   0.0   0.0   0.0    2.0    0.0    5.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   3.0    0.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   1.0    0.0   3.0    4.0   0.0   1.0   2.0   0.0   0.0    3.0    1.0   0.0    0.0   0.0   0.0    1.0   0.0    2.0    0.0   0.0   0.0   0.0    79.0   1.0    2.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   1.0   3.0    3.0   0.0    0.0    4.0   0.0   3.0   2.0    0.0    90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    12.0   0.0   0.0   0.0   0.0    1.0    0.0    71.0  0.1839080459770115   16 / 87
93.0  112.0  75.0  119.0  91.0  87.0  85.0  77.0  79.0  100.0  102.0  91.0  100.0  95.0  85.0  114.0  88.0  108.0  120.0  87.0  97.0  77.0  105.0  101.0  109.0  93.0  0.18835341365461847  469 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.811647
2    0.895181
3    0.925301
4    0.945783
5    0.958635
6    0.971486
7    0.976707
8    0.983133
9    0.986345
10   0.990361
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:36  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:36  14.803 sec  69979 obs/sec     1         1             10007      0.64889          1.26876             0.992519       0.3321                           0.649266           1.27181               0.992489         0.330924
    2019-07-23 13:31:37  15.916 sec  81823 obs/sec     10        10            100070     0.457577         0.665526            0.99628        0.185244                         0.459392           0.672373              0.99624          0.188353
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0909324
C13         0.950258               0.950258             0.0864092
C8          0.849954               0.849954             0.0772883
C12         0.841107               0.841107             0.0764839
C9          0.804552               0.804552             0.0731598
C7          0.754                  0.754                0.068563
C5          0.730307               0.730307             0.0664086
C11         0.728983               0.728983             0.0662882
C14         0.618004               0.618004             0.0561966
C3          0.606006               0.606006             0.0551056
C6          0.603944               0.603944             0.054918
C10         0.583659               0.583659             0.0530735
C4          0.552296               0.552296             0.0502216
C16         0.536316               0.536316             0.0487685
C1          0.456121               0.456121             0.0414762
C2          0.381678               0.381678             0.0347069
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_103

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012626422563926099  0.00036180345341563225  0.0         -0.016006896419893835  0.2066773772239685  0.10056821151393801  0.16238552331924438
    3        26       Softmax                      0.0   0.0   0.006755986785282613   0.017845474183559418    0.0         -0.23610627467846476   0.5373260974884033  -0.9079577712768272  0.4151700735092163


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21701524913888087
RMSE: 0.46584895528366366
LogLoss: 0.6840284956048347
Mean Per-Class Error: 0.1887299537300054
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    6.0    3.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    2.0    2.0    0.0    7.0    0.0    0.09390862944162437  37 / 394
0.0    333.0  0.0    4.0    1.0    1.0    2.0    2.0    2.0    0.0    3.0    0.0    1.0    0.0    3.0    7.0    0.0    16.0   2.0    2.0    0.0    1.0    1.0    2.0    0.0    0.0    0.13054830287206268  50 / 383
0.0    0.0    299.0  0.0    7.0    0.0    11.0   1.0    0.0    0.0    29.0   0.0    0.0    0.0    7.0    0.0    1.0    0.0    2.0    3.0    1.0    0.0    6.0    0.0    0.0    0.0    0.18528610354223432  68 / 367
2.0    23.0   0.0    340.0  0.0    0.0    0.0    5.0    0.0    5.0    1.0    0.0    7.0    2.0    1.0    0.0    0.0    6.0    4.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.15632754342431762  63 / 403
0.0    8.0    0.0    0.0    310.0  4.0    15.0   0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    6.0    4.0    11.0   4.0    0.0    0.0    0.0    4.0    0.0    12.0   0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    3.0    0.0    21.0   0.0    1.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    2.0    0.0    5.0    4.0    0.0    0.0    1.0    3.0    2.0    10.0   1.0    0.0    0.0    2.0    0.0    8.0    1.0    8.0    2.0    3.0    0.0    0.0    336.0  3.0    3.0    0.14720812182741116  58 / 394
1.0    0.0    0.0    1.0    0.0    7.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    1.0    4.0    0.0    5.0    18.0   1.0    20.0   0.0    0.0    332.0  0.0    0.15521628498727735  61 / 393
0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    33.0   1.0    0.0    0.0    0.0    3.0    0.0    307.0  0.16348773841961853  60 / 367
398.0  481.0  356.0  423.0  378.0  373.0  339.0  272.0  342.0  358.0  447.0  334.0  455.0  378.0  427.0  377.0  322.0  425.0  409.0  382.0  380.0  371.0  403.0  415.0  394.0  364.0  0.18784364690592822  1,879 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.812156
2    0.892432
3    0.927522
4    0.947216
5    0.960412
6    0.970809
7    0.976807
8    0.982205
9    0.987404
10   0.989603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21840571842105003
RMSE: 0.4673389759275916
LogLoss: 0.6907377192777059
Mean Per-Class Error: 0.18910541315360196
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   1.0    0.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   86.0   0.0   0.0    1.0   1.0   1.0   1.0   1.0   0.0    1.0    0.0   0.0   0.0    2.0   2.0    0.0   7.0    0.0   0.0   0.0   1.0   1.0    1.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    59.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    7.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   1.0   0.0   2.0    0.0    0.0    0.0   0.2804878048780488   23 / 82
2.0   3.0    0.0   94.0   0.0   0.0   0.0   2.0   0.0   2.0    1.0    0.0   3.0   1.0    0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.16071428571428573  18 / 112
0.0   1.0    0.0   0.0    75.0  2.0   3.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    3.0   1.0    3.0   2.0   0.0   0.0   0.0    2.0    0.0    4.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   5.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    4.0    1.0   0.0   0.0    0.0   0.0    2.0   1.0    1.0   0.0   0.0   0.0   0.0    82.0   1.0    2.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   1.0    0.0   1.0    1.0   0.0    0.0   5.0   0.0   6.0   0.0    0.0    91.0   0.0   0.14953271028037382  16 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0    1.0    0.0    76.0  0.12643678160919541  11 / 87
93.0  116.0  73.0  114.0  90.0  86.0  86.0  70.0  84.0  100.0  114.0  90.0  98.0  102.0  86.0  110.0  87.0  112.0  96.0  89.0  94.0  84.0  104.0  101.0  112.0  99.0  0.18835341365461847  469 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.811647
2    0.892369
3    0.926506
4    0.948594
5    0.959438
6    0.968273
7    0.974297
8    0.980321
9    0.986747
10   0.987952
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:53  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:53  4 min 31.454 sec  56857 obs/sec     1         1             10007      0.657267         1.27788             0.99232        0.323303                         0.658189           1.27913               0.992281         0.327711
    2019-07-23 13:35:55  4 min 32.990 sec  60102 obs/sec     10        10            100070     0.465849         0.684028            0.996142       0.187844                         0.467339           0.690738              0.996108         0.188353
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0923212
C13         0.896095               0.896095             0.0827285
C9          0.802872               0.802872             0.074122
C8          0.794475               0.794475             0.0733469
C12         0.787234               0.787234             0.0726783
C7          0.744979               0.744979             0.0687773
C11         0.709918               0.709918             0.0655404
C10         0.65241                0.65241              0.0602312
C6          0.642148               0.642148             0.0592838
C5          0.63421                0.63421              0.058551
C14         0.617867               0.617867             0.0570422
C3          0.596853               0.596853             0.0551021
C16         0.55386                0.55386              0.051133
C4          0.550986               0.550986             0.0508676
C1          0.442665               0.442665             0.0408673
C2          0.405183               0.405183             0.037407
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_83

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.001264130669937913  0.0003570710541680455  0.0         -0.01013009412454835  0.20878243446350098  0.08283480282464556  0.15956902503967285
    3        26       Softmax                      0.0   0.0   0.006914788670288685  0.018163003027439117   0.0         -0.21308937184804877  0.5350515842437744   -0.8989744735464964  0.39731431007385254


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2185276612315564
RMSE: 0.4674694227771014
LogLoss: 0.6864779309425689
Mean Per-Class Error: 0.18662454794966443
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    1.0    6.0    0.0    1.0    0.0    0.0    0.0    7.0    0.0    3.0    0.0    3.0    1.0    5.0    0.0    0.08860759493670886  35 / 395
0.0    335.0  0.0    7.0    2.0    0.0    5.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    1.0    15.0   6.0    0.0    0.0    2.0    0.0    2.0    1.0    0.0    0.12532637075718014  48 / 383
0.0    0.0    294.0  0.0    18.0   1.0    19.0   0.0    0.0    0.0    19.0   0.0    1.0    0.0    5.0    0.0    2.0    0.0    3.0    2.0    1.0    0.0    3.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
2.0    18.0   0.0    342.0  0.0    0.0    0.0    4.0    0.0    5.0    0.0    0.0    6.0    4.0    1.0    0.0    0.0    10.0   1.0    0.0    0.0    0.0    0.0    7.0    0.0    3.0    0.1513647642679901   61 / 403
0.0    11.0   0.0    0.0    300.0  1.0    15.0   0.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    9.0    4.0    8.0    4.0    0.0    0.0    0.0    7.0    0.0    20.0   0.21875              84 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    1.0    0.0    12.0   1.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    3.0    0.0    4.0    5.0    0.0    0.0    1.0    1.0    1.0    9.0    2.0    0.0    0.0    2.0    0.0    5.0    0.0    3.0    3.0    5.0    0.0    0.0    340.0  6.0    3.0    0.13486005089058525  53 / 393
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    11.0   0.0    4.0    17.0   3.0    14.0   1.0    0.0    334.0  0.0    0.15012722646310434  59 / 393
3.0    1.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    28.0   2.0    0.0    0.0    0.0    2.0    0.0    307.0  0.16348773841961853  60 / 367
415.0  536.0  329.0  447.0  385.0  364.0  371.0  284.0  331.0  348.0  379.0  335.0  435.0  385.0  412.0  381.0  339.0  428.0  340.0  379.0  388.0  369.0  414.0  436.0  383.0  390.0  0.1856443067079876   1,857 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814356
2    0.892532
3    0.925622
4    0.945216
5    0.960612
6    0.970209
7    0.976107
8    0.981106
9    0.985504
10   0.988703

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22168150102677442
RMSE: 0.4708306500502855
LogLoss: 0.6962787923727022
Mean Per-Class Error: 0.18605545935757548
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17     18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0   0.0   1.0    0.0    2.0    0.0    0.0898876404494382   8 / 89
0.0   89.0   0.0   1.0    2.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   2.0   0.0    0.0   5.0    1.0   0.0   0.0   2.0   0.0    2.0    0.0    0.0    0.16037735849056603  17 / 106
0.0   0.0    62.0  0.0    4.0   0.0   5.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0   2.0   0.0    1.0   0.0    2.0   1.0   0.0   0.0   1.0    0.0    0.0    0.0    0.24390243902439024  20 / 82
2.0   4.0    0.0   94.0   0.0   0.0   0.0   2.0   0.0   3.0    0.0   0.0   2.0    2.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0    0.16071428571428573  18 / 112
0.0   1.0    0.0   0.0    72.0  1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    2.0   1.0   0.0   0.0   0.0    3.0    0.0    9.0    0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   87.0   0.0    0.0    0.0    0.05434782608695652  5 / 92
0.0   1.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   0.0    4.0   1.0   0.0    0.0   0.0   0.0    1.0   0.0    1.0   0.0   1.0   0.0   0.0    85.0   1.0    0.0    0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    3.0   0.0    0.0   4.0   1.0   4.0   1.0    0.0    90.0   0.0    0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0    1.0    0.0    75.0   0.13793103448275862  12 / 87
98.0  129.0  66.0  128.0  90.0  83.0  94.0  72.0  77.0  104.0  94.0  91.0  101.0  99.0  80.0  112.0  91.0  109.0  82.0  86.0  97.0  86.0  103.0  110.0  105.0  103.0  0.18514056224899597  461 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814859
2    0.892771
3    0.924096
4    0.944177
5    0.960241
6    0.970281
7    0.976707
8    0.981526
9    0.985944
10   0.987952
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:59  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:59  3 min 37.931 sec  57843 obs/sec     1         1             10007      0.66251          1.29592             0.9922         0.326402                         0.66311            1.29686               0.992165         0.321687
    2019-07-23 13:35:01  3 min 39.469 sec  60174 obs/sec     10        10            100070     0.467469         0.686478            0.996117       0.185644                         0.470831           0.696279              0.99605          0.185141
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0931811
C13         0.897087               0.897087             0.0835916
C9          0.853308               0.853308             0.0795122
C7          0.781604               0.781604             0.0728308
C12         0.756134               0.756134             0.0704574
C8          0.754286               0.754286             0.0702852
C11         0.721416               0.721416             0.0672224
C6          0.640917               0.640917             0.0597214
C5          0.623887               0.623887             0.0581345
C14         0.608298               0.608298             0.0566819
C10         0.607998               0.607998             0.056654
C3          0.569566               0.569566             0.0530728
C16         0.556394               0.556394             0.0518454
C4          0.555699               0.555699             0.0517807
C1          0.412697               0.412697             0.0384556
C2          0.392495               0.392495             0.0365731
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_20

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012724423297925114  0.0003562126075848937  0.0         -0.012861247180190105  0.20869100093841553  0.10399951433052125  0.13746148347854614
    3        26       Softmax                      0.0   0.0   0.006512595038307504   0.019845575094223022   0.0         -0.2018545920479959    0.5244419574737549   -0.877706502942025   0.4138631820678711


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.219866596907909
RMSE: 0.468899346243849
LogLoss: 0.6920699006542164
Mean Per-Class Error: 0.18668446352455115
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    6.0    4.0    1.0    4.0    2.0    1.0    0.0    0.0    2.0    6.0    0.0    4.0    0.0    1.0    3.0    4.0    0.0    0.10126582278481013  40 / 395
0.0    327.0  0.0    4.0    2.0    0.0    4.0    5.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    20.0   7.0    0.0    0.0    1.0    1.0    2.0    1.0    0.0    0.1462140992167102   56 / 383
0.0    0.0    305.0  1.0    17.0   0.0    9.0    0.0    0.0    0.0    17.0   0.0    1.0    0.0    4.0    0.0    3.0    0.0    5.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
4.0    22.0   0.0    336.0  0.0    0.0    1.0    4.0    0.0    3.0    0.0    0.0    6.0    3.0    1.0    2.0    0.0    6.0    4.0    0.0    0.0    0.0    0.0    6.0    0.0    5.0    0.1662531017369727   67 / 403
0.0    10.0   2.0    0.0    312.0  1.0    12.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    6.0    5.0    11.0   1.0    1.0    0.0    0.0    6.0    0.0    12.0   0.1875               72 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    16.0   0.0    0.0    1.0    0.0    14.0   4.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    3.0    0.0    7.0    8.0    0.0    0.0    1.0    2.0    2.0    7.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    9.0    3.0    3.0    0.0    0.0    334.0  5.0    1.0    0.15228426395939088  60 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    0.0    10.0   13.0   1.0    9.0    1.0    0.0    341.0  0.0    0.13010204081632654  51 / 392
0.0    0.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    32.0   1.0    0.0    0.0    0.0    2.0    0.0    299.0  0.18528610354223432  68 / 367
402.0  492.0  354.0  428.0  426.0  343.0  328.0  321.0  333.0  362.0  401.0  329.0  433.0  391.0  375.0  403.0  367.0  432.0  430.0  360.0  384.0  352.0  397.0  413.0  401.0  346.0  0.18594421673497952  1,860 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814056
2    0.892732
3    0.927322
4    0.946616
5    0.962111
6    0.971609
7    0.978506
8    0.981606
9    0.985404
10   0.988104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22154167298703645
RMSE: 0.470682135827393
LogLoss: 0.6963814140202179
Mean Per-Class Error: 0.18754050636041428
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.0    0.0   0.0    1.0    0.0   1.0   0.0   0.0   1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   1.0    1.0    0.0   0.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   2.0    0.0   8.0    2.0    0.0   0.0   1.0   1.0   2.0    0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    63.0  0.0    3.0    0.0   3.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    3.0    1.0   0.0   0.0   2.0   0.0    0.0    0.0   0.23170731707317074  19 / 82
3.0   4.0    0.0   95.0   0.0    0.0   1.0   2.0   0.0   1.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.15178571428571427  17 / 112
0.0   2.0    0.0   0.0    77.0   1.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0    0.0   0.0   0.0   0.0   2.0    0.0    6.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   1.0    0.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   1.0    0.0   2.0    4.0    0.0   0.0   1.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0    0.0   1.0   0.0   0.0   82.0   1.0    0.0   0.18                 18 / 100
0.0   0.0    0.0   1.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    1.0    2.0   1.0   1.0   1.0   0.0    96.0   0.0   0.102803738317757    11 / 107
0.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   1.0    0.0    70.0  0.19540229885057472  17 / 87
97.0  119.0  74.0  118.0  100.0  79.0  80.0  85.0  79.0  105.0  98.0  87.0  97.0  104.0  77.0  116.0  97.0  111.0  109.0  80.0  94.0  79.0  98.0  105.0  113.0  89.0  0.1859437751004016   463 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814056
2    0.892369
3    0.926104
4    0.945381
5    0.961847
6    0.971084
7    0.977108
8    0.980723
9    0.983132
10   0.986345
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:21  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:21  59.198 sec        53228 obs/sec     1         1             10007      0.662989         1.28649             0.992189       0.312306                         0.66439            1.28528               0.992135         0.321687
    2019-07-23 13:32:22  1 min  0.801 sec  57644 obs/sec     10        10            100070     0.468899         0.69207             0.996093       0.185944                         0.470682           0.696381              0.996052         0.185944
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0874969
C13         0.997403               0.997403             0.0872697
C8          0.859636               0.859636             0.0752155
C9          0.824781               0.824781             0.0721658
C11         0.81465                0.81465              0.0712793
C12         0.809967               0.809967             0.0708696
C7          0.783968               0.783968             0.0685948
C14         0.686061               0.686061             0.0600282
C10         0.680247               0.680247             0.0595195
C6          0.678625               0.678625             0.0593776
C5          0.652075               0.652075             0.0570546
C3          0.604228               0.604228             0.0528681
C4          0.586477               0.586477             0.0513149
C16         0.581181               0.581181             0.0508516
C2          0.449965               0.449965             0.0393705
C1          0.419712               0.419712             0.0367235
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_98

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013593941015415112  0.00035172654315829277  0.0         0.004008216662668929  0.7495026588439941   -0.11043806692113534  0.7851717472076416
    3        26       Softmax                 0.0   0.0   0.001969566772109269   0.00037627085112035275  0.0         0.010121972048007312  0.49977195262908936  -0.45040251198938935  0.258719801902771


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2149521625351881
RMSE: 0.4636293374401453
LogLoss: 0.7162371320855999
Mean Per-Class Error: 0.2057779314272946
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    7.0    1.0    1.0    7.0    0.0    1.0    0.0    1.0    0.0    1.0    0.0    2.0    1.0    4.0    3.0    4.0    1.0    0.08860759493670886  35 / 395
0.0    316.0  0.0    7.0    1.0    1.0    5.0    1.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    30.0   3.0    2.0    1.0    6.0    1.0    2.0    1.0    0.0    0.17493472584856398  67 / 383
0.0    0.0    296.0  0.0    8.0    1.0    21.0   0.0    0.0    0.0    15.0   2.0    1.0    1.0    3.0    1.0    3.0    0.0    7.0    2.0    2.0    0.0    4.0    0.0    0.0    1.0    0.1956521739130435   72 / 368
5.0    20.0   0.0    317.0  0.0    6.0    0.0    8.0    1.0    6.0    0.0    0.0    5.0    1.0    3.0    5.0    0.0    13.0   1.0    0.0    1.0    0.0    0.0    6.0    0.0    3.0    0.20947630922693267  84 / 401
0.0    5.0    1.0    0.0    282.0  2.0    19.0   0.0    2.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    8.0    6.0    14.0   7.0    1.0    0.0    0.0    12.0   0.0    17.0   0.26370757180156656  101 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    1.0    0.0    3.0    11.0   0.0    0.0    1.0    0.0    24.0   5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    329.0  0.0    0.0    0.0    0.125                47 / 376
1.0    2.0    0.0    1.0    1.0    5.0    1.0    1.0    2.0    1.0    10.0   0.0    0.0    1.0    2.0    0.0    8.0    7.0    8.0    2.0    1.0    1.0    0.0    334.0  1.0    4.0    0.15228426395939088  60 / 394
0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    0.0    5.0    10.0   7.0    12.0   1.0    2.0    345.0  0.0    0.12213740458015267  48 / 393
3.0    0.0    0.0    2.0    18.0   1.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    34.0   6.0    0.0    0.0    0.0    1.0    1.0    295.0  0.19618528610354224  72 / 367
417.0  468.0  339.0  429.0  339.0  380.0  366.0  304.0  339.0  353.0  381.0  319.0  483.0  348.0  372.0  394.0  361.0  485.0  361.0  390.0  400.0  354.0  407.0  420.0  420.0  374.0  0.20483854843546936  2,049 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.795161
2    0.880036
3    0.916125
4    0.937619
5    0.950415
6    0.960912
7    0.969109
8    0.974708
9    0.980306
10   0.985004

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21621365900663872
RMSE: 0.4649878052235765
LogLoss: 0.7202218123087694
Mean Per-Class Error: 0.20609711615858173
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    1.0    3.0    1.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   3.0    1.0   0.0   2.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   8.0    0.0   0.0   1.0   3.0   1.0    1.0    0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    63.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   1.0    1.0   0.0    2.0   1.0   0.0   0.0   2.0    0.0    0.0    0.0   0.23170731707317074  19 / 82
3.0   4.0    0.0   88.0   0.0   1.0   0.0   4.0   1.0   1.0   0.0   0.0   2.0    0.0   0.0   3.0    0.0   2.0    0.0   0.0   1.0   0.0   0.0    1.0    0.0    1.0   0.21428571428571427  24 / 112
0.0   1.0    0.0   0.0    68.0  2.0   4.0   0.0   0.0   0.0   5.0   0.0   0.0    0.0   0.0   0.0    1.0   1.0    3.0   2.0   0.0   0.0   0.0    4.0    0.0    6.0   0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   2.0   0.0   0.0   0.0   0.0   5.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   83.0   0.0    0.0    0.0   0.09782608695652174  9 / 92
1.0   1.0    0.0   0.0    0.0   1.0   0.0   1.0   1.0   0.0   4.0   0.0   0.0    0.0   0.0   0.0    2.0   3.0    1.0   0.0   0.0   0.0   0.0    83.0   0.0    2.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    2.0   0.0    0.0   1.0   3.0   3.0   1.0    0.0    96.0   0.0   0.102803738317757    11 / 107
0.0   0.0    0.0   1.0    5.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    7.0   2.0   0.0   0.0   0.0    0.0    0.0    70.0  0.19540229885057472  17 / 87
96.0  116.0  69.0  121.0  81.0  90.0  87.0  77.0  82.0  99.0  99.0  84.0  106.0  90.0  68.0  111.0  98.0  129.0  94.0  94.0  99.0  83.0  103.0  107.0  117.0  90.0  0.20522088353413653  511 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.794779
2    0.878313
3    0.916064
4    0.939357
5    0.953012
6    0.965462
7    0.973092
8    0.97751
9    0.983936
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:38  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:39  4 min 16.974 sec  55594 obs/sec     1         1             10007      0.606671         1.15927             0.993459       0.310107                         0.605689           1.14826               0.993463         0.310843
    2019-07-23 13:35:40  4 min 18.795 sec  50822 obs/sec     10        10            100070     0.463629         0.716237            0.99618        0.204839                         0.464988           0.720222              0.996147         0.205221
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0948039
C13         0.896018               0.896018             0.0849461
C9          0.82713                0.82713              0.0784152
C12         0.81752                0.81752              0.0775041
C8          0.747176               0.747176             0.0708352
C11         0.725235               0.725235             0.0687551
C10         0.693681               0.693681             0.0657637
C7          0.664425               0.664425             0.0629901
C16         0.628514               0.628514             0.0595856
C14         0.587477               0.587477             0.0556952
C6          0.574037               0.574037             0.0544209
C3          0.57059                0.57059              0.0540942
C5          0.531116               0.531116             0.0503519
C4          0.463104               0.463104             0.0439041
C2          0.418241               0.418241             0.0396509
C1          0.403821               0.403821             0.0382838
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_94

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.000787984533872077   0.00019511301070451736  0.0         -0.019477981255578314  0.2936950922012329  0.23353823692473621   0.24309992790222168
    3        26       Softmax                      0.0   0.0   0.0044336848892411445  0.010270074009895325    0.0         -0.36579809800966684   0.8634588718414307  -0.44703724312720106  0.33383309841156006


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22123697430070477
RMSE: 0.4703583466897391
LogLoss: 0.7207828760177796
Mean Per-Class Error: 0.19888322831775312
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    3.0    1.0    6.0    0.0    7.0    0.0    0.0    0.0    5.0    0.0    3.0    3.0    2.0    1.0    5.0    0.0    0.10379746835443038  41 / 395
0.0    329.0  0.0    5.0    1.0    1.0    2.0    10.0   1.0    1.0    5.0    0.0    0.0    0.0    2.0    2.0    0.0    8.0    10.0   0.0    0.0    2.0    1.0    3.0    0.0    0.0    0.1409921671018277   54 / 383
0.0    1.0    288.0  0.0    5.0    0.0    15.0   3.0    0.0    0.0    29.0   1.0    1.0    0.0    2.0    0.0    1.0    0.0    7.0    3.0    7.0    0.0    4.0    0.0    0.0    0.0    0.21525885558583105  79 / 367
2.0    21.0   0.0    329.0  0.0    0.0    1.0    5.0    0.0    5.0    2.0    0.0    7.0    6.0    2.0    1.0    0.0    7.0    7.0    0.0    1.0    0.0    0.0    4.0    0.0    3.0    0.18362282878411912  74 / 403
0.0    9.0    2.0    0.0    284.0  6.0    11.0   0.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    12.0   3.0    16.0   4.0    0.0    0.0    0.0    8.0    0.0    24.0   0.2604166666666667   100 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    1.0    0.0    3.0    6.0    0.0    0.0    0.0    0.0    13.0   3.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    4.0    0.0    3.0    3.0    0.0    0.0    0.0    1.0    1.0    9.0    2.0    1.0    0.0    2.0    1.0    9.0    1.0    9.0    4.0    3.0    0.0    0.0    323.0  7.0    11.0   0.1802030456852792   71 / 394
1.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    4.0    1.0    1.0    11.0   0.0    4.0    10.0   1.0    14.0   0.0    0.0    338.0  0.0    0.13994910941475827  55 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    27.0   3.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
395.0  507.0  316.0  402.0  345.0  375.0  389.0  334.0  342.0  342.0  410.0  350.0  437.0  385.0  389.0  389.0  371.0  375.0  387.0  352.0  396.0  366.0  449.0  380.0  405.0  415.0  0.1981405578326502   1,982 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.801859
2    0.883935
3    0.918624
4    0.938418
5    0.955813
6    0.96621
7    0.974808
8    0.979506
9    0.983505
10   0.986604

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22259210187826567
RMSE: 0.4717966742975894
LogLoss: 0.7211372599309348
Mean Per-Class Error: 0.20254556616941802
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13     14    15     16    17    18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   2.0   1.0    0.0   2.0    0.0    0.07865168539325842  7 / 89
0.0   84.0   0.0   1.0    1.0   0.0   1.0   5.0   0.0   0.0   1.0    0.0   0.0    0.0    1.0   1.0    0.0   3.0   4.0   0.0   0.0   1.0   1.0    2.0   0.0    0.0    0.20754716981132076  22 / 106
0.0   0.0    59.0  0.0    1.0   0.0   5.0   2.0   0.0   0.0   7.0    0.0   0.0    0.0    1.0   0.0    0.0   0.0   3.0   1.0   1.0   0.0   2.0    0.0   0.0    0.0    0.2804878048780488   23 / 82
2.0   5.0    0.0   93.0   0.0   0.0   0.0   2.0   0.0   2.0   1.0    0.0   3.0    2.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    64.0  2.0   4.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0    0.0   0.0    4.0   1.0   5.0   1.0   0.0   0.0   0.0    1.0   0.0    11.0   0.3402061855670103   33 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0    0.0   4.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   1.0    0.0   1.0    1.0   0.0   0.0   0.0   0.0   0.0   4.0    2.0   1.0    0.0    0.0   0.0    2.0   1.0   2.0   0.0   1.0   0.0   0.0    80.0  2.0    2.0    0.2                  20 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    3.0    1.0   0.0    4.0   0.0   0.0   2.0   0.0   4.0   0.0    0.0   91.0   0.0    0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   4.0   1.0   0.0   0.0   0.0    0.0   0.0    74.0   0.14942528735632185  13 / 87
97.0  129.0  63.0  113.0  77.0  85.0  98.0  91.0  82.0  98.0  109.0  96.0  100.0  100.0  73.0  110.0  99.0  94.0  90.0  83.0  99.0  81.0  110.0  92.0  112.0  109.0  0.20240963855421687  504 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.79759
2    0.884739
3    0.920482
4    0.937751
5    0.957028
6    0.969076
7    0.977912
8    0.981526
9    0.984739
10   0.985944
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:24  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:24  4 min  2.091 sec  86267 obs/sec     1         1             10007      0.682238         1.4159              0.991729       0.373888                         0.680152           1.39879               0.991757         0.371084
    2019-07-23 13:35:24  4 min  2.875 sec  113586 obs/sec    10        10            100070     0.470358         0.720783            0.996069       0.198141                         0.471797           0.721137              0.996034         0.20241
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0943067
C13         0.924056               0.924056             0.0871447
C9          0.862914               0.862914             0.0813786
C8          0.815278               0.815278             0.0768861
C12         0.771125               0.771125             0.0727222
C7          0.664699               0.664699             0.0626856
C11         0.642701               0.642701             0.060611
C3          0.613371               0.613371             0.0578449
C6          0.588929               0.588929             0.0555399
C5          0.581597               0.581597             0.0548485
C4          0.579507               0.579507             0.0546514
C16         0.548021               0.548021             0.051682
C10         0.544074               0.544074             0.0513098
C14         0.533303               0.533303             0.0502941
C2          0.490653               0.490653             0.0462718
C1          0.443477               0.443477             0.0418228
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_34

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013645710670004974  0.00039042450953274965  0.0         0.0015125387568346582   0.7290554046630859  -0.03641812593911013  0.7583911418914795
    3        26       Softmax                 0.0   0.0   0.0019615354797049523  0.0003924460615962744   0.0         -9.123531341314307e-05  0.5026171207427979  -0.46186031450549536  0.2181447148323059


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21592990391236935
RMSE: 0.4646825840424508
LogLoss: 0.7178289920395194
Mean Per-Class Error: 0.2148112183263856
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    6.0    1.0    4.0    1.0    3.0    0.0    2.0    2.0    2.0    0.0    0.0    0.0    3.0    2.0    5.0    0.0    0.09367088607594937  37 / 395
0.0    314.0  0.0    12.0   1.0    1.0    1.0    6.0    1.0    0.0    2.0    0.0    3.0    0.0    1.0    3.0    8.0    23.0   5.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.1801566579634465   69 / 383
0.0    0.0    307.0  0.0    9.0    2.0    13.0   0.0    0.0    0.0    14.0   2.0    0.0    0.0    10.0   1.0    2.0    0.0    2.0    1.0    2.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
6.0    4.0    0.0    335.0  0.0    3.0    0.0    11.0   0.0    4.0    0.0    2.0    6.0    4.0    3.0    5.0    1.0    6.0    5.0    0.0    1.0    0.0    0.0    6.0    0.0    1.0    0.1687344913151365   68 / 403
0.0    4.0    1.0    1.0    302.0  2.0    11.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    12.0   3.0    16.0   5.0    0.0    0.0    0.0    8.0    4.0    12.0   0.21354166666666666  82 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    22.0   3.0    3.0    0.0    0.0    1.0    0.0    0.0    1.0    3.0    331.0  0.0    0.0    0.0    0.1196808510638298   45 / 376
0.0    3.0    0.0    11.0   14.0   1.0    0.0    1.0    3.0    0.0    5.0    4.0    0.0    0.0    2.0    0.0    4.0    2.0    8.0    6.0    4.0    0.0    0.0    314.0  5.0    5.0    0.1989795918367347   78 / 392
0.0    0.0    0.0    3.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    5.0    0.0    2.0    22.0   2.0    28.0   2.0    0.0    313.0  0.0    0.2035623409669211   80 / 393
4.0    1.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    11.0   0.0    3.0    0.0    0.0    0.0    0.0    6.0    2.0    27.0   4.0    0.0    0.0    0.0    2.0    0.0    292.0  0.20435967302452315  75 / 367
422.0  465.0  376.0  461.0  426.0  349.0  302.0  256.0  329.0  351.0  382.0  356.0  484.0  365.0  436.0  404.0  421.0  417.0  306.0  401.0  376.0  373.0  413.0  383.0  377.0  372.0  0.21363590922723183  2,137 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.786364
2    0.878636
3    0.919124
4    0.940618
5    0.953614
6    0.962311
7    0.970709
8    0.976807
9    0.980606
10   0.985204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21816247451950652
RMSE: 0.46707865988450653
LogLoss: 0.7215662895478163
Mean Per-Class Error: 0.2144503302319492
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   1.0    2.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   83.0   0.0   1.0    1.0   0.0   1.0   2.0   0.0   0.0    1.0   0.0   0.0    0.0    1.0   0.0    6.0    8.0    0.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    66.0  0.0    1.0   0.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0    6.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.1951219512195122   16 / 82
3.0   0.0    0.0   93.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   3.0    1.0    1.0   2.0    0.0    1.0    0.0   0.0   1.0   0.0   0.0    2.0   0.0    1.0   0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    73.0  1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    2.0    1.0    4.0   3.0   0.0   0.0   0.0    1.0   0.0    8.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   6.0    1.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   1.0   83.0   0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0   1.0    0.0   2.0    5.0   0.0   0.0   0.0   0.0   0.0    3.0   3.0   0.0    0.0    0.0   0.0    0.0    1.0    4.0   1.0   1.0   0.0   0.0    77.0  1.0    1.0   0.23                 23 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    1.0   0.0    1.0    0.0    1.0   5.0   0.0   6.0   2.0    0.0   88.0   0.0   0.17757009345794392  19 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0    0.0    0.0   0.0    1.0    1.0    4.0   2.0   0.0   0.0   0.0    0.0   0.0    70.0  0.19540229885057472  17 / 87
99.0  114.0  79.0  125.0  99.0  83.0  80.0  67.0  74.0  102.0  97.0  97.0  108.0  100.0  93.0  111.0  106.0  107.0  75.0  92.0  94.0  86.0  102.0  93.0  111.0  96.0  0.21405622489959839  533 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785944
2    0.879116
3    0.921687
4    0.943373
5    0.958634
6    0.96506
7    0.972289
8    0.97751
9    0.980321
10   0.985542
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:58  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:58  1 min 36.194 sec  50035 obs/sec     1         1             10007      0.61067          1.16957             0.993372       0.325702                         0.609576           1.15322               0.993379         0.326908
    2019-07-23 13:33:00  1 min 38.038 sec  49761 obs/sec     10        10            100070     0.464683         0.717829            0.996162       0.213636                         0.467079           0.721566              0.996113         0.214056
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0899738
C13         0.903276               0.903276             0.0812712
C9          0.902324               0.902324             0.0811855
C12         0.857809               0.857809             0.0771803
C11         0.837399               0.837399             0.0753439
C8          0.783984               0.783984             0.070538
C7          0.736348               0.736348             0.066252
C10         0.692524               0.692524             0.062309
C14         0.661193               0.661193             0.05949
C6          0.642689               0.642689             0.0578251
C16         0.631382               0.631382             0.0568078
C5          0.614553               0.614553             0.0552936
C3          0.505916               0.505916             0.0455192
C1          0.472814               0.472814             0.0425409
C4          0.461673               0.461673             0.0415384
C2          0.410466               0.410466             0.0369312
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_87

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  ------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013089824866767685  0.00036924611777067184  0.0         -0.03382254445568833    0.7349233627319336  -0.055194167894790355  0.846233606338501
    3        26       Softmax                 0.0   0.0   0.0019551008610086194  0.000379956909455359    0.0         -0.0006823229348880816  0.503150463104248   -0.4520334466346233    0.17433267831802368


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21778439330281768
RMSE: 0.46667375467538097
LogLoss: 0.7308482615539613
Mean Per-Class Error: 0.21357627919887895
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    2.0    1.0    5.0    0.0    5.0    0.0    2.0    0.0    2.0    2.0    2.0    4.0    3.0    0.0    3.0    2.0    0.09113924050632911  36 / 395
1.0    317.0  0.0    6.0    1.0    4.0    1.0    13.0   1.0    0.0    0.0    1.0    1.0    0.0    1.0    3.0    0.0    18.0   7.0    0.0    1.0    0.0    1.0    3.0    1.0    2.0    0.17232375979112272  66 / 383
0.0    0.0    283.0  0.0    17.0   3.0    22.0   0.0    0.0    0.0    19.0   0.0    1.0    0.0    4.0    0.0    2.0    0.0    7.0    1.0    5.0    0.0    3.0    1.0    0.0    0.0    0.23097826086956522  85 / 368
3.0    12.0   0.0    305.0  0.0    7.0    0.0    17.0   0.0    9.0    0.0    0.0    2.0    6.0    14.0   2.0    1.0    13.0   0.0    0.0    4.0    0.0    0.0    8.0    0.0    0.0    0.24317617866004962  98 / 403
0.0    14.0   3.0    0.0    283.0  4.0    17.0   0.0    0.0    0.0    1.0    2.0    0.0    0.0    1.0    0.0    6.0    6.0    15.0   4.0    0.0    0.0    0.0    7.0    0.0    21.0   0.2630208333333333   101 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    8.0    8.0    6.0    0.0    0.0    1.0    0.0    0.0    9.0    3.0    329.0  0.0    0.0    0.0    0.12266666666666666  46 / 375
0.0    5.0    0.0    11.0   13.0   4.0    1.0    3.0    1.0    2.0    6.0    0.0    0.0    0.0    7.0    1.0    9.0    0.0    2.0    4.0    1.0    0.0    0.0    309.0  10.0   5.0    0.21573604060913706  85 / 394
0.0    0.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    0.0    3.0    13.0   2.0    12.0   2.0    0.0    349.0  0.0    0.11195928753180662  44 / 393
2.0    3.0    0.0    0.0    8.0    6.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    19.0   4.0    0.0    0.0    0.0    5.0    0.0    308.0  0.16076294277929154  59 / 367
400.0  508.0  337.0  398.0  378.0  372.0  354.0  339.0  326.0  361.0  340.0  353.0  408.0  371.0  418.0  386.0  378.0  453.0  275.0  394.0  438.0  353.0  419.0  400.0  442.0  402.0  0.21253623912826153  2,126 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787464
2    0.877537
3    0.914726
4    0.935619
5    0.948316
6    0.958712
7    0.96771
8    0.975407
9    0.981306
10   0.985704

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21781913171661021
RMSE: 0.466710972355065
LogLoss: 0.7245683512975365
Mean Per-Class Error: 0.2177413512936544
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   1.0    0.0   2.0    0.0    0.07865168539325842  7 / 89
0.0   86.0   0.0   0.0    1.0   2.0   1.0   5.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    6.0    1.0   0.0   1.0    0.0   1.0    2.0   0.0    0.0    0.18867924528301888  20 / 106
0.0   0.0    57.0  0.0    4.0   1.0   7.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0   1.0   0.0    0.0    0.0    4.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0    0.3048780487804878   25 / 82
1.0   0.0    0.0   88.0   0.0   1.0   0.0   5.0   0.0   2.0    0.0   0.0   1.0   2.0   5.0   0.0    1.0    3.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    0.0    0.21428571428571427  24 / 112
0.0   4.0    1.0   0.0    69.0  2.0   7.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0    1.0    4.0   2.0   0.0    0.0   0.0    0.0   0.0    5.0    0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0    0.0   0.0   4.0    0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   0.0    0.0   4.0    4.0   1.0   0.0   2.0   0.0   0.0    3.0   0.0   0.0   0.0   1.0   0.0    2.0    0.0    1.0   0.0   0.0    0.0   0.0    76.0  4.0    2.0    0.24                 24 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    2.0    0.0    0.0   3.0   0.0    3.0   1.0    0.0   95.0   0.0    0.11214953271028037  12 / 107
1.0   1.0    0.0   0.0    3.0   2.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    3.0   1.0   0.0    0.0   0.0    2.0   0.0    72.0   0.1724137931034483   15 / 87
94.0  121.0  65.0  115.0  92.0  83.0  92.0  85.0  77.0  104.0  80.0  94.0  88.0  93.0  87.0  116.0  100.0  110.0  73.0  93.0  120.0  77.0  106.0  98.0  127.0  100.0  0.21526104417670683  536 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.784739
2    0.880723
3    0.92008
4    0.937349
5    0.951004
6    0.961044
7    0.970683
8    0.977912
9    0.981928
10   0.987148
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:08  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:08  3 min 46.422 sec  51056 obs/sec     1         1             10007      0.595742         1.13774             0.993693       0.30111                          0.594103           1.12389               0.993711         0.301606
    2019-07-23 13:35:10  3 min 48.314 sec  49126 obs/sec     10        10            100070     0.466674         0.730848            0.99613        0.212536                         0.466711           0.724568              0.996119         0.215261
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0889792
C15         0.98662                0.98662              0.0877887
C9          0.940912               0.940912             0.0837216
C12         0.875692               0.875692             0.0779184
C11         0.804875               0.804875             0.0716171
C8          0.786423               0.786423             0.0699753
C7          0.775959               0.775959             0.0690442
C14         0.69499                0.69499              0.0618396
C6          0.659234               0.659234             0.0586581
C10         0.659137               0.659137             0.0586495
C16         0.593049               0.593049             0.052769
C5          0.571508               0.571508             0.0508523
C3          0.548562               0.548562             0.0488106
C4          0.526319               0.526319             0.0468314
C1          0.417373               0.417373             0.0371375
C2          0.397929               0.397929             0.0354074
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_31

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007723664793957141  0.00018644530791789293  0.0         -0.026434635941541273  0.2892385721206665  0.21280556653801966   0.24652326107025146
    3        26       Softmax                      0.0   0.0   0.0050357968074982076  0.016709715127944946    0.0         -0.3995664132698249    0.8671469688415527  -0.45310857565133694  0.3785543441772461


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2202796001735642
RMSE: 0.4693395361287649
LogLoss: 0.7128198977360214
Mean Per-Class Error: 0.20584784443754472
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    5.0    0.0    3.0    0.0    3.0    0.0    3.0    2.0    5.0    0.0    2.0    3.0    2.0    1.0    5.0    0.0    0.10379746835443038  41 / 395
0.0    325.0  0.0    4.0    3.0    2.0    6.0    10.0   5.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    10.0   8.0    0.0    1.0    1.0    0.0    4.0    0.0    0.0    0.14921465968586387  57 / 382
0.0    0.0    295.0  0.0    11.0   0.0    13.0   1.0    0.0    0.0    26.0   0.0    0.0    0.0    6.0    0.0    3.0    1.0    5.0    3.0    1.0    0.0    3.0    0.0    0.0    0.0    0.1983695652173913   73 / 368
1.0    15.0   0.0    323.0  0.0    2.0    0.0    12.0   0.0    8.0    0.0    1.0    5.0    6.0    3.0    3.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    7.0    0.0    10.0   0.19851116625310175  80 / 403
0.0    7.0    2.0    0.0    295.0  1.0    16.0   2.0    0.0    0.0    5.0    0.0    0.0    0.0    1.0    3.0    5.0    3.0    5.0    5.0    0.0    0.0    0.0    9.0    1.0    24.0   0.23177083333333334  89 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    4.0    0.0    6.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    9.0    2.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    3.0    0.0    8.0    9.0    0.0    0.0    1.0    6.0    1.0    7.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    10.0   3.0    2.0    0.0    328.0  6.0    6.0    0.16539440203562342  65 / 393
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    16.0   0.0    3.0    22.0   8.0    11.0   0.0    0.0    325.0  0.0    0.17302798982188294  68 / 393
1.0    0.0    0.0    0.0    13.0   1.0    0.0    0.0    1.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    18.0   3.0    0.0    0.0    0.0    2.0    0.0    310.0  0.15300546448087432  56 / 366
414.0  494.0  361.0  407.0  383.0  347.0  337.0  334.0  362.0  368.0  385.0  336.0  393.0  367.0  400.0  392.0  341.0  441.0  263.0  394.0  421.0  358.0  431.0  400.0  411.0  463.0  0.20493851844446667  2,050 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.795061
2    0.886234
3    0.920224
4    0.942917
5    0.957413
6    0.96781
7    0.974208
8    0.978506
9    0.983005
10   0.987104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22462493216507773
RMSE: 0.4739461279144263
LogLoss: 0.7267175200515543
Mean Per-Class Error: 0.20740023207011093
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    2.0   1.0    1.0   2.0    0.0    0.11235955056179775  10 / 89
0.0   85.0   0.0   1.0    2.0   0.0   2.0   3.0   1.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    0.0   5.0    2.0   0.0   1.0    1.0   0.0    2.0   0.0    0.0    0.19811320754716982  21 / 106
0.0   0.0    64.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    6.0    0.0   0.0   0.0    2.0   0.0    1.0   0.0    2.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0    0.21951219512195122  18 / 82
1.0   3.0    0.0   90.0   0.0   0.0   0.0   4.0   0.0   3.0    0.0    1.0   2.0   2.0    0.0   2.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0    0.19642857142857142  22 / 112
0.0   0.0    0.0   0.0    70.0  1.0   4.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0    0.0   1.0    2.0   1.0    3.0   2.0   0.0    0.0   0.0    2.0   0.0    8.0    0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0    0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   1.0    0.0   3.0    3.0   0.0   0.0   1.0   2.0   0.0    3.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   1.0    0.0   0.0    82.0  3.0    0.0    0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    7.0   0.0    0.0   5.0   3.0    3.0   0.0    0.0   88.0   0.0    0.17757009345794392  19 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    73.0   0.16091954022988506  14 / 87
97.0  121.0  77.0  113.0  92.0  81.0  80.0  89.0  89.0  102.0  102.0  92.0  86.0  101.0  76.0  114.0  96.0  113.0  68.0  91.0  106.0  83.0  101.0  96.0  115.0  109.0  0.20682730923694778  515 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793173
2    0.885944
3    0.918875
4    0.941365
5    0.95743
6    0.96747
7    0.973092
8    0.975904
9    0.980723
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:52  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:52  1 min 30.881 sec  105336 obs/sec    1         1             10007      0.698307         1.46948             0.991331       0.383285                         0.700286           1.47285               0.991262         0.388353
    2019-07-23 13:32:53  1 min 31.652 sec  118566 obs/sec    10        10            100070     0.46934          0.71282             0.996084       0.204939                         0.473946           0.726718              0.995998         0.206827
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0966527
C13         0.888031               0.888031             0.0858306
C8          0.793106               0.793106             0.0766558
C7          0.787276               0.787276             0.0760923
C12         0.775854               0.775854             0.0749884
C9          0.736728               0.736728             0.0712068
C11         0.709928               0.709928             0.0686164
C14         0.671488               0.671488             0.0649011
C5          0.591662               0.591662             0.0571858
C16         0.582581               0.582581             0.056308
C10         0.554279               0.554279             0.0535725
C6          0.528384               0.528384             0.0510697
C3          0.516837               0.516837             0.0499537
C4          0.478094               0.478094             0.046209
C2          0.366357               0.366357             0.0354093
C1          0.365721               0.365721             0.0353479
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_75

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.000783496397559702  0.00018409284530207515  0.0         -0.025072240844565385  0.28663814067840576  0.22734080972690884   0.23634600639343262
    3        26       Softmax                      0.0   0.0   0.004767130287361327  0.008630361407995224    0.0         -0.37264614851944944   0.8902738094329834   -0.46651759903945744  0.404634952545166


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22099343828307336
RMSE: 0.470099391919489
LogLoss: 0.7141330186307558
Mean Per-Class Error: 0.20656641978800058
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    2.0    3.0    0.0    7.0    0.0    4.0    1.0    5.0    0.0    1.0    1.0    0.0    8.0    4.0    0.0    0.11139240506329114  44 / 395
0.0    311.0  0.0    9.0    1.0    2.0    2.0    4.0    0.0    1.0    8.0    0.0    0.0    0.0    2.0    7.0    3.0    10.0   11.0   1.0    1.0    0.0    4.0    6.0    0.0    0.0    0.18798955613577023  72 / 383
0.0    0.0    289.0  0.0    24.0   2.0    7.0    3.0    0.0    0.0    22.0   0.0    0.0    0.0    2.0    0.0    2.0    0.0    9.0    1.0    3.0    1.0    2.0    0.0    0.0    0.0    0.2125340599455041   78 / 367
3.0    21.0   0.0    325.0  0.0    1.0    1.0    4.0    2.0    5.0    2.0    0.0    2.0    3.0    0.0    1.0    1.0    10.0   1.0    0.0    5.0    0.0    0.0    13.0   0.0    3.0    0.1935483870967742   78 / 403
0.0    12.0   0.0    0.0    298.0  2.0    17.0   1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    3.0    2.0    4.0    19.0   5.0    0.0    0.0    0.0    2.0    0.0    14.0   0.22395833333333334  86 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    16.0   0.0    0.0    1.0    0.0    12.0   4.0    0.0    0.0    1.0    1.0    0.0    0.0    2.0    0.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    2.0    0.0    4.0    12.0   0.0    0.0    2.0    2.0    1.0    3.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    2.0    0.0    0.0    342.0  11.0   7.0    0.1319796954314721   52 / 394
1.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    17.0   0.0    1.0    32.0   1.0    30.0   0.0    1.0    295.0  0.0    0.24936386768447838  98 / 393
1.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    28.0   2.0    0.0    0.0    0.0    3.0    0.0    306.0  0.16621253405994552  61 / 367
396.0  453.0  330.0  435.0  416.0  364.0  359.0  337.0  339.0  367.0  415.0  337.0  405.0  371.0  356.0  414.0  351.0  407.0  366.0  386.0  394.0  379.0  414.0  461.0  365.0  386.0  0.20583824852544236  2,059 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.794162
2    0.882235
3    0.920724
4    0.941018
5    0.954913
6    0.964311
7    0.971608
8    0.977807
9    0.982405
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22363263220824595
RMSE: 0.4728981203264039
LogLoss: 0.7271977697824912
Mean Per-Class Error: 0.21021702604232215
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16     17     18    19    20     21    22    23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  -----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0   0.0   0.0    1.0   0.0   2.0    2.0   0.0   0.07865168539325842  7 / 89
0.0   80.0   0.0   1.0    1.0   0.0   1.0   2.0   0.0   0.0    4.0    0.0   0.0   0.0    1.0   3.0    1.0    5.0    3.0   0.0   0.0    0.0   3.0   1.0    0.0   0.0   0.24528301886792453  26 / 106
0.0   0.0    60.0  0.0    5.0   0.0   0.0   2.0   0.0   0.0    7.0    0.0   0.0   0.0    1.0   0.0    1.0    0.0    3.0   1.0   1.0    1.0   0.0   0.0    0.0   0.0   0.2682926829268293   22 / 82
2.0   3.0    0.0   95.0   0.0   0.0   0.0   1.0   1.0   2.0    1.0    0.0   1.0   2.0    0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   0.0   2.0    0.0   0.0   0.15178571428571427  17 / 112
0.0   1.0    0.0   0.0    73.0  2.0   5.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   1.0    0.0    1.0    5.0   3.0   0.0    0.0   0.0   1.0    0.0   3.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   4.0   2.0    0.0   0.0    1.0    0.0    0.0   0.0   0.0    0.0   84.0  0.0    0.0   0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   2.0    7.0   0.0   0.0   1.0   0.0   0.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0   0.0   0.0    0.0   0.0   81.0   4.0   2.0   0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    1.0   5.0    6.0    0.0    0.0   10.0  0.0    8.0   0.0   0.0    76.0  0.0   0.2897196261682243   31 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    6.0   0.0   0.0    0.0   0.0   1.0    0.0   72.0  0.1724137931034483   15 / 87
99.0  112.0  71.0  121.0  97.0  87.0  84.0  83.0  81.0  104.0  106.0  87.0  89.0  100.0  73.0  119.0  101.0  101.0  96.0  91.0  101.0  88.0  98.0  108.0  99.0  94.0  0.20963855421686747  522 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790361
2    0.880321
3    0.918474
4    0.941767
5    0.954619
6    0.963454
7    0.971486
8    0.975904
9    0.982329
10   0.984337
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:33  3 min 11.906 sec  109967 obs/sec    1         1             10007      0.680521         1.42892             0.991771       0.381486                         0.683125           1.44314               0.991685         0.386345
    2019-07-23 13:34:34  3 min 12.652 sec  122484 obs/sec    10        10            100070     0.470099         0.714133            0.996073       0.205838                         0.472898           0.727198              0.996015         0.209639
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0890415
C8          0.939598               0.939598             0.0836632
C15         0.937944               0.937944             0.083516
C9          0.845377               0.845377             0.0752736
C7          0.823828               0.823828             0.0733549
C12         0.759875               0.759875             0.0676604
C11         0.742553               0.742553             0.0661181
C6          0.672163               0.672163             0.0598504
C10         0.650711               0.650711             0.0579403
C16         0.613719               0.613719             0.0546465
C14         0.60133                0.60133              0.0535433
C4          0.586534               0.586534             0.0522259
C5          0.572087               0.572087             0.0509395
C3          0.559173               0.559173             0.0497897
C1          0.487768               0.487768             0.0434316
C2          0.438053               0.438053             0.0390049
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_67

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.001572773345941414   0.0003581142518669367   0.0         -0.02096136656425074   0.7503323554992676   -0.10384265812600689  0.6779234409332275
    3        26       Softmax                 0.0   0.0   0.0018300917686246976  0.00027765484992414713  0.0         -0.014155822537877437  0.38394010066986084  -0.5709831938684551   0.30634450912475586


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2113803589655224
RMSE: 0.4597611977597962
LogLoss: 0.7210920773619635
Mean Per-Class Error: 0.20256590358068258
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    0.0    6.0    1.0    3.0    0.0    0.0    1.0    3.0    2.0    2.0    0.0    3.0    3.0    6.0    1.0    0.09620253164556962  38 / 395
0.0    327.0  0.0    7.0    2.0    1.0    6.0    0.0    3.0    1.0    0.0    0.0    2.0    0.0    2.0    1.0    0.0    16.0   6.0    0.0    0.0    3.0    0.0    2.0    3.0    0.0    0.14397905759162305  55 / 382
0.0    0.0    298.0  0.0    15.0   2.0    14.0   1.0    0.0    0.0    19.0   0.0    0.0    0.0    4.0    0.0    1.0    0.0    5.0    2.0    0.0    0.0    7.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
1.0    22.0   0.0    329.0  0.0    2.0    0.0    4.0    0.0    4.0    0.0    3.0    2.0    10.0   7.0    3.0    0.0    10.0   2.0    1.0    1.0    0.0    0.0    2.0    0.0    0.0    0.18362282878411912  74 / 403
0.0    9.0    0.0    0.0    296.0  6.0    21.0   1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    5.0    2.0    8.0    6.0    0.0    0.0    0.0    9.0    0.0    17.0   0.22916666666666666  88 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    4.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    4.0    0.0    11.0   7.0    1.0    0.0    2.0    3.0    1.0    10.0   3.0    0.0    0.0    1.0    0.0    10.0   0.0    6.0    4.0    3.0    0.0    0.0    321.0  5.0    2.0    0.18527918781725888  73 / 394
0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    1.0    5.0    0.0    2.0    8.0    2.0    18.0   1.0    2.0    342.0  0.0    0.1297709923664122   51 / 393
2.0    1.0    0.0    1.0    16.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    26.0   6.0    0.0    0.0    0.0    3.0    0.0    298.0  0.1880108991825613   69 / 367
403.0  583.0  336.0  432.0  398.0  399.0  393.0  266.0  332.0  349.0  375.0  345.0  430.0  368.0  406.0  352.0  328.0  395.0  287.0  372.0  395.0  400.0  470.0  395.0  416.0  378.0  0.20163950814755574  2,017 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.79836
2    0.882135
3    0.916225
4    0.939318
5    0.951814
6    0.962511
7    0.972708
8    0.978806
9    0.983505
10   0.986304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.215335047910053
RMSE: 0.4640420755815716
LogLoss: 0.7298652056571482
Mean Per-Class Error: 0.20906608223443376
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    0.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   83.0   0.0   2.0    1.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   8.0    3.0   0.0   0.0    3.0   0.0    1.0   1.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    63.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   2.0    0.0   0.0    0.0   0.23170731707317074  19 / 82
1.0   4.0    0.0   93.0   0.0   1.0   0.0   3.0   0.0   1.0   0.0   0.0   1.0   2.0   1.0   1.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.16964285714285715  19 / 112
0.0   3.0    0.0   0.0    68.0  4.0   6.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    3.0   3.0   0.0    0.0   0.0    2.0   0.0    5.0   0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    1.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   6.0    2.0   0.0   0.0   1.0   1.0   0.0   4.0   1.0   0.0   0.0   0.0   0.0    2.0   0.0    1.0   1.0   0.0    0.0   0.0    78.0  2.0    0.0   0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0    2.0   0.0    0.0   1.0   0.0    5.0   1.0    0.0   94.0   0.0   0.12149532710280374  13 / 107
0.0   1.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   3.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   3.0   0.0    0.0   0.0    1.0   0.0    69.0  0.20689655172413793  18 / 87
97.0  149.0  72.0  127.0  83.0  95.0  94.0  67.0  79.0  98.0  95.0  93.0  93.0  98.0  82.0  102.0  83.0  100.0  74.0  87.0  103.0  96.0  117.0  95.0  121.0  90.0  0.20883534136546184  520 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791165
2    0.879116
3    0.91245
4    0.935341
5    0.948594
6    0.960643
7    0.970683
8    0.978715
9    0.983534
10   0.986747
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:12  2 min 50.067 sec  36126 obs/sec     1         1             10007      0.591306         1.12211             0.993786       0.314906                         0.587953           1.10602               0.99384          0.316064
    2019-07-23 13:34:14  2 min 52.814 sec  34060 obs/sec     10        10            100070     0.459761         0.721092            0.996243       0.20164                          0.464042           0.729865              0.996163         0.208835
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0891267
C13         0.955927               0.955927             0.0851986
C12         0.915365               0.915365             0.0815835
C9          0.903728               0.903728             0.0805463
C11         0.798352               0.798352             0.0711545
C8          0.79746                0.79746              0.071075
C7          0.77777                0.77777              0.06932
C14         0.705177               0.705177             0.0628501
C10         0.69084                0.69084              0.0615723
C16         0.589021               0.589021             0.0524975
C6          0.58868                0.58868              0.0524671
C3          0.572261               0.572261             0.0510037
C5          0.53748                0.53748              0.0479038
C4          0.528578               0.528578             0.0471104
C2          0.447933               0.447933             0.0399228
C1          0.411412               0.411412             0.0366678
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_50

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0014055230922735973  0.00039733736775815487  0.0         -0.014865262471886354  0.7449483871459961  -0.05807991489200538  0.7884228229522705
    3        26       Softmax                 0.0   0.0   0.0019791455272822464  0.00034290726762264967  0.0         0.014031334313760734   0.5019931793212891  -0.4676231959307108   0.2493964433670044


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.216991749878889
RMSE: 0.46582373262736304
LogLoss: 0.7209197986117857
Mean Per-Class Error: 0.21085967864902358
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  1.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    3.0    1.0    2.0    9.0    0.0    0.0    0.0    1.0    1.0    3.0    1.0    2.0    0.0    2.0    0.0    7.0    6.0    0.10632911392405063  42 / 395
0.0    299.0  0.0    5.0    1.0    1.0    7.0    10.0   3.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    32.0   15.0   0.0    0.0    0.0    1.0    3.0    3.0    0.0    0.2193211488250653   84 / 383
0.0    0.0    298.0  1.0    11.0   0.0    15.0   1.0    0.0    0.0    22.0   0.0    0.0    0.0    4.0    0.0    1.0    0.0    6.0    2.0    3.0    0.0    4.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
1.0    14.0   0.0    325.0  0.0    1.0    0.0    8.0    0.0    3.0    0.0    0.0    5.0    4.0    3.0    5.0    0.0    22.0   2.0    0.0    0.0    0.0    1.0    6.0    0.0    3.0    0.1935483870967742   78 / 403
0.0    5.0    1.0    1.0    301.0  1.0    18.0   0.0    2.0    0.0    12.0   0.0    0.0    0.0    0.0    2.0    7.0    5.0    11.0   4.0    0.0    0.0    0.0    2.0    0.0    12.0   0.21614583333333334  83 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    11.0   0.0    0.0    1.0    0.0    14.0   0.0    1.0    0.0    1.0    4.0    0.0    0.0    0.0    9.0    332.0  0.0    0.0    0.0    0.11702127659574468  44 / 376
0.0    3.0    0.0    7.0    6.0    0.0    1.0    2.0    5.0    0.0    16.0   2.0    0.0    2.0    0.0    0.0    8.0    1.0    4.0    4.0    2.0    0.0    0.0    319.0  10.0   2.0    0.19035532994923857  75 / 394
0.0    1.0    0.0    2.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    10.0   8.0    0.0    5.0    14.0   1.0    23.0   2.0    0.0    315.0  0.0    0.1984732824427481   78 / 393
2.0    3.0    0.0    2.0    10.0   5.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    25.0   2.0    0.0    0.0    0.0    3.0    0.0    306.0  0.16393442622950818  60 / 366
379.0  493.0  339.0  429.0  392.0  345.0  361.0  315.0  341.0  335.0  369.0  340.0  439.0  380.0  350.0  414.0  388.0  496.0  298.0  395.0  408.0  380.0  402.0  397.0  404.0  414.0  0.2096371088673398   2,097 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790363
2    0.880836
3    0.920524
4    0.938419
5    0.952214
6    0.963511
7    0.970609
8    0.977107
9    0.981406
10   0.984905

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22100194192558553
RMSE: 0.4701084363480255
LogLoss: 0.7338011208960881
Mean Per-Class Error: 0.2168518952247786
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   1.0    0.0   4.0    1.0    0.10112359550561797  9 / 89
0.0   76.0   0.0   3.0    1.0   0.0   1.0   4.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   10.0   5.0   0.0   0.0    0.0   1.0    1.0   2.0    0.0    0.2830188679245283   30 / 106
0.0   0.0    61.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0   6.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    3.0   2.0   0.0    0.0   1.0    0.0   0.0    0.0    0.25609756097560976  21 / 82
1.0   2.0    0.0   90.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   0.0   1.0   2.0    0.0   2.0    0.0   8.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.19642857142857142  22 / 112
0.0   1.0    0.0   0.0    70.0  1.0   6.0   0.0   0.0   0.0   6.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   1.0   0.0    0.0   0.0    2.0   0.0    5.0    0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0   1.0    0.0   2.0    2.0   0.0   0.0   1.0   2.0   0.0   6.0   2.0   0.0   0.0    0.0   0.0    2.0   1.0    0.0   0.0   1.0    0.0   0.0    75.0  4.0    1.0    0.25                 25 / 100
0.0   1.0    0.0   0.0    0.0   2.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   6.0    1.0   0.0    0.0   1.0   1.0    6.0   1.0    0.0   87.0   0.0    0.18691588785046728  20 / 107
0.0   2.0    0.0   1.0    3.0   2.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    75.0   0.13793103448275862  12 / 87
87.0  117.0  65.0  118.0  87.0  79.0  88.0  87.0  78.0  96.0  99.0  96.0  92.0  100.0  74.0  120.0  99.0  130.0  70.0  94.0  104.0  88.0  102.0  92.0  118.0  110.0  0.21606425702811244  538 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783936
2    0.881124
3    0.92249
4    0.936145
5    0.948996
6    0.962651
7    0.969879
8    0.9751
9    0.980723
10   0.984739
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:38  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:39  2 min 16.968 sec  52947 obs/sec     1         1             10007      0.605847         1.15116             0.993477       0.328002                         0.603292           1.13654               0.993515         0.324498
    2019-07-23 13:33:40  2 min 18.833 sec  49490 obs/sec     10        10            100070     0.465824         0.72092             0.996144       0.209637                         0.470108           0.733801              0.996062         0.216064
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0871747
C15         0.980124               0.980124             0.085442
C12         0.945937               0.945937             0.0824618
C9          0.929007               0.929007             0.080986
C8          0.761162               0.761162             0.0663541
C11         0.750618               0.750618             0.0654349
C7          0.748063               0.748063             0.0652122
C14         0.698992               0.698992             0.0609344
C10         0.688842               0.688842             0.0600496
C6          0.670408               0.670408             0.0584426
C3          0.631877               0.631877             0.0550837
C16         0.624595               0.624595             0.0544489
C5          0.598555               0.598555             0.0521789
C4          0.547356               0.547356             0.0477157
C2          0.463755               0.463755             0.0404277
C1          0.431923               0.431923             0.0376527
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_106

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007894149363778524  0.0001862065400928259  0.0         -0.031694585871179015  0.2820936441421509  0.21255758170952108   0.270776629447937
    3        26       Softmax                      0.0   0.0   0.006681661011428402   0.03896915912628174    0.0         -0.42275028511288      0.8842072486877441  -0.49678640046187306  0.38090991973876953


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2242226087028279
RMSE: 0.47352149761423495
LogLoss: 0.7334847226967374
Mean Per-Class Error: 0.2046427777110569
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    0.0    3.0    0.0    4.0    0.0    0.0    0.0    4.0    1.0    2.0    1.0    2.0    2.0    6.0    2.0    0.08860759493670886  35 / 395
0.0    299.0  0.0    14.0   1.0    2.0    4.0    9.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    1.0    22.0   12.0   0.0    0.0    9.0    0.0    4.0    0.0    0.0    0.2193211488250653   84 / 383
0.0    1.0    287.0  0.0    21.0   1.0    14.0   1.0    0.0    0.0    16.0   0.0    0.0    0.0    3.0    0.0    3.0    0.0    4.0    2.0    7.0    0.0    6.0    0.0    0.0    0.0    0.21584699453551912  79 / 366
1.0    13.0   0.0    326.0  0.0    0.0    2.0    4.0    0.0    9.0    0.0    0.0    3.0    6.0    10.0   1.0    0.0    15.0   0.0    1.0    1.0    0.0    0.0    5.0    0.0    6.0    0.19106699751861042  77 / 403
0.0    8.0    1.0    0.0    297.0  4.0    23.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    10.0   5.0    3.0    5.0    0.0    0.0    0.0    7.0    0.0    17.0   0.2265625            87 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    1.0    15.0   0.0    0.0    0.0    0.0    8.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    1.0    0.0    5.0    5.0    0.0    1.0    4.0    2.0    1.0    5.0    1.0    0.0    0.0    2.0    0.0    6.0    2.0    3.0    7.0    4.0    1.0    0.0    330.0  4.0    10.0   0.16243654822335024  64 / 394
0.0    0.0    0.0    2.0    0.0    2.0    1.0    2.0    0.0    1.0    0.0    0.0    1.0    0.0    1.0    0.0    17.0   0.0    2.0    21.0   3.0    25.0   0.0    0.0    314.0  1.0    0.2010178117048346   79 / 393
0.0    0.0    0.0    1.0    14.0   0.0    1.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    24.0   3.0    0.0    0.0    0.0    1.0    0.0    315.0  0.14168937329700274  52 / 367
398.0  460.0  330.0  439.0  386.0  334.0  380.0  324.0  360.0  334.0  400.0  347.0  393.0  371.0  408.0  380.0  390.0  411.0  285.0  393.0  425.0  386.0  421.0  419.0  381.0  448.0  0.20363890832750176  2,037 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796361
2    0.882435
3    0.914126
4    0.935219
5    0.950215
6    0.961212
7    0.969409
8    0.975707
9    0.980806
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22616387706456267
RMSE: 0.4755669007243489
LogLoss: 0.7372600265657291
Mean Per-Class Error: 0.21285184960985562
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16     17     18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0    1.0   0.0    0.0    3.0    0.0    0.06741573033707865  6 / 89
0.0   77.0   0.0   5.0    1.0   0.0   1.0   4.0   1.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0    6.0    4.0   0.0   0.0    4.0   0.0    1.0    0.0    0.0    0.27358490566037735  29 / 106
0.0   0.0    57.0  0.0    5.0   0.0   7.0   1.0   0.0   0.0   3.0   0.0   0.0   0.0    2.0   0.0    1.0    0.0    2.0   1.0   1.0    0.0   2.0    0.0    0.0    0.0    0.3048780487804878   25 / 82
1.0   2.0    0.0   90.0   0.0   0.0   1.0   1.0   0.0   3.0   0.0   0.0   1.0   2.0    3.0   0.0    0.0    3.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    2.0    0.19642857142857142  22 / 112
0.0   2.0    0.0   0.0    69.0  3.0   5.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    4.0    1.0    1.0   3.0   0.0    0.0   0.0    3.0    0.0    5.0    0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    1.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   2.0   0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    1.0    1.0    2.0   0.0   1.0    0.0   0.0    79.0   1.0    4.0    0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0    5.0    0.0    0.0   7.0   2.0    10.0  0.0    0.0    79.0   0.0    0.2616822429906542   28 / 107
0.0   0.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    3.0   1.0   0.0    0.0   0.0    1.0    0.0    76.0   0.12643678160919541  11 / 87
95.0  109.0  67.0  121.0  84.0  74.0  98.0  87.0  86.0  91.0  96.0  94.0  87.0  104.0  90.0  110.0  103.0  101.0  72.0  98.0  106.0  93.0  100.0  106.0  101.0  117.0  0.21285140562248997  530 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787149
2    0.884739
3    0.914056
4    0.936145
5    0.951807
6    0.959839
7    0.968273
8    0.9751
9    0.983133
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:02  4 min 40.278 sec  106457 obs/sec    1         1             10007      0.688894         1.44779             0.991565       0.383285                         0.687982           1.43919               0.991566         0.37992
    2019-07-23 13:36:03  4 min 40.991 sec  127477 obs/sec    10        10            100070     0.473521         0.733485            0.996015       0.203639                         0.475567           0.73726               0.99597          0.212851
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0928123
C8          0.855084               0.855084             0.0793623
C13         0.828163               0.828163             0.0768637
C9          0.820003               0.820003             0.0761063
C7          0.798959               0.798959             0.0741532
C12         0.793765               0.793765             0.0736711
C11         0.730497               0.730497             0.0677991
C5          0.632304               0.632304             0.0586856
C3          0.609137               0.609137             0.0565354
C10         0.60343                0.60343              0.0560057
C6          0.592474               0.592474             0.0549889
C14         0.579366               0.579366             0.0537723
C4          0.579319               0.579319             0.0537679
C16         0.534877               0.534877             0.0496431
C2          0.408692               0.408692             0.0379317
C1          0.408366               0.408366             0.0379013
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_5

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007734898783269273  0.00017689220840111375  0.0         -0.01337431221962504  0.2825967073440552  0.2277835127078082   0.2431861162185669
    3        26       Softmax                      0.0   0.0   0.005060083012512433   0.014426909387111664    0.0         -0.40038146161745874  0.8675494194030762  -0.4831724076674392  0.3371312618255615


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22307493953314517
RMSE: 0.4723080981024411
LogLoss: 0.7337127530677926
Mean Per-Class Error: 0.2046819276960345
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    3.0    1.0    6.0    0.0    0.0    0.0    1.0    1.0    4.0    0.0    1.0    0.0    6.0    1.0    5.0    4.0    0.09620253164556962  38 / 395
0.0    317.0  0.0    13.0   0.0    1.0    2.0    6.0    2.0    0.0    1.0    0.0    0.0    0.0    12.0   11.0   0.0    7.0    2.0    0.0    1.0    0.0    2.0    4.0    1.0    1.0    0.17232375979112272  66 / 383
0.0    1.0    307.0  0.0    14.0   0.0    23.0   0.0    0.0    0.0    10.0   0.0    0.0    0.0    4.0    0.0    2.0    0.0    1.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
0.0    16.0   0.0    331.0  0.0    1.0    2.0    5.0    0.0    8.0    0.0    1.0    4.0    6.0    6.0    2.0    0.0    12.0   0.0    1.0    1.0    0.0    0.0    1.0    1.0    4.0    0.17661691542288557  71 / 402
0.0    12.0   4.0    0.0    285.0  1.0    14.0   4.0    0.0    0.0    11.0   1.0    0.0    0.0    0.0    1.0    5.0    6.0    7.0    7.0    0.0    0.0    0.0    10.0   0.0    16.0   0.2578125            99 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    1.0    0.0    20.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
1.0    4.0    0.0    5.0    6.0    0.0    1.0    4.0    1.0    2.0    5.0    0.0    0.0    0.0    2.0    2.0    6.0    0.0    12.0   1.0    4.0    0.0    0.0    332.0  2.0    4.0    0.15736040609137056  62 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    2.0    19.0   3.0    14.0   2.0    0.0    339.0  1.0    0.13740458015267176  54 / 393
3.0    0.0    0.0    1.0    13.0   0.0    2.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    32.0   2.0    0.0    0.0    0.0    3.0    1.0    291.0  0.20708446866485014  76 / 367
391.0  510.0  379.0  451.0  357.0  360.0  379.0  299.0  322.0  376.0  418.0  349.0  437.0  382.0  401.0  389.0  334.0  382.0  324.0  386.0  396.0  361.0  418.0  423.0  397.0  382.0  0.20373887833649906  2,038 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796261
2    0.880536
3    0.914026
4    0.93312
5    0.949715
6    0.960812
7    0.969009
8    0.974808
9    0.979606
10   0.983905

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22845033767643838
RMSE: 0.4779647870674558
LogLoss: 0.7424656553880428
Mean Per-Class Error: 0.2186443269527463
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   3.0    0.0    2.0    1.0   0.0898876404494382   8 / 89
0.0   80.0   0.0   4.0    0.0   0.0   0.0   1.0   1.0   0.0    1.0    0.0   0.0   0.0    4.0   4.0    0.0   5.0    2.0   0.0   0.0   0.0   1.0    2.0    1.0    0.0   0.24528301886792453  26 / 106
0.0   0.0    64.0  0.0    2.0   0.0   7.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   2.0   0.0   0.0   1.0    0.0    0.0    0.0   0.21951219512195122  18 / 82
0.0   2.0    0.0   93.0   0.0   1.0   1.0   4.0   0.0   2.0    0.0    1.0   2.0   2.0    1.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   3.0    2.0   0.0    64.0  1.0   2.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0   0.0    3.0   2.0    3.0   3.0   0.0   0.0   0.0    5.0    0.0    5.0   0.3402061855670103   33 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0   2.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   1.0    0.0   4.0    3.0   0.0   1.0   2.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    4.0   0.0   0.0   0.0   0.0    80.0   0.0    2.0   0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   3.0    1.0   0.0    0.0   6.0   1.0   4.0   1.0    0.0    88.0   1.0   0.17757009345794392  19 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    9.0   1.0   0.0   0.0   0.0    1.0    0.0    67.0  0.22988505747126436  20 / 87
90.0  127.0  80.0  132.0  79.0  81.0  88.0  74.0  77.0  103.0  105.0  93.0  94.0  103.0  80.0  112.0  91.0  108.0  85.0  94.0  99.0  81.0  110.0  103.0  105.0  96.0  0.21807228915662652  543 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781928
2    0.882329
3    0.916867
4    0.935743
5    0.951406
6    0.963052
7    0.970281
8    0.977108
9    0.982329
10   0.985944
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:43  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:43  21.421 sec  94405 obs/sec     1         1             10007      0.704014         1.52077             0.991193       0.40148                          0.705862           1.52926               0.991122         0.412851
    2019-07-23 13:31:44  22.190 sec  117177 obs/sec    10        10            100070     0.472308         0.733713            0.996036       0.203739                         0.477965           0.742466              0.995929         0.218072
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0890326
C13         0.919636               0.919636             0.0818776
C9          0.907622               0.907622             0.0808079
C7          0.899749               0.899749             0.080107
C12         0.762999               0.762999             0.0679318
C8          0.759151               0.759151             0.0675892
C11         0.698957               0.698957             0.06223
C10         0.698074               0.698074             0.0621513
C5          0.66847                0.66847              0.0595156
C14         0.658504               0.658504             0.0586283
C4          0.6369                 0.6369               0.0567049
C3          0.590213               0.590213             0.0525482
C6          0.588569               0.588569             0.0524018
C16         0.573731               0.573731             0.0510808
C1          0.441342               0.441342             0.0392938
C2          0.427922               0.427922             0.038099
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_72

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.001574839399040684   0.00030786427669227123  0.0         -0.00548977386776528  0.7520666122436523   0.09025729768654835  0.8112821578979492
    3        26       Softmax                 0.0   0.0   0.0018971781027385776  0.0003625662066042423   0.0         0.000809409708333183  0.38731253147125244  -0.5421699756430913  0.2572813034057617


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21761059861754375
RMSE: 0.46648751174875386
LogLoss: 0.7410858912575445
Mean Per-Class Error: 0.21724364415152675
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    2.0    0.0    7.0    0.0    2.0    0.0    0.0    2.0    6.0    0.0    1.0    1.0    3.0    3.0    5.0    1.0    0.09620253164556962  38 / 395
0.0    302.0  0.0    5.0    3.0    0.0    1.0    12.0   4.0    1.0    4.0    0.0    0.0    0.0    1.0    2.0    1.0    22.0   14.0   0.0    0.0    7.0    0.0    2.0    0.0    2.0    0.21148825065274152  81 / 383
0.0    0.0    294.0  0.0    12.0   1.0    21.0   1.0    0.0    0.0    23.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    6.0    2.0    3.0    0.0    4.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
3.0    16.0   0.0    317.0  0.0    1.0    0.0    6.0    1.0    7.0    0.0    1.0    6.0    6.0    3.0    3.0    0.0    15.0   4.0    0.0    1.0    0.0    0.0    11.0   0.0    2.0    0.21339950372208435  86 / 403
0.0    3.0    0.0    0.0    300.0  4.0    9.0    2.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    2.0    15.0   4.0    16.0   3.0    0.0    0.0    0.0    5.0    0.0    13.0   0.21875              84 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    1.0    0.0    11.0   1.0    2.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    5.0    0.0    2.0    9.0    0.0    2.0    1.0    4.0    1.0    8.0    2.0    0.0    0.0    0.0    1.0    10.0   2.0    12.0   2.0    3.0    1.0    0.0    322.0  5.0    2.0    0.18274111675126903  72 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    8.0    0.0    5.0    13.0   4.0    23.0   2.0    1.0    323.0  0.0    0.178117048346056    70 / 393
1.0    0.0    0.0    0.0    12.0   1.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    49.0   5.0    0.0    0.0    0.0    0.0    0.0    278.0  0.24250681198910082  89 / 367
398.0  452.0  368.0  402.0  397.0  330.0  289.0  347.0  342.0  363.0  417.0  335.0  410.0  365.0  352.0  394.0  379.0  419.0  482.0  377.0  415.0  379.0  456.0  403.0  408.0  324.0  0.21613515945216435  2,162 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783865
2    0.875837
3    0.914925
4    0.937119
5    0.953614
6    0.963611
7    0.971309
8    0.977307
9    0.982605
10   0.986904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21816321960477503
RMSE: 0.46707945748531376
LogLoss: 0.7435305113684832
Mean Per-Class Error: 0.21922243922093038
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16     17     18     19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  -----  -----  -----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0    0.0    1.0    0.0   0.0    0.0   1.0    2.0   3.0    0.0   0.0898876404494382    8 / 89
0.0   78.0   0.0   1.0    2.0   0.0   1.0   3.0   1.0   0.0    1.0    0.0   0.0   0.0   1.0   0.0    1.0    9.0    3.0    0.0   0.0    4.0   0.0    1.0   0.0    0.0   0.2641509433962264    28 / 106
0.0   0.0    63.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   1.0   0.0    0.0    0.0    3.0    1.0   0.0    0.0   2.0    0.0   0.0    0.0   0.23170731707317074   19 / 82
1.0   3.0    0.0   93.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0    0.0   2.0   1.0   1.0   1.0    0.0    5.0    1.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.16964285714285715   19 / 112
0.0   2.0    0.0   0.0    72.0  3.0   2.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    4.0    1.0    3.0    1.0   0.0    0.0   0.0    2.0   0.0    5.0   0.25773195876288657   25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---    ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0    1.0    0.0    0.0   0.0    0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   3.0    0.0   2.0    3.0   0.0   0.0   1.0   1.0   0.0    4.0    0.0   0.0   0.0   0.0   0.0    2.0    1.0    3.0    0.0   0.0    0.0   0.0    76.0  3.0    1.0   0.24                  24 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   2.0    3.0    0.0    0.0    4.0   2.0    7.0   2.0    0.0   86.0   0.0   0.19626168224299065   21 / 107
1.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0   0.0   0.0    1.0    0.0    14.0   2.0   0.0    0.0   0.0    0.0   0.0    61.0  0.2988505747126437    26 / 87
94.0  108.0  78.0  117.0  90.0  75.0  69.0  88.0  79.0  101.0  108.0  91.0  89.0  97.0  73.0  113.0  100.0  106.0  129.0  87.0  104.0  89.0  118.0  97.0  117.0  73.0  0.2176706827309237    542 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782329
2    0.878313
3    0.921285
4    0.941365
5    0.955823
6    0.96506
7    0.969478
8    0.976707
9    0.982731
10   0.98755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:27  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:27  3 min  5.937 sec  35112 obs/sec     1         1             10007      0.587438         1.11138             0.993868       0.30071                          0.58471            1.09389               0.993908         0.297189
    2019-07-23 13:34:30  3 min  8.683 sec  33991 obs/sec     10        10            100070     0.466488         0.741086            0.996133       0.216135                         0.467079           0.743531              0.996113         0.217671
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0907986
C13         0.976041               0.976041             0.0886231
C9          0.918246               0.918246             0.0833755
C12         0.87837                0.87837              0.0797548
C7          0.791419               0.791419             0.0718597
C11         0.774447               0.774447             0.0703187
C8          0.71601                0.71601              0.0650127
C10         0.655458               0.655458             0.0595146
C14         0.652422               0.652422             0.0592389
C6          0.628036               0.628036             0.0570248
C3          0.579671               0.579671             0.0526333
C16         0.565289               0.565289             0.0513275
C4          0.539756               0.539756             0.049009
C5          0.515766               0.515766             0.0468308
C2          0.43113                0.43113              0.039146
C1          0.391328               0.391328             0.035532
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_47

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0016019514217759934  0.0003613776061683893  0.0         0.007857820517841674  0.7535288333892822  -0.09676407833815591  0.7096641063690186
    3        26       Softmax                 0.0   0.0   0.001855551938381093   0.0002696181181818247  0.0         0.015678034158965532  0.3825187683105469  -0.5481006929942026   0.28736066818237305


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21399433276490396
RMSE: 0.4625952148097772
LogLoss: 0.7327231284917439
Mean Per-Class Error: 0.2136145672002906
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    4.0    1.0    0.0    6.0    0.0    2.0    0.0    3.0    0.0    7.0    1.0    1.0    0.0    4.0    0.0    6.0    1.0    0.09873417721518987  39 / 395
0.0    318.0  0.0    4.0    1.0    2.0    6.0    8.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    23.0   5.0    0.0    0.0    3.0    0.0    4.0    3.0    0.0    0.16971279373368145  65 / 383
0.0    0.0    290.0  0.0    23.0   0.0    9.0    1.0    0.0    0.0    19.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    8.0    3.0    7.0    0.0    5.0    0.0    0.0    0.0    0.21195652173913043  78 / 368
3.0    28.0   0.0    315.0  0.0    1.0    0.0    6.0    1.0    8.0    0.0    1.0    6.0    5.0    2.0    3.0    0.0    6.0    3.0    1.0    3.0    0.0    0.0    10.0   0.0    1.0    0.21836228287841192  88 / 403
0.0    11.0   2.0    0.0    305.0  3.0    7.0    0.0    2.0    0.0    3.0    3.0    0.0    0.0    0.0    2.0    12.0   4.0    6.0    2.0    0.0    0.0    0.0    8.0    0.0    14.0   0.20572916666666666  79 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    1.0    0.0    10.0   0.0    1.0    0.0    0.0    4.0    0.0    0.0    1.0    2.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    9.0    0.0    2.0    11.0   1.0    1.0    4.0    4.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    8.0    2.0    14.0   6.0    2.0    0.0    0.0    315.0  5.0    2.0    0.20050761421319796  79 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    9.0    0.0    8.0    34.0   2.0    29.0   3.0    0.0    298.0  0.0    0.23979591836734693  94 / 392
2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    2.0    28.0   4.0    0.0    0.0    0.0    3.0    0.0    304.0  0.17166212534059946  63 / 367
400.0  523.0  354.0  419.0  403.0  372.0  303.0  299.0  340.0  354.0  370.0  334.0  429.0  342.0  372.0  373.0  380.0  473.0  361.0  406.0  414.0  380.0  460.0  406.0  357.0  379.0  0.21273617914625612  2,128 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787264
2    0.882835
3    0.918824
4    0.940618
5    0.954114
6    0.963211
7    0.971209
8    0.977007
9    0.981506
10   0.985404

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21820409627434295
RMSE: 0.4671232131615201
LogLoss: 0.7453076456975221
Mean Per-Class Error: 0.2212448036496045
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0   0.0    0.0   2.0    0.0   3.0   0.0   0.07865168539325842  7 / 89
0.0   80.0   0.0   1.0    1.0   0.0   3.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   9.0    3.0   0.0   0.0    2.0   0.0    1.0   1.0   0.0   0.24528301886792453  26 / 106
0.0   0.0    63.0  0.0    3.0   0.0   4.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   2.0    0.0   0.0   0.0   0.23170731707317074  19 / 82
2.0   5.0    0.0   88.0   0.0   0.0   0.0   4.0   1.0   2.0    0.0   0.0   3.0   1.0   0.0   1.0    0.0   1.0    2.0   0.0   1.0    0.0   0.0    1.0   0.0   0.0   0.21428571428571427  24 / 112
0.0   3.0    1.0   0.0    69.0  3.0   3.0   0.0   1.0   0.0    2.0   2.0   0.0   0.0   0.0   0.0    3.0   1.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0   7.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   86.0   0.0   0.0   0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    5.0   0.0   0.0   1.0   1.0   0.0    4.0   0.0   0.0   0.0   0.0   0.0    2.0   2.0    6.0   0.0   1.0    0.0   0.0    73.0  1.0   1.0   0.27                 27 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    4.0   0.0    0.0   7.0   1.0    10.0  1.0    0.0   80.0  0.0   0.2523364485981308   27 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    3.0   1.0   0.0    0.0   0.0    2.0   0.0   73.0  0.16091954022988506  14 / 87
93.0  124.0  79.0  116.0  88.0  85.0  75.0  83.0  87.0  103.0  96.0  88.0  98.0  90.0  72.0  108.0  99.0  117.0  94.0  93.0  102.0  92.0  118.0  96.0  99.0  95.0  0.221285140562249    551 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.778715
2    0.881124
3    0.918072
4    0.941365
5    0.954217
6    0.960643
7    0.968273
8    0.977108
9    0.982731
10   0.986345
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:29  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:30  2 min  8.025 sec  35112 obs/sec     1         1             10007      0.59289          1.11482             0.993753       0.29861                          0.593171           1.10968               0.993731         0.303614
    2019-07-23 13:33:32  2 min 10.734 sec  34037 obs/sec     10        10            100070     0.462595         0.732723            0.996197       0.212736                         0.467123           0.745308              0.996112         0.221285
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.092137
C13         0.951064               0.951064             0.0876282
C12         0.85506                0.85506              0.0787827
C9          0.822703               0.822703             0.0758014
C7          0.776292               0.776292             0.0715253
C8          0.773849               0.773849             0.0713001
C11         0.753378               0.753378             0.069414
C10         0.706458               0.706458             0.0650909
C14         0.651559               0.651559             0.0600327
C6          0.585335               0.585335             0.053931
C3          0.574347               0.574347             0.0529186
C16         0.565178               0.565178             0.0520738
C5          0.5192                 0.5192               0.0478375
C4          0.478863               0.478863             0.044121
C2          0.441257               0.441257             0.0406561
C1          0.398858               0.398858             0.0367496
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_68

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.001529253887071036   0.0003613278968259692   0.0         -0.028573294440207064  0.7475907802581787   -0.03096419637252658  0.7238426208496094
    3        26       Softmax                 0.0   0.0   0.0018536945969502155  0.00028089352417737246  0.0         0.00697748988146976    0.38875484466552734  -0.5428265820732701   0.2727065086364746


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2163026068210986
RMSE: 0.46508344070832985
LogLoss: 0.7333683044311828
Mean Per-Class Error: 0.21204274754368874
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    7.0    0.0    1.0    0.0    0.0    0.0    7.0    3.0    2.0    0.0    2.0    3.0    6.0    0.0    0.09367088607594937  37 / 395
0.0    321.0  0.0    8.0    3.0    1.0    0.0    3.0    5.0    0.0    2.0    0.0    1.0    0.0    1.0    2.0    4.0    14.0   11.0   0.0    1.0    1.0    1.0    2.0    2.0    0.0    0.1618798955613577   62 / 383
0.0    0.0    295.0  0.0    19.0   1.0    15.0   1.0    0.0    0.0    16.0   0.0    0.0    0.0    3.0    0.0    3.0    0.0    4.0    2.0    3.0    0.0    5.0    0.0    0.0    1.0    0.1983695652173913   73 / 368
6.0    16.0   0.0    337.0  0.0    2.0    0.0    6.0    0.0    5.0    2.0    0.0    8.0    4.0    2.0    3.0    0.0    6.0    2.0    1.0    0.0    0.0    0.0    1.0    0.0    2.0    0.16377171215880892  66 / 403
0.0    9.0    3.0    0.0    304.0  5.0    11.0   0.0    1.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    8.0    3.0    9.0    3.0    0.0    0.0    0.0    4.0    0.0    18.0   0.20833333333333334  80 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    17.0   1.0    3.0    0.0    0.0    4.0    0.0    0.0    1.0    1.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    11.0   0.0    5.0    6.0    2.0    3.0    2.0    4.0    2.0    10.0   5.0    0.0    0.0    2.0    1.0    11.0   3.0    4.0    4.0    2.0    0.0    0.0    306.0  9.0    2.0    0.2233502538071066   88 / 394
1.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    4.0    48.0   4.0    45.0   6.0    0.0    270.0  0.0    0.31297709923664124  123 / 393
0.0    0.0    0.0    1.0    15.0   1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    24.0   6.0    0.0    0.0    0.0    0.0    0.0    300.0  0.1780821917808219   65 / 365
413.0  509.0  352.0  446.0  407.0  366.0  311.0  282.0  328.0  361.0  366.0  347.0  450.0  383.0  363.0  380.0  367.0  449.0  343.0  441.0  402.0  393.0  452.0  367.0  334.0  391.0  0.2111366590022993   2,112 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788863
2    0.881736
3    0.918924
4    0.939218
5    0.954614
6    0.963011
7    0.970909
8    0.976207
9    0.981905
10   0.985804

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21915237731511036
RMSE: 0.4681371351592505
LogLoss: 0.7461901182204224
Mean Per-Class Error: 0.21929847494918053
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16    17     18    19     20     21    22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.0   1.0    1.0   3.0   0.0    0.0898876404494382   8 / 89
0.0   86.0   0.0   2.0    2.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0    2.0   3.0    3.0   0.0    1.0    1.0   1.0    2.0   0.0   0.0    0.18867924528301888  20 / 106
0.0   0.0    61.0  0.0    4.0   1.0   5.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0    2.0   0.0    0.0   0.0    2.0   1.0    1.0    0.0   2.0    0.0   0.0   0.0    0.25609756097560976  21 / 82
3.0   2.0    0.0   94.0   0.0   1.0   0.0   3.0   0.0   1.0   1.0   0.0   3.0    1.0    0.0   0.0    0.0   2.0    1.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.16071428571428573  18 / 112
0.0   2.0    2.0   0.0    71.0  3.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0    2.0   1.0    3.0   1.0    0.0    0.0   0.0    0.0   0.0   8.0    0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0    0.0    0.0   0.0    0.0   2.0    0.0   0.0    0.0    0.0   85.0   0.0   0.0   0.0    0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    3.0   0.0   1.0   1.0   2.0   0.0   4.0   3.0   0.0    0.0    0.0   0.0    2.0   1.0    0.0   0.0    1.0    0.0   0.0    71.0  5.0   2.0    0.29                 29 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0    2.0   0.0    0.0   11.0   3.0    14.0  2.0    0.0   73.0  0.0    0.3177570093457944   34 / 107
0.0   0.0    0.0   1.0    5.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   0.0    2.0   0.0    3.0   3.0    0.0    0.0   0.0    0.0   0.0   71.0   0.1839080459770115   16 / 87
95.0  120.0  72.0  132.0  96.0  85.0  81.0  75.0  76.0  99.0  91.0  98.0  100.0  103.0  70.0  108.0  94.0  112.0  86.0  104.0  105.0  94.0  112.0  84.0  96.0  102.0  0.21847389558232932  544 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781526
2    0.881928
3    0.92008
4    0.938153
5    0.953012
6    0.959438
7    0.969076
8    0.973896
9    0.980723
10   0.986345
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:14  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:15  2 min 53.263 sec  27797 obs/sec     1         1             10007      0.579343         1.07668             0.994033       0.287214                         0.577289           1.06503               0.994062         0.286345
    2019-07-23 13:34:17  2 min 55.956 sec  33434 obs/sec     10        10            100070     0.465083         0.733368            0.996155       0.211137                         0.468137           0.74619               0.996095         0.218474
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0915416
C13         0.924128               0.924128             0.0845961
C12         0.902932               0.902932             0.0826558
C9          0.86633                0.86633              0.0793052
C11         0.813809               0.813809             0.0744974
C7          0.77651                0.77651              0.0710829
C8          0.761529               0.761529             0.0697116
C10         0.67258                0.67258              0.061569
C14         0.665224               0.665224             0.0608956
C6          0.617193               0.617193             0.0564989
C16         0.574949               0.574949             0.0526317
C3          0.548827               0.548827             0.0502404
C4          0.505167               0.505167             0.0462438
C5          0.485863               0.485863             0.0444766
C2          0.428403               0.428403             0.0392167
C1          0.380555               0.380555             0.0348366
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_18

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011431691406755817  0.00033889326732605696  0.0         -0.05355371535279119  0.5780835151672363  -0.06055060653707597  0.6185381412506104
    3        26       Softmax                 0.0   0.0   0.002350770551297151   0.0008249112870544195   0.0         0.02615835136496641   0.743671178817749   -0.540404630212909    0.2563670873641968


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21961222037648687
RMSE: 0.46862801919698194
LogLoss: 0.7368525827337029
Mean Per-Class Error: 0.20167718149352767
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    12.0   3.0    3.0    4.0    4.0    0.0    0.0    0.0    1.0    0.0    2.0    2.0    0.0    4.0    1.0    5.0    0.0    0.11392405063291139  45 / 395
0.0    315.0  0.0    11.0   3.0    0.0    2.0    4.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    29.0   4.0    1.0    0.0    2.0    0.0    3.0    1.0    1.0    0.17539267015706805  67 / 382
0.0    0.0    300.0  0.0    16.0   0.0    7.0    3.0    0.0    0.0    16.0   0.0    0.0    0.0    9.0    0.0    0.0    0.0    1.0    4.0    7.0    0.0    4.0    1.0    0.0    0.0    0.18478260869565216  68 / 368
1.0    13.0   0.0    344.0  0.0    2.0    0.0    8.0    0.0    6.0    0.0    0.0    2.0    7.0    3.0    2.0    0.0    7.0    4.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.14640198511166252  59 / 403
0.0    8.0    4.0    1.0    299.0  1.0    16.0   1.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    13.0   8.0    2.0    6.0    0.0    0.0    0.0    1.0    0.0    17.0   0.2193211488250653   84 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    8.0    7.0    0.0    0.0    2.0    10.0   0.0    0.0    2.0    1.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    1.0    0.0    3.0    7.0    1.0    2.0    0.0    2.0    2.0    9.0    0.0    0.0    0.0    0.0    0.0    10.0   2.0    12.0   2.0    1.0    0.0    0.0    335.0  2.0    3.0    0.14974619289340102  59 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    5.0    6.0    0.0    4.0    15.0   0.0    6.0    0.0    0.0    347.0  0.0    0.11704834605597965  46 / 393
3.0    0.0    0.0    1.0    16.0   0.0    0.0    0.0    0.0    19.0   0.0    3.0    0.0    0.0    0.0    0.0    4.0    1.0    24.0   6.0    0.0    0.0    0.0    1.0    1.0    288.0  0.21525885558583105  79 / 367
375.0  490.0  345.0  458.0  414.0  336.0  354.0  340.0  350.0  364.0  387.0  338.0  392.0  414.0  388.0  401.0  366.0  444.0  285.0  409.0  397.0  339.0  408.0  420.0  400.0  389.0  0.2005398380485854   2,006 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.79946
2    0.879636
3    0.914826
4    0.936719
5    0.951515
6    0.962011
7    0.969009
8    0.975807
9    0.980306
10   0.985104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22578713468477146
RMSE: 0.47517063743961646
LogLoss: 0.746694684818107
Mean Per-Class Error: 0.21240590693708644
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
77.0  0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   1.0    0.0    1.0   2.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0    3.0    0.0   0.1348314606741573   12 / 89
0.0   82.0   0.0   1.0    2.0   0.0   1.0   2.0   1.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    1.0   10.0   2.0   0.0   0.0   2.0   0.0    1.0    0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    62.0  0.0    3.0   0.0   3.0   1.0   0.0   0.0    5.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0   2.0   0.0   0.0   2.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
1.0   2.0    0.0   93.0   0.0   0.0   0.0   5.0   0.0   2.0    0.0    0.0   1.0   3.0    0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    72.0  1.0   7.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0    0.0   0.0    4.0   1.0    1.0   3.0   0.0   0.0   0.0    0.0    0.0    5.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   2.0    0.0   0.0    1.0   2.0    0.0   0.0   2.0   0.0   83.0   0.0    0.0    0.0   0.09782608695652174  9 / 92
0.0   0.0    0.0   2.0    2.0   0.0   1.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0    5.0   0.0   0.0   0.0   0.0    80.0   0.0    2.0   0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   1.0    0.0   3.0    2.0   0.0    0.0   5.0   0.0   3.0   0.0    0.0    92.0   0.0   0.14018691588785046  15 / 107
0.0   0.0    0.0   1.0    5.0   0.0   0.0   0.0   0.0   5.0    0.0    2.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   2.0   0.0   0.0   0.0    1.0    1.0    64.0  0.26436781609195403  23 / 87
84.0  118.0  69.0  124.0  96.0  76.0  94.0  92.0  81.0  105.0  101.0  93.0  86.0  108.0  74.0  122.0  99.0  115.0  70.0  98.0  97.0  77.0  100.0  102.0  111.0  98.0  0.21084337349397592  525 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789157
2    0.873896
3    0.911647
4    0.93253
5    0.952209
6    0.963454
7    0.971486
8    0.976707
9    0.980321
10   0.986345
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:18  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:18  56.744 sec  89348 obs/sec     1         1             10007      0.682619         1.42477             0.991718       0.387984                         0.680368           1.40913               0.991752         0.388755
    2019-07-23 13:32:19  57.861 sec  83322 obs/sec     10        10            100070     0.468628         0.736853            0.996097       0.20054                          0.475171           0.746695              0.995977         0.210843
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.100764
C15         0.936804               0.936804             0.0943957
C9          0.812495               0.812495             0.0818699
C12         0.778838               0.778838             0.0784785
C8          0.725847               0.725847             0.0731389
C11         0.68343                0.68343              0.0688649
C14         0.630929               0.630929             0.0635747
C7          0.623627               0.623627             0.0628389
C10         0.61704                0.61704              0.0621752
C6          0.596662               0.596662             0.0601218
C16         0.480051               0.480051             0.0483716
C4          0.455456               0.455456             0.0458934
C3          0.429826               0.429826             0.0433108
C5          0.425962               0.425962             0.0429214
C2          0.392704               0.392704             0.0395702
C1          0.334551               0.334551             0.0337106
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_12

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.001169691500990666   0.00033309950958937407  0.0         -0.015570914060576868  0.5563197135925293  -0.08151610246486936  0.6216726303100586
    3        26       Softmax                 0.0   0.0   0.0022775607870314093  0.0007419595494866371   0.0         -0.01816443906220509   0.7299940586090088  -0.5243436744562973   0.27716028690338135


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22189706858975042
RMSE: 0.47105951703553384
LogLoss: 0.7531804095968391
Mean Per-Class Error: 0.2134535253776237
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    6.0    1.0    3.0    0.0    8.0    0.0    0.0    0.0    3.0    1.0    4.0    0.0    2.0    1.0    4.0    1.0    0.09873417721518987  39 / 395
0.0    318.0  0.0    6.0    4.0    2.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    24.0   14.0   0.0    0.0    2.0    0.0    5.0    0.0    1.0    0.16971279373368145  65 / 383
0.0    0.0    291.0  1.0    16.0   0.0    24.0   0.0    0.0    0.0    23.0   0.0    0.0    0.0    6.0    0.0    0.0    0.0    2.0    2.0    0.0    0.0    2.0    0.0    0.0    1.0    0.20923913043478262  77 / 368
6.0    22.0   0.0    325.0  0.0    0.0    2.0    6.0    0.0    7.0    1.0    0.0    2.0    7.0    5.0    5.0    0.0    9.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    0.1935483870967742   78 / 403
0.0    1.0    2.0    0.0    322.0  5.0    13.0   2.0    0.0    0.0    4.0    2.0    0.0    0.0    0.0    1.0    4.0    6.0    4.0    0.0    1.0    0.0    0.0    2.0    0.0    14.0   0.15926892950391644  61 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    12.0   6.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    329.0  0.0    0.0    0.0    0.125                47 / 376
0.0    6.0    1.0    9.0    7.0    1.0    0.0    1.0    0.0    2.0    8.0    4.0    0.0    0.0    2.0    1.0    8.0    1.0    4.0    5.0    5.0    0.0    0.0    315.0  8.0    6.0    0.20050761421319796  79 / 394
0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    2.0    5.0    0.0    3.0    26.0   1.0    28.0   2.0    0.0    314.0  0.0    0.2010178117048346   79 / 393
1.0    0.0    0.0    1.0    32.0   0.0    0.0    0.0    3.0    17.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    32.0   1.0    0.0    0.0    0.0    2.0    0.0    274.0  0.25340599455040874  93 / 367
395.0  487.0  352.0  425.0  452.0  344.0  361.0  304.0  322.0  368.0  369.0  343.0  405.0  380.0  417.0  402.0  367.0  432.0  319.0  392.0  402.0  370.0  419.0  402.0  388.0  386.0  0.21213635909227233  2,122 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787864
2    0.881835
3    0.918624
4    0.937219
5    0.951415
6    0.961711
7    0.96781
8    0.973108
9    0.978806
10   0.984605

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22248474028688262
RMSE: 0.4716828810619298
LogLoss: 0.7486037600707075
Mean Per-Class Error: 0.2141553975120802
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13     14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   2.0    0.0   0.0    0.0   2.0    0.0    0.07865168539325842  7 / 89
0.0   83.0   0.0   1.0    2.0    0.0   1.0   1.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    1.0    10.0   3.0   0.0   0.0    1.0   0.0    2.0   0.0    0.0    0.2169811320754717   23 / 106
0.0   0.0    60.0  0.0    2.0    0.0   8.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    3.0   0.0    0.0    0.0    1.0   1.0   0.0    0.0   1.0    0.0   0.0    1.0    0.2682926829268293   22 / 82
3.0   2.0    0.0   93.0   0.0    0.0   1.0   1.0   0.0   1.0    0.0    0.0   1.0   2.0    2.0   1.0    0.0    2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0    0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    77.0   3.0   2.0   0.0   0.0   0.0    2.0    1.0   0.0   0.0    0.0   0.0    1.0    2.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    8.0    0.20618556701030927  20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   4.0   0.0   0.0    0.0    0.0   2.0   2.0    2.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   82.0   0.0   0.0    0.0    0.10869565217391304  10 / 92
0.0   2.0    0.0   3.0    3.0    0.0   0.0   1.0   0.0   0.0    3.0    2.0   0.0   0.0    0.0   0.0    2.0    1.0    1.0   1.0   1.0    0.0   0.0    75.0  4.0    1.0    0.25                 25 / 100
0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0   8.0   1.0    8.0   2.0    0.0   84.0   0.0    0.21495327102803738  23 / 107
0.0   0.0    0.0   1.0    9.0    0.0   0.0   0.0   1.0   5.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    7.0   0.0   0.0    0.0   0.0    0.0   0.0    64.0   0.26436781609195403  23 / 87
94.0  121.0  73.0  120.0  105.0  73.0  80.0  80.0  74.0  106.0  100.0  90.0  86.0  104.0  84.0  114.0  101.0  110.0  81.0  95.0  101.0  82.0  105.0  96.0  113.0  102.0  0.21204819277108433  528 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787952
2    0.886345
3    0.916867
4    0.934137
5    0.952209
6    0.960643
7    0.966667
8    0.971888
9    0.976305
10   0.985542
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:59  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:59  37.303 sec  63738 obs/sec     1         1             10007      0.669922         1.40517             0.992026       0.382685                         0.666902           1.39342               0.992075         0.377108
    2019-07-23 13:32:00  38.439 sec  78671 obs/sec     10        10            100070     0.47106          0.75318             0.996057       0.212136                         0.471683           0.748604              0.996036         0.212048
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0987522
C13         0.932847               0.932847             0.0921207
C12         0.833934               0.833934             0.0823529
C9          0.825858               0.825858             0.0815553
C8          0.797206               0.797206             0.0787259
C7          0.767738               0.767738             0.0758158
C11         0.764169               0.764169             0.0754634
C14         0.598219               0.598219             0.0590755
C16         0.592249               0.592249             0.0584859
C10         0.583359               0.583359             0.057608
C6          0.544553               0.544553             0.0537759
C5          0.477582               0.477582             0.0471623
C3          0.394322               0.394322             0.0389401
C4          0.391061               0.391061             0.0386181
C1          0.332282               0.332282             0.0328136
C2          0.290973               0.290973             0.0287342
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_39

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  ------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011354617242318454  0.0003562441561371088  0.0         -0.0019075593972956995  0.5819201469421387  -0.041286346291978984  0.6819536685943604
    3        26       Softmax                 0.0   0.0   0.002202170480394181   0.0004089061403647065  0.0         -0.03794771796786405    0.7336647510528564  -0.5255622960898096    0.21870219707489014


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2219233623038066
RMSE: 0.47108742532974346
LogLoss: 0.749109092480013
Mean Per-Class Error: 0.20891529843346912
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    2.0    0.0    0.0    2.0    0.0    0.0    9.0    5.0    0.0    5.0    0.0    0.0    0.0    1.0    1.0    1.0    1.0    1.0    0.0    6.0    2.0    7.0    0.0    0.10886075949367088  43 / 395
1.0    314.0  0.0    10.0   0.0    2.0    3.0    8.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    20.0   8.0    0.0    0.0    5.0    1.0    2.0    1.0    1.0    0.1801566579634465   69 / 383
0.0    0.0    300.0  0.0    8.0    0.0    22.0   2.0    0.0    0.0    24.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    3.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
2.0    13.0   0.0    326.0  0.0    3.0    0.0    6.0    0.0    5.0    0.0    0.0    7.0    4.0    2.0    3.0    1.0    12.0   1.0    1.0    2.0    0.0    0.0    4.0    1.0    10.0   0.19106699751861042  77 / 403
0.0    12.0   1.0    0.0    287.0  1.0    28.0   0.0    1.0    0.0    7.0    1.0    0.0    0.0    2.0    0.0    0.0    3.0    12.0   2.0    0.0    0.0    0.0    7.0    0.0    20.0   0.2526041666666667   97 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    11.0   0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    15.0   2.0    2.0    0.0    1.0    1.0    0.0    0.0    3.0    2.0    331.0  0.0    0.0    0.0    0.1196808510638298   45 / 376
0.0    2.0    0.0    3.0    7.0    0.0    1.0    3.0    0.0    1.0    8.0    1.0    0.0    0.0    0.0    0.0    8.0    2.0    1.0    9.0    0.0    1.0    0.0    333.0  3.0    11.0   0.1548223350253807   61 / 394
1.0    0.0    1.0    0.0    0.0    7.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    6.0    8.0    0.0    0.0    33.0   2.0    39.0   0.0    0.0    291.0  0.0    0.2576530612244898   101 / 392
0.0    1.0    0.0    0.0    8.0    2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    33.0   4.0    0.0    0.0    0.0    1.0    4.0    298.0  0.1880108991825613   69 / 367
426.0  489.0  350.0  439.0  357.0  364.0  408.0  356.0  330.0  378.0  395.0  343.0  421.0  365.0  364.0  373.0  322.0  406.0  337.0  376.0  388.0  416.0  412.0  402.0  367.0  419.0  0.20823752874137758  2,083 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791763
2    0.876737
3    0.913826
4    0.935919
5    0.950415
6    0.960312
7    0.969809
8    0.976107
9    0.980706
10   0.984705

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22193738234931668
RMSE: 0.471102305608152
LogLoss: 0.7537618629704226
Mean Per-Class Error: 0.20856584173462941
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10     11    12    13    14    15     16    17    18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    1.0   1.0   1.0   0.0   0.0    0.0   2.0    1.0    3.0    0.0    0.12359550561797752  11 / 89
0.0   82.0   0.0   2.0    0.0   0.0   2.0    3.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0   6.0   4.0   0.0   0.0    3.0   1.0    1.0    1.0    0.0    0.22641509433962265  24 / 106
0.0   0.0    67.0  0.0    1.0   0.0   4.0    0.0   0.0   0.0    6.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0   1.0   0.0   1.0    0.0   1.0    0.0    0.0    0.0    0.18292682926829268  15 / 82
2.0   3.0    0.0   91.0   0.0   1.0   0.0    2.0   0.0   2.0    0.0    0.0   3.0   0.0   2.0   2.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0    0.1875               21 / 112
0.0   3.0    0.0   0.0    70.0  1.0   7.0    0.0   0.0   0.0    3.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   4.0   1.0   0.0    0.0   0.0    1.0    0.0    6.0    0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   2.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0    0.0   4.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0   0.0    0.0   83.0   0.0    0.0    0.0    0.09782608695652174  9 / 92
0.0   0.0    0.0   2.0    3.0   0.0   1.0    1.0   0.0   0.0    5.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    82.0   1.0    4.0    0.18                 18 / 100
0.0   0.0    1.0   0.0    0.0   1.0   1.0    0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   2.0    2.0   0.0   0.0   8.0   1.0    10.0  0.0    0.0    81.0   0.0    0.24299065420560748  26 / 107
0.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   0.0   5.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   1.0   0.0    0.0   0.0    1.0    1.0    71.0   0.1839080459770115   16 / 87
95.0  123.0  76.0  128.0  81.0  86.0  104.0  86.0  77.0  106.0  104.0  92.0  90.0  97.0  75.0  108.0  80.0  97.0  87.0  87.0  101.0  95.0  103.0  101.0  109.0  102.0  0.20923694779116467  521 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790763
2    0.882731
3    0.912851
4    0.935743
5    0.950603
6    0.960643
7    0.969478
8    0.974699
9    0.977912
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:08  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:09  1 min 46.991 sec  77573 obs/sec     1         1             10007      0.671625         1.39401             0.991984       0.384285                         0.666134           1.36802               0.992093         0.376305
    2019-07-23 13:33:10  1 min 48.107 sec  81890 obs/sec     10        10            100070     0.471087         0.749109            0.996056       0.208238                         0.471102           0.753762              0.996045         0.209237
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.104507
C13         0.889547               0.889547             0.0929639
C12         0.803558               0.803558             0.0839775
C8          0.737032               0.737032             0.077025
C7          0.718018               0.718018             0.0750379
C9          0.673837               0.673837             0.0704208
C11         0.657668               0.657668             0.0687309
C16         0.595899               0.595899             0.0622757
C10         0.593098               0.593098             0.0619829
C6          0.57849                0.57849              0.0604563
C14         0.541775               0.541775             0.0566193
C5          0.507085               0.507085             0.052994
C4          0.410036               0.410036             0.0428516
C3          0.385035               0.385035             0.0402389
C1          0.252196               0.252196             0.0263563
C2          0.225458               0.225458             0.0235619
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_53

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011399278297403725  0.00032164063304662704  0.0         -0.019842162585518963  0.5796058177947998  0.060543906823191204  0.685957670211792
    3        26       Softmax                 0.0   0.0   0.0022587833156229374  0.0005720232147723436   0.0         0.011823079943077084   0.7379715442657471  -0.5498466726289416   0.28086137771606445


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22592623118919888
RMSE: 0.4753169796979684
LogLoss: 0.7503200104512079
Mean Per-Class Error: 0.21046548771238832
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    4.0    0.0    1.0    0.0    1.0    1.0    8.0    0.0    0.0    0.0    4.0    1.0    7.0    1.0    0.08883248730964467  35 / 394
0.0    292.0  0.0    11.0   2.0    2.0    9.0    6.0    3.0    1.0    4.0    0.0    2.0    0.0    4.0    4.0    2.0    20.0   10.0   0.0    0.0    2.0    0.0    5.0    4.0    0.0    0.23759791122715404  91 / 383
0.0    0.0    295.0  0.0    6.0    1.0    12.0   1.0    0.0    0.0    25.0   0.0    0.0    0.0    10.0   0.0    2.0    0.0    4.0    2.0    4.0    0.0    6.0    0.0    0.0    0.0    0.1983695652173913   73 / 368
5.0    12.0   0.0    330.0  0.0    2.0    0.0    5.0    0.0    0.0    0.0    4.0    4.0    5.0    10.0   1.0    1.0    13.0   1.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.1791044776119403   72 / 402
0.0    10.0   4.0    1.0    278.0  9.0    25.0   0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    18.0   4.0    0.0    0.0    0.0    4.0    1.0    16.0   0.2760416666666667   106 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    13.0   2.0    4.0    1.0    0.0    0.0    0.0    0.0    1.0    2.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    1.0    0.0    10.0   1.0    0.0    1.0    2.0    3.0    4.0    17.0   1.0    0.0    0.0    2.0    1.0    5.0    4.0    6.0    3.0    3.0    1.0    0.0    311.0  6.0    12.0   0.21065989847715735  83 / 394
0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    10.0   6.0    0.0    2.0    30.0   3.0    31.0   0.0    1.0    298.0  1.0    0.24173027989821882  95 / 393
0.0    0.0    0.0    1.0    16.0   1.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    23.0   2.0    0.0    0.0    0.0    3.0    1.0    309.0  0.15803814713896458  58 / 367
408.0  447.0  325.0  429.0  338.0  366.0  390.0  333.0  333.0  335.0  427.0  325.0  424.0  382.0  417.0  404.0  364.0  409.0  348.0  402.0  390.0  384.0  433.0  422.0  358.0  410.0  0.2096371088673398   2,097 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790363
2    0.877737
3    0.915525
4    0.937619
5    0.951715
6    0.961712
7    0.969809
8    0.976407
9    0.981006
10   0.984605

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22711570344447185
RMSE: 0.4765665781865865
LogLoss: 0.7541430963074279
Mean Per-Class Error: 0.21113131021966683
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6      7     8     9     10     11    12    13     14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0    0.07865168539325842  7 / 89
0.0    76.0   0.0   3.0    2.0   0.0   5.0    2.0   1.0   0.0   1.0    0.0   0.0   0.0    3.0   1.0    0.0   7.0    1.0   0.0   0.0   2.0   0.0    1.0   1.0    0.0    0.2830188679245283   30 / 106
0.0    0.0    63.0  0.0    1.0   0.0   2.0    0.0   0.0   0.0   6.0    0.0   0.0   0.0    4.0   0.0    1.0   0.0    1.0   1.0   1.0   0.0   2.0    0.0   0.0    0.0    0.23170731707317074  19 / 82
4.0    0.0    0.0   93.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    2.0   1.0   3.0    2.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0    0.16964285714285715  19 / 112
0.0    1.0    1.0   0.0    66.0  5.0   7.0    0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0    6.0   1.0   0.0   0.0   0.0    2.0   0.0    4.0    0.31958762886597936  31 / 97
---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   87.0   0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0    0.0    0.0   6.0    1.0   0.0   0.0    1.0   0.0   1.0   8.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   0.0   0.0   0.0   0.0    71.0  2.0    6.0    0.29                 29 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   4.0    1.0   0.0    0.0   8.0   1.0   10.0  0.0    1.0   80.0   0.0    0.2523364485981308   27 / 107
0.0    0.0    0.0   0.0    6.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    3.0   0.0   0.0   0.0   0.0    1.0   1.0    74.0   0.14942528735632185  13 / 87
100.0  103.0  67.0  122.0  81.0  88.0  102.0  86.0  75.0  95.0  109.0  89.0  90.0  105.0  87.0  115.0  92.0  105.0  87.0  96.0  96.0  89.0  106.0  98.0  100.0  107.0  0.21124497991967872  526 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788755
2    0.875502
3    0.918072
4    0.934137
5    0.947791
6    0.960241
7    0.969076
8    0.973896
9    0.978715
10   0.983132
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:48  2 min 26.691 sec  79420 obs/sec     1         1             10007      0.673517         1.41456             0.991937       0.373188                         0.674396           1.41326               0.991896         0.376305
    2019-07-23 13:33:50  2 min 27.953 sec  73204 obs/sec     10        10            100070     0.475317         0.75032             0.995985       0.209637                         0.476567           0.754143              0.995953         0.211245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0963427
C9          0.93095                0.93095              0.0896902
C13         0.919161               0.919161             0.0885545
C7          0.841355               0.841355             0.0810584
C12         0.757158               0.757158             0.0729467
C8          0.75649                0.75649              0.0728823
C11         0.690904               0.690904             0.0665636
C14         0.681259               0.681259             0.0656343
C10         0.667305               0.667305             0.06429
C16         0.655788               0.655788             0.0631804
C6          0.532316               0.532316             0.0512847
C5          0.496354               0.496354             0.0478201
C3          0.449177               0.449177             0.043275
C4          0.370536               0.370536             0.0356984
C2          0.341794               0.341794             0.0329294
C1          0.289065               0.289065             0.0278493
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_46

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015699536105557854  0.0003218975616618991  0.0         0.022200700432268405   0.7658035755157471  0.09512121069353797  0.7169702053070068
    3        26       Softmax                 0.0   0.0   0.00185467235255251    0.0002847032155841589  0.0         -0.014309176688562695  0.3809323310852051  -0.5595337324926211  0.26476025581359863


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21955441533849518
RMSE: 0.46856634038148237
LogLoss: 0.7457117548852321
Mean Per-Class Error: 0.21592992815476475
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    6.0    0.0    3.0    0.0    5.0    0.0    7.0    0.0    1.0    0.0    4.0    2.0    5.0    0.0    0.09620253164556962  38 / 395
0.0    304.0  0.0    6.0    2.0    2.0    2.0    15.0   2.0    0.0    6.0    0.0    0.0    0.0    3.0    2.0    0.0    19.0   13.0   0.0    0.0    5.0    0.0    1.0    1.0    0.0    0.206266318537859    79 / 383
0.0    0.0    294.0  0.0    16.0   2.0    15.0   0.0    0.0    0.0    19.0   1.0    1.0    0.0    5.0    1.0    1.0    1.0    4.0    2.0    3.0    0.0    3.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
5.0    12.0   0.0    326.0  0.0    2.0    0.0    4.0    1.0    2.0    1.0    0.0    5.0    4.0    7.0    10.0   0.0    14.0   5.0    1.0    1.0    0.0    0.0    2.0    0.0    1.0    0.19106699751861042  77 / 403
0.0    1.0    0.0    0.0    278.0  7.0    39.0   2.0    1.0    0.0    11.0   1.0    0.0    0.0    0.0    1.0    1.0    2.0    12.0   4.0    0.0    0.0    0.0    3.0    0.0    21.0   0.2760416666666667   106 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    1.0    0.0    12.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    3.0    3.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    1.0    0.0    6.0    6.0    1.0    0.0    2.0    2.0    0.0    10.0   1.0    0.0    0.0    2.0    0.0    8.0    2.0    13.0   5.0    3.0    0.0    0.0    325.0  3.0    3.0    0.17302798982188294  68 / 393
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    3.0    0.0    3.0    22.0   5.0    19.0   2.0    1.0    322.0  0.0    0.1806615776081425   71 / 393
2.0    0.0    0.0    1.0    13.0   1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    37.0   4.0    0.0    0.0    0.0    0.0    0.0    296.0  0.19346049046321526  71 / 367
413.0  468.0  336.0  423.0  370.0  371.0  371.0  351.0  326.0  354.0  401.0  341.0  442.0  377.0  369.0  401.0  343.0  438.0  344.0  397.0  405.0  384.0  411.0  396.0  383.0  388.0  0.21473557932620213  2,148 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785264
2    0.878736
3    0.914226
4    0.93492
5    0.950915
6    0.959912
7    0.96811
8    0.975208
9    0.980706
10   0.985105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22213377104527365
RMSE: 0.4713106948131706
LogLoss: 0.7558172246826708
Mean Per-Class Error: 0.21698902858029354
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0    3.0    0.0    0.07865168539325842  7 / 89
0.0   78.0   0.0   0.0    1.0   0.0   1.0   7.0   1.0   0.0    1.0    0.0   0.0   0.0   2.0   1.0    0.0   7.0    2.0   0.0   0.0    3.0   0.0    1.0    1.0    0.0    0.2641509433962264   28 / 106
0.0   0.0    64.0  0.0    2.0   1.0   4.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0    2.0   2.0   1.0    0.0   1.0    0.0    0.0    0.0    0.21951219512195122  18 / 82
3.0   3.0    0.0   92.0   0.0   0.0   0.0   2.0   1.0   0.0    0.0    0.0   2.0   1.0   0.0   2.0    0.0   4.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0    0.17857142857142858  20 / 112
0.0   0.0    0.0   0.0    68.0  5.0   9.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0   1.0   0.0    0.0   0.0    0.0    0.0    9.0    0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    3.0   0.0   0.0   1.0   0.0   0.0    4.0    1.0   0.0   0.0   0.0   0.0    2.0   0.0    2.0   0.0   1.0    0.0   0.0    81.0   1.0    1.0    0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   4.0    1.0   0.0    0.0   7.0   1.0    4.0   2.0    0.0    87.0   0.0    0.18691588785046728  20 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    6.0   2.0   0.0    0.0   0.0    0.0    0.0    71.0   0.1839080459770115   16 / 87
99.0  109.0  72.0  116.0  86.0  85.0  89.0  98.0  76.0  102.0  101.0  92.0  98.0  97.0  75.0  114.0  87.0  110.0  79.0  97.0  103.0  88.0  105.0  103.0  106.0  103.0  0.21686746987951808  540 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783133
2    0.880321
3    0.916867
4    0.932932
5    0.949799
6    0.958233
7    0.96506
8    0.972691
9    0.978715
10   0.983936
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:26  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:27  2 min  4.985 sec  37200 obs/sec     1         1             10007      0.591752         1.11916             0.993777       0.307408                         0.5912             1.11397               0.993772         0.308835
    2019-07-23 13:33:29  2 min  7.671 sec  34495 obs/sec     10        10            100070     0.468566         0.745712            0.996099       0.214736                         0.471311           0.755817              0.996042         0.216867
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0867416
C9          0.935239               0.935239             0.0811242
C13         0.93335                0.93335              0.0809603
C12         0.932955               0.932955             0.080926
C11         0.840604               0.840604             0.0729154
C8          0.805638               0.805638             0.0698823
C7          0.786121               0.786121             0.0681894
C14         0.697987               0.697987             0.0605445
C10         0.665995               0.665995             0.0577695
C3          0.642065               0.642065             0.0556937
C6          0.613488               0.613488             0.0532149
C4          0.601159               0.601159             0.0521455
C5          0.581947               0.581947             0.050479
C16         0.579157               0.579157             0.050237
C2          0.481736               0.481736             0.0417865
C1          0.431053               0.431053             0.0373902
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_37

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.00155579398261807    0.0003733929479494691   0.0         -0.011048180806881192  0.7622470855712891  0.0366184104192671   0.6918284893035889
    3        26       Softmax                 0.0   0.0   0.0018655743680518265  0.00030679721385240555  0.0         0.005132034381677368   0.3845423460006714  -0.5478537156596948  0.2525085210800171


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2176028303966445
RMSE: 0.4664791853841332
LogLoss: 0.7387255305512045
Mean Per-Class Error: 0.21326727153008695
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    3.0    2.0    0.0    8.0    0.0    0.0    0.0    2.0    1.0    7.0    2.0    1.0    0.0    3.0    3.0    6.0    0.0    0.10379746835443038  41 / 395
0.0    318.0  0.0    7.0    3.0    4.0    1.0    4.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    26.0   3.0    0.0    0.0    2.0    1.0    3.0    5.0    0.0    0.16971279373368145  65 / 383
0.0    0.0    291.0  0.0    13.0   3.0    11.0   1.0    0.0    0.0    25.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    7.0    6.0    3.0    0.0    4.0    0.0    0.0    0.0    0.20923913043478262  77 / 368
7.0    17.0   0.0    333.0  0.0    2.0    0.0    1.0    0.0    4.0    0.0    0.0    6.0    5.0    1.0    3.0    0.0    14.0   1.0    1.0    2.0    0.0    0.0    5.0    1.0    0.0    0.17369727047146402  70 / 403
0.0    4.0    0.0    0.0    300.0  5.0    11.0   0.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    10.0   6.0    9.0    7.0    0.0    0.0    0.0    2.0    0.0    19.0   0.21671018276762402  83 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    1.0    0.0    19.0   1.0    1.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    3.0    0.0    7.0    9.0    2.0    0.0    4.0    6.0    1.0    7.0    2.0    0.0    0.0    2.0    0.0    14.0   2.0    11.0   8.0    3.0    0.0    0.0    304.0  3.0    6.0    0.22842639593908629  90 / 394
1.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    9.0    0.0    2.0    56.0   1.0    14.0   2.0    0.0    302.0  0.0    0.23155216284987276  91 / 393
1.0    0.0    0.0    0.0    16.0   2.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    33.0   7.0    0.0    0.0    0.0    2.0    0.0    294.0  0.1989100817438692   73 / 367
417.0  496.0  358.0  443.0  392.0  375.0  306.0  290.0  335.0  351.0  382.0  330.0  448.0  355.0  386.0  368.0  370.0  484.0  351.0  465.0  403.0  358.0  413.0  368.0  378.0  381.0  0.2123362991102669   2,124 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787664
2    0.876537
3    0.914026
4    0.935419
5    0.953314
6    0.963311
7    0.970209
8    0.976507
9    0.981506
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22242787709104006
RMSE: 0.47162260027594105
LogLoss: 0.756945549276463
Mean Per-Class Error: 0.21995416536976856
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16    17     18    19     20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    0.0   1.0    2.0   3.0    0.0   0.12359550561797752  11 / 89
0.0   82.0   0.0   2.0    2.0   1.0   1.0   1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   10.0   0.0   0.0    0.0    1.0   1.0    1.0   2.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    62.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0   6.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    3.0   1.0    1.0    0.0   1.0    0.0   0.0    0.0   0.24390243902439024  20 / 82
3.0   5.0    0.0   93.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   3.0   1.0   1.0   1.0    0.0   1.0    0.0   0.0    1.0    0.0   0.0    1.0   0.0    0.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    70.0  3.0   3.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0    3.0   1.0    2.0   3.0    0.0    0.0   0.0    1.0   0.0    8.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    4.0   1.0   0.0   2.0   1.0   0.0   4.0   1.0   0.0   0.0   0.0   0.0    3.0   0.0    3.0   1.0    0.0    0.0   0.0    75.0  0.0    2.0   0.25                 25 / 100
1.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    4.0   0.0    0.0   11.0   0.0    4.0   1.0    0.0   83.0   0.0   0.22429906542056074  24 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    6.0   3.0    0.0    0.0   0.0    1.0   0.0    68.0  0.21839080459770116  19 / 87
97.0  118.0  78.0  129.0  90.0  87.0  79.0  75.0  77.0  97.0  95.0  88.0  98.0  93.0  77.0  101.0  96.0  125.0  88.0  111.0  103.0  79.0  109.0  91.0  111.0  98.0  0.22008032128514057  548 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.77992
2    0.872691
3    0.913253
4    0.931325
5    0.948996
6    0.961044
7    0.965462
8    0.973494
9    0.979518
10   0.986345
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:03  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:03  1 min 41.863 sec  32702 obs/sec     1         1             10007      0.589029         1.11261             0.993834       0.295911                         0.588494           1.11293               0.993829         0.290763
    2019-07-23 13:33:06  1 min 44.577 sec  33739 obs/sec     10        10            100070     0.466479         0.738726            0.996133       0.212336                         0.471623           0.756946              0.996037         0.22008
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.086201
C13         0.983424               0.983424             0.0847721
C12         0.932441               0.932441             0.0803773
C9          0.910592               0.910592             0.0784939
C7          0.827893               0.827893             0.0713651
C11         0.808304               0.808304             0.0696766
C8          0.80786                0.80786              0.0696383
C10         0.749017               0.749017             0.064566
C14         0.73183                0.73183              0.0630845
C16         0.626082               0.626082             0.0539689
C6          0.608699               0.608699             0.0524705
C3          0.583742               0.583742             0.0503191
C4          0.569977               0.569977             0.0491325
C5          0.568752               0.568752             0.049027
C2          0.4659                 0.4659               0.040161
C1          0.426285               0.426285             0.0367462
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_63

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias           bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007465681378562294  0.00018591067055240273  0.0         -0.011943432933662734  0.28031253814697266  0.2296486432355582  0.17753541469573975
    3        26       Softmax                      0.0   0.0   0.0043319049302506475  0.008746549487113953    0.0         -0.3790371720166989    0.8860561847686768   -0.46225688093622   0.33343565464019775


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22801025623921145
RMSE: 0.47750419499645386
LogLoss: 0.7511779383060598
Mean Per-Class Error: 0.21215872243506145
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    2.0    0.0    0.0    2.0    4.0    0.0    10.0   4.0    1.0    6.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0    1.0    2.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    307.0  0.0    1.0    0.0    0.0    3.0    10.0   2.0    0.0    10.0   1.0    1.0    0.0    3.0    2.0    0.0    24.0   11.0   1.0    0.0    2.0    0.0    2.0    3.0    0.0    0.19843342036553524  76 / 383
1.0    0.0    300.0  0.0    12.0   4.0    13.0   1.0    0.0    0.0    21.0   0.0    0.0    0.0    4.0    0.0    4.0    0.0    3.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
2.0    24.0   0.0    320.0  0.0    3.0    0.0    9.0    1.0    6.0    1.0    4.0    4.0    7.0    2.0    1.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    7.0    0.0    2.0    0.20595533498759305  83 / 403
0.0    13.0   5.0    0.0    288.0  2.0    17.0   1.0    0.0    0.0    6.0    2.0    0.0    0.0    0.0    0.0    5.0    4.0    13.0   5.0    0.0    0.0    0.0    5.0    1.0    17.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    14.0   2.0    0.0    0.0    0.0    12.0   0.0    0.0    3.0    2.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
1.0    3.0    0.0    10.0   9.0    0.0    0.0    3.0    5.0    1.0    7.0    1.0    0.0    0.0    4.0    0.0    7.0    1.0    13.0   3.0    1.0    0.0    0.0    315.0  7.0    3.0    0.20050761421319796  79 / 394
0.0    0.0    0.0    0.0    1.0    5.0    0.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    7.0    29.0   1.0    18.0   1.0    0.0    322.0  0.0    0.17857142857142858  70 / 392
3.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    1.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    27.0   1.0    0.0    0.0    0.0    8.0    1.0    294.0  0.1989100817438692   73 / 367
424.0  504.0  349.0  404.0  380.0  354.0  358.0  337.0  353.0  372.0  399.0  347.0  451.0  383.0  336.0  370.0  346.0  472.0  361.0  387.0  381.0  360.0  409.0  404.0  383.0  379.0  0.2114365690292912   2,115 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788563
2    0.874138
3    0.911627
4    0.93362
5    0.947516
6    0.960012
7    0.96791
8    0.974608
9    0.979106
10   0.983005

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22987349418110528
RMSE: 0.4794512427568681
LogLoss: 0.7605967658523803
Mean Per-Class Error: 0.2197016032088815
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22    23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   1.0   2.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    2.0    0.0   0.07865168539325842  7 / 89
0.0    75.0   0.0   1.0    0.0   0.0   1.0   5.0   1.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   10.0   5.0   1.0   0.0   1.0   0.0   1.0    0.0    0.0   0.29245283018867924  31 / 106
0.0    0.0    65.0  0.0    0.0   2.0   4.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    1.0   0.0   1.0   0.0   1.0   0.0    0.0    0.0   0.2073170731707317   17 / 82
1.0    2.0    0.0   92.0   0.0   1.0   0.0   4.0   0.0   2.0    0.0   2.0   2.0   2.0    0.0   1.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    1.0   0.17857142857142858  20 / 112
0.0    2.0    0.0   0.0    70.0  2.0   6.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0   2.0   0.0   0.0   0.0   2.0    0.0    6.0   0.27835051546391754  27 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0   2.0   81.0  0.0    0.0    0.0   0.11956521739130435  11 / 92
0.0    1.0    0.0   3.0    2.0   0.0   0.0   1.0   0.0   0.0    2.0   1.0   0.0   0.0    1.0   0.0    2.0   1.0    6.0   0.0   0.0   0.0   0.0   76.0   3.0    1.0   0.24                 24 / 100
0.0    0.0    0.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   8.0   0.0   5.0   1.0   0.0    88.0   0.0   0.17757009345794392  19 / 107
1.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   3.0    1.0    67.0  0.22988505747126436  20 / 87
109.0  116.0  73.0  118.0  87.0  87.0  93.0  82.0  83.0  105.0  98.0  90.0  98.0  102.0  63.0  110.0  89.0  122.0  96.0  92.0  96.0  82.0  98.0  101.0  108.0  92.0  0.2176706827309237   542 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782329
2    0.875502
3    0.911245
4    0.93012
5    0.944177
6    0.954618
7    0.964257
8    0.970281
9    0.977108
10   0.982731
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:06  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:06  2 min 44.593 sec  98107 obs/sec     1         1             10007      0.701983         1.51804             0.991244       0.407978                         0.699747           1.50178               0.991275         0.408835
    2019-07-23 13:34:07  2 min 45.350 sec  119272 obs/sec    10        10            100070     0.477504         0.751178            0.995948       0.211437                         0.479451           0.760597              0.995904         0.217671
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0986043
C13         0.913203               0.913203             0.0900457
C9          0.847665               0.847665             0.0835834
C8          0.775119               0.775119             0.0764301
C12         0.722848               0.722848             0.0712759
C7          0.674762               0.674762             0.0665344
C10         0.599558               0.599558             0.059119
C5          0.592075               0.592075             0.0583812
C11         0.584706               0.584706             0.0576546
C14         0.569711               0.569711             0.0561759
C6          0.545232               0.545232             0.0537622
C3          0.535107               0.535107             0.0527638
C4          0.528731               0.528731             0.0521351
C16         0.512938               0.512938             0.0505779
C1          0.393584               0.393584             0.0388091
C2          0.346307               0.346307             0.0341474
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_57

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.00133108584270758   0.0003502580802887678   0.0         0.026340019194549313   0.7319366931915283   0.18555000375666533   0.664696216583252
    3        26       Softmax                 0.0   0.0   0.001914395028157182  0.00039069901686161757  0.0         -0.015654272128533472  0.49559199810028076  -0.46627850757130673  0.23557370901107788


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2179842960555808
RMSE: 0.46688788381749724
LogLoss: 0.734817073701951
Mean Per-Class Error: 0.21105278751112494
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    3.0    0.0    3.0    0.0    4.0    3.0    2.0    0.0    2.0    0.0    3.0    0.0    6.0    6.0    0.09620253164556962  38 / 395
0.0    302.0  0.0    5.0    3.0    1.0    2.0    14.0   2.0    0.0    2.0    0.0    0.0    0.0    5.0    6.0    7.0    18.0   9.0    0.0    1.0    1.0    1.0    2.0    1.0    1.0    0.21148825065274152  81 / 383
0.0    0.0    298.0  0.0    12.0   1.0    17.0   0.0    0.0    0.0    20.0   0.0    0.0    0.0    4.0    0.0    1.0    0.0    5.0    3.0    3.0    0.0    4.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
5.0    15.0   0.0    325.0  1.0    0.0    0.0    5.0    0.0    6.0    0.0    0.0    5.0    6.0    7.0    2.0    2.0    11.0   5.0    0.0    1.0    0.0    0.0    4.0    1.0    2.0    0.1935483870967742   78 / 403
0.0    7.0    2.0    0.0    294.0  3.0    13.0   0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    1.0    13.0   5.0    10.0   5.0    0.0    0.0    0.0    4.0    0.0    17.0   0.23237597911227154  89 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    2.0    0.0    18.0   4.0    10.0   0.0    0.0    3.0    0.0    0.0    2.0    0.0    330.0  0.0    0.0    0.0    0.12234042553191489  46 / 376
0.0    11.0   0.0    5.0    6.0    0.0    1.0    2.0    2.0    1.0    12.0   1.0    0.0    0.0    1.0    0.0    9.0    0.0    15.0   4.0    3.0    0.0    0.0    312.0  6.0    3.0    0.20812182741116753  82 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    2.0    9.0    0.0    5.0    40.0   4.0    18.0   1.0    1.0    299.0  0.0    0.23918575063613232  94 / 393
3.0    0.0    0.0    1.0    10.0   0.0    0.0    2.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    40.0   5.0    0.0    0.0    0.0    2.0    0.0    296.0  0.19346049046321526  71 / 367
407.0  480.0  334.0  411.0  387.0  341.0  356.0  307.0  320.0  340.0  403.0  319.0  434.0  382.0  439.0  398.0  447.0  407.0  358.0  416.0  408.0  357.0  396.0  394.0  390.0  372.0  0.2102369289213236   2,103 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789763
2    0.879736
3    0.915026
4    0.937519
5    0.952014
6    0.961712
7    0.970109
8    0.975707
9    0.982005
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22321713519193437
RMSE: 0.4724586068556
LogLoss: 0.7608120982773531
Mean Per-Class Error: 0.2223201295871629
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16     17    18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   1.0   0.0   3.0    1.0   0.06741573033707865  6 / 89
0.0   78.0   0.0   1.0    2.0   1.0   1.0   4.0   1.0   0.0   2.0    0.0   0.0   0.0   2.0   1.0    2.0    5.0   2.0   0.0   1.0    1.0   1.0   1.0   0.0    0.0   0.2641509433962264   28 / 106
0.0   0.0    62.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0   2.0   0.0    0.0    0.0   2.0   2.0   1.0    0.0   1.0   0.0   0.0    0.0   0.24390243902439024  20 / 82
3.0   5.0    0.0   91.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   2.0   2.0   2.0   0.0    2.0    2.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.1875               21 / 112
0.0   1.0    0.0   0.0    72.0  1.0   3.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0    3.0    1.0   3.0   2.0   0.0    0.0   0.0   0.0   0.0    7.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   4.0   1.0   1.0   0.0    0.0    2.0   0.0   0.0   0.0    0.0   83.0  0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0   3.0    0.0   2.0    3.0   0.0   0.0   2.0   1.0   0.0   5.0    1.0   0.0   0.0   0.0   0.0    2.0    0.0   5.0   1.0   1.0    0.0   0.0   73.0  0.0    1.0   0.27                 27 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   2.0   0.0    3.0    0.0   0.0   9.0   2.0    5.0   1.0   0.0   83.0   0.0   0.22429906542056074  24 / 107
0.0   0.0    0.0   1.0    3.0   0.0   0.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0   0.0    0.0    0.0   6.0   2.0   0.0    0.0   0.0   1.0   0.0    71.0  0.1839080459770115   16 / 87
97.0  120.0  72.0  119.0  95.0  74.0  76.0  85.0  76.0  96.0  108.0  87.0  99.0  98.0  94.0  115.0  117.0  93.0  92.0  97.0  105.0  83.0  97.0  93.0  113.0  89.0  0.221285140562249    551 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.778715
2    0.873494
3    0.906024
4    0.931727
5    0.948193
6    0.960241
7    0.969478
8    0.975904
9    0.981928
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:56  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:56  2 min 34.826 sec  47652 obs/sec     1         1             10007      0.602988         1.17551             0.993538       0.312306                         0.603587           1.17722               0.993508         0.31004
    2019-07-23 13:33:58  2 min 36.633 sec  50796 obs/sec     10        10            100070     0.466888         0.734817            0.996126       0.210237                         0.472459           0.760812              0.996023         0.221285
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0896344
C13         0.985923               0.985923             0.0883726
C12         0.887368               0.887368             0.0795387
C9          0.856601               0.856601             0.0767809
C8          0.779547               0.779547             0.0698743
C7          0.765561               0.765561             0.0686206
C11         0.757863               0.757863             0.0679306
C10         0.711618               0.711618             0.0637855
C14         0.705452               0.705452             0.0632328
C16         0.658883               0.658883             0.0590586
C5          0.611117               0.611117             0.0547771
C3          0.568954               0.568954             0.0509979
C6          0.553745               0.553745             0.0496346
C4          0.496981               0.496981             0.0445466
C1          0.415969               0.415969             0.0372851
C2          0.400847               0.400847             0.0359297
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_8

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013598451581628979  0.0003752670018002391  0.0         0.02779245091323901    0.7408590316772461  0.16485306968341124  0.8066451549530029
    3        26       Softmax                 0.0   0.0   0.001905588931409651   0.0003049600636586547  0.0         -0.005807731063842316  0.498191237449646   -0.4538464030813526  0.21727079153060913


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2255653510229784
RMSE: 0.4749372074527099
LogLoss: 0.7497165164201585
Mean Per-Class Error: 0.21958195511743264
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    6.0    3.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    2.0    2.0    1.0    5.0    2.0    0.09137055837563451  36 / 394
1.0    279.0  0.0    7.0    3.0    2.0    2.0    8.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    39.0   25.0   0.0    1.0    5.0    0.0    2.0    4.0    0.0    0.2696335078534031   103 / 382
0.0    0.0    290.0  0.0    24.0   2.0    5.0    4.0    0.0    0.0    18.0   0.0    1.0    0.0    5.0    0.0    4.0    0.0    5.0    2.0    6.0    1.0    1.0    0.0    0.0    0.0    0.21195652173913043  78 / 368
0.0    17.0   0.0    318.0  0.0    0.0    0.0    4.0    2.0    6.0    0.0    0.0    3.0    11.0   2.0    3.0    0.0    20.0   4.0    1.0    0.0    0.0    0.0    8.0    1.0    3.0    0.2109181141439206   85 / 403
0.0    6.0    1.0    0.0    297.0  3.0    12.0   0.0    2.0    0.0    3.0    2.0    0.0    0.0    0.0    1.0    7.0    4.0    10.0   6.0    2.0    0.0    0.0    13.0   1.0    14.0   0.2265625            87 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    1.0    15.0   0.0    0.0    0.0    0.0    6.0    9.0    6.0    0.0    0.0    2.0    0.0    0.0    5.0    0.0    330.0  0.0    0.0    0.0    0.12234042553191489  46 / 376
0.0    0.0    1.0    8.0    10.0   1.0    1.0    2.0    4.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    7.0    1.0    10.0   1.0    3.0    1.0    0.0    325.0  10.0   4.0    0.1751269035532995   69 / 394
1.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    2.0    35.0   2.0    13.0   1.0    0.0    318.0  1.0    0.19083969465648856  75 / 393
0.0    0.0    0.0    0.0    11.0   2.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    31.0   11.0   0.0    0.0    0.0    7.0    0.0    286.0  0.22070844686648503  81 / 367
436.0  426.0  367.0  417.0  417.0  393.0  301.0  339.0  344.0  381.0  333.0  341.0  414.0  389.0  372.0  364.0  367.0  483.0  341.0  410.0  405.0  372.0  394.0  425.0  403.0  369.0  0.21853443966809957  2,186 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781466
2    0.876737
3    0.915126
4    0.937719
5    0.951515
6    0.961512
7    0.969709
8    0.976207
9    0.981905
10   0.986204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22793132573084687
RMSE: 0.4774215388216653
LogLoss: 0.7608141879768353
Mean Per-Class Error: 0.22298712109400534
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19     20     21    22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   1.0    1.0    2.0    1.0   0.07865168539325842  7 / 89
0.0    72.0   0.0   2.0    0.0   0.0   2.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   14.0   6.0   0.0    1.0    4.0   0.0    1.0    0.0    0.0   0.32075471698113206  34 / 106
0.0    0.0    59.0  0.0    4.0   2.0   2.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    2.0   1.0    1.0    1.0   0.0    0.0    0.0    0.0   0.2804878048780488   23 / 82
0.0    2.0    0.0   89.0   0.0   0.0   0.0   4.0   1.0   2.0    0.0   0.0   1.0   3.0    1.0   2.0    0.0   4.0    0.0   0.0    0.0    0.0   0.0    1.0    0.0    2.0   0.20535714285714285  23 / 112
0.0    2.0    0.0   0.0    69.0  2.0   5.0   0.0   1.0   0.0    1.0   1.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   4.0    0.0    0.0   0.0    2.0    0.0    5.0   0.28865979381443296  28 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   1.0   2.0    0.0   0.0    0.0   1.0    0.0   0.0    2.0    0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0    0.0    0.0   2.0    4.0   0.0   0.0   1.0   1.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   0.0    1.0    0.0   0.0    82.0   2.0    1.0   0.18                 18 / 100
1.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0   0.0    0.0   8.0    0.0    4.0   1.0    0.0    88.0   0.0   0.17757009345794392  19 / 107
0.0    0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   3.0    0.0    0.0   0.0    3.0    0.0    71.0  0.1839080459770115   16 / 87
104.0  104.0  75.0  117.0  90.0  88.0  71.0  83.0  79.0  108.0  81.0  94.0  89.0  102.0  80.0  106.0  93.0  123.0  88.0  103.0  106.0  87.0  101.0  111.0  109.0  98.0  0.22208835341365463  553 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.777912
2    0.873092
3    0.916466
4    0.934137
5    0.951807
6    0.960643
7    0.968675
8    0.974699
9    0.981526
10   0.985141
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:49  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:49  27.351 sec  52947 obs/sec     1         1             10007      0.604892         1.16087             0.993496       0.318105                         0.602048           1.1466                0.993541         0.311647
    2019-07-23 13:31:51  29.241 sec  48981 obs/sec     10        10            100070     0.474937         0.749717            0.995991       0.218534                         0.477422           0.760814              0.995939         0.222088
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0878315
C12         0.976099               0.976099             0.0857322
C15         0.923547               0.923547             0.0811165
C9          0.838581               0.838581             0.0736538
C8          0.831129               0.831129             0.0729993
C11         0.754716               0.754716             0.0662878
C7          0.724015               0.724015             0.0635913
C16         0.715023               0.715023             0.0628015
C14         0.694155               0.694155             0.0609687
C6          0.677415               0.677415             0.0594984
C10         0.648663               0.648663             0.056973
C5          0.595471               0.595471             0.0523011
C3          0.588789               0.588789             0.0517142
C4          0.575975               0.575975             0.0505887
C1          0.45212                0.45212              0.0397103
C2          0.38974                0.38974              0.0342314
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_30

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0016084139082011006  0.0003443802706897259  0.0         0.029267267395482577  0.76932692527771     0.014823887093354367  0.7159409523010254
    3        26       Softmax                 0.0   0.0   0.0018753091777188485  0.0003195590106770396  0.0         0.007617893289285313  0.38457274436950684  -0.5555598330173945   0.3283790349960327


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21905967371127708
RMSE: 0.468038111387606
LogLoss: 0.7461100577360299
Mean Per-Class Error: 0.21027252410223735
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  2.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    2.0    2.0    0.0    7.0    0.0    2.0    0.0    1.0    1.0    6.0    0.0    3.0    0.0    3.0    1.0    6.0    0.0    0.09620253164556962  38 / 395
0.0    330.0  0.0    8.0    2.0    0.0    3.0    5.0    3.0    0.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    19.0   2.0    0.0    1.0    1.0    0.0    3.0    3.0    0.0    0.13838120104438642  53 / 383
0.0    1.0    289.0  0.0    17.0   1.0    22.0   1.0    0.0    0.0    14.0   1.0    0.0    0.0    4.0    0.0    4.0    0.0    6.0    1.0    4.0    0.0    3.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
4.0    27.0   0.0    314.0  0.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    5.0    7.0    13.0   1.0    0.0    12.0   3.0    0.0    1.0    0.0    0.0    9.0    0.0    0.0    0.22084367245657568  89 / 403
0.0    8.0    1.0    0.0    291.0  1.0    16.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    6.0    10.0   9.0    0.0    0.0    0.0    10.0   1.0    21.0   0.2421875            93 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    7.0    1.0    5.0    0.0    1.0    6.0    0.0    0.0    3.0    5.0    338.0  0.0    1.0    0.0    0.10106382978723404  38 / 376
1.0    4.0    0.0    3.0    9.0    0.0    5.0    2.0    5.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    10.0   7.0    7.0    3.0    2.0    0.0    0.0    318.0  8.0    5.0    0.19289340101522842  76 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    14.0   0.0    2.0    14.0   4.0    24.0   1.0    0.0    324.0  0.0    0.17557251908396945  69 / 393
0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    9.0    1.0    27.0   6.0    0.0    0.0    0.0    4.0    0.0    302.0  0.1771117166212534   65 / 367
406.0  560.0  332.0  414.0  388.0  347.0  364.0  264.0  326.0  345.0  348.0  332.0  414.0  391.0  426.0  364.0  416.0  453.0  331.0  375.0  405.0  377.0  425.0  408.0  417.0  375.0  0.2092372288313506   2,093 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790763
2    0.878137
3    0.914326
4    0.936019
5    0.952714
6    0.963211
7    0.971409
8    0.977407
9    0.982005
10   0.986804

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22431511180029007
RMSE: 0.47361916325280806
LogLoss: 0.7608854840285355
Mean Per-Class Error: 0.2189272579035047
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   86.0   0.0   2.0    1.0   0.0   2.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0    8.0    0.0   0.0   1.0    1.0   0.0    2.0   1.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    60.0  0.0    4.0   0.0   6.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    1.0    0.0    3.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.2682926829268293   22 / 82
2.0   4.0    0.0   88.0   0.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   2.0   2.0    5.0   1.0    0.0    3.0    1.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.21428571428571427  24 / 112
0.0   2.0    0.0   0.0    72.0  1.0   7.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    2.0    2.0   4.0   0.0    0.0   0.0    2.0   0.0    4.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   2.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
1.0   1.0    0.0   2.0    5.0   0.0   1.0   2.0   1.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    2.0    2.0    1.0   1.0   0.0    0.0   0.0    73.0  4.0    2.0   0.27                 27 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    7.0    0.0    0.0   6.0   2.0    6.0   1.0    0.0   82.0   0.0   0.2336448598130841   25 / 107
0.0   0.0    0.0   1.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0    0.0    5.0   3.0   0.0    0.0   0.0    0.0   0.0    69.0  0.20689655172413793  18 / 87
96.0  137.0  70.0  116.0  92.0  78.0  92.0  74.0  75.0  103.0  86.0  90.0  90.0  105.0  90.0  104.0  107.0  109.0  83.0  95.0  106.0  86.0  110.0  91.0  115.0  90.0  0.21807228915662652  543 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781928
2    0.875502
3    0.916466
4    0.937751
5    0.953012
6    0.957831
7    0.966667
8    0.974297
9    0.981124
10   0.987148
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:49  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:50  1 min 28.022 sec  27045 obs/sec     1         1             10007      0.590099         1.12449             0.993813       0.302209                         0.592133           1.13121               0.993752         0.306827
    2019-07-23 13:32:52  1 min 30.750 sec  32874 obs/sec     10        10            100070     0.468038         0.74611             0.996108       0.209237                         0.473619           0.760885              0.996003         0.218072
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.089387
C13         0.972519               0.972519             0.0869305
C9          0.961724               0.961724             0.0859655
C12         0.868068               0.868068             0.0775939
C7          0.788206               0.788206             0.0704553
C11         0.777542               0.777542             0.0695021
C8          0.771984               0.771984             0.0690053
C14         0.664811               0.664811             0.0594254
C10         0.647223               0.647223             0.0578533
C6          0.628064               0.628064             0.0561407
C3          0.586217               0.586217             0.0524002
C16         0.568188               0.568188             0.0507886
C5          0.554264               0.554264             0.0495439
C4          0.550628               0.550628             0.0492189
C2          0.456998               0.456998             0.0408496
C1          0.390881               0.390881             0.0349397
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_90

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011138335009945877  0.0002945770975202322  0.0         0.0002569013480524518  0.5580086708068848  0.04947844610532193  0.7002208232879639
    3        26       Softmax                 0.0   0.0   0.0021976103933131807  0.0004369729431346059  0.0         -0.022986077475322348  0.7380273342132568  -0.5198833909236065  0.24617552757263184


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2197692600577248
RMSE: 0.46879554184924244
LogLoss: 0.7422709019649225
Mean Per-Class Error: 0.21084650540196395
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  1.0    0.0    0.0    0.0    1.0    1.0    2.0    0.0    2.0    6.0    0.0    6.0    0.0    2.0    0.0    1.0    2.0    7.0    0.0    0.0    2.0    2.0    2.0    5.0    0.0    0.1065989847715736   42 / 394
0.0    305.0  0.0    8.0    4.0    0.0    3.0    5.0    1.0    0.0    3.0    0.0    6.0    0.0    0.0    0.0    2.0    22.0   16.0   0.0    0.0    1.0    0.0    5.0    2.0    0.0    0.20365535248041775  78 / 383
0.0    0.0    288.0  0.0    13.0   0.0    13.0   0.0    0.0    0.0    24.0   0.0    1.0    1.0    5.0    0.0    6.0    0.0    11.0   3.0    0.0    0.0    3.0    0.0    0.0    0.0    0.21739130434782608  80 / 368
1.0    33.0   0.0    322.0  0.0    0.0    0.0    10.0   0.0    5.0    7.0    0.0    5.0    4.0    4.0    0.0    0.0    6.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.20099255583126552  81 / 403
0.0    4.0    3.0    0.0    310.0  4.0    20.0   0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    7.0    2.0    0.0    0.0    0.0    2.0    0.0    19.0   0.1906005221932115   73 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    6.0    0.0    0.0    10.0   0.0    0.0    1.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    7.0    0.0    6.0    14.0   0.0    0.0    2.0    2.0    0.0    4.0    0.0    0.0    2.0    2.0    0.0    0.0    1.0    15.0   1.0    5.0    2.0    0.0    326.0  3.0    2.0    0.17258883248730963  68 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    1.0    10.0   9.0    0.0    1.0    21.0   0.0    38.0   3.0    0.0    300.0  1.0    0.2366412213740458   93 / 393
1.0    2.0    0.0    0.0    21.0   0.0    0.0    1.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    11.0   1.0    40.0   3.0    0.0    0.0    0.0    3.0    0.0    279.0  0.23978201634877383  88 / 367
402.0  498.0  318.0  394.0  457.0  360.0  388.0  274.0  325.0  349.0  406.0  338.0  430.0  379.0  423.0  369.0  359.0  498.0  382.0  368.0  380.0  406.0  404.0  404.0  348.0  344.0  0.2098370488853344   2,099 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790163
2    0.879136
3    0.912926
4    0.93232
5    0.947116
6    0.958312
7    0.96591
8    0.972908
9    0.979306
10   0.983405

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2260229895771003
RMSE: 0.47541875181475574
LogLoss: 0.7636730405793919
Mean Per-Class Error: 0.2163931313876142
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20    21    22     23     24    25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  -----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0   1.0   1.0    1.0    2.0   0.0   0.10112359550561797  9 / 89
0.0   82.0   0.0   2.0    2.0    0.0   1.0   2.0   0.0   0.0    1.0    0.0   1.0   0.0   0.0   0.0    1.0   8.0    4.0    0.0   0.0   1.0   0.0    1.0    0.0   0.0   0.22641509433962265  24 / 106
0.0   0.0    59.0  0.0    2.0    0.0   4.0   0.0   0.0   0.0    8.0    0.0   0.0   1.0   2.0   0.0    2.0   0.0    3.0    1.0   0.0   0.0   0.0    0.0    0.0   0.0   0.2804878048780488   23 / 82
1.0   6.0    0.0   89.0   0.0    0.0   0.0   5.0   0.0   1.0    3.0    0.0   2.0   1.0   1.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.20535714285714285  23 / 112
0.0   0.0    1.0   0.0    76.0   1.0   5.0   0.0   1.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   1.0    3.0    0.0   0.0   0.0   0.0    1.0    0.0   7.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0    0.0   2.0   0.0   1.0   0.0    0.0   2.0    0.0    0.0   0.0   1.0   85.0   0.0    0.0   0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   2.0    3.0    0.0   0.0   1.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    5.0    0.0   2.0   0.0   0.0    81.0   0.0   2.0   0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0   0.0   4.0    3.0   0.0    0.0    4.0   0.0   11.0  1.0    0.0    81.0  0.0   0.24299065420560748  26 / 107
0.0   0.0    0.0   0.0    8.0    0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    10.0   1.0   0.0   0.0   0.0    0.0    0.0   64.0  0.26436781609195403  23 / 87
94.0  127.0  64.0  108.0  107.0  78.0  88.0  77.0  74.0  100.0  104.0  90.0  97.0  99.0  87.0  102.0  92.0  130.0  105.0  90.0  97.0  92.0  103.0  103.0  96.0  86.0  0.21606425702811244  538 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783936
2    0.875502
3    0.91245
4    0.93012
5    0.946185
6    0.956225
7    0.964257
8    0.972289
9    0.979518
10   0.984337
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:18  3 min 56.543 sec  82024 obs/sec     1         1             10007      0.660092         1.35461             0.992256       0.36539                          0.659078           1.35483               0.99226          0.363052
    2019-07-23 13:35:19  3 min 57.766 sec  75524 obs/sec     10        10            100070     0.468796         0.742271            0.996094       0.209837                         0.475419           0.763673              0.995973         0.216064
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.097357
C15         0.991775               0.991775             0.0965563
C12         0.861806               0.861806             0.0839028
C9          0.767742               0.767742             0.074745
C7          0.746067               0.746067             0.0726349
C8          0.740892               0.740892             0.072131
C10         0.726455               0.726455             0.0707254
C11         0.664868               0.664868             0.0647295
C16         0.661383               0.661383             0.0643902
C14         0.606954               0.606954             0.0590912
C6          0.510909               0.510909             0.0497405
C5          0.482285               0.482285             0.0469538
C4          0.438024               0.438024             0.0426447
C3          0.392912               0.392912             0.0382527
C2          0.341457               0.341457             0.0332433
C1          0.337949               0.337949             0.0329017
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_54

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007747106340616483  0.0001635508961044252  0.0         -0.01718060495468876  0.2895526885986328  0.09709107476611811  0.22698593139648438
    3        26       Softmax                      0.0   0.0   0.005063031767629302   0.011039391160011292   0.0         -0.36942880155888463  0.8787755966186523  -0.5912787936797032  0.44092798233032227


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2566261682244633
RMSE: 0.5065828345142217
LogLoss: 0.8109130776713486
Mean Per-Class Error: 0.22034981685977756
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    4.0    1.0    2.0    0.0    3.0    0.0    10.0   0.0    1.0    6.0    3.0    1.0    3.0    0.0    0.09620253164556962  38 / 395
0.0    325.0  0.0    10.0   1.0    0.0    1.0    0.0    3.0    1.0    1.0    0.0    0.0    0.0    3.0    6.0    1.0    13.0   8.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.1514360313315927   58 / 383
0.0    0.0    296.0  0.0    13.0   1.0    15.0   0.0    0.0    0.0    24.0   0.0    1.0    0.0    2.0    0.0    2.0    0.0    5.0    2.0    2.0    0.0    5.0    0.0    0.0    0.0    0.1956521739130435   72 / 368
1.0    32.0   0.0    318.0  0.0    1.0    0.0    6.0    1.0    5.0    1.0    1.0    7.0    4.0    5.0    4.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    4.0    0.2109181141439206   85 / 403
0.0    12.0   5.0    0.0    281.0  1.0    8.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    3.0    14.0   3.0    16.0   2.0    0.0    0.0    0.0    6.0    0.0    17.0   0.2643979057591623   101 / 382
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    15.0   8.0    0.0    1.0    0.0    1.0    0.0    0.0    2.0    1.0    328.0  0.0    0.0    0.0    0.1276595744680851   48 / 376
0.0    4.0    0.0    7.0    5.0    0.0    0.0    0.0    6.0    1.0    10.0   1.0    0.0    0.0    0.0    1.0    10.0   0.0    11.0   2.0    6.0    1.0    0.0    317.0  8.0    4.0    0.19543147208121828  77 / 394
0.0    1.0    0.0    1.0    1.0    7.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    1.0    13.0   0.0    10.0   16.0   2.0    52.0   1.0    0.0    284.0  0.0    0.27735368956743     109 / 393
2.0    1.0    0.0    0.0    16.0   2.0    0.0    0.0    1.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    29.0   1.0    0.0    0.0    0.0    1.0    0.0    297.0  0.1907356948228883   70 / 367
406.0  552.0  368.0  433.0  370.0  331.0  321.0  291.0  342.0  348.0  435.0  319.0  430.0  367.0  360.0  441.0  392.0  395.0  359.0  354.0  404.0  450.0  426.0  378.0  336.0  395.0  0.2194341697490753   2,195 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780566
2    0.873538
3    0.908627
4    0.930321
5    0.946716
6    0.957013
7    0.96631
8    0.972108
9    0.976307
10   0.979906

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.25865667299392125
RMSE: 0.5085830050187691
LogLoss: 0.814722066410858
Mean Per-Class Error: 0.22780752723741265
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16     17    18    19    20    21     22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0    1.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   2.0    0.0    1.0   2.0   0.0    0.10112359550561797  9 / 89
0.0   86.0   0.0   0.0    1.0   0.0   1.0   0.0   1.0   0.0    1.0    0.0   0.0    0.0   2.0   2.0    0.0    4.0   2.0   0.0   0.0   5.0    0.0    1.0   0.0   0.0    0.18867924528301888  20 / 106
0.0   0.0    62.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0    5.0    0.0   0.0    0.0   1.0   0.0    0.0    0.0   3.0   1.0   0.0   0.0    2.0    0.0   0.0   0.0    0.24390243902439024  20 / 82
1.0   3.0    0.0   91.0   0.0   1.0   0.0   2.0   1.0   1.0    1.0    1.0   3.0    1.0   1.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0    2.0   0.0   2.0    0.1875               21 / 112
0.0   2.0    0.0   0.0    66.0  1.0   1.0   0.0   0.0   0.0    7.0    0.0   0.0    0.0   0.0   0.0    4.0    1.0   5.0   1.0   0.0   0.0    0.0    1.0   0.0   8.0    0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0    0.0    0.0   4.0    0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    84.0   0.0   0.0   0.0    0.08695652173913043  8 / 92
0.0   2.0    0.0   3.0    2.0   0.0   0.0   0.0   2.0   0.0    4.0    1.0   0.0    0.0   0.0   0.0    2.0    0.0   5.0   0.0   1.0   0.0    0.0    75.0  2.0   1.0    0.25                 25 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0   1.0   1.0    5.0    0.0   1.0   4.0   0.0   17.0   1.0    0.0   73.0  0.0    0.3177570093457944   34 / 107
0.0   0.0    0.0   0.0    5.0   1.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0   5.0   0.0   0.0   0.0    0.0    1.0   0.0   71.0   0.1839080459770115   16 / 87
93.0  133.0  75.0  121.0  85.0  78.0  76.0  74.0  85.0  102.0  113.0  89.0  102.0  98.0  74.0  123.0  107.0  94.0  85.0  86.0  99.0  116.0  100.0  87.0  86.0  109.0  0.22690763052208834  565 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773092
2    0.871486
3    0.903614
4    0.928112
5    0.945381
6    0.956627
7    0.965462
8    0.972289
9    0.9751
10   0.977912
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:50  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:50  2 min 28.065 sec  129961 obs/sec    1         1             10007      0.738976         1.62215             0.990295       0.428172                         0.740265           1.62418               0.990236         0.427711
    2019-07-23 13:33:50  2 min 28.702 sec  143985 obs/sec    10        10            100070     0.506583         0.810913            0.995439       0.219434                         0.508583           0.814722              0.995391         0.226908
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0915692
C13         0.953828               0.953828             0.0873412
C9          0.8981                 0.8981               0.0822382
C12         0.833136               0.833136             0.0762896
C8          0.805231               0.805231             0.0737344
C7          0.741441               0.741441             0.0678931
C11         0.720454               0.720454             0.0659714
C10         0.676296               0.676296             0.0619278
C5          0.637918               0.637918             0.0584136
C14         0.633452               0.633452             0.0580046
C4          0.581491               0.581491             0.0532466
C6          0.562856               0.562856             0.0515403
C3          0.557449               0.557449             0.0510452
C16         0.530313               0.530313             0.0485603
C1          0.401402               0.401402             0.036756
C2          0.38734                0.38734              0.0354684
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_91

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007683695112064015  0.00018725136760622263  0.0         -0.01949875262914702  0.2804781198501587  0.07173600798111002  0.2262309193611145
    3        26       Softmax                      0.0   0.0   0.004671197020588107   0.010799583047628403    0.0         -0.4051464975897873   0.8732130527496338  -0.5833589894056761  0.4708763360977173


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2732749198656659
RMSE: 0.522757037126872
LogLoss: 0.8520392190758028
Mean Per-Class Error: 0.22942461161754626
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    9.0    3.0    0.0    8.0    0.0    1.0    0.0    2.0    0.0    7.0    1.0    1.0    3.0    2.0    4.0    2.0    0.0    0.11392405063291139  45 / 395
0.0    301.0  0.0    6.0    1.0    0.0    3.0    4.0    3.0    0.0    1.0    0.0    1.0    0.0    4.0    4.0    1.0    26.0   12.0   0.0    1.0    3.0    2.0    8.0    2.0    0.0    0.21409921671018275  82 / 383
0.0    0.0    307.0  2.0    10.0   0.0    8.0    1.0    0.0    0.0    19.0   0.0    1.0    1.0    5.0    0.0    1.0    0.0    1.0    3.0    4.0    0.0    5.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
2.0    19.0   0.0    308.0  0.0    0.0    0.0    9.0    0.0    7.0    4.0    0.0    8.0    2.0    4.0    5.0    0.0    8.0    7.0    0.0    0.0    0.0    0.0    19.0   0.0    0.0    0.23383084577114427  94 / 402
0.0    3.0    1.0    0.0    305.0  1.0    17.0   0.0    1.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    7.0    4.0    20.0   0.0    0.0    0.0    0.0    6.0    0.0    12.0   0.20572916666666666  79 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    16.0   0.0    0.0    3.0    0.0    12.0   4.0    1.0    0.0    0.0    5.0    0.0    0.0    2.0    1.0    331.0  0.0    0.0    0.0    0.1196808510638298   45 / 376
0.0    4.0    0.0    0.0    10.0   0.0    1.0    8.0    1.0    2.0    5.0    3.0    0.0    0.0    0.0    0.0    12.0   1.0    22.0   3.0    3.0    0.0    0.0    315.0  1.0    3.0    0.20050761421319796  79 / 394
0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    20.0   0.0    9.0    35.0   6.0    30.0   1.0    1.0    281.0  0.0    0.28498727735368956  112 / 393
10.0   0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    31.0   3.0    0.0    0.0    0.0    3.0    0.0    305.0  0.16893732970027248  62 / 367
407.0  468.0  385.0  419.0  390.0  342.0  307.0  298.0  336.0  347.0  393.0  328.0  458.0  367.0  417.0  375.0  348.0  414.0  436.0  391.0  394.0  380.0  421.0  456.0  347.0  379.0  0.22883135059482154  2,289 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.771169
2    0.86684
3    0.904129
4    0.926422
5    0.941318
6    0.952814
7    0.962111
8    0.969309
9    0.975307
10   0.979906

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2737282895129209
RMSE: 0.5231904906560524
LogLoss: 0.8548045996189166
Mean Per-Class Error: 0.23653206354180673
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12     13     14    15     16    17     18     19    20     21    22     23     24    25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  ----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   3.0    0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    1.0   1.0    1.0    2.0   0.0   0.11235955056179775  10 / 89
0.0   77.0   0.0   0.0    1.0    0.0   2.0   1.0   1.0   0.0    1.0   0.0   0.0    0.0    3.0   0.0    1.0   10.0   2.0    0.0   1.0    2.0   1.0    3.0    0.0   0.0   0.27358490566037735  29 / 106
0.0   0.0    67.0  1.0    2.0    0.0   2.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0    2.0   0.0    0.0   0.0    0.0    1.0   1.0    0.0   2.0    0.0    0.0   0.0   0.18292682926829268  15 / 82
2.0   3.0    0.0   86.0   0.0    0.0   0.0   4.0   0.0   3.0    1.0   0.0   3.0    1.0    0.0   2.0    0.0   1.0    4.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0   0.23214285714285715  26 / 112
0.0   0.0    0.0   0.0    75.0   1.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0    0.0   0.0    3.0   1.0    6.0    0.0   0.0    0.0   0.0    2.0    0.0   4.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0    2.0    0.0   0.0    0.0   1.0    0.0    0.0   1.0    0.0   85.0   0.0    0.0   0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   0.0    4.0    0.0   1.0   3.0   0.0   0.0    2.0   0.0   0.0    0.0    0.0   0.0    3.0   1.0    7.0    0.0   0.0    0.0   0.0    75.0   0.0   2.0   0.25                 25 / 100
0.0   0.0    0.0   0.0    1.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    1.0   1.0    9.0   0.0    0.0    9.0   2.0    8.0   1.0    0.0    74.0  0.0   0.308411214953271    33 / 107
2.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0    6.0    0.0   0.0    0.0   0.0    1.0    0.0   72.0  0.1724137931034483   15 / 87
97.0  111.0  83.0  116.0  101.0  74.0  83.0  77.0  79.0  103.0  94.0  88.0  103.0  104.0  79.0  107.0  93.0  108.0  110.0  89.0  101.0  91.0  102.0  108.0  92.0  97.0  0.23654618473895583  589 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.763454
2    0.863855
3    0.904418
4    0.924498
5    0.940562
6    0.952209
7    0.961446
8    0.969076
9    0.974297
10   0.978715
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:19  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:19  3 min 57.881 sec  131671 obs/sec    1         1             10007      0.735965         1.65248             0.990375       0.43177                          0.736209           1.64898               0.990342         0.433333
    2019-07-23 13:35:20  3 min 58.504 sec  147161 obs/sec    10        10            100070     0.522757         0.852039            0.995144       0.228831                         0.52319            0.854805              0.995123         0.236546
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.09769
C9          0.915516               0.915516             0.0894368
C13         0.87083                0.87083              0.0850714
C12         0.7401                 0.7401               0.0723004
C11         0.738036               0.738036             0.0720988
C8          0.733948               0.733948             0.0716994
C6          0.637369               0.637369             0.0622646
C7          0.633407               0.633407             0.0618775
C16         0.597368               0.597368             0.0583569
C14         0.583738               0.583738             0.0570254
C3          0.5288                 0.5288               0.0516585
C5          0.508696               0.508696             0.0496945
C4          0.498695               0.498695             0.0487175
C10         0.482446               0.482446             0.0471302
C1          0.456826               0.456826             0.0446273
C2          0.310684               0.310684             0.0303507
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_40

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007445606643159408  0.0001898786867968738  0.0         -0.015701350408903636  0.2752647399902344  0.11690827156609496  0.21375662088394165
    3        26       Softmax                      0.0   0.0   0.0050804835371029465  0.011515136808156967   0.0         -0.36828053906125346   0.9081501960754395  -0.6131581547346945  0.45498907566070557


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.26968623361503263
RMSE: 0.5193132326592811
LogLoss: 0.8488969525790576
Mean Per-Class Error: 0.2288464541856737
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    0.0    2.0    4.0    1.0    3.0    3.0    0.09367088607594937  37 / 395
0.0    305.0  0.0    9.0    3.0    0.0    4.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    6.0    4.0    1.0    27.0   12.0   0.0    0.0    2.0    1.0    4.0    0.0    0.0    0.20365535248041775  78 / 383
0.0    0.0    291.0  0.0    28.0   1.0    7.0    2.0    0.0    0.0    22.0   0.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0    9.0    0.0    0.0    3.0    0.0    0.0    0.0    0.20923913043478262  77 / 368
6.0    16.0   0.0    322.0  0.0    0.0    0.0    0.0    2.0    3.0    6.0    0.0    8.0    2.0    2.0    1.0    0.0    12.0   5.0    0.0    2.0    0.0    0.0    13.0   1.0    1.0    0.19900497512437812  80 / 402
0.0    17.0   11.0   1.0    276.0  2.0    12.0   0.0    1.0    0.0    7.0    1.0    0.0    0.0    2.0    0.0    7.0    4.0    3.0    0.0    1.0    0.0    0.0    9.0    1.0    29.0   0.28125              108 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    6.0    8.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    4.0    0.0    7.0    11.0   0.0    0.0    0.0    4.0    1.0    8.0    0.0    1.0    0.0    0.0    0.0    8.0    1.0    10.0   3.0    3.0    1.0    0.0    325.0  6.0    1.0    0.1751269035532995   69 / 394
0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    6.0    0.0    11.0   17.0   3.0    38.0   2.0    0.0    307.0  0.0    0.21882951653944022  86 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    41.0   0.0    0.0    0.0    0.0    2.0    0.0    305.0  0.16893732970027248  62 / 367
396.0  490.0  396.0  439.0  389.0  325.0  320.0  236.0  350.0  359.0  431.0  339.0  456.0  371.0  371.0  383.0  345.0  427.0  371.0  379.0  368.0  371.0  455.0  416.0  391.0  429.0  0.22783165050484855  2,279 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.772168
2    0.86724
3    0.903429
4    0.926122
5    0.943417
6    0.954414
7    0.962511
8    0.971009
9    0.976207
10   0.981006

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2723640257877972
RMSE: 0.5218850695199061
LogLoss: 0.8550415071456045
Mean Per-Class Error: 0.23194267133983823
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17     18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   2.0    1.0    2.0    1.0    0.10112359550561797  9 / 89
0.0   75.0   0.0   3.0    2.0   0.0   2.0   1.0   1.0   0.0    1.0    0.0   0.0    0.0   4.0   0.0    1.0   8.0    4.0   0.0   0.0   2.0   1.0    1.0    0.0    0.0    0.29245283018867924  31 / 106
0.0   0.0    59.0  0.0    4.0   0.0   3.0   1.0   0.0   0.0    6.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0    0.0   6.0   0.0   0.0   1.0    0.0    0.0    0.0    0.2804878048780488   23 / 82
3.0   2.0    0.0   92.0   0.0   0.0   0.0   0.0   1.0   1.0    2.0    0.0   3.0    1.0   1.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0    0.17857142857142858  20 / 112
0.0   3.0    4.0   0.0    67.0  1.0   2.0   0.0   0.0   0.0    2.0    0.0   0.0    0.0   1.0   0.0    2.0   2.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    12.0   0.30927835051546393  30 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   1.0    2.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   87.0   0.0    0.0    0.0    0.05434782608695652  5 / 92
0.0   2.0    0.0   2.0    6.0   0.0   0.0   0.0   1.0   0.0    3.0    0.0   1.0    0.0   0.0   0.0    1.0   0.0    2.0   1.0   0.0   0.0   0.0    80.0   1.0    0.0    0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0    1.0   0.0    2.0   4.0   0.0   11.0  2.0    0.0    85.0   0.0    0.205607476635514    22 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    7.0   0.0   0.0   0.0   0.0    0.0    0.0    73.0   0.16091954022988506  14 / 87
93.0  115.0  81.0  118.0  93.0  72.0  82.0  70.0  84.0  100.0  107.0  90.0  103.0  97.0  76.0  111.0  91.0  113.0  92.0  95.0  90.0  87.0  113.0  100.0  104.0  113.0  0.23012048192771084  573 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.76988
2    0.86988
3    0.901205
4    0.92249
5    0.940562
6    0.95261
7    0.961847
8    0.971084
9    0.977912
10   0.981124
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:10  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:10  1 min 48.255 sec  101080 obs/sec    1         1             10007      0.751299         1.70001             0.989969       0.438069                         0.752744           1.70429               0.989904         0.453012
    2019-07-23 13:33:11  1 min 48.956 sec  128624 obs/sec    10        10            100070     0.519313         0.848897            0.995208       0.227832                         0.521885           0.855042              0.995147         0.23012
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0993513
C13         0.856414               0.856414             0.0850858
C12         0.831759               0.831759             0.0826364
C11         0.752315               0.752315             0.0747435
C8          0.740317               0.740317             0.0735514
C9          0.737379               0.737379             0.0732596
C7          0.674469               0.674469             0.0670094
C6          0.640808               0.640808             0.0636651
C10         0.537271               0.537271             0.0533786
C4          0.533707               0.533707             0.0530245
C14         0.522949               0.522949             0.0519557
C5          0.51317                0.51317              0.0509841
C3          0.501938               0.501938             0.0498682
C16         0.45763                0.45763              0.0454661
C1          0.398169               0.398169             0.0395586
C2          0.366999               0.366999             0.0364618
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_64

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight          weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  -------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009510916947306214  0.0002701663179323077  0.0         -0.0177416179335097  0.24751609563827515  0.023534847708525784  0.16758698225021362
    3        26       Softmax                      0.0   0.0   0.005400810616580342   0.013127420097589493   0.0         -0.2791524552042688  0.7370500564575195   -0.8466293890451163   0.43116629123687744


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.278283776196745
RMSE: 0.5275260905365203
LogLoss: 0.8489706872290506
Mean Per-Class Error: 0.22064098923187536
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    11.0   1.0    6.0    0.0    0.0    0.0    7.0    1.0    1.0    1.0    4.0    1.0    4.0    0.0    0.10632911392405063  42 / 395
0.0    315.0  0.0    4.0    3.0    0.0    7.0    2.0    2.0    0.0    1.0    0.0    1.0    1.0    4.0    4.0    0.0    23.0   6.0    0.0    0.0    0.0    2.0    6.0    0.0    2.0    0.17754569190600522  68 / 383
0.0    0.0    290.0  0.0    8.0    0.0    16.0   0.0    0.0    0.0    29.0   0.0    0.0    0.0    8.0    0.0    2.0    0.0    4.0    0.0    5.0    0.0    6.0    0.0    0.0    0.0    0.21195652173913043  78 / 368
3.0    23.0   0.0    320.0  0.0    0.0    2.0    7.0    0.0    3.0    0.0    0.0    3.0    8.0    2.0    0.0    0.0    16.0   2.0    1.0    0.0    0.0    0.0    12.0   0.0    1.0    0.20595533498759305  83 / 403
0.0    13.0   0.0    0.0    284.0  1.0    23.0   0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    6.0    6.0    4.0    4.0    0.0    0.0    0.0    8.0    1.0    26.0   0.2584856396866841   99 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    21.0   1.0    3.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    337.0  0.0    0.0    0.0    0.10133333333333333  38 / 375
0.0    5.0    1.0    6.0    3.0    0.0    1.0    2.0    2.0    0.0    6.0    0.0    0.0    0.0    2.0    0.0    8.0    0.0    14.0   3.0    4.0    0.0    0.0    330.0  4.0    3.0    0.16243654822335024  64 / 394
0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    18.0   0.0    10.0   38.0   1.0    13.0   1.0    0.0    305.0  0.0    0.22391857506361323  88 / 393
0.0    1.0    0.0    2.0    17.0   0.0    2.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    49.0   2.0    0.0    0.0    0.0    3.0    0.0    282.0  0.23160762942779292  85 / 367
411.0  541.0  346.0  409.0  370.0  290.0  368.0  279.0  343.0  331.0  398.0  323.0  439.0  401.0  402.0  413.0  389.0  462.0  352.0  416.0  380.0  341.0  445.0  429.0  361.0  364.0  0.21953413975807257  2,196 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780466
2    0.874938
3    0.908527
4    0.929421
5    0.947116
6    0.957513
7    0.964611
8    0.971608
9    0.977607
10   0.981506

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.27987020422513453
RMSE: 0.5290276025172359
LogLoss: 0.8555327270379137
Mean Per-Class Error: 0.2268551403341021
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16     17     18    19     20    21    22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -----  ----  ----  -----  -----  -----  ----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0   1.0    0.0   0.0    0.0    0.0    1.0   0.0    0.0   1.0   1.0    0.0    2.0    0.0   0.11235955056179775  10 / 89
0.0    79.0   0.0   1.0    2.0   0.0   3.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0    4.0   2.0    0.0    7.0    3.0   0.0    0.0   0.0   1.0    2.0    0.0    0.0   0.25471698113207547  27 / 106
0.0    0.0    61.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0    4.0   0.0    0.0    0.0    2.0   0.0    2.0   0.0   2.0    0.0    0.0    0.0   0.25609756097560976  21 / 82
2.0    5.0    0.0   92.0   0.0   0.0   2.0   3.0   0.0   1.0   0.0    0.0   1.0   3.0    0.0   0.0    0.0    2.0    0.0   0.0    0.0   0.0   0.0    1.0    0.0    0.0   0.17857142857142858  20 / 112
0.0    4.0    0.0   0.0    66.0  1.0   6.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0    3.0    1.0    2.0   1.0    0.0   0.0   0.0    2.0    0.0    8.0   0.31958762886597936  31 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---    ---   ---   ---    ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   5.0   1.0    0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0    2.0    1.0   1.0    1.0   0.0   1.0   1.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    4.0   0.0    1.0   0.0   0.0    81.0   1.0    1.0   0.19                 19 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0    2.0   0.0    7.0    0.0    0.0   9.0    0.0   2.0   1.0    0.0    85.0   0.0   0.205607476635514    22 / 107
0.0    0.0    0.0   1.0    5.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    12.0  1.0    0.0   0.0   0.0    1.0    0.0    66.0  0.2413793103448276   21 / 87
101.0  135.0  76.0  116.0  84.0  65.0  88.0  69.0  81.0  95.0  103.0  86.0  98.0  107.0  84.0  114.0  104.0  112.0  90.0  101.0  98.0  74.0  112.0  102.0  102.0  93.0  0.22449799196787149  559 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.775502
2    0.869478
3    0.908032
4    0.926506
5    0.945783
6    0.956225
7    0.963052
8    0.969478
9    0.975502
10   0.977912
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:07  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:07  2 min 45.489 sec  102112 obs/sec    1         1             10007      0.752086         1.65434             0.989947       0.408377                         0.753026           1.66134               0.989896         0.414056
    2019-07-23 13:34:08  2 min 46.418 sec  100270 obs/sec    10        10            100070     0.527526         0.848971            0.995054       0.219534                         0.529028           0.855533              0.995013         0.224498
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.088006
C13         0.951823               0.951823             0.0837661
C12         0.909269               0.909269             0.0800211
C9          0.889633               0.889633             0.078293
C7          0.862876               0.862876             0.0759382
C8          0.847978               0.847978             0.0746271
C11         0.738437               0.738437             0.0649868
C14         0.701768               0.701768             0.0617598
C6          0.697154               0.697154             0.0613537
C3          0.629593               0.629593             0.055408
C16         0.607331               0.607331             0.0534487
C10         0.591128               0.591128             0.0520228
C5          0.561388               0.561388             0.0494055
C4          0.546312               0.546312             0.0480787
C1          0.422915               0.422915             0.0372191
C2          0.405263               0.405263             0.0356656
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_105

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0008173662498620615  0.00020192470401525497  0.0         -0.018419009886315507  0.2944730520248413  0.04951128633607006  0.21589583158493042
    3        26       Softmax                      0.0   0.0   0.005183374555284759   0.013065949082374573    0.0         -0.4299551115696326    0.8593015670776367  -0.5914140229176985  0.4273887872695923


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2701329395782255
RMSE: 0.5197431476972308
LogLoss: 0.8475690272851767
Mean Per-Class Error: 0.2263819044534792
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    4.0    4.0    0.0    6.0    1.0    8.0    0.0    0.0    2.0    3.0    1.0    2.0    2.0    1.0    1.0    6.0    0.0    0.11392405063291139  45 / 395
0.0    317.0  0.0    8.0    3.0    0.0    2.0    2.0    3.0    0.0    4.0    0.0    4.0    0.0    0.0    2.0    2.0    19.0   9.0    0.0    0.0    1.0    2.0    4.0    0.0    0.0    0.17015706806282724  65 / 382
0.0    0.0    302.0  0.0    5.0    5.0    12.0   1.0    0.0    0.0    27.0   1.0    0.0    0.0    4.0    0.0    2.0    0.0    4.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.1771117166212534   65 / 367
6.0    23.0   0.0    315.0  0.0    0.0    0.0    3.0    1.0    10.0   0.0    1.0    6.0    1.0    6.0    3.0    0.0    6.0    0.0    0.0    6.0    0.0    0.0    16.0   0.0    0.0    0.21836228287841192  88 / 403
0.0    8.0    8.0    3.0    281.0  1.0    10.0   0.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    11.0   8.0    7.0    0.0    0.0    1.0    0.0    13.0   0.0    26.0   0.2682291666666667   103 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    8.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    24.0   1.0    0.0    0.0    1.0    2.0    0.0    0.0    2.0    0.0    329.0  0.0    0.0    0.0    0.125                47 / 376
5.0    3.0    0.0    3.0    5.0    0.0    0.0    0.0    2.0    2.0    8.0    4.0    0.0    0.0    0.0    0.0    2.0    2.0    6.0    1.0    3.0    1.0    0.0    341.0  5.0    1.0    0.13451776649746192  53 / 394
1.0    3.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    4.0    30.0   0.0    39.0   2.0    0.0    292.0  0.0    0.25510204081632654  100 / 392
4.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    28.0   2.0    0.0    0.0    0.0    4.0    0.0    301.0  0.17983651226158037  66 / 367
420.0  539.0  387.0  401.0  361.0  365.0  315.0  240.0  348.0  356.0  405.0  325.0  486.0  317.0  437.0  380.0  333.0  427.0  360.0  365.0  414.0  382.0  454.0  445.0  368.0  373.0  0.22563231030690792  2,257 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.774368
2    0.86774
3    0.909627
4    0.930921
5    0.945716
6    0.956913
7    0.96661
8    0.973408
9    0.976407
10   0.981106

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2717816031238821
RMSE: 0.5213267719232172
LogLoss: 0.8578165148442856
Mean Per-Class Error: 0.22566953980545057
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   1.0    0.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   86.0   0.0   1.0    2.0   0.0   1.0   2.0   1.0   0.0    0.0    0.0   1.0    0.0   0.0   0.0    1.0   6.0    1.0   0.0   0.0    0.0   2.0    2.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    64.0  0.0    1.0   2.0   2.0   0.0   0.0   0.0    7.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0    2.0   0.0   2.0    0.0   0.0    0.0    0.0    0.0   0.21951219512195122  18 / 82
3.0   4.0    0.0   91.0   0.0   0.0   0.0   2.0   1.0   3.0    0.0    1.0   2.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   0.0    2.0    0.0    0.0   0.1875               21 / 112
0.0   2.0    1.0   0.0    66.0  1.0   2.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0   0.0   0.0    3.0   2.0    3.0   0.0   0.0    0.0   0.0    4.0    0.0    10.0  0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   4.0    0.0   0.0   0.0    1.0   1.0    0.0   0.0   0.0    0.0   83.0   0.0    0.0    0.0   0.09782608695652174  9 / 92
1.0   1.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   0.0    4.0    3.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0    83.0   1.0    1.0   0.17                 17 / 100
0.0   2.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    4.0   0.0    0.0   6.0   0.0    13.0  2.0    0.0    77.0   0.0   0.2803738317757009   30 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    7.0   0.0   0.0    0.0   0.0    1.0    0.0    70.0  0.19540229885057472  17 / 87
99.0  138.0  82.0  109.0  86.0  88.0  72.0  62.0  83.0  105.0  102.0  93.0  109.0  86.0  93.0  106.0  94.0  104.0  91.0  81.0  102.0  90.0  114.0  109.0  101.0  91.0  0.22650602409638554  564 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773494
2    0.868675
3    0.913253
4    0.930522
5    0.946185
6    0.956627
7    0.962651
8    0.972691
9    0.974699
10   0.978313
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:01  4 min 39.519 sec  129961 obs/sec    1         1             10007      0.757282         1.68779             0.989805       0.458362                         0.757017           1.68982               0.989789         0.456225
    2019-07-23 13:36:02  4 min 40.149 sec  145662 obs/sec    10        10            100070     0.519743         0.847569            0.995198       0.225632                         0.521327           0.857817              0.995157         0.226506
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0846931
C13         0.960485               0.960485             0.0813464
C8          0.899422               0.899422             0.0761748
C12         0.879023               0.879023             0.0744471
C9          0.876163               0.876163             0.0742049
C7          0.841847               0.841847             0.0712987
C3          0.75607                0.75607              0.0640339
C6          0.751839               0.751839             0.0636756
C11         0.750319               0.750319             0.0635468
C5          0.676789               0.676789             0.0573193
C16         0.641539               0.641539             0.0543339
C14         0.610819               0.610819             0.0517322
C10         0.608856               0.608856             0.0515659
C4          0.601657               0.601657             0.0509562
C1          0.515106               0.515106             0.0436259
C2          0.437406               0.437406             0.0370452
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_43

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009460602393289719  0.0002431037719361484  0.0         -0.012375385226818025  0.24261635541915894  0.06861942497485032  0.1798490285873413
    3        26       Softmax                      0.0   0.0   0.005225049524702067   0.010660473257303238   0.0         -0.2578856357166002    0.732064962387085    -0.8493067547056583  0.4292553663253784


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.28587726036314653
RMSE: 0.5346749109161066
LogLoss: 0.8748124843756155
Mean Per-Class Error: 0.2330755456381753
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   2.0    0.0    6.0    0.0    3.0    0.0    0.0    0.0    3.0    0.0    1.0    1.0    4.0    2.0    6.0    0.0    0.09873417721518987  39 / 395
0.0    318.0  0.0    6.0    2.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    5.0    2.0    0.0    29.0   1.0    0.0    0.0    1.0    0.0    11.0   3.0    0.0    0.16971279373368145  65 / 383
0.0    0.0    302.0  0.0    20.0   0.0    6.0    2.0    0.0    0.0    22.0   1.0    0.0    0.0    4.0    0.0    1.0    0.0    3.0    2.0    0.0    0.0    5.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
5.0    18.0   0.0    315.0  0.0    0.0    1.0    4.0    1.0    4.0    0.0    0.0    5.0    4.0    4.0    4.0    0.0    12.0   3.0    0.0    0.0    0.0    0.0    22.0   0.0    0.0    0.21641791044776118  87 / 402
0.0    12.0   1.0    0.0    307.0  1.0    14.0   0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    4.0    5.0    10.0   2.0    1.0    0.0    0.0    5.0    0.0    17.0   0.20052083333333334  77 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    13.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
2.0    1.0    0.0    10.0   7.0    0.0    2.0    0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    8.0    2.0    14.0   1.0    3.0    1.0    0.0    325.0  7.0    4.0    0.1751269035532995   69 / 394
0.0    0.0    0.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    9.0    39.0   1.0    66.0   2.0    0.0    257.0  1.0    0.3460559796437659   136 / 393
2.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    41.0   2.0    0.0    0.0    0.0    10.0   0.0    288.0  0.21525885558583105  79 / 367
415.0  530.0  366.0  439.0  400.0  311.0  332.0  223.0  343.0  349.0  447.0  330.0  423.0  356.0  410.0  379.0  316.0  441.0  367.0  413.0  365.0  437.0  452.0  470.0  322.0  367.0  0.23223033090072978  2,323 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.76777
2    0.863841
3    0.904929
4    0.929121
5    0.944717
6    0.956013
7    0.96631
8    0.973908
9    0.980206
10   0.984905

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2855355023654999
RMSE: 0.5343552211455409
LogLoss: 0.8693944481067933
Mean Per-Class Error: 0.2305054240323322
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16    17     18    19    20    21     22     23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  -----  -----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0    1.0    1.0    3.0   0.0   0.10112359550561797  9 / 89
0.0   81.0   0.0   3.0    2.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   3.0   1.0    0.0   8.0    0.0   0.0   0.0   1.0    0.0    5.0    1.0   0.0   0.2358490566037736   25 / 106
0.0   0.0    61.0  0.0    5.0   0.0   3.0   1.0   0.0   0.0   6.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0    2.0   1.0   0.0   0.0    2.0    0.0    0.0   0.0   0.25609756097560976  21 / 82
3.0   2.0    0.0   90.0   0.0   0.0   1.0   2.0   1.0   1.0   0.0    0.0   1.0   3.0   1.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0    0.0    3.0    0.0   0.0   0.19642857142857142  22 / 112
0.0   2.0    0.0   0.0    71.0  1.0   3.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0    2.0   1.0    3.0   0.0   0.0   0.0    0.0    2.0    0.0   10.0  0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---    ---    ---   ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0    87.0   0.0    0.0   0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    4.0   0.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    2.0   2.0    3.0   0.0   1.0   0.0    0.0    79.0   3.0   2.0   0.21                 21 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    4.0   0.0    0.0   10.0  0.0   17.0   2.0    0.0    72.0  0.0   0.32710280373831774  35 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    8.0   1.0   0.0   0.0    0.0    3.0    0.0   67.0  0.22988505747126436  20 / 87
95.0  123.0  76.0  124.0  92.0  72.0  86.0  59.0  82.0  98.0  102.0  90.0  93.0  98.0  81.0  109.0  91.0  115.0  89.0  99.0  96.0  100.0  113.0  118.0  94.0  95.0  0.22971887550200804  572 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.770281
2    0.863855
3    0.903213
4    0.928514
5    0.943373
6    0.956627
7    0.968273
8    0.975502
9    0.980321
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:18  1 min 56.036 sec  100070 obs/sec    1         1             10007      0.75961          1.66532             0.989747       0.396581                         0.761233           1.66304               0.989675         0.403213
    2019-07-23 13:33:18  1 min 56.877 sec  109725 obs/sec    10        10            100070     0.534675         0.874812            0.99492        0.23223                          0.534355           0.869394              0.994912         0.229719
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.096446
C13         0.943882               0.943882             0.0910336
C7          0.795528               0.795528             0.0767255
C12         0.788388               0.788388             0.0760369
C8          0.779958               0.779958             0.0752238
C9          0.726046               0.726046             0.0700242
C11         0.700797               0.700797             0.0675891
C14         0.632513               0.632513             0.0610034
C10         0.619738               0.619738             0.0597712
C6          0.614609               0.614609             0.0592766
C5          0.537008               0.537008             0.0517923
C4          0.514152               0.514152             0.0495879
C3          0.505808               0.505808             0.0487831
C16         0.464772               0.464772             0.0448254
C2          0.412952               0.412952             0.0398276
C1          0.332344               0.332344             0.0320533
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_113

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 10,007 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0014962287132789243  0.0003797076642513275  0.0         0.005027958090110474  0.17922699451446533  -0.01820711825617801  0.12382873892784119
    3        26       Softmax                 0.0   0.0   0.0033817545829081678  0.0011696279980242252  0.0         0.011857502627441315  0.43837177753448486  -0.1245340594010395   0.10312744975090027


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.29963747032528487
RMSE: 0.5473915146632115
LogLoss: 0.9894540029923288
Mean Per-Class Error: 0.2745735851452689
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    1.0    0.0    3.0    1.0    7.0    0.0    0.09113924050632911  36 / 395
1.0    312.0  0.0    4.0    3.0    1.0    1.0    1.0    5.0    0.0    1.0    0.0    2.0    0.0    3.0    6.0    1.0    25.0   11.0   1.0    0.0    0.0    1.0    3.0    1.0    0.0    0.185378590078329    71 / 383
0.0    0.0    296.0  0.0    19.0   0.0    14.0   1.0    0.0    0.0    11.0   2.0    0.0    0.0    3.0    0.0    3.0    0.0    7.0    2.0    4.0    0.0    6.0    0.0    0.0    0.0    0.1956521739130435   72 / 368
8.0    25.0   0.0    321.0  0.0    0.0    0.0    1.0    1.0    7.0    0.0    0.0    7.0    3.0    11.0   4.0    0.0    6.0    4.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    0.20149253731343283  81 / 402
0.0    24.0   0.0    1.0    286.0  4.0    11.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    13.0   3.0    13.0   3.0    2.0    0.0    0.0    6.0    0.0    12.0   0.25326370757180156  97 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    6.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    3.0    0.0    21.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
1.0    7.0    0.0    20.0   13.0   1.0    6.0    0.0    8.0    1.0    2.0    1.0    0.0    0.0    4.0    1.0    8.0    1.0    5.0    5.0    9.0    0.0    0.0    295.0  5.0    1.0    0.2512690355329949   99 / 394
1.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    12.0   0.0    9.0    60.0   5.0    74.0   1.0    0.0    221.0  0.0    0.43765903307888043  172 / 393
5.0    1.0    0.0    0.0    32.0   0.0    0.0    0.0    0.0    16.0   0.0    3.0    0.0    0.0    0.0    1.0    3.0    1.0    50.0   5.0    0.0    0.0    0.0    1.0    0.0    249.0  0.3215258855585831   118 / 367
477.0  580.0  375.0  483.0  440.0  311.0  286.0  159.0  324.0  357.0  277.0  350.0  462.0  359.0  442.0  467.0  326.0  405.0  385.0  421.0  451.0  391.0  483.0  385.0  305.0  302.0  0.2727181845446366   2,728 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.727282
2    0.837749
3    0.888333
4    0.914226
5    0.93232
6    0.945916
7    0.955713
8    0.963411
9    0.970509
10   0.975307

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.29674059855207835
RMSE: 0.544739018753089
LogLoss: 0.9730625983581738
Mean Per-Class Error: 0.2766528236791374
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9      10    11    12     13     14    15     16    17     18    19    20     21    22     23    24    25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0   0.0   0.10112359550561797  9 / 89
0.0    83.0   0.0   0.0    2.0    0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0    0.0    2.0   2.0    0.0   7.0    3.0   0.0   0.0    0.0   1.0    2.0   1.0   0.0   0.2169811320754717   23 / 106
0.0    0.0    63.0  0.0    3.0    0.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0    1.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   2.0    0.0   0.0   0.0   0.23170731707317074  19 / 82
4.0    6.0    0.0   88.0   0.0    0.0   0.0   1.0   0.0   4.0    0.0   0.0   2.0    1.0    3.0   2.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.21428571428571427  24 / 112
0.0    5.0    0.0   0.0    71.0   1.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0    0.0   1.0    4.0   1.0    3.0   2.0   0.0    0.0   0.0    1.0   0.0   6.0   0.26804123711340205  26 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---                  ---
0.0    1.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    1.0   0.0   4.0    0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   85.0   0.0   0.0   0.0   0.07608695652173914  7 / 92
0.0    1.0    0.0   8.0    5.0    0.0   0.0   0.0   1.0   0.0    0.0   1.0   0.0    0.0    1.0   0.0    2.0   1.0    2.0   0.0   2.0    0.0   0.0    74.0  2.0   0.0   0.26                 26 / 100
1.0    0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   2.0    7.0   0.0    1.0   13.0  1.0    25.0  1.0    0.0   55.0  0.0   0.48598130841121495  52 / 107
1.0    0.0    0.0   0.0    9.0    0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0    0.0    0.0   1.0    1.0   0.0    11.0  2.0   0.0    0.0   0.0    1.0   0.0   57.0  0.3448275862068966   30 / 87
112.0  137.0  81.0  134.0  104.0  66.0  69.0  47.0  74.0  101.0  70.0  96.0  102.0  102.0  88.0  135.0  89.0  106.0  98.0  98.0  110.0  97.0  121.0  96.0  81.0  76.0  0.27389558232931727  682 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.726104
2    0.840161
3    0.891566
4    0.916064
5    0.934137
6    0.946988
7    0.956627
8    0.963052
9    0.968273
10   0.973896
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:19  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:19  4 min 57.834 sec  23380 obs/sec     1         1             10007      0.547392         0.989454            0.994675       0.272718                         0.544739           0.973063              0.994713         0.273896
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0786457
C13         0.958393               0.958393             0.0753736
C7          0.946522               0.946522             0.0744399
C12         0.935959               0.935959             0.0736092
C9          0.921644               0.921644             0.0724834
C11         0.832364               0.832364             0.0654619
C14         0.824204               0.824204             0.0648201
C8          0.816494               0.816494             0.0642138
C10         0.777665               0.777665             0.06116
C6          0.745446               0.745446             0.0586262
C3          0.714616               0.714616             0.0562015
C16         0.688412               0.688412             0.0541406
C5          0.655426               0.655426             0.0515464
C4          0.645083               0.645083             0.050733
C2          0.641706               0.641706             0.0504674
C1          0.611314               0.611314             0.0480772
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_15

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012838262907166609  0.00031735224183648825  0.0         0.05203135107740309    1.2118792533874512   0.24352679660116483  1.0422797203063965
    3        26       Softmax                 0.0   0.0   0.0017526580158328915  0.00018706556875258684  0.0         -0.017699643702056934  0.45360493659973145  -0.5574936819742657  0.3447505235671997


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3021891991803501
RMSE: 0.549717381188143
LogLoss: 0.9824990711716447
Mean Per-Class Error: 0.2780372130094567
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    6.0    1.0    2.0    0.0    2.0    2.0    6.0    0.0    1.0    2.0    6.0    0.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    258.0  0.0    12.0   4.0    3.0    6.0    10.0   1.0    3.0    0.0    1.0    1.0    0.0    0.0    4.0    4.0    38.0   28.0   0.0    1.0    2.0    1.0    2.0    4.0    0.0    0.3263707571801567   125 / 383
0.0    0.0    283.0  0.0    15.0   5.0    18.0   1.0    1.0    0.0    23.0   0.0    4.0    0.0    1.0    0.0    2.0    0.0    2.0    1.0    4.0    0.0    3.0    0.0    0.0    4.0    0.22888283378746593  84 / 367
7.0    8.0    0.0    329.0  0.0    3.0    0.0    4.0    0.0    9.0    0.0    0.0    10.0   2.0    2.0    5.0    0.0    13.0   1.0    1.0    0.0    0.0    0.0    8.0    1.0    0.0    0.18362282878411912  74 / 403
0.0    4.0    1.0    0.0    274.0  1.0    17.0   2.0    3.0    0.0    9.0    0.0    0.0    0.0    0.0    1.0    8.0    11.0   11.0   4.0    1.0    0.0    0.0    9.0    0.0    28.0   0.2864583333333333   110 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    37.0   3.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    324.0  0.0    0.0    0.0    0.13829787234042554  52 / 376
0.0    9.0    0.0    12.0   8.0    0.0    1.0    3.0    3.0    2.0    9.0    4.0    0.0    0.0    3.0    1.0    23.0   4.0    13.0   5.0    3.0    1.0    0.0    283.0  6.0    0.0    0.27989821882951654  110 / 393
0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    16.0   0.0    5.0    84.0   2.0    64.0   2.0    0.0    216.0  0.0    0.45038167938931295  177 / 393
0.0    0.0    0.0    1.0    19.0   3.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    39.0   3.0    0.0    0.0    0.0    4.0    0.0    289.0  0.2125340599455041   78 / 367
406.0  433.0  395.0  496.0  381.0  331.0  320.0  299.0  317.0  366.0  344.0  349.0  526.0  329.0  377.0  369.0  372.0  466.0  332.0  441.0  378.0  425.0  450.0  373.0  318.0  410.0  0.27701689493152054  2,771 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.722983
2    0.837849
3    0.886934
4    0.915325
5    0.931421
6    0.944217
7    0.952914
8    0.964211
9    0.972608
10   0.976607

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.30301529048989545
RMSE: 0.5504682465773075
LogLoss: 0.9898737668138023
Mean Per-Class Error: 0.279992868347114
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17     18    19     20    21    22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   3.0    0.0   2.0   0.0    0.06741573033707865  6 / 89
0.0   71.0   0.0   3.0    1.0   0.0   1.0   4.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    4.0   11.0   5.0   0.0    1.0   1.0   0.0    1.0   1.0   0.0    0.330188679245283    35 / 106
0.0   0.0    60.0  0.0    2.0   1.0   6.0   0.0   1.0   0.0    6.0   0.0   0.0    0.0   1.0   0.0    1.0   0.0    1.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.2682926829268293   22 / 82
4.0   1.0    0.0   90.0   0.0   1.0   0.0   3.0   0.0   2.0    0.0   0.0   3.0    1.0   0.0   3.0    0.0   1.0    1.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0    0.19642857142857142  22 / 112
0.0   0.0    0.0   0.0    68.0  0.0   5.0   0.0   1.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0    1.0   5.0    2.0   1.0    0.0   0.0   0.0    1.0   0.0   11.0   0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   7.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   82.0   0.0   0.0   0.0    0.10869565217391304  10 / 92
0.0   2.0    0.0   4.0    4.0   0.0   0.0   1.0   2.0   0.0    4.0   1.0   0.0    0.0   0.0   0.0    4.0   2.0    3.0   2.0    1.0   0.0   0.0    68.0  2.0   0.0    0.32                 32 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    7.0   0.0    0.0   20.0   1.0   19.0  2.0    0.0   58.0  0.0    0.45794392523364486  49 / 107
0.0   0.0    0.0   1.0    3.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    7.0   2.0    0.0   0.0   0.0    1.0   0.0   71.0   0.1839080459770115   16 / 87
95.0  109.0  84.0  140.0  92.0  71.0  74.0  80.0  71.0  103.0  90.0  95.0  113.0  86.0  77.0  105.0  96.0  119.0  81.0  109.0  98.0  99.0  120.0  87.0  87.0  109.0  0.28072289156626506  699 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.719277
2    0.831325
3    0.886345
4    0.916064
5    0.933333
6    0.941365
7    0.948594
8    0.960241
9    0.971084
10   0.976707
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:07  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:08  46.123 sec  54983 obs/sec     1         1             10007      0.649888         1.31551             0.992494       0.36559                          0.648966           1.30994               0.992496         0.363454
    2019-07-23 13:32:09  47.743 sec  56536 obs/sec     10        10            100070     0.549717         0.982499            0.994629       0.277017                         0.550468           0.989874              0.994601         0.280723
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0875864
C9          0.964834               0.964834             0.0845064
C13         0.949874               0.949874             0.083196
C15         0.947236               0.947236             0.082965
C11         0.844199               0.844199             0.0739404
C7          0.81907                0.81907              0.0717395
C14         0.780517               0.780517             0.0683627
C8          0.763133               0.763133             0.0668401
C10         0.755634               0.755634             0.0661833
C16         0.619162               0.619162             0.0542302
C6          0.594026               0.594026             0.0520287
C3          0.55795                0.55795              0.0488688
C4          0.496561               0.496561             0.0434921
C5          0.490611               0.490611             0.0429708
C1          0.422485               0.422485             0.037004
C2          0.411999               0.411999             0.0360855
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_65

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012743432040451808  0.000353013863787055    0.0         -0.02234811972057571   1.2562766075134277  -0.024243125553394508  1.0599579811096191
    3        26       Softmax                 0.0   0.0   0.0017293933931516502  0.00018146412912756205  0.0         -0.004332965952025565  0.4537010192871094  -0.5485760296717006    0.3088768720626831


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3075263146617825
RMSE: 0.5545505519443493
LogLoss: 0.982763750752783
Mean Per-Class Error: 0.28413735593983397
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  2.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    1.0    4.0    0.0    7.0    0.0    3.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    6.0    0.0    4.0    2.0    0.09367088607594937  37 / 395
0.0    273.0  0.0    7.0    0.0    1.0    2.0    8.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    3.0    31.0   45.0   0.0    0.0    0.0    2.0    1.0    4.0    1.0    0.28720626631853785  110 / 383
0.0    0.0    287.0  0.0    6.0    4.0    19.0   1.0    0.0    0.0    20.0   0.0    0.0    0.0    1.0    1.0    7.0    0.0    11.0   3.0    2.0    0.0    5.0    1.0    0.0    0.0    0.22010869565217392  81 / 368
8.0    21.0   0.0    290.0  0.0    2.0    0.0    10.0   1.0    5.0    1.0    2.0    3.0    6.0    11.0   8.0    0.0    19.0   3.0    3.0    0.0    0.0    0.0    9.0    1.0    0.0    0.2803970223325062   113 / 403
0.0    7.0    3.0    0.0    247.0  4.0    24.0   0.0    2.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    17.0   5.0    10.0   11.0   0.0    0.0    0.0    4.0    0.0    43.0   0.3567708333333333   137 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    17.0   0.0    0.0    0.0    0.0    17.0   0.0    3.0    0.0    0.0    2.0    0.0    0.0    1.0    7.0    327.0  0.0    0.0    0.0    0.13031914893617022  49 / 376
7.0    17.0   0.0    4.0    15.0   2.0    1.0    2.0    7.0    0.0    7.0    3.0    0.0    0.0    5.0    1.0    15.0   3.0    11.0   6.0    3.0    1.0    0.0    263.0  6.0    14.0   0.33078880407124683  130 / 393
0.0    0.0    0.0    1.0    0.0    17.0   0.0    0.0    0.0    0.0    1.0    0.0    2.0    0.0    1.0    3.0    3.0    0.0    7.0    46.0   3.0    19.0   3.0    0.0    287.0  0.0    0.2697201017811705   106 / 393
0.0    6.0    0.0    1.0    20.0   6.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    49.0   3.0    0.0    0.0    0.0    3.0    0.0    271.0  0.2615803814713896   96 / 367
423.0  516.0  357.0  396.0  340.0  371.0  383.0  284.0  333.0  321.0  376.0  333.0  454.0  367.0  361.0  406.0  367.0  471.0  377.0  382.0  395.0  345.0  475.0  332.0  429.0  409.0  0.2829151254623613   2,830 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.717085
2    0.83475
3    0.884834
4    0.913726
5    0.93302
6    0.946116
7    0.955813
8    0.964911
9    0.971708
10   0.977407

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.30940908201214384
RMSE: 0.5562455231389677
LogLoss: 0.9920835896074431
Mean Per-Class Error: 0.28498864405476215
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16    17     18     19    20    21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   3.0    0.0   2.0    0.0    0.0898876404494382   8 / 89
0.0    68.0   0.0   2.0    0.0   0.0   0.0   6.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    2.0   10.0   12.0   0.0   0.0   0.0   2.0    1.0   1.0    1.0    0.3584905660377358   38 / 106
0.0    0.0    58.0  0.0    1.0   0.0   5.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   1.0   1.0    3.0   0.0    4.0    2.0   1.0   0.0   2.0    0.0   0.0    0.0    0.2926829268292683   24 / 82
4.0    3.0    0.0   85.0   0.0   1.0   0.0   2.0   0.0   3.0   1.0   2.0   1.0   1.0   5.0   1.0    0.0   2.0    0.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0    0.24107142857142858  27 / 112
0.0    1.0    0.0   0.0    58.0  3.0   6.0   0.0   0.0   0.0   3.0   1.0   0.0   0.0   0.0   0.0    4.0   1.0    2.0    3.0   0.0   0.0   0.0    2.0   0.0    13.0   0.4020618556701031   39 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   1.0   2.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
2.0    5.0    0.0   2.0    6.0   0.0   0.0   1.0   3.0   0.0   3.0   0.0   0.0   0.0   1.0   0.0    2.0   2.0    3.0    1.0   0.0   0.0   0.0    64.0  3.0    2.0    0.36                 36 / 100
0.0    0.0    0.0   0.0    0.0   5.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   1.0    1.0   0.0    0.0    11.0  2.0   4.0   1.0    0.0   80.0   0.0    0.2523364485981308   27 / 107
0.0    1.0    0.0   1.0    6.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    11.0   1.0   0.0   0.0   0.0    1.0   0.0    62.0   0.28735632183908044  25 / 87
103.0  115.0  72.0  121.0  85.0  87.0  95.0  80.0  77.0  92.0  91.0  88.0  98.0  99.0  70.0  115.0  96.0  123.0  100.0  90.0  98.0  77.0  121.0  78.0  118.0  101.0  0.28313253012048195  705 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.716867
2    0.836145
3    0.887149
4    0.911647
5    0.928514
6    0.938554
7    0.947791
8    0.961847
9    0.967871
10   0.975904
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:08  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:08  2 min 46.631 sec  60283 obs/sec     1         1             10007      0.648813         1.31508             0.99252        0.36779                          0.646922           1.30807               0.992543         0.364257
    2019-07-23 13:34:10  2 min 48.178 sec  60246 obs/sec     10        10            100070     0.554551         0.982764            0.994535       0.282915                         0.556246           0.992084              0.994487         0.283133
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0891529
C9          0.953866               0.953866             0.0850399
C12         0.949541               0.949541             0.0846544
C13         0.932511               0.932511             0.083136
C7          0.838334               0.838334             0.0747399
C8          0.828568               0.828568             0.0738693
C11         0.788076               0.788076             0.0702593
C14         0.741705               0.741705             0.0661252
C10         0.725711               0.725711             0.0646993
C16         0.576447               0.576447             0.051392
C6          0.557603               0.557603             0.049712
C3          0.516705               0.516705             0.0460658
C4          0.484377               0.484377             0.0431836
C5          0.481722               0.481722             0.0429469
C2          0.42707                0.42707              0.0380745
C1          0.414447               0.414447             0.0369491
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_111

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011472922607254077  0.00032035703770816326  0.0         -0.007490163270404082  1.0024542808532715  0.026590280694230715  1.0806593894958496
    3        26       Softmax                 0.0   0.0   0.0018114709230128657  0.0002033929922617972   0.0         0.014007606715984786   0.5920796394348145  -0.47129256297072075  0.2408144474029541


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3040312261951504
RMSE: 0.5513902666851768
LogLoss: 0.9854945804078524
Mean Per-Class Error: 0.28758990767867243
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    5.0    0.0    6.0    2.0    8.0    0.0    1.0    0.0    2.0    0.0    2.0    0.0    1.0    4.0    6.0    0.0    0.10126582278481013  40 / 395
0.0    264.0  0.0    14.0   6.0    8.0    0.0    15.0   2.0    1.0    2.0    0.0    1.0    1.0    1.0    3.0    3.0    46.0   5.0    0.0    0.0    3.0    0.0    3.0    4.0    1.0    0.31070496083550914  119 / 383
0.0    0.0    282.0  0.0    28.0   5.0    23.0   0.0    1.0    0.0    14.0   0.0    0.0    0.0    1.0    2.0    2.0    1.0    2.0    0.0    2.0    0.0    1.0    0.0    0.0    4.0    0.23369565217391305  86 / 368
5.0    13.0   0.0    306.0  0.0    3.0    0.0    8.0    0.0    8.0    0.0    1.0    1.0    3.0    3.0    6.0    0.0    19.0   16.0   1.0    3.0    0.0    0.0    7.0    0.0    0.0    0.24069478908188585  97 / 403
0.0    0.0    6.0    0.0    277.0  7.0    31.0   1.0    2.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    3.0    6.0    3.0    4.0    0.0    0.0    0.0    5.0    1.0    31.0   0.2786458333333333   107 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    19.0   7.0    1.0    0.0    0.0    4.0    0.0    0.0    1.0    2.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    4.0    0.0    13.0   11.0   1.0    4.0    4.0    4.0    3.0    10.0   0.0    0.0    0.0    1.0    0.0    21.0   5.0    5.0    7.0    2.0    0.0    0.0    279.0  8.0    12.0   0.2918781725888325   115 / 394
0.0    0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    2.0    0.0    0.0    0.0    2.0    4.0    2.0    8.0    0.0    5.0    46.0   2.0    64.0   2.0    0.0    243.0  1.0    0.38010204081632654  149 / 392
3.0    2.0    0.0    2.0    21.0   6.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    25.0   1.0    0.0    0.0    0.0    7.0    0.0    283.0  0.22888283378746593  84 / 367
443.0  455.0  360.0  459.0  414.0  412.0  382.0  289.0  329.0  370.0  367.0  335.0  439.0  383.0  330.0  351.0  374.0  476.0  208.0  396.0  402.0  412.0  462.0  356.0  353.0  446.0  0.28631410576826954  2,864 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.713686
2    0.835349
3    0.885134
4    0.913026
5    0.930521
6    0.944917
7    0.955813
8    0.963211
9    0.970609
10   0.976907

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3072949242909494
RMSE: 0.5543418839407225
LogLoss: 0.9933247048014003
Mean Per-Class Error: 0.29342409790927854
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5      6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24    25     Error                Rate
-----  -----  ----  -----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   1.0    0.0   0.0   1.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    1.0   3.0   0.0    0.0898876404494382   8 / 89
0.0    67.0   0.0   2.0    2.0    3.0    0.0   4.0   1.0   0.0    0.0   0.0   1.0   0.0    1.0   1.0    1.0   15.0   2.0   0.0   0.0    3.0   0.0    2.0   1.0   0.0    0.36792452830188677  39 / 106
0.0    0.0    58.0  0.0    6.0    2.0    8.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   1.0    0.2926829268292683   24 / 82
4.0    4.0    0.0   88.0   0.0    1.0    0.0   2.0   0.0   1.0    0.0   0.0   1.0   2.0    2.0   1.0    0.0   1.0    3.0   0.0   1.0    0.0   0.0    1.0   0.0   0.0    0.21428571428571427  24 / 112
0.0    0.0    0.0   0.0    69.0   3.0    8.0   0.0   1.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0   0.0   0.0    0.0   0.0    2.0   0.0   9.0    0.28865979381443296  28 / 97
---    ---    ---   ---    ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---                  ---
1.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   5.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   83.0   0.0   0.0   0.0    0.09782608695652174  9 / 92
0.0    0.0    0.0   4.0    4.0    0.0    1.0   2.0   3.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    3.0   2.0    0.0   3.0   1.0    0.0   0.0    68.0  2.0   3.0    0.32                 32 / 100
0.0    0.0    0.0   0.0    0.0    2.0    0.0   1.0   0.0   2.0    0.0   0.0   0.0   0.0    1.0   1.0    3.0   0.0    1.0   14.0  0.0    20.0  0.0    0.0   62.0  0.0    0.4205607476635514   45 / 107
0.0    2.0    0.0   2.0    9.0    1.0    0.0   1.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0    1.0   0.0   65.0   0.25287356321839083  22 / 87
107.0  103.0  71.0  128.0  107.0  100.0  97.0  84.0  80.0  112.0  91.0  85.0  91.0  105.0  71.0  104.0  94.0  117.0  50.0  89.0  102.0  98.0  115.0  87.0  95.0  107.0  0.2927710843373494   729 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.707229
2    0.828514
3    0.878313
4    0.91004
5    0.927711
6    0.943373
7    0.955422
8    0.966265
9    0.974297
10   0.978313
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:13  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:13  4 min 51.086 sec  82702 obs/sec     1         1             10007      0.708525         1.55697             0.991079       0.435569                         0.704173           1.53574               0.991165         0.434137
    2019-07-23 13:36:14  4 min 52.134 sec  87093 obs/sec     10        10            100070     0.55139          0.985495            0.994597       0.286314                         0.554342           0.993325              0.994524         0.292771
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0897297
C15         0.998714               0.998714             0.0896143
C9          0.923482               0.923482             0.0828638
C7          0.89867                0.89867              0.0806374
C13         0.897067               0.897067             0.0804935
C11         0.869875               0.869875             0.0780536
C14         0.849841               0.849841             0.076256
C10         0.783212               0.783212             0.0702774
C8          0.747495               0.747495             0.0670725
C6          0.606188               0.606188             0.0543931
C16         0.588927               0.588927             0.0528442
C5          0.490466               0.490466             0.0440093
C3          0.437079               0.437079             0.0392189
C4          0.390759               0.390759             0.0350627
C2          0.352119               0.352119             0.0315955
C1          0.310691               0.310691             0.0278782
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_42

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.001325013147095433   0.00035958411172032356  0.0         -0.03351072023428969  1.3257040977478027  -0.09622404053537649  0.9394564628601074
    3        26       Softmax                 0.0   0.0   0.0017278002075657311  0.00019468064419925213  0.0         0.02821927803223354   0.4448460340499878  -0.5388525231425805   0.3734855651855469


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.31809964490460935
RMSE: 0.5640032312891561
LogLoss: 1.0079753129133868
Mean Per-Class Error: 0.3003605141302458
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    5.0    0.0    0.0    0.0    2.0    0.0    1.0    5.0    0.0    4.0    0.0    3.0    0.0    1.0    0.0    2.0    0.0    0.0    1.0    4.0    3.0    7.0    0.0    0.09873417721518987  39 / 395
0.0    278.0  0.0    6.0    1.0    1.0    2.0    8.0    10.0   1.0    1.0    0.0    4.0    0.0    0.0    2.0    4.0    37.0   18.0   0.0    0.0    2.0    0.0    5.0    3.0    0.0    0.2741514360313316   105 / 383
1.0    1.0    275.0  0.0    26.0   3.0    21.0   1.0    0.0    0.0    14.0   1.0    1.0    0.0    2.0    0.0    1.0    0.0    4.0    6.0    3.0    0.0    7.0    0.0    0.0    0.0    0.2506811989100817   92 / 367
6.0    11.0   0.0    295.0  0.0    2.0    0.0    6.0    0.0    9.0    0.0    0.0    7.0    8.0    6.0    8.0    0.0    21.0   5.0    0.0    1.0    0.0    0.0    16.0   1.0    1.0    0.2679900744416873   108 / 403
0.0    10.0   4.0    0.0    260.0  6.0    24.0   0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    8.0    8.0    14.0   0.0    0.0    0.0    12.0   0.0    28.0   0.3229166666666667   124 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    3.0    0.0    26.0   8.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    5.0    323.0  0.0    0.0    0.0    0.14095744680851063  53 / 376
11.0   16.0   0.0    7.0    10.0   2.0    3.0    0.0    14.0   1.0    11.0   3.0    0.0    0.0    0.0    0.0    29.0   3.0    20.0   19.0   3.0    0.0    0.0    226.0  5.0    11.0   0.4263959390862944   168 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    6.0    8.0    0.0    6.0    69.0   2.0    29.0   0.0    0.0    249.0  0.0    0.366412213740458    144 / 393
2.0    2.0    0.0    1.0    17.0   10.0   0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    34.0   4.0    0.0    0.0    0.0    6.0    0.0    284.0  0.22615803814713897  83 / 367
442.0  515.0  377.0  403.0  361.0  386.0  344.0  244.0  343.0  335.0  340.0  342.0  460.0  440.0  361.0  399.0  357.0  488.0  284.0  429.0  383.0  349.0  448.0  346.0  386.0  441.0  0.29911026691992404  2,992 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.70089
2    0.828851
3    0.886334
4    0.911726
5    0.929121
6    0.943017
7    0.954214
8    0.963911
9    0.972508
10   0.978306

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3227735097566328
RMSE: 0.5681315954571026
LogLoss: 1.0227900322667813
Mean Per-Class Error: 0.305749861742458
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16    17     18    19     20    21    22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   3.0    1.0   2.0   0.0    0.0898876404494382   8 / 89
0.0    71.0   0.0   1.0    0.0   0.0   1.0   5.0   2.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0    4.0   15.0   3.0   0.0    0.0   1.0   0.0    2.0   0.0   0.0    0.330188679245283    35 / 106
0.0    0.0    56.0  0.0    6.0   1.0   8.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0    1.0   0.0    0.0   0.0    2.0   2.0    1.0   0.0   2.0    0.0   0.0   0.0    0.3170731707317073   26 / 82
3.0    1.0    0.0   83.0   0.0   0.0   0.0   2.0   0.0   2.0   0.0   0.0   3.0    2.0    3.0   4.0    0.0   5.0    2.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0    0.25892857142857145  29 / 112
0.0    2.0    2.0   0.0    66.0  3.0   5.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    1.0   2.0    1.0   5.0    0.0   0.0   0.0    1.0   0.0   8.0    0.31958762886597936  31 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   5.0    1.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   1.0   83.0   0.0   0.0   0.0    0.09782608695652174  9 / 92
1.0    4.0    0.0   2.0    5.0   0.0   1.0   0.0   4.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0    5.0   1.0    8.0   4.0    0.0   0.0   0.0    60.0  1.0   2.0    0.4                  40 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   5.0   0.0   0.0   0.0   0.0   0.0    0.0    3.0   1.0    4.0   0.0    0.0   21.0   0.0   11.0  0.0    0.0   62.0  0.0    0.4205607476635514   45 / 107
0.0    0.0    0.0   1.0    4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    1.0   0.0    7.0   1.0    0.0   0.0   0.0    3.0   0.0   67.0   0.22988505747126436  20 / 87
104.0  123.0  77.0  116.0  92.0  84.0  85.0  66.0  76.0  95.0  81.0  91.0  103.0  109.0  72.0  114.0  93.0  124.0  78.0  103.0  94.0  88.0  121.0  93.0  97.0  111.0  0.30522088353413657  760 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.694779
2    0.828112
3    0.882731
4    0.907631
5    0.928916
6    0.940562
7    0.95261
8    0.961847
9    0.969478
10   0.975502
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:16  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:16  1 min 54.260 sec  62937 obs/sec     1         1             10007      0.663871         1.35913             0.992168       0.372088                         0.660195           1.34515               0.992234         0.370281
    2019-07-23 13:33:17  1 min 55.891 sec  56987 obs/sec     10        10            100070     0.564003         1.00798             0.994347       0.29911                          0.568132           1.02279               0.994249         0.305221
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0891211
C13         0.975502               0.975502             0.0869378
C9          0.95473                0.95473              0.0850866
C12         0.940379               0.940379             0.0838076
C11         0.794432               0.794432             0.0708007
C7          0.767357               0.767357             0.0683877
C8          0.730584               0.730584             0.0651105
C14         0.699042               0.699042             0.0622994
C10         0.69346                0.69346              0.0618019
C3          0.609647               0.609647             0.0543325
C6          0.599775               0.599775             0.0534527
C16         0.580072               0.580072             0.0516966
C5          0.510144               0.510144             0.0454646
C4          0.474911               0.474911             0.0423246
C1          0.456901               0.456901             0.0407195
C2          0.433749               0.433749             0.0386562
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_107

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012813097530965933  0.000341994222253561    0.0         -0.05025265039127902  1.240616798400879   -0.22515659548758013  0.9997026920318604
    3        26       Softmax                 0.0   0.0   0.0017340836880416295  0.00019084732048213482  0.0         0.03820155607331799   0.4489985704421997  -0.5470773636881942   0.38096296787261963


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.30941884059203173
RMSE: 0.556254294897605
LogLoss: 1.0044074654096136
Mean Per-Class Error: 0.28491090287383547
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  4.0    0.0    3.0    0.0    0.0    3.0    0.0    0.0    8.0    0.0    0.0    7.0    2.0    2.0    0.0    0.0    1.0    3.0    0.0    1.0    1.0    5.0    0.0    7.0    0.0    0.1189873417721519   47 / 395
0.0    283.0  0.0    7.0    0.0    1.0    6.0    12.0   3.0    0.0    4.0    0.0    1.0    0.0    1.0    3.0    8.0    29.0   19.0   0.0    0.0    2.0    0.0    1.0    3.0    0.0    0.26109660574412535  100 / 383
0.0    0.0    272.0  0.0    15.0   1.0    22.0   0.0    0.0    0.0    23.0   0.0    0.0    0.0    3.0    0.0    3.0    0.0    8.0    6.0    3.0    0.0    7.0    0.0    0.0    4.0    0.25885558583106266  95 / 367
6.0    16.0   0.0    308.0  0.0    8.0    0.0    2.0    0.0    7.0    0.0    2.0    8.0    6.0    6.0    2.0    0.0    18.0   3.0    0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.23573200992555832  95 / 403
0.0    14.0   4.0    0.0    239.0  3.0    25.0   0.0    2.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    16.0   5.0    6.0    8.0    0.0    1.0    0.0    21.0   0.0    32.0   0.3776041666666667   145 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    1.0    0.0    22.0   3.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    14.0   321.0  0.0    0.0    0.0    0.14627659574468085  55 / 376
10.0   5.0    1.0    7.0    8.0    2.0    3.0    3.0    10.0   3.0    12.0   1.0    0.0    0.0    0.0    1.0    9.0    5.0    14.0   11.0   2.0    0.0    0.0    249.0  15.0   23.0   0.3680203045685279   145 / 394
0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    2.0    4.0    0.0    7.0    61.0   2.0    70.0   5.0    0.0    234.0  0.0    0.40458015267175573  159 / 393
0.0    2.0    0.0    1.0    14.0   2.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    45.0   7.0    0.0    0.0    0.0    9.0    1.0    276.0  0.24795640326975477  91 / 367
432.0  493.0  339.0  438.0  345.0  350.0  374.0  255.0  331.0  337.0  402.0  332.0  462.0  339.0  391.0  371.0  325.0  458.0  338.0  425.0  408.0  430.0  466.0  362.0  373.0  427.0  0.2839148255523343   2,840 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.716085
2    0.829051
3    0.877137
4    0.906228
5    0.930321
6    0.945117
7    0.954614
8    0.963011
9    0.96791
10   0.973908

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3138149867344772
RMSE: 0.5601919195547872
LogLoss: 1.0271744215384557
Mean Per-Class Error: 0.2916897015307724
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18    19    20     21     22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    1.0    1.0    0.0   3.0    0.0    0.0898876404494382   8 / 89
0.0    73.0   0.0   1.0    0.0   0.0   1.0   5.0   1.0   0.0   2.0   0.0   0.0    0.0   1.0   1.0    3.0   9.0    6.0   0.0   0.0    2.0    0.0    1.0   0.0    0.0    0.3113207547169811   33 / 106
0.0    0.0    57.0  0.0    2.0   0.0   10.0  0.0   0.0   0.0   4.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0    2.0    0.0   0.0    1.0    0.3048780487804878   25 / 82
3.0    3.0    0.0   89.0   0.0   2.0   0.0   1.0   0.0   1.0   0.0   1.0   3.0    1.0   2.0   1.0    0.0   3.0    2.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0    0.20535714285714285  23 / 112
0.0    1.0    2.0   0.0    56.0  1.0   7.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    5.0   1.0    2.0   2.0   0.0    0.0    0.0    7.0   0.0    10.0   0.422680412371134    41 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0    85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
2.0    1.0    1.0   3.0    3.0   0.0   0.0   1.0   3.0   1.0   5.0   0.0   0.0    0.0   0.0   0.0    2.0   3.0    5.0   4.0   0.0    0.0    0.0    59.0  4.0    3.0    0.41                 41 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0    2.0   0.0    0.0   13.0  0.0    20.0   4.0    0.0   66.0   0.0    0.38317757009345793  41 / 107
0.0    1.0    0.0   1.0    6.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    8.0   3.0   0.0    0.0    0.0    3.0   1.0    63.0   0.27586206896551724  24 / 87
108.0  121.0  72.0  132.0  79.0  80.0  96.0  72.0  76.0  93.0  99.0  87.0  103.0  88.0  76.0  108.0  86.0  107.0  86.0  96.0  102.0  103.0  122.0  90.0  105.0  103.0  0.29116465863453816  725 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.708835
2    0.826506
3    0.873494
4    0.903213
5    0.927309
6    0.941767
7    0.950201
8    0.958233
9    0.964257
10   0.968675
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:03  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:03  4 min 41.254 sec  53513 obs/sec     1         1             10007      0.656202         1.34202             0.992348       0.377587                         0.653805           1.32931               0.992383         0.374297
    2019-07-23 13:36:04  4 min 42.785 sec  59459 obs/sec     10        10            100070     0.556254         1.00441             0.994502       0.283915                         0.560192           1.02717               0.994408         0.291165
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0896619
C9          0.95163                0.95163              0.085325
C13         0.92857                0.92857              0.0832573
C12         0.887517               0.887517             0.0795764
C11         0.857411               0.857411             0.0768771
C8          0.819076               0.819076             0.0734399
C7          0.802395               0.802395             0.0719442
C14         0.781038               0.781038             0.0700293
C10         0.624108               0.624108             0.0559587
C6          0.614065               0.614065             0.0550582
C16         0.612303               0.612303             0.0549003
C3          0.529927               0.529927             0.0475142
C5          0.501891               0.501891             0.0450005
C4          0.475084               0.475084             0.0425969
C2          0.396014               0.396014             0.0355074
C1          0.371983               0.371983             0.0333527
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_35

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight          weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  -------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.001281688696508354   0.00031995936296880245  0.0         0.01864161192264646  1.2804641723632812  -0.18258689134162104  1.0317292213439941
    3        26       Softmax                 0.0   0.0   0.0017421415174025102  0.0001993562327697873   0.0         0.01624969931362312  0.4546579122543335  -0.544914609556847    0.321636438369751


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.32106587784268054
RMSE: 0.5666267535535897
LogLoss: 1.0259399260189936
Mean Per-Class Error: 0.29191007818504655
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  1.0    0.0    5.0    0.0    0.0    0.0    2.0    0.0    4.0    2.0    0.0    10.0   1.0    0.0    0.0    0.0    3.0    7.0    0.0    0.0    1.0    4.0    1.0    6.0    0.0    0.1189873417721519   47 / 395
0.0    263.0  0.0    7.0    1.0    2.0    3.0    20.0   0.0    4.0    2.0    0.0    2.0    0.0    0.0    3.0    10.0   39.0   16.0   0.0    0.0    4.0    1.0    4.0    1.0    0.0    0.31151832460732987  119 / 382
0.0    0.0    275.0  0.0    22.0   2.0    31.0   0.0    2.0    0.0    14.0   0.0    3.0    0.0    3.0    0.0    0.0    0.0    6.0    3.0    3.0    0.0    3.0    0.0    1.0    0.0    0.25271739130434784  93 / 368
5.0    16.0   0.0    304.0  0.0    1.0    0.0    15.0   0.0    11.0   6.0    1.0    6.0    3.0    2.0    8.0    1.0    6.0    2.0    0.0    1.0    0.0    0.0    14.0   1.0    0.0    0.2456575682382134   99 / 403
0.0    4.0    18.0   0.0    205.0  0.0    61.0   1.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    14.0   6.0    9.0    10.0   1.0    0.0    0.0    27.0   0.0    19.0   0.4661458333333333   179 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    2.0    7.0    0.0    0.0    0.0    0.0    31.0   16.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    9.0    305.0  0.0    0.0    0.0    0.18882978723404256  71 / 376
0.0    7.0    0.0    5.0    9.0    0.0    8.0    4.0    16.0   4.0    6.0    1.0    0.0    0.0    0.0    0.0    8.0    2.0    10.0   3.0    1.0    0.0    0.0    281.0  13.0   16.0   0.2868020304568528   113 / 394
0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    3.0    6.0    0.0    4.0    63.0   3.0    50.0   8.0    0.0    247.0  0.0    0.37150127226463103  146 / 393
0.0    6.0    1.0    1.0    12.0   1.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    40.0   4.0    0.0    0.0    0.0    4.0    0.0    288.0  0.21525885558583105  79 / 367
402.0  448.0  384.0  440.0  300.0  318.0  425.0  312.0  342.0  358.0  358.0  311.0  537.0  349.0  341.0  417.0  335.0  454.0  323.0  407.0  384.0  417.0  453.0  422.0  357.0  409.0  0.29081275617314806  2,909 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.709187
2    0.83425
3    0.885234
4    0.913726
5    0.931321
6    0.943317
7    0.954713
8    0.962911
9    0.968909
10   0.974508

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.32518966823702183
RMSE: 0.5702540383346898
LogLoss: 1.045575178131415
Mean Per-Class Error: 0.30614527465516317
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9     10    11    12     13    14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0   0.0   2.0    1.0   3.0    0.0    0.12359550561797752  11 / 89
0.0   66.0   0.0   0.0    0.0   0.0   1.0    8.0   0.0   1.0   0.0   0.0   1.0    0.0   0.0   0.0    7.0   15.0   3.0   0.0   0.0   2.0   1.0    1.0   0.0    0.0    0.37735849056603776  40 / 106
0.0   0.0    56.0  0.0    4.0   0.0   11.0   0.0   1.0   0.0   3.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    2.0   1.0   1.0   0.0   1.0    0.0   1.0    0.0    0.3170731707317073   26 / 82
3.0   5.0    0.0   89.0   0.0   1.0   0.0    4.0   0.0   1.0   1.0   0.0   3.0    1.0   0.0   2.0    1.0   0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    0.20535714285714285  23 / 112
0.0   1.0    5.0   0.0    46.0  0.0   16.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    4.0   1.0    3.0   5.0   0.0   0.0   0.0    6.0   0.0    8.0    0.5257731958762887   51 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   6.0    5.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   2.0   77.0   0.0   0.0    0.0    0.16304347826086957  15 / 92
0.0   3.0    0.0   2.0    4.0   0.0   1.0    2.0   5.0   1.0   2.0   0.0   0.0    0.0   0.0   0.0    2.0   1.0    4.0   0.0   0.0   0.0   0.0    64.0  4.0    5.0    0.36                 36 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   1.0    2.0   0.0    0.0   18.0  0.0   14.0  3.0    0.0   66.0   0.0    0.38317757009345793  41 / 107
0.0   1.0    1.0   0.0    3.0   1.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    6.0   2.0   0.0   0.0   0.0    2.0   0.0    68.0   0.21839080459770116  19 / 87
94.0  108.0  82.0  130.0  68.0  72.0  117.0  89.0  82.0  98.0  75.0  84.0  123.0  88.0  65.0  116.0  93.0  111.0  82.0  99.0  97.0  91.0  120.0  98.0  104.0  104.0  0.30562248995983937  761 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.694377
2    0.824096
3    0.881124
4    0.906024
5    0.929317
6    0.941365
7    0.951807
8    0.961044
9    0.96747
10   0.973896
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:33:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:33:00  1 min 38.262 sec  55905 obs/sec     1         1             10007      0.654656         1.32214             0.992384       0.36759                          0.652025           1.3101                0.992425         0.362651
    2019-07-23 13:33:01  1 min 39.912 sec  55811 obs/sec     10        10            100070     0.566627         1.02594             0.994294       0.290813                         0.570254           1.04558               0.994206         0.305622
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0880747
C13         0.941616               0.941616             0.0829326
C12         0.903514               0.903514             0.0795767
C9          0.877023               0.877023             0.0772436
C8          0.854072               0.854072             0.0752222
C11         0.817108               0.817108             0.0719666
C7          0.805175               0.805175             0.0709156
C14         0.757555               0.757555             0.0667215
C10         0.723169               0.723169             0.0636929
C16         0.634299               0.634299             0.0558657
C6          0.570461               0.570461             0.0502432
C3          0.547418               0.547418             0.0482137
C5          0.527122               0.527122             0.0464261
C4          0.498634               0.498634             0.043917
C1          0.451615               0.451615             0.0397758
C2          0.445216               0.445216             0.0392122
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_6

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011235046175670504  0.0002908912720158696  0.0         -0.04241124392910933   1.1194119453430176  -0.2790108352122643   1.1251163482666016
    3        26       Softmax                 0.0   0.0   0.001767310652352395   0.0001899019698612392  0.0         -0.005208890263859827  0.5844359397888184  -0.47943175523253356  0.24655210971832275


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3345131386561253
RMSE: 0.5783711080751919
LogLoss: 1.0691035149140047
Mean Per-Class Error: 0.3075213834898368
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  2.0    0.0    8.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    7.0    2.0    8.0    0.0    0.11392405063291139  45 / 395
2.0    284.0  1.0    12.0   2.0    0.0    1.0    5.0    4.0    4.0    0.0    0.0    0.0    0.0    7.0    0.0    10.0   26.0   7.0    0.0    0.0    4.0    0.0    11.0   3.0    0.0    0.2584856396866841   99 / 383
0.0    1.0    268.0  0.0    22.0   2.0    16.0   1.0    1.0    0.0    21.0   0.0    0.0    0.0    3.0    0.0    7.0    1.0    8.0    6.0    2.0    0.0    5.0    1.0    0.0    2.0    0.26975476839237056  99 / 367
4.0    15.0   0.0    295.0  0.0    0.0    0.0    23.0   0.0    4.0    3.0    0.0    10.0   1.0    8.0    1.0    5.0    20.0   6.0    1.0    1.0    0.0    0.0    3.0    2.0    1.0    0.2679900744416873   108 / 403
0.0    14.0   28.0   0.0    195.0  10.0   32.0   0.0    2.0    0.0    15.0   1.0    0.0    0.0    0.0    1.0    16.0   6.0    12.0   4.0    1.0    0.0    0.0    27.0   0.0    20.0   0.4921875            189 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    8.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    12.0   27.0   2.0    0.0    1.0    5.0    0.0    0.0    0.0    21.0   295.0  2.0    0.0    0.0    0.2154255319148936   81 / 376
0.0    14.0   0.0    2.0    27.0   0.0    0.0    2.0    8.0    2.0    8.0    8.0    1.0    0.0    0.0    0.0    23.0   3.0    25.0   8.0    1.0    0.0    0.0    226.0  17.0   19.0   0.4263959390862944   168 / 394
2.0    0.0    0.0    1.0    0.0    18.0   0.0    2.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    10.0   2.0    0.0    11.0   78.0   1.0    48.0   2.0    0.0    214.0  0.0    0.455470737913486    179 / 393
3.0    13.0   0.0    2.0    9.0    12.0   1.0    0.0    0.0    1.0    2.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    42.0   2.0    0.0    0.0    0.0    5.0    2.0    266.0  0.27520435967302453  101 / 367
420.0  622.0  384.0  419.0  312.0  360.0  353.0  297.0  329.0  332.0  357.0  334.0  476.0  378.0  365.0  382.0  420.0  418.0  297.0  464.0  380.0  407.0  408.0  365.0  346.0  378.0  0.306408077576727    3,065 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.693592
2    0.817855
3    0.870939
4    0.897131
5    0.918324
6    0.93382
7    0.945016
8    0.954014
9    0.960812
10   0.96741

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3364992065317815
RMSE: 0.5800855165678432
LogLoss: 1.0747156942258902
Mean Per-Class Error: 0.30558845211257224
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20    21    22     23    24    25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -------------------  -----------
78.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   2.0    1.0   3.0   0.0   0.12359550561797752  11 / 89
1.0    73.0   1.0   3.0    0.0   0.0   1.0   2.0   1.0   1.0   0.0   0.0   0.0    0.0   3.0   0.0    2.0    11.0   1.0   0.0    0.0   3.0   0.0    2.0   1.0   0.0   0.3113207547169811   33 / 106
0.0    1.0    59.0  0.0    2.0   0.0   5.0   1.0   1.0   0.0   6.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0    3.0   1.0    0.0   0.0   1.0    0.0   0.0   0.0   0.2804878048780488   23 / 82
2.0    2.0    0.0   87.0   0.0   0.0   0.0   3.0   0.0   1.0   0.0   0.0   3.0    0.0   4.0   0.0    2.0    5.0    3.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.22321428571428573  25 / 112
0.0    4.0    8.0   0.0    49.0  3.0   6.0   0.0   1.0   0.0   7.0   0.0   0.0    0.0   0.0   0.0    5.0    2.0    2.0   2.0    0.0   0.0   0.0    2.0   0.0   6.0   0.4948453608247423   48 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---                  ---
0.0    1.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   5.0    4.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   2.0   79.0   0.0   0.0   0.0   0.14130434782608695  13 / 92
0.0    2.0    0.0   1.0    10.0  0.0   0.0   2.0   2.0   0.0   4.0   1.0   0.0    0.0   0.0   0.0    3.0    3.0    6.0   0.0    0.0   0.0   0.0    53.0  6.0   7.0   0.47                 47 / 100
2.0    0.0    0.0   0.0    0.0   3.0   0.0   2.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   3.0    0.0    0.0    1.0   21.0   0.0   14.0  1.0    0.0   58.0  0.0   0.45794392523364486  49 / 107
0.0    3.0    0.0   1.0    3.0   3.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    0.0   0.0   0.0    1.0    0.0    11.0  1.0    0.0   0.0   0.0    2.0   1.0   59.0  0.3218390804597701   28 / 87
102.0  139.0  87.0  117.0  76.0  83.0  83.0  84.0  74.0  90.0  89.0  92.0  113.0  98.0  86.0  111.0  103.0  108.0  83.0  111.0  94.0  93.0  104.0  80.0  98.0  92.0  0.30562248995983937  761 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.694377
2    0.809639
3    0.866667
4    0.892369
5    0.916064
6    0.933333
7    0.944177
8    0.953815
9    0.961847
10   0.968273
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:31:44  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:31:44  22.365 sec  80056 obs/sec     1         1             10007      0.69284          1.51832             0.99147        0.425872                         0.689782           1.49802               0.991522         0.43253
    2019-07-23 13:31:45  23.481 sec  82429 obs/sec     10        10            100070     0.578371         1.0691              0.994055       0.306408                         0.580086           1.07472               0.994004         0.305622
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0882614
C13         0.942094               0.942094             0.0831505
C12         0.896029               0.896029             0.0790848
C11         0.859397               0.859397             0.0758516
C9          0.841411               0.841411             0.0742641
C14         0.815652               0.815652             0.0719906
C8          0.77393                0.77393              0.0683082
C7          0.76939                0.76939              0.0679074
C16         0.660916               0.660916             0.0583334
C6          0.654097               0.654097             0.0577315
C5          0.587762               0.587762             0.0518767
C10         0.566255               0.566255             0.0499785
C3          0.563792               0.563792             0.0497611
C4          0.516094               0.516094             0.0455512
C1          0.473123               0.473123             0.0417585
C2          0.410036               0.410036             0.0361903
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_99

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011379172005945293  0.00028162915259599686  0.0         0.03802991379961895   1.0571093559265137  -0.2113709507808162   1.1161603927612305
    3        26       Softmax                 0.0   0.0   0.0018041787207039306  0.00033340509980916977  0.0         0.001490730362093018  0.600914478302002   -0.47298260114020685  0.2920929193496704


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.33241971433950923
RMSE: 0.5765585090340002
LogLoss: 1.052284421610117
Mean Per-Class Error: 0.3103342641966763
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    1.0    1.0    0.0    1.0    0.0    1.0    0.0    1.0    3.0    0.0    9.0    1.0    9.0    0.0    0.0    3.0    2.0    0.0    1.0    0.0    6.0    2.0    5.0    0.0    0.11645569620253164  46 / 395
0.0    261.0  0.0    20.0   5.0    0.0    1.0    12.0   3.0    1.0    0.0    0.0    2.0    0.0    1.0    1.0    5.0    35.0   14.0   0.0    0.0    1.0    0.0    20.0   1.0    0.0    0.3185378590078329   122 / 383
0.0    0.0    279.0  0.0    19.0   0.0    18.0   0.0    1.0    0.0    26.0   0.0    1.0    0.0    5.0    1.0    0.0    1.0    6.0    4.0    5.0    0.0    0.0    1.0    0.0    1.0    0.2418478260869565   89 / 368
7.0    23.0   0.0    279.0  1.0    4.0    0.0    15.0   4.0    6.0    2.0    2.0    8.0    1.0    5.0    4.0    0.0    21.0   2.0    0.0    1.0    0.0    0.0    18.0   0.0    0.0    0.3076923076923077   124 / 403
0.0    13.0   3.0    0.0    250.0  6.0    19.0   3.0    3.0    0.0    3.0    2.0    0.0    0.0    0.0    0.0    3.0    8.0    18.0   1.0    0.0    2.0    1.0    33.0   0.0    16.0   0.3489583333333333   134 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    2.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    23.0   4.0    0.0    0.0    5.0    3.0    0.0    0.0    1.0    7.0    324.0  0.0    0.0    0.0    0.13829787234042554  52 / 376
0.0    14.0   1.0    4.0    30.0   2.0    5.0    1.0    11.0   0.0    14.0   13.0   0.0    1.0    0.0    0.0    29.0   2.0    14.0   5.0    3.0    0.0    0.0    210.0  6.0    29.0   0.467005076142132    184 / 394
9.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    6.0    9.0    0.0    8.0    78.0   4.0    72.0   2.0    4.0    189.0  1.0    0.5190839694656488   204 / 393
2.0    12.0   0.0    1.0    11.0   1.0    1.0    0.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    32.0   7.0    0.0    0.0    0.0    25.0   3.0    263.0  0.28337874659400547  104 / 367
432.0  533.0  342.0  396.0  386.0  265.0  349.0  232.0  336.0  318.0  395.0  368.0  479.0  383.0  373.0  396.0  381.0  471.0  308.0  490.0  395.0  450.0  441.0  409.0  269.0  406.0  0.3092072378286514   3,093 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.690793
2    0.811856
3    0.86744
4    0.89833
5    0.917625
6    0.936119
7    0.946916
8    0.957813
9    0.96561
10   0.973508

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3383887803701149
RMSE: 0.5817119393394937
LogLoss: 1.0781602067715796
Mean Per-Class Error: 0.32212698796797967
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11     12     13    14    15     16     17     18    19     20    21     22     23     24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  -----  -----  ----  -----  ----  -----  -----  -----  ----  -----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    1.0    0.0   0.0   0.0    0.0    1.0    1.0   0.0    0.0   0.0    3.0    1.0    2.0   0.0    0.11235955056179775  10 / 89
0.0    65.0   0.0   4.0    2.0   0.0   1.0   2.0   2.0   1.0   0.0   0.0    1.0    0.0   1.0   0.0    3.0    14.0   2.0   0.0    0.0   1.0    0.0    7.0    0.0   0.0    0.3867924528301887   41 / 106
0.0    0.0    57.0  0.0    5.0   0.0   6.0   0.0   0.0   0.0   8.0   0.0    0.0    0.0   1.0   0.0    0.0    0.0    3.0   2.0    0.0   0.0    0.0    0.0    0.0   0.0    0.3048780487804878   25 / 82
4.0    6.0    0.0   80.0   0.0   1.0   0.0   4.0   1.0   1.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0    8.0    1.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0    0.2857142857142857   32 / 112
0.0    2.0    0.0   0.0    62.0  2.0   5.0   1.0   1.0   0.0   1.0   1.0    0.0    0.0   0.0   0.0    0.0    3.0    5.0   1.0    0.0   0.0    0.0    6.0    0.0   7.0    0.36082474226804123  35 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---    ---    ---   ---    ---   ---    ---    ---    ---   ---    ---                  ---
1.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0    3.0    1.0   0.0   0.0    0.0    1.0    0.0   0.0    0.0   1.0    83.0   0.0    0.0   0.0    0.09782608695652174  9 / 92
0.0    2.0    0.0   1.0    6.0   0.0   1.0   1.0   4.0   0.0   4.0   4.0    0.0    0.0   0.0   0.0    3.0    0.0    5.0   2.0    1.0   0.0    0.0    57.0   2.0   7.0    0.43                 43 / 100
5.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0   1.0   3.0    4.0    0.0    2.0   15.0   0.0   20.0   1.0    1.0    53.0  1.0    0.5046728971962616   54 / 107
0.0    4.0    0.0   1.0    2.0   1.0   0.0   0.0   0.0   1.0   0.0   3.0    0.0    0.0   0.0   0.0    0.0    0.0    7.0   2.0    0.0   0.0    0.0    6.0    1.0   59.0   0.3218390804597701   28 / 87
107.0  126.0  67.0  113.0  90.0  58.0  84.0  66.0  75.0  95.0  95.0  100.0  107.0  99.0  72.0  107.0  105.0  124.0  83.0  114.0  99.0  106.0  111.0  106.0  78.0  103.0  0.321285140562249    800 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.678715
2    0.806827
3    0.864257
4    0.894378
5    0.917671
6    0.934137
7    0.94498
8    0.954619
9    0.962651
10   0.96988
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:40  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:41  4 min 18.947 sec  85529 obs/sec     1         1             10007      0.691632         1.49166             0.991501       0.417475                         0.690759           1.48271               0.991498         0.419679
    2019-07-23 13:35:42  4 min 20.056 sec  83461 obs/sec     10        10            100070     0.576559         1.05228             0.994094       0.309207                         0.581712           1.07816               0.99397          0.321285
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.10037
C13         0.851201               0.851201             0.085435
C12         0.807033               0.807033             0.0810018
C11         0.776391               0.776391             0.0779262
C7          0.772663               0.772663             0.0775521
C9          0.765745               0.765745             0.0768577
C14         0.672679               0.672679             0.0675167
C8          0.653724               0.653724             0.0656141
C16         0.546428               0.546428             0.0548449
C10         0.543099               0.543099             0.0545107
C6          0.540989               0.540989             0.054299
C3          0.474539               0.474539             0.0476294
C5          0.460215               0.460215             0.0461918
C4          0.41115                0.41115              0.0412671
C2          0.346595               0.346595             0.0347877
C1          0.340699               0.340699             0.0341959
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_62

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008038138573169817  0.00021453143563121557  0.0         -0.014201816511331344  0.28121185302734375  0.04101097323519997  0.1864711046218872
    3        26       Softmax                      0.0   0.0   0.004320414560005212   0.0073869191110134125   0.0         -0.3606687491975698    0.8924925327301025   -0.8431256196257491  0.6226263046264648


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3734993529849786
RMSE: 0.6111459342783674
LogLoss: 1.102199103636762
Mean Per-Class Error: 0.26881528467263033
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  3.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    1.0    3.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    7.0    0.0    0.0    1.0    5.0    0.0    4.0    0.0    0.09390862944162437  37 / 394
0.0    314.0  0.0    14.0   0.0    2.0    6.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    17.0   2.0    2.0    8.0    1.0    0.0    0.0    1.0    2.0    10.0   1.0    0.0    0.1801566579634465   69 / 383
0.0    5.0    291.0  0.0    5.0    0.0    20.0   0.0    0.0    0.0    27.0   0.0    0.0    0.0    4.0    1.0    0.0    0.0    1.0    0.0    2.0    0.0    6.0    6.0    0.0    0.0    0.20923913043478262  77 / 368
3.0    19.0   0.0    319.0  0.0    0.0    5.0    2.0    0.0    6.0    0.0    0.0    8.0    1.0    13.0   1.0    0.0    5.0    3.0    0.0    0.0    0.0    0.0    11.0   0.0    7.0    0.20843672456575682  84 / 403
0.0    7.0    3.0    1.0    265.0  2.0    27.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    4.0    7.0    19.0   0.0    1.0    0.0    0.0    18.0   0.0    24.0   0.30809399477806787  118 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    5.0    0.0    16.0   1.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    3.0    0.0    14.0   3.0    0.0    1.0    1.0    6.0    2.0    9.0    2.0    0.0    0.0    2.0    0.0    2.0    0.0    22.0   3.0    1.0    3.0    0.0    290.0  10.0   20.0   0.2639593908629442   104 / 394
0.0    0.0    0.0    2.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    9.0    0.0    9.0    52.0   1.0    46.0   6.0    0.0    249.0  0.0    0.366412213740458    144 / 393
3.0    2.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    46.0   2.0    0.0    0.0    0.0    2.0    0.0    299.0  0.18528610354223432  68 / 367
414.0  538.0  367.0  520.0  317.0  305.0  352.0  180.0  334.0  348.0  415.0  324.0  480.0  362.0  483.0  388.0  284.0  387.0  387.0  410.0  346.0  399.0  450.0  450.0  332.0  431.0  0.26781965410376884  2,679 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.73218
2    0.83335
3    0.872238
4    0.89873
5    0.925522
6    0.940918
7    0.954614
8    0.964911
9    0.971709
10   0.977907

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.375087859250626
RMSE: 0.6124441682721993
LogLoss: 1.1006499250727775
Mean Per-Class Error: 0.27160690687981853
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12     13    14     15     16    17    18    19    20    21    22     23     24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   3.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0   0.0   2.0    0.0    2.0   0.0    0.10112359550561797  9 / 89
0.0    80.0   0.0   4.0    0.0   0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   8.0    1.0    2.0   4.0   0.0   0.0   0.0   1.0   1.0    3.0    0.0   0.0    0.24528301886792453  26 / 106
0.0    3.0    59.0  0.0    0.0   0.0   8.0   0.0   0.0   0.0   7.0    0.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   2.0    1.0    0.0   0.0    0.2804878048780488   23 / 82
3.0    1.0    0.0   94.0   0.0   0.0   2.0   1.0   0.0   0.0   0.0    0.0   3.0    0.0   3.0    0.0    0.0   1.0   1.0   0.0   0.0   0.0   0.0    1.0    0.0   2.0    0.16071428571428573  18 / 112
0.0    3.0    0.0   0.0    63.0  1.0   5.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0    0.0    1.0   2.0   6.0   0.0   0.0   0.0   0.0    5.0    0.0   10.0   0.35051546391752575  34 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   2.0    0.0   3.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   85.0   0.0    0.0   0.0    0.07608695652173914  7 / 92
0.0    1.0    0.0   5.0    1.0   0.0   0.0   0.0   4.0   0.0   4.0    0.0   0.0    0.0   0.0    0.0    1.0   0.0   7.0   0.0   0.0   0.0   0.0    69.0   3.0   5.0    0.31                 31 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   4.0    2.0    4.0   0.0   1.0   12.0  0.0   14.0  2.0    0.0    67.0  0.0    0.37383177570093457  40 / 107
0.0    1.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   9.0   1.0   0.0   0.0   0.0    1.0    0.0   72.0   0.1724137931034483   15 / 87
100.0  129.0  76.0  146.0  69.0  75.0  81.0  51.0  81.0  98.0  102.0  91.0  105.0  92.0  114.0  108.0  81.0  99.0  92.0  98.0  90.0  91.0  113.0  104.0  90.0  114.0  0.27068273092369477  674 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.729317
2    0.838554
3    0.874699
4    0.906426
5    0.93012
6    0.945783
7    0.954618
8    0.963454
9    0.969478
10   0.978715
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:05  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:06  2 min 43.953 sec  151621 obs/sec    1         1             10007      0.854418         2.18069             0.987024       0.53234                          0.85379            2.17316               0.987011         0.536145
    2019-07-23 13:34:06  2 min 44.449 sec  184631 obs/sec    10        10            100070     0.611146         1.1022              0.993361       0.26782                          0.612444           1.10065               0.993316         0.270683
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.103871
C15         0.976219               0.976219             0.101401
C9          0.805085               0.805085             0.0836248
C8          0.695225               0.695225             0.0722136
C7          0.688617               0.688617             0.0715272
C11         0.663968               0.663968             0.0689668
C14         0.651912               0.651912             0.0677147
C3          0.566041               0.566041             0.0587951
C12         0.532851               0.532851             0.0553477
C10         0.511324               0.511324             0.0531116
C16         0.504043               0.504043             0.0523553
C6          0.502659               0.502659             0.0522116
C5          0.491347               0.491347             0.0510366
C4          0.415047               0.415047             0.0431113
C1          0.327131               0.327131             0.0339794
C2          0.295876               0.295876             0.0307329
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_71

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011242837978215903  0.00031745608430355787  0.0         -0.04401945271365548   1.113701343536377   0.164787062553797    1.0073204040527344
    3        26       Softmax                 0.0   0.0   0.0017774731512382948  0.00018846802413463593  0.0         -0.004481310290290052  0.5833001136779785  -0.4604601695879306  0.265134334564209


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3399952060076514
RMSE: 0.5830910786555145
LogLoss: 1.1000999053033038
Mean Per-Class Error: 0.3126630784907143
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  0.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    9.0    0.0    0.0    6.0    4.0    7.0    0.0    2.0    1.0    1.0    0.0    0.0    1.0    7.0    0.0    4.0    0.0    0.116751269035533    46 / 394
0.0    268.0  0.0    6.0    0.0    1.0    1.0    18.0   0.0    5.0    0.0    0.0    5.0    0.0    0.0    6.0    4.0    45.0   19.0   0.0    0.0    0.0    2.0    2.0    0.0    1.0    0.3002610966057441   115 / 383
0.0    2.0    281.0  0.0    16.0   3.0    17.0   2.0    2.0    0.0    12.0   0.0    0.0    0.0    3.0    1.0    8.0    2.0    6.0    3.0    4.0    0.0    5.0    0.0    0.0    1.0    0.23641304347826086  87 / 368
11.0   25.0   0.0    275.0  0.0    2.0    0.0    18.0   0.0    20.0   0.0    1.0    4.0    4.0    3.0    13.0   0.0    18.0   3.0    1.0    1.0    0.0    0.0    1.0    1.0    2.0    0.3176178660049628   128 / 403
0.0    16.0   15.0   0.0    204.0  9.0    25.0   2.0    2.0    2.0    9.0    0.0    0.0    0.0    0.0    2.0    16.0   5.0    8.0    10.0   0.0    0.0    0.0    17.0   0.0    42.0   0.46875              180 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    1.0    11.0   0.0    0.0    0.0    0.0    22.0   9.0    0.0    0.0    2.0    3.0    0.0    0.0    2.0    8.0    317.0  0.0    0.0    0.0    0.15691489361702127  59 / 376
4.0    23.0   0.0    8.0    3.0    2.0    0.0    3.0    15.0   15.0   6.0    3.0    0.0    0.0    7.0    0.0    10.0   7.0    9.0    28.0   2.0    1.0    0.0    235.0  4.0    9.0    0.4035532994923858   159 / 394
0.0    3.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    5.0    7.0    8.0    0.0    9.0    79.0   2.0    58.0   4.0    0.0    209.0  0.0    0.4681933842239186   184 / 393
2.0    7.0    0.0    1.0    8.0    4.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    47.0   4.0    0.0    0.0    0.0    3.0    3.0    276.0  0.24795640326975477  91 / 367
456.0  593.0  364.0  400.0  297.0  392.0  323.0  336.0  347.0  373.0  301.0  320.0  462.0  368.0  396.0  409.0  401.0  424.0  298.0  435.0  391.0  415.0  450.0  323.0  310.0  419.0  0.31190642807157853  3,120 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.688094
2    0.813756
3    0.86664
4    0.897231
5    0.917025
6    0.93232
7    0.942117
8    0.952514
9    0.959112
10   0.96691

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.34282878933383887
RMSE: 0.5855158318387632
LogLoss: 1.107681210817472
Mean Per-Class Error: 0.3117437769086313
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17    18    19     20     21    22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  ----  ----  -----  -----  ----  -----  ----  ----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    2.0    0.0   0.0    0.0    1.0   0.0   0.0    0.0    0.0   1.0    0.0   2.0   0.0    0.0898876404494382   8 / 89
0.0    77.0   0.0   1.0    0.0   0.0   0.0   6.0   0.0   1.0    0.0   0.0   2.0    0.0    0.0   2.0    2.0    9.0   4.0   0.0    0.0    0.0   2.0    0.0   0.0   0.0    0.27358490566037735  29 / 106
0.0    2.0    59.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0    2.0   1.0    3.0    0.0   2.0   1.0    2.0    0.0   1.0    0.0   0.0   0.0    0.2804878048780488   23 / 82
4.0    7.0    0.0   82.0   0.0   0.0   0.0   3.0   0.0   4.0    0.0   0.0   2.0    1.0    0.0   2.0    0.0    4.0   2.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0    0.26785714285714285  30 / 112
0.0    4.0    3.0   0.0    44.0  3.0   8.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0    0.0   2.0    4.0    2.0   2.0   1.0    0.0    0.0   0.0    3.0   0.0   18.0   0.5463917525773195   53 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---   ---   ---    ---    ---   ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   5.0    2.0    0.0   0.0    1.0    1.0   0.0   0.0    1.0    1.0   80.0   0.0   0.0   0.0    0.13043478260869565  12 / 92
0.0    6.0    0.0   3.0    2.0   0.0   0.0   2.0   2.0   1.0    1.0   0.0   0.0    0.0    1.0   0.0    2.0    4.0   2.0   9.0    1.0    0.0   0.0    56.0  2.0   6.0    0.44                 44 / 100
0.0    2.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    3.0   3.0    3.0    0.0   1.0   21.0   0.0    19.0  1.0    0.0   51.0  0.0    0.5233644859813084   56 / 107
0.0    1.0    0.0   1.0    1.0   2.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   9.0   1.0    0.0    0.0   0.0    2.0   1.0   66.0   0.2413793103448276   21 / 87
118.0  152.0  77.0  115.0  63.0  92.0  84.0  88.0  78.0  103.0  72.0  84.0  102.0  102.0  71.0  121.0  109.0  99.0  77.0  101.0  106.0  99.0  107.0  78.0  81.0  111.0  0.31204819277108437  777 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.687952
2    0.819679
3    0.868273
4    0.897189
5    0.914056
6    0.929719
7    0.940161
8    0.951004
9    0.955823
10   0.964659
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:26  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:26  3 min  4.567 sec  89348 obs/sec     1         1             10007      0.725632         1.59264             0.990642       0.447566                         0.719252           1.56192               0.990782         0.433735
    2019-07-23 13:34:27  3 min  5.582 sec  90479 obs/sec     10        10            100070     0.583091         1.1001              0.993957       0.311906                         0.585516           1.10768               0.993891         0.312048
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0954855
C15         0.839527               0.839527             0.0801627
C12         0.796257               0.796257             0.076031
C9          0.795737               0.795737             0.0759813
C7          0.753226               0.753226             0.0719222
C14         0.747195               0.747195             0.0713463
C11         0.745664               0.745664             0.0712002
C8          0.7164                 0.7164               0.0684059
C10         0.648323               0.648323             0.0619054
C6          0.63632                0.63632              0.0607594
C16         0.606366               0.606366             0.0578991
C3          0.523845               0.523845             0.0500197
C5          0.504918               0.504918             0.0482123
C1          0.409506               0.409506             0.0391019
C4          0.39527                0.39527              0.0377425
C2          0.354236               0.354236             0.0338244
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_23

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008226045786727809  0.00024304602993652225  0.0         -0.01527028216708004  0.29496848583221436  -0.00847360237638406  0.2199881672859192
    3        26       Softmax                      0.0   0.0   0.0038910252616145813  0.0060114506632089615   0.0         -0.3040456600570346   0.8614611625671387   -0.8621461162285637   0.5293400287628174


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.37534835884229767
RMSE: 0.6126568034734435
LogLoss: 1.1034987009634503
Mean Per-Class Error: 0.2696758769016131
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    1.0    0.0    11.0   0.0    2.0    0.0    1.0    0.0    12.0   0.0    1.0    2.0    6.0    1.0    3.0    0.0    0.11392405063291139  45 / 395
0.0    282.0  0.0    8.0    0.0    1.0    2.0    0.0    3.0    0.0    6.0    0.0    4.0    0.0    4.0    3.0    2.0    39.0   12.0   0.0    0.0    0.0    2.0    15.0   0.0    0.0    0.26370757180156656  101 / 383
0.0    0.0    304.0  0.0    10.0   1.0    9.0    1.0    0.0    0.0    32.0   0.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    2.0    2.0    0.0    2.0    0.0    0.0    0.0    0.17391304347826086  64 / 368
4.0    13.0   0.0    310.0  0.0    1.0    0.0    0.0    1.0    9.0    2.0    1.0    7.0    2.0    4.0    1.0    0.0    12.0   3.0    0.0    1.0    0.0    0.0    32.0   0.0    0.0    0.23076923076923078  93 / 403
0.0    8.0    5.0    1.0    266.0  0.0    14.0   0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    13.0   8.0    1.0    4.0    2.0    0.0    0.0    22.0   5.0    28.0   0.3072916666666667   118 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    18.0   4.0    0.0    0.0    0.0    11.0   0.0    0.0    2.0    1.0    338.0  0.0    0.0    0.0    0.09866666666666667  37 / 375
1.0    3.0    0.0    11.0   9.0    0.0    1.0    0.0    2.0    1.0    5.0    1.0    0.0    0.0    0.0    0.0    5.0    5.0    9.0    3.0    11.0   0.0    0.0    305.0  14.0   8.0    0.22588832487309646  89 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    20.0   0.0    6.0    37.0   2.0    40.0   4.0    3.0    269.0  2.0    0.3155216284987277   124 / 393
5.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    28.0   3.0    0.0    0.0    0.0    9.0    0.0    302.0  0.1771117166212534   65 / 367
403.0  423.0  391.0  441.0  359.0  309.0  261.0  187.0  341.0  337.0  447.0  320.0  489.0  351.0  349.0  387.0  385.0  503.0  276.0  374.0  406.0  353.0  502.0  545.0  397.0  467.0  0.26861941417574725  2,687 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.731381
2    0.843547
3    0.887334
4    0.912626
5    0.931421
6    0.945216
7    0.954514
8    0.963411
9    0.970009
10   0.974208

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3773632010857701
RMSE: 0.614298950907268
LogLoss: 1.108835899240189
Mean Per-Class Error: 0.27512709234037236
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9     10     11    12     13    14    15     16     17     18    19    20    21    22     23     24     25     Error                Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   1.0   2.0    0.0    2.0    0.0    0.0898876404494382   8 / 89
0.0   71.0  0.0   3.0    0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0    0.0   4.0   0.0    1.0    13.0   5.0   0.0   0.0   0.0   2.0    5.0    0.0    0.0    0.330188679245283    35 / 106
0.0   0.0   64.0  0.0    2.0   0.0   4.0   1.0   0.0   0.0   8.0    0.0   0.0    0.0   1.0   0.0    0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0    0.0    0.0    0.21951219512195122  18 / 82
2.0   2.0   0.0   92.0   0.0   0.0   0.0   0.0   1.0   2.0   1.0    0.0   2.0    1.0   1.0   0.0    0.0    2.0    1.0   0.0   0.0   0.0   0.0    5.0    0.0    0.0    0.17857142857142858  20 / 112
0.0   2.0   1.0   0.0    60.0  0.0   4.0   0.0   0.0   0.0   4.0    0.0   0.0    0.0   0.0   0.0    4.0    3.0    0.0   2.0   0.0   0.0   0.0    4.0    0.0    13.0   0.38144329896907214  37 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0    1.0   0.0   0.0    0.0    2.0    0.0   0.0   0.0   0.0   85.0   0.0    0.0    0.0    0.07608695652173914  7 / 92
0.0   2.0   0.0   3.0    3.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    1.0    3.0    2.0   0.0   2.0   0.0   0.0    74.0   5.0    3.0    0.26                 26 / 100
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0   0.0    7.0    0.0    2.0   8.0   0.0   11.0  2.0    2.0    73.0   0.0    0.3177570093457944   34 / 107
2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0    5.0   1.0   0.0   0.0   0.0    4.0    0.0    71.0   0.1839080459770115   16 / 87
94.0  96.0  83.0  125.0  84.0  59.0  62.0  44.0  77.0  98.0  117.0  93.0  109.0  88.0  79.0  111.0  109.0  128.0  70.0  91.0  99.0  81.0  125.0  133.0  112.0  123.0  0.27389558232931727  682 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.726104
2    0.841365
3    0.895984
4    0.917671
5    0.934137
6    0.948594
7    0.956225
8    0.962651
9    0.969478
10   0.973092
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:29  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:29  1 min  7.327 sec  158841 obs/sec    1         1             10007      0.839912         2.11211             0.987464       0.53424                          0.838436           2.10581               0.987474         0.528916
    2019-07-23 13:32:29  1 min  7.820 sec  186350 obs/sec    10        10            100070     0.612657         1.1035              0.99333        0.268619                         0.614299           1.10884               0.993276         0.273896
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.101347
C15         0.857331               0.857331             0.0868883
C9          0.772444               0.772444             0.0782852
C8          0.75578                0.75578              0.0765963
C11         0.738533               0.738533             0.0748484
C7          0.737959               0.737959             0.0747902
C12         0.735628               0.735628             0.0745539
C14         0.608227               0.608227             0.0616422
C6          0.563464               0.563464             0.0571056
C10         0.552742               0.552742             0.056019
C4          0.525725               0.525725             0.0532809
C5          0.475601               0.475601             0.0482009
C3          0.460198               0.460198             0.0466399
C16         0.45022                0.45022              0.0456286
C1          0.338748               0.338748             0.0343312
C2          0.294454               0.294454             0.0298421
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_14

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008050990393826396  0.00023429951397702098  0.0         -0.03194769129049746  0.28764188289642334  0.05515893503232817  0.1914713978767395
    3        26       Softmax                      0.0   0.0   0.0043203172544263695  0.00733005627989769     0.0         -0.35722700133248086  0.8942224979400635   -0.7909845600380814  0.6334888935089111


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.37318916386505463
RMSE: 0.610892104929385
LogLoss: 1.0951482638914554
Mean Per-Class Error: 0.2682448403147718
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
347.0  4.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    4.0    3.0    0.0    6.0    0.0    6.0    0.0    5.0    0.0    0.0    2.0    1.0    5.0    5.0    1.0    1.0    1.0    0.12151898734177215  48 / 395
0.0    322.0  0.0    10.0   0.0    0.0    5.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    3.0    2.0    0.0    22.0   10.0   0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.15926892950391644  61 / 383
0.0    0.0    293.0  1.0    13.0   1.0    11.0   2.0    0.0    0.0    15.0   1.0    1.0    0.0    3.0    0.0    11.0   0.0    8.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.20380434782608695  75 / 368
1.0    28.0   0.0    312.0  2.0    0.0    3.0    11.0   1.0    4.0    0.0    0.0    5.0    5.0    4.0    1.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.22580645161290322  91 / 403
0.0    5.0    12.0   0.0    277.0  3.0    14.0   0.0    0.0    0.0    7.0    1.0    0.0    0.0    1.0    2.0    13.0   4.0    11.0   3.0    0.0    0.0    0.0    5.0    0.0    26.0   0.2786458333333333   107 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    24.0   7.0    2.0    0.0    0.0    4.0    0.0    0.0    1.0    2.0    331.0  0.0    0.0    0.0    0.1196808510638298   45 / 376
0.0    8.0    0.0    2.0    15.0   0.0    1.0    0.0    1.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    22.0   1.0    14.0   5.0    2.0    0.0    0.0    291.0  7.0    18.0   0.2614213197969543   103 / 394
0.0    2.0    0.0    0.0    0.0    9.0    4.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    24.0   0.0    1.0    45.0   0.0    56.0   0.0    1.0    245.0  0.0    0.37659033078880405  148 / 393
0.0    13.0   0.0    0.0    24.0   2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    9.0    0.0    25.0   2.0    0.0    0.0    0.0    2.0    0.0    285.0  0.22343324250681199  82 / 367
394.0  599.0  376.0  438.0  386.0  323.0  312.0  238.0  345.0  326.0  366.0  312.0  475.0  355.0  399.0  381.0  429.0  388.0  292.0  407.0  389.0  422.0  473.0  401.0  318.0  459.0  0.2669199240227932   2,670 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.73308
2    0.839748
3    0.884135
4    0.912526
5    0.930721
6    0.944917
7    0.955313
8    0.964711
9    0.972008
10   0.977207

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3769176753615009
RMSE: 0.6139362144078984
LogLoss: 1.1090319543213378
Mean Per-Class Error: 0.2732836223470091
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20     21     22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -----  -----  ----  ----  -----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   1.0    0.0   2.0   0.0    1.0    0.0    0.0   0.0    0.0    3.0    1.0    0.0   1.0   0.0    0.12359550561797752  11 / 89
0.0   82.0   0.0   3.0    0.0   0.0   2.0   1.0   1.0   0.0   1.0   0.0   0.0    0.0   2.0   1.0    0.0    10.0   1.0   0.0    0.0    1.0    0.0    1.0   0.0   0.0    0.22641509433962265  24 / 106
0.0   0.0    58.0  0.0    2.0   1.0   3.0   1.0   0.0   0.0   5.0   0.0   0.0    0.0   1.0   0.0    5.0    0.0    3.0   0.0    1.0    0.0    2.0    0.0   0.0   0.0    0.2926829268292683   24 / 82
1.0   5.0    0.0   92.0   0.0   0.0   2.0   2.0   0.0   2.0   0.0   0.0   2.0    2.0   1.0   0.0    0.0    2.0    0.0   0.0    0.0    0.0    0.0    1.0   0.0   0.0    0.17857142857142858  20 / 112
0.0   0.0    5.0   0.0    66.0  3.0   5.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    3.0    1.0    2.0   2.0    0.0    0.0    0.0    1.0   0.0   7.0    0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---    ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   6.0    1.0   1.0   0.0    0.0    1.0    0.0   0.0    0.0    1.0    82.0   0.0   0.0   0.0    0.10869565217391304  10 / 92
0.0   3.0    0.0   2.0    7.0   0.0   1.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0    5.0   0.0    1.0    0.0    0.0    72.0  3.0   2.0    0.28                 28 / 100
0.0   1.0    0.0   0.0    0.0   2.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0   3.0   0.0    7.0    0.0    0.0   9.0    0.0    12.0   0.0    0.0   71.0  0.0    0.3364485981308411   36 / 107
0.0   3.0    0.0   0.0    8.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    2.0    0.0    4.0   1.0    0.0    0.0    0.0    0.0   0.0   68.0   0.21839080459770116  19 / 87
91.0  142.0  79.0  125.0  95.0  70.0  80.0  58.0  81.0  90.0  99.0  89.0  105.0  91.0  81.0  113.0  111.0  101.0  78.0  101.0  101.0  100.0  117.0  94.0  89.0  109.0  0.2714859437751004   676 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.728514
2    0.83253
3    0.883936
4    0.914056
5    0.930522
6    0.942972
7    0.953414
8    0.961847
9    0.971486
10   0.977109
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:07  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:07  45.367 sec  181945 obs/sec    1         1             10007      0.83977          2.09071             0.987471       0.509947                         0.840104           2.09102               0.987424         0.506024
    2019-07-23 13:32:07  45.866 sec  188811 obs/sec    10        10            100070     0.610892         1.09515             0.99337        0.26692                          0.613936           1.10903               0.993284         0.271486
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0994059
C15         0.999511               0.999511             0.0993573
C12         0.876689               0.876689             0.0871481
C9          0.779382               0.779382             0.0774752
C8          0.751299               0.751299             0.0746835
C11         0.692583               0.692583             0.0688469
C7          0.672887               0.672887             0.0668889
C14         0.654922               0.654922             0.0651031
C10         0.562925               0.562925             0.055958
C6          0.539162               0.539162             0.0535959
C4          0.483148               0.483148             0.0480278
C16         0.476825               0.476825             0.0473992
C3          0.465242               0.465242             0.0462478
C5          0.434534               0.434534             0.0431953
C1          0.367314               0.367314             0.0365132
C2          0.303341               0.303341             0.0301539
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_79

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011268225475760119  0.000285329413600266    0.0         0.038030287198125734   2.033479690551758   0.04927575493094986  1.469621181488037
    3        26       Softmax                 0.0   0.0   0.001685216146982454   0.00012813060311600566  0.0         -0.024154236911272164  0.5046021938323975  -0.5981660236239779  0.34496569633483887


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.46394835969437676
RMSE: 0.6811375482928369
LogLoss: 1.3937340432973786
Mean Per-Class Error: 0.3774845764425386
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    1.0    0.0    1.0    0.0    2.0    0.0    2.0    2.0    2.0    9.0    2.0    3.0    0.0    0.0    3.0    6.0    0.0    2.0    0.0    6.0    1.0    4.0    0.0    0.11645569620253164  46 / 395
0.0    264.0  0.0    11.0   0.0    1.0    3.0    10.0   9.0    10.0   0.0    0.0    3.0    0.0    1.0    0.0    7.0    27.0   27.0   0.0    0.0    0.0    2.0    1.0    1.0    6.0    0.31070496083550914  119 / 383
0.0    3.0    207.0  0.0    62.0   9.0    16.0   1.0    0.0    0.0    13.0   1.0    3.0    0.0    4.0    7.0    4.0    0.0    5.0    0.0    24.0   0.0    7.0    0.0    0.0    2.0    0.4375               161 / 368
7.0    30.0   0.0    260.0  0.0    0.0    0.0    17.0   0.0    17.0   0.0    2.0    2.0    6.0    4.0    13.0   0.0    24.0   3.0    0.0    0.0    0.0    0.0    15.0   2.0    0.0    0.35323383084577115  142 / 402
0.0    17.0   4.0    0.0    207.0  2.0    11.0   0.0    12.0   2.0    5.0    2.0    1.0    0.0    0.0    0.0    19.0   7.0    10.0   10.0   2.0    0.0    0.0    23.0   4.0    46.0   0.4609375            177 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    48.0   0.0    4.0    0.0    1.0    2.0    0.0    0.0    0.0    26.0   291.0  0.0    0.0    0.0    0.22606382978723405  85 / 376
12.0   19.0   0.0    5.0    19.0   1.0    2.0    0.0    15.0   7.0    14.0   6.0    1.0    0.0    0.0    0.0    38.0   6.0    10.0   12.0   10.0   0.0    0.0    200.0  13.0   4.0    0.49238578680203043  194 / 394
0.0    3.0    0.0    3.0    0.0    15.0   0.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    6.0    11.0   9.0    0.0    5.0    70.0   1.0    117.0  5.0    0.0    141.0  1.0    0.6412213740458015   252 / 393
3.0    18.0   0.0    5.0    25.0   1.0    3.0    0.0    0.0    4.0    1.0    2.0    0.0    0.0    0.0    7.0    1.0    5.0    32.0   6.0    0.0    0.0    0.0    7.0    0.0    247.0  0.32697547683923706  120 / 367
431.0  653.0  295.0  388.0  410.0  423.0  290.0  188.0  350.0  382.0  300.0  350.0  569.0  341.0  352.0  395.0  414.0  473.0  235.0  418.0  421.0  474.0  459.0  334.0  247.0  411.0  0.37588723382985106  3,760 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.624113
2    0.76807
3    0.829551
4    0.86634
5    0.892532
6    0.914126
7    0.928022
8    0.940118
9    0.950215
10   0.957213

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.466692259345048
RMSE: 0.6831487827296833
LogLoss: 1.3990531549936727
Mean Per-Class Error: 0.3896734005083552
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9      10    11     12     13    14    15     16     17     18    19    20    21     22     23    24    25     Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  -----  -----  -----  ----  ----  ----  -----  -----  ----  ----  -----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0    1.0   0.0   0.0    0.0    1.0    1.0   0.0   0.0   0.0    2.0    1.0   1.0   0.0    0.10112359550561797  9 / 89
0.0    70.0   0.0   1.0    0.0    0.0   1.0   3.0   2.0   5.0    0.0   0.0    2.0    0.0   0.0   0.0    4.0    10.0   5.0   0.0   0.0   0.0    2.0    1.0   0.0   0.0    0.33962264150943394  36 / 106
0.0    0.0    46.0  0.0    13.0   3.0   4.0   0.0   0.0   0.0    4.0   0.0    1.0    0.0   2.0   3.0    2.0    0.0    2.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    0.43902439024390244  36 / 82
4.0    10.0   0.0   73.0   0.0    0.0   0.0   6.0   0.0   3.0    0.0   1.0    1.0    1.0   1.0   5.0    0.0    4.0    1.0   0.0   0.0   0.0    0.0    2.0   0.0   0.0    0.3482142857142857   39 / 112
0.0    3.0    1.0   0.0    51.0   1.0   3.0   0.0   3.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0    6.0    4.0    3.0   5.0   0.0   0.0    0.0    4.0   0.0   11.0   0.4742268041237113   46 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---    ---    ---    ---   ---   ---   ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    12.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0   4.0    76.0   0.0   0.0   0.0    0.17391304347826086  16 / 92
4.0    2.0    0.0   0.0    5.0    0.0   1.0   0.0   4.0   1.0    5.0   1.0    0.0    0.0   0.0   0.0    5.0    3.0    4.0   3.0   3.0   0.0    0.0    53.0  5.0   1.0    0.47                 47 / 100
0.0    2.0    0.0   0.0    0.0    3.0   0.0   3.0   0.0   0.0    0.0   0.0    0.0    0.0   2.0   3.0    4.0    0.0    0.0   17.0  0.0   33.0   2.0    0.0   38.0  0.0    0.6448598130841121   69 / 107
0.0    3.0    0.0   3.0    8.0    0.0   0.0   0.0   0.0   1.0    1.0   1.0    0.0    0.0   0.0   1.0    0.0    1.0    7.0   3.0   0.0   0.0    0.0    1.0   0.0   57.0   0.3448275862068966   30 / 87
107.0  162.0  67.0  106.0  101.0  95.0  69.0  56.0  77.0  110.0  69.0  101.0  134.0  79.0  76.0  115.0  107.0  116.0  58.0  99.0  99.0  112.0  123.0  86.0  66.0  100.0  0.3899598393574297   971 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.61004
2    0.759839
3    0.821285
4    0.864257
5    0.889157
6    0.914458
7    0.928113
8    0.942169
9    0.951406
10   0.961446
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:46  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:46  3 min 24.741 sec  103164 obs/sec    1         1             10007      0.753622         1.71133             0.989909       0.469359                         0.752852           1.71005               0.989901         0.471084
    2019-07-23 13:34:47  3 min 25.680 sec  98688 obs/sec     10        10            100070     0.681138         1.39373             0.991757       0.375887                         0.683149           1.39905               0.991684         0.38996
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0971035
C12         0.921334               0.921334             0.0894647
C13         0.901799               0.901799             0.0875678
C9          0.889731               0.889731             0.086396
C14         0.762448               0.762448             0.0740364
C8          0.760441               0.760441             0.0738415
C11         0.757432               0.757432             0.0735493
C7          0.739306               0.739306             0.0717893
C10         0.641527               0.641527             0.0622945
C6          0.546109               0.546109             0.0530291
C16         0.511437               0.511437             0.0496624
C5          0.418717               0.418717             0.0406589
C3          0.418127               0.418127             0.0406016
C1          0.382133               0.382133             0.0371064
C4          0.362036               0.362036             0.0351549
C2          0.285711               0.285711             0.0277436
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_60

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011190018771003452  0.00031464744824916124  0.0         -0.16227260721780112  2.054492950439453   -0.4138523168821646  1.3065237998962402
    3        26       Softmax                 0.0   0.0   0.001676080808325563   0.00010072157601825893  0.0         -0.03188280899590049  0.5031054019927979  -0.5777863090835914  0.3573390245437622


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.47504414323968436
RMSE: 0.6892344617324966
LogLoss: 1.4041159913898968
Mean Per-Class Error: 0.3972312170739686
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    5.0    0.0    0.0    0.0    3.0    0.0    0.0    3.0    0.0    10.0   0.0    4.0    0.0    1.0    0.0    2.0    0.0    0.0    1.0    6.0    0.0    5.0    0.0    0.10126582278481013  40 / 395
0.0    211.0  0.0    11.0   0.0    1.0    3.0    15.0   3.0    7.0    0.0    0.0    1.0    0.0    1.0    1.0    4.0    75.0   40.0   0.0    0.0    1.0    2.0    2.0    0.0    5.0    0.4490861618798956   172 / 383
0.0    4.0    257.0  0.0    25.0   1.0    16.0   0.0    1.0    0.0    16.0   0.0    7.0    0.0    2.0    1.0    13.0   1.0    4.0    5.0    6.0    0.0    3.0    0.0    6.0    0.0    0.3016304347826087   111 / 368
11.0   12.0   0.0    272.0  0.0    2.0    0.0    11.0   0.0    8.0    3.0    0.0    3.0    5.0    5.0    13.0   0.0    37.0   13.0   0.0    0.0    0.0    0.0    6.0    1.0    1.0    0.3250620347394541   131 / 403
0.0    22.0   52.0   0.0    140.0  4.0    14.0   1.0    16.0   2.0    5.0    0.0    0.0    0.0    0.0    0.0    19.0   7.0    22.0   5.0    1.0    0.0    0.0    12.0   3.0    59.0   0.6354166666666666   244 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    1.0    0.0    35.0   5.0    0.0    4.0    0.0    4.0    0.0    0.0    0.0    26.0   286.0  0.0    1.0    0.0    0.2393617021276596   90 / 376
31.0   11.0   2.0    3.0    24.0   0.0    0.0    5.0    26.0   13.0   8.0    4.0    0.0    0.0    3.0    0.0    24.0   6.0    32.0   13.0   3.0    0.0    0.0    136.0  18.0   32.0   0.6548223350253807   258 / 394
0.0    1.0    0.0    8.0    0.0    37.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    4.0    1.0    14.0   8.0    0.0    3.0    67.0   1.0    59.0   4.0    0.0    182.0  0.0    0.5368956743002544   211 / 393
3.0    3.0    0.0    5.0    15.0   10.0   0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    2.0    34.0   2.0    0.0    0.0    0.0    4.0    0.0    280.0  0.23705722070844687  87 / 367
461.0  458.0  463.0  426.0  270.0  423.0  272.0  214.0  382.0  361.0  278.0  314.0  541.0  385.0  289.0  394.0  456.0  564.0  363.0  392.0  373.0  376.0  443.0  269.0  353.0  483.0  0.3956812956113166   3,958 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.604319
2    0.761372
3    0.83145
4    0.872338
5    0.90013
6    0.919924
7    0.93402
8    0.946616
9    0.956813
10   0.964211

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.47248366234853967
RMSE: 0.6873744702478698
LogLoss: 1.3990946687543047
Mean Per-Class Error: 0.390890079580615
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19    20    21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0    0.0    1.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   3.0    0.0   2.0    0.0    0.0898876404494382   8 / 89
0.0    52.0   0.0   1.0    0.0   0.0   1.0   5.0   0.0   3.0    0.0   0.0   0.0    0.0    1.0   1.0    2.0    26.0   9.0   0.0   0.0   1.0   1.0    1.0   0.0    2.0    0.5094339622641509   54 / 106
0.0    2.0    49.0  0.0    4.0   1.0   7.0   0.0   0.0   0.0    5.0   0.0   0.0    0.0    2.0   0.0    4.0    0.0    1.0   1.0   1.0   0.0   2.0    0.0   3.0    0.0    0.4024390243902439   33 / 82
6.0    2.0    0.0   78.0   0.0   0.0   0.0   3.0   0.0   0.0    2.0   0.0   1.0    1.0    1.0   3.0    0.0    10.0   5.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.30357142857142855  34 / 112
0.0    5.0    16.0  0.0    34.0  1.0   5.0   0.0   2.0   0.0    2.0   0.0   0.0    0.0    0.0   0.0    6.0    2.0    5.0   2.0   0.0   0.0   0.0    2.0   1.0    14.0   0.6494845360824743   63 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   8.0    1.0    0.0   1.0    0.0    0.0    0.0   0.0   0.0   5.0   75.0   0.0   1.0    0.0    0.18478260869565216  17 / 92
5.0    4.0    0.0   1.0    8.0   0.0   0.0   4.0   4.0   3.0    3.0   1.0   0.0    0.0    0.0   0.0    4.0    1.0    9.0   4.0   0.0   0.0   0.0    37.0  4.0    8.0    0.63                 63 / 100
0.0    1.0    0.0   4.0    0.0   8.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0    1.0    1.0   4.0    2.0    0.0    0.0   14.0  0.0   15.0  0.0    0.0   55.0   0.0    0.48598130841121495  52 / 107
0.0    1.0    0.0   2.0    3.0   2.0   0.0   0.0   1.0   2.0    0.0   0.0   0.0    0.0    0.0   2.0    0.0    0.0    5.0   0.0   0.0   0.0   0.0    1.0   0.0    68.0   0.21839080459770116  19 / 87
108.0  106.0  94.0  119.0  61.0  90.0  78.0  50.0  82.0  103.0  82.0  90.0  115.0  104.0  55.0  115.0  116.0  144.0  96.0  83.0  99.0  87.0  117.0  70.0  103.0  123.0  0.3895582329317269   970 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.610442
2    0.760241
3    0.835743
4    0.875904
5    0.898795
6    0.920884
7    0.934137
8    0.948594
9    0.956225
10   0.964257
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:01  2 min 39.237 sec  80701 obs/sec     1         1             10007      0.750999         1.70481             0.989979       0.474858                         0.7509             1.70755               0.989953         0.472289
    2019-07-23 13:34:02  2 min 40.148 sec  98688 obs/sec     10        10            100070     0.689234         1.40412             0.99156        0.395681                         0.687374           1.39909               0.991581         0.389558
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0933608
C15         0.941266               0.941266             0.0878774
C13         0.938161               0.938161             0.0875875
C12         0.897003               0.897003             0.083745
C14         0.772458               0.772458             0.0721173
C11         0.771085               0.771085             0.0719892
C7          0.768054               0.768054             0.0717061
C8          0.735879               0.735879             0.0687022
C10         0.697971               0.697971             0.0651631
C16         0.593043               0.593043             0.055367
C6          0.589614               0.589614             0.0550469
C3          0.501757               0.501757             0.0468445
C5          0.43822                0.43822              0.0409126
C1          0.392118               0.392118             0.0366085
C4          0.367588               0.367588             0.0343183
C2          0.306913               0.306913             0.0286536
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_92

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011169630954555032  0.0002969655906781554   0.0         -0.10919609808115638  2.074422836303711   -0.29298662822206345  1.1943325996398926
    3        26       Softmax                 0.0   0.0   0.0016756280916664624  0.00011996744433417916  0.0         0.059964716621508915  0.5045504570007324  -0.590667354835561    0.36205577850341797


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.46592831219887465
RMSE: 0.6825894169988828
LogLoss: 1.400059205769837
Mean Per-Class Error: 0.3854538361142978
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  2.0    0.0    7.0    0.0    0.0    2.0    1.0    0.0    0.0    1.0    1.0    8.0    1.0    4.0    0.0    0.0    2.0    2.0    0.0    1.0    0.0    7.0    0.0    4.0    0.0    0.10886075949367088  43 / 395
0.0    275.0  0.0    9.0    1.0    0.0    5.0    8.0    3.0    6.0    2.0    0.0    4.0    0.0    9.0    3.0    10.0   31.0   11.0   0.0    0.0    5.0    0.0    0.0    1.0    0.0    0.2819843342036554   108 / 383
0.0    5.0    234.0  2.0    32.0   6.0    34.0   0.0    0.0    0.0    20.0   1.0    11.0   0.0    1.0    0.0    6.0    1.0    5.0    3.0    4.0    1.0    2.0    0.0    0.0    0.0    0.3641304347826087   134 / 368
14.0   29.0   0.0    234.0  1.0    3.0    0.0    11.0   1.0    47.0   0.0    3.0    9.0    0.0    6.0    17.0   0.0    21.0   4.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.417910447761194    168 / 402
0.0    17.0   3.0    0.0    195.0  7.0    48.0   0.0    4.0    1.0    5.0    0.0    2.0    0.0    0.0    1.0    15.0   5.0    13.0   8.0    0.0    0.0    0.0    14.0   6.0    40.0   0.4921875            189 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    4.0    4.0    0.0    0.0    2.0    0.0    45.0   3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    19.0   295.0  0.0    0.0    0.0    0.2154255319148936   81 / 376
36.0   14.0   0.0    3.0    26.0   1.0    1.0    3.0    18.0   2.0    4.0    7.0    0.0    0.0    0.0    0.0    21.0   1.0    35.0   24.0   3.0    0.0    1.0    128.0  24.0   42.0   0.6751269035532995   266 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    5.0    4.0    10.0   0.0    7.0    105.0  4.0    75.0   3.0    0.0    164.0  0.0    0.5816326530612245   228 / 392
5.0    12.0   0.0    2.0    21.0   3.0    2.0    0.0    0.0    2.0    1.0    1.0    0.0    0.0    1.0    0.0    3.0    2.0    53.0   5.0    0.0    0.0    0.0    3.0    1.0    250.0  0.3188010899182561   117 / 367
512.0  647.0  310.0  387.0  349.0  344.0  390.0  178.0  345.0  413.0  288.0  317.0  616.0  336.0  324.0  410.0  413.0  414.0  289.0  424.0  412.0  447.0  456.0  203.0  359.0  420.0  0.38408477456762974  3,842 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.615915
2    0.76787
3    0.83405
4    0.871239
5    0.894232
6    0.914726
7    0.930821
8    0.942117
9    0.952214
10   0.959912

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4670674003520866
RMSE: 0.6834232951488313
LogLoss: 1.4073808298767465
Mean Per-Class Error: 0.3922578921448071
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19    20     21     22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -------------------  -----------
80.0   0.0    0.0   1.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    1.0    1.0   0.0   0.0    0.0    3.0    0.0   2.0    0.0    0.10112359550561797  9 / 89
0.0    69.0   0.0   1.0    0.0   0.0   1.0   2.0   0.0   1.0    0.0   0.0   1.0    0.0   3.0   1.0    7.0    13.0   4.0   0.0   0.0    3.0    0.0    0.0   0.0    0.0    0.3490566037735849   37 / 106
0.0    1.0    54.0  1.0    3.0   1.0   6.0   0.0   0.0   0.0    7.0   0.0   1.0    0.0   0.0   0.0    3.0    1.0    2.0   1.0   0.0    0.0    1.0    0.0   0.0    0.0    0.34146341463414637  28 / 82
7.0    7.0    0.0   63.0   0.0   0.0   0.0   6.0   0.0   11.0   0.0   1.0   3.0    0.0   2.0   5.0    0.0    5.0    1.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0    0.4375               49 / 112
0.0    7.0    1.0   0.0    45.0  4.0   12.0  0.0   1.0   1.0    2.0   0.0   0.0    0.0   0.0   0.0    3.0    1.0    5.0   2.0   0.0    0.0    0.0    6.0   0.0    7.0    0.5360824742268041   52 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---    ---    ---   ---    ---    ---                  ---
0.0    2.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   8.0    1.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    3.0    77.0   0.0   0.0    0.0    0.16304347826086957  15 / 92
7.0    6.0    0.0   2.0    9.0   0.0   0.0   1.0   4.0   1.0    1.0   0.0   0.0    0.0   0.0   0.0    4.0    1.0    12.0  3.0   1.0    0.0    0.0    27.0  9.0    12.0   0.73                 73 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0    0.0   3.0   1.0    3.0    0.0    0.0   22.0  0.0    27.0   0.0    0.0   48.0   0.0    0.5514018691588785   59 / 107
1.0    3.0    0.0   2.0    6.0   1.0   0.0   0.0   0.0   0.0    1.0   1.0   0.0    0.0   1.0   0.0    0.0    0.0    13.0  1.0   0.0    0.0    0.0    2.0   0.0    55.0   0.367816091954023    32 / 87
121.0  159.0  74.0  105.0  76.0  73.0  94.0  51.0  73.0  116.0  82.0  85.0  133.0  92.0  64.0  121.0  113.0  105.0  79.0  97.0  104.0  112.0  115.0  42.0  101.0  103.0  0.39156626506024095  975 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.608434
2    0.760241
3    0.83253
4    0.870683
5    0.892771
6    0.909639
7    0.929317
8    0.939759
9    0.951004
10   0.959036
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:20  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:20  3 min 58.645 sec  94405 obs/sec     1         1             10007      0.758598         1.73647             0.989773       0.486754                         0.755903           1.72116               0.989819         0.481928
    2019-07-23 13:35:21  3 min 59.660 sec  91807 obs/sec     10        10            100070     0.682589         1.40006             0.99172        0.384085                         0.683423           1.40738               0.991678         0.391566
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0931401
C15         0.98947                0.98947              0.0921593
C11         0.926436               0.926436             0.0862883
C12         0.925116               0.925116             0.0861655
C13         0.888744               0.888744             0.0827778
C14         0.835957               0.835957             0.0778612
C7          0.816842               0.816842             0.0760807
C8          0.718319               0.718319             0.0669043
C10         0.693039               0.693039             0.0645497
C6          0.607089               0.607089             0.0565443
C16         0.530944               0.530944             0.0494522
C3          0.444012               0.444012             0.0413553
C1          0.381894               0.381894             0.0355697
C5          0.374681               0.374681             0.0348978
C4          0.354967               0.354967             0.0330617
C2          0.249001               0.249001             0.023192
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_22

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011341577562689054  0.00031901581678539515  0.0         0.07807801307353657   2.1389331817626953  -0.31641948811803944  1.5483956336975098
    3        26       Softmax                 0.0   0.0   0.0016706399500645392  9.909830987453461e-05   0.0         0.008947500619893408  0.5064215660095215  -0.5831607881250526   0.3517721891403198


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.48180707040121673
RMSE: 0.6941232386264105
LogLoss: 1.4417098543522264
Mean Per-Class Error: 0.4005256703674279
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
339.0  0.0    0.0    6.0    0.0    0.0    0.0    7.0    0.0    2.0    1.0    8.0    5.0    2.0    0.0    0.0    1.0    8.0    0.0    0.0    2.0    1.0    5.0    1.0    6.0    1.0    0.14177215189873418  56 / 395
2.0    231.0  0.0    29.0   0.0    0.0    3.0    9.0    1.0    23.0   1.0    0.0    9.0    0.0    3.0    2.0    13.0   38.0   11.0   0.0    0.0    4.0    0.0    2.0    1.0    1.0    0.3968668407310705   152 / 383
0.0    2.0    215.0  0.0    51.0   7.0    37.0   0.0    4.0    0.0    15.0   0.0    5.0    0.0    2.0    2.0    6.0    0.0    7.0    8.0    3.0    0.0    3.0    0.0    1.0    0.0    0.4157608695652174   153 / 368
9.0    10.0   0.0    239.0  0.0    1.0    0.0    5.0    0.0    40.0   0.0    0.0    12.0   2.0    31.0   11.0   1.0    25.0   3.0    3.0    0.0    0.0    0.0    8.0    0.0    3.0    0.40694789081885857  164 / 403
0.0    14.0   6.0    0.0    184.0  0.0    38.0   0.0    17.0   1.0    5.0    0.0    1.0    0.0    2.0    0.0    23.0   17.0   10.0   16.0   0.0    0.0    0.0    19.0   1.0    30.0   0.5208333333333334   200 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    33.0   13.0   0.0    0.0    2.0    1.0    0.0    0.0    2.0    33.0   289.0  0.0    0.0    0.0    0.23138297872340424  87 / 376
48.0   11.0   0.0    12.0   15.0   0.0    1.0    2.0    18.0   20.0   6.0    16.0   0.0    0.0    2.0    0.0    4.0    0.0    10.0   24.0   1.0    0.0    0.0    155.0  16.0   33.0   0.6065989847715736   239 / 394
0.0    1.0    0.0    2.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    1.0    10.0   0.0    4.0    64.0   0.0    63.0   8.0    0.0    220.0  2.0    0.4402035623409669   173 / 393
7.0    9.0    0.0    7.0    11.0   1.0    1.0    0.0    16.0   0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    2.0    26.0   3.0    0.0    0.0    0.0    20.0   0.0    257.0  0.2997275204359673   110 / 367
495.0  491.0  310.0  451.0  329.0  340.0  364.0  137.0  362.0  411.0  239.0  338.0  550.0  409.0  387.0  441.0  386.0  456.0  250.0  382.0  403.0  468.0  448.0  328.0  413.0  415.0  0.39898030590822753  3,991 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.60102
2    0.760472
3    0.826952
4    0.86634
5    0.894332
6    0.912226
7    0.931221
8    0.944816
9    0.954813
10   0.962911

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4791951262231104
RMSE: 0.692239211705831
LogLoss: 1.439902824609909
Mean Per-Class Error: 0.3991526028985447
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19    20     21     22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -------------------  -----------
74.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0   0.0    0.0    0.0   0.0    0.0    4.0    0.0   0.0   0.0    0.0    2.0    1.0   3.0    0.0    0.16853932584269662  15 / 89
0.0    57.0   0.0   7.0    0.0   0.0   2.0   6.0   0.0   6.0    1.0   0.0   1.0    0.0    2.0   0.0    6.0    13.0   2.0   0.0   0.0    2.0    0.0    1.0   0.0    0.0    0.46226415094339623  49 / 106
0.0    0.0    45.0  0.0    12.0  1.0   7.0   0.0   1.0   0.0    4.0   0.0   0.0    0.0    1.0   1.0    4.0    0.0    2.0   2.0   1.0    0.0    1.0    0.0   0.0    0.0    0.45121951219512196  37 / 82
5.0    5.0    0.0   74.0   0.0   0.0   0.0   1.0   0.0   7.0    0.0   0.0   3.0    1.0    6.0   2.0    1.0    4.0    1.0   0.0   0.0    0.0    0.0    0.0   0.0    2.0    0.3392857142857143   38 / 112
0.0    4.0    1.0   0.0    48.0  0.0   8.0   0.0   2.0   0.0    1.0   0.0   0.0    0.0    2.0   0.0    6.0    3.0    2.0   5.0   0.0    0.0    0.0    8.0   0.0    7.0    0.5051546391752577   49 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---    ---    ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   7.0    4.0    0.0   0.0    2.0    0.0    0.0   0.0   0.0    4.0    75.0   0.0   0.0    0.0    0.18478260869565216  17 / 92
9.0    2.0    0.0   5.0    4.0   0.0   0.0   2.0   3.0   3.0    2.0   6.0   0.0    0.0    0.0   0.0    1.0    0.0    3.0   9.0   1.0    0.0    0.0    37.0  2.0    11.0   0.63                 63 / 100
0.0    0.0    0.0   0.0    0.0   2.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0    3.0    0.0   0.0    5.0    0.0    0.0   17.0  0.0    14.0   2.0    0.0   62.0   0.0    0.4205607476635514   45 / 107
0.0    1.0    0.0   2.0    4.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0   0.0    0.0    0.0   3.0    0.0    0.0    3.0   2.0   0.0    0.0    0.0    8.0   0.0    61.0   0.2988505747126437   26 / 87
110.0  121.0  65.0  132.0  83.0  74.0  83.0  40.0  76.0  106.0  59.0  92.0  120.0  109.0  82.0  123.0  107.0  114.0  61.0  95.0  108.0  104.0  118.0  95.0  108.0  105.0  0.3967871485943775   988 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.603213
2    0.74739
3    0.817671
4    0.861847
5    0.890361
6    0.908434
7    0.926506
8    0.94257
9    0.953815
10   0.96506
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:28  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:28  1 min  6.197 sec  89348 obs/sec     1         1             10007      0.752781         1.70656             0.989931       0.469159                         0.749956           1.69864               0.989978         0.462651
    2019-07-23 13:32:29  1 min  7.227 sec  89910 obs/sec     10        10            100070     0.694123         1.44171             0.991439       0.39898                          0.692239           1.4399                0.991461         0.396787
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0859831
C13         0.998685               0.998685             0.08587
C9          0.931593               0.931593             0.0801012
C12         0.925812               0.925812             0.0796042
C7          0.894106               0.894106             0.076878
C11         0.882461               0.882461             0.0758767
C14         0.853354               0.853354             0.073374
C8          0.829418               0.829418             0.0713159
C10         0.739649               0.739649             0.0635973
C16         0.60261                0.60261              0.0518142
C3          0.597928               0.597928             0.0514117
C6          0.533532               0.533532             0.0458748
C5          0.499604               0.499604             0.0429575
C1          0.486108               0.486108             0.0417971
C4          0.451224               0.451224             0.0387977
C2          0.40411                0.40411              0.0347467
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_19

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011382802430830452  0.0003279248485341668   0.0         -0.26377148232018044   2.0306739807128906  -0.10669898283972579  0.9417879581451416
    3        26       Softmax                 0.0   0.0   0.0016668506993412918  0.00010817314614541829  0.0         -0.035278941286098695  0.5075297355651855  -0.602589673554479    0.38624143600463867


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4909428393700502
RMSE: 0.7006731330442535
LogLoss: 1.458449960762021
Mean Per-Class Error: 0.4108467110344772
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
331.0  0.0    0.0    12.0   0.0    0.0    3.0    2.0    0.0    2.0    1.0    3.0    12.0   1.0    0.0    0.0    2.0    11.0   1.0    0.0    2.0    3.0    3.0    0.0    5.0    0.0    0.1598984771573604   63 / 394
1.0    173.0  0.0    9.0    5.0    0.0    3.0    5.0    18.0   1.0    2.0    1.0    4.0    1.0    2.0    8.0    13.0   60.0   59.0   0.0    3.0    1.0    1.0    3.0    1.0    9.0    0.5483028720626631   210 / 383
0.0    0.0    221.0  0.0    44.0   1.0    42.0   1.0    0.0    0.0    26.0   2.0    5.0    2.0    0.0    5.0    2.0    1.0    10.0   3.0    2.0    0.0    0.0    0.0    0.0    1.0    0.39945652173913043  147 / 368
3.0    13.0   0.0    267.0  0.0    0.0    0.0    8.0    4.0    7.0    0.0    12.0   2.0    11.0   18.0   11.0   2.0    26.0   3.0    4.0    1.0    0.0    0.0    7.0    0.0    4.0    0.337468982630273    136 / 403
0.0    6.0    24.0   0.0    201.0  2.0    46.0   0.0    9.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    14.0   7.0    16.0   3.0    6.0    2.0    0.0    14.0   0.0    33.0   0.4765625            183 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    12.0   13.0   0.0    0.0    1.0    15.0   0.0    0.0    0.0    21.0   306.0  0.0    0.0    0.0    0.18617021276595744  70 / 376
27.0   6.0    6.0    9.0    31.0   0.0    3.0    1.0    26.0   0.0    4.0    21.0   0.0    0.0    2.0    0.0    21.0   3.0    19.0   9.0    12.0   0.0    0.0    121.0  7.0    66.0   0.6928934010152284   273 / 394
0.0    1.0    0.0    0.0    0.0    15.0   2.0    4.0    0.0    0.0    1.0    0.0    0.0    2.0    2.0    11.0   11.0   0.0    4.0    65.0   10.0   89.0   4.0    0.0    172.0  0.0    0.5623409669211196   221 / 393
0.0    13.0   0.0    6.0    32.0   1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    7.0    3.0    31.0   5.0    0.0    0.0    0.0    6.0    0.0    259.0  0.29427792915531337  108 / 367
436.0  325.0  345.0  457.0  442.0  307.0  434.0  170.0  382.0  300.0  282.0  353.0  420.0  428.0  347.0  435.0  414.0  579.0  343.0  417.0  389.0  430.0  470.0  230.0  359.0  509.0  0.4093771868439468   4,095 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.590623
2    0.753474
3    0.819654
4    0.858143
5    0.886634
6    0.905728
7    0.923123
8    0.936819
9    0.948116
10   0.958513

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.49145869875999404
RMSE: 0.7010411533997088
LogLoss: 1.4557943029293878
Mean Per-Class Error: 0.4171298372525762
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1     2     3      4      5     6      7     8     9     10    11    12    13     14    15     16     17     18    19    20     21     22     23    24    25     Error                Rate
-----  ----  ----  -----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  -----  -----  ----  ----  -----  -------------------  -------------
75.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    1.0    5.0    0.0   0.0   0.0    1.0    2.0    0.0   2.0   0.0    0.15730337078651685  14 / 89
0.0    43.0  0.0   1.0    0.0    0.0   1.0    1.0   5.0   0.0   0.0   1.0   1.0   1.0    1.0   2.0    11.0   21.0   12.0  0.0   1.0    0.0    1.0    1.0   0.0   2.0    0.5943396226415094   63 / 106
0.0    0.0   45.0  0.0    11.0   0.0   10.0   0.0   0.0   0.0   6.0   0.0   0.0   1.0    0.0   4.0    1.0    1.0    1.0   2.0   0.0    0.0    0.0    0.0   0.0   0.0    0.45121951219512196  37 / 82
1.0    5.0   0.0   83.0   0.0    0.0   0.0    4.0   0.0   1.0   0.0   4.0   1.0   3.0    4.0   1.0    0.0    3.0    1.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.25892857142857145  29 / 112
0.0    0.0   10.0  0.0    48.0   2.0   12.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    3.0    6.0   1.0   2.0    0.0    0.0    2.0   0.0   5.0    0.5051546391752577   49 / 97
---    ---   ---   ---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---    ---    ---   ---   ---    ---                  ---
0.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   4.0   5.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0    2.0    79.0   0.0   0.0   0.0    0.14130434782608695  13 / 92
5.0    3.0   1.0   1.0    10.0   0.0   1.0    1.0   9.0   0.0   2.0   4.0   0.0   0.0    0.0   0.0    3.0    0.0    5.0   1.0   5.0    0.0    0.0    34.0  2.0   13.0   0.66                 66 / 100
0.0    1.0   0.0   0.0    0.0    3.0   0.0    2.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   3.0    5.0    0.0    0.0   16.0  3.0    29.0   2.0    0.0   42.0  0.0    0.6074766355140186   65 / 107
0.0    2.0   0.0   3.0    8.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0    0.0    7.0   3.0   0.0    0.0    0.0    2.0   0.0   59.0   0.3218390804597701   28 / 87
103.0  85.0  70.0  135.0  102.0  65.0  110.0  44.0  94.0  78.0  69.0  92.0  93.0  110.0  76.0  122.0  111.0  153.0  84.0  97.0  101.0  105.0  124.0  67.0  89.0  111.0  0.41566265060240964  1,035 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.584337
2    0.75743
3    0.822088
4    0.856626
5    0.888353
6    0.904819
7    0.922892
8    0.938956
9    0.950602
10   0.960642
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:32:19  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:32:20  58.032 sec  81357 obs/sec     1         1             10007      0.762214         1.74024             0.989675       0.479856                         0.759624           1.72195               0.989718         0.468273
    2019-07-23 13:32:21  58.943 sec  98883 obs/sec     10        10            100070     0.700673         1.45845             0.991275       0.409377                         0.701041           1.45579               0.991243         0.415663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0946358
C12         0.932201               0.932201             0.0882196
C13         0.917654               0.917654             0.0868429
C9          0.881445               0.881445             0.0834162
C11         0.766958               0.766958             0.0725817
C7          0.746465               0.746465             0.0706423
C8          0.738217               0.738217             0.0698618
C14         0.66525                0.66525              0.0629565
C10         0.661959               0.661959             0.062645
C16         0.55636                0.55636              0.0526516
C6          0.528328               0.528328             0.0499987
C3          0.502815               0.502815             0.0475843
C5          0.490223               0.490223             0.0463927
C1          0.406714               0.406714             0.0384897
C4          0.393197               0.393197             0.0372105
C2          0.379039               0.379039             0.0358707
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_86

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011426677715462574  0.00033135199919342995  0.0         0.06917135598268942   2.2103023529052734  -0.021318138176688217  1.260267734527588
    3        26       Softmax                 0.0   0.0   0.0016758758122775292  0.00011045584687963128  0.0         -0.04572000143826489  0.4951791763305664  -0.5874942055387138    0.3813406229019165


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5037139979759195
RMSE: 0.7097281155315178
LogLoss: 1.490114004598124
Mean Per-Class Error: 0.4168385923415593
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  0.0    0.0    10.0   0.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    10.0   0.0    1.0    0.0    1.0    5.0    3.0    0.0    0.0    0.0    7.0    0.0    5.0    0.0    0.1189873417721519   47 / 395
1.0    239.0  0.0    25.0   0.0    1.0    2.0    6.0    10.0   1.0    0.0    0.0    10.0   0.0    1.0    2.0    15.0   39.0   22.0   0.0    0.0    0.0    1.0    5.0    3.0    0.0    0.37597911227154046  144 / 383
0.0    0.0    229.0  0.0    34.0   3.0    40.0   1.0    8.0    1.0    11.0   0.0    8.0    0.0    1.0    1.0    15.0   1.0    6.0    2.0    1.0    0.0    5.0    1.0    0.0    0.0    0.37771739130434784  139 / 368
9.0    23.0   0.0    284.0  0.0    2.0    0.0    13.0   2.0    8.0    1.0    3.0    5.0    7.0    3.0    12.0   0.0    14.0   6.0    0.0    1.0    0.0    1.0    5.0    0.0    4.0    0.29528535980148884  119 / 403
0.0    4.0    19.0   2.0    169.0  5.0    43.0   1.0    20.0   5.0    2.0    0.0    0.0    0.0    1.0    2.0    19.0   12.0   20.0   5.0    0.0    0.0    0.0    19.0   0.0    36.0   0.5598958333333334   215 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    32.0   17.0   1.0    1.0    8.0    1.0    0.0    0.0    0.0    32.0   277.0  0.0    0.0    0.0    0.2632978723404255   99 / 376
5.0    16.0   0.0    31.0   21.0   4.0    25.0   1.0    31.0   1.0    1.0    10.0   0.0    0.0    2.0    3.0    12.0   1.0    31.0   33.0   2.0    0.0    0.0    115.0  8.0    41.0   0.7081218274111675   279 / 394
0.0    0.0    1.0    5.0    0.0    14.0   0.0    5.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    11.0   17.0   0.0    0.0    130.0  1.0    74.0   3.0    0.0    126.0  2.0    0.6793893129770993   267 / 393
6.0    7.0    0.0    4.0    9.0    4.0    0.0    0.0    2.0    1.0    0.0    1.0    0.0    0.0    1.0    12.0   2.0    1.0    41.0   5.0    0.0    0.0    0.0    34.0   2.0    234.0  0.36065573770491804  132 / 366
476.0  513.0  332.0  560.0  296.0  320.0  350.0  192.0  434.0  319.0  261.0  311.0  587.0  384.0  294.0  454.0  504.0  420.0  318.0  524.0  337.0  448.0  434.0  266.0  257.0  412.0  0.41517544736579026  4,153 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.584825
2    0.744677
3    0.813556
4    0.854144
5    0.879736
6    0.902229
7    0.917925
8    0.93382
9    0.947716
10   0.957313

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.500928693697508
RMSE: 0.7077631621506647
LogLoss: 1.481614749977432
Mean Per-Class Error: 0.41779533988176976
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16     17     18    19     20    21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  -----  ----  -----  ----  -----  -----  ----  ----  -----  -------------------  -------------
79.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.0    0.0    1.0    1.0   0.0    0.0   0.0    3.0    0.0   2.0   0.0    0.11235955056179775  10 / 89
1.0    64.0   0.0   3.0    0.0   0.0   0.0   3.0   2.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0    8.0    12.0   4.0   0.0    0.0   0.0    1.0    3.0   1.0   0.0    0.39622641509433965  42 / 106
0.0    0.0    46.0  0.0    7.0   2.0   6.0   1.0   3.0   0.0   5.0   0.0   0.0    0.0    1.0   0.0    6.0    1.0    2.0   0.0    0.0   0.0    2.0    0.0   0.0   0.0    0.43902439024390244  36 / 82
4.0    8.0    0.0   81.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   3.0   2.0    2.0    1.0   4.0    0.0    2.0    2.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0    0.2767857142857143   31 / 112
0.0    2.0    4.0   1.0    43.0  1.0   10.0  0.0   3.0   1.0   2.0   0.0   0.0    0.0    0.0   1.0    7.0    5.0    4.0   1.0    0.0   0.0    0.0    3.0   0.0   9.0    0.5567010309278351   54 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---    ---   ---    ---   ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   6.0    8.0    0.0   0.0    1.0    0.0    0.0   0.0    0.0   7.0    69.0   0.0   0.0   0.0    0.25                 23 / 92
1.0    6.0    0.0   10.0   5.0   0.0   3.0   1.0   5.0   0.0   0.0   3.0   0.0    0.0    0.0   0.0    4.0    0.0    9.0   12.0   1.0   0.0    0.0    28.0  0.0   12.0   0.72                 72 / 100
0.0    0.0    0.0   2.0    0.0   1.0   0.0   2.0   0.0   0.0   0.0   0.0   1.0    1.0    0.0   2.0    6.0    0.0    0.0   35.0   0.0   20.0   1.0    0.0   36.0  0.0    0.6635514018691588   71 / 107
0.0    1.0    0.0   3.0    3.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0    1.0    0.0    11.0  2.0    0.0   0.0    0.0    9.0   0.0   54.0   0.3793103448275862   33 / 87
116.0  138.0  65.0  149.0  76.0  70.0  77.0  41.0  94.0  82.0  71.0  88.0  131.0  105.0  53.0  131.0  143.0  106.0  87.0  119.0  91.0  109.0  111.0  68.0  68.0  101.0  0.41566265060240964  1,035 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.584337
2    0.738554
3    0.810843
4    0.85261
5    0.8751
6    0.90241
7    0.920482
8    0.933333
9    0.948193
10   0.957831
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:35:07  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:35:07  3 min 45.180 sec  100070 obs/sec    1         1             10007      0.768916         1.79572             0.989493       0.494852                         0.766611           1.78349               0.989528         0.487952
    2019-07-23 13:35:08  3 min 46.180 sec  92915 obs/sec     10        10            100070     0.709728         1.49011             0.991048       0.415175                         0.707763           1.48161               0.991074         0.415663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.090419
C15         0.952546               0.952546             0.0861283
C9          0.931166               0.931166             0.0841951
C12         0.879569               0.879569             0.0795297
C11         0.84139                0.84139              0.0760777
C14         0.806386               0.806386             0.0729126
C7          0.79681                0.79681              0.0720468
C8          0.641687               0.641687             0.0580207
C16         0.629847               0.629847             0.0569501
C3          0.594271               0.594271             0.0537334
C6          0.579223               0.579223             0.0523727
C10         0.557002               0.557002             0.0503635
C5          0.515475               0.515475             0.0466087
C4          0.470675               0.470675             0.0425579
C1          0.463963               0.463963             0.0419511
C2          0.399613               0.399613             0.0361326
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_110

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight         weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.001119249687917545   0.000322093372233212   0.0         0.1380638745995384  2.245634078979492   -0.35831993568122145  1.4572176933288574
    3        26       Softmax                 0.0   0.0   0.0016467605703208111  8.305651135742664e-05  0.0         0.0197966202907677  0.4988213777542114  -0.5991439666476895   0.35922515392303467


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5160715049727751
RMSE: 0.7183811696952914
LogLoss: 1.5252928913427921
Mean Per-Class Error: 0.42323551086841704
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    11.0   0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    8.0    2.0    0.0    0.0    5.0    2.0    2.0    0.0    1.0    1.0    8.0    0.0    4.0    0.0    0.11645569620253164  46 / 395
1.0    258.0  0.0    20.0   0.0    0.0    0.0    21.0   11.0   0.0    1.0    0.0    2.0    1.0    0.0    6.0    5.0    33.0   19.0   0.0    1.0    0.0    1.0    0.0    2.0    1.0    0.3263707571801567   125 / 383
0.0    0.0    243.0  0.0    46.0   9.0    15.0   0.0    0.0    0.0    18.0   0.0    0.0    3.0    2.0    0.0    4.0    0.0    7.0    3.0    10.0   0.0    6.0    0.0    0.0    2.0    0.33967391304347827  125 / 368
4.0    40.0   0.0    249.0  0.0    0.0    0.0    11.0   4.0    4.0    1.0    4.0    10.0   6.0    22.0   4.0    0.0    27.0   8.0    0.0    2.0    0.0    0.0    0.0    7.0    0.0    0.38213399503722084  154 / 403
1.0    8.0    22.0   0.0    169.0  1.0    28.0   0.0    3.0    2.0    17.0   0.0    0.0    0.0    1.0    0.0    11.0   17.0   22.0   4.0    1.0    0.0    0.0    10.0   0.0    66.0   0.5587467362924282   214 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    40.0   21.0   0.0    0.0    1.0    1.0    0.0    0.0    8.0    15.0   283.0  0.0    0.0    0.0    0.24331550802139038  91 / 374
28.0   15.0   11.0   1.0    17.0   0.0    1.0    10.0   35.0   7.0    11.0   1.0    0.0    2.0    4.0    1.0    2.0    9.0    19.0   4.0    16.0   2.0    0.0    107.0  7.0    84.0   0.7284263959390863   287 / 394
0.0    1.0    0.0    4.0    0.0    2.0    0.0    9.0    0.0    0.0    3.0    0.0    2.0    6.0    0.0    6.0    7.0    0.0    1.0    131.0  2.0    99.0   8.0    0.0    107.0  5.0    0.727735368956743    286 / 393
1.0    16.0   0.0    2.0    12.0   2.0    2.0    0.0    5.0    0.0    0.0    7.0    0.0    0.0    0.0    1.0    1.0    4.0    39.0   3.0    0.0    0.0    0.0    9.0    0.0    263.0  0.28337874659400547  104 / 367
451.0  590.0  399.0  443.0  338.0  293.0  305.0  211.0  457.0  275.0  312.0  262.0  485.0  460.0  376.0  397.0  287.0  479.0  279.0  542.0  437.0  414.0  522.0  197.0  229.0  563.0  0.4215735279416175   4,217 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.578426
2    0.73268
3    0.811856
4    0.855143
5    0.886334
6    0.906528
7    0.922123
8    0.935219
9    0.948116
10   0.957613

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.513419476424423
RMSE: 0.716532955574566
LogLoss: 1.5164182560610366
Mean Per-Class Error: 0.41453282202874325
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8      9     10    11    12     13     14    15     16    17     18    19     20     21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  -----  -----  -----  -----  ----  ----  -----  -------------------  -------------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    1.0    0.0   0.0    2.0   0.0    1.0   0.0    0.0    0.0    2.0    0.0   2.0   0.0    0.10112359550561797  9 / 89
1.0    65.0   0.0   4.0    0.0   0.0   0.0   10.0  3.0    0.0   1.0   0.0   0.0    1.0    0.0   1.0    2.0   12.0   3.0   0.0    1.0    0.0    1.0    0.0   1.0   0.0    0.3867924528301887   41 / 106
0.0    0.0    51.0  0.0    9.0   1.0   5.0   0.0   0.0    0.0   5.0   0.0   0.0    0.0    2.0   0.0    1.0   0.0    2.0   1.0    1.0    0.0    3.0    0.0   0.0   1.0    0.3780487804878049   31 / 82
1.0    16.0   0.0   71.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0   1.0   4.0    1.0    7.0   0.0    0.0   4.0    3.0   0.0    1.0    0.0    0.0    0.0   0.0   0.0    0.36607142857142855  41 / 112
0.0    3.0    6.0   0.0    40.0  0.0   7.0   0.0   0.0    0.0   6.0   0.0   0.0    0.0    0.0   0.0    3.0   3.0    8.0   1.0    0.0    0.0    0.0    1.0   0.0   19.0   0.5876288659793815   57 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---    ---    ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   8.0    6.0    0.0   0.0    1.0   0.0    0.0   0.0    2.0    4.0    70.0   0.0   0.0   0.0    0.2391304347826087   22 / 92
5.0    3.0    5.0   0.0    5.0   0.0   1.0   4.0   5.0    0.0   3.0   0.0   0.0    0.0    0.0   1.0    1.0   2.0    6.0   2.0    4.0    0.0    0.0    29.0  1.0   23.0   0.71                 71 / 100
0.0    0.0    0.0   2.0    0.0   1.0   0.0   4.0   0.0    0.0   2.0   0.0   1.0    1.0    0.0   3.0    3.0   0.0    0.0   33.0   0.0    30.0   3.0    0.0   24.0  0.0    0.7757009345794392   83 / 107
0.0    3.0    0.0   1.0    5.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0    0.0   1.0    0.0   0.0    7.0   1.0    0.0    0.0    0.0    4.0   0.0   63.0   0.27586206896551724  24 / 87
104.0  150.0  83.0  119.0  77.0  63.0  83.0  65.0  101.0  75.0  90.0  69.0  100.0  123.0  79.0  116.0  76.0  117.0  79.0  130.0  107.0  109.0  127.0  53.0  50.0  145.0  0.41606425702811245  1,036 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.583936
2    0.730924
3    0.810843
4    0.852209
5    0.890763
6    0.909237
7    0.922891
8    0.936948
9    0.948193
10   0.959438
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:36:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:36:11  4 min 49.905 sec  94405 obs/sec     1         1             10007      0.760752         1.74603             0.989714       0.510147                         0.757223           1.72307               0.989783         0.50241
    2019-07-23 13:36:13  4 min 50.929 sec  90234 obs/sec     10        10            100070     0.718381         1.52529             0.990828       0.421574                         0.716533           1.51642               0.990852         0.416064
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0870253
C15         0.968565               0.968565             0.0842897
C9          0.964142               0.964142             0.0839048
C12         0.935332               0.935332             0.0813976
C11         0.870079               0.870079             0.0757189
C14         0.772691               0.772691             0.0672437
C7          0.768212               0.768212             0.066854
C8          0.747597               0.747597             0.0650598
C3          0.618914               0.618914             0.0538612
C10         0.617725               0.617725             0.0537577
C16         0.598054               0.598054             0.0520459
C6          0.584787               0.584787             0.0508913
C5          0.557854               0.557854             0.0485474
C1          0.518135               0.518135             0.0450908
C2          0.504824               0.504824             0.0439324
C4          0.463997               0.463997             0.0403795
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_59

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011673296995695637  0.00032559363171458244  0.0         -0.03841715899579867  2.179764747619629    0.08709466214584184  1.0509920120239258
    3        26       Softmax                 0.0   0.0   0.0016558090148744388  9.201417560689151e-05   0.0         0.018112556743373122  0.49285364151000977  -0.6042854811101424  0.37868785858154297


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5160173642010027
RMSE: 0.7183434862243847
LogLoss: 1.5327514082086857
Mean Per-Class Error: 0.44197011164716454
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
346.0  2.0    0.0    3.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    5.0    8.0    0.0    3.0    0.0    0.0    8.0    0.0    0.0    5.0    3.0    5.0    1.0    2.0    0.0    0.1240506329113924   49 / 395
1.0    217.0  0.0    12.0   7.0    1.0    0.0    2.0    9.0    6.0    2.0    0.0    7.0    0.0    2.0    4.0    10.0   48.0   45.0   0.0    1.0    0.0    3.0    2.0    4.0    0.0    0.43342036553524804  166 / 383
0.0    0.0    241.0  0.0    21.0   6.0    32.0   1.0    0.0    0.0    26.0   0.0    2.0    1.0    2.0    0.0    4.0    0.0    1.0    7.0    13.0   0.0    1.0    0.0    0.0    10.0   0.3451086956521739   127 / 368
9.0    30.0   0.0    231.0  0.0    0.0    0.0    5.0    0.0    30.0   0.0    2.0    5.0    3.0    20.0   19.0   0.0    34.0   5.0    1.0    2.0    0.0    1.0    6.0    0.0    0.0    0.4267990074441687   172 / 403
0.0    6.0    15.0   0.0    201.0  1.0    19.0   1.0    14.0   1.0    9.0    0.0    0.0    0.0    0.0    0.0    18.0   7.0    22.0   18.0   0.0    0.0    0.0    4.0    3.0    44.0   0.4751958224543081   182 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    48.0   9.0    1.0    0.0    1.0    2.0    0.0    0.0    1.0    40.0   268.0  0.0    0.0    0.0    0.2853333333333333   107 / 375
20.0   15.0   2.0    2.0    36.0   0.0    0.0    0.0    16.0   9.0    5.0    4.0    0.0    0.0    12.0   0.0    46.0   8.0    39.0   52.0   2.0    0.0    0.0    77.0   4.0    45.0   0.8045685279187818   317 / 394
0.0    0.0    0.0    2.0    0.0    8.0    0.0    1.0    0.0    0.0    1.0    0.0    4.0    2.0    0.0    10.0   15.0   0.0    3.0    136.0  3.0    115.0  10.0   1.0    81.0   1.0    0.7938931297709924   312 / 393
2.0    23.0   0.0    0.0    42.0   1.0    0.0    0.0    11.0   2.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    3.0    42.0   8.0    0.0    0.0    0.0    6.0    0.0    220.0  0.40054495912806537  147 / 367
504.0  520.0  384.0  356.0  436.0  297.0  301.0  127.0  404.0  332.0  215.0  329.0  619.0  252.0  344.0  498.0  450.0  536.0  328.0  579.0  485.0  460.0  438.0  194.0  199.0  416.0  0.44016794961511546  4,403 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.559832
2    0.715085
3    0.79956
4    0.847046
5    0.882335
6    0.903029
7    0.920424
8    0.936419
9    0.947016
10   0.955613

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.5142632174630558
RMSE: 0.7171214802688982
LogLoss: 1.522617362164723
Mean Per-Class Error: 0.4459475642066454
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3     4      5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20     21     22     23    24    25    Error                Rate
-----  -----  ----  ----  -----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -----  -----  ----  ----  ----  -------------------  -------------
81.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0    0.0    1.0    0.0   0.0    0.0    1.0    3.0    0.0   1.0   0.0   0.0898876404494382   8 / 89
1.0    50.0   0.0   4.0   0.0    1.0   0.0   1.0   2.0   1.0   1.0   0.0   3.0    0.0   0.0   1.0    5.0    16.0   14.0  0.0    1.0    0.0    2.0    1.0   2.0   0.0   0.5283018867924528   56 / 106
0.0    0.0    56.0  0.0   2.0    0.0   7.0   0.0   0.0   0.0   9.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0    0.0   2.0    0.0    0.0    0.0    0.0   0.0   4.0   0.3170731707317073   26 / 82
5.0    13.0   0.0   64.0  0.0    0.0   0.0   1.0   0.0   8.0   0.0   0.0   2.0    1.0   6.0   5.0    0.0    5.0    1.0   0.0    0.0    0.0    1.0    0.0   0.0   0.0   0.42857142857142855  48 / 112
0.0    1.0    8.0   0.0   45.0   1.0   6.0   0.0   1.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    4.0    1.0    5.0   7.0    0.0    0.0    0.0    2.0   0.0   13.0  0.5360824742268041   52 / 97
---    ---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---    ---    ---   ---   ---   ---                  ---
0.0    0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   11.0   1.0   0.0   0.0    1.0    0.0    0.0   0.0    0.0    6.0    72.0   0.0   0.0   0.0   0.21739130434782608  20 / 92
3.0    4.0    1.0   1.0   9.0    0.0   0.0   0.0   5.0   1.0   3.0   1.0   0.0    0.0   1.0   0.0    8.0    3.0    9.0   12.0   2.0    0.0    0.0    23.0  1.0   13.0  0.77                 77 / 100
0.0    0.0    0.0   0.0   0.0    2.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   3.0    6.0    0.0    0.0   32.0   1.0    37.0   3.0    0.0   20.0  0.0   0.8130841121495327   87 / 107
0.0    5.0    0.0   0.0   13.0   1.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0    13.0  3.0    0.0    0.0    0.0    1.0   0.0   47.0  0.45977011494252873  40 / 87
116.0  133.0  98.0  96.0  101.0  68.0  71.0  31.0  94.0  88.0  61.0  87.0  150.0  56.0  73.0  134.0  112.0  134.0  93.0  140.0  115.0  115.0  122.0  54.0  49.0  99.0  0.4469879518072289   1,113 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.553012
2    0.724498
3    0.807631
4    0.85261
5    0.888353
6    0.907631
7    0.92249
8    0.935341
9    0.948193
10   0.955823
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:34:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:34:00  2 min 38.119 sec  95304 obs/sec     1         1             10007      0.771014         1.8094              0.989436       0.509647                         0.772874           1.80782               0.989356         0.518876
    2019-07-23 13:34:01  2 min 39.071 sec  96967 obs/sec     10        10            100070     0.718343         1.53275             0.99083        0.440168                         0.717121           1.52262               0.990837         0.446988
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0919462
C9          0.991183               0.991183             0.0911355
C12         0.954409               0.954409             0.0877543
C13         0.896316               0.896316             0.0824128
C11         0.835957               0.835957             0.0768631
C7          0.817571               0.817571             0.0751725
C14         0.780561               0.780561             0.0717696
C8          0.672381               0.672381             0.0618229
C10         0.66374                0.66374              0.0610283
C16         0.561544               0.561544             0.0516318
C6          0.518457               0.518457             0.0476701
C3          0.506503               0.506503             0.046571
C1          0.442144               0.442144             0.0406534
C5          0.437751               0.437751             0.0402495
C4          0.399746               0.399746             0.0367551
C2          0.397668               0.397668             0.0365641
[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ]
                  activation  ...                 model_ids              logloss
0       RectifierWithDropout  ...   DL_random_grid_model_82   0.3711320890758745
1       RectifierWithDropout  ...   DL_random_grid_model_41   0.3763900887768799
2       RectifierWithDropout  ...   DL_random_grid_model_21   0.3870429506735884
3       RectifierWithDropout  ...  DL_random_grid_model_112   0.3886003901946542
4       RectifierWithDropout  ...   DL_random_grid_model_17    0.389559671798665
5       RectifierWithDropout  ...    DL_random_grid_model_4  0.39442694007075924
6       RectifierWithDropout  ...   DL_random_grid_model_88    0.435255020125103
7       RectifierWithDropout  ...   DL_random_grid_model_97  0.43576534595803446
8       RectifierWithDropout  ...   DL_random_grid_model_49  0.43743234374541595
9       RectifierWithDropout  ...    DL_random_grid_model_1   0.4377204479635536
10      RectifierWithDropout  ...   DL_random_grid_model_26   0.4392988053848215
11           TanhWithDropout  ...   DL_random_grid_model_13   0.4427564394164619
12      RectifierWithDropout  ...   DL_random_grid_model_27   0.4468889205766348
13      RectifierWithDropout  ...   DL_random_grid_model_78   0.4503980997565001
14      RectifierWithDropout  ...   DL_random_grid_model_33  0.45388386484197046
15      RectifierWithDropout  ...   DL_random_grid_model_70   0.4553700564650325
16      RectifierWithDropout  ...   DL_random_grid_model_29   0.4556649388665165
17           TanhWithDropout  ...   DL_random_grid_model_25   0.4607308998783082
18           TanhWithDropout  ...   DL_random_grid_model_89  0.47733961788872087
19           TanhWithDropout  ...   DL_random_grid_model_24  0.48315236694703295
20           TanhWithDropout  ...  DL_random_grid_model_104  0.48445761961230077
21           TanhWithDropout  ...   DL_random_grid_model_96    0.496767680757655
22           TanhWithDropout  ...   DL_random_grid_model_51  0.49984871273305437
23           TanhWithDropout  ...   DL_random_grid_model_45   0.5042610314803945
24           TanhWithDropout  ...   DL_random_grid_model_77   0.5061229593429812
25      RectifierWithDropout  ...   DL_random_grid_model_93   0.5170599787661931
26      RectifierWithDropout  ...   DL_random_grid_model_85   0.5175997822028726
27      RectifierWithDropout  ...   DL_random_grid_model_28   0.5239629131554563
28      RectifierWithDropout  ...   DL_random_grid_model_11   0.5320315731364251
29           TanhWithDropout  ...  DL_random_grid_model_101   0.5487662795512535
..  ..                   ...  ...                       ...                  ...
83           TanhWithDropout  ...    DL_random_grid_model_8   0.7608141879768353
84           TanhWithDropout  ...   DL_random_grid_model_30   0.7608854840285355
85           TanhWithDropout  ...   DL_random_grid_model_90   0.7636730405793919
86      RectifierWithDropout  ...   DL_random_grid_model_54    0.814722066410858
87      RectifierWithDropout  ...   DL_random_grid_model_91   0.8548045996189166
88      RectifierWithDropout  ...   DL_random_grid_model_40   0.8550415071456045
89      RectifierWithDropout  ...   DL_random_grid_model_64   0.8555327270379137
90      RectifierWithDropout  ...  DL_random_grid_model_105   0.8578165148442856
91      RectifierWithDropout  ...   DL_random_grid_model_43   0.8693944481067933
92           TanhWithDropout  ...  DL_random_grid_model_113   0.9730625983581738
93           TanhWithDropout  ...   DL_random_grid_model_15   0.9898737668138023
94           TanhWithDropout  ...   DL_random_grid_model_65   0.9920835896074431
95           TanhWithDropout  ...  DL_random_grid_model_111   0.9933247048014003
96           TanhWithDropout  ...   DL_random_grid_model_42   1.0227900322667813
97           TanhWithDropout  ...  DL_random_grid_model_107   1.0271744215384557
98           TanhWithDropout  ...   DL_random_grid_model_35    1.045575178131415
99           TanhWithDropout  ...    DL_random_grid_model_6   1.0747156942258902
100          TanhWithDropout  ...   DL_random_grid_model_99   1.0781602067715796
101     RectifierWithDropout  ...   DL_random_grid_model_62   1.1006499250727775
102          TanhWithDropout  ...   DL_random_grid_model_71    1.107681210817472
103     RectifierWithDropout  ...   DL_random_grid_model_23    1.108835899240189
104     RectifierWithDropout  ...   DL_random_grid_model_14   1.1090319543213378
105          TanhWithDropout  ...   DL_random_grid_model_79   1.3990531549936727
106          TanhWithDropout  ...   DL_random_grid_model_60   1.3990946687543047
107          TanhWithDropout  ...   DL_random_grid_model_92   1.4073808298767465
108          TanhWithDropout  ...   DL_random_grid_model_22    1.439902824609909
109          TanhWithDropout  ...   DL_random_grid_model_19   1.4557943029293878
110          TanhWithDropout  ...   DL_random_grid_model_86    1.481614749977432
111          TanhWithDropout  ...  DL_random_grid_model_110   1.5164182560610366
112          TanhWithDropout  ...   DL_random_grid_model_59    1.522617362164723

[113 rows x 7 columns]

--- 306.02778816223145 seconds ---
Evalutation of best performing model:
Final acc, selected model:  87.0909636745722
Time consumed:  0.08504438440004984  hours
H2O session _sid_b128 closed.
