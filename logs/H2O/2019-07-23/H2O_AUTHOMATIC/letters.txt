Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmpv18n9ubt
  JVM stdout: /tmp/tmpv18n9ubt/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmpv18n9ubt/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    7 days, 15 hours and 13 minutes
H2O cluster name:           H2O_from_python_davidserranogemes_gwo955
H2O cluster total nodes:    1
H2O cluster free memory:    1.922 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Authomatic  mode.

AutoML progress: |
13:13:48.898: Project: automl_py_3_sid_a7de
13:13:48.898: AutoML job created: 2019.07.23 13:13:48.895
13:13:48.899: Disabling Algo: GLM as requested by the user.
13:13:48.899: Disabling Algo: XGBoost as requested by the user.
13:13:48.899: Disabling Algo: StackedEnsemble as requested by the user.
13:13:48.900: Disabling Algo: GBM as requested by the user.
13:13:48.900: Disabling Algo: DRF as requested by the user.
13:13:48.900: Build control seed: 1
13:13:48.922: training frame: Frame key: automl_training_py_3_sid_a7de    cols: 17    rows: 7517  chunks: 1    size: 131113  checksum: -9457487542503
13:13:48.929: validation frame: Frame key: py_4_sid_a7de    cols: 17    rows: 2490  chunks: 1    size: 45654  checksum: -8175476536668
13:13:48.929: leaderboard frame: NULL
13:13:48.929: response column: C17
13:13:48.929: fold column: null
13:13:48.929: weights column: null
13:13:48.981: Setting stopping tolerance adaptively based on the training frame: 0.011533940982981885
13:13:48.990: AutoML build started: 2019.07.23 13:13:48.989

███████
13:14:01.91: New leader: DeepLearning_1_AutoML_20190723_131348, mean_per_class_error: 0.3953631574386283
13:14:01.93: AutoML: starting DeepLearning hyperparameter search

██████████████
13:15:05.159: New leader: DeepLearning_grid_1_AutoML_20190723_131348_model_1, mean_per_class_error: 0.15745279108860294

███████
13:15:44.166: AutoML: starting DeepLearning hyperparameter search

█████████
13:16:43.206: New leader: DeepLearning_grid_1_AutoML_20190723_131348_model_4, mean_per_class_error: 0.14746550613815188

████████
13:17:32.214: AutoML: starting DeepLearning hyperparameter search

███████████| 100%

13:18:50.232: StackedEnsemble builds skipped due to the exclude_algos option.
13:18:50.232: AutoML build stopped: 2019.07.23 13:18:50.232
13:18:50.232: AutoML build done: built 8 models
13:18:50.232: AutoML duration:  5 min  1.243 sec

--- 302.23790073394775 seconds ---
Evalutation of best performing model:
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DeepLearning_grid_1_AutoML_20190723_131348_model_4

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 4,726 weights/biases, 62.4 KB, 1,127,550 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ---------------------  ------------------
    1        16       Input             15.0
    2        50       RectifierDropout  20.0       0.0   0.0   0.000970671393261      0.00034827913623303175  0.0         -0.023408427737631427  0.305377721786499   -0.5389618307320624    0.4018770456314087
    3        50       RectifierDropout  20.0       0.0   0.0   0.0016280795629601925  0.0008584100287407637   0.0         -0.07999162120906986   0.310927152633667   -0.008062987741529009  0.3972592353820801
    4        26       Softmax                      0.0   0.0   0.05453022150734726    0.13795113563537598     0.0         -3.7938810619851573    2.5702877044677734  -20.762659768216903    1.0530147552490234


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13534806808568348
RMSE: 0.36789681717253747
LogLoss: 0.4136629521469625
Mean Per-Class Error: 0.12042571759424023
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  -----------
289.0  0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    5.0    1.0    3.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.05555555555555555   17 / 306
0.0    233.0  0.0    7.0    0.0    2.0    1.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    14.0   5.0    0.0    0.0    0.0    4.0    1.0    1.0    0.0    0.1588447653429603    44 / 277
0.0    0.0    254.0  0.0    13.0   0.0    7.0    1.0    0.0    0.0    2.0    4.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.11188811188811189   32 / 286
1.0    9.0    0.0    264.0  0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    1.0    1.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.09278350515463918   27 / 291
0.0    1.0    5.0    0.0    241.0  0.0    9.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    3.0    3.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    16.0   0.1602787456445993    46 / 287
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    264.0  0.0    0.0    0.0    0.07042253521126761   20 / 284
0.0    2.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    3.0    4.0    7.0    0.0    0.0    2.0    0.0    1.0    0.0    3.0    3.0    0.0    0.0    0.0    255.0  4.0    4.0    0.1326530612244898    39 / 294
0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    7.0    1.0    4.0    0.0    0.0    273.0  0.0    0.045454545454545456  13 / 286
4.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    255.0  0.08928571428571429   25 / 280
345.0  277.0  266.0  329.0  287.0  316.0  311.0  269.0  250.0  256.0  272.0  283.0  321.0  288.0  285.0  284.0  286.0  326.0  240.0  322.0  281.0  266.0  291.0  264.0  294.0  308.0  0.11986164693361713   901 / 7,517

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.880138
2    0.946654
3    0.970733
4    0.980577
5    0.985499
6    0.990156
7    0.993215
8    0.995344
9    0.996142
10   0.996807

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16119211028942151
RMSE: 0.40148737251552696
LogLoss: 0.5054233637191997
Mean Per-Class Error: 0.15121873162968633
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6      7     8     9      10    11     12    13    14    15     16    17     18    19    20    21    22    23    24     25     Error                 Rate
----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  -----  --------------------  -----------
84.0  0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0   2.0    0.0    0.056179775280898875  5 / 89
0.0   78.0  0.0   4.0    1.0   2.0   1.0    2.0   0.0   0.0    1.0   0.0    0.0   0.0   0.0   2.0    0.0   8.0    0.0   0.0   0.0   4.0   3.0   0.0   0.0    0.0    0.2641509433962264    28 / 106
0.0   0.0   67.0  0.0    8.0   2.0   2.0    0.0   0.0   0.0    1.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.18292682926829268   15 / 82
3.0   0.0   0.0   99.0   0.0   0.0   0.0    4.0   0.0   1.0    0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.11607142857142858   13 / 112
0.0   2.0   2.0   0.0    71.0  1.0   3.0    0.0   0.0   0.0    1.0   4.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   1.0   0.0   0.0   0.0   0.0   0.0    9.0    0.26804123711340205   26 / 97
---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---    ---                   ---
0.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0   0.0    0.0   1.0    0.0   0.0   1.0   2.0   85.0  0.0   0.0    0.0    0.07608695652173914   7 / 92
0.0   2.0   0.0   1.0    0.0   2.0   0.0    2.0   1.0   0.0    2.0   6.0    0.0   0.0   0.0   0.0    1.0   0.0    2.0   1.0   0.0   0.0   0.0   77.0  0.0    3.0    0.23                  23 / 100
0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.0    0.0   0.0   1.0   2.0   1.0   0.0   100.0  0.0    0.06542056074766354   7 / 107
1.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0   0.0    79.0   0.09195402298850575   8 / 87
99.0  98.0  71.0  126.0  88.0  91.0  101.0  95.0  75.0  115.0  93.0  101.0  87.0  98.0  70.0  123.0  99.0  108.0  82.0  97.0  96.0  88.0  97.0  81.0  111.0  100.0  0.1502008032128514    374 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.849799
2    0.925301
3    0.950201
4    0.964659
5    0.975502
6    0.981124
7    0.985141
8    0.988353
9    0.989558
10   0.990763

ModelMetricsMultinomial: deeplearning
** Reported on cross-validation data. **

MSE: 0.15567263189316224
RMSE: 0.39455371230437336
LogLoss: 0.4949685996521495
Mean Per-Class Error: 0.14746550613815188
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  -------------
287.0  0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    2.0    2.0    2.0    5.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.06209150326797386  19 / 306
0.0    243.0  0.0    5.0    1.0    5.0    1.0    2.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    7.0    6.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.12274368231046931  34 / 277
1.0    0.0    256.0  0.0    12.0   0.0    5.0    1.0    0.0    0.0    3.0    2.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    0.1048951048951049   30 / 286
0.0    21.0   0.0    238.0  0.0    1.0    0.0    3.0    0.0    8.0    0.0    0.0    4.0    6.0    1.0    2.0    1.0    3.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.18213058419243985  53 / 291
0.0    4.0    8.0    0.0    239.0  3.0    13.0   0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    2.0    3.0    3.0    0.0    0.0    0.0    2.0    1.0    3.0    0.1672473867595819   48 / 287
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    14.0   0.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    6.0    256.0  0.0    1.0    0.0    0.09859154929577464  28 / 284
0.0    1.0    0.0    8.0    7.0    2.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    261.0  1.0    0.0    0.11224489795918367  33 / 294
0.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    1.0    16.0   1.0    10.0   0.0    0.0    249.0  0.0    0.12937062937062938  37 / 286
6.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    31.0   1.0    0.0    0.0    0.0    1.0    1.0    215.0  0.23214285714285715  65 / 280
328.0  334.0  281.0  305.0  297.0  331.0  287.0  224.0  241.0  278.0  260.0  258.0  373.0  292.0  300.0  294.0  254.0  299.0  304.0  314.0  281.0  287.0  305.0  291.0  271.0  228.0  0.14660103764799787  1,102 / 7,517

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853399
2    0.930291
3    0.955168
4    0.969004
5    0.976719
6    0.982041
7    0.98683
8    0.989091
9    0.991619
10   0.993348
Cross-Validation Metrics Summary: 
                         mean      sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------------------  --------  -----------  ------------  ------------  ------------  ------------  ------------
accuracy                 0.849009  0.0074716    0.859043      0.838431      0.860945      0.85163       0.834997
err                      0.150991  0.0074716    0.140957      0.161569      0.139055      0.14837       0.165003
err_count                227       11.2339      212           243           209           223           248
logloss                  0.504803  0.018563     0.482728      0.554736      0.491119      0.488293      0.507142
max_per_class_error      0.329907  0.0516907    0.280702      0.328125      0.290323      0.278689      0.471698
mean_per_class_accuracy  0.848624  0.00833809   0.857948      0.837174      0.862685      0.85286       0.832453
mean_per_class_error     0.151376  0.00833809   0.142052      0.162826      0.137315      0.14714       0.167547
mse                      0.157544  0.00547222   0.151719      0.171093      0.153463      0.150307      0.161138
r2                       0.997201  8.83362e-05  0.997277      0.996994      0.997264      0.997343      0.997128
rmse                     0.3968    0.00682884   0.389511      0.413633      0.391744      0.387694      0.40142
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-23 13:16:31  0.000 sec                     0         0             0            nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-23 13:16:32  48.639 sec  91559 obs/sec     10        1             75170        0.456658         0.656646            0.996297       0.190901                         0.475383           0.71273               0.995973         0.213655
    2019-07-23 13:16:38  53.860 sec  100260 obs/sec    80        8             601360       0.373255         0.431357            0.997526       0.124651                         0.397465           0.499292              0.997185         0.146988
    2019-07-23 13:16:43  58.953 sec  102142 obs/sec    150       15            1.12755e+06  0.367897         0.413663            0.997597       0.119862                         0.401487           0.505423              0.997128         0.150201
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0958775
C9          0.996639               0.996639             0.0955552
C15         0.982526               0.982526             0.0942021
C8          0.844918               0.844918             0.0810086
C12         0.812084               0.812084             0.0778606
C11         0.732753               0.732753             0.0702545
C7          0.713954               0.713954             0.0684521
C10         0.678629               0.678629             0.0650653
C14         0.674695               0.674695             0.064688
C6          0.655962               0.655962             0.0628919
C5          0.515031               0.515031             0.0493798
C16         0.509659               0.509659             0.0488648
C3          0.358013               0.358013             0.0343254
C4          0.340136               0.340136             0.0326114
C1          0.337135               0.337135             0.0323237
C2          0.277848               0.277848             0.0266394

model_id                                              mean_per_class_error    logloss      rmse       mse
--------------------------------------------------  ----------------------  ---------  --------  --------
DeepLearning_grid_1_AutoML_20190723_131348_model_4                0.147466   0.494969  0.394554  0.155673
DeepLearning_grid_1_AutoML_20190723_131348_model_1                0.157453   0.550216  0.399794  0.159835
DeepLearning_grid_1_AutoML_20190723_131348_model_7                0.166644   0.55106   0.415956  0.17302
DeepLearning_grid_1_AutoML_20190723_131348_model_3                0.171147   0.585155  0.400115  0.160092
DeepLearning_grid_1_AutoML_20190723_131348_model_2                0.175805   0.638728  0.395432  0.156366
DeepLearning_grid_1_AutoML_20190723_131348_model_5                0.189345   0.623884  0.412499  0.170156
DeepLearning_grid_1_AutoML_20190723_131348_model_6                0.24911    0.794438  0.490985  0.241066
DeepLearning_1_AutoML_20190723_131348                             0.395363   1.35792   0.639253  0.408644

[8 rows x 5 columns]

deeplearning prediction progress: |███████████████████████████████████████| 100%
Final acc, selected model:  84.90943660562394
Time consumed:  0.08409264657232496  hours
H2O session _sid_a7de closed.
