Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmpola8qpz0
  JVM stdout: /tmp/tmpola8qpz0/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmpola8qpz0/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    19 days
H2O cluster name:           H2O_from_python_davidserranogemes_l78odq
H2O cluster total nodes:    1
H2O cluster free memory:    3.900 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Guided  mode.

deeplearning Grid Build progress: |███████████████████████████████████████| 100%
deeplearning prediction progress: |███████████████████████████████████████| 100%
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_41

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.001903826145792209  0.0004933832678943872  0.0         -0.008023053877060704  0.17527824640274048  0.27209427184819285  0.12429946660995483
    3        26       Softmax                      0.0   0.0   0.009412726920651529  0.043415576219558716   0.0         -0.21079041081581698   0.3935617208480835   -0.4893654188023756  0.10069486498832703


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.10741438158817217
RMSE: 0.32774133335325917
LogLoss: 0.35709063274535774
Mean Per-Class Error: 0.10511865536975194
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
375.0  0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    2.0    0.0    0.0    1.0    0.0    1.0    2.0    1.0    0.0    1.0    2.0    0.0    3.0    2.0    0.05063291139240506  20 / 395
0.0    351.0  0.0    7.0    3.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    5.0    3.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0835509138381201   32 / 383
0.0    0.0    325.0  0.0    12.0   0.0    15.0   1.0    0.0    0.0    2.0    2.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    0.11684782608695653  43 / 368
3.0    15.0   0.0    353.0  0.0    1.0    0.0    7.0    1.0    0.0    2.0    0.0    4.0    5.0    3.0    0.0    0.0    5.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.12406947890818859  50 / 403
0.0    0.0    1.0    0.0    344.0  3.0    14.0   2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    2.0    2.0    4.0    0.0    0.0    0.0    3.0    0.0    5.0    0.10416666666666667  40 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    7.0    1.0    3.0    0.0    0.0    2.0    0.0    0.0    3.0    1.0    354.0  0.0    0.0    0.0    0.05851063829787234  22 / 376
0.0    0.0    0.0    4.0    6.0    1.0    0.0    1.0    2.0    2.0    3.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    0.0    0.0    362.0  1.0    2.0    0.07653061224489796  30 / 392
0.0    1.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    5.0    1.0    10.0   1.0    0.0    363.0  0.0    0.07633587786259542  30 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    11.0   2.0    0.0    0.0    0.0    1.0    0.0    335.0  0.08719346049046321  32 / 367
411.0  456.0  335.0  400.0  426.0  377.0  398.0  354.0  342.0  361.0  337.0  368.0  383.0  383.0  406.0  393.0  341.0  416.0  386.0  405.0  402.0  365.0  398.0  412.0  387.0  361.0  0.10466859942017395  1,047 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.895331
2    0.953414
3    0.971808
4    0.980206
5    0.987104
6    0.991402
7    0.993502
8    0.995201
9    0.996401
10   0.997501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.10808740533465125
RMSE: 0.3287664905896756
LogLoss: 0.3638058298017319
Mean Per-Class Error: 0.10273151909401548
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
85.0  0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0    2.0    0.0   0.0449438202247191    4 / 89
0.0   94.0   0.0   2.0    2.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   4.0    0.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.11320754716981132   12 / 106
0.0   0.0    70.0  0.0    2.0    0.0   4.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0    3.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.14634146341463414   12 / 82
1.0   1.0    0.0   98.0   0.0    1.0   0.0    4.0   0.0   0.0    1.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    0.0   0.125                 14 / 112
0.0   0.0    0.0   0.0    86.0   2.0   4.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0    1.0    0.0    2.0   0.1134020618556701    11 / 97
---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    2.0    1.0   0.0    0.0   0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    92.0   0.0    0.0   0.08                  8 / 100
0.0   1.0    0.0   0.0    0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   2.0   0.0    4.0   1.0    0.0    96.0   0.0   0.102803738317757     11 / 107
1.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0    0.0    0.0    79.0  0.09195402298850575   8 / 87
91.0  118.0  71.0  110.0  101.0  86.0  103.0  90.0  86.0  105.0  87.0  96.0  80.0  100.0  85.0  110.0  89.0  102.0  95.0  96.0  107.0  81.0  100.0  105.0  110.0  86.0  0.10281124497991968   256 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.897189
2    0.956225
3    0.971084
4    0.977912
5    0.984739
6    0.990361
7    0.99237
8    0.994378
9    0.995181
10   0.99759
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:12  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:12  1 min 10.700 sec  26196 obs/sec     1         1             10007      0.505374         0.853834            0.995461       0.240728                         0.506984           0.860458              0.99542          0.246185
    2019-08-04 09:01:15  1 min 13.671 sec  30315 obs/sec     10        10            100070     0.327741         0.357091            0.998091       0.104669                         0.328766           0.363806              0.998074         0.102811
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.083109
C13         0.941406               0.941406             0.0782393
C8          0.905573               0.905573             0.0752613
C9          0.895023               0.895023             0.0743845
C12         0.83469                0.83469              0.0693702
C10         0.779015               0.779015             0.0647432
C5          0.773424               0.773424             0.0642785
C7          0.763417               0.763417             0.0634468
C11         0.719571               0.719571             0.0598028
C14         0.704709               0.704709             0.0585676
C6          0.69373                0.69373              0.0576552
C16         0.682803               0.682803             0.0567471
C3          0.622338               0.622338             0.0517219
C4          0.609489               0.609489             0.050654
C1          0.56882                0.56882              0.0472741
C2          0.538383               0.538383             0.0447445
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_21

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018908952916518729  0.0004563076654449105  0.0         -0.007183893821201548  0.16805219650268555  0.2837679450598296   0.11321753263473511
    3        26       Softmax                      0.0   0.0   0.008624280969115716   0.04144981503486633    0.0         -0.21875259748593562   0.3937753438949585   -0.4771148662333138  0.09933072328567505


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1122892917538783
RMSE: 0.3350959441023993
LogLoss: 0.3766332639305882
Mean Per-Class Error: 0.1086685450973901
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    2.0    4.0    0.0    0.0    0.0    0.0    2.0    2.0    3.0    2.0    1.0    2.0    2.0    3.0    2.0    0.07848101265822785  31 / 395
0.0    349.0  0.0    7.0    5.0    0.0    1.0    2.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    7.0    0.0    0.0    1.0    0.0    3.0    0.0    1.0    0.08877284595300261  34 / 383
0.0    0.0    322.0  1.0    12.0   0.0    9.0    1.0    0.0    0.0    3.0    2.0    0.0    0.0    3.0    0.0    0.0    1.0    3.0    2.0    4.0    0.0    4.0    1.0    0.0    0.0    0.125                46 / 368
0.0    13.0   0.0    369.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    4.0    0.0    2.0    3.0    0.0    0.0    4.0    0.0    0.0    0.08436724565756824  34 / 403
0.0    1.0    1.0    0.0    343.0  2.0    12.0   0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    1.0    3.0    3.0    1.0    4.0    0.0    0.0    0.0    3.0    0.0    5.0    0.10677083333333333  41 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    351.0  0.0    0.0    0.0    0.064                24 / 375
0.0    1.0    0.0    4.0    4.0    0.0    0.0    1.0    2.0    4.0    4.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    360.0  1.0    5.0    0.08629441624365482  34 / 394
0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    8.0    0.0    0.0    1.0    0.0    378.0  0.0    0.03816793893129771  15 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    6.0    3.0    0.0    0.0    0.0    1.0    0.0    337.0  0.08174386920980926  30 / 367
383.0  488.0  345.0  439.0  416.0  377.0  369.0  293.0  339.0  375.0  338.0  382.0  396.0  384.0  391.0  369.0  372.0  402.0  355.0  419.0  419.0  344.0  391.0  436.0  417.0  364.0  0.10796760971708487  1,080 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.892032
2    0.949615
3    0.969309
4    0.979006
5    0.984305
6    0.989703
7    0.993102
8    0.994602
9    0.996301
10   0.997101

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11173407098539466
RMSE: 0.3342664670369953
LogLoss: 0.37839525497612897
Mean Per-Class Error: 0.10443676035239012
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   1.0   0.0    2.0    1.0   0.0898876404494382   8 / 89
0.0   92.0   0.0   2.0    3.0    0.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0   0.0   0.0    1.0   0.0   1.0    0.0    1.0   0.1320754716981132   14 / 106
0.0   0.0    69.0  0.0    2.0    0.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0   2.0   1.0    0.0   1.0   0.0    0.0    0.0   0.15853658536585366  13 / 82
0.0   2.0    0.0   105.0  0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   1.0    0.0    0.0   0.0625               7 / 112
0.0   0.0    0.0   0.0    85.0   1.0   5.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0   1.0    0.0    1.0   0.12371134020618557  12 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   89.0  0.0    0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    1.0    0.0   0.0   0.0   0.0   1.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   92.0   0.0    2.0   0.08                 8 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   2.0   0.0    0.0   1.0   0.0    102.0  0.0   0.04672897196261682  5 / 107
1.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   1.0    0.0    79.0  0.09195402298850575  8 / 87
86.0  125.0  73.0  122.0  100.0  86.0  97.0  69.0  82.0  111.0  88.0  97.0  84.0  101.0  83.0  107.0  95.0  101.0  90.0  99.0  109.0  74.0  99.0  107.0  117.0  88.0  0.10321285140562249  257 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.896787
2    0.951807
3    0.968675
4    0.979518
5    0.985141
6    0.989558
7    0.993976
8    0.994779
9    0.995984
10   0.997189
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:41  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:42  40.072 sec  24647 obs/sec     1         1             10007      0.507909         0.867145            0.995416       0.245026                         0.507736           0.872931              0.995406         0.253815
    2019-08-04 09:00:45  43.103 sec  29545 obs/sec     10        10            100070     0.335096         0.376633            0.998005       0.107968                         0.334266           0.378395              0.998009         0.103213
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0868096
C13         0.931921               0.931921             0.0808997
C8          0.860566               0.860566             0.0747054
C12         0.83872                0.83872              0.0728089
C9          0.818523               0.818523             0.0710557
C7          0.744082               0.744082             0.0645934
C10         0.717961               0.717961             0.0623258
C5          0.710465               0.710465             0.0616752
C11         0.689117               0.689117             0.0598219
C6          0.655647               0.655647             0.0569165
C14         0.650079               0.650079             0.056433
C16         0.636904               0.636904             0.0552893
C4          0.625113               0.625113             0.0542657
C3          0.586749               0.586749             0.0509355
C1          0.53362                0.53362              0.0463233
C2          0.520002               0.520002             0.0451411
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_220

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018918822202067531  0.0004928575363010168  0.0         -0.007661350063731476  0.1710084080696106   0.2768496430375709   0.11982408165931702
    3        26       Softmax                      0.0   0.0   0.008453725955790175   0.03900687396526337    0.0         -0.21945590133735984   0.39176857471466064  -0.4781697079582693  0.09866213798522949


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11258299309309461
RMSE: 0.33553389261458316
LogLoss: 0.37620933702115983
Mean Per-Class Error: 0.11020121501475323
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
372.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    5.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    2.0    0.0    2.0    3.0    2.0    0.05822784810126582  23 / 395
0.0    354.0  0.0    5.0    3.0    0.0    1.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    7.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.07571801566579635  29 / 383
0.0    0.0    316.0  0.0    10.0   1.0    10.0   1.0    0.0    0.0    10.0   2.0    0.0    0.0    5.0    0.0    1.0    0.0    2.0    3.0    5.0    0.0    2.0    0.0    0.0    0.0    0.14130434782608695  52 / 368
0.0    15.0   0.0    359.0  0.0    0.0    0.0    1.0    0.0    3.0    2.0    0.0    6.0    4.0    0.0    0.0    0.0    8.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.10918114143920596  44 / 403
0.0    2.0    1.0    0.0    336.0  5.0    10.0   1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    6.0    3.0    3.0    2.0    0.0    0.0    0.0    5.0    0.0    7.0    0.1227154046997389   47 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    23.0   0.0    4.0    0.0    0.0    1.0    0.0    0.0    3.0    3.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    0.0    0.0    4.0    2.0    1.0    0.0    1.0    3.0    4.0    7.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    362.0  1.0    3.0    0.08121827411167512  32 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    2.0    8.0    2.0    23.0   0.0    0.0    347.0  0.0    0.11704834605597965  46 / 393
1.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    14.0   1.0    0.0    0.0    0.0    1.0    0.0    321.0  0.12534059945504086  46 / 367
388.0  470.0  330.0  414.0  409.0  374.0  361.0  298.0  337.0  388.0  378.0  357.0  440.0  384.0  386.0  405.0  383.0  393.0  411.0  386.0  412.0  407.0  355.0  412.0  371.0  354.0  0.10956712986104168  1,096 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.890433
2    0.948615
3    0.96781
4    0.978107
5    0.984405
6    0.989503
7    0.992702
8    0.994702
9    0.996201
10   0.997301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11421557514653784
RMSE: 0.33795794878436847
LogLoss: 0.38152252927507474
Mean Per-Class Error: 0.11603407317958415
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17    18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   0.0    1.0   0.0   0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   91.0   0.0   1.0    2.0   0.0   1.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    4.0   2.0    0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.14150943396226415  15 / 106
0.0   0.0    66.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    3.0   0.0    1.0    0.0   1.0    2.0   0.0    0.0   1.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
0.0   2.0    0.0   102.0  0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0   2.0   1.0    0.0   0.0    0.0    0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0    0.0   0.08928571428571429  10 / 112
0.0   0.0    0.0   0.0    82.0  4.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0   1.0    0.0   0.0    0.0   0.0   2.0    0.0    2.0   0.15463917525773196  15 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    2.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0   1.0   1.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    0.0   0.0   91.0   0.0    1.0   0.09                 9 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   2.0    1.0    0.0   0.0    3.0   0.0    9.0   0.0   0.0    91.0   0.0   0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   2.0    0.0   0.0    0.0   0.0   1.0    0.0    77.0  0.11494252873563218  10 / 87
87.0  117.0  68.0  119.0  95.0  86.0  91.0  76.0  80.0  115.0  96.0  91.0  98.0  101.0  80.0  117.0  101.0  99.0  102.0  90.0  105.0  98.0  87.0  104.0  102.0  85.0  0.11485943775100402  286 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.885141
2    0.951807
3    0.969076
4    0.979116
5    0.983534
6    0.98996
7    0.992771
8    0.994779
9    0.996385
10   0.997189
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:25  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:25  6 min 23.244 sec  27720 obs/sec     1         1             10007      0.503079         0.855718            0.995503       0.236829                         0.502087           0.850772              0.995508         0.240562
    2019-08-04 09:06:28  6 min 26.118 sec  31438 obs/sec     10        10            100070     0.335534         0.376209            0.998          0.109567                         0.337958           0.381523              0.997965         0.114859
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0853375
C13         0.917171               0.917171             0.0782691
C8          0.8925                 0.8925               0.0761636
C9          0.865774               0.865774             0.073883
C12         0.80139                0.80139              0.0683886
C7          0.765915               0.765915             0.0653612
C10         0.748095               0.748095             0.0638406
C5          0.730293               0.730293             0.0623213
C11         0.72758                0.72758              0.0620898
C16         0.690542               0.690542             0.0589291
C6          0.682438               0.682438             0.0582375
C14         0.65805                0.65805              0.0561563
C3          0.600297               0.600297             0.0512278
C4          0.574763               0.574763             0.0490489
C1          0.570679               0.570679             0.0487003
C2          0.492696               0.492696             0.0420454
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_169

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms         mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -----------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019204463253430504  0.0004591000033542514  0.0         -0.009948571281903781  0.170393168926239  0.28445581490176497   0.11345618963241577
    3        26       Softmax                      0.0   0.0   0.010599923027309789   0.04678136110305786    0.0         -0.21719132923743756   0.392187237739563  -0.46801430179711784  0.08818349242210388


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11394243322217047
RMSE: 0.3375536005172667
LogLoss: 0.3757787031066225
Mean Per-Class Error: 0.11075286096400458
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    5.0    2.0    3.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    1.0    0.0    1.0    2.0    5.0    1.0    0.08354430379746836  33 / 395
0.0    349.0  0.0    7.0    2.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    7.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.08877284595300261  34 / 383
0.0    0.0    336.0  0.0    7.0    0.0    3.0    1.0    0.0    0.0    8.0    2.0    0.0    0.0    4.0    0.0    0.0    1.0    1.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.08695652173913043  32 / 368
0.0    10.0   0.0    370.0  0.0    0.0    0.0    1.0    0.0    3.0    2.0    0.0    6.0    4.0    0.0    0.0    0.0    2.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.08188585607940446  33 / 403
0.0    6.0    4.0    0.0    333.0  6.0    10.0   3.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    6.0    2.0    1.0    4.0    0.0    0.0    0.0    2.0    0.0    3.0    0.13054830287206268  50 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    355.0  0.0    0.0    0.0    0.05585106382978723  21 / 376
0.0    0.0    0.0    4.0    4.0    1.0    0.0    0.0    2.0    4.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    362.0  1.0    3.0    0.08121827411167512  32 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    1.0    18.0   1.0    16.0   1.0    0.0    344.0  0.0    0.12468193384223919  49 / 393
1.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    15.0   0.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    10.0   2.0    0.0    0.0    0.0    1.0    0.0    315.0  0.14168937329700274  52 / 367
381.0  438.0  370.0  444.0  392.0  415.0  348.0  357.0  362.0  393.0  381.0  373.0  417.0  382.0  350.0  394.0  369.0  388.0  378.0  396.0  399.0  384.0  384.0  409.0  363.0  336.0  0.11016694991502549  1,102 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.889833
2    0.951215
3    0.969109
4    0.980006
5    0.986604
6    0.990903
7    0.993302
8    0.994801
9    0.996401
10   0.997201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11459364884767313
RMSE: 0.33851683687473083
LogLoss: 0.38281506906516327
Mean Per-Class Error: 0.10817396779252425
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24    25    Error                 Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.06741573033707865   6 / 89
0.0   89.0   0.0   2.0    1.0   0.0    0.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   4.0    2.0   0.0   0.0    2.0   0.0   1.0   1.0   0.0   0.16037735849056603   17 / 106
0.0   0.0    74.0  0.0    2.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0975609756097561    8 / 82
0.0   2.0    0.0   102.0  0.0   0.0    0.0   0.0   0.0   1.0    1.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0   0.0   0.08928571428571429   10 / 112
0.0   1.0    0.0   0.0    83.0  5.0    3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    1.0   1.0   0.0    0.0   0.0   1.0   0.0   0.0   0.14432989690721648   14 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   88.0  0.0   0.0   0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    2.0   1.0    0.0   0.0   0.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   89.0  0.0   1.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0   5.0   0.0    6.0   1.0   0.0   91.0  0.0   0.14953271028037382   16 / 107
1.0   0.0    0.0   0.0    5.0   0.0    0.0   0.0   0.0   3.0    0.0   3.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0   73.0  0.16091954022988506   14 / 87
87.0  105.0  79.0  124.0  97.0  100.0  87.0  85.0  86.0  112.0  98.0  98.0  91.0  100.0  77.0  110.0  98.0  101.0  99.0  94.0  103.0  87.0  96.0  99.0  99.0  78.0  0.10843373493975904   270 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.891566
2    0.953815
3    0.969076
4    0.977912
5    0.983936
6    0.989558
7    0.993173
8    0.994779
9    0.995582
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:54  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:55  4 min 52.959 sec  28348 obs/sec     1         1             10007      0.510471         0.870959            0.995369       0.244527                         0.509692           0.87671               0.995371         0.248996
    2019-08-04 09:04:58  4 min 55.911 sec  30752 obs/sec     10        10            100070     0.337554         0.375779            0.997975       0.110167                         0.338517           0.382815              0.997958         0.108434
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0837046
C13         0.941123               0.941123             0.0787763
C9          0.883418               0.883418             0.0739461
C8          0.873569               0.873569             0.0731217
C12         0.810004               0.810004             0.067801
C10         0.786456               0.786456             0.0658299
C7          0.784684               0.784684             0.0656816
C5          0.734208               0.734208             0.0614566
C6          0.716945               0.716945             0.0600116
C11         0.712901               0.712901             0.059673
C14         0.683594               0.683594             0.0572199
C16         0.666275               0.666275             0.0557703
C3          0.656234               0.656234             0.0549297
C4          0.628883               0.628883             0.0526404
C1          0.550436               0.550436             0.046074
C2          0.518051               0.518051             0.0433632
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_197

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018823418990336904  0.0005071328487247229  0.0         -0.00895866141321644  0.1674056053161621  0.2864757211541663    0.12324544787406921
    3        26       Softmax                      0.0   0.0   0.009040598643073631   0.0404026061296463     0.0         -0.22043999596552247  0.3922656774520874  -0.47264252758919834  0.09080949425697327


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1110038001146415
RMSE: 0.33317232795453094
LogLoss: 0.3728869928918577
Mean Per-Class Error: 0.10771500830382838
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
371.0  0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    2.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    1.0    4.0    2.0    0.0    3.0    3.0    0.060759493670886074  24 / 395
0.0    335.0  2.0    4.0    1.0    2.0    2.0    12.0   2.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    2.0    5.0    2.0    1.0    0.0    4.0    0.0    2.0    2.0    0.0    0.12532637075718014   48 / 383
0.0    0.0    331.0  1.0    4.0    0.0    12.0   0.0    0.0    0.0    5.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    3.0    5.0    0.0    0.0    0.0    0.0    0.0    0.09809264305177112   36 / 367
0.0    10.0   0.0    366.0  0.0    1.0    0.0    5.0    0.0    3.0    0.0    0.0    3.0    6.0    1.0    1.0    0.0    1.0    2.0    1.0    1.0    0.0    0.0    2.0    0.0    0.0    0.09181141439205956   37 / 403
0.0    4.0    1.0    0.0    325.0  7.0    17.0   1.0    0.0    0.0    3.0    4.0    0.0    0.0    0.0    1.0    2.0    2.0    1.0    4.0    1.0    0.0    0.0    2.0    0.0    9.0    0.15364583333333334   59 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    1.0    0.0    1.0    5.0    0.0    353.0  0.0    0.0    0.0    0.061170212765957445  23 / 376
0.0    2.0    0.0    4.0    2.0    0.0    0.0    1.0    2.0    4.0    6.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    2.0    1.0    0.0    0.0    358.0  3.0    4.0    0.09137055837563451   36 / 394
0.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    2.0    0.0    0.0    6.0    1.0    0.0    374.0  0.0    0.04591836734693878   18 / 392
1.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    6.0    1.0    0.0    0.0    0.0    1.0    0.0    342.0  0.0681198910081744    25 / 367
391.0  410.0  358.0  426.0  364.0  392.0  389.0  368.0  350.0  372.0  356.0  358.0  395.0  371.0  407.0  388.0  405.0  366.0  352.0  394.0  413.0  389.0  389.0  393.0  416.0  391.0  0.10726781965410377   1,073 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.892732
2    0.948315
3    0.969109
4    0.978206
5    0.984205
6    0.989203
7    0.992202
8    0.993602
9    0.995101
10   0.996601

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11375430634009133
RMSE: 0.33727482316367957
LogLoss: 0.3842824549683893
Mean Per-Class Error: 0.10615610851176366
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17    18    19    20     21    22    23    24     25    Error                 Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0   0.0    1.0   0.0   0.0   2.0    1.0   0.056179775280898875  5 / 89
0.0   86.0  1.0   2.0    1.0   1.0   2.0   3.0   1.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0    2.0   0.0   0.0   0.0    3.0   0.0   1.0   1.0    0.0   0.18867924528301888   20 / 106
0.0   0.0   75.0  0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   3.0   0.0    0.0    0.0   0.0   2.0   0.0    0.0   0.0   0.0   0.0    0.0   0.08536585365853659   7 / 82
0.0   1.0   0.0   102.0  0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   1.0   2.0   0.0   1.0    0.0    0.0   1.0   0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.08928571428571429   10 / 112
0.0   0.0   0.0   0.0    80.0  4.0   5.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0   2.0   0.0    0.0   0.0   0.0   0.0    2.0   0.17525773195876287   17 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   2.0    0.0   88.0  0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0   0.0   2.0    1.0   0.0   0.0   1.0   0.0   1.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   90.0  1.0    1.0   0.1                   10 / 100
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    1.0    0.0   0.0   0.0   0.0    1.0   1.0   0.0   102.0  0.0   0.04672897196261682   5 / 107
1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    81.0  0.06896551724137931   6 / 87
90.0  96.0  81.0  119.0  88.0  91.0  95.0  91.0  86.0  110.0  90.0  92.0  85.0  99.0  87.0  110.0  104.0  94.0  83.0  91.0  106.0  89.0  95.0  96.0  123.0  99.0  0.10642570281124498   265 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.893574
2    0.949799
3    0.969478
4    0.977108
5    0.981124
6    0.987149
7    0.991165
8    0.993173
9    0.995984
10   0.99759
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:47  5 min 45.738 sec  27720 obs/sec     1         1             10007      0.50864          0.86929             0.995402       0.246226                         0.511121           0.882801              0.995345         0.251004
    2019-08-04 09:05:51  5 min 48.842 sec  29346 obs/sec     10        10            100070     0.333172         0.372887            0.998027       0.107268                         0.337275           0.384282              0.997973         0.106426
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0878874
C13         0.904516               0.904516             0.0794956
C8          0.838313               0.838313             0.0736772
C9          0.783526               0.783526             0.0688621
C12         0.764215               0.764215             0.0671649
C10         0.729472               0.729472             0.0641114
C7          0.725072               0.725072             0.0637246
C11         0.718811               0.718811             0.0631744
C5          0.701331               0.701331             0.0616381
C6          0.691323               0.691323             0.0607586
C16         0.646854               0.646854             0.0568503
C14         0.630922               0.630922             0.0554501
C3          0.591801               0.591801             0.0520118
C4          0.583235               0.583235             0.051259
C1          0.547357               0.547357             0.0481058
C2          0.52145                0.52145              0.0458289
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_112

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019371034057371617  0.0005131540820002556  0.0         -0.00883636238837271  0.1688407063484192   0.28614148330002565  0.1189441978931427
    3        26       Softmax                      0.0   0.0   0.008556115324643962   0.03883032500743866    0.0         -0.21669798329176068  0.39395976066589355  -0.48358306869493    0.09600251913070679


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11055720742027106
RMSE: 0.3325014397266139
LogLoss: 0.37625452171534135
Mean Per-Class Error: 0.10925925882383716
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
374.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    1.0    1.0    0.0    3.0    4.0    0.050761421319796954  20 / 394
0.0    358.0  1.0    4.0    3.0    0.0    1.0    0.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    4.0    3.0    0.0    0.0    1.0    0.0    1.0    0.0    1.0    0.06282722513089005   24 / 382
0.0    0.0    329.0  0.0    7.0    1.0    6.0    1.0    0.0    0.0    4.0    4.0    0.0    0.0    5.0    0.0    2.0    1.0    1.0    3.0    4.0    0.0    0.0    0.0    0.0    0.0    0.10597826086956522   39 / 368
0.0    11.0   0.0    368.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    6.0    2.0    2.0    0.0    1.0    2.0    1.0    0.0    2.0    0.0    0.0    5.0    0.0    0.0    0.0845771144278607    34 / 402
0.0    5.0    0.0    0.0    329.0  7.0    14.0   0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    3.0    3.0    2.0    2.0    0.0    0.0    0.0    1.0    0.0    11.0   0.14322916666666666   55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    3.0    0.0    1.0    4.0    2.0    348.0  0.0    0.0    0.0    0.07446808510638298   28 / 376
0.0    2.0    0.0    4.0    4.0    1.0    0.0    1.0    2.0    3.0    3.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    361.0  1.0    4.0    0.08142493638676845   32 / 393
1.0    0.0    0.0    3.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    3.0    1.0    1.0    372.0  0.0    0.05343511450381679   21 / 393
1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    9.0    1.0    0.0    0.0    0.0    2.0    0.0    338.0  0.07901907356948229   29 / 367
399.0  483.0  348.0  441.0  388.0  398.0  357.0  268.0  332.0  370.0  341.0  392.0  406.0  369.0  394.0  378.0  382.0  419.0  411.0  378.0  421.0  356.0  375.0  405.0  411.0  381.0  0.10856742977106867   1,086 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.891433
2    0.947216
3    0.96731
4    0.978207
5    0.984005
6    0.989103
7    0.992902
8    0.994102
9    0.995701
10   0.997301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11065959317352639
RMSE: 0.33265536696937026
LogLoss: 0.38441140401407786
Mean Per-Class Error: 0.106773272314708
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18     19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
86.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   0.0    2.0    1.0   0.033707865168539325  3 / 89
0.0   94.0   0.0   0.0    3.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0    3.0    0.0    0.0   0.0    1.0   0.0   1.0    0.0    1.0   0.11320754716981132   12 / 106
0.0   0.0    73.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0   3.0   0.0    0.0    0.0    1.0    2.0   0.0    0.0   0.0   0.0    0.0    0.0   0.10975609756097561   9 / 82
0.0   2.0    0.0   103.0  0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   2.0    0.0   0.0   2.0    0.0    0.0   0.08035714285714286   9 / 112
0.0   0.0    0.0   0.0    80.0  5.0   6.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    1.0    1.0    0.0   0.0    0.0   0.0   1.0    0.0    2.0   0.17525773195876287   17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0    1.0    0.0    0.0   2.0    1.0   85.0  0.0    0.0    0.0   0.07608695652173914   7 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0   0.0   0.0   1.0    2.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   90.0   0.0    1.0   0.1                   10 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    1.0   1.0   0.0    102.0  0.0   0.04672897196261682   5 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0    0.0   0.0    0.0   0.0   1.0    0.0    81.0  0.06896551724137931   6 / 87
90.0  117.0  76.0  122.0  93.0  92.0  91.0  64.0  80.0  112.0  92.0  97.0  87.0  96.0  83.0  105.0  100.0  109.0  100.0  89.0  110.0  79.0  90.0  101.0  121.0  94.0  0.10562248995983936   263 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.894378
2    0.951004
3    0.966667
4    0.976707
5    0.982329
6    0.987149
7    0.990763
8    0.992771
9    0.994779
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:08  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:08  3 min  6.159 sec  27267 obs/sec     1         1             10007      0.505719         0.856613            0.995453       0.241028                         0.507328           0.867637              0.995414         0.248193
    2019-08-04 09:03:11  3 min  9.170 sec  30159 obs/sec     10        10            100070     0.332501         0.376255            0.998034       0.108567                         0.332655           0.384411              0.998028         0.105622
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.088487
C8          0.830613               0.830613             0.0734985
C9          0.823353               0.823353             0.0728561
C13         0.794147               0.794147             0.0702717
C12         0.786041               0.786041             0.0695544
C7          0.744653               0.744653             0.0658921
C10         0.729534               0.729534             0.0645543
C5          0.723888               0.723888             0.0640546
C11         0.687644               0.687644             0.0608476
C6          0.657533               0.657533             0.0581831
C16         0.632879               0.632879             0.0560016
C14         0.631247               0.631247             0.0558571
C4          0.608306               0.608306             0.0538272
C3          0.587371               0.587371             0.0519747
C1          0.536347               0.536347             0.0474597
C2          0.527541               0.527541             0.0466805
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_17

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018185547526030632  0.000445658341050148  0.0         -0.00898358409973432  0.17108702659606934  0.28520576742078735  0.1067848801612854
    3        26       Softmax                      0.0   0.0   0.008684430682120155   0.037416547536849976  0.0         -0.22048304708628416  0.3921806812286377   -0.4750664761762898  0.07888934016227722


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11345488983258162
RMSE: 0.3368306545321872
LogLoss: 0.3775367577050965
Mean Per-Class Error: 0.11161084681342691
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
370.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    6.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    2.0    1.0    1.0    3.0    3.0    0.06329113924050633   25 / 395
0.0    341.0  0.0    5.0    3.0    3.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    8.0    7.0    0.0    0.0    3.0    0.0    1.0    1.0    0.0    0.10966057441253264   42 / 383
0.0    0.0    341.0  0.0    3.0    0.0    2.0    1.0    0.0    0.0    9.0    1.0    1.0    0.0    3.0    0.0    1.0    1.0    0.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    0.07336956521739131   27 / 368
0.0    12.0   0.0    358.0  0.0    0.0    0.0    2.0    0.0    2.0    2.0    0.0    6.0    5.0    0.0    3.0    0.0    7.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.11166253101736973   45 / 403
0.0    6.0    3.0    0.0    324.0  6.0    17.0   0.0    0.0    0.0    2.0    6.0    0.0    0.0    0.0    1.0    2.0    3.0    3.0    2.0    0.0    0.0    0.0    4.0    0.0    5.0    0.15625               60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    14.0   1.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    353.0  0.0    0.0    0.0    0.061170212765957445  23 / 376
0.0    0.0    0.0    4.0    3.0    0.0    0.0    1.0    2.0    5.0    10.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    0.0    355.0  3.0    4.0    0.09898477157360407   39 / 394
0.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    15.0   1.0    28.0   1.0    1.0    338.0  0.0    0.13994910941475827   55 / 393
0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    12.0   1.0    0.0    0.0    0.0    2.0    0.0    328.0  0.10626702997275204   39 / 367
382.0  426.0  391.0  421.0  372.0  385.0  335.0  322.0  348.0  384.0  381.0  369.0  426.0  392.0  396.0  414.0  372.0  400.0  410.0  383.0  395.0  403.0  387.0  398.0  355.0  356.0  0.1112666200139958    1,113 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.888733
2    0.949915
3    0.969009
4    0.978407
5    0.985005
6    0.989903
7    0.993302
8    0.994302
9    0.995301
10   0.996901

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11589197642120624
RMSE: 0.3404291063073283
LogLoss: 0.38731681338517787
Mean Per-Class Error: 0.11071308490093454
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18     19    20     21    22    23     24    25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  -----  ----  -----  ----  ----  -----  ----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0    1.0    0.0    0.0   0.0    0.0   0.0   0.0    2.0   1.0   0.07865168539325842   7 / 89
0.0   87.0   0.0   1.0    2.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0    5.0    2.0    0.0   0.0    3.0   0.0   1.0    1.0   0.0   0.1792452830188679    19 / 106
0.0   0.0    78.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.04878048780487805   4 / 82
0.0   1.0    0.0   99.0   0.0   0.0   0.0   1.0   0.0   1.0    1.0   0.0   2.0   1.0    0.0   1.0    0.0    0.0    1.0    0.0   1.0    0.0   0.0   2.0    0.0   1.0   0.11607142857142858   13 / 112
0.0   0.0    0.0   0.0    80.0  5.0   5.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0    0.0   0.0    0.0   0.0   1.0    0.0   2.0   0.17525773195876287   17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---    ---   ---    ---   ---   ---    ---   ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   90.0  0.0    0.0   0.0   0.021739130434782608  2 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   89.0   0.0   2.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0    0.0    0.0    4.0   0.0    11.0  1.0   0.0    88.0  0.0   0.17757009345794392   19 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0    0.0   0.0    0.0   0.0   1.0    0.0   79.0  0.09195402298850575   8 / 87
84.0  102.0  88.0  116.0  94.0  91.0  83.0  80.0  84.0  112.0  92.0  94.0  93.0  101.0  83.0  119.0  102.0  102.0  101.0  90.0  101.0  94.0  99.0  100.0  95.0  90.0  0.11124497991967872   277 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.888755
2    0.951807
3    0.96988
4    0.979116
5    0.984337
6    0.988755
7    0.99237
8    0.993173
9    0.993976
10   0.996386
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:35  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:36  34.123 sec  28109 obs/sec     1         1             10007      0.505302         0.86059             0.995463       0.242827                         0.507774           0.873181              0.995406         0.245382
    2019-08-04 09:00:39  36.972 sec  31727 obs/sec     10        10            100070     0.336831         0.377537            0.997984       0.111267                         0.340429           0.387317              0.997935         0.111245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0851895
C13         0.941527               0.941527             0.0802083
C8          0.88382                0.88382              0.0752922
C9          0.87005                0.87005              0.0741191
C12         0.811947               0.811947             0.0691693
C10         0.77578                0.77578              0.0660884
C7          0.744125               0.744125             0.0633916
C5          0.730566               0.730566             0.0622366
C6          0.720795               0.720795             0.0614042
C11         0.687086               0.687086             0.0585325
C14         0.637612               0.637612             0.0543179
C16         0.62232                0.62232              0.0530152
C4          0.608685               0.608685             0.0518536
C3          0.603875               0.603875             0.0514438
C1          0.572534               0.572534             0.0487739
C2          0.527811               0.527811             0.044964
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_82

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019517992624429326  0.0004901327192783356  0.0         -0.009301705612474898  0.16998302936553955  0.2827951303051536   0.12684208154678345
    3        26       Softmax                      0.0   0.0   0.008568034032962784   0.035403475165367126   0.0         -0.2174832253767539    0.3901916742324829   -0.4665711797010381  0.08928325772285461


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11550006198458851
RMSE: 0.33985300055257495
LogLoss: 0.38504069475222574
Mean Per-Class Error: 0.11576546618516997
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    3.0    1.0    6.0    0.0    0.0    1.0    0.0    2.0    4.0    1.0    0.0    0.0    1.0    1.0    3.0    0.0    0.0759493670886076   30 / 395
0.0    338.0  0.0    4.0    3.0    0.0    0.0    6.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    2.0    12.0   8.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    338.0  1.0    5.0    0.0    5.0    1.0    0.0    0.0    5.0    1.0    0.0    0.0    4.0    0.0    0.0    1.0    4.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.08152173913043478  30 / 368
0.0    8.0    0.0    364.0  0.0    1.0    0.0    2.0    0.0    3.0    2.0    0.0    7.0    4.0    0.0    3.0    0.0    5.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0967741935483871   39 / 403
0.0    4.0    4.0    0.0    331.0  2.0    9.0    1.0    0.0    0.0    4.0    4.0    0.0    0.0    0.0    1.0    7.0    3.0    4.0    2.0    0.0    0.0    0.0    4.0    0.0    4.0    0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    16.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    352.0  0.0    0.0    0.0    0.06133333333333333  23 / 375
0.0    1.0    0.0    4.0    3.0    0.0    0.0    0.0    2.0    5.0    9.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    359.0  2.0    4.0    0.08883248730964467  35 / 394
0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    15.0   0.0    16.0   1.0    2.0    344.0  0.0    0.12468193384223919  49 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    20.0   2.0    0.0    0.0    0.0    1.0    0.0    315.0  0.13934426229508196  51 / 366
379.0  423.0  401.0  427.0  384.0  410.0  310.0  309.0  341.0  387.0  385.0  362.0  428.0  382.0  375.0  407.0  385.0  410.0  462.0  381.0  399.0  383.0  380.0  400.0  361.0  332.0  0.11526542037388783  1,153 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.884735
2    0.948415
3    0.968609
4    0.980706
5    0.986304
6    0.989903
7    0.991802
8    0.993502
9    0.995201
10   0.996601

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1160612047846181
RMSE: 0.34067756718724246
LogLoss: 0.38950430587220863
Mean Per-Class Error: 0.1099139115841029
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0    1.0    1.0    0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   88.0   0.0   0.0    2.0   0.0   0.0   2.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   2.0    0.0    5.0    3.0    0.0   0.0    1.0   0.0   1.0    1.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    75.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   3.0   0.0    0.0    0.0    2.0    0.0   0.0    0.0   1.0   0.0    0.0    0.0   0.08536585365853659  7 / 82
0.0   1.0    0.0   101.0  0.0   1.0   0.0   1.0   0.0   1.0    1.0   0.0   3.0   1.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.09821428571428571  11 / 112
0.0   0.0    1.0   0.0    86.0  1.0   2.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    2.0    1.0    1.0    0.0   0.0    0.0   0.0   1.0    0.0    1.0   0.1134020618556701   11 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   89.0  0.0    0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0   0.0   1.0    5.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   89.0   1.0    1.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0    0.0    3.0   0.0    5.0   1.0   0.0    93.0   0.0   0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0    3.0    0.0   0.0    0.0   0.0   0.0    0.0    75.0  0.13793103448275862  12 / 87
86.0  100.0  88.0  117.0  97.0  97.0  77.0  76.0  84.0  108.0  99.0  94.0  95.0  98.0  83.0  118.0  103.0  103.0  113.0  88.0  103.0  86.0  95.0  100.0  102.0  80.0  0.11004016064257029  274 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.88996
2    0.951406
3    0.971486
4    0.980723
5    0.985542
6    0.987952
7    0.991566
8    0.993976
9    0.995181
10   0.996386
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:18  2 min 16.565 sec  27797 obs/sec     1         1             10007      0.508423         0.869921            0.995405       0.235029                         0.507314           0.867901              0.995414         0.240964
    2019-08-04 09:02:21  2 min 19.494 sec  30933 obs/sec     10        10            100070     0.339853         0.385041            0.997947       0.115265                         0.340678           0.389504              0.997932         0.11004
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0853441
C13         0.915427               0.915427             0.0781263
C8          0.89371                0.89371              0.0762729
C9          0.8692                 0.8692               0.0741811
C10         0.808769               0.808769             0.0690237
C7          0.792434               0.792434             0.0676296
C12         0.78057                0.78057              0.0666171
C5          0.747534               0.747534             0.0637976
C11         0.714856               0.714856             0.0610088
C6          0.698916               0.698916             0.0596484
C14         0.665971               0.665971             0.0568367
C16         0.649435               0.649435             0.0554254
C4          0.617968               0.617968             0.05274
C3          0.556132               0.556132             0.0474626
C2          0.509348               0.509348             0.0434699
C1          0.497001               0.497001             0.0424161
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_4

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018733836204489762  0.00048504385631531477  0.0         -0.008686267896406141  0.16756147146224976  0.2857537624999674    0.11861976981163025
    3        26       Softmax                      0.0   0.0   0.008436026082449644   0.036713480949401855    0.0         -0.21714910621106862   0.3904399871826172   -0.48376561234853244  0.08838877081871033


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1165394532110931
RMSE: 0.3413787533094189
LogLoss: 0.38782834691751034
Mean Per-Class Error: 0.116796335540132
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    2.0    1.0    6.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    4.0    1.0    1.0    4.0    1.0    0.07088607594936709  28 / 395
0.0    348.0  1.0    5.0    2.0    1.0    1.0    5.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    2.0    6.0    4.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.09138381201044386  35 / 383
0.0    0.0    320.0  0.0    11.0   0.0    5.0    1.0    0.0    0.0    10.0   2.0    3.0    0.0    3.0    0.0    0.0    1.0    3.0    2.0    4.0    0.0    3.0    0.0    0.0    0.0    0.13043478260869565  48 / 368
0.0    15.0   0.0    356.0  0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    6.0    6.0    2.0    1.0    0.0    8.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    0.11662531017369727  47 / 403
0.0    4.0    4.0    0.0    333.0  2.0    12.0   1.0    0.0    0.0    3.0    4.0    0.0    0.0    0.0    1.0    2.0    3.0    3.0    3.0    0.0    0.0    0.0    2.0    0.0    7.0    0.1328125            51 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    4.0    346.0  0.0    0.0    0.0    0.07733333333333334  29 / 375
0.0    1.0    0.0    4.0    2.0    0.0    0.0    1.0    2.0    4.0    11.0   0.0    0.0    0.0    2.0    0.0    3.0    0.0    1.0    1.0    1.0    0.0    0.0    355.0  2.0    4.0    0.09898477157360407  39 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    13.0   1.0    17.0   1.0    0.0    353.0  0.0    0.10178117048346055  40 / 393
2.0    0.0    0.0    0.0    19.0   0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    12.0   1.0    0.0    0.0    0.0    3.0    0.0    315.0  0.14168937329700274  52 / 367
395.0  478.0  353.0  417.0  408.0  385.0  348.0  313.0  328.0  404.0  378.0  363.0  432.0  392.0  368.0  386.0  387.0  396.0  385.0  395.0  397.0  393.0  374.0  407.0  375.0  346.0  0.11616515045486354  1,162 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.883835
2    0.944816
3    0.96731
4    0.977707
5    0.985104
6    0.990203
7    0.992602
8    0.994602
9    0.996101
10   0.997401

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11744541800307357
RMSE: 0.342703104746767
LogLoss: 0.3932605111679277
Mean Per-Class Error: 0.11642718655760513
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   90.0   1.0   1.0    1.0    1.0   1.0   1.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0    4.0    1.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    70.0  0.0    2.0    0.0   0.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    2.0   0.0    0.0    0.0    2.0   2.0   1.0    0.0   1.0   0.0   0.0    0.0   0.14634146341463414  12 / 82
0.0   3.0    0.0   99.0   0.0    0.0   0.0   0.0   0.0   3.0    0.0   0.0   2.0   2.0    1.0   1.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.11607142857142858  13 / 112
0.0   0.0    0.0   0.0    84.0   1.0   4.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    0.0   0.0    0.0    1.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   0.13402061855670103  13 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    1.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0    0.0   0.0   0.0   0.0   1.0    6.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   88.0  0.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   3.0   0.0    7.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
2.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    3.0   0.0   0.0    0.0   0.0   1.0   0.0    76.0  0.12643678160919541  11 / 87
91.0  119.0  75.0  113.0  101.0  90.0  91.0  72.0  77.0  122.0  97.0  93.0  95.0  103.0  78.0  113.0  100.0  102.0  98.0  92.0  103.0  88.0  92.0  97.0  105.0  83.0  0.11566265060240964  288 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.884337
2    0.944578
3    0.965462
4    0.978313
5    0.983534
6    0.990362
7    0.993574
8    0.995181
9    0.996787
10   0.997992
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:13  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:13  11.431 sec  24407 obs/sec     1         1             10007      0.502194         0.861194            0.995518       0.235929                         0.502241           0.860039              0.995505         0.241365
    2019-08-04 09:00:16  14.442 sec  29694 obs/sec     10        10            100070     0.341379         0.387828            0.997929       0.116165                         0.342703           0.393261              0.997907         0.115663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0884132
C13         0.883869               0.883869             0.0781457
C9          0.840488               0.840488             0.0743102
C8          0.821829               0.821829             0.0726605
C12         0.760674               0.760674             0.0672536
C7          0.748495               0.748495             0.0661769
C10         0.731949               0.731949             0.064714
C5          0.717037               0.717037             0.0633955
C6          0.677857               0.677857             0.0599315
C11         0.665317               0.665317             0.0588228
C16         0.64112                0.64112              0.0566835
C14         0.633438               0.633438             0.0560043
C3          0.574772               0.574772             0.0508174
C4          0.56418                0.56418              0.049881
C2          0.530812               0.530812             0.0469308
C1          0.51869                0.51869              0.0458591
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_158

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019290155889564176  0.000492992578074336  0.0         -0.007019847770507681  0.16874301433563232  0.28039824194157054  0.119010329246521
    3        26       Softmax                      0.0   0.0   0.009369818563405156   0.04271902143955231   0.0         -0.2157514028989478    0.39228713512420654  -0.4629452615937684  0.08380356431007385


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11260101237450801
RMSE: 0.3355607431963817
LogLoss: 0.3805738545731771
Mean Per-Class Error: 0.10803420072972957
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    6.0    0.0    1.0    1.0    0.0    2.0    4.0    2.0    0.0    3.0    1.0    1.0    4.0    0.0    0.0759493670886076   30 / 395
0.0    345.0  0.0    6.0    1.0    2.0    0.0    7.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    5.0    0.0    6.0    6.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.09921671018276762  38 / 383
0.0    0.0    345.0  1.0    4.0    0.0    1.0    0.0    0.0    0.0    7.0    1.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0625               23 / 368
0.0    10.0   0.0    362.0  0.0    1.0    0.0    4.0    0.0    0.0    1.0    0.0    7.0    4.0    1.0    3.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.10173697270471464  41 / 403
0.0    5.0    2.0    0.0    322.0  9.0    13.0   2.0    0.0    0.0    8.0    3.0    0.0    0.0    0.0    1.0    5.0    3.0    4.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    16.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    2.0    0.0    4.0    5.0    1.0    0.0    0.0    2.0    1.0    10.0   0.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    0.0    356.0  2.0    4.0    0.09644670050761421  38 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    0.0    1.0    10.0   2.0    5.0    1.0    0.0    364.0  0.0    0.0737913486005089   29 / 393
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    9.0    2.0    0.0    0.0    0.0    2.0    0.0    327.0  0.10899182561307902  40 / 367
375.0  416.0  378.0  424.0  377.0  421.0  331.0  325.0  347.0  366.0  406.0  360.0  434.0  370.0  434.0  421.0  357.0  403.0  393.0  383.0  402.0  364.0  386.0  392.0  391.0  347.0  0.10766769969009297  1,077 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.892332
2    0.948715
3    0.969509
4    0.978806
5    0.984305
6    0.990003
7    0.992202
8    0.993902
9    0.995301
10   0.996801

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11638579866949156
RMSE: 0.3411536291313513
LogLoss: 0.39400225138624645
Mean Per-Class Error: 0.10655062347312194
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   93.0   0.0   1.0    1.0   1.0    0.0   1.0   0.0   0.0    1.0    0.0   0.0   0.0   1.0   1.0    0.0   3.0    1.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.12264150943396226  13 / 106
0.0   0.0    76.0  0.0    1.0   0.0    0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.07317073170731707  6 / 82
0.0   1.0    0.0   102.0  0.0   1.0    0.0   2.0   0.0   0.0    0.0    0.0   3.0   1.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.08928571428571429  10 / 112
0.0   0.0    0.0   0.0    79.0  5.0    4.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   0.0   0.0    1.0   1.0    3.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0    0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   87.0  0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   1.0    0.0   0.0   0.0   0.0    6.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   86.0  0.0    2.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   3.0    1.0   0.0    0.0   2.0   0.0    1.0   1.0   0.0   98.0   0.0   0.08411214953271028  9 / 107
1.0   0.0    0.0   0.0    5.0   0.0    0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0   0.0    78.0  0.10344827586206896  9 / 87
84.0  105.0  80.0  120.0  92.0  103.0  86.0  81.0  83.0  106.0  105.0  90.0  97.0  98.0  93.0  120.0  98.0  101.0  98.0  89.0  100.0  80.0  94.0  95.0  108.0  84.0  0.10722891566265061  267 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.892771
2    0.948996
3    0.965863
4    0.974699
5    0.982731
6    0.990361
7    0.992369
8    0.993976
9    0.995984
10   0.997189
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:28  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:29  4 min 26.905 sec  28591 obs/sec     1         1             10007      0.495558         0.834019            0.995637       0.224033                         0.495599           0.834307              0.995623         0.230522
    2019-08-04 09:04:32  4 min 29.893 sec  30453 obs/sec     10        10            100070     0.335561         0.380574            0.997999       0.107668                         0.341154           0.394002              0.997926         0.107229
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0827093
C13         0.974745               0.974745             0.0806205
C8          0.917816               0.917816             0.0759119
C12         0.851825               0.851825             0.0704538
C9          0.82947                0.82947              0.0686049
C5          0.797552               0.797552             0.0659649
C7          0.77701                0.77701              0.0642659
C10         0.741594               0.741594             0.0613367
C11         0.719707               0.719707             0.0595265
C14         0.69294                0.69294              0.0573126
C6          0.687351               0.687351             0.0568503
C16         0.687303               0.687303             0.0568464
C4          0.644548               0.644548             0.0533101
C3          0.628332               0.628332             0.0519689
C2          0.579444               0.579444             0.0479254
C1          0.560904               0.560904             0.046392
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_202

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0024939691877108316  0.0007450964767485857  0.0         0.003948638853413122   0.24907225370407104  0.017761554380962285  0.26984524726867676
    3        26       Softmax                 0.0   0.0   0.003374344300499825   0.0017070844769477844  0.0         -0.007374780858395542  0.35244643688201904  -0.5872652382488727   0.12121999263763428


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12354885500215809
RMSE: 0.351495170666907
LogLoss: 0.41353036053985087
Mean Per-Class Error: 0.1179709273823
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
369.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    2.0    0.0    2.0    0.0    0.0    2.0    2.0    1.0    1.0    3.0    1.0    0.0    2.0    4.0    0.061068702290076333  24 / 393
0.0    345.0  0.0    2.0    3.0    0.0    1.0    15.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    9.0    0.0    0.0    1.0    0.0    1.0    0.0    1.0    0.09921671018276762   38 / 383
0.0    0.0    328.0  1.0    4.0    1.0    14.0   1.0    0.0    0.0    10.0   1.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.10869565217391304   40 / 368
0.0    12.0   0.0    353.0  0.0    0.0    0.0    13.0   0.0    1.0    0.0    0.0    6.0    4.0    2.0    2.0    0.0    3.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    4.0    0.12406947890818859   50 / 403
0.0    4.0    2.0    0.0    334.0  5.0    17.0   4.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    2.0    1.0    2.0    2.0    1.0    0.0    0.0    1.0    0.0    6.0    0.13020833333333334   50 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    14.0   0.0    5.0    0.0    0.0    0.0    0.0    1.0    2.0    2.0    347.0  0.0    0.0    0.0    0.07712765957446809   29 / 376
0.0    2.0    1.0    4.0    5.0    1.0    0.0    5.0    3.0    3.0    12.0   1.0    0.0    0.0    0.0    1.0    7.0    2.0    0.0    4.0    1.0    0.0    0.0    335.0  2.0    5.0    0.14974619289340102   59 / 394
0.0    0.0    0.0    2.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    0.0    1.0    4.0    0.0    9.0    1.0    1.0    363.0  0.0    0.07633587786259542   30 / 393
1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    5.0    1.0    0.0    0.0    0.0    0.0    0.0    342.0  0.0681198910081744    25 / 367
391.0  443.0  342.0  401.0  398.0  384.0  416.0  441.0  351.0  370.0  372.0  354.0  423.0  375.0  393.0  391.0  391.0  335.0  328.0  385.0  401.0  381.0  368.0  368.0  394.0  407.0  0.11746476057182845   1,175 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.882535
2    0.941018
3    0.964211
4    0.974908
5    0.982005
6    0.987304
7    0.990303
8    0.992702
9    0.994102
10   0.995701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1264317163921535
RMSE: 0.3555723785562561
LogLoss: 0.4235906091966062
Mean Per-Class Error: 0.12124521190894805
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6      7      8     9      10    11    12    13    14    15     16     17    18    19    20     21    22    23    24     25     Error                 Rate
----  -----  ----  -----  -----  ----  -----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  -----  --------------------  -----------
86.0  0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0    0.033707865168539325  3 / 89
0.0   91.0   0.0   1.0    2.0    0.0   1.0    6.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    1.0   2.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0    0.14150943396226415   15 / 106
0.0   0.0    74.0  0.0    2.0    0.0   2.0    0.0    0.0   0.0    1.0   0.0   0.0   0.0   3.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0975609756097561    8 / 82
0.0   1.0    0.0   95.0   0.0    0.0   0.0    6.0    0.0   0.0    0.0   0.0   2.0   1.0   1.0   2.0    0.0    0.0   0.0   0.0   1.0    0.0   0.0   1.0   0.0    2.0    0.15178571428571427   17 / 112
0.0   0.0    1.0   0.0    81.0   4.0   5.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0    0.16494845360824742   16 / 97
---   ---    ---   ---    ---    ---   ---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   1.0    1.0   86.0  0.0   0.0    0.0    0.06521739130434782   6 / 92
0.0   0.0    0.0   2.0    2.0    1.0   0.0    2.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   0.0    1.0    2.0   0.0   0.0   0.0    0.0   0.0   82.0  0.0    2.0    0.18                  18 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0    2.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    2.0    0.0   0.0   0.0   0.0    3.0   1.0   0.0   97.0   0.0    0.09345794392523364   10 / 107
1.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    82.0   0.05747126436781609   5 / 87
91.0  108.0  78.0  108.0  100.0  92.0  101.0  116.0  84.0  106.0  91.0  91.0  95.0  98.0  84.0  117.0  100.0  84.0  81.0  84.0  103.0  88.0  91.0  89.0  108.0  102.0  0.12208835341365462   304 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877912
2    0.94498
3    0.964659
4    0.974699
5    0.981526
6    0.986747
7    0.989157
8    0.991968
9    0.993173
10   0.996386
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:55  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:55  5 min 53.583 sec  23657 obs/sec     1         1             10007      0.515959         0.896854            0.995268       0.246626                         0.515494           0.897406              0.995265         0.252209
    2019-08-04 09:05:59  5 min 57.611 sec  22805 obs/sec     10        10            100070     0.351495         0.41353             0.997804       0.117465                         0.355572           0.423591              0.997747         0.122088
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0871171
C15         0.987661               0.987661             0.0860422
C9          0.900522               0.900522             0.0784509
C12         0.863839               0.863839             0.0752551
C8          0.843602               0.843602             0.0734922
C7          0.771493               0.771493             0.0672103
C10         0.763541               0.763541             0.0665175
C11         0.751209               0.751209             0.0654432
C6          0.689488               0.689488             0.0600662
C14         0.660458               0.660458             0.0575372
C5          0.653809               0.653809             0.0569579
C16         0.615256               0.615256             0.0535993
C3          0.549747               0.549747             0.0478924
C4          0.515776               0.515776             0.0449329
C2          0.461459               0.461459             0.040201
C1          0.450941               0.450941             0.0392846
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_122

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.002648448207509091   0.0007432685233652592  0.0         0.0027909617567090095  0.2465948462486267  0.012113524425934498  0.27556276321411133
    3        26       Softmax                 0.0   0.0   0.0037328004244465353  0.001719075720757246   0.0         -0.002546121498333229  0.349078893661499   -0.5959373841666963   0.12074500322341919


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1260865709403588
RMSE: 0.35508670904493006
LogLoss: 0.4178084848719232
Mean Per-Class Error: 0.12307871049974005
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    3.0    4.0    6.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    1.0    2.0    1.0    1.0    4.0    2.0    0.08375634517766498  33 / 394
0.0    334.0  1.0    11.0   2.0    2.0    1.0    10.0   3.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    3.0    6.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.1279373368146214   49 / 383
0.0    0.0    329.0  1.0    4.0    1.0    8.0    1.0    0.0    0.0    10.0   1.0    0.0    0.0    5.0    0.0    0.0    1.0    2.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.10597826086956522  39 / 368
0.0    9.0    0.0    366.0  0.0    1.0    0.0    5.0    1.0    5.0    2.0    0.0    5.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.09181141439205956  37 / 403
0.0    3.0    5.0    0.0    323.0  6.0    16.0   1.0    0.0    0.0    2.0    6.0    0.0    0.0    0.0    1.0    3.0    3.0    7.0    2.0    0.0    0.0    0.0    4.0    0.0    2.0    0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    23.0   0.0    1.0    2.0    0.0    0.0    0.0    0.0    2.0    3.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    0.0    0.0    4.0    4.0    1.0    0.0    2.0    4.0    2.0    11.0   0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    1.0    0.0    0.0    354.0  2.0    2.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    3.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    1.0    6.0    1.0    21.0   1.0    1.0    349.0  0.0    0.11195928753180662  44 / 393
1.0    1.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    28.0   2.0    0.0    0.0    0.0    1.0    0.0    302.0  0.1771117166212534   65 / 367
377.0  427.0  353.0  455.0  372.0  418.0  369.0  341.0  358.0  401.0  389.0  391.0  436.0  380.0  368.0  388.0  378.0  350.0  395.0  379.0  397.0  398.0  380.0  415.0  369.0  319.0  0.1224632610216935   1,225 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877537
2    0.943617
3    0.96541
4    0.976307
5    0.983505
6    0.987704
7    0.990903
8    0.992402
9    0.994702
10   0.995801

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1284228801898983
RMSE: 0.3583613821129424
LogLoss: 0.42838937950685774
Mean Per-Class Error: 0.12411567108396701
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11     12    13    14    15     16    17    18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   2.0    1.0   0.07865168539325842  7 / 89
0.0   87.0   1.0   2.0    2.0   1.0    1.0   3.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0   3.0   1.0   0.0   0.0    3.0   0.0   1.0   0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    72.0  0.0    1.0   1.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0   2.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.12195121951219512  10 / 82
0.0   1.0    0.0   98.0   0.0   1.0    0.0   2.0   1.0   2.0    1.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   2.0   0.0    0.0   0.125                14 / 112
0.0   1.0    1.0   0.0    79.0  5.0    5.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0   1.0   2.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    1.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   1.0    0.0   1.0   0.0   0.0    7.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   86.0  0.0    1.0   0.14                 14 / 100
0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.0   0.0   0.0   0.0    7.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0   0.0   3.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0   5.0   0.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
85.0  110.0  77.0  118.0  91.0  103.0  96.0  86.0  88.0  113.0  96.0  102.0  96.0  99.0  82.0  110.0  93.0  91.0  98.0  89.0  101.0  93.0  93.0  97.0  106.0  77.0  0.12449799196787148  310 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875502
2    0.946586
3    0.967871
4    0.977912
5    0.983132
6    0.987148
7    0.989558
8    0.991165
9    0.994377
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:26  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:26  3 min 24.271 sec  23326 obs/sec     1         1             10007      0.516668         0.919912            0.995256       0.243127                         0.515782           0.9155                0.99526          0.242972
    2019-08-04 09:03:30  3 min 28.346 sec  22578 obs/sec     10        10            100070     0.355087         0.417808            0.997759       0.122463                         0.358361           0.428389              0.997712         0.124498
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0847423
C13         0.97041                0.97041              0.0822348
C9          0.9307                 0.9307               0.0788697
C8          0.858815               0.858815             0.072778
C12         0.857816               0.857816             0.0726933
C11         0.812691               0.812691             0.0688693
C10         0.797581               0.797581             0.0675888
C7          0.766828               0.766828             0.0649828
C6          0.712823               0.712823             0.0604062
C16         0.701784               0.701784             0.0594708
C14         0.663678               0.663678             0.0562416
C5          0.661007               0.661007             0.0560153
C3          0.558012               0.558012             0.0472872
C4          0.546776               0.546776             0.0463351
C1          0.488304               0.488304             0.04138
C2          0.473253               0.473253             0.0401046
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_144

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0026779030715715635  0.0007395821157842875  0.0         -0.0013250012294747648  0.24729454517364502  0.021577118785218265  0.2752879858016968
    3        26       Softmax                 0.0   0.0   0.003868300380453058   0.00194172328338027    0.0         -0.011318869108585808   0.3458414077758789   -0.5930907503690533   0.15086418390274048


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12478661504835369
RMSE: 0.3532514898034454
LogLoss: 0.4188477715838021
Mean Per-Class Error: 0.12296010799303804
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    4.0    1.0    3.0    0.0    0.0    0.0    0.0    3.0    3.0    2.0    2.0    0.0    0.0    0.0    3.0    3.0    0.07341772151898734  29 / 395
0.0    336.0  2.0    4.0    2.0    0.0    1.0    13.0   2.0    1.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    8.0    6.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    324.0  0.0    4.0    0.0    10.0   2.0    0.0    0.0    10.0   0.0    0.0    0.0    4.0    0.0    0.0    1.0    4.0    2.0    7.0    0.0    0.0    0.0    0.0    0.0    0.11956521739130435  44 / 368
0.0    17.0   0.0    347.0  0.0    0.0    0.0    11.0   0.0    4.0    0.0    0.0    3.0    5.0    2.0    2.0    0.0    5.0    3.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.13895781637717122  56 / 403
0.0    5.0    3.0    0.0    329.0  4.0    15.0   3.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    2.0    3.0    3.0    4.0    1.0    0.0    0.0    4.0    0.0    4.0    0.14322916666666666  55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    13.0   0.0    5.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    4.0    5.0    0.0    0.0    1.0    2.0    2.0    6.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    3.0    1.0    0.0    0.0    354.0  2.0    3.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    1.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    0.0    2.0    4.0    3.0    5.0    1.0    1.0    366.0  0.0    0.0663265306122449   26 / 392
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    10.0   3.0    0.0    0.0    0.0    1.0    0.0    330.0  0.1008174386920981   37 / 367
384.0  463.0  343.0  394.0  409.0  371.0  372.0  394.0  343.0  371.0  362.0  366.0  403.0  375.0  400.0  386.0  390.0  389.0  376.0  390.0  419.0  351.0  375.0  407.0  404.0  366.0  0.12236329101269619  1,224 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877637
2    0.940918
3    0.963611
4    0.973408
5    0.981406
6    0.987104
7    0.989703
8    0.992302
9    0.993602
10   0.994802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.12693080349153418
RMSE: 0.3562734953536878
LogLoss: 0.4286010326259021
Mean Per-Class Error: 0.12232930254960452
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7      8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   88.0   0.0   1.0    2.0    0.0   1.0   4.0    1.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   4.0    2.0   0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    72.0  0.0    1.0    0.0   3.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.12195121951219512   10 / 82
0.0   1.0    0.0   97.0   0.0    0.0   0.0   5.0    0.0   1.0    0.0   0.0   1.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.13392857142857142   15 / 112
0.0   0.0    0.0   0.0    82.0   2.0   4.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   2.0   0.0    0.0   0.0   2.0    0.0    1.0   0.15463917525773196   15 / 97
---   ---    ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   88.0  0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   1.0    2.0    0.0   0.0   1.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   91.0   0.0    1.0   0.09                  9 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    2.0   0.0    0.0   0.0   0.0    2.0   1.0   0.0    99.0   0.0   0.07476635514018691   8 / 107
0.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0   0.0    0.0    77.0  0.11494252873563218   10 / 87
87.0  111.0  75.0  110.0  105.0  81.0  94.0  102.0  86.0  110.0  90.0  93.0  88.0  99.0  85.0  115.0  99.0  101.0  94.0  91.0  105.0  75.0  91.0  102.0  115.0  86.0  0.1216867469879518    303 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878313
2    0.939357
3    0.963454
4    0.971888
5    0.980723
6    0.987148
7    0.989558
8    0.991968
9    0.993173
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:56  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:57  3 min 54.943 sec  23326 obs/sec     1         1             10007      0.514603         0.900465            0.995294       0.245826                         0.516102           0.904707              0.995254         0.253414
    2019-08-04 09:04:00  3 min 58.755 sec  23934 obs/sec     10        10            100070     0.353251         0.418848            0.997783       0.122363                         0.356273           0.428601              0.997738         0.121687
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.085773
C13         0.996864               0.996864             0.085504
C9          0.907674               0.907674             0.0778539
C12         0.869495               0.869495             0.0745792
C8          0.836963               0.836963             0.0717888
C10         0.791955               0.791955             0.0679284
C11         0.772596               0.772596             0.0662679
C7          0.752949               0.752949             0.0645826
C16         0.703081               0.703081             0.0603053
C6          0.675886               0.675886             0.0579728
C14         0.672711               0.672711             0.0577004
C5          0.646629               0.646629             0.0554633
C3          0.549054               0.549054             0.047094
C4          0.526396               0.526396             0.0451505
C2          0.480735               0.480735             0.041234
C1          0.475698               0.475698             0.040802
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_13

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.002585489559663756  0.0007786978967487812  0.0         -0.002112596657606991   0.24766498804092407  0.010235455299436988  0.28151392936706543
    3        26       Softmax                 0.0   0.0   0.00365161500625478   0.0016218870878219604  0.0         -0.0034731938529677544  0.3526749610900879   -0.5898650927399716   0.10221001505851746


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12537154365333272
RMSE: 0.3540784427966954
LogLoss: 0.4206360625916419
Mean Per-Class Error: 0.1223083818546665
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
374.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    0.0    1.0    1.0    3.0    4.0    0.053164556962025315  21 / 395
0.0    343.0  0.0    9.0    6.0    1.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    4.0    0.0    0.0    0.0    1.0    1.0    1.0    2.0    0.10443864229765012   40 / 383
0.0    0.0    323.0  1.0    5.0    1.0    8.0    1.0    0.0    0.0    13.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    4.0    8.0    0.0    0.0    0.0    0.0    0.0    0.12228260869565218   45 / 368
1.0    13.0   0.0    357.0  0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    2.0    7.0    2.0    1.0    0.0    6.0    1.0    0.0    3.0    0.0    0.0    5.0    0.0    2.0    0.11194029850746269   45 / 402
0.0    2.0    2.0    0.0    339.0  5.0    13.0   1.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    3.0    4.0    1.0    2.0    0.0    0.0    0.0    2.0    0.0    7.0    0.1171875             45 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    1.0    0.0    12.0   0.0    5.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    343.0  0.0    0.0    0.0    0.08533333333333333   32 / 375
0.0    1.0    0.0    5.0    3.0    2.0    0.0    2.0    3.0    1.0    12.0   1.0    0.0    0.0    0.0    1.0    7.0    0.0    1.0    3.0    1.0    0.0    0.0    342.0  3.0    5.0    0.1297709923664122    51 / 393
0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    15.0   3.0    5.0    1.0    1.0    362.0  0.0    0.07888040712468193   31 / 393
3.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    10.0   2.0    0.0    0.0    0.0    0.0    0.0    336.0  0.08446866485013624   31 / 367
402.0  447.0  342.0  430.0  428.0  354.0  368.0  327.0  346.0  357.0  376.0  341.0  396.0  385.0  384.0  415.0  389.0  429.0  341.0  405.0  444.0  345.0  377.0  385.0  396.0  394.0  0.12156353094071778   1,216 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878436
2    0.940318
3    0.964311
4    0.975707
5    0.982805
6    0.986104
7    0.989003
8    0.991702
9    0.993402
10   0.995301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1277888042331746
RMSE: 0.3574755994934124
LogLoss: 0.4289909612045266
Mean Per-Class Error: 0.1258677857989989
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  -----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   2.0    1.0    0.0449438202247191   4 / 89
0.0   90.0   0.0   4.0    3.0    0.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   4.0    0.0   0.0   0.0    0.0   1.0   1.0   1.0    0.0    0.1509433962264151   16 / 106
0.0   0.0    72.0  0.0    2.0    0.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   2.0   1.0    0.0   0.0   0.0   0.0    0.0    0.12195121951219512  10 / 82
1.0   1.0    0.0   99.0   0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   3.0    1.0   1.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0    2.0    0.11607142857142858  13 / 112
0.0   0.0    1.0   0.0    84.0   4.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0    0.13402061855670103  13 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---    ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   4.0    0.0   85.0  0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0    1.0   0.0   1.0   1.0   0.0    5.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   84.0  0.0    2.0    0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   3.0   0.0    3.0   1.0   0.0   98.0   0.0    0.08411214953271028  9 / 107
1.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    81.0   0.06896551724137931  6 / 87
91.0  106.0  76.0  123.0  106.0  85.0  91.0  80.0  84.0  106.0  93.0  90.0  84.0  103.0  82.0  117.0  99.0  106.0  78.0  97.0  114.0  75.0  95.0  94.0  114.0  101.0  0.1248995983935743   311 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.8751
2    0.943775
3    0.966265
4    0.975502
5    0.983132
6    0.985944
7    0.989558
8    0.991165
9    0.993976
10   0.995984
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:27  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:28  25.938 sec  23057 obs/sec     1         1             10007      0.522503         0.920668            0.995147       0.252124                         0.521562           0.92325               0.995153         0.257028
    2019-08-04 09:00:32  29.865 sec  23299 obs/sec     10        10            100070     0.354078         0.420636            0.997771       0.121564                         0.357476           0.428991              0.997723         0.1249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0872675
C13         0.982679               0.982679             0.0857559
C9          0.918819               0.918819             0.080183
C12         0.881338               0.881338             0.0769121
C8          0.843124               0.843124             0.0735773
C10         0.757187               0.757187             0.0660777
C7          0.742308               0.742308             0.0647793
C11         0.712893               0.712893             0.0622124
C16         0.687813               0.687813             0.0600237
C5          0.66859                0.66859              0.0583461
C6          0.637111               0.637111             0.0555991
C14         0.636177               0.636177             0.0555175
C3          0.538481               0.538481             0.0469919
C4          0.533926               0.533926             0.0465944
C1          0.466955               0.466955             0.0407499
C2          0.451627               0.451627             0.0394123
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_178

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0025780814899718507  0.000760895200073719   0.0         -0.0010817168458547854  0.2484411597251892   0.005277538001781833  0.272241473197937
    3        26       Softmax                 0.0   0.0   0.0036997140356596413  0.0018929601646959782  0.0         0.004429208418947348    0.35559940338134766  -0.5819770752980058   0.11911535263061523


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12512571573914102
RMSE: 0.3537311348173087
LogLoss: 0.4199645470886772
Mean Per-Class Error: 0.12432584326583945
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
369.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    2.0    3.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    1.0    0.0    2.0    0.0    4.0    3.0    0.06582278481012659   26 / 395
0.0    326.0  0.0    6.0    5.0    0.0    1.0    4.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    28.0   5.0    0.0    0.0    1.0    0.0    2.0    0.0    1.0    0.14882506527415143   57 / 383
0.0    0.0    319.0  1.0    9.0    0.0    9.0    1.0    0.0    0.0    12.0   1.0    0.0    0.0    3.0    0.0    1.0    1.0    4.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    0.1331521739130435    49 / 368
1.0    9.0    0.0    351.0  0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    5.0    4.0    2.0    0.0    0.0    12.0   0.0    0.0    1.0    0.0    0.0    6.0    0.0    1.0    0.12903225806451613   52 / 403
0.0    3.0    1.0    0.0    332.0  3.0    13.0   0.0    1.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    3.0    5.0    4.0    3.0    0.0    0.0    0.0    4.0    0.0    9.0    0.13541666666666666   52 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    3.0    353.0  0.0    0.0    0.0    0.061170212765957445  23 / 376
0.0    0.0    0.0    4.0    5.0    0.0    0.0    3.0    2.0    1.0    4.0    3.0    0.0    0.0    2.0    0.0    3.0    1.0    0.0    3.0    1.0    0.0    0.0    355.0  3.0    3.0    0.09669211195928754   38 / 393
0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    5.0    1.0    2.0    1.0    0.0    375.0  0.0    0.04092071611253197   16 / 391
2.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    2.0    8.0    4.0    0.0    0.0    0.0    1.0    0.0    336.0  0.08446866485013624   31 / 367
396.0  430.0  338.0  408.0  410.0  386.0  355.0  324.0  333.0  357.0  350.0  375.0  391.0  366.0  366.0  346.0  387.0  536.0  357.0  404.0  412.0  334.0  415.0  414.0  438.0  375.0  0.1236629011296611    1,237 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876337
2    0.939918
3    0.96511
4    0.975807
5    0.983105
6    0.987804
7    0.990003
8    0.992402
9    0.993402
10   0.994502

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.12730939834706345
RMSE: 0.35680442590733574
LogLoss: 0.43059831251856706
Mean Per-Class Error: 0.12531769132440765
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11     12    13     14    15    16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   1.0    0.0    2.0    1.0   0.07865168539325842  7 / 89
0.0   85.0   0.0   2.0    3.0    0.0   1.0   1.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   8.0    3.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    67.0  0.0    3.0    0.0   2.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0    3.0   1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.18292682926829268  15 / 82
1.0   2.0    0.0   94.0   0.0    0.0   0.0   5.0   0.0   0.0    0.0   0.0    2.0   1.0    0.0   0.0   0.0   3.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    1.0   0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    83.0   1.0   4.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0    2.0   1.0   0.0    0.0   0.0    1.0    0.0    3.0   0.14432989690721648  14 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   1.0    2.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    1.0    0.0   0.0   1.0   0.0   0.0    2.0   2.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    89.0   1.0    1.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0   0.0    1.0   1.0    0.0    102.0  0.0   0.04672897196261682  5 / 107
1.0   0.0    0.0   0.0    2.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    0.0    0.0    81.0  0.06896551724137931  6 / 87
87.0  106.0  72.0  110.0  104.0  85.0  87.0  82.0  82.0  105.0  87.0  102.0  84.0  100.0  81.0  98.0  95.0  133.0  91.0  99.0  105.0  75.0  101.0  100.0  128.0  91.0  0.1248995983935743   311 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.8751
2    0.944578
3    0.96747
4    0.976707
5    0.982731
6    0.987952
7    0.98996
8    0.992771
9    0.993976
10   0.994378
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:15  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:16  5 min 13.908 sec  22640 obs/sec     1         1             10007      0.516498         0.900959            0.995258       0.249525                         0.516704           0.905383              0.995243         0.257831
    2019-08-04 09:05:20  5 min 17.823 sec  23304 obs/sec     10        10            100070     0.353731         0.419965            0.997776       0.123663                         0.356804           0.430598              0.997732         0.1249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.085434
C13         0.973062               0.973062             0.0831326
C12         0.912248               0.912248             0.077937
C9          0.901302               0.901302             0.0770019
C8          0.868312               0.868312             0.0741834
C10         0.773034               0.773034             0.0660434
C7          0.760469               0.760469             0.06497
C11         0.740523               0.740523             0.0632659
C16         0.713777               0.713777             0.0609808
C6          0.692043               0.692043             0.059124
C14         0.683662               0.683662             0.058408
C5          0.675239               0.675239             0.0576884
C3          0.540807               0.540807             0.0462033
C4          0.529947               0.529947             0.0452755
C1          0.477485               0.477485             0.0407935
C2          0.463028               0.463028             0.0395583
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_26

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight          weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  -------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018383149300404966  0.00048782164230942726  0.0         -0.0097304013780396  0.16859763860702515  0.18079611084809125  0.11773091554641724
    3        26       Softmax                      0.0   0.0   0.012133934353405844   0.05062510073184967     0.0         -0.199891660686178   0.3972219228744507   -0.6588508212869383  0.19012582302093506


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12911744749307288
RMSE: 0.3593291631541655
LogLoss: 0.42390904731858603
Mean Per-Class Error: 0.12054186171746686
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.0    1.0    1.0    0.0    2.0    3.0    0.0    3.0    1.0    3.0    1.0    2.0    5.0    0.06852791878172589   27 / 394
0.0    343.0  0.0    3.0    3.0    0.0    0.0    7.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    15.0   6.0    0.0    1.0    0.0    1.0    1.0    0.0    0.0    0.10443864229765012   40 / 383
0.0    0.0    330.0  0.0    10.0   0.0    6.0    1.0    0.0    0.0    7.0    2.0    0.0    0.0    5.0    0.0    0.0    1.0    1.0    1.0    2.0    0.0    2.0    0.0    0.0    0.0    0.10326086956521739   38 / 368
0.0    21.0   0.0    352.0  0.0    1.0    0.0    5.0    0.0    2.0    0.0    0.0    2.0    8.0    2.0    1.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.12655086848635236   51 / 403
0.0    4.0    1.0    0.0    336.0  3.0    17.0   1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    2.0    0.0    1.0    0.0    0.0    4.0    0.0    9.0    0.125                 48 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    358.0  0.0    0.0    0.0    0.047872340425531915  18 / 376
0.0    2.0    0.0    4.0    5.0    0.0    0.0    1.0    2.0    2.0    6.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    2.0    2.0    1.0    0.0    0.0    357.0  2.0    4.0    0.09390862944162437   37 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    2.0    4.0    3.0    5.0    1.0    0.0    370.0  0.0    0.058524173027989825  23 / 393
2.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    13.0   2.0    0.0    0.0    0.0    0.0    0.0    332.0  0.09289617486338798   34 / 366
387.0  458.0  360.0  413.0  420.0  344.0  372.0  318.0  342.0  354.0  355.0  349.0  379.0  399.0  397.0  408.0  368.0  438.0  391.0  375.0  421.0  351.0  413.0  417.0  400.0  374.0  0.11996401079676097   1,200 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.880036
2    0.939718
3    0.964411
4    0.974108
5    0.980406
6    0.986804
7    0.990803
8    0.992502
9    0.994202
10   0.995701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.12992481761005756
RMSE: 0.3604508532519483
LogLoss: 0.43154334158772156
Mean Per-Class Error: 0.11524175189459186
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   1.0    0.0   1.0    0.0   2.0    0.0   0.06741573033707865   6 / 89
0.0   89.0   0.0   1.0    2.0    0.0   0.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   5.0    2.0   0.0   1.0    0.0   1.0    1.0   0.0    0.0   0.16037735849056603   17 / 106
0.0   0.0    72.0  0.0    1.0    0.0   1.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0   0.12195121951219512   10 / 82
0.0   2.0    0.0   99.0   0.0    1.0   0.0   2.0   0.0   1.0    0.0   0.0   0.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    1.0   0.11607142857142858   13 / 112
0.0   0.0    0.0   0.0    84.0   1.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0    2.0   0.0    3.0   0.13402061855670103   13 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   90.0   0.0   0.0    0.0   0.021739130434782608  2 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    87.0  0.0    2.0   0.13                  13 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0   1.0   0.0    1.0   1.0    0.0   101.0  0.0   0.056074766355140186  6 / 107
1.0   0.0    0.0   0.0    2.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    81.0  0.06896551724137931   6 / 87
89.0  110.0  77.0  116.0  101.0  79.0  95.0  75.0  84.0  104.0  89.0  94.0  79.0  108.0  86.0  117.0  98.0  112.0  95.0  87.0  107.0  76.0  103.0  98.0  116.0  95.0  0.1144578313253012    285 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.885542
2    0.943373
3    0.964659
4    0.973092
5    0.980321
6    0.984337
7    0.987952
8    0.991165
9    0.994378
10   0.994779
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:51  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:51  49.273 sec  32073 obs/sec     1         1             10007      0.525677         0.918355            0.995088       0.248625                         0.5284             0.925073              0.995025         0.25261
    2019-08-04 09:00:54  51.810 sec  35957 obs/sec     10        10            100070     0.359329         0.423909            0.997705       0.119964                         0.360451           0.431543              0.997685         0.114458
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0872959
C13         0.904301               0.904301             0.0789418
C9          0.830547               0.830547             0.0725033
C8          0.81228                0.81228              0.0709087
C12         0.803204               0.803204             0.0701164
C7          0.798082               0.798082             0.0696693
C11         0.748121               0.748121             0.0653079
C5          0.724713               0.724713             0.0632645
C10         0.691212               0.691212             0.06034
C6          0.658072               0.658072             0.0574469
C14         0.652448               0.652448             0.056956
C16         0.626838               0.626838             0.0547204
C3          0.602775               0.602775             0.0526198
C4          0.590644               0.590644             0.0515608
C2          0.511849               0.511849             0.0446823
C1          0.500208               0.500208             0.0436661
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_232

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018170285484018223  0.0004515731707215309  0.0         -0.010027232153459353  0.16954320669174194  0.18006183551160185  0.12716984748840332
    3        26       Softmax                      0.0   0.0   0.009476096036792114   0.03844645619392395    0.0         -0.20130514861328772   0.39619314670562744  -0.6334144517139658  0.18991762399673462


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12971122340296556
RMSE: 0.3601544438195447
LogLoss: 0.42467751039925955
Mean Per-Class Error: 0.12058696310100761
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
369.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    3.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    1.0    0.0    2.0    2.0    5.0    1.0    0.06582278481012659  26 / 395
0.0    344.0  0.0    9.0    3.0    0.0    2.0    2.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    9.0    6.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.10182767624020887  39 / 383
0.0    0.0    319.0  0.0    9.0    0.0    8.0    1.0    0.0    0.0    13.0   3.0    0.0    0.0    4.0    0.0    0.0    1.0    3.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    0.1331521739130435   49 / 368
0.0    13.0   0.0    359.0  0.0    0.0    1.0    3.0    0.0    4.0    0.0    0.0    4.0    5.0    1.0    0.0    0.0    7.0    0.0    0.0    2.0    0.0    0.0    4.0    0.0    0.0    0.10918114143920596  44 / 403
0.0    1.0    3.0    0.0    330.0  2.0    17.0   0.0    0.0    0.0    2.0    4.0    0.0    0.0    0.0    0.0    1.0    4.0    6.0    3.0    0.0    0.0    0.0    4.0    0.0    7.0    0.140625             54 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    10.0   1.0    1.0    0.0    0.0    2.0    0.0    0.0    8.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    0.0    0.0    4.0    6.0    0.0    0.0    1.0    3.0    4.0    5.0    4.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    0.0    357.0  1.0    3.0    0.09390862944162437  37 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    15.0   2.0    9.0    1.0    0.0    355.0  0.0    0.09669211195928754  38 / 393
1.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    0.0    326.0  0.11171662125340599  41 / 367
394.0  470.0  349.0  411.0  406.0  386.0  378.0  313.0  351.0  387.0  365.0  391.0  388.0  391.0  390.0  366.0  347.0  431.0  380.0  380.0  413.0  365.0  389.0  419.0  389.0  354.0  0.12006398080575827  1,201 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.879936
2    0.942017
3    0.964711
4    0.975208
5    0.982205
6    0.987904
7    0.991003
8    0.992802
9    0.994002
10   0.995501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13180150140062852
RMSE: 0.3630447650092596
LogLoss: 0.432818182599059
Mean Per-Class Error: 0.12082695735432004
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0   0.0    2.0    0.0   0.0449438202247191   4 / 89
0.0   88.0   0.0   3.0    2.0   0.0   2.0   1.0   1.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    0.0   4.0    1.0   0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    69.0  0.0    1.0   0.0   1.0   0.0   0.0   0.0    3.0   1.0    0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.15853658536585366  13 / 82
0.0   2.0    0.0   100.0  0.0   0.0   1.0   2.0   0.0   1.0    0.0   0.0    1.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    0.0   0.10714285714285714  12 / 112
0.0   0.0    0.0   0.0    81.0  1.0   5.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0    0.0   0.0    0.0   1.0    3.0   1.0   0.0    0.0   0.0   1.0    0.0    2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   3.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0   1.0   1.0    2.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   89.0   0.0    1.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   5.0   0.0    3.0   1.0   0.0    96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0    78.0  0.10344827586206896  9 / 87
92.0  120.0  73.0  114.0  96.0  90.0  96.0  74.0  87.0  112.0  94.0  102.0  82.0  105.0  85.0  106.0  90.0  107.0  95.0  89.0  106.0  79.0  96.0  104.0  111.0  85.0  0.12088353413654618  301 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.879116
2    0.944578
3    0.961044
4    0.973494
5    0.980321
6    0.985944
7    0.991165
8    0.993173
9    0.993976
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:47  6 min 45.480 sec  32702 obs/sec     1         1             10007      0.522827         0.90427             0.995142       0.243127                         0.522199           0.904388              0.995141         0.246586
    2019-08-04 09:06:50  6 min 47.981 sec  36296 obs/sec     10        10            100070     0.360154         0.424678            0.997695       0.120064                         0.363045           0.432818              0.997651         0.120884
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0877079
C13         0.942419               0.942419             0.0826576
C9          0.829108               0.829108             0.0727193
C7          0.804757               0.804757             0.0705835
C8          0.799896               0.799896             0.0701572
C12         0.799004               0.799004             0.0700789
C5          0.738084               0.738084             0.0647357
C10         0.705645               0.705645             0.0618906
C11         0.676713               0.676713             0.0593531
C14         0.64434                0.64434              0.0565137
C6          0.636847               0.636847             0.0558565
C3          0.623443               0.623443             0.0546808
C16         0.594502               0.594502             0.0521425
C4          0.589142               0.589142             0.0516724
C1          0.512345               0.512345             0.0449366
C2          0.505244               0.505244             0.0443139
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_1

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018355830654996907  0.00046687701251357794  0.0         -0.011471151471402763  0.168789803981781   0.17546969544991498  0.12351483106613159
    3        26       Softmax                      0.0   0.0   0.01022605842312994    0.038969025015830994    0.0         -0.19739245434851135   0.3970773220062256  -0.6541408315376999  0.17641937732696533


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1295879148017517
RMSE: 0.35998321461111443
LogLoss: 0.42575098588862736
Mean Per-Class Error: 0.12337240703294243
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
368.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    2.0    3.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    5.0    0.0    0.0    0.0    5.0    2.0    0.06835443037974684  27 / 395
0.0    353.0  0.0    6.0    2.0    0.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    3.0    5.0    4.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0783289817232376   30 / 383
0.0    0.0    327.0  0.0    8.0    0.0    3.0    0.0    0.0    0.0    8.0    1.0    0.0    0.0    6.0    0.0    2.0    0.0    1.0    2.0    9.0    0.0    1.0    0.0    0.0    0.0    0.11141304347826086  41 / 368
1.0    17.0   0.0    357.0  0.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    5.0    5.0    1.0    1.0    0.0    4.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    3.0    0.11194029850746269  45 / 402
0.0    6.0    3.0    0.0    334.0  2.0    13.0   2.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    5.0    3.0    3.0    1.0    0.0    0.0    0.0    3.0    0.0    5.0    0.13020833333333334  50 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    2.0    0.0    0.0    9.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    2.0    0.0    4.0    6.0    0.0    0.0    1.0    3.0    3.0    2.0    0.0    0.0    0.0    2.0    0.0    4.0    0.0    1.0    1.0    1.0    0.0    0.0    359.0  1.0    4.0    0.08883248730964467  35 / 394
0.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    5.0    0.0    2.0    7.0    1.0    6.0    1.0    0.0    361.0  0.0    0.07908163265306123  31 / 392
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    19.0   2.0    0.0    0.0    0.0    0.0    0.0    317.0  0.1362397820163488   50 / 367
389.0  486.0  376.0  412.0  411.0  336.0  326.0  315.0  355.0  359.0  361.0  361.0  403.0  374.0  400.0  419.0  401.0  423.0  413.0  376.0  424.0  353.0  387.0  398.0  398.0  347.0  0.1227631710486854   1,228 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877237
2    0.939518
3    0.963411
4    0.973108
5    0.980206
6    0.984904
7    0.989403
8    0.992202
9    0.993702
10   0.996001

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1305242632382583
RMSE: 0.3612814183406867
LogLoss: 0.43401299703868323
Mean Per-Class Error: 0.1189559479265419
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   0.0   0.0   2.0    0.0   0.0449438202247191   4 / 89
0.0   95.0   0.0   0.0    1.0    0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0    3.0    1.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.10377358490566038  11 / 106
0.0   0.0    71.0  0.0    1.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    3.0   0.0    1.0    0.0    1.0   2.0   1.0    0.0   0.0   0.0   0.0    0.0   0.13414634146341464  11 / 82
1.0   1.0    0.0   101.0  0.0    0.0   0.0   1.0   0.0   0.0    1.0   0.0   1.0   2.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0    0.0   0.0   1.0   0.0    2.0   0.09821428571428571  11 / 112
0.0   0.0    1.0   0.0    84.0   1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    1.0    1.0   0.0   0.0    0.0   0.0   1.0   0.0    3.0   0.13402061855670103  13 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   4.0    0.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   93.0  0.0    1.0   0.07                 7 / 100
0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   1.0    2.0    0.0    0.0   2.0   0.0    2.0   1.0   0.0   97.0   0.0   0.09345794392523364  10 / 107
1.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    76.0  0.12643678160919541  11 / 87
92.0  121.0  80.0  115.0  101.0  77.0  82.0  76.0  88.0  104.0  90.0  92.0  86.0  100.0  88.0  119.0  107.0  106.0  99.0  91.0  107.0  78.0  93.0  99.0  112.0  87.0  0.1176706827309237   293 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.882329
2    0.939759
3    0.961847
4    0.96988
5    0.977912
6    0.983133
7    0.988755
8    0.991165
9    0.993574
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:02  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:03  1.740 sec   19974 obs/sec     1         1             10007      0.527464         0.91205             0.995055       0.259122                         0.527204           0.914525              0.995047         0.266265
    2019-08-04 09:00:06  4.364 sec   33026 obs/sec     10        10            100070     0.359983         0.425751            0.997697       0.122763                         0.361281           0.434013              0.997674         0.117671
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0850115
C13         0.969829               0.969829             0.0824466
C8          0.854174               0.854174             0.0726146
C9          0.846758               0.846758             0.0719841
C12         0.837319               0.837319             0.0711818
C7          0.822448               0.822448             0.0699175
C5          0.770915               0.770915             0.0655366
C11         0.752459               0.752459             0.0639677
C10         0.734927               0.734927             0.0624773
C6          0.657612               0.657612             0.0559045
C14         0.646241               0.646241             0.0549379
C16         0.637871               0.637871             0.0542264
C3          0.614108               0.614108             0.0522063
C4          0.595414               0.595414             0.050617
C1          0.512144               0.512144             0.0435381
C2          0.510895               0.510895             0.043432
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_233

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0024455156211047324  0.0007511239964514971  0.0         -0.006890718765500958  0.24763429164886475  -0.0016497344430614028  0.2619732618331909
    3        26       Softmax                 0.0   0.0   0.0032853385734002726  0.001536509022116661   0.0         0.006144635496434821   0.3470933437347412   -0.6046403400789178     0.10889071226119995


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12794440052806375
RMSE: 0.35769316533596746
LogLoss: 0.42774830638059147
Mean Per-Class Error: 0.12243680470711402
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
374.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    1.0    1.0    2.0    3.0    0.053164556962025315  21 / 395
0.0    345.0  4.0    5.0    2.0    0.0    2.0    14.0   2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0968586387434555    37 / 382
0.0    0.0    325.0  1.0    1.0    1.0    14.0   2.0    0.0    0.0    7.0    0.0    0.0    0.0    2.0    0.0    3.0    1.0    3.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    0.11684782608695653   43 / 368
1.0    16.0   0.0    350.0  0.0    0.0    0.0    14.0   2.0    3.0    0.0    0.0    6.0    2.0    1.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    1.0    0.1315136476426799    53 / 403
0.0    5.0    2.0    0.0    324.0  7.0    21.0   1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    5.0    1.0    0.0    0.0    3.0    0.0    8.0    0.15625               60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    2.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    355.0  0.0    0.0    0.0    0.05585106382978723   21 / 376
0.0    1.0    0.0    4.0    2.0    1.0    0.0    2.0    3.0    6.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    353.0  5.0    2.0    0.10406091370558376   41 / 394
0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    1.0    5.0    3.0    8.0    1.0    1.0    368.0  0.0    0.06361323155216285   25 / 393
1.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    4.0    4.0    0.0    0.0    0.0    0.0    0.0    339.0  0.07629427792915532   28 / 367
399.0  479.0  347.0  401.0  363.0  406.0  439.0  398.0  356.0  388.0  333.0  338.0  408.0  374.0  378.0  364.0  392.0  358.0  272.0  409.0  434.0  375.0  383.0  404.0  406.0  399.0  0.12166350094971509   1,217 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878336
2    0.938718
3    0.962511
4    0.973308
5    0.981006
6    0.986104
7    0.989103
8    0.991303
9    0.993302
10   0.994902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.12916657459291486
RMSE: 0.3593975161195676
LogLoss: 0.4349931213969348
Mean Per-Class Error: 0.11717756672507516
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6      7      8     9      10    11    12    13     14    15     16     17    18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  -----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   1.0   0.0    2.0    1.0   0.056179775280898875  5 / 89
0.0   91.0   1.0   2.0    2.0   0.0    1.0    4.0    1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.14150943396226415   15 / 106
0.0   0.0    75.0  0.0    0.0   0.0    1.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0    0.0   2.0   0.0   2.0    0.0   0.0   0.0    0.0    0.0   0.08536585365853659   7 / 82
1.0   2.0    0.0   97.0   0.0   0.0    0.0    6.0    1.0   1.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   1.0    0.0   0.0   1.0    0.0    0.0   0.13392857142857142   15 / 112
0.0   2.0    1.0   0.0    76.0  5.0    5.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0   1.0   3.0   0.0    0.0   0.0   1.0    0.0    2.0   0.21649484536082475   21 / 97
---   ---    ---   ---    ---   ---    ---    ---    ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   1.0    0.0   89.0  0.0    0.0    0.0   0.03260869565217391   3 / 92
0.0   0.0    0.0   2.0    1.0   0.0    0.0    1.0    0.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   89.0   1.0    1.0   0.11                  11 / 100
0.0   1.0    0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0    0.0   0.0   0.0   0.0    3.0   1.0   0.0    99.0   0.0   0.07476635514018691   8 / 107
1.0   0.0    0.0   0.0    1.0   0.0    0.0    0.0    0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0    81.0  0.06896551724137931   6 / 87
90.0  119.0  78.0  108.0  84.0  100.0  107.0  108.0  87.0  108.0  85.0  89.0  88.0  100.0  81.0  104.0  100.0  88.0  74.0  94.0  109.0  84.0  95.0  102.0  114.0  94.0  0.1176706827309237    293 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.882329
2    0.943373
3    0.965462
4    0.974297
5    0.979518
6    0.984337
7    0.988353
8    0.990763
9    0.993173
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:50  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:50  6 min 48.472 sec  23940 obs/sec     1         1             10007      0.512862         0.891222            0.995326       0.251824                         0.513972           0.894461              0.995293         0.260241
    2019-08-04 09:06:54  6 min 52.333 sec  23809 obs/sec     10        10            100070     0.357693         0.427748            0.997726       0.121664                         0.359398           0.434993              0.997698         0.117671
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0886234
C15         0.972079               0.972079             0.0861489
C9          0.88816                0.88816              0.0787117
C12         0.867959               0.867959             0.0769215
C8          0.857742               0.857742             0.0760161
C11         0.733601               0.733601             0.0650142
C10         0.720951               0.720951             0.0638931
C7          0.692213               0.692213             0.0613463
C6          0.650687               0.650687             0.0576661
C5          0.64924                0.64924              0.0575378
C16         0.642683               0.642683             0.0569568
C14         0.618328               0.618328             0.0547983
C3          0.566028               0.566028             0.0501633
C4          0.533291               0.533291             0.0472621
C2          0.44551                0.44551              0.0394826
C1          0.445231               0.445231             0.0394579
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_211

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018244050896640829  0.00044383597560226917  0.0         -0.009621696722887832  0.16956520080566406  0.1812732345702308   0.11370646953582764
    3        26       Softmax                      0.0   0.0   0.010528039571839214   0.04483678936958313     0.0         -0.20173429865937464   0.3975783586502075   -0.6441244445619516  0.14815938472747803


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13111647217713468
RMSE: 0.3621000858562929
LogLoss: 0.4269251542615166
Mean Per-Class Error: 0.1244642321915884
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    7.0    7.0    3.0    1.0    0.0    0.0    0.0    0.0    2.0    5.0    1.0    3.0    1.0    2.0    1.0    3.0    0.0    0.09620253164556962  38 / 395
0.0    348.0  0.0    6.0    2.0    1.0    1.0    4.0    2.0    0.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    6.0    7.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.09138381201044386  35 / 383
0.0    0.0    323.0  0.0    9.0    0.0    3.0    1.0    0.0    0.0    11.0   2.0    0.0    0.0    3.0    0.0    0.0    1.0    4.0    2.0    7.0    0.0    2.0    0.0    0.0    0.0    0.12228260869565218  45 / 368
0.0    14.0   0.0    358.0  0.0    0.0    0.0    0.0    0.0    5.0    2.0    0.0    7.0    4.0    2.0    2.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.11166253101736973  45 / 403
0.0    3.0    1.0    0.0    323.0  6.0    14.0   2.0    0.0    0.0    6.0    3.0    0.0    0.0    0.0    1.0    5.0    3.0    3.0    2.0    0.0    0.0    0.0    4.0    0.0    8.0    0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    3.0    0.0    0.0    3.0    2.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    4.0    3.0    1.0    1.0    1.0    2.0    4.0    7.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    359.0  2.0    3.0    0.08883248730964467  35 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    17.0   2.0    14.0   1.0    0.0    345.0  0.0    0.12213740458015267  48 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    19.0   1.0    0.0    0.0    0.0    1.0    0.0    320.0  0.12806539509536785  47 / 367
378.0  449.0  356.0  438.0  384.0  387.0  351.0  295.0  344.0  396.0  395.0  365.0  410.0  387.0  376.0  413.0  360.0  410.0  424.0  377.0  422.0  374.0  398.0  405.0  365.0  344.0  0.12386284114765571  1,239 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876137
2    0.939818
3    0.962411
4    0.973908
5    0.980806
6    0.987004
7    0.990603
8    0.993702
9    0.995401
10   0.996501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13323048457694325
RMSE: 0.36500751304177737
LogLoss: 0.4352481667440239
Mean Per-Class Error: 0.12581287246676492
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   1.0    0.0   1.0   0.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   92.0   0.0   1.0    1.0   1.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0   3.0    2.0    0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.1320754716981132   14 / 106
0.0   0.0    67.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    1.0   2.0    0.0   1.0   0.0    0.0    0.0   0.18292682926829268  15 / 82
0.0   1.0    0.0   100.0  0.0   0.0   0.0   0.0   0.0   2.0    1.0   0.0   3.0   1.0    0.0   1.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.10714285714285714  12 / 112
0.0   0.0    0.0   0.0    79.0  5.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0    0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   1.0    0.0   86.0  0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   1.0   1.0   0.0   0.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   88.0   0.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    5.0   0.0    5.0   1.0   0.0    92.0   0.0   0.14018691588785046  15 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0    0.0    77.0  0.11494252873563218  10 / 87
88.0  112.0  73.0  122.0  95.0  94.0  90.0  72.0  85.0  112.0  99.0  92.0  92.0  104.0  79.0  114.0  97.0  102.0  104.0  90.0  107.0  86.0  97.0  101.0  100.0  83.0  0.1248995983935743   311 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.8751
2    0.939759
3    0.961446
4    0.973896
5    0.980723
6    0.985944
7    0.988755
8    0.99237
9    0.995984
10   0.997189
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:12  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:12  6 min 10.376 sec  31174 obs/sec     1         1             10007      0.524609         0.911552            0.995111       0.250725                         0.525907           0.916397              0.995072         0.259036
    2019-08-04 09:06:15  6 min 12.873 sec  36309 obs/sec     10        10            100070     0.3621           0.426925            0.997671       0.123863                         0.365008           0.435248              0.997626         0.1249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.086225
C13         0.927016               0.927016             0.079932
C9          0.835423               0.835423             0.0720344
C8          0.816664               0.816664             0.0704169
C7          0.799727               0.799727             0.0689565
C12         0.781781               0.781781             0.0674091
C10         0.750808               0.750808             0.0647384
C5          0.729416               0.729416             0.0628939
C11         0.699637               0.699637             0.0603263
C6          0.695391               0.695391             0.0599601
C14         0.649022               0.649022             0.055962
C4          0.643371               0.643371             0.0554747
C16         0.629042               0.629042             0.0542392
C3          0.614943               0.614943             0.0530235
C2          0.5188                 0.5188               0.0447335
C1          0.506519               0.506519             0.0436746
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_193

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018428224872621968  0.0004628979368135333  0.0         -0.012029935198743402  0.16768187284469604  0.1762426626724244   0.11679992079734802
    3        26       Softmax                      0.0   0.0   0.011240713338600892   0.04863478243350983    0.0         -0.20139733621691008   0.39714694023132324  -0.6430271181366914  0.1745607852935791


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13335383364954936
RMSE: 0.36517644180525854
LogLoss: 0.43452699293190405
Mean Per-Class Error: 0.12712012478469956
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    4.0    3.0    3.0    0.0    2.0    0.0    0.0    1.0    5.0    2.0    1.0    2.0    2.0    2.0    3.0    0.0    0.08607594936708861  34 / 395
0.0    350.0  0.0    5.0    5.0    0.0    1.0    1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    9.0    6.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.08616187989556136  33 / 383
0.0    0.0    328.0  0.0    8.0    0.0    1.0    2.0    0.0    0.0    14.0   2.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    4.0    0.0    0.0    0.0    0.10869565217391304  40 / 368
0.0    15.0   0.0    358.0  0.0    1.0    1.0    1.0    0.0    3.0    1.0    0.0    7.0    5.0    2.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.11166253101736973  45 / 403
0.0    3.0    1.0    0.0    340.0  2.0    16.0   1.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    1.0    1.0    3.0    3.0    1.0    1.0    0.0    0.0    3.0    0.0    5.0    0.11458333333333333  44 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    5.0    2.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    1.0    0.0    3.0    4.0    0.0    0.0    1.0    2.0    5.0    8.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    360.0  3.0    2.0    0.08629441624365482  34 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    2.0    8.0    2.0    9.0    1.0    0.0    360.0  0.0    0.0792838874680307   31 / 391
1.0    0.0    0.0    0.0    23.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    18.0   2.0    0.0    0.0    0.0    2.0    0.0    306.0  0.16621253405994552  61 / 367
378.0  485.0  363.0  412.0  438.0  396.0  351.0  294.0  343.0  381.0  375.0  365.0  406.0  388.0  408.0  365.0  356.0  416.0  390.0  363.0  404.0  379.0  404.0  420.0  390.0  333.0  0.12646206138158553  1,265 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873538
2    0.938818
3    0.961911
4    0.971908
5    0.980406
6    0.985804
7    0.989903
8    0.992802
9    0.994002
10   0.996001

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1328815777216631
RMSE: 0.3645292549599594
LogLoss: 0.43714574063347966
Mean Per-Class Error: 0.12453962030091634
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   89.0   0.0   1.0    2.0    0.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   6.0    3.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.16037735849056603  17 / 106
0.0   0.0    72.0  0.0    2.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0   0.0    0.0   1.0    0.0    0.0    0.0   0.12195121951219512  10 / 82
0.0   1.0    0.0   102.0  0.0    1.0   0.0   1.0   0.0   1.0    0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0   0.08928571428571429  10 / 112
0.0   0.0    0.0   0.0    84.0   1.0   5.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0   0.0    0.0   0.0    1.0    0.0    2.0   0.13402061855670103  13 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0    0.0   0.0   0.0   0.0   1.0    2.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    91.0   1.0    0.0   0.09                 9 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   3.0   0.0    4.0   1.0    0.0    97.0   0.0   0.09345794392523364  10 / 107
1.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0    0.0    0.0    76.0  0.12643678160919541  11 / 87
88.0  123.0  78.0  116.0  105.0  94.0  93.0  69.0  84.0  108.0  93.0  94.0  89.0  99.0  89.0  102.0  93.0  105.0  96.0  83.0  101.0  87.0  101.0  104.0  111.0  85.0  0.12449799196787148  310 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875502
2    0.94257
3    0.961446
4    0.971486
5    0.979116
6    0.983936
7    0.988353
8    0.991165
9    0.993173
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:42  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:42  5 min 40.378 sec  32073 obs/sec     1         1             10007      0.531928         0.926466            0.994971       0.262121                         0.531731           0.919405              0.994962         0.266667
    2019-08-04 09:05:45  5 min 42.885 sec  36152 obs/sec     10        10            100070     0.365176         0.434527            0.99763        0.126462                         0.364529           0.437146              0.997632         0.124498
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0861458
C13         0.954114               0.954114             0.0821929
C9          0.843521               0.843521             0.0726658
C12         0.843286               0.843286             0.0726455
C8          0.814121               0.814121             0.0701331
C7          0.772434               0.772434             0.0665419
C11         0.755757               0.755757             0.0651053
C5          0.754745               0.754745             0.0650181
C10         0.708138               0.708138             0.0610031
C6          0.694681               0.694681             0.0598438
C14         0.621877               0.621877             0.0535721
C16         0.621656               0.621656             0.053553
C3          0.611046               0.611046             0.052639
C4          0.583951               0.583951             0.0503049
C1          0.517069               0.517069             0.0445433
C2          0.511835               0.511835             0.0440924
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_142

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018501417653311591  0.0004724066238850355  0.0         -0.011764891394005161  0.16944831609725952  0.18757277264334113  0.12381213903427124
    3        26       Softmax                      0.0   0.0   0.008806926819820897   0.02996404469013214    0.0         -0.20368514791645145   0.3959224224090576   -0.6519945512885504  0.147305428981781


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13092704103584624
RMSE: 0.3618384184077836
LogLoss: 0.4279178459413984
Mean Per-Class Error: 0.12404083164256743
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    8.0    4.0    2.0    4.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    1.0    1.0    2.0    4.0    0.0    0.08354430379746836  33 / 395
0.0    336.0  0.0    7.0    3.0    2.0    0.0    6.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    3.0    8.0    4.0    0.0    0.0    3.0    0.0    2.0    2.0    0.0    0.12041884816753927  46 / 382
0.0    0.0    329.0  0.0    7.0    0.0    2.0    1.0    0.0    0.0    10.0   4.0    1.0    0.0    4.0    0.0    1.0    1.0    2.0    1.0    3.0    0.0    2.0    0.0    0.0    0.0    0.10597826086956522  39 / 368
0.0    12.0   0.0    355.0  0.0    2.0    0.0    2.0    0.0    3.0    2.0    0.0    6.0    4.0    1.0    3.0    0.0    6.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    2.0    0.11910669975186104  48 / 403
0.0    2.0    3.0    0.0    319.0  6.0    19.0   0.0    0.0    0.0    3.0    7.0    0.0    0.0    0.0    1.0    1.0    3.0    4.0    4.0    0.0    0.0    0.0    5.0    0.0    7.0    0.16927083333333334  65 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    14.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    1.0    0.0    4.0    3.0    0.0    0.0    1.0    2.0    3.0    9.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    359.0  2.0    3.0    0.08883248730964467  35 / 394
0.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    4.0    1.0    9.0    1.0    0.0    363.0  0.0    0.07633587786259542  30 / 393
0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    15.0   1.0    0.0    0.0    0.0    0.0    0.0    322.0  0.1226158038147139   45 / 367
380.0  424.0  361.0  426.0  380.0  426.0  347.0  310.0  344.0  400.0  389.0  385.0  414.0  384.0  378.0  375.0  364.0  417.0  402.0  340.0  412.0  369.0  402.0  415.0  408.0  351.0  0.1235629311206638   1,236 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876437
2    0.939918
3    0.963311
4    0.974108
5    0.982205
6    0.988104
7    0.991803
8    0.993602
9    0.995401
10   0.996801

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13283956339569125
RMSE: 0.36447162220904283
LogLoss: 0.43827156641252624
Mean Per-Class Error: 0.11956059917779943
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   88.0   0.0   2.0    2.0   0.0    0.0   2.0   1.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    1.0   3.0    1.0   0.0   0.0    3.0   0.0   1.0    1.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    74.0  0.0    1.0   0.0    0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.0975609756097561   8 / 82
0.0   2.0    0.0   98.0   0.0   1.0    0.0   1.0   0.0   1.0    1.0    0.0   2.0   1.0   0.0   1.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.125                14 / 112
0.0   0.0    0.0   0.0    78.0  4.0    5.0   0.0   0.0   0.0    1.0    1.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   2.0   0.0    0.0   0.0   2.0    0.0    2.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    1.0   0.0    0.0   0.0   0.0   0.0    5.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   89.0   1.0    1.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   1.0   0.0    2.0   1.0   0.0    99.0   0.0   0.07476635514018691  8 / 107
0.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0   0.0   4.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0    77.0  0.11494252873563218  10 / 87
89.0  104.0  78.0  114.0  93.0  105.0  87.0  78.0  85.0  111.0  101.0  99.0  93.0  99.0  83.0  104.0  91.0  103.0  95.0  81.0  107.0  81.0  98.0  101.0  122.0  88.0  0.12008032128514057  299 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.87992
2    0.943373
3    0.962651
4    0.973092
5    0.981928
6    0.986747
7    0.991566
8    0.993173
9    0.994779
10   0.995582
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:53  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:53  3 min 51.146 sec  32702 obs/sec     1         1             10007      0.527666         0.913621            0.995052       0.252524                         0.527139           0.912268              0.995049         0.251406
    2019-08-04 09:03:55  3 min 53.637 sec  36455 obs/sec     10        10            100070     0.361838         0.427918            0.997673       0.123563                         0.364472           0.438272              0.997633         0.12008
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0864848
C13         0.948771               0.948771             0.0820543
C9          0.844966               0.844966             0.0730767
C8          0.843149               0.843149             0.0729196
C12         0.817874               0.817874             0.0707337
C7          0.768702               0.768702             0.066481
C10         0.721471               0.721471             0.0623962
C5          0.712244               0.712244             0.0615983
C6          0.711897               0.711897             0.0615682
C11         0.69631                0.69631              0.0602202
C14         0.626505               0.626505             0.0541832
C3          0.618157               0.618157             0.0534611
C16         0.614634               0.614634             0.0531564
C4          0.596806               0.596806             0.0516147
C1          0.528517               0.528517             0.0457087
C2          0.512728               0.512728             0.0443431
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_166

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.002575696824891338   0.0006592182908207178  0.0         -0.0074052093742444924  0.24761885404586792  -0.03749600729540262  0.2552293539047241
    3        26       Softmax                 0.0   0.0   0.0034960534314730186  0.0015116729773581028  0.0         0.006791428911016011    0.3534954786300659   -0.5796461477668711   0.11371368169784546


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12693240432141226
RMSE: 0.356275741977211
LogLoss: 0.42071874875379695
Mean Per-Class Error: 0.12173227691468601
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    2.0    2.0    6.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    1.0    0.0    3.0    4.0    0.0759493670886076   30 / 395
0.0    327.0  0.0    8.0    7.0    1.0    2.0    14.0   1.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    11.0   5.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    0.1462140992167102   56 / 383
0.0    0.0    335.0  1.0    2.0    0.0    2.0    1.0    0.0    0.0    12.0   1.0    0.0    0.0    4.0    0.0    0.0    1.0    1.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.08967391304347826  33 / 368
0.0    8.0    0.0    360.0  0.0    0.0    0.0    7.0    1.0    3.0    0.0    0.0    6.0    4.0    2.0    2.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    0.10669975186104218  43 / 403
0.0    1.0    2.0    0.0    333.0  5.0    10.0   2.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    1.0    3.0    3.0    4.0    2.0    1.0    0.0    0.0    3.0    0.0    9.0    0.1328125            51 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    22.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    346.0  0.0    0.0    0.0    0.07733333333333334  29 / 375
0.0    0.0    0.0    6.0    3.0    2.0    0.0    2.0    3.0    3.0    14.0   7.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    1.0    1.0    0.0    0.0    343.0  1.0    3.0    0.12944162436548223  51 / 394
0.0    0.0    0.0    2.0    0.0    3.0    0.0    4.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    12.0   0.0    9.0    1.0    1.0    355.0  0.0    0.09669211195928754  38 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    14.0   2.0    0.0    0.0    0.0    0.0    0.0    330.0  0.1008174386920981   37 / 367
374.0  405.0  370.0  428.0  405.0  407.0  326.0  377.0  351.0  384.0  392.0  382.0  448.0  370.0  365.0  374.0  386.0  393.0  367.0  396.0  400.0  355.0  405.0  391.0  375.0  377.0  0.12126362091372589  1,213 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878736
2    0.941717
3    0.963711
4    0.974308
5    0.980406
6    0.986704
7    0.990803
8    0.991703
9    0.993602
10   0.994902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1312231762029715
RMSE: 0.36224739640606324
LogLoss: 0.43902965944744293
Mean Per-Class Error: 0.12491521995565708
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15     16     17    18    19    20    21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0449438202247191   4 / 89
0.0   85.0   0.0   2.0    3.0   0.0   1.0   6.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0    4.0   2.0   0.0   0.0   0.0   0.0   1.0   0.0    1.0   0.19811320754716982  21 / 106
0.0   0.0    76.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0   3.0   0.0    0.0    0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.07317073170731707  6 / 82
0.0   1.0    0.0   98.0   0.0   0.0   0.0   2.0   1.0   0.0    0.0   0.0    3.0   1.0   0.0   2.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    2.0   0.125                14 / 112
0.0   0.0    0.0   0.0    81.0  4.0   3.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0    1.0   2.0   1.0   0.0   0.0   0.0   1.0   0.0    2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---    ---   ---                  ---
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    2.0   1.0   0.0   1.0   0.0   1.0    6.0   3.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   82.0  0.0    1.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   1.0    1.0    0.0   0.0   4.0   0.0   2.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0    78.0  0.10344827586206896  9 / 87
89.0  100.0  82.0  116.0  99.0  95.0  82.0  99.0  84.0  112.0  99.0  100.0  99.0  99.0  79.0  106.0  100.0  99.0  91.0  99.0  99.0  78.0  98.0  93.0  104.0  89.0  0.12530120481927712  312 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.874699
2    0.939357
3    0.958635
4    0.971084
5    0.977912
6    0.985542
7    0.990763
8    0.990763
9    0.991566
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:42  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:43  4 min 40.968 sec  23435 obs/sec     1         1             10007      0.517067         0.916939            0.995249       0.245726                         0.517353           0.92069               0.995231         0.251807
    2019-08-04 09:04:47  4 min 44.929 sec  23137 obs/sec     10        10            100070     0.356276         0.420719            0.997744       0.121264                         0.362247           0.43903               0.997662         0.125301
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0858306
C15         0.968526               0.968526             0.0831292
C9          0.91808                0.91808              0.0787994
C8          0.868981               0.868981             0.0745852
C12         0.867538               0.867538             0.0744613
C10         0.782911               0.782911             0.0671977
C11         0.768198               0.768198             0.0659349
C7          0.7565                 0.7565               0.0649309
C16         0.708955               0.708955             0.06085
C5          0.707735               0.707735             0.0607453
C6          0.653527               0.653527             0.0560926
C14         0.648669               0.648669             0.0556756
C3          0.553642               0.553642             0.0475195
C4          0.516828               0.516828             0.0443596
C1          0.488328               0.488328             0.0419135
C2          0.442434               0.442434             0.0379744
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_223

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.002558582022643918   0.0007707520853728056  0.0         0.0015292305917018467  0.24682432413101196  -0.02567349504898216  0.2628101110458374
    3        26       Softmax                 0.0   0.0   0.0038704059046407425  0.002381223253905773   0.0         0.01417715255231236    0.3468911647796631   -0.6052756781391605   0.11971661448478699


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1276036823724825
RMSE: 0.3572165762845875
LogLoss: 0.430403370339917
Mean Per-Class Error: 0.12409861507096163
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
370.0  0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    1.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    1.0    0.0    0.0    1.0    3.0    4.0    0.06329113924050633  25 / 395
0.0    330.0  0.0    8.0    8.0    0.0    1.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    17.0   4.0    0.0    0.0    1.0    0.0    3.0    0.0    4.0    0.13838120104438642  53 / 383
0.0    0.0    321.0  1.0    9.0    0.0    15.0   1.0    0.0    0.0    9.0    2.0    0.0    0.0    4.0    0.0    2.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.12771739130434784  47 / 368
0.0    8.0    0.0    365.0  0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    5.0    4.0    1.0    0.0    0.0    8.0    1.0    0.0    2.0    0.0    0.0    3.0    0.0    4.0    0.09429280397022333  38 / 403
0.0    5.0    1.0    0.0    330.0  5.0    9.0    0.0    1.0    0.0    1.0    4.0    0.0    0.0    0.0    1.0    5.0    3.0    7.0    2.0    1.0    0.0    0.0    4.0    0.0    4.0    0.13838120104438642  53 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    6.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    21.0   0.0    5.0    0.0    0.0    0.0    0.0    0.0    5.0    6.0    330.0  0.0    0.0    0.0    0.12234042553191489  46 / 376
0.0    1.0    0.0    4.0    6.0    0.0    0.0    1.0    1.0    1.0    4.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    2.0    1.0    0.0    0.0    359.0  2.0    5.0    0.08883248730964467  35 / 394
1.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    1.0    6.0    1.0    1.0    1.0    1.0    371.0  1.0    0.05597964376590331  22 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    8.0    3.0    0.0    0.0    0.0    0.0    0.0    341.0  0.07084468664850137  26 / 367
401.0  454.0  343.0  443.0  429.0  350.0  359.0  304.0  325.0  367.0  335.0  369.0  432.0  377.0  369.0  418.0  402.0  427.0  351.0  391.0  415.0  350.0  345.0  425.0  414.0  408.0  0.1231630510846746   1,232 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876837
2    0.936119
3    0.962111
4    0.972308
5    0.981206
6    0.985704
7    0.988603
8    0.991103
9    0.992702
10   0.994702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1294575801546243
RMSE: 0.35980214028633056
LogLoss: 0.43985315043595086
Mean Per-Class Error: 0.12304374688106373
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0    2.0    1.0   0.06741573033707865  6 / 89
0.0   86.0   0.0   5.0    2.0   0.0   1.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    5.0    2.0   0.0   0.0    1.0   0.0   1.0    0.0    1.0   0.18867924528301888  20 / 106
0.0   0.0    74.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    3.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0975609756097561   8 / 82
0.0   1.0    0.0   103.0  0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   2.0   1.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.08035714285714286  9 / 112
0.0   0.0    0.0   0.0    79.0  4.0   3.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    2.0    1.0    4.0   0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   2.0    2.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   91.0   0.0    3.0   0.09                 9 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0    0.0    0.0   1.0   0.0    1.0   1.0   0.0    100.0  0.0   0.06542056074766354  7 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   1.0   0.0    0.0   0.0   0.0    0.0    80.0  0.08045977011494253  7 / 87
93.0  116.0  76.0  122.0  97.0  83.0  92.0  76.0  74.0  113.0  84.0  96.0  92.0  101.0  81.0  121.0  101.0  108.0  90.0  89.0  108.0  75.0  87.0  105.0  114.0  96.0  0.1216867469879518   303 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878313
2    0.939759
3    0.960241
4    0.970683
5    0.981526
6    0.986747
7    0.988755
8    0.991566
9    0.992771
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:31  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:32  6 min 29.917 sec  22951 obs/sec     1         1             10007      0.523731         0.918945            0.995126       0.248326                         0.522414           0.916837              0.995137         0.253815
    2019-08-04 09:06:36  6 min 33.922 sec  22899 obs/sec     10        10            100070     0.357217         0.430403            0.997733       0.123163                         0.359802           0.439853              0.997693         0.121687
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0868281
C13         0.97577                0.97577              0.0847243
C12         0.880301               0.880301             0.0764349
C9          0.877871               0.877871             0.0762239
C8          0.849588               0.849588             0.0737681
C7          0.782699               0.782699             0.0679603
C10         0.779668               0.779668             0.0676971
C11         0.736458               0.736458             0.0639453
C5          0.671131               0.671131             0.058273
C6          0.659846               0.659846             0.0572932
C14         0.658106               0.658106             0.0571421
C16         0.631468               0.631468             0.0548292
C3          0.572627               0.572627             0.0497201
C2          0.486501               0.486501             0.042242
C4          0.480768               0.480768             0.0417441
C1          0.474202               0.474202             0.0411741
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_27

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.00137429326076699   0.00036980502773076296  0.0         -0.009371987503595136  0.20600497722625732  0.22803453045346206  0.15645891427993774
    3        26       Softmax                      0.0   0.0   0.008728735694778432  0.04499344527721405     0.0         -0.2637820880595602    0.5126042366027832   -0.5010097993698117  0.1866510510444641


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13135005520898033
RMSE: 0.3624224816550159
LogLoss: 0.4350742786231737
Mean Per-Class Error: 0.12314853535127332
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
369.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    2.0    3.0    4.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    1.0    5.0    1.0    0.0    4.0    0.0    0.06582278481012659  26 / 395
0.0    352.0  0.0    0.0    2.0    0.0    1.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    7.0    6.0    1.0    0.0    2.0    0.0    2.0    1.0    0.0    0.08093994778067885  31 / 383
0.0    0.0    316.0  0.0    11.0   0.0    13.0   0.0    0.0    0.0    8.0    2.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    4.0    6.0    0.0    3.0    0.0    0.0    0.0    0.13896457765667575  51 / 367
1.0    27.0   0.0    344.0  0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    7.0    3.0    4.0    0.0    0.0    2.0    1.0    1.0    2.0    0.0    0.0    4.0    0.0    1.0    0.14640198511166252  59 / 403
0.0    1.0    1.0    0.0    331.0  3.0    11.0   1.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    1.0    8.0    3.0    2.0    3.0    0.0    0.0    0.0    3.0    0.0    10.0   0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    8.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    11.0   1.0    4.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    1.0    0.0    4.0    3.0    0.0    0.0    1.0    2.0    4.0    9.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    354.0  2.0    4.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    6.0    1.0    10.0   1.0    0.0    367.0  0.0    0.06615776081424936  26 / 393
2.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    5.0    2.0    0.0    0.0    0.0    1.0    0.0    335.0  0.08469945355191257  31 / 366
396.0  501.0  333.0  389.0  409.0  365.0  404.0  327.0  344.0  387.0  328.0  366.0  408.0  378.0  421.0  373.0  381.0  398.0  332.0  394.0  415.0  379.0  389.0  403.0  404.0  379.0  0.1226632010396881   1,227 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877337
2    0.938418
3    0.961511
4    0.972508
5    0.980706
6    0.986504
7    0.990103
8    0.992502
9    0.994102
10   0.995401

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1325939109143447
RMSE: 0.36413446817672274
LogLoss: 0.4422159351326902
Mean Per-Class Error: 0.11960402889707891
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17    18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    2.0   0.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   92.0   0.0   0.0    1.0   0.0   1.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   4.0   2.0   0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.1320754716981132   14 / 106
0.0   0.0    71.0  0.0    1.0   0.0   3.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   0.0   2.0   0.0    0.0   1.0   0.0   0.0    0.0   0.13414634146341464  11 / 82
1.0   4.0    0.0   97.0   0.0   0.0   0.0    1.0   0.0   1.0    0.0   0.0   3.0   1.0    1.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   1.0   0.0    1.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    82.0  2.0   3.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    3.0   1.0   1.0   1.0   0.0    0.0   0.0   1.0   0.0    2.0   0.15463917525773196  15 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0    1.0   0.0   1.0    2.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   88.0  0.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   0.0    4.0   1.0   0.0   100.0  0.0   0.06542056074766354  7 / 107
2.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    79.0  0.09195402298850575  8 / 87
92.0  127.0  75.0  107.0  99.0  83.0  103.0  80.0  83.0  111.0  81.0  95.0  90.0  100.0  94.0  104.0  98.0  99.0  88.0  89.0  105.0  89.0  95.0  99.0  115.0  89.0  0.11967871485943775  298 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.880321
2    0.942972
3    0.961044
4    0.971486
5    0.980723
6    0.984739
7    0.988755
8    0.991165
9    0.993574
10   0.995582
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:54  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:54  52.083 sec  49053 obs/sec     1         1             10007      0.52353          0.893663            0.995128       0.236629                         0.525543           0.895886              0.995079         0.245783
    2019-08-04 09:00:55  53.618 sec  58588 obs/sec     10        10            100070     0.362422         0.435074            0.997665       0.122663                         0.364134           0.442216              0.997637         0.119679
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.079833
C15         0.98713                0.98713              0.0788056
C8          0.957107               0.957107             0.0764087
C9          0.947428               0.947428             0.075636
C12         0.935078               0.935078             0.0746501
C7          0.875851               0.875851             0.0699218
C5          0.794976               0.794976             0.0634653
C11         0.786399               0.786399             0.0627806
C10         0.759815               0.759815             0.0606583
C6          0.70978                0.70978              0.0566639
C14         0.694282               0.694282             0.0554266
C4          0.672748               0.672748             0.0537075
C16         0.659236               0.659236             0.0526288
C3          0.618361               0.618361             0.0493656
C1          0.579899               0.579899             0.0462951
C2          0.548054               0.548054             0.0437528
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_97

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0017900238825490078  0.00044154690112918615  0.0         -0.009717666676389375  0.1683775782585144   0.18428194357600464  0.1158817708492279
    3        26       Softmax                      0.0   0.0   0.010155218014714452   0.04425355792045593     0.0         -0.20558768033429523   0.39797675609588623  -0.6373357724616397  0.19629323482513428


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13208752462083306
RMSE: 0.3634384743265813
LogLoss: 0.42930570936007306
Mean Per-Class Error: 0.1234102720707523
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    4.0    3.0    1.0    5.0    0.0    2.0    0.0    0.0    1.0    3.0    1.0    1.0    1.0    2.0    1.0    5.0    3.0    0.08883248730964467   35 / 394
0.0    351.0  0.0    6.0    3.0    3.0    1.0    4.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    2.0    2.0    1.0    0.0    0.0    3.0    0.0    1.0    1.0    0.0    0.0835509138381201    32 / 383
0.0    0.0    320.0  1.0    14.0   0.0    10.0   0.0    0.0    0.0    10.0   1.0    1.0    0.0    5.0    0.0    0.0    1.0    1.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.13043478260869565   48 / 368
1.0    19.0   0.0    345.0  0.0    1.0    1.0    5.0    0.0    7.0    0.0    1.0    7.0    6.0    2.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.14392059553349876   58 / 403
0.0    6.0    7.0    0.0    319.0  6.0    19.0   0.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    3.0    2.0    2.0    3.0    0.0    0.0    0.0    3.0    0.0    10.0   0.16927083333333334   65 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    17.0   0.0    4.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851   33 / 376
0.0    1.0    0.0    4.0    2.0    0.0    0.0    2.0    2.0    4.0    12.0   1.0    0.0    0.0    2.0    0.0    5.0    0.0    2.0    3.0    1.0    0.0    0.0    347.0  3.0    3.0    0.11928934010152284   47 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    1.0    3.0    2.0    7.0    1.0    0.0    370.0  0.0    0.058524173027989825  23 / 393
1.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    6.0    2.0    0.0    0.0    0.0    1.0    0.0    342.0  0.0681198910081744    25 / 367
377.0  469.0  353.0  397.0  374.0  378.0  400.0  327.0  335.0  378.0  376.0  359.0  435.0  388.0  426.0  385.0  405.0  369.0  336.0  374.0  401.0  375.0  369.0  397.0  424.0  396.0  0.12296311106668      1,230 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877037
2    0.940618
3    0.963911
4    0.974108
5    0.981006
6    0.986404
7    0.990203
8    0.992802
9    0.995101
10   0.996301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1357795862736806
RMSE: 0.3684828167956826
LogLoss: 0.4425308965803657
Mean Per-Class Error: 0.1253316441245632
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17    18    19    20     21    22    23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  ----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0   1.0   0.0   0.0    0.0   1.0   0.0    3.0    0.0    0.0898876404494382   8 / 89
0.0   90.0   0.0   1.0    2.0   1.0   1.0   1.0   1.0   0.0    1.0   0.0   0.0   0.0    1.0   0.0    1.0    2.0   0.0   0.0   0.0    2.0   0.0   1.0    1.0    0.0    0.1509433962264151   16 / 106
0.0   0.0    72.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0    0.12195121951219512  10 / 82
1.0   1.0    0.0   98.0   0.0   1.0   0.0   2.0   0.0   2.0    0.0   0.0   3.0   1.0    1.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0    0.125                14 / 112
0.0   0.0    1.0   0.0    79.0  3.0   6.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   2.0   1.0   0.0    0.0   0.0   1.0    0.0    3.0    0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---   ---    ---    ---    ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   1.0    0.0   86.0  0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   1.0   0.0   1.0    6.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0    0.0   0.0   86.0   1.0    1.0    0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0    0.0   0.0   1.0   0.0    3.0   1.0   0.0    99.0   0.0    0.07476635514018691  8 / 107
1.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0    0.0   0.0   1.0    0.0    82.0   0.05747126436781609  5 / 87
87.0  112.0  78.0  114.0  91.0  87.0  98.0  82.0  79.0  107.0  97.0  94.0  98.0  101.0  90.0  112.0  104.0  92.0  82.0  84.0  102.0  85.0  92.0  100.0  122.0  100.0  0.1248995983935743   311 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.8751
2    0.943373
3    0.963454
4    0.972289
5    0.980321
6    0.98514
7    0.989558
8    0.992369
9    0.994779
10   0.996385
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:42  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:43  2 min 40.880 sec  29260 obs/sec     1         1             10007      0.524569         0.912597            0.99511        0.247726                         0.524467           0.912782              0.995099         0.253012
    2019-08-04 09:02:45  2 min 43.307 sec  36790 obs/sec     10        10            100070     0.363438         0.429306            0.997653       0.122963                         0.368483           0.442531              0.997581         0.1249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0829157
C13         0.972382               0.972382             0.0806257
C8          0.878671               0.878671             0.0728557
C7          0.873991               0.873991             0.0724676
C9          0.858853               0.858853             0.0712124
C11         0.848457               0.848457             0.0703504
C12         0.847547               0.847547             0.070275
C5          0.734935               0.734935             0.0609377
C10         0.733023               0.733023             0.0607791
C6          0.687878               0.687878             0.0570359
C14         0.683976               0.683976             0.0567123
C3          0.638024               0.638024             0.0529022
C16         0.624984               0.624984             0.051821
C4          0.623048               0.623048             0.0516605
C1          0.540297               0.540297             0.0447991
C2          0.514375               0.514375             0.0426497
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_49

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.001875568958354279  0.00047790328972041607  0.0         -0.008507718353017779  0.16840559244155884  0.17444575817549754  0.12056273221969604
    3        26       Softmax                      0.0   0.0   0.01046083019674335   0.034980177879333496    0.0         -0.19416082030717177   0.4005168676376343   -0.6488490997292456  0.19494497776031494


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13154942452579813
RMSE: 0.36269742834185925
LogLoss: 0.4293986785019321
Mean Per-Class Error: 0.12541870805947555
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    2.0    2.0    0.0    0.0    0.0    0.0    2.0    3.0    2.0    3.0    1.0    2.0    0.0    4.0    1.0    0.0759493670886076   30 / 395
0.0    348.0  0.0    6.0    3.0    0.0    0.0    10.0   1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    4.0    4.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.09138381201044386  35 / 383
0.0    0.0    324.0  0.0    7.0    0.0    1.0    1.0    0.0    0.0    18.0   1.0    0.0    0.0    3.0    0.0    0.0    0.0    6.0    2.0    4.0    0.0    1.0    0.0    0.0    0.0    0.11956521739130435  44 / 368
0.0    11.0   0.0    358.0  0.0    0.0    0.0    3.0    1.0    1.0    2.0    0.0    7.0    4.0    2.0    0.0    0.0    7.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    0.11166253101736973  45 / 403
0.0    5.0    2.0    0.0    332.0  3.0    13.0   1.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    1.0    4.0    3.0    5.0    2.0    0.0    0.0    0.0    1.0    0.0    6.0    0.13541666666666666  52 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    0.0    0.0    0.0    16.0   1.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    1.0    0.0    4.0    5.0    0.0    0.0    2.0    2.0    1.0    10.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    4.0    2.0    1.0    0.0    0.0    354.0  2.0    3.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    11.0   2.0    22.0   1.0    0.0    342.0  0.0    0.1297709923664122   51 / 393
2.0    0.0    0.0    0.0    17.0   0.0    0.0    1.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    22.0   2.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
384.0  441.0  368.0  424.0  402.0  391.0  333.0  373.0  348.0  368.0  406.0  366.0  422.0  385.0  396.0  381.0  375.0  389.0  413.0  394.0  402.0  384.0  373.0  384.0  362.0  339.0  0.12476257122863141  1,248 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875237
2    0.937819
3    0.962911
4    0.973708
5    0.981406
6    0.987204
7    0.990603
8    0.992602
9    0.994202
10   0.996001

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13482057443907444
RMSE: 0.36717921297245903
LogLoss: 0.4430326500924669
Mean Per-Class Error: 0.12532163660351772
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13    14    15     16    17    18     19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0   0.0    0.0   1.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   90.0   0.0   2.0    2.0    0.0   0.0   4.0   0.0   0.0    1.0    0.0   0.0   0.0   1.0   0.0    0.0   1.0   1.0    0.0   0.0    2.0   0.0   1.0   1.0    0.0   0.1509433962264151    16 / 106
0.0   0.0    71.0  0.0    1.0    0.0   0.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0   3.0    1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.13414634146341464   11 / 82
0.0   1.0    0.0   101.0  0.0    0.0   0.0   1.0   1.0   0.0    1.0    0.0   3.0   1.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.09821428571428571   11 / 112
0.0   0.0    0.0   0.0    85.0   2.0   4.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   1.0   3.0    0.0   0.0    0.0   0.0   0.0   0.0    1.0   0.12371134020618557   12 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0    0.0    0.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914   7 / 92
0.0   0.0    0.0   2.0    2.0    0.0   0.0   1.0   0.0   0.0    6.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   86.0  0.0    1.0   0.14                  14 / 100
0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    1.0   0.0   0.0    3.0   0.0    8.0   1.0   0.0   91.0   0.0   0.14953271028037382   16 / 107
2.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   2.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0   0.0    75.0  0.13793103448275862   12 / 87
94.0  105.0  78.0  120.0  100.0  95.0  88.0  92.0  86.0  103.0  104.0  95.0  97.0  98.0  85.0  106.0  98.0  96.0  102.0  92.0  100.0  89.0  93.0  90.0  101.0  83.0  0.12570281124497992   313 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.874297
2    0.938153
3    0.962249
4    0.972289
5    0.979518
6    0.985542
7    0.990361
8    0.991968
9    0.993976
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:27  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:28  1 min 25.946 sec  30051 obs/sec     1         1             10007      0.523845         0.914781            0.995124       0.249225                         0.525809           0.918818              0.995074         0.258635
    2019-08-04 09:01:30  1 min 28.468 sec  35790 obs/sec     10        10            100070     0.362697         0.429399            0.997662       0.124763                         0.367179           0.443033              0.997598         0.125703
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0869735
C13         0.915266               0.915266             0.0796039
C8          0.824583               0.824583             0.0717169
C9          0.812759               0.812759             0.0706885
C12         0.803991               0.803991             0.0699259
C7          0.786228               0.786228             0.068381
C5          0.74374                0.74374              0.0646857
C10         0.73337                0.73337              0.0637838
C11         0.711413               0.711413             0.0618741
C14         0.666646               0.666646             0.0579805
C6          0.664155               0.664155             0.0577639
C4          0.618486               0.618486             0.0537919
C16         0.607249               0.607249             0.0528146
C3          0.599385               0.599385             0.0521306
C1          0.50668                0.50668              0.0440678
C2          0.503801               0.503801             0.0438174
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_129

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias           bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  ------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.00184774232407392   0.000457450863905251  0.0         -0.009903048957854654  0.16452372074127197  0.1915194828222331  0.11780470609664917
    3        26       Softmax                      0.0   0.0   0.010013095195622905  0.04712049663066864   0.0         -0.19962589459743404   0.39635276794433594  -0.628786965821821  0.16573619842529297


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13379081784400643
RMSE: 0.36577427170866794
LogLoss: 0.43730448857491844
Mean Per-Class Error: 0.12516856982181598
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    2.0    1.0    4.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    1.0    3.0    1.0    0.0    4.0    1.0    0.07088607594936709  28 / 395
0.0    348.0  0.0    5.0    3.0    0.0    1.0    9.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    3.0    2.0    0.0    0.0    4.0    0.0    2.0    1.0    0.0    0.09138381201044386  35 / 383
0.0    0.0    307.0  0.0    10.0   0.0    10.0   1.0    0.0    0.0    16.0   4.0    1.0    0.0    5.0    0.0    2.0    0.0    0.0    6.0    4.0    0.0    2.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
0.0    24.0   0.0    351.0  0.0    0.0    0.0    4.0    0.0    4.0    2.0    0.0    7.0    5.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.12903225806451613  52 / 403
0.0    4.0    1.0    0.0    320.0  5.0    20.0   1.0    0.0    0.0    2.0    4.0    0.0    0.0    0.0    1.0    3.0    2.0    1.0    7.0    0.0    0.0    0.0    3.0    0.0    9.0    0.16449086161879894  63 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    16.0   1.0    2.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    1.0    0.0    4.0    3.0    1.0    0.0    3.0    3.0    4.0    7.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    6.0    1.0    0.0    0.0    350.0  3.0    4.0    0.1116751269035533   44 / 394
0.0    0.0    0.0    1.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    2.0    1.0    1.0    7.0    1.0    0.0    373.0  0.0    0.04846938775510204  19 / 392
1.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    11.0   3.0    0.0    0.0    0.0    0.0    0.0    332.0  0.09536784741144415  35 / 367
390.0  479.0  322.0  405.0  374.0  382.0  399.0  355.0  342.0  389.0  382.0  372.0  429.0  387.0  373.0  370.0  391.0  377.0  343.0  392.0  399.0  381.0  380.0  388.0  423.0  379.0  0.12446266120163951  1,245 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875537
2    0.940618
3    0.962311
4    0.973608
5    0.981106
6    0.985904
7    0.989403
8    0.992302
9    0.994702
10   0.996401

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13484528307490806
RMSE: 0.3672128579923476
LogLoss: 0.443228845893888
Mean Per-Class Error: 0.12244728677278156
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17    18    19    20    21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  --------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   2.0    0.0   0.0449438202247191    4 / 89
0.0   89.0   0.0   1.0    2.0   0.0   0.0   5.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0   2.0   0.0   0.0   0.0   3.0   0.0   1.0   1.0    0.0   0.16037735849056603   17 / 106
0.0   0.0    67.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0    3.0   0.0    1.0   0.0   0.0   2.0   0.0   0.0   1.0   0.0   0.0    0.0   0.18292682926829268   15 / 82
0.0   3.0    0.0   99.0   0.0   0.0   0.0   2.0   0.0   2.0    1.0   0.0   3.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.11607142857142858   13 / 112
0.0   0.0    0.0   0.0    81.0  3.0   6.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   2.0   0.0   0.0   0.0   1.0   0.0    2.0   0.16494845360824742   16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   87.0  0.0   0.0    0.0   0.05434782608695652   5 / 92
0.0   0.0    0.0   2.0    1.0   1.0   0.0   2.0   0.0   1.0    4.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   86.0  0.0    1.0   0.14                  14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   104.0  0.0   0.028037383177570093  3 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0    78.0  0.10344827586206896   9 / 87
92.0  111.0  71.0  112.0  93.0  90.0  98.0  87.0  84.0  112.0  96.0  96.0  97.0  101.0  84.0  107.0  97.0  94.0  83.0  93.0  99.0  86.0  95.0  96.0  125.0  91.0  0.1216867469879518    303 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878313
2    0.940964
3    0.960241
4    0.972289
5    0.980321
6    0.984739
7    0.990361
8    0.991968
9    0.995181
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:37  3 min 35.414 sec  31174 obs/sec     1         1             10007      0.531613         0.927711            0.994977       0.260522                         0.530661           0.927487              0.994982         0.263052
    2019-08-04 09:03:40  3 min 38.007 sec  34940 obs/sec     10        10            100070     0.365774         0.437304            0.997622       0.124463                         0.367213           0.443229              0.997597         0.121687
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0826602
C15         0.996448               0.996448             0.0823666
C9          0.909724               0.909724             0.075198
C8          0.893739               0.893739             0.0738767
C12         0.837012               0.837012             0.0691875
C7          0.810779               0.810779             0.0670192
C5          0.760365               0.760365             0.0628519
C10         0.752295               0.752295             0.0621849
C11         0.74041                0.74041              0.0612024
C6          0.683073               0.683073             0.0564629
C4          0.664191               0.664191             0.0549022
C14         0.651669               0.651669             0.0538671
C16         0.645094               0.645094             0.0533236
C3          0.640843               0.640843             0.0529722
C1          0.571521               0.571521             0.047242
C2          0.54056                0.54056              0.0446828
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_172

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.002523999611241834  0.0006889842916280031  0.0         0.0043949855214115985  0.2471640706062317  -0.02689525270844099  0.25921809673309326
    3        26       Softmax                 0.0   0.0   0.003702822332343203  0.001803695224225521   0.0         0.0074090460738996345  0.3540147542953491  -0.5971411741346624   0.11360356211662292


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12910877006500188
RMSE: 0.3593170884678349
LogLoss: 0.42649004049150213
Mean Per-Class Error: 0.1272541749497959
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
376.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    4.0    0.04810126582278481  19 / 395
0.0    326.0  1.0    7.0    3.0    3.0    1.0    9.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    2.0    8.0    14.0   0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    325.0  1.0    3.0    1.0    4.0    1.0    0.0    0.0    11.0   4.0    0.0    0.0    5.0    0.0    2.0    1.0    2.0    2.0    4.0    1.0    1.0    0.0    0.0    0.0    0.11684782608695653  43 / 368
0.0    10.0   0.0    366.0  0.0    0.0    0.0    2.0    1.0    1.0    0.0    0.0    5.0    4.0    1.0    0.0    0.0    4.0    1.0    0.0    2.0    0.0    0.0    3.0    0.0    3.0    0.09181141439205956  37 / 403
0.0    0.0    6.0    0.0    320.0  5.0    6.0    1.0    0.0    0.0    5.0    7.0    0.0    0.0    0.0    1.0    7.0    3.0    7.0    7.0    0.0    0.0    0.0    3.0    0.0    6.0    0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    4.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    12.0   0.0    4.0    2.0    0.0    0.0    0.0    0.0    5.0    2.0    343.0  0.0    0.0    0.0    0.08533333333333333  32 / 375
0.0    0.0    0.0    6.0    5.0    2.0    0.0    2.0    5.0    3.0    10.0   5.0    0.0    0.0    2.0    1.0    0.0    1.0    3.0    0.0    1.0    0.0    0.0    342.0  4.0    2.0    0.1319796954314721   52 / 394
0.0    1.0    0.0    2.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    6.0    2.0    16.0   0.0    1.0    351.0  0.0    0.10687022900763359  42 / 393
2.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    20.0   2.0    0.0    0.0    0.0    0.0    0.0    323.0  0.11989100817438691  44 / 367
409.0  450.0  359.0  440.0  394.0  433.0  306.0  331.0  347.0  370.0  379.0  401.0  403.0  385.0  407.0  391.0  364.0  370.0  393.0  372.0  410.0  388.0  374.0  389.0  383.0  355.0  0.12666200139958012  1,267 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873338
2    0.937219
3    0.963311
4    0.975108
5    0.981706
6    0.987904
7    0.990803
8    0.993402
9    0.995101
10   0.996201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13285220458402777
RMSE: 0.36448896359701727
LogLoss: 0.44334054632345943
Mean Per-Class Error: 0.12848140382085202
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11     12    13     14    15     16    17    18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.0449438202247191   4 / 89
0.0   85.0   0.0   4.0    2.0   0.0    1.0   4.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0    0.0   4.0   4.0    0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    72.0  0.0    0.0   1.0    0.0   0.0   0.0   0.0    2.0    1.0    0.0   0.0    3.0   0.0    0.0   0.0   2.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.12195121951219512  10 / 82
0.0   2.0    0.0   102.0  0.0   0.0    0.0   1.0   0.0   0.0    0.0    0.0    2.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   2.0   0.0    1.0   0.08928571428571429  10 / 112
0.0   0.0    1.0   0.0    75.0  4.0    1.0   0.0   0.0   0.0    2.0    3.0    0.0   0.0    0.0   0.0    1.0   1.0   4.0    4.0   0.0    0.0   0.0   0.0   0.0    1.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
1.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   2.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    3.0   0.0    0.0   0.0   0.0   1.0    7.0    2.0    0.0   0.0    0.0   0.0    0.0   1.0   1.0    0.0   0.0    0.0   0.0   81.0  0.0    1.0   0.19                 19 / 100
0.0   1.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    1.0   0.0    5.0   0.0   0.0   94.0   0.0   0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0   0.0   1.0    0.0    1.0    0.0   0.0    0.0   0.0    0.0   0.0   4.0    0.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218  10 / 87
93.0  116.0  76.0  122.0  92.0  105.0  77.0  86.0  84.0  106.0  100.0  106.0  86.0  100.0  85.0  107.0  93.0  93.0  101.0  90.0  105.0  89.0  93.0  91.0  108.0  86.0  0.12931726907630522  322 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.870683
2    0.935743
3    0.960643
4    0.971888
5    0.979116
6    0.987149
7    0.990361
8    0.993173
9    0.994779
10   0.996787
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:03  5 min  1.192 sec  22041 obs/sec     1         1             10007      0.518115         0.905407            0.99523        0.246126                         0.516293           0.904484              0.99525          0.248594
    2019-08-04 09:05:07  5 min  5.143 sec  23036 obs/sec     10        10            100070     0.359317         0.42649             0.997706       0.126662                         0.364489           0.443341              0.997633         0.129317
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0882921
C15         0.973191               0.973191             0.085925
C9          0.868806               0.868806             0.0767087
C8          0.821722               0.821722             0.0725515
C12         0.820915               0.820915             0.0724803
C10         0.785432               0.785432             0.0693474
C11         0.741115               0.741115             0.0654346
C7          0.715711               0.715711             0.0631916
C14         0.671534               0.671534             0.0592912
C16         0.669375               0.669375             0.0591005
C5          0.637271               0.637271             0.056266
C6          0.617929               0.617929             0.0545582
C3          0.537243               0.537243             0.0474343
C4          0.536042               0.536042             0.0473282
C1          0.478572               0.478572             0.0422542
C2          0.451186               0.451186             0.0398362
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_88

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018256092945847513  0.0004412316484376788  0.0         -0.010763959249868726  0.16709893941879272  0.17789306773178623  0.1142197847366333
    3        26       Softmax                      0.0   0.0   0.01063156297216385    0.04608248174190521    0.0         -0.20837668172368878   0.3995405435562134   -0.6463997217468703  0.14980846643447876


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13374482526481848
RMSE: 0.36571139613747133
LogLoss: 0.43586803873203034
Mean Per-Class Error: 0.12693965737006283
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
369.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    1.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    1.0    2.0    1.0    4.0    3.0    0.06582278481012659  26 / 395
0.0    339.0  0.0    6.0    3.0    0.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    3.0    14.0   7.0    0.0    0.0    2.0    0.0    1.0    2.0    0.0    0.11488250652741515  44 / 383
0.0    0.0    321.0  0.0    8.0    0.0    2.0    0.0    0.0    0.0    15.0   2.0    0.0    0.0    5.0    0.0    0.0    1.0    4.0    1.0    7.0    0.0    2.0    0.0    0.0    0.0    0.12771739130434784  47 / 368
1.0    6.0    0.0    366.0  0.0    0.0    1.0    1.0    0.0    5.0    0.0    0.0    6.0    4.0    3.0    0.0    0.0    4.0    2.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.08955223880597014  36 / 402
0.0    6.0    8.0    0.0    309.0  6.0    11.0   0.0    0.0    0.0    7.0    3.0    0.0    0.0    0.0    0.0    9.0    4.0    4.0    3.0    0.0    0.0    0.0    4.0    0.0    10.0   0.1953125            75 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    16.0   0.0    2.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    351.0  0.0    0.0    0.0    0.06648936170212766  25 / 376
0.0    0.0    0.0    5.0    2.0    1.0    0.0    1.0    2.0    4.0    9.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    358.0  1.0    4.0    0.09137055837563451  36 / 394
0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    6.0    1.0    36.0   1.0    0.0    331.0  0.0    0.15776081424936386  62 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    16.0   1.0    0.0    0.0    0.0    1.0    0.0    321.0  0.12295081967213115  45 / 366
404.0  415.0  369.0  425.0  365.0  430.0  333.0  269.0  338.0  388.0  400.0  367.0  427.0  380.0  380.0  362.0  397.0  444.0  407.0  348.0  426.0  405.0  398.0  413.0  363.0  350.0  0.12636209137258822  1,264 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873638
2    0.937919
3    0.963511
4    0.976107
5    0.982705
6    0.986604
7    0.989803
8    0.992802
9    0.994702
10   0.996601

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13540547624053903
RMSE: 0.36797483098785305
LogLoss: 0.4455514402270114
Mean Per-Class Error: 0.12491299296255355
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11    12    13     14    15     16     17     18     19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  -----  -----  -----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   1.0   0.0    2.0    1.0   0.056179775280898875  5 / 89
0.0   89.0   0.0   1.0    2.0   0.0    0.0   1.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    1.0    5.0    2.0    0.0   0.0    2.0   0.0   1.0    1.0    0.0   0.16037735849056603   17 / 106
0.0   0.0    69.0  0.0    1.0   0.0    1.0   0.0   0.0   0.0    3.0    1.0   0.0   0.0    2.0   0.0    0.0    0.0    3.0    1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.15853658536585366   13 / 82
1.0   1.0    0.0   102.0  0.0   0.0    0.0   1.0   0.0   1.0    0.0    0.0   2.0   1.0    0.0   0.0    0.0    0.0    1.0    0.0   1.0    0.0   0.0   1.0    0.0    0.0   0.08928571428571429   10 / 112
0.0   0.0    1.0   0.0    77.0  3.0    2.0   0.0   0.0   0.0    2.0    1.0   0.0   0.0    0.0   0.0    3.0    1.0    2.0    1.0   0.0    0.0   0.0   1.0    0.0    3.0   0.20618556701030927   20 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---    ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   88.0  0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   1.0    0.0   0.0   0.0   1.0    5.0    1.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   88.0   0.0    1.0   0.12                  12 / 100
0.0   0.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    2.0    0.0    0.0    2.0   0.0    10.0  1.0   0.0    88.0   0.0   0.17757009345794392   19 / 107
1.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0   0.0   3.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0    0.0   0.0    0.0   0.0   1.0    0.0    77.0  0.11494252873563218   10 / 87
95.0  102.0  78.0  117.0  89.0  100.0  83.0  67.0  82.0  112.0  101.0  94.0  94.0  102.0  81.0  105.0  101.0  117.0  102.0  85.0  106.0  92.0  98.0  100.0  101.0  86.0  0.1248995983935743    311 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.8751
2    0.942972
3    0.962249
4    0.973896
5    0.981124
6    0.984337
7    0.989157
8    0.991165
9    0.994779
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:28  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:28  2 min 26.521 sec  31271 obs/sec     1         1             10007      0.524488         0.909801            0.995111       0.252124                         0.523383           0.906805              0.995119         0.255422
    2019-08-04 09:02:31  2 min 29.003 sec  36415 obs/sec     10        10            100070     0.365711         0.435868            0.997623       0.126362                         0.367975           0.445551              0.997587         0.1249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0869785
C13         0.917602               0.917602             0.0798116
C8          0.830976               0.830976             0.072277
C12         0.805838               0.805838             0.0700905
C7          0.800216               0.800216             0.0696016
C9          0.796074               0.796074             0.0692413
C11         0.721753               0.721753             0.062777
C5          0.709384               0.709384             0.0617012
C10         0.691                  0.691                0.0601021
C6          0.682814               0.682814             0.0593901
C14         0.663221               0.663221             0.0576859
C16         0.618201               0.618201             0.0537702
C3          0.616064               0.616064             0.0535844
C4          0.605171               0.605171             0.0526369
C1          0.546219               0.546219             0.0475093
C2          0.492563               0.492563             0.0428424
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_228

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.001317188242680345  0.00034645397681742907  0.0         -0.01088579989691496  0.2046908140182495  0.24702960496672008   0.14977073669433594
    3        26       Softmax                      0.0   0.0   0.008302611732460718  0.041115596890449524    0.0         -0.24668644222509345  0.513153076171875   -0.48612486880534866  0.13733136653900146


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1365601660696621
RMSE: 0.3695404796090167
LogLoss: 0.4495341360795577
Mean Per-Class Error: 0.1292062708668717
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    2.0    1.0    3.0    1.0    0.0    0.0    0.0    1.0    5.0    1.0    1.0    1.0    3.0    1.0    5.0    0.0    0.08607594936708861  34 / 395
0.0    340.0  0.0    4.0    3.0    0.0    1.0    3.0    2.0    0.0    1.0    1.0    0.0    0.0    1.0    3.0    4.0    4.0    11.0   0.0    0.0    1.0    0.0    2.0    2.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    324.0  0.0    11.0   0.0    7.0    1.0    0.0    0.0    7.0    2.0    0.0    0.0    4.0    0.0    1.0    0.0    5.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.11956521739130435  44 / 368
1.0    15.0   0.0    359.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    4.0    2.0    0.0    0.0    5.0    2.0    2.0    0.0    0.0    0.0    2.0    0.0    4.0    0.10918114143920596  44 / 403
0.0    4.0    3.0    0.0    322.0  5.0    19.0   1.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    5.0    0.0    0.0    0.0    2.0    0.0    8.0    0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    361.0  0.0    0.0    0.0    0.0398936170212766   15 / 376
0.0    1.0    0.0    4.0    6.0    0.0    0.0    1.0    2.0    2.0    4.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    359.0  2.0    4.0    0.08651399491094147  34 / 393
0.0    0.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0    2.0    7.0    1.0    11.0   1.0    0.0    357.0  0.0    0.0916030534351145   36 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    14.0   3.0    0.0    0.0    0.0    0.0    0.0    324.0  0.11716621253405994  43 / 367
384.0  457.0  369.0  435.0  403.0  397.0  362.0  320.0  355.0  374.0  321.0  380.0  399.0  374.0  378.0  376.0  351.0  403.0  378.0  377.0  412.0  377.0  422.0  425.0  409.0  365.0  0.12856143157052885  1,286 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871439
2    0.93492
3    0.957413
4    0.972108
5    0.979206
6    0.984904
7    0.988903
8    0.992302
9    0.994002
10   0.995701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13610831791317618
RMSE: 0.3689286081522768
LogLoss: 0.44932354230706806
Mean Per-Class Error: 0.12037354418264247
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   88.0   0.0   0.0    2.0   0.0   1.0   1.0   1.0   0.0    1.0   0.0   0.0   0.0   1.0   1.0    1.0   3.0    3.0   0.0   0.0    1.0   0.0    1.0    1.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    73.0  0.0    1.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   1.0    0.0    0.0    0.0   0.10975609756097561   9 / 82
1.0   1.0    0.0   102.0  0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    3.0   0.08928571428571429   10 / 112
0.0   0.0    0.0   0.0    78.0  3.0   5.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   1.0    3.0   3.0   0.0    0.0   0.0    1.0    0.0    1.0   0.1958762886597938    19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   91.0   0.0    0.0    0.0   0.010869565217391304  1 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    92.0   1.0    1.0   0.08                  8 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0   0.0    2.0   1.0    0.0    99.0   0.0   0.07476635514018691   8 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0    0.0    0.0    78.0  0.10344827586206896   9 / 87
92.0  110.0  80.0  120.0  94.0  96.0  95.0  78.0  86.0  105.0  81.0  97.0  87.0  98.0  77.0  104.0  92.0  103.0  93.0  91.0  102.0  84.0  104.0  106.0  122.0  93.0  0.12008032128514057   299 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.87992
2    0.939759
3    0.959839
4    0.972691
5    0.979116
6    0.985944
7    0.989157
8    0.99237
9    0.993976
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:42  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:42  6 min 40.625 sec  52392 obs/sec     1         1             10007      0.537936         0.933888            0.994857       0.254024                         0.539169           0.93091               0.99482          0.260241
    2019-08-04 09:06:44  6 min 42.162 sec  59003 obs/sec     10        10            100070     0.36954          0.449534            0.997573       0.128561                         0.368929           0.449324              0.997575         0.12008
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0871434
C13         0.914056               0.914056             0.0796539
C9          0.822811               0.822811             0.0717026
C8          0.818432               0.818432             0.071321
C12         0.81362                0.81362              0.0709016
C11         0.764036               0.764036             0.0665807
C5          0.723271               0.723271             0.0630283
C7          0.711922               0.711922             0.0620393
C10         0.701064               0.701064             0.0610931
C14         0.666348               0.666348             0.0580678
C4          0.63708                0.63708              0.0555174
C6          0.636904               0.636904             0.055502
C16         0.625176               0.625176             0.05448
C3          0.62352                0.62352              0.0543357
C1          0.511627               0.511627             0.0445849
C2          0.50547                0.50547              0.0440484
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_121

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.002725630646423838  0.0007414366118609905  0.0         0.0003813927170490672  0.2480325698852539   0.014298214618555844  0.2796691656112671
    3        26       Softmax                 0.0   0.0   0.003714230571369206  0.0015531191602349281  0.0         0.0005988867801842883  0.34823620319366455  -0.5889833584349494   0.10186681151390076


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13074754528075883
RMSE: 0.3615903003134332
LogLoss: 0.43155866721815933
Mean Per-Class Error: 0.1291740200332016
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    1.0    2.0    8.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    2.0    1.0    0.0    2.0    2.0    0.0759493670886076   30 / 395
0.0    334.0  1.0    11.0   2.0    2.0    1.0    10.0   2.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    10.0   0.0    0.0    1.0    0.0    2.0    1.0    1.0    0.1279373368146214   49 / 383
0.0    0.0    327.0  0.0    2.0    1.0    4.0    0.0    0.0    0.0    14.0   3.0    0.0    0.0    7.0    0.0    1.0    2.0    2.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.11141304347826086  41 / 368
0.0    5.0    0.0    374.0  0.0    1.0    0.0    2.0    0.0    3.0    0.0    0.0    7.0    4.0    2.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.07196029776674938  29 / 403
0.0    1.0    3.0    0.0    318.0  9.0    14.0   0.0    0.0    0.0    5.0    9.0    0.0    0.0    0.0    1.0    1.0    3.0    8.0    2.0    0.0    0.0    0.0    3.0    0.0    7.0    0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    17.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    0.0    0.0    6.0    3.0    6.0    0.0    0.0    3.0    4.0    12.0   4.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    0.0    1.0    0.0    0.0    346.0  4.0    1.0    0.1218274111675127   48 / 394
0.0    0.0    0.0    1.0    0.0    11.0   0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    21.0   2.0    21.0   0.0    1.0    329.0  0.0    0.1628498727735369   64 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    24.0   1.0    0.0    0.0    0.0    0.0    0.0    311.0  0.15258855585831063  56 / 367
380.0  420.0  356.0  456.0  359.0  476.0  340.0  306.0  343.0  398.0  413.0  390.0  445.0  367.0  405.0  354.0  347.0  374.0  434.0  362.0  403.0  387.0  384.0  392.0  368.0  344.0  0.12876137158852344  1,288 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871239
2    0.938718
3    0.963211
4    0.974608
5    0.982305
6    0.987104
7    0.990403
8    0.992802
9    0.994602
10   0.995701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13513933684285018
RMSE: 0.3676130259428387
LogLoss: 0.4495178091999161
Mean Per-Class Error: 0.12847408534321145
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11     12    13    14    15     16    17    18     19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  -----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   84.0   0.0   5.0    2.0   0.0    1.0   5.0   1.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0    0.0   2.0   3.0    0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.20754716981132076   22 / 106
0.0   0.0    71.0  0.0    1.0   1.0    0.0   0.0   0.0   0.0    3.0    0.0    0.0   0.0   3.0   0.0    0.0   0.0   2.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.13414634146341464   11 / 82
0.0   1.0    0.0   104.0  0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    3.0   1.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.07142857142857142   8 / 112
0.0   0.0    1.0   0.0    77.0  5.0    4.0   0.0   0.0   0.0    2.0    2.0    0.0   0.0   0.0   0.0    0.0   1.0   2.0    0.0   0.0    0.0   0.0   0.0   0.0    3.0   0.20618556701030927   20 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---    ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0    3.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   2.0    2.0   85.0  0.0   0.0    0.0   0.07608695652173914   7 / 92
0.0   0.0    0.0   3.0    1.0   0.0    0.0   0.0   0.0   1.0    6.0    2.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   86.0  1.0    0.0   0.14                  14 / 100
0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0   1.0    1.0   0.0   0.0    6.0   0.0    7.0   0.0   0.0   89.0   0.0   0.16822429906542055   18 / 107
1.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0   0.0   3.0    0.0    1.0    0.0   0.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218   10 / 87
87.0  106.0  76.0  128.0  86.0  110.0  87.0  78.0  82.0  115.0  105.0  101.0  96.0  97.0  85.0  103.0  90.0  91.0  104.0  85.0  104.0  89.0  94.0  99.0  108.0  84.0  0.12931726907630522   322 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.870683
2    0.937751
3    0.962249
4    0.974699
5    0.982731
6    0.987149
7    0.989558
8    0.991165
9    0.992771
10   0.994377
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:21  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:22  3 min 19.885 sec  26685 obs/sec     1         1             10007      0.519913         0.909677            0.995197       0.252424                         0.52053            0.909987              0.995172         0.253012
    2019-08-04 09:03:25  3 min 23.765 sec  23877 obs/sec     10        10            100070     0.36159          0.431559            0.997677       0.128761                         0.367613           0.449518              0.997592         0.129317
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0872398
C13         0.958068               0.958068             0.0835816
C12         0.860507               0.860507             0.0750704
C8          0.849339               0.849339             0.0740961
C9          0.842887               0.842887             0.0735332
C10         0.758362               0.758362             0.0661593
C11         0.730308               0.730308             0.0637119
C7          0.718823               0.718823             0.0627099
C14         0.682193               0.682193             0.0595143
C16         0.675601               0.675601             0.0589393
C6          0.665034               0.665034             0.0580174
C5          0.647442               0.647442             0.0564826
C3          0.57849                0.57849              0.0504673
C4          0.515688               0.515688             0.0449885
C1          0.494343               0.494343             0.0431263
C2          0.48558                0.48558              0.0423619
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_78

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0014393309165541268  0.0003983800997957587  0.0         -0.014208604905035394  0.20532548427581787  0.25334707240687643   0.16214317083358765
    3        26       Softmax                      0.0   0.0   0.009616929261675558   0.04665307700634003    0.0         -0.24808596651161652   0.515446662902832    -0.47335295205482625  0.16984474658966064


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1331931391511928
RMSE: 0.36495635239188917
LogLoss: 0.4412828016864862
Mean Per-Class Error: 0.12719937141467297
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    3.0    1.0    0.0    1.0    0.0    0.0    1.0    4.0    4.0    1.0    1.0    2.0    1.0    4.0    1.0    0.07848101265822785  31 / 395
0.0    332.0  0.0    4.0    2.0    0.0    1.0    10.0   2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    17.0   7.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    0.13315926892950392  51 / 383
0.0    0.0    326.0  1.0    6.0    0.0    10.0   1.0    0.0    0.0    10.0   0.0    0.0    1.0    3.0    0.0    1.0    0.0    2.0    3.0    2.0    0.0    2.0    0.0    0.0    0.0    0.11413043478260869  42 / 368
1.0    11.0   0.0    360.0  0.0    0.0    0.0    6.0    0.0    1.0    3.0    0.0    4.0    7.0    1.0    0.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    2.0    0.10669975186104218  43 / 403
0.0    3.0    3.0    1.0    330.0  7.0    18.0   2.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    2.0    0.0    0.0    0.0    6.0    0.0    3.0    0.140625             54 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    2.0    13.0   0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    1.0    0.0    3.0    7.0    0.0    0.0    2.0    2.0    1.0    4.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    364.0  2.0    3.0    0.07614213197969544  30 / 394
0.0    0.0    1.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    2.0    0.0    2.0    24.0   0.0    13.0   1.0    0.0    340.0  0.0    0.1326530612244898   52 / 392
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    9.0    2.0    0.0    0.0    0.0    3.0    0.0    329.0  0.10354223433242507  38 / 367
397.0  409.0  356.0  416.0  416.0  365.0  381.0  368.0  345.0  338.0  368.0  356.0  387.0  402.0  409.0  399.0  368.0  417.0  363.0  414.0  407.0  360.0  389.0  422.0  380.0  371.0  0.12656203139058284  1,266 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873438
2    0.937319
3    0.961312
4    0.972708
5    0.980106
6    0.985604
7    0.988603
8    0.990703
9    0.992702
10   0.995001

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13553997448047883
RMSE: 0.3681575403009951
LogLoss: 0.4501054183760715
Mean Per-Class Error: 0.12713446070949969
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19     20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  ----  -----  -----  ----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.0   1.0   0.0    2.0    0.0   0.0449438202247191   4 / 89
0.0   85.0   0.0   0.0    2.0   0.0   0.0   4.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   7.0    2.0   0.0    0.0    1.0   0.0   2.0    1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    70.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    1.0   2.0    0.0    0.0   1.0   0.0    0.0    0.0   0.14634146341463414  12 / 82
1.0   1.0    0.0   99.0   0.0   0.0   0.0   3.0   0.0   1.0    2.0   0.0   0.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   1.0    0.0    0.0   0.11607142857142858  13 / 112
0.0   1.0    0.0   0.0    80.0  5.0   6.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   2.0    0.0    0.0   0.0   1.0    0.0    0.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   90.0   1.0    1.0   0.1                  10 / 100
0.0   0.0    1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   5.0    0.0    3.0   1.0   0.0    95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0    0.0    80.0  0.08045977011494253  7 / 87
94.0  100.0  76.0  115.0  98.0  86.0  93.0  92.0  86.0  100.0  94.0  92.0  84.0  103.0  89.0  112.0  94.0  106.0  88.0  102.0  102.0  75.0  98.0  104.0  115.0  92.0  0.12730923694779117  317 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.872691
2    0.940161
3    0.959036
4    0.971888
5    0.979518
6    0.984739
7    0.988755
8    0.98996
9    0.993173
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:11  2 min  9.649 sec  52947 obs/sec     1         1             10007      0.538995         0.927081            0.994838       0.259522                         0.53777            0.9275                0.994847         0.262249
    2019-08-04 09:02:13  2 min 11.176 sec  59353 obs/sec     10        10            100070     0.364956         0.441283            0.997633       0.126562                         0.368158           0.450105              0.997585         0.127309
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0817616
C13         0.98877                0.98877              0.0808434
C9          0.878406               0.878406             0.0718199
C12         0.862904               0.862904             0.0705524
C8          0.821478               0.821478             0.0671654
C7          0.817408               0.817408             0.0668325
C10         0.817049               0.817049             0.0668032
C5          0.775362               0.775362             0.0633948
C11         0.771306               0.771306             0.0630632
C16         0.718694               0.718694             0.0587616
C14         0.710282               0.710282             0.0580738
C6          0.671588               0.671588             0.0549101
C4          0.66815                0.66815              0.054629
C3          0.658515               0.658515             0.0538412
C1          0.562466               0.562466             0.0459881
C2          0.508304               0.508304             0.0415597
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_70

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013866154486947835  0.0003619682975113392  0.0         -0.010877762169030802  0.20251625776290894  0.24484516323747477  0.16238486766815186
    3        26       Softmax                      0.0   0.0   0.007813013953234705   0.036911800503730774   0.0         -0.2539979246795252    0.5193519592285156   -0.4994608178685901  0.1409691572189331


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13387886964868106
RMSE: 0.3658946154956111
LogLoss: 0.44503370833295236
Mean Per-Class Error: 0.12727938997492771
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    7.0    0.0    1.0    0.0    0.0    1.0    4.0    3.0    1.0    1.0    2.0    0.0    3.0    1.0    0.07614213197969544  30 / 394
0.0    352.0  0.0    2.0    3.0    0.0    0.0    5.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    2.0    7.0    2.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.08093994778067885  31 / 383
0.0    0.0    316.0  0.0    9.0    0.0    6.0    0.0    0.0    0.0    15.0   2.0    0.0    0.0    5.0    0.0    0.0    1.0    1.0    5.0    3.0    0.0    4.0    0.0    0.0    0.0    0.13896457765667575  51 / 367
0.0    17.0   0.0    356.0  0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    7.0    6.0    2.0    0.0    0.0    4.0    3.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.11662531017369727  47 / 403
0.0    4.0    2.0    0.0    325.0  7.0    18.0   1.0    0.0    0.0    4.0    3.0    0.0    0.0    0.0    1.0    2.0    2.0    1.0    2.0    0.0    0.0    0.0    3.0    0.0    9.0    0.15364583333333334  59 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    11.0   0.0    6.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    351.0  0.0    0.0    0.0    0.064                24 / 375
0.0    0.0    0.0    4.0    4.0    0.0    0.0    1.0    2.0    4.0    9.0    4.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    0.0    354.0  1.0    5.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    1.0    1.0    0.0    3.0    11.0   0.0    8.0    1.0    0.0    358.0  1.0    0.08673469387755102  34 / 392
3.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    6.0    0.0    3.0    0.0    0.0    0.0    0.0    3.0    0.0    10.0   1.0    0.0    0.0    0.0    0.0    0.0    332.0  0.09536784741144415  35 / 367
387.0  458.0  349.0  415.0  401.0  376.0  363.0  342.0  344.0  366.0  395.0  373.0  423.0  391.0  387.0  402.0  387.0  385.0  356.0  384.0  394.0  371.0  392.0  393.0  381.0  388.0  0.12666200139958012  1,267 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873338
2    0.936719
3    0.958812
4    0.971508
5    0.979206
6    0.984005
7    0.988004
8    0.990503
9    0.993302
10   0.995301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1365673210295077
RMSE: 0.36955016037002025
LogLoss: 0.45038121601998754
Mean Per-Class Error: 0.12914312378042928
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11     12    13    14    15     16    17    18    19    20    21    22     23    24     25     Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  --------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0    3.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   1.0    0.0   2.0    0.0    0.0898876404494382    8 / 89
0.0   90.0   0.0   0.0    2.0   0.0   0.0   2.0   0.0   0.0    1.0    0.0    0.0   0.0   1.0   1.0    1.0   3.0   1.0   0.0   0.0   3.0   0.0    1.0   0.0    0.0    0.1509433962264151    16 / 106
0.0   0.0    69.0  0.0    2.0   0.0   0.0   0.0   0.0   0.0    4.0    0.0    0.0   0.0   3.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0   1.0    0.0   0.0    0.0    0.15853658536585366   13 / 82
0.0   2.0    0.0   102.0  0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0    3.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0    0.08928571428571429   10 / 112
0.0   1.0    0.0   0.0    79.0  4.0   6.0   0.0   0.0   0.0    1.0    2.0    0.0   0.0   0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0   0.0    0.0   0.0    2.0    0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   90.0   0.0   0.0    0.0    0.021739130434782608  2 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   1.0    5.0    3.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    85.0  0.0    2.0    0.15                  15 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0   1.0    1.0   0.0   0.0   2.0   0.0   2.0   1.0    0.0   99.0   0.0    0.07476635514018691   8 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0    2.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    81.0   0.06896551724137931   6 / 87
87.0  112.0  75.0  118.0  95.0  90.0  91.0  87.0  79.0  107.0  104.0  103.0  97.0  99.0  89.0  113.0  97.0  94.0  81.0  91.0  97.0  81.0  100.0  91.0  110.0  102.0  0.12891566265060242   321 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871084
2    0.938153
3    0.961446
4    0.973494
5    0.979518
6    0.985542
7    0.988755
8    0.990362
9    0.993173
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:58  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:58  1 min 56.659 sec  61018 obs/sec     1         1             10007      0.535239         0.944236            0.994906       0.253024                         0.535354           0.945608              0.994893         0.259036
    2019-08-04 09:02:00  1 min 58.113 sec  62976 obs/sec     10        10            100070     0.365895         0.445034            0.99762        0.126662                         0.36955            0.450381              0.997567         0.128916
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0862147
C13         0.910847               0.910847             0.0785284
C8          0.868854               0.868854             0.074908
C9          0.85547                0.85547              0.0737541
C7          0.797512               0.797512             0.0687573
C12         0.786839               0.786839             0.0678371
C10         0.757727               0.757727             0.0653272
C11         0.732341               0.732341             0.0631385
C5          0.717451               0.717451             0.0618549
C6          0.683539               0.683539             0.0589312
C14         0.63075                0.63075              0.05438
C3          0.603206               0.603206             0.0520053
C16         0.580964               0.580964             0.0500876
C4          0.578787               0.578787             0.0498999
C1          0.570448               0.570448             0.049181
C2          0.524211               0.524211             0.0451947
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_219

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013868438540214356  0.0003743832930922508  0.0         -0.011045298036044926  0.20375603437423706  0.23845783843775048   0.15967005491256714
    3        26       Softmax                      0.0   0.0   0.00827170763855415    0.03698192536830902    0.0         -0.2450958265122923    0.5126471519470215   -0.48058041482030894  0.172876238822937


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13514382495232685
RMSE: 0.36761913028612486
LogLoss: 0.44496432429808974
Mean Per-Class Error: 0.12919253300202363
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    3.0    3.0    1.0    4.0    0.0    0.0    1.0    0.0    1.0    4.0    1.0    2.0    1.0    2.0    0.0    3.0    2.0    0.0759493670886076   30 / 395
0.0    343.0  0.0    5.0    2.0    0.0    1.0    11.0   1.0    0.0    1.0    0.0    0.0    0.0    2.0    1.0    3.0    4.0    6.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.10443864229765012  40 / 383
0.0    0.0    323.0  0.0    11.0   1.0    13.0   2.0    0.0    0.0    7.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    0.0    0.0    0.0    0.11989100817438691  44 / 367
2.0    18.0   0.0    346.0  0.0    0.0    0.0    6.0    0.0    1.0    2.0    0.0    6.0    5.0    1.0    2.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    3.0    0.141439205955335    57 / 403
0.0    1.0    4.0    0.0    324.0  3.0    15.0   2.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    1.0    3.0    3.0    5.0    7.0    0.0    0.0    0.0    2.0    0.0    9.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    11.0   0.0    0.0    0.0    0.0    16.0   0.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    1.0    0.0    4.0    7.0    0.0    0.0    4.0    2.0    3.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    5.0    4.0    1.0    0.0    0.0    348.0  2.0    3.0    0.116751269035533    46 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    2.0    8.0    2.0    14.0   1.0    0.0    351.0  0.0    0.10687022900763359  42 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    10.0   2.0    0.0    0.0    0.0    0.0    0.0    330.0  0.1008174386920981   37 / 367
389.0  438.0  346.0  398.0  413.0  389.0  385.0  388.0  337.0  372.0  381.0  357.0  427.0  378.0  390.0  395.0  373.0  381.0  381.0  378.0  414.0  371.0  371.0  385.0  388.0  378.0  0.12866140157952613  1,287 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871339
2    0.936219
3    0.960512
4    0.971608
5    0.979706
6    0.986404
7    0.989203
8    0.992002
9    0.994902
10   0.996401

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13833732963554352
RMSE: 0.3719372657257451
LogLoss: 0.4553964482475325
Mean Per-Class Error: 0.12860291726923218
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17    18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0   0.0   0.0    0.0   1.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   88.0   0.0   1.0    1.0   0.0   1.0   6.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    1.0    3.0   2.0   0.0   0.0    0.0   0.0   1.0   1.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    73.0  0.0    0.0   0.0   2.0   1.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0   0.0   1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.10975609756097561   9 / 82
1.0   3.0    0.0   93.0   0.0   0.0   0.0   3.0   0.0   0.0    1.0   0.0   2.0   2.0    0.0   2.0    0.0    1.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    2.0   0.16964285714285715   19 / 112
0.0   0.0    1.0   0.0    80.0  2.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    1.0   2.0   2.0   0.0    0.0   0.0   1.0   0.0    3.0   0.17525773195876287   17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   1.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914   7 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   2.0   0.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   86.0  0.0    1.0   0.14                  14 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0    0.0   0.0   0.0   0.0    5.0   1.0   0.0   95.0   0.0   0.11214953271028037   12 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218   10 / 87
90.0  111.0  77.0  107.0  96.0  91.0  95.0  99.0  80.0  109.0  99.0  94.0  93.0  102.0  81.0  115.0  107.0  93.0  92.0  86.0  105.0  82.0  92.0  94.0  109.0  91.0  0.12891566265060242   321 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871084
2    0.935743
3    0.960643
4    0.96988
5    0.979116
6    0.985141
7    0.989558
8    0.991566
9    0.994779
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:23  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:23  6 min 21.274 sec  55594 obs/sec     1         1             10007      0.538826         0.945063            0.99484        0.260722                         0.537848           0.940212              0.994845         0.263855
    2019-08-04 09:06:25  6 min 22.817 sec  59388 obs/sec     10        10            100070     0.367619         0.444964            0.997598       0.128661                         0.371937           0.455396              0.997535         0.128916
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0825347
C13         0.941728               0.941728             0.0777253
C8          0.889978               0.889978             0.0734541
C9          0.884031               0.884031             0.0729633
C12         0.871237               0.871237             0.0719073
C11         0.811609               0.811609             0.0669859
C10         0.808268               0.808268             0.0667102
C7          0.79093                0.79093              0.0652792
C5          0.770665               0.770665             0.0636066
C16         0.716915               0.716915             0.0591704
C14         0.69935                0.69935              0.0577207
C6          0.65041                0.65041              0.0536814
C3          0.628748               0.628748             0.0518936
C4          0.602136               0.602136             0.0496971
C1          0.52821                0.52821              0.0435957
C2          0.521894               0.521894             0.0430744
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_160

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0014046797942910416  0.0003344498109072447  0.0         -0.008045919861246607  0.20340335369110107  0.2467591302701458   0.16267693042755127
    3        26       Softmax                      0.0   0.0   0.008705211085236022   0.038802191615104675   0.0         -0.2507450647900581    0.516716480255127    -0.4932504081668538  0.14138829708099365


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13664665213154878
RMSE: 0.3696574794746466
LogLoss: 0.45026889086342314
Mean Per-Class Error: 0.13222468083237174
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    3.0    1.0    6.0    0.0    1.0    0.0    0.0    0.0    4.0    1.0    0.0    1.0    2.0    2.0    6.0    0.0    0.08607594936708861  34 / 395
0.0    341.0  0.0    8.0    2.0    1.0    0.0    5.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    4.0    3.0    10.0   2.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.10966057441253264  42 / 383
0.0    0.0    330.0  0.0    10.0   1.0    5.0    1.0    0.0    0.0    8.0    1.0    1.0    0.0    1.0    0.0    1.0    1.0    0.0    1.0    2.0    0.0    4.0    0.0    0.0    0.0    0.1008174386920981   37 / 367
0.0    10.0   0.0    368.0  0.0    1.0    0.0    5.0    0.0    3.0    0.0    0.0    7.0    4.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0845771144278607   34 / 402
0.0    6.0    1.0    0.0    326.0  3.0    14.0   0.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    1.0    2.0    4.0    9.0    3.0    0.0    0.0    0.0    2.0    0.0    5.0    0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    351.0  0.0    0.0    0.0    0.06648936170212766  25 / 376
0.0    1.0    0.0    3.0    4.0    1.0    0.0    1.0    2.0    4.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    361.0  1.0    3.0    0.08375634517766498  33 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    10.0   3.0    18.0   1.0    0.0    346.0  0.0    0.11959287531806616  47 / 393
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    11.0   1.0    0.0    0.0    0.0    3.0    0.0    322.0  0.1226158038147139   45 / 367
377.0  460.0  373.0  429.0  399.0  391.0  336.0  325.0  350.0  395.0  373.0  359.0  422.0  378.0  379.0  390.0  360.0  431.0  384.0  372.0  390.0  380.0  410.0  415.0  379.0  346.0  0.13166050184944517  1,317 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86834
2    0.93472
3    0.958412
4    0.970509
5    0.977607
6    0.983605
7    0.988803
8    0.991403
9    0.993402
10   0.995201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13898585563454713
RMSE: 0.37280806809207756
LogLoss: 0.4556870681590015
Mean Per-Class Error: 0.13356493537015177
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18     19    20    21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  -----  ----  ----  ----  -----  -----  -----  ----  --------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0    0.0    0.0    1.0    0.0   0.0   0.0   1.0    0.0    3.0    0.0   0.0898876404494382    8 / 89
0.0   91.0   0.0   2.0    1.0   0.0   0.0   2.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0    1.0    3.0    1.0    0.0   0.0   1.0   0.0    1.0    1.0    0.0   0.14150943396226415   15 / 106
0.0   0.0    72.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0    0.0    1.0   0.0   0.0   1.0    0.0    0.0    0.0   0.12195121951219512   10 / 82
0.0   1.0    0.0   101.0  0.0   1.0   0.0   2.0   0.0   2.0    0.0   0.0   3.0    1.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.09821428571428571   11 / 112
0.0   0.0    1.0   0.0    79.0  2.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    1.0    1.0    5.0    1.0   0.0   0.0   0.0    1.0    0.0    1.0   0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---    ---   ---   ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0   0.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   1.0   0.0   0.0   0.0   1.0    4.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0    91.0   0.0    0.0   0.09                  9 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0    1.0    0.0    0.0    2.0   0.0   6.0   1.0    0.0    94.0   0.0   0.12149532710280374   13 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0    2.0    0.0   0.0   0.0   0.0    2.0    0.0    76.0  0.12643678160919541   11 / 87
84.0  114.0  80.0  120.0  92.0  92.0  82.0  75.0  86.0  114.0  97.0  92.0  100.0  96.0  82.0  109.0  100.0  111.0  100.0  87.0  98.0  81.0  104.0  103.0  111.0  80.0  0.13293172690763053   331 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.867068
2    0.938153
3    0.957028
4    0.970683
5    0.977912
6    0.985542
7    0.98996
8    0.992369
9    0.993574
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:33  4 min 31.497 sec  53228 obs/sec     1         1             10007      0.529342         0.910088            0.99502        0.242027                         0.530732           0.910479              0.994981         0.245382
    2019-08-04 09:04:35  4 min 33.079 sec  57511 obs/sec     10        10            100070     0.369657         0.450269            0.997572       0.131661                         0.372808           0.455687              0.997523         0.132932
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0857441
C13         0.974804               0.974804             0.0835837
C8          0.856805               0.856805             0.073466
C9          0.832062               0.832062             0.0713445
C12         0.817869               0.817869             0.0701274
C7          0.814451               0.814451             0.0698344
C5          0.740058               0.740058             0.0634557
C11         0.729605               0.729605             0.0625594
C6          0.686474               0.686474             0.0588611
C14         0.68194                0.68194              0.0584724
C10         0.658697               0.658697             0.0564794
C4          0.621494               0.621494             0.0532895
C16         0.613043               0.613043             0.0525649
C3          0.584088               0.584088             0.0500821
C1          0.536419               0.536419             0.0459948
C2          0.514794               0.514794             0.0441405
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_29

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013240675793326773  0.0003416860708966851  0.0         -0.009761164034610914  0.20533841848373413  0.2472841318281116    0.14535236358642578
    3        26       Softmax                      0.0   0.0   0.00806275211495561    0.03588053584098816    0.0         -0.239401882308873     0.5153844356536865   -0.49323939091101265  0.14686036109924316


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13457937829562902
RMSE: 0.36685062122835366
LogLoss: 0.4419023945926325
Mean Per-Class Error: 0.12899307189338535
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    3.0    2.0    5.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    1.0    4.0    1.0    0.0    3.0    0.0    0.07341772151898734  29 / 395
0.0    329.0  3.0    5.0    2.0    2.0    2.0    5.0    2.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    2.0    13.0   7.0    0.0    0.0    3.0    0.0    2.0    2.0    0.0    0.1409921671018277   54 / 383
0.0    0.0    323.0  1.0    6.0    0.0    3.0    1.0    0.0    0.0    7.0    3.0    1.0    0.0    5.0    0.0    1.0    1.0    5.0    3.0    4.0    0.0    4.0    0.0    0.0    0.0    0.12228260869565218  45 / 368
0.0    8.0    0.0    356.0  0.0    1.0    0.0    5.0    0.0    3.0    1.0    1.0    5.0    2.0    3.0    1.0    0.0    6.0    1.0    0.0    2.0    0.0    0.0    3.0    0.0    5.0    0.11662531017369727  47 / 403
0.0    4.0    1.0    0.0    326.0  3.0    16.0   1.0    0.0    0.0    4.0    8.0    0.0    0.0    0.0    1.0    5.0    2.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    9.0    0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    12.0   1.0    2.0    0.0    0.0    1.0    0.0    0.0    1.0    5.0    346.0  0.0    0.0    0.0    0.07733333333333334  29 / 375
0.0    1.0    0.0    4.0    4.0    1.0    0.0    1.0    3.0    3.0    14.0   5.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    1.0    0.0    0.0    345.0  2.0    4.0    0.12213740458015267  48 / 393
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    0.0    1.0    18.0   1.0    18.0   1.0    0.0    339.0  0.0    0.13740458015267176  54 / 393
2.0    0.0    0.0    0.0    20.0   0.0    0.0    0.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    12.0   3.0    0.0    0.0    0.0    1.0    0.0    317.0  0.1362397820163488   50 / 367
393.0  447.0  352.0  413.0  395.0  401.0  352.0  324.0  353.0  379.0  388.0  400.0  420.0  381.0  400.0  386.0  368.0  404.0  363.0  394.0  397.0  401.0  377.0  381.0  370.0  364.0  0.12846146156153154  1,285 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871538
2    0.936519
3    0.959712
4    0.972708
5    0.982005
6    0.986804
7    0.990303
8    0.992702
9    0.994702
10   0.996301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13789629934688968
RMSE: 0.3713439098018031
LogLoss: 0.4558868190541362
Mean Per-Class Error: 0.1321412534205977
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17    18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    2.0   0.0   0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   85.0   1.0   1.0    2.0   0.0   1.0   2.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    0.0   5.0   2.0   0.0   0.0    3.0   0.0   1.0   1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    69.0  0.0    2.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0   2.0   2.0   2.0    0.0   1.0   0.0   0.0    0.0   0.15853658536585366  13 / 82
0.0   2.0    0.0   97.0   0.0   1.0   0.0   2.0   0.0   1.0    0.0   1.0    2.0   1.0    0.0   1.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   2.0   0.0    1.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    81.0  2.0   6.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   0.0    0.0   1.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0    3.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0    2.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0   0.0   0.0   0.0    7.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   85.0  0.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   2.0    1.0   0.0   0.0   4.0   0.0    8.0   1.0   0.0   90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    76.0  0.12643678160919541  11 / 87
88.0  114.0  73.0  109.0  96.0  98.0  92.0  82.0  85.0  110.0  96.0  103.0  96.0  102.0  85.0  109.0  92.0  98.0  91.0  93.0  100.0  97.0  92.0  95.0  104.0  90.0  0.13293172690763053  331 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.867068
2    0.940562
3    0.958635
4    0.96988
5    0.978715
6    0.984739
7    0.988353
8    0.990361
9    0.994779
10   0.995984
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:57  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:57  55.349 sec  51317 obs/sec     1         1             10007      0.523368         0.903578            0.995132       0.244327                         0.524145           0.904219              0.995105         0.247791
    2019-08-04 09:00:59  56.889 sec  58692 obs/sec     10        10            100070     0.366851         0.441902            0.997608       0.128461                         0.371344           0.455887              0.997543         0.132932
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0879442
C13         0.921839               0.921839             0.0810704
C9          0.866871               0.866871             0.0762362
C8          0.83763                0.83763              0.0736647
C7          0.806539               0.806539             0.0709304
C12         0.768536               0.768536             0.0675882
C11         0.718147               0.718147             0.0631568
C10         0.710896               0.710896             0.0625191
C5          0.697237               0.697237             0.0613179
C6          0.628429               0.628429             0.0552667
C14         0.628144               0.628144             0.0552416
C16         0.612485               0.612485             0.0538645
C4          0.585025               0.585025             0.0514496
C3          0.549478               0.549478             0.0483234
C2          0.525802               0.525802             0.0462413
C1          0.513794               0.513794             0.0451852
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_134

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013514959369445023  0.00034370797220617533  0.0         -0.013225169075056442  0.20287317037582397  0.2432594899283877   0.1518654227256775
    3        26       Softmax                      0.0   0.0   0.008488073053618232   0.03723306953907013     0.0         -0.25249018258250544   0.5152325630187988   -0.4872574511768685  0.14633899927139282


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13412683204461895
RMSE: 0.36623330275197385
LogLoss: 0.44220433828592404
Mean Per-Class Error: 0.12788333469483532
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    2.0    2.0    0.0    1.0    0.0    0.0    1.0    5.0    1.0    1.0    0.0    2.0    2.0    4.0    0.0    0.07341772151898734  29 / 395
0.0    341.0  0.0    6.0    3.0    0.0    1.0    8.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    8.0    8.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.10966057441253264  42 / 383
0.0    0.0    325.0  0.0    12.0   0.0    4.0    0.0    0.0    0.0    6.0    3.0    0.0    0.0    6.0    0.0    2.0    1.0    4.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.11684782608695653  43 / 368
1.0    15.0   0.0    351.0  0.0    1.0    0.0    5.0    0.0    1.0    1.0    0.0    5.0    4.0    3.0    0.0    0.0    8.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    2.0    0.12903225806451613  52 / 403
0.0    4.0    1.0    0.0    330.0  6.0    14.0   0.0    0.0    0.0    2.0    4.0    0.0    0.0    0.0    0.0    3.0    4.0    2.0    3.0    1.0    0.0    0.0    2.0    0.0    8.0    0.140625             54 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    1.0    9.0    1.0    1.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    3.0    4.0    1.0    0.0    2.0    2.0    2.0    2.0    2.0    0.0    0.0    2.0    0.0    4.0    0.0    2.0    1.0    1.0    0.0    0.0    359.0  1.0    4.0    0.08883248730964467  35 / 394
1.0    0.0    0.0    2.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    1.0    0.0    1.0    7.0    1.0    6.0    1.0    0.0    363.0  0.0    0.07633587786259542  30 / 393
2.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    10.0   0.0    3.0    0.0    0.0    0.0    0.0    4.0    0.0    8.0    4.0    0.0    0.0    0.0    0.0    0.0    325.0  0.11444141689373297  42 / 367
395.0  474.0  354.0  408.0  401.0  388.0  356.0  335.0  335.0  368.0  334.0  393.0  391.0  389.0  401.0  380.0  361.0  420.0  366.0  374.0  413.0  362.0  391.0  422.0  410.0  382.0  0.12726182145356393  1,273 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.872738
2    0.936019
3    0.961112
4    0.972708
5    0.981406
6    0.987204
7    0.990303
8    0.993102
9    0.994902
10   0.996601

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1378956098601964
RMSE: 0.3713429814338712
LogLoss: 0.45685953215760927
Mean Per-Class Error: 0.12908405467988227
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0   0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   88.0   0.0   1.0    2.0   0.0   1.0   4.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0    0.0   3.0    2.0   0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    73.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0    2.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.10975609756097561   9 / 82
1.0   1.0    0.0   98.0   0.0   1.0   0.0   1.0   0.0   0.0    1.0   0.0    1.0   1.0    2.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.125                 14 / 112
0.0   0.0    0.0   0.0    82.0  4.0   4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0    1.0   1.0   0.0    0.0   0.0   0.0    0.0    3.0   0.15463917525773196   15 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   88.0  0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   1.0    1.0   1.0   0.0   1.0   0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   94.0   0.0    1.0   0.06                  6 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   2.0    1.0   0.0    0.0   2.0   0.0    2.0   1.0   0.0    97.0   0.0   0.09345794392523364   10 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0    76.0  0.12643678160919541   11 / 87
93.0  115.0  79.0  112.0  96.0  95.0  87.0  87.0  77.0  106.0  83.0  104.0  85.0  101.0  83.0  108.0  91.0  109.0  87.0  89.0  103.0  79.0  99.0  108.0  120.0  94.0  0.12891566265060242   321 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871084
2    0.938554
3    0.959438
4    0.971084
5    0.977109
6    0.983936
7    0.986345
8    0.991165
9    0.993173
10   0.996386
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:43  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:43  3 min 41.744 sec  51849 obs/sec     1         1             10007      0.532296         0.919057            0.994965       0.251125                         0.535958           0.93151               0.994882         0.253414
    2019-08-04 09:03:45  3 min 43.279 sec  58899 obs/sec     10        10            100070     0.366233         0.442204            0.997617       0.127262                         0.371343           0.45686               0.997543         0.128916
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0825279
C13         0.98028                0.98028              0.0809005
C8          0.906147               0.906147             0.0747824
C12         0.865212               0.865212             0.0714041
C9          0.837108               0.837108             0.0690848
C7          0.827769               0.827769             0.068314
C5          0.772845               0.772845             0.0637813
C10         0.768165               0.768165             0.063395
C11         0.767234               0.767234             0.0633182
C6          0.691953               0.691953             0.0571054
C14         0.671408               0.671408             0.0554099
C16         0.660596               0.660596             0.0545176
C3          0.648448               0.648448             0.0535151
C4          0.60764                0.60764              0.0501473
C2          0.564338               0.564338             0.0465736
C1          0.547971               0.547971             0.0452229
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_33

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013574292888165473  0.000359848840162158  0.0         -0.003936878886648287  0.20168453454971313  0.25609631299395685  0.15372520685195923
    3        26       Softmax                      0.0   0.0   0.008022709569436652   0.031039133667945862  0.0         -0.24838418198055479   0.5155410766601562   -0.4839556564064394  0.13036072254180908


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13459933061324197
RMSE: 0.3668778142832324
LogLoss: 0.4492252496604577
Mean Per-Class Error: 0.13065154067480303
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
369.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    2.0    0.0    0.0    0.0    1.0    1.0    7.0    0.0    1.0    1.0    3.0    1.0    4.0    0.0    0.06582278481012659  26 / 395
0.0    345.0  0.0    7.0    1.0    0.0    1.0    6.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    8.0    7.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0968586387434555   37 / 382
0.0    0.0    318.0  0.0    12.0   0.0    7.0    1.0    0.0    0.0    8.0    1.0    0.0    0.0    4.0    0.0    0.0    1.0    6.0    1.0    6.0    0.0    2.0    0.0    0.0    0.0    0.1335149863760218   49 / 367
2.0    17.0   0.0    354.0  0.0    2.0    0.0    3.0    0.0    1.0    2.0    0.0    4.0    6.0    0.0    2.0    0.0    3.0    4.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.12158808933002481  49 / 403
0.0    1.0    2.0    0.0    334.0  2.0    16.0   0.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    1.0    1.0    4.0    4.0    5.0    0.0    0.0    0.0    3.0    0.0    4.0    0.13020833333333334  50 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    9.0    1.0    0.0    1.0    0.0    3.0    0.0    0.0    4.0    0.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    0.0    0.0    4.0    8.0    2.0    0.0    2.0    2.0    2.0    7.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    5.0    3.0    1.0    0.0    0.0    350.0  1.0    5.0    0.1116751269035533   44 / 394
0.0    0.0    0.0    1.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    2.0    8.0    0.0    21.0   1.0    0.0    344.0  0.0    0.12244897959183673  48 / 392
0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    16.0   4.0    0.0    0.0    0.0    3.0    0.0    318.0  0.1335149863760218   49 / 367
394.0  459.0  357.0  432.0  397.0  394.0  366.0  338.0  330.0  372.0  358.0  365.0  389.0  400.0  354.0  401.0  354.0  426.0  432.0  381.0  407.0  370.0  410.0  397.0  375.0  345.0  0.13006098170548835  1,301 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869939
2    0.937719
3    0.960312
4    0.971708
5    0.979406
6    0.985204
7    0.988204
8    0.991803
9    0.994602
10   0.996101

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13682087009503907
RMSE: 0.36989305223948055
LogLoss: 0.4602516622329094
Mean Per-Class Error: 0.1308296952751977
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0    0.0   0.0    0.0   1.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   90.0   0.0   1.0    1.0   0.0   1.0   3.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0   4.0    2.0    0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    68.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.17073170731707318  14 / 82
1.0   2.0    0.0   97.0   0.0   1.0   0.0   2.0   0.0   1.0    1.0   0.0   1.0   2.0    0.0   1.0    0.0   0.0    1.0    0.0   1.0    0.0   0.0    1.0    0.0    0.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    81.0  1.0   5.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0    3.0   0.0    0.0   0.0    1.0    0.0    1.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   1.0    0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0    88.0   0.0    2.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0    2.0   0.0    8.0   1.0    0.0    93.0   0.0   0.1308411214953271   14 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   5.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0   0.0    1.0    0.0    73.0  0.16091954022988506  14 / 87
89.0  112.0  75.0  120.0  94.0  98.0  94.0  81.0  77.0  109.0  91.0  97.0  82.0  107.0  73.0  113.0  91.0  113.0  108.0  92.0  103.0  86.0  101.0  100.0  103.0  81.0  0.13012048192771083  324 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86988
2    0.937349
3    0.960241
4    0.973092
5    0.97751
6    0.982731
7    0.986747
8    0.990362
9    0.993173
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:02  1 min  0.627 sec  54091 obs/sec     1         1             10007      0.536412         0.927322            0.994885       0.249825                         0.535353           0.926867              0.994893         0.251406
    2019-08-04 09:01:04  1 min  2.213 sec  57478 obs/sec     10        10            100070     0.366878         0.449225            0.997607       0.130061                         0.369893           0.460252              0.997562         0.13012
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0869862
C15         0.922798               0.922798             0.0802707
C9          0.853497               0.853497             0.0742425
C8          0.833588               0.833588             0.0725107
C12         0.82339                0.82339              0.0716236
C7          0.758124               0.758124             0.0659463
C10         0.729674               0.729674             0.0634715
C11         0.70274                0.70274              0.0611287
C5          0.688325               0.688325             0.0598748
C6          0.669565               0.669565             0.0582429
C14         0.663813               0.663813             0.0577426
C4          0.607279               0.607279             0.0528249
C16         0.606084               0.606084             0.052721
C3          0.596323               0.596323             0.0518719
C1          0.549653               0.549653             0.0478122
C2          0.491221               0.491221             0.0427295
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_25

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.001986684403078698   0.0005310641136020422  0.0         -0.0023803954701886454  0.34399425983428955  0.04417670978941545  0.3801002502441406
    3        26       Softmax                 0.0   0.0   0.0030363499784541023  0.00133958226069808    0.0         -0.013636708322182427   0.43978559970855713  -0.5431613835727102  0.18692362308502197


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13876176393697046
RMSE: 0.3725074011841516
LogLoss: 0.46534956195003035
Mean Per-Class Error: 0.1332513877054173
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    3.0    1.0    6.0    0.0    1.0    0.0    0.0    3.0    5.0    1.0    1.0    1.0    0.0    1.0    3.0    1.0    0.09113924050632911  36 / 395
0.0    324.0  0.0    10.0   5.0    0.0    1.0    11.0   1.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    18.0   6.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.15404699738903394  59 / 383
0.0    0.0    327.0  1.0    8.0    1.0    2.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    3.0    0.0    2.0    1.0    3.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.10899182561307902  40 / 367
0.0    7.0    0.0    355.0  0.0    1.0    0.0    11.0   0.0    6.0    0.0    0.0    6.0    3.0    1.0    1.0    0.0    5.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    2.0    0.11910669975186104  48 / 403
0.0    0.0    3.0    0.0    338.0  2.0    9.0    4.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    8.0    2.0    5.0    1.0    1.0    0.0    0.0    3.0    0.0    6.0    0.11979166666666667  46 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    1.0    0.0    1.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    23.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    0.0    0.0    5.0    11.0   2.0    0.0    2.0    5.0    5.0    8.0    3.0    0.0    0.0    0.0    0.0    2.0    2.0    1.0    1.0    1.0    0.0    0.0    340.0  3.0    3.0    0.13705583756345177  54 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    15.0   1.0    11.0   1.0    1.0    352.0  0.0    0.10432569974554708  41 / 393
0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    20.0   3.0    0.0    0.0    0.0    0.0    0.0    324.0  0.11716621253405994  43 / 367
377.0  419.0  370.0  426.0  428.0  393.0  329.0  372.0  343.0  388.0  377.0  363.0  427.0  376.0  378.0  380.0  381.0  425.0  398.0  385.0  398.0  377.0  371.0  386.0  376.0  360.0  0.13276017194841547  1,328 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86724
2    0.930221
3    0.955013
4    0.968909
5    0.977207
6    0.983605
7    0.987304
8    0.989803
9    0.992102
10   0.994202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13998377735841616
RMSE: 0.37414405963267167
LogLoss: 0.46989772445477707
Mean Per-Class Error: 0.1320149890331173
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   84.0   0.0   5.0    3.0    0.0   1.0   3.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   5.0    2.0   0.0   0.0    0.0   1.0   1.0   0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    72.0  0.0    2.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.12195121951219512  10 / 82
0.0   1.0    0.0   96.0   0.0    0.0   0.0   4.0   0.0   2.0    0.0   0.0   3.0   1.0    1.0   1.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    2.0   0.0    81.0   2.0   2.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    3.0   0.0   0.0    0.0   0.0   1.0   0.0    2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   3.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   2.0    4.0    0.0   0.0   1.0   0.0   1.0    3.0   2.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   84.0  1.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   2.0   0.0    5.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    78.0  0.10344827586206896  9 / 87
85.0  104.0  81.0  116.0  101.0  87.0  82.0  98.0  81.0  114.0  95.0  97.0  92.0  100.0  81.0  110.0  97.0  110.0  98.0  88.0  104.0  85.0  95.0  93.0  107.0  89.0  0.1321285140562249   329 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.867871
2    0.936546
3    0.956627
4    0.968675
5    0.977912
6    0.983534
7    0.986747
8    0.989157
9    0.990361
10   0.992771
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:48  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:49  46.790 sec  42223 obs/sec     1         1             10007      0.535977         0.94856             0.994895       0.258023                         0.535205           0.939795              0.994896         0.263052
    2019-08-04 09:00:51  48.892 sec  43433 obs/sec     10        10            100070     0.372507         0.46535             0.997534       0.13276                          0.374144           0.469898              0.997506         0.132129
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0905986
C13         0.919351               0.919351             0.0832919
C9          0.85732                0.85732              0.077672
C8          0.853301               0.853301             0.0773079
C12         0.819754               0.819754             0.0742686
C7          0.767145               0.767145             0.0695022
C10         0.75222                0.75222              0.06815
C11         0.723817               0.723817             0.0655768
C16         0.649272               0.649272             0.0588231
C14         0.642732               0.642732             0.0582306
C5          0.598179               0.598179             0.0541942
C6          0.591106               0.591106             0.0535534
C2          0.488333               0.488333             0.0442423
C3          0.474301               0.474301             0.042971
C4          0.47192                0.47192              0.0427553
C1          0.428949               0.428949             0.0388622
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_170

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.001989058090373419   0.0005899609532207251  0.0         0.0060143107832146825  0.3420168161392212  0.00615073214714377  0.34177374839782715
    3        26       Softmax                 0.0   0.0   0.0031681081571220534  0.0013518519699573517  0.0         -0.011777500486730857  0.4442847967147827  -0.5384801373551135  0.13463878631591797


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1399288109167793
RMSE: 0.3740705961670595
LogLoss: 0.4662581494554027
Mean Per-Class Error: 0.13227319778003024
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    1.0    6.0    0.0    0.0    0.0    1.0    1.0    3.0    0.0    2.0    0.0    1.0    1.0    4.0    2.0    0.0810126582278481   32 / 395
0.0    337.0  0.0    4.0    3.0    2.0    1.0    6.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    11.0   6.0    0.0    0.0    2.0    0.0    2.0    1.0    2.0    0.12010443864229765  46 / 383
0.0    0.0    323.0  0.0    9.0    0.0    6.0    1.0    0.0    0.0    8.0    0.0    0.0    1.0    3.0    0.0    3.0    0.0    4.0    4.0    4.0    0.0    2.0    0.0    0.0    0.0    0.12228260869565218  45 / 368
0.0    18.0   0.0    351.0  0.0    1.0    0.0    7.0    0.0    4.0    2.0    0.0    3.0    6.0    1.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.12903225806451613  52 / 403
0.0    2.0    1.0    0.0    336.0  3.0    12.0   0.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    1.0    2.0    2.0    4.0    5.0    0.0    0.0    0.0    4.0    0.0    6.0    0.1227154046997389   47 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    0.0    2.0    0.0    0.0    4.0    1.0    355.0  0.0    0.0    0.0    0.05333333333333334  20 / 375
0.0    2.0    0.0    4.0    7.0    0.0    0.0    2.0    2.0    0.0    9.0    3.0    0.0    0.0    0.0    0.0    7.0    1.0    1.0    2.0    1.0    0.0    0.0    343.0  5.0    4.0    0.1272264631043257   50 / 393
0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    16.0   0.0    9.0    1.0    1.0    353.0  0.0    0.10178117048346055  40 / 393
2.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    7.0    0.0    11.0   2.0    0.0    0.0    0.0    1.0    0.0    327.0  0.10899182561307902  40 / 367
389.0  453.0  356.0  422.0  410.0  362.0  347.0  344.0  339.0  356.0  370.0  361.0  392.0  399.0  389.0  424.0  382.0  422.0  375.0  388.0  406.0  353.0  393.0  406.0  396.0  369.0  0.13166050184944517  1,317 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86834
2    0.931021
3    0.956313
4    0.968409
5    0.976707
6    0.983605
7    0.988104
8    0.990303
9    0.993002
10   0.994502

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14184247077550652
RMSE: 0.37661979604835766
LogLoss: 0.4722543682304401
Mean Per-Class Error: 0.13096450900187848
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   88.0   0.0   2.0    2.0    1.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0   5.0    1.0   0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    72.0  0.0    2.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.12195121951219512  10 / 82
0.0   1.0    0.0   98.0   0.0    1.0   0.0   3.0   0.0   1.0    1.0   0.0   1.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0    1.0   0.125                14 / 112
0.0   0.0    0.0   0.0    85.0   2.0   4.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   0.12371134020618557  12 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   89.0  0.0   0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0   1.0   0.0   0.0    4.0   2.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   85.0  1.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   2.0   0.0    4.0   1.0   0.0   97.0   0.0   0.09345794392523364  10 / 107
2.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   3.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0   0.0    75.0  0.13793103448275862  12 / 87
91.0  114.0  77.0  120.0  101.0  85.0  89.0  85.0  79.0  104.0  94.0  97.0  82.0  105.0  85.0  123.0  92.0  108.0  98.0  88.0  102.0  80.0  98.0  98.0  111.0  84.0  0.13052208835341367  325 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869478
2    0.93012
3    0.953414
4    0.967871
5    0.976707
6    0.984337
7    0.989558
8    0.991968
9    0.993574
10   0.994378
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:58  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:58  4 min 56.201 sec  42223 obs/sec     1         1             10007      0.534075         0.945821            0.99493        0.249825                         0.533228           0.940881              0.994934         0.250602
    2019-08-04 09:05:00  4 min 58.325 sec  43059 obs/sec     10        10            100070     0.374071         0.466258            0.997513       0.131661                         0.37662            0.472254              0.997473         0.130522
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0890841
C13         0.941764               0.941764             0.0838962
C12         0.900455               0.900455             0.0802163
C9          0.863541               0.863541             0.0769278
C8          0.815981               0.815981             0.072691
C7          0.775596               0.775596             0.0690933
C11         0.688964               0.688964             0.0613757
C10         0.683917               0.683917             0.0609261
C6          0.664911               0.664911             0.059233
C5          0.664878               0.664878             0.0592301
C14         0.64894                0.64894              0.0578103
C16         0.622505               0.622505             0.0554553
C3          0.5513                 0.5513               0.0491121
C4          0.485385               0.485385             0.0432401
C1          0.471939               0.471939             0.0420423
C2          0.445266               0.445266             0.0396662
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_149

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  ----------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0019473432624295128  0.0005909556057304144  0.0         0.003196789297728486  0.3401843309402466  -0.0037478838206058728  0.36934471130371094
    3        26       Softmax                 0.0   0.0   0.0031393091170195055  0.0015149647369980812  0.0         0.005870050875573659  0.4505711793899536  -0.519218152930378      0.14961731433868408


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14044285619907235
RMSE: 0.3747570629075219
LogLoss: 0.46695910517769806
Mean Per-Class Error: 0.13666699652644232
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0    8.0    2.0    1.0    4.0    2.0    0.0    0.0    0.0    2.0    3.0    1.0    2.0    0.0    1.0    0.0    4.0    1.0    0.08860759493670886  35 / 395
0.0    335.0  0.0    10.0   3.0    1.0    1.0    7.0    2.0    0.0    0.0    1.0    0.0    1.0    1.0    1.0    0.0    10.0   7.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    0.12532637075718014  48 / 383
0.0    0.0    330.0  0.0    6.0    2.0    2.0    1.0    0.0    0.0    8.0    2.0    0.0    0.0    6.0    0.0    1.0    1.0    1.0    1.0    4.0    0.0    3.0    0.0    0.0    0.0    0.10326086956521739  38 / 368
1.0    12.0   0.0    358.0  0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    2.0    6.0    2.0    0.0    5.0    1.0    0.0    2.0    0.0    0.0    4.0    0.0    3.0    0.11166253101736973  45 / 403
0.0    7.0    2.0    0.0    323.0  6.0    10.0   0.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    9.0    3.0    3.0    4.0    0.0    0.0    0.0    2.0    0.0    11.0   0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    8.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    2.0    0.0    6.0    8.0    3.0    0.0    2.0    3.0    0.0    5.0    3.0    0.0    0.0    2.0    0.0    5.0    1.0    2.0    2.0    1.0    0.0    0.0    343.0  1.0    5.0    0.12944162436548223  51 / 394
0.0    0.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    4.0    1.0    0.0    1.0    17.0   2.0    13.0   1.0    1.0    342.0  0.0    0.1297709923664122   51 / 393
2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    16.0   2.0    0.0    0.0    0.0    0.0    0.0    326.0  0.11171662125340599  41 / 367
391.0  473.0  360.0  450.0  424.0  370.0  356.0  301.0  349.0  362.0  357.0  371.0  413.0  383.0  383.0  403.0  373.0  411.0  360.0  403.0  409.0  358.0  399.0  401.0  373.0  370.0  0.1360591822453264   1,361 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.863941
2    0.931421
3    0.955913
4    0.969009
5    0.978706
6    0.984305
7    0.987504
8    0.989903
9    0.992902
10   0.994402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14204116830285554
RMSE: 0.3768834943359228
LogLoss: 0.4745262952799496
Mean Per-Class Error: 0.1360472383533947
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   86.0   0.0   3.0    2.0   1.0   1.0   1.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   5.0    2.0   0.0   0.0    1.0   1.0   1.0   0.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    73.0  0.0    1.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.10975609756097561   9 / 82
1.0   1.0    0.0   98.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    1.0   2.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    2.0   0.125                 14 / 112
0.0   1.0    0.0   0.0    78.0  3.0   3.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0    0.0   0.0    2.0   1.0    1.0   2.0   0.0    0.0   0.0   1.0   0.0    3.0   0.1958762886597938    19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   87.0  0.0   0.0    0.0   0.05434782608695652   5 / 92
0.0   0.0    0.0   3.0    2.0   1.0   0.0   1.0   1.0   0.0    3.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   85.0  0.0    1.0   0.15                  15 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   1.0    1.0   0.0    0.0   5.0   0.0    5.0   1.0   0.0   92.0   0.0   0.14018691588785046   15 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   0.0   0.0    79.0  0.09195402298850575   8 / 87
89.0  115.0  77.0  123.0  96.0  85.0  93.0  76.0  82.0  108.0  92.0  100.0  90.0  103.0  81.0  116.0  95.0  105.0  94.0  98.0  105.0  80.0  98.0  95.0  103.0  91.0  0.1357429718875502    338 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.864257
2    0.93253
3    0.958634
4    0.969076
5    0.978715
6    0.983936
7    0.986747
8    0.988755
9    0.991566
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:09  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:09  4 min  7.445 sec  41351 obs/sec     1         1             10007      0.540308         0.955855            0.994812       0.264521                         0.540751           0.954552              0.99479          0.265863
    2019-08-04 09:04:12  4 min 10.572 sec  31597 obs/sec     10        10            100070     0.374757         0.466959            0.997504       0.136059                         0.376883           0.474526              0.997469         0.135743
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0891312
C13         0.970376               0.970376             0.0864908
C9          0.913857               0.913857             0.0814531
C12         0.818942               0.818942             0.0729932
C8          0.799906               0.799906             0.0712966
C11         0.746398               0.746398             0.0665274
C7          0.739425               0.739425             0.0659058
C14         0.688658               0.688658             0.0613809
C10         0.678779               0.678779             0.0605004
C6          0.656771               0.656771             0.0585388
C5          0.653901               0.653901             0.058283
C16         0.630874               0.630874             0.0562306
C3          0.530433               0.530433             0.0472781
C4          0.503258               0.503258             0.044856
C2          0.453436               0.453436             0.0404153
C1          0.434406               0.434406             0.0387191
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_185

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013171049243396737  0.00036432489287108183  0.0         -0.007724490915421711  0.2015688419342041  0.24957333503570736   0.15431195497512817
    3        26       Softmax                      0.0   0.0   0.007275597421557205   0.029573775827884674    0.0         -0.2599578535046021    0.5120508670806885  -0.48542583002994344  0.12996381521224976


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13994277877163352
RMSE: 0.37408926577975143
LogLoss: 0.4609454896796666
Mean Per-Class Error: 0.132808877894741
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
370.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    4.0    4.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    2.0    1.0    1.0    4.0    0.0    0.06329113924050633  25 / 395
0.0    336.0  0.0    3.0    1.0    2.0    3.0    8.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    3.0    9.0    3.0    0.0    0.0    3.0    0.0    2.0    1.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    312.0  0.0    13.0   0.0    11.0   0.0    0.0    0.0    12.0   1.0    1.0    0.0    4.0    0.0    0.0    0.0    6.0    1.0    6.0    0.0    1.0    0.0    0.0    0.0    0.15217391304347827  56 / 368
0.0    21.0   0.0    347.0  0.0    0.0    1.0    5.0    0.0    4.0    0.0    0.0    7.0    4.0    2.0    1.0    0.0    5.0    2.0    2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.13895781637717122  56 / 403
0.0    7.0    4.0    0.0    317.0  6.0    19.0   1.0    0.0    0.0    4.0    5.0    0.0    0.0    0.0    1.0    2.0    3.0    4.0    3.0    0.0    0.0    0.0    1.0    0.0    7.0    0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    19.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    2.0    0.0    2.0    2.0    2.0    0.0    2.0    2.0    2.0    8.0    0.0    0.0    0.0    2.0    0.0    1.0    2.0    4.0    3.0    1.0    0.0    0.0    353.0  2.0    4.0    0.10406091370558376  41 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    0.0    2.0    5.0    2.0    13.0   1.0    0.0    354.0  0.0    0.09923664122137404  39 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    11.0   2.0    0.0    0.0    0.0    0.0    0.0    322.0  0.1226158038147139   45 / 367
386.0  443.0  341.0  411.0  385.0  409.0  381.0  342.0  347.0  380.0  375.0  377.0  451.0  366.0  406.0  391.0  368.0  400.0  377.0  362.0  407.0  385.0  378.0  399.0  385.0  351.0  0.13226032190342898  1,323 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86774
2    0.93252
3    0.958612
4    0.971509
5    0.980006
6    0.984805
7    0.987704
8    0.991103
9    0.993602
10   0.995801

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14421803795002427
RMSE: 0.3797605007765082
LogLoss: 0.4750111272286729
Mean Per-Class Error: 0.13989478323664117
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   88.0   0.0   0.0    1.0   0.0   1.0   4.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    1.0   3.0    1.0   0.0   0.0    3.0   0.0   1.0   1.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    65.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.2073170731707317    17 / 82
0.0   3.0    0.0   97.0   0.0   0.0   1.0   3.0   0.0   1.0    0.0   0.0   3.0   1.0   1.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.13392857142857142   15 / 112
0.0   1.0    1.0   0.0    76.0  4.0   5.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0   2.0   0.0    0.0   0.0   0.0   0.0    1.0   0.21649484536082475   21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   85.0  0.0   0.0    0.0   0.07608695652173914   7 / 92
0.0   0.0    0.0   2.0    1.0   1.0   0.0   1.0   0.0   0.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0   0.0    0.0   0.0   86.0  0.0    2.0   0.14                  14 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   3.0    1.0   0.0    0.0   1.0   0.0    5.0   1.0   0.0   95.0   0.0   0.11214953271028037   12 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218   10 / 87
89.0  108.0  73.0  113.0  91.0  99.0  96.0  86.0  82.0  109.0  98.0  96.0  97.0  98.0  90.0  109.0  94.0  101.0  92.0  84.0  102.0  92.0  95.0  97.0  111.0  88.0  0.14016064257028113   349 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.859839
2    0.932129
3    0.958635
4    0.969478
5    0.979518
6    0.982329
7    0.985141
8    0.988353
9    0.992771
10   0.996386
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:31  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:32  5 min 29.775 sec  51849 obs/sec     1         1             10007      0.546617         0.967458            0.994692       0.261222                         0.54486            0.95931               0.99471          0.263454
    2019-08-04 09:05:33  5 min 31.216 sec  62543 obs/sec     10        10            100070     0.374089         0.460945            0.997514       0.13226                          0.379761           0.475011              0.99743          0.140161
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0812604
C13         0.984511               0.984511             0.0800018
C9          0.949744               0.949744             0.0771766
C8          0.87662                0.87662              0.0712346
C7          0.87471                0.87471              0.0710793
C12         0.820909               0.820909             0.0667075
C11         0.779058               0.779058             0.0633066
C10         0.778582               0.778582             0.0632679
C5          0.744639               0.744639             0.0605097
C6          0.740851               0.740851             0.0602018
C14         0.708684               0.708684             0.057588
C16         0.68061                0.68061              0.0553067
C4          0.669255               0.669255             0.0543839
C3          0.643689               0.643689             0.0523064
C1          0.532133               0.532133             0.0432414
C2          0.522116               0.522116             0.0424274
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_24

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.00198288223926113   0.0005586163606494665  0.0         0.013389944500953987   0.33158981800079346  0.0052731695460819525  0.36405646800994873
    3        26       Softmax                 0.0   0.0   0.003261426892724837  0.0015789251774549484  0.0         0.0029168513588118117  0.4500776529312134   -0.5416454984100256    0.17378902435302734


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13822431896922194
RMSE: 0.37178531300902934
LogLoss: 0.4634602855133763
Mean Per-Class Error: 0.1339012984721871
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    4.0    1.0    2.0    7.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    2.0    0.0    0.0    2.0    5.0    4.0    0.08860759493670886  35 / 395
0.0    323.0  0.0    12.0   4.0    1.0    1.0    10.0   1.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    12.0   7.0    0.0    0.0    4.0    0.0    3.0    1.0    0.0    0.1544502617801047   59 / 382
0.0    0.0    318.0  1.0    13.0   1.0    8.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    7.0    0.0    1.0    1.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.1358695652173913   50 / 368
1.0    10.0   0.0    365.0  0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    6.0    4.0    1.0    0.0    0.0    5.0    2.0    0.0    2.0    0.0    0.0    4.0    0.0    0.0    0.09429280397022333  38 / 403
0.0    0.0    3.0    0.0    335.0  3.0    4.0    2.0    0.0    0.0    3.0    3.0    0.0    0.0    0.0    1.0    13.0   3.0    3.0    2.0    1.0    0.0    0.0    2.0    0.0    6.0    0.12760416666666666  49 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    15.0   0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    0.0    0.0    7.0    5.0    2.0    0.0    2.0    2.0    3.0    7.0    0.0    0.0    0.0    2.0    0.0    4.0    0.0    3.0    1.0    1.0    0.0    0.0    348.0  4.0    3.0    0.116751269035533    46 / 394
0.0    1.0    0.0    1.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    1.0    6.0    2.0    15.0   1.0    1.0    349.0  0.0    0.11195928753180662  44 / 393
0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    8.0    0.0    22.0   2.0    0.0    0.0    0.0    0.0    0.0    312.0  0.14986376021798364  55 / 367
378.0  455.0  345.0  447.0  412.0  396.0  333.0  313.0  325.0  373.0  361.0  364.0  427.0  372.0  384.0  366.0  411.0  423.0  416.0  379.0  418.0  367.0  394.0  404.0  396.0  344.0  0.13316005198440467  1,332 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86684
2    0.930921
3    0.956413
4    0.968609
5    0.978307
6    0.983505
7    0.987304
8    0.990303
9    0.992202
10   0.994002

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14284304141313756
RMSE: 0.37794581809187616
LogLoss: 0.4765822329452094
Mean Per-Class Error: 0.13762622984963768
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0    1.0    1.0    0.0   0.0    0.0   0.0   0.0   3.0    0.0   0.10112359550561797  9 / 89
0.0   84.0   0.0   4.0    2.0   0.0   1.0   4.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    4.0    2.0    0.0   0.0    3.0   0.0   1.0   0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    71.0  0.0    2.0   1.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   3.0   0.0    0.0    0.0    1.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.13414634146341464  11 / 82
1.0   2.0    0.0   99.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   1.0   0.0   0.0    0.0    1.0    1.0    0.0   1.0    0.0   0.0   2.0   0.0    0.0   0.11607142857142858  13 / 112
0.0   0.0    1.0   0.0    82.0  1.0   1.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    3.0    1.0    2.0    2.0   0.0    0.0   0.0   1.0   0.0    1.0   0.15463917525773196  15 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   1.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   1.0   0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   87.0  1.0    1.0   0.13                 13 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    3.0    0.0    0.0    1.0   0.0    4.0   1.0   0.0   94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0   0.0   0.0    2.0    0.0    5.0    0.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
84.0  112.0  78.0  122.0  98.0  91.0  85.0  83.0  79.0  109.0  89.0  91.0  97.0  98.0  83.0  104.0  105.0  112.0  108.0  88.0  105.0  80.0  99.0  99.0  112.0  79.0  0.13694779116465863  341 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.863052
2    0.928112
3    0.954217
4    0.967068
5    0.978313
6    0.985542
7    0.988755
8    0.99237
9    0.993976
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:46  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:46  44.376 sec  47880 obs/sec     1         1             10007      0.537655         0.953065            0.994862       0.250925                         0.537889           0.954528              0.994845         0.25502
    2019-08-04 09:00:48  46.505 sec  43603 obs/sec     10        10            100070     0.371785         0.46346             0.997543       0.13316                          0.377946           0.476582              0.997455         0.136948
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.090047
C13         0.978253               0.978253             0.0880887
C9          0.866165               0.866165             0.0779956
C12         0.826673               0.826673             0.0744394
C8          0.821239               0.821239             0.0739501
C10         0.768333               0.768333             0.069186
C7          0.741227               0.741227             0.0667453
C11         0.706014               0.706014             0.0635744
C16         0.675449               0.675449             0.0608222
C14         0.625232               0.625232             0.0563002
C6          0.603352               0.603352             0.05433
C5          0.590139               0.590139             0.0531403
C3          0.550266               0.550266             0.0495498
C4          0.489271               0.489271             0.0440574
C2          0.440121               0.440121             0.0396316
C1          0.423579               0.423579             0.038142
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_135

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.00199890810088732   0.0005511145573109388  0.0         0.0029869479617339323  0.3433622121810913   -0.025785829314527633  0.37275266647338867
    3        26       Softmax                 0.0   0.0   0.003131239036450167  0.001127821858972311   0.0         -0.001310591333125243  0.45265960693359375  -0.5186985249972652    0.13894975185394287


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1389392090595358
RMSE: 0.37274550172944515
LogLoss: 0.4650696007807619
Mean Per-Class Error: 0.13481290961859274
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    3.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    3.0    1.0    0.0    3.0    3.0    5.0    0.07848101265822785  31 / 395
0.0    325.0  0.0    10.0   3.0    1.0    1.0    8.0    3.0    0.0    3.0    2.0    0.0    0.0    0.0    7.0    0.0    7.0    5.0    0.0    0.0    5.0    0.0    2.0    1.0    0.0    0.1514360313315927   58 / 383
0.0    0.0    320.0  1.0    5.0    0.0    4.0    1.0    0.0    0.0    19.0   1.0    0.0    0.0    2.0    0.0    2.0    1.0    6.0    1.0    4.0    0.0    1.0    0.0    0.0    0.0    0.13043478260869565  48 / 368
0.0    12.0   0.0    346.0  0.0    2.0    0.0    14.0   1.0    1.0    1.0    0.0    4.0    4.0    1.0    2.0    0.0    3.0    1.0    0.0    3.0    0.0    0.0    2.0    0.0    6.0    0.141439205955335    57 / 403
0.0    0.0    2.0    0.0    328.0  6.0    16.0   1.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    1.0    2.0    3.0    3.0    4.0    0.0    0.0    0.0    2.0    0.0    7.0    0.14360313315926893  55 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    10.0   0.0    2.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    1.0    0.0    5.0    4.0    2.0    0.0    1.0    2.0    3.0    9.0    2.0    0.0    0.0    0.0    0.0    6.0    1.0    3.0    1.0    1.0    0.0    0.0    343.0  3.0    6.0    0.1272264631043257   50 / 393
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    5.0    2.0    0.0    1.0    7.0    4.0    15.0   1.0    1.0    350.0  0.0    0.10941475826972011  43 / 393
2.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    1.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    11.0   2.0    0.0    0.0    0.0    0.0    0.0    326.0  0.11171662125340599  41 / 367
383.0  437.0  336.0  413.0  397.0  423.0  356.0  340.0  355.0  368.0  404.0  363.0  405.0  373.0  384.0  406.0  372.0  399.0  373.0  372.0  426.0  377.0  392.0  397.0  383.0  369.0  0.134259722083375    1,343 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86574
2    0.929021
3    0.955013
4    0.969509
5    0.978007
6    0.982805
7    0.986404
8    0.990303
9    0.992602
10   0.994502

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14202881662076886
RMSE: 0.3768671073744283
LogLoss: 0.4781097932087188
Mean Per-Class Error: 0.13652413049700277
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0   1.0   2.0    1.0   0.0898876404494382   8 / 89
0.0   86.0   0.0   2.0    3.0   0.0   1.0   3.0   1.0   0.0    0.0    0.0   0.0   0.0   0.0   2.0    0.0   2.0    1.0   0.0   0.0    3.0   0.0   1.0   1.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    71.0  0.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.13414634146341464  11 / 82
0.0   1.0    0.0   95.0   0.0   0.0   0.0   5.0   1.0   1.0    0.0    0.0   2.0   1.0   0.0   1.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0   1.0   0.0    2.0   0.15178571428571427  17 / 112
0.0   0.0    1.0   0.0    79.0  3.0   4.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0   1.0   0.0    0.0   0.0   1.0   0.0    3.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   87.0  0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   4.0    2.0   0.0   0.0   0.0   0.0   1.0    3.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   86.0  1.0    1.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   2.0   0.0    5.0   1.0   0.0   96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0   0.0    79.0  0.09195402298850575  8 / 87
87.0  107.0  76.0  112.0  95.0  98.0  86.0  88.0  85.0  106.0  101.0  98.0  88.0  99.0  80.0  115.0  95.0  100.0  96.0  88.0  106.0  87.0  96.0  95.0  116.0  90.0  0.13694779116465863  341 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.863052
2    0.93012
3    0.955422
4    0.968273
5    0.977108
6    0.981928
7    0.985944
8    0.990763
9    0.991968
10   0.994378
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:45  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:45  3 min 43.568 sec  41522 obs/sec     1         1             10007      0.541981         0.959565            0.99478        0.262221                         0.539855           0.957363              0.994807         0.264659
    2019-08-04 09:03:48  3 min 45.808 sec  41062 obs/sec     10        10            100070     0.372746         0.46507             0.997531       0.13426                          0.376867           0.47811               0.997469         0.136948
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0895795
C13         0.927956               0.927956             0.0831259
C9          0.91066                0.91066              0.0815765
C12         0.889493               0.889493             0.0796804
C8          0.799733               0.799733             0.0716397
C7          0.743009               0.743009             0.0665584
C11         0.703314               0.703314             0.0630026
C16         0.694295               0.694295             0.0621946
C10         0.688315               0.688315             0.061659
C6          0.630732               0.630732             0.0565007
C14         0.621634               0.621634             0.0556857
C5          0.61029                0.61029              0.0546695
C3          0.549536               0.549536             0.0492272
C4          0.487031               0.487031             0.0436281
C2          0.46376                0.46376              0.0415434
C1          0.443505               0.443505             0.039729
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_89

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.001905370538565876  0.0005126530304551125  0.0         0.000610109449240781   0.34300529956817627  0.006651922732669116  0.3792695999145508
    3        26       Softmax                 0.0   0.0   0.00306058716096931   0.0014735651202499866  0.0         -0.016345515093401167  0.4501516819000244   -0.5347702717581208   0.1578029990196228


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13746346157223552
RMSE: 0.37076065267532843
LogLoss: 0.4609726579108829
Mean Per-Class Error: 0.1328530275188588
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    0.0    2.0    2.0    5.0    0.0    2.0    0.0    0.0    2.0    2.0    0.0    1.0    0.0    1.0    1.0    3.0    3.0    0.0759493670886076   30 / 395
0.0    340.0  1.0    4.0    3.0    1.0    1.0    5.0    3.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    0.0    6.0    10.0   0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    314.0  1.0    6.0    0.0    11.0   2.0    0.0    0.0    14.0   0.0    0.0    0.0    5.0    0.0    2.0    1.0    5.0    1.0    4.0    0.0    2.0    0.0    0.0    0.0    0.14673913043478262  54 / 368
1.0    15.0   0.0    358.0  0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    6.0    3.0    3.0    0.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    0.11166253101736973  45 / 403
0.0    2.0    2.0    0.0    331.0  7.0    13.0   0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    2.0    5.0    4.0    5.0    0.0    0.0    0.0    1.0    0.0    8.0    0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    9.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    1.0    0.0    7.0    5.0    3.0    0.0    1.0    3.0    2.0    6.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    2.0    0.0    0.0    350.0  3.0    4.0    0.1116751269035533   44 / 394
1.0    1.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    2.0    7.0    2.0    7.0    1.0    2.0    360.0  0.0    0.08396946564885496  33 / 393
2.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    13.0   4.0    0.0    0.0    0.0    4.0    0.0    320.0  0.12568306010928962  46 / 366
394.0  488.0  335.0  426.0  405.0  380.0  370.0  328.0  338.0  352.0  366.0  357.0  414.0  379.0  419.0  398.0  363.0  397.0  366.0  402.0  407.0  364.0  383.0  414.0  392.0  366.0  0.13196041187643706  1,320 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86804
2    0.931521
3    0.955413
4    0.96841
5    0.978007
6    0.983805
7    0.987304
8    0.989903
9    0.992003
10   0.993602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14299726620156522
RMSE: 0.37814979333799087
LogLoss: 0.4813565282778017
Mean Per-Class Error: 0.13337921110373538
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17    18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   1.0   0.0   1.0   0.0    0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.0898876404494382   8 / 89
0.0   91.0   0.0   2.0    1.0   1.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   2.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.14150943396226415  15 / 106
0.0   0.0    68.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0   2.0   1.0   1.0    0.0   1.0   0.0   0.0    0.0   0.17073170731707318  14 / 82
1.0   1.0    0.0   100.0  0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   3.0   1.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    2.0   0.10714285714285714  12 / 112
0.0   1.0    0.0   0.0    80.0  5.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   2.0   2.0   0.0    0.0   0.0   0.0   0.0    1.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   2.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    1.0   0.0   0.0   0.0   1.0   0.0    3.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   88.0  1.0    1.0   0.12                 12 / 100
1.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    2.0   0.0   0.0   0.0   0.0    3.0   1.0   0.0   97.0   0.0   0.09345794392523364  10 / 107
2.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   2.0   0.0    0.0   0.0   1.0   0.0    75.0  0.13793103448275862  12 / 87
91.0  127.0  70.0  118.0  93.0  93.0  94.0  82.0  84.0  103.0  94.0  93.0  94.0  99.0  90.0  115.0  96.0  97.0  87.0  97.0  102.0  82.0  93.0  99.0  110.0  87.0  0.13253012048192772  330 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86747
2    0.928916
3    0.953012
4    0.965863
5    0.977108
6    0.981124
7    0.98514
8    0.987952
9    0.991165
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:31  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:31  2 min 29.276 sec  44083 obs/sec     1         1             10007      0.539395         0.947671            0.994829       0.259222                         0.53804            0.940843              0.994842         0.268675
    2019-08-04 09:02:33  2 min 31.448 sec  42366 obs/sec     10        10            100070     0.370761         0.460973            0.997557       0.13196                          0.37815            0.481357              0.997452         0.13253
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0869951
C15         0.96479                0.96479              0.083932
C9          0.864156               0.864156             0.0751773
C8          0.853441               0.853441             0.0742452
C12         0.851226               0.851226             0.0740524
C7          0.788501               0.788501             0.0685957
C11         0.765255               0.765255             0.0665734
C14         0.746073               0.746073             0.0649046
C10         0.737886               0.737886             0.0641924
C6          0.679891               0.679891             0.0591472
C16         0.679214               0.679214             0.0590882
C5          0.6553                 0.6553               0.0570078
C3          0.524428               0.524428             0.0456227
C4          0.515095               0.515095             0.0448107
C2          0.435257               0.435257             0.0378652
C1          0.434393               0.434393             0.03779
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_180

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0018615733384024225  0.0004768505459651351  0.0         -0.0004957550432393987  0.33845674991607666  -0.03734765746584814  0.3681144714355469
    3        26       Softmax                 0.0   0.0   0.0028255137962542695  0.0010894909501075745  0.0         0.016908579220057618    0.4527524709701538   -0.5284927956514924   0.17221617698669434


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13892003199871936
RMSE: 0.3727197767743474
LogLoss: 0.4692396596420167
Mean Per-Class Error: 0.1307412056985265
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    6.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    2.0    0.0    1.0    0.0    6.0    4.0    0.07614213197969544  30 / 394
0.0    342.0  1.0    8.0    2.0    1.0    1.0    12.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    5.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.10704960835509138  41 / 383
0.0    1.0    316.0  1.0    5.0    1.0    14.0   1.0    0.0    0.0    12.0   1.0    0.0    0.0    6.0    0.0    2.0    1.0    2.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    0.14130434782608695  52 / 368
0.0    13.0   0.0    356.0  0.0    1.0    0.0    3.0    0.0    3.0    0.0    0.0    6.0    5.0    3.0    2.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    2.0    0.11662531017369727  47 / 403
0.0    4.0    4.0    0.0    321.0  5.0    15.0   2.0    1.0    0.0    4.0    2.0    0.0    0.0    0.0    1.0    1.0    3.0    4.0    5.0    0.0    0.0    0.0    4.0    0.0    8.0    0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    6.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    7.0    2.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    1.0    0.0    5.0    3.0    2.0    0.0    1.0    5.0    4.0    8.0    1.0    0.0    1.0    0.0    0.0    7.0    2.0    1.0    9.0    1.0    0.0    0.0    337.0  4.0    2.0    0.1446700507614213   57 / 394
2.0    1.0    0.0    2.0    0.0    5.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    4.0    1.0    9.0    1.0    0.0    362.0  0.0    0.07888040712468193  31 / 393
2.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    7.0    4.0    0.0    0.0    0.0    0.0    0.0    331.0  0.09809264305177112  36 / 367
397.0  461.0  331.0  437.0  368.0  377.0  389.0  354.0  342.0  383.0  366.0  357.0  407.0  386.0  421.0  380.0  373.0  370.0  345.0  412.0  408.0  374.0  382.0  389.0  413.0  381.0  0.13016095171448566  1,302 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869839
2    0.930621
3    0.954914
4    0.96841
5    0.975507
6    0.982205
7    0.987204
8    0.989703
9    0.991903
10   0.994002

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1410421995695155
RMSE: 0.3755558541276058
LogLoss: 0.48140489451936547
Mean Per-Class Error: 0.13077084455867305
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17    18    19     20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0   3.0    1.0   0.056179775280898875  5 / 89
0.0   90.0   0.0   3.0    2.0   0.0   1.0   5.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   2.0   0.0   0.0    0.0    1.0   0.0   1.0   0.0    0.0   0.1509433962264151    16 / 106
0.0   0.0    68.0  0.0    2.0   0.0   2.0   1.0   0.0   0.0    2.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0   2.0   1.0    0.0    0.0   0.0   0.0   0.0    0.0   0.17073170731707318   14 / 82
0.0   1.0    0.0   100.0  0.0   0.0   0.0   2.0   0.0   1.0    0.0   0.0   2.0   2.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   1.0   0.0    1.0   0.10714285714285714   12 / 112
0.0   0.0    0.0   0.0    77.0  4.0   4.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0   2.0   2.0    0.0    0.0   0.0   1.0   0.0    3.0   0.20618556701030927   20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    3.0    0.0   88.0  0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   3.0    1.0   1.0   0.0   1.0   0.0   1.0    4.0   1.0   0.0   0.0    0.0   0.0    1.0   2.0   0.0   1.0    0.0    0.0   0.0   83.0  0.0    1.0   0.17                  17 / 100
1.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0   1.0    0.0    4.0   1.0   0.0   96.0   0.0   0.102803738317757     11 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0   0.0    78.0  0.10344827586206896   9 / 87
90.0  111.0  68.0  124.0  87.0  89.0  98.0  92.0  82.0  111.0  96.0  96.0  87.0  101.0  85.0  111.0  96.0  95.0  81.0  102.0  105.0  83.0  95.0  93.0  118.0  94.0  0.13052208835341367   325 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869478
2    0.927711
3    0.954619
4    0.967068
5    0.975904
6    0.981928
7    0.986747
8    0.989157
9    0.991968
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:22  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:22  5 min 20.319 sec  43890 obs/sec     1         1             10007      0.536319         0.942383            0.994888       0.252224                         0.534923           0.942181              0.994901         0.253815
    2019-08-04 09:05:24  5 min 22.478 sec  42764 obs/sec     10        10            100070     0.37272          0.46924             0.997531       0.130161                         0.375556           0.481405              0.997487         0.130522
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0874514
C15         0.99416                0.99416              0.0869407
C9          0.902208               0.902208             0.0788994
C12         0.872835               0.872835             0.0763306
C8          0.808993               0.808993             0.0707475
C11         0.767817               0.767817             0.0671467
C10         0.725304               0.725304             0.0634288
C7          0.699705               0.699705             0.0611902
C16         0.685372               0.685372             0.0599368
C5          0.680851               0.680851             0.0595414
C6          0.672466               0.672466             0.0588081
C14         0.661062               0.661062             0.0578108
C3          0.57378                0.57378              0.0501778
C4          0.490217               0.490217             0.0428701
C2          0.455188               0.455188             0.0398068
C1          0.444965               0.444965             0.0389128
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_177

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0019062210596416662  0.0005875763017684221  0.0         0.012711356028997756   0.3350285291671753   0.02309340434960396  0.3679530620574951
    3        26       Softmax                 0.0   0.0   0.0029697062586470004  0.0012070420198142529  0.0         -0.018935491439724325  0.44497859477996826  -0.5409537331270916  0.14774048328399658


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14254960489781646
RMSE: 0.3775574193388556
LogLoss: 0.47797346244996697
Mean Per-Class Error: 0.13734310382119247
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    2.0    4.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    2.0    0.0    3.0    3.0    4.0    0.07868020304568528  31 / 394
0.0    333.0  2.0    8.0    3.0    0.0    0.0    12.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    2.0    8.0    7.0    0.0    0.0    2.0    0.0    1.0    1.0    1.0    0.13054830287206268  50 / 383
0.0    0.0    320.0  1.0    4.0    0.0    10.0   0.0    0.0    0.0    10.0   1.0    0.0    0.0    4.0    0.0    0.0    2.0    5.0    1.0    9.0    0.0    0.0    0.0    0.0    0.0    0.12806539509536785  47 / 367
1.0    16.0   0.0    355.0  0.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    3.0    7.0    1.0    1.0    0.0    7.0    0.0    0.0    1.0    0.0    0.0    6.0    0.0    0.0    0.11910669975186104  48 / 403
0.0    5.0    1.0    1.0    327.0  8.0    11.0   1.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    6.0    3.0    8.0    0.0    0.0    0.0    0.0    2.0    0.0    7.0    0.1484375            57 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    6.0    0.0    0.0    7.0    0.0    0.0    3.0    0.0    348.0  0.0    0.0    0.0    0.072                27 / 375
0.0    4.0    1.0    6.0    5.0    3.0    0.0    3.0    4.0    1.0    5.0    2.0    0.0    0.0    2.0    0.0    4.0    0.0    1.0    1.0    1.0    0.0    0.0    346.0  3.0    2.0    0.1218274111675127   48 / 394
1.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    0.0    2.0    11.0   2.0    17.0   1.0    1.0    342.0  1.0    0.1297709923664122   51 / 393
4.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    34.0   4.0    0.0    0.0    0.0    0.0    0.0    302.0  0.17486338797814208  64 / 366
399.0  470.0  370.0  429.0  386.0  366.0  325.0  332.0  344.0  354.0  364.0  356.0  397.0  396.0  391.0  412.0  385.0  440.0  413.0  391.0  419.0  370.0  379.0  397.0  375.0  343.0  0.13665900229931022  1,367 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.863341
2    0.93192
3    0.957813
4    0.96781
5    0.974608
6    0.981106
7    0.985504
8    0.988204
9    0.990903
10   0.992802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14468981436662495
RMSE: 0.38038114354765923
LogLoss: 0.4845197701230319
Mean Per-Class Error: 0.14243240374908372
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17    18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.0449438202247191   4 / 89
0.0   87.0   1.0   2.0    2.0   0.0   0.0   5.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   2.0   2.0   0.0   0.0    2.0   0.0   1.0    1.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    71.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   2.0   1.0   1.0    0.0   0.0   0.0    0.0    0.0   0.13414634146341464  11 / 82
0.0   2.0    0.0   99.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   2.0    1.0   1.0    0.0   1.0   0.0   0.0   1.0    0.0   0.0   3.0    0.0    0.0   0.11607142857142858  13 / 112
0.0   0.0    0.0   0.0    80.0  4.0   3.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   4.0   0.0   0.0    0.0   0.0   1.0    0.0    3.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   1.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   1.0    0.0   3.0    3.0   0.0   0.0   2.0   1.0   0.0    1.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   86.0   1.0    1.0   0.14                 14 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0   0.0   4.0   0.0    4.0   1.0   0.0    94.0   0.0   0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   6.0   1.0   0.0    0.0   0.0   0.0    0.0    73.0  0.16091954022988506  14 / 87
95.0  114.0  81.0  120.0  99.0  79.0  79.0  88.0  84.0  103.0  94.0  95.0  83.0  105.0  85.0  122.0  91.0  99.0  99.0  94.0  107.0  83.0  95.0  103.0  109.0  84.0  0.14136546184738955  352 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.858635
2    0.932932
3    0.956225
4    0.968273
5    0.975904
6    0.981124
7    0.985542
8    0.987952
9    0.989558
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:13  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:13  5 min 11.227 sec  42046 obs/sec     1         1             10007      0.538868         0.953246            0.994837       0.256023                         0.538128           0.949003              0.99484          0.254618
    2019-08-04 09:05:15  5 min 13.391 sec  42277 obs/sec     10        10            100070     0.377557         0.477973            0.997465       0.136659                         0.380381           0.48452               0.997422         0.141365
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0883736
C15         0.997883               0.997883             0.0881865
C12         0.890485               0.890485             0.0786954
C9          0.862544               0.862544             0.0762262
C8          0.805204               0.805204             0.0711588
C7          0.756512               0.756512             0.0668557
C10         0.708634               0.708634             0.0626246
C11         0.684311               0.684311             0.0604751
C14         0.668616               0.668616             0.0590881
C5          0.654017               0.654017             0.0577979
C6          0.644755               0.644755             0.0569793
C16         0.636461               0.636461             0.0562464
C3          0.594331               0.594331             0.0525232
C4          0.512708               0.512708             0.0453098
C2          0.45083                0.45083              0.0398415
C1          0.4483                 0.4483               0.0396179
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_191

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002248015124223457   0.0005926070734858513  0.0         0.006181056146971287   0.2999356985092163  -0.002883205493862724  0.3702719211578369
    3        26       Softmax                 0.0   0.0   0.0027548676564667684  0.001081101130694151   0.0         -0.005530829666451353  0.318820595741272   -0.5692849925820075    0.1897432804107666


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1408907090883609
RMSE: 0.3753541115911226
LogLoss: 0.4735920054490505
Mean Per-Class Error: 0.14160967043310016
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    1.0    0.0    2.0    0.0    5.0    3.0    0.08354430379746836  33 / 395
0.0    330.0  2.0    8.0    2.0    1.0    2.0    12.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    10.0   5.0    0.0    0.0    1.0    1.0    3.0    1.0    0.0    0.13838120104438642  53 / 383
0.0    0.0    316.0  1.0    6.0    0.0    19.0   1.0    0.0    0.0    9.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    2.0    5.0    0.0    2.0    0.0    0.0    0.0    0.14130434782608695  52 / 368
1.0    18.0   0.0    346.0  0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    5.0    4.0    3.0    2.0    0.0    6.0    3.0    1.0    3.0    0.0    0.0    3.0    0.0    2.0    0.141439205955335    57 / 403
0.0    11.0   8.0    0.0    302.0  5.0    18.0   0.0    1.0    0.0    2.0    2.0    0.0    0.0    0.0    1.0    1.0    3.0    4.0    6.0    0.0    0.0    0.0    6.0    0.0    14.0   0.21354166666666666  82 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    2.0    8.0    0.0    0.0    0.0    0.0    10.0   0.0    5.0    0.0    1.0    1.0    0.0    0.0    3.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    2.0    0.0    4.0    4.0    2.0    0.0    5.0    2.0    2.0    8.0    1.0    0.0    0.0    0.0    1.0    7.0    0.0    1.0    3.0    1.0    0.0    0.0    345.0  2.0    4.0    0.12436548223350254  49 / 394
0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    7.0    1.0    6.0    1.0    1.0    368.0  0.0    0.06361323155216285  25 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    15.0   3.0    0.0    0.0    0.0    0.0    0.0    328.0  0.10626702997275204  39 / 367
390.0  433.0  347.0  411.0  361.0  338.0  422.0  375.0  356.0  372.0  366.0  356.0  404.0  380.0  394.0  406.0  383.0  381.0  347.0  409.0  411.0  356.0  392.0  400.0  420.0  393.0  0.14085774267719683  1,409 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.859142
2    0.929721
3    0.955113
4    0.96691
5    0.975307
6    0.982005
7    0.987304
8    0.989303
9    0.991403
10   0.993602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1447346998171584
RMSE: 0.3804401395977538
LogLoss: 0.4867970318959491
Mean Per-Class Error: 0.1480684820340509
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7      8     9      10    11    12    13    14    15     16    17    18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0    0.0   1.0    0.0   3.0    0.0    0.06741573033707865  6 / 89
0.0   82.0   1.0   3.0    2.0   0.0   2.0    5.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   4.0   2.0   0.0   0.0    1.0   1.0    1.0   1.0    0.0    0.22641509433962265  24 / 106
0.0   0.0    67.0  0.0    1.0   0.0   4.0    0.0    0.0   0.0    1.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0   0.0   2.0   2.0    0.0   1.0    0.0   0.0    0.0    0.18292682926829268  15 / 82
1.0   2.0    0.0   96.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0   0.0   1.0   1.0   2.0   2.0    0.0   0.0   0.0   0.0   2.0    0.0   0.0    1.0   0.0    1.0    0.14285714285714285  16 / 112
0.0   2.0    2.0   0.0    69.0  4.0   5.0    0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0   3.0   0.0    0.0   0.0    1.0   0.0    8.0    0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   1.0    0.0   87.0   0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0    3.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    85.0  0.0    2.0    0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0   0.0   1.0   0.0    3.0   1.0    0.0   100.0  0.0    0.06542056074766354  7 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    80.0   0.08045977011494253  7 / 87
89.0  103.0  70.0  113.0  85.0  75.0  110.0  102.0  86.0  104.0  94.0  92.0  86.0  99.0  90.0  118.0  94.0  93.0  81.0  95.0  107.0  81.0  100.0  97.0  123.0  103.0  0.14738955823293173  367 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.85261
2    0.930924
3    0.954618
4    0.964659
5    0.974297
6    0.980321
7    0.98755
8    0.989157
9    0.990763
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:37  5 min 35.684 sec  25080 obs/sec     1         1             10007      0.52421          0.929606            0.995118       0.252624                         0.523656           0.925967              0.995114         0.257028
    2019-08-04 09:05:41  5 min 39.380 sec  24794 obs/sec     10        10            100070     0.375354         0.473592            0.997497       0.140858                         0.38044            0.486797              0.997421         0.14739
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.086777
C15         0.995306               0.995306             0.0863697
C9          0.884025               0.884025             0.076713
C12         0.846291               0.846291             0.0734386
C7          0.801814               0.801814             0.069579
C8          0.799044               0.799044             0.0693386
C10         0.77539                0.77539              0.0672861
C11         0.715098               0.715098             0.062054
C14         0.681322               0.681322             0.0591231
C16         0.67287                0.67287              0.0583896
C5          0.662104               0.662104             0.0574554
C6          0.629971               0.629971             0.054667
C3          0.597114               0.597114             0.0518158
C4          0.543724               0.543724             0.0471827
C1          0.464401               0.464401             0.0402994
C2          0.455316               0.455316             0.039511
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_115

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight              weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  -----------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0019693337036699177  0.0005677123554050922  0.0         -0.00012153539741888153  0.34417450428009033  0.07089773534584147  0.34422528743743896
    3        26       Softmax                 0.0   0.0   0.002915112880425743   0.001020004041492939   0.0         -0.020335985266993744    0.4438915252685547   -0.532011593745847   0.12357604503631592


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14070549938797805
RMSE: 0.37510731716133994
LogLoss: 0.47297326087412594
Mean Per-Class Error: 0.13471640749736313
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    6.0    1.0    1.0    5.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    2.0    2.0    3.0    3.0    4.0    0.08860759493670886   35 / 395
0.0    340.0  1.0    12.0   2.0    0.0    5.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    6.0    1.0    0.0    0.0    1.0    0.0    2.0    1.0    1.0    0.1122715404699739    43 / 383
0.0    0.0    324.0  0.0    2.0    1.0    11.0   2.0    0.0    0.0    13.0   3.0    0.0    0.0    4.0    0.0    3.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    0.11956521739130435   44 / 368
0.0    14.0   0.0    360.0  0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    4.0    5.0    1.0    0.0    0.0    9.0    1.0    0.0    3.0    0.0    0.0    2.0    0.0    1.0    0.10669975186104218   43 / 403
0.0    4.0    7.0    0.0    323.0  4.0    12.0   1.0    1.0    0.0    2.0    4.0    0.0    0.0    0.0    1.0    8.0    1.0    3.0    3.0    1.0    0.0    0.0    4.0    0.0    5.0    0.15885416666666666   61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    7.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    353.0  0.0    0.0    0.0    0.061170212765957445  23 / 376
0.0    3.0    0.0    5.0    2.0    0.0    0.0    4.0    3.0    2.0    9.0    2.0    0.0    0.0    2.0    1.0    5.0    0.0    4.0    1.0    1.0    0.0    0.0    344.0  3.0    3.0    0.12690355329949238   50 / 394
0.0    0.0    0.0    1.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    12.0   1.0    11.0   1.0    1.0    356.0  0.0    0.09414758269720101   37 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    19.0   4.0    0.0    0.0    0.0    2.0    0.0    313.0  0.14713896457765668   54 / 367
379.0  489.0  347.0  448.0  369.0  388.0  424.0  294.0  333.0  383.0  346.0  371.0  397.0  387.0  369.0  363.0  382.0  425.0  367.0  387.0  418.0  369.0  392.0  426.0  396.0  354.0  0.13395981205638308   1,340 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86604
2    0.930421
3    0.954714
4    0.96611
5    0.974908
6    0.981006
7    0.986304
8    0.989603
9    0.992002
10   0.994202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14472738988758654
RMSE: 0.38043053227571855
LogLoss: 0.4876206738410092
Mean Per-Class Error: 0.1334185283284051
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   1.0   0.0    2.0    1.0   0.06741573033707865   6 / 89
0.0   86.0   0.0   4.0    2.0   0.0   4.0    4.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0    1.0   0.0   1.0    1.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    71.0  0.0    2.0   1.0   2.0    1.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.13414634146341464   11 / 82
0.0   1.0    0.0   103.0  0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   0.0   1.0    0.0    1.0   0.08035714285714286   9 / 112
0.0   0.0    1.0   0.0    80.0  2.0   3.0    0.0   0.0   0.0    2.0   2.0    0.0   0.0    0.0   0.0    2.0   0.0    1.0   1.0   0.0    0.0   0.0   1.0    0.0    2.0   0.17525773195876287   17 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    1.0   88.0  0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0    1.0   1.0   0.0    3.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.0   0.0    0.0   0.0   87.0   0.0    1.0   0.13                  13 / 100
0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   3.0   0.0    5.0   1.0   0.0    96.0   0.0   0.102803738317757     11 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0   0.0   4.0    0.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   2.0   0.0    0.0   0.0   0.0    0.0    74.0  0.14942528735632185   13 / 87
85.0  115.0  72.0  128.0  95.0  91.0  105.0  77.0  80.0  108.0  87.0  100.0  88.0  105.0  74.0  100.0  96.0  106.0  93.0  91.0  106.0  84.0  99.0  105.0  115.0  85.0  0.13293172690763053   331 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.867068
2    0.931727
3    0.952611
4    0.964659
5    0.974699
6    0.981928
7    0.986747
8    0.988755
9    0.991165
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:15  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:15  3 min 13.169 sec  41695 obs/sec     1         1             10007      0.540674         0.954146            0.994806       0.252124                         0.540374           0.951092              0.994797         0.25743
    2019-08-04 09:03:17  3 min 15.310 sec  42637 obs/sec     10        10            100070     0.375107         0.472973            0.9975         0.13396                          0.380431           0.487621              0.997421         0.132932
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0903177
C13         0.969857               0.969857             0.0875953
C8          0.929916               0.929916             0.0839879
C9          0.850411               0.850411             0.0768072
C12         0.792801               0.792801             0.071604
C11         0.719641               0.719641             0.0649963
C7          0.708657               0.708657             0.0640043
C10         0.674089               0.674089             0.0608822
C14         0.643088               0.643088             0.0580822
C16         0.636757               0.636757             0.0575105
C5          0.633164               0.633164             0.057186
C6          0.610192               0.610192             0.0551112
C3          0.532979               0.532979             0.0481375
C4          0.50591                0.50591              0.0456926
C1          0.435672               0.435672             0.0393489
C2          0.428888               0.428888             0.0387362
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_104

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight              weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  -----------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002382049749726889  0.0006394302472472191  0.0         -0.001727168720929484    0.30390143394470215  -0.015606589443742247  0.35138797760009766
    3        26       Softmax                 0.0   0.0   0.0028983266992537    0.000952206552028656   0.0         -0.00014056923312275252  0.32250261306762695  -0.5517680090374584    0.1348872184753418


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13988849156143196
RMSE: 0.3740166995756098
LogLoss: 0.47792617910528096
Mean Per-Class Error: 0.141911928730927
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
375.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    3.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    1.0    0.0    3.0    2.0    0.05063291139240506  20 / 395
0.0    352.0  0.0    8.0    2.0    0.0    2.0    3.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    4.0    7.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.08093994778067885  31 / 383
0.0    0.0    312.0  0.0    8.0    1.0    12.0   3.0    0.0    0.0    11.0   4.0    0.0    0.0    3.0    0.0    2.0    1.0    3.0    3.0    4.0    0.0    1.0    0.0    0.0    0.0    0.15217391304347827  56 / 368
1.0    15.0   0.0    362.0  0.0    1.0    0.0    1.0    0.0    2.0    0.0    0.0    1.0    8.0    2.0    1.0    0.0    5.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    0.0    0.10173697270471464  41 / 403
0.0    6.0    2.0    0.0    316.0  4.0    18.0   0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    1.0    3.0    4.0    6.0    5.0    1.0    0.0    0.0    6.0    0.0    6.0    0.17708333333333334  68 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    4.0    0.0    0.0    1.0    0.0    0.0    4.0    3.0    354.0  0.0    0.0    0.0    0.05851063829787234  22 / 376
0.0    3.0    0.0    6.0    5.0    1.0    0.0    1.0    5.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    1.0    1.0    0.0    0.0    354.0  1.0    4.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    4.0    0.0    0.0    10.0   2.0    24.0   1.0    3.0    343.0  0.0    0.1272264631043257   50 / 393
4.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    2.0    1.0    16.0   4.0    0.0    0.0    0.0    1.0    0.0    320.0  0.12806539509536785  47 / 367
434.0  527.0  323.0  456.0  376.0  345.0  408.0  301.0  342.0  342.0  334.0  380.0  373.0  402.0  368.0  414.0  361.0  400.0  342.0  390.0  412.0  376.0  424.0  438.0  381.0  354.0  0.14095771268619414  1,410 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.859042
2    0.927922
3    0.954814
4    0.96791
5    0.976607
6    0.982205
7    0.986404
8    0.989403
9    0.992202
10   0.993902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14266300243999377
RMSE: 0.3777075620635544
LogLoss: 0.4894410086770417
Mean Per-Class Error: 0.14261480202717763
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                 Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
85.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0449438202247191    4 / 89
0.0    91.0   0.0   3.0    2.0   0.0   1.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0    2.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.14150943396226415   15 / 106
0.0    0.0    68.0  0.0    2.0   0.0   1.0   1.0   0.0   0.0   3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0   2.0   1.0    0.0   0.0    0.0    0.0    0.0   0.17073170731707318   14 / 82
1.0    1.0    0.0   101.0  0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0    1.0    0.0    0.0   0.09821428571428571   11 / 112
0.0    1.0    1.0   0.0    75.0  3.0   6.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0   4.0   0.0    0.0   0.0    1.0    0.0    0.0   0.2268041237113402    22 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0    1.0    0.0   3.0    3.0   0.0   0.0   1.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    88.0   0.0    2.0   0.12                  12 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   2.0   0.0    9.0   1.0    0.0    92.0   0.0   0.14018691588785046   15 / 107
2.0    0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0   0.0   3.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0    0.0    0.0    77.0  0.11494252873563218   10 / 87
101.0  132.0  70.0  129.0  89.0  82.0  99.0  79.0  81.0  99.0  85.0  97.0  82.0  106.0  78.0  116.0  89.0  102.0  88.0  97.0  104.0  90.0  101.0  104.0  107.0  83.0  0.14176706827309238   353 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.858233
2    0.927309
3    0.956225
4    0.96747
5    0.975904
6    0.979518
7    0.984739
8    0.989157
9    0.991968
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:56  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:56  2 min 54.225 sec  24526 obs/sec     1         1             10007      0.517186         0.922087            0.995247       0.251924                         0.5185             0.923539              0.99521          0.259839
    2019-08-04 09:03:00  2 min 57.903 sec  24917 obs/sec     10        10            100070     0.374017         0.477926            0.997514       0.140958                         0.377708           0.489441              0.997458         0.141767
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0863708
C13         0.983005               0.983005             0.0849029
C12         0.887659               0.887659             0.0766679
C9          0.860663               0.860663             0.0743362
C8          0.842996               0.842996             0.0728102
C11         0.776114               0.776114             0.0670336
C7          0.76566                0.76566              0.0661307
C10         0.752148               0.752148             0.0649636
C5          0.712457               0.712457             0.0615355
C14         0.67934                0.67934              0.0586752
C16         0.654797               0.654797             0.0565554
C6          0.62416                0.62416              0.0539092
C3          0.600637               0.600637             0.0518775
C4          0.514341               0.514341             0.0444241
C2          0.478843               0.478843             0.0413581
C1          0.445163               0.445163             0.0384491
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_45

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002444131261881921   0.0006763734854757786  0.0         -0.0009085890167987998  0.3064042329788208   0.021165399892917266  0.3790464401245117
    3        26       Softmax                 0.0   0.0   0.0029289700549515354  0.0011007287539541721  0.0         0.007435780025770756    0.31475400924682617  -0.5640746966376635   0.14393079280853271


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14059088385469257
RMSE: 0.37495450904702105
LogLoss: 0.4783296685447401
Mean Per-Class Error: 0.13974358946970433
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    4.0    2.0    3.0    2.0    0.0    0.0    0.0    1.0    3.0    2.0    1.0    1.0    1.0    2.0    3.0    4.0    0.08860759493670886  35 / 395
0.0    325.0  0.0    6.0    3.0    0.0    1.0    13.0   2.0    0.0    4.0    0.0    0.0    0.0    0.0    3.0    1.0    14.0   7.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.14921465968586387  57 / 382
0.0    0.0    320.0  1.0    7.0    0.0    5.0    2.0    0.0    0.0    16.0   2.0    0.0    0.0    3.0    0.0    0.0    0.0    4.0    1.0    5.0    0.0    2.0    0.0    0.0    0.0    0.13043478260869565  48 / 368
1.0    12.0   0.0    345.0  0.0    0.0    0.0    7.0    0.0    1.0    5.0    0.0    7.0    4.0    1.0    4.0    0.0    7.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    0.14392059553349876  58 / 403
0.0    5.0    2.0    0.0    322.0  3.0    15.0   2.0    0.0    0.0    5.0    4.0    0.0    0.0    0.0    1.0    4.0    3.0    2.0    3.0    1.0    0.0    0.0    5.0    0.0    7.0    0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    14.0   0.0    5.0    0.0    0.0    1.0    0.0    0.0    3.0    4.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    1.0    0.0    7.0    4.0    1.0    0.0    2.0    3.0    1.0    11.0   2.0    0.0    0.0    3.0    1.0    3.0    0.0    5.0    1.0    1.0    0.0    0.0    342.0  4.0    2.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    4.0    0.0    1.0    2.0    1.0    16.0   1.0    3.0    354.0  0.0    0.09923664122137404  39 / 393
2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    23.0   2.0    0.0    0.0    0.0    0.0    0.0    317.0  0.1362397820163488   50 / 367
380.0  416.0  353.0  417.0  401.0  385.0  333.0  370.0  351.0  352.0  400.0  365.0  416.0  380.0  402.0  396.0  364.0  413.0  425.0  359.0  409.0  387.0  383.0  405.0  388.0  353.0  0.13915825252424271  1,392 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.860842
2    0.925622
3    0.954114
4    0.96801
5    0.978406
6    0.983205
7    0.986404
8    0.990003
9    0.991403
10   0.993902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.144868328960936
RMSE: 0.38061572348096184
LogLoss: 0.49307427101297896
Mean Per-Class Error: 0.1406802718119982
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   86.0   0.0   1.0    2.0    0.0   1.0   3.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   1.0    0.0   7.0    1.0    0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    69.0  0.0    3.0    0.0   0.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   1.0    0.0   95.0   0.0    0.0   0.0   3.0   0.0   0.0    2.0    0.0   3.0   1.0    0.0   2.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.15178571428571427  17 / 112
0.0   0.0    1.0   0.0    78.0   2.0   6.0   0.0   0.0   0.0    2.0    2.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0    1.0   0.0    0.0   0.0   1.0   0.0    2.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   1.0    2.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    2.0    0.0   0.0   1.0   0.0   0.0    5.0    2.0   0.0   0.0    1.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   83.0  1.0    2.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0    0.0   2.0    2.0   0.0    0.0    0.0   0.0    5.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0    0.0   0.0    0.0   0.0   0.0   0.0    76.0  0.12643678160919541  11 / 87
88.0  104.0  75.0  116.0  100.0  88.0  85.0  96.0  86.0  101.0  102.0  97.0  91.0  101.0  83.0  114.0  91.0  104.0  104.0  87.0  103.0  88.0  95.0  95.0  110.0  86.0  0.14056224899598393  350 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.859438
2    0.929317
3    0.951004
4    0.965863
5    0.976707
6    0.983133
7    0.986747
8    0.989558
9    0.991165
10   0.994378
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:18  1 min 16.762 sec  24347 obs/sec     1         1             10007      0.521825         0.915314            0.995161       0.247126                         0.522789           0.919196              0.99513          0.258233
    2019-08-04 09:01:22  1 min 20.609 sec  23917 obs/sec     10        10            100070     0.374955         0.47833             0.997502       0.139158                         0.380616           0.493074              0.997419         0.140562
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.088732
C13         0.991381               0.991381             0.0879672
C9          0.876799               0.876799             0.0778001
C8          0.843101               0.843101             0.07481
C12         0.821461               0.821461             0.0728899
C11         0.728119               0.728119             0.0646074
C10         0.71773                0.71773              0.0636856
C7          0.711471               0.711471             0.0631302
C5          0.655599               0.655599             0.0581726
C14         0.645009               0.645009             0.0572329
C16         0.638486               0.638486             0.0566541
C6          0.610254               0.610254             0.054149
C3          0.575679               0.575679             0.0510812
C4          0.548864               0.548864             0.0487017
C1          0.454346               0.454346             0.040315
C2          0.451596               0.451596             0.040071
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_167

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0022682963169842196  0.0006133343558758497  0.0         -0.002241902013862429  0.30531489849090576  0.010167325277672955  0.34765875339508057
    3        26       Softmax                 0.0   0.0   0.0027252115992793665  0.0010669417679309845  0.0         0.0048483299870914955  0.3167339563369751   -0.541491253775006    0.13915973901748657


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1414346488087518
RMSE: 0.37607798235040535
LogLoss: 0.48680661319991336
Mean Per-Class Error: 0.14403983345201038
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    3.0    4.0    0.0    0.0    0.0    0.0    3.0    6.0    0.0    1.0    1.0    2.0    0.0    4.0    1.0    0.07848101265822785  31 / 395
0.0    346.0  1.0    4.0    2.0    0.0    1.0    5.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    9.0    6.0    0.0    0.0    1.0    0.0    3.0    0.0    1.0    0.09660574412532637  37 / 383
0.0    0.0    316.0  1.0    5.0    1.0    10.0   0.0    0.0    0.0    14.0   3.0    0.0    0.0    4.0    0.0    2.0    1.0    4.0    3.0    3.0    0.0    1.0    0.0    0.0    0.0    0.14130434782608695  52 / 368
1.0    25.0   0.0    338.0  0.0    0.0    0.0    3.0    1.0    3.0    0.0    0.0    6.0    4.0    5.0    2.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    0.16129032258064516  65 / 403
0.0    3.0    6.0    0.0    315.0  7.0    19.0   0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    1.0    1.0    3.0    6.0    2.0    1.0    0.0    0.0    5.0    0.0    9.0    0.17754569190600522  68 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    5.0    0.0    0.0    1.0    0.0    0.0    7.0    1.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    0.0    0.0    5.0    2.0    1.0    0.0    3.0    4.0    5.0    10.0   2.0    0.0    0.0    2.0    0.0    4.0    1.0    1.0    1.0    1.0    0.0    0.0    344.0  5.0    3.0    0.12690355329949238  50 / 394
0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    3.0    3.0    10.0   1.0    1.0    358.0  0.0    0.089058524173028    35 / 393
2.0    0.0    0.0    0.0    11.0   1.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    17.0   2.0    0.0    0.0    0.0    1.0    0.0    318.0  0.1335149863760218   49 / 367
399.0  547.0  346.0  412.0  380.0  405.0  366.0  298.0  352.0  394.0  358.0  385.0  401.0  356.0  429.0  383.0  335.0  380.0  364.0  363.0  413.0  366.0  396.0  410.0  402.0  363.0  0.14345696291112667  1,435 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.856543
2    0.925122
3    0.951914
4    0.96631
5    0.974808
6    0.981805
7    0.986104
8    0.989003
9    0.991603
10   0.993702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14151429047304545
RMSE: 0.3761838519567865
LogLoss: 0.49358841570912176
Mean Per-Class Error: 0.14102028229317792
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15     16    17    18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0   1.0   0.0   0.0    0.0   1.0   0.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   91.0   0.0   2.0    2.0   0.0   1.0   3.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   3.0   1.0   0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.14150943396226415  15 / 106
0.0   0.0    68.0  0.0    3.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0   2.0   2.0   0.0    0.0   1.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
1.0   3.0    0.0   95.0   0.0   0.0   0.0   2.0   1.0   1.0    0.0   0.0    2.0   1.0   2.0   2.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.15178571428571427  17 / 112
0.0   0.0    1.0   0.0    77.0  4.0   7.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0   1.0   2.0   0.0   0.0    0.0   0.0   1.0    0.0    2.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0   2.0    1.0   86.0  0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   1.0   0.0   1.0    3.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   87.0   1.0    2.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   1.0    2.0   0.0   0.0   0.0   0.0    4.0   1.0   0.0    95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0   1.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    0.0    77.0  0.11494252873563218  10 / 87
88.0  136.0  71.0  112.0  94.0  96.0  94.0  77.0  86.0  114.0  91.0  103.0  87.0  96.0  89.0  114.0  88.0  95.0  96.0  83.0  104.0  81.0  99.0  100.0  110.0  86.0  0.14096385542168674  351 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.859036
2    0.929317
3    0.951406
4    0.964257
5    0.972289
6    0.97992
7    0.985141
8    0.987952
9    0.991165
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:47  4 min 45.396 sec  25528 obs/sec     1         1             10007      0.52651          0.935358            0.995075       0.271119                         0.524829           0.92905               0.995092         0.278715
    2019-08-04 09:04:51  4 min 49.000 sec  25476 obs/sec     10        10            100070     0.376078         0.486807            0.997487       0.143457                         0.376184           0.493588              0.997478         0.140964
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0880983
C13         0.953701               0.953701             0.0840195
C9          0.85764                0.85764              0.0755567
C12         0.85357                0.85357              0.0751981
C8          0.785416               0.785416             0.0691938
C7          0.778322               0.778322             0.0685689
C11         0.76327                0.76327              0.0672428
C10         0.731921               0.731921             0.064481
C5          0.675523               0.675523             0.0595125
C6          0.656853               0.656853             0.0578677
C16         0.634593               0.634593             0.0559065
C14         0.628004               0.628004             0.0553261
C3          0.573433               0.573433             0.0505185
C4          0.524432               0.524432             0.0462016
C2          0.474651               0.474651             0.0418159
C1          0.459626               0.459626             0.0404923
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_148

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002303733753521442  0.0006125150248408318  0.0         0.00456041868664947    0.30674827098846436  0.006297664745141869  0.37621593475341797
    3        26       Softmax                 0.0   0.0   0.002718964669471601  0.0010943114757537842  0.0         -0.001673524225771836  0.3185960054397583   -0.5385386399503687   0.16417527198791504


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14216259146241872
RMSE: 0.3770445483791255
LogLoss: 0.48409381432841986
Mean Per-Class Error: 0.14682917932182218
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    2.0    5.0    0.0    1.0    0.0    0.0    2.0    3.0    3.0    2.0    0.0    0.0    1.0    5.0    1.0    0.0759493670886076   30 / 395
0.0    341.0  0.0    7.0    2.0    0.0    0.0    6.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    14.0   4.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    0.10966057441253264  42 / 383
0.0    0.0    311.0  1.0    9.0    0.0    7.0    2.0    0.0    0.0    16.0   3.0    0.0    0.0    7.0    0.0    0.0    1.0    3.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
2.0    20.0   0.0    350.0  0.0    0.0    0.0    3.0    1.0    1.0    1.0    0.0    7.0    2.0    4.0    1.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.1315136476426799   53 / 403
0.0    5.0    2.0    0.0    327.0  4.0    17.0   1.0    1.0    0.0    3.0    3.0    0.0    0.0    0.0    1.0    0.0    3.0    5.0    1.0    1.0    0.0    0.0    3.0    0.0    6.0    0.1462140992167102   56 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    7.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    18.0   0.0    5.0    0.0    0.0    1.0    0.0    0.0    7.0    1.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    5.0    0.0    6.0    7.0    0.0    0.0    2.0    3.0    1.0    9.0    2.0    0.0    0.0    3.0    0.0    3.0    0.0    5.0    1.0    2.0    0.0    0.0    340.0  3.0    2.0    0.13705583756345177  54 / 394
0.0    1.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    1.0    12.0   2.0    3.0    1.0    1.0    361.0  0.0    0.08142493638676845  32 / 393
2.0    1.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    25.0   3.0    0.0    0.0    0.0    1.0    0.0    315.0  0.14168937329700274  52 / 367
389.0  517.0  340.0  445.0  402.0  368.0  335.0  301.0  346.0  359.0  378.0  370.0  443.0  374.0  423.0  415.0  348.0  412.0  358.0  379.0  414.0  361.0  359.0  409.0  404.0  354.0  0.1459562131360592   1,460 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854044
2    0.923523
3    0.953114
4    0.96711
5    0.976607
6    0.983205
7    0.987404
8    0.990203
9    0.992002
10   0.994202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14377356506090702
RMSE: 0.3791748476111081
LogLoss: 0.49511565574014776
Mean Per-Class Error: 0.14399738421607128
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   89.0   0.0   2.0    2.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   6.0    1.0   0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.16037735849056603  17 / 106
0.0   0.0    66.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    5.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    2.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.1951219512195122   16 / 82
2.0   3.0    0.0   95.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0   0.0    3.0   0.0   1.0   1.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0    1.0   0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    81.0  3.0   5.0   0.0   0.0   0.0    2.0   1.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   2.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   3.0    3.0   0.0   0.0   1.0   0.0   0.0    3.0   2.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   83.0  1.0    1.0   0.17                 17 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0    1.0   0.0    0.0   3.0   0.0    1.0   1.0   0.0   99.0   0.0   0.07476635514018691  8 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0   0.0   0.0   0.0    75.0  0.13793103448275862  12 / 87
88.0  129.0  67.0  118.0  97.0  85.0  87.0  74.0  82.0  108.0  99.0  101.0  97.0  98.0  88.0  119.0  90.0  109.0  93.0  89.0  104.0  80.0  91.0  98.0  114.0  85.0  0.14337349397590363  357 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.856626
2    0.924096
3    0.951807
4    0.965462
5    0.975502
6    0.981928
7    0.985141
8    0.988755
9    0.991566
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:05  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:05  4 min  3.639 sec  23435 obs/sec     1         1             10007      0.516549         0.926109            0.995259       0.246826                         0.515802           0.923825              0.995259         0.252209
    2019-08-04 09:04:09  4 min  7.151 sec  25817 obs/sec     10        10            100070     0.377045         0.484094            0.997474       0.145956                         0.379175           0.495116              0.997438         0.143373
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0847915
C13         0.996407               0.996407             0.0844869
C9          0.877178               0.877178             0.0743773
C12         0.872726               0.872726             0.0739998
C7          0.844949               0.844949             0.0716446
C8          0.844474               0.844474             0.0716043
C11         0.785083               0.785083             0.0665684
C10         0.737157               0.737157             0.0625047
C14         0.719149               0.719149             0.0609777
C5          0.715034               0.715034             0.0606289
C16         0.672559               0.672559             0.0570273
C6          0.640923               0.640923             0.0543449
C3          0.620934               0.620934             0.0526499
C4          0.544578               0.544578             0.0461756
C2          0.470539               0.470539             0.0398977
C1          0.451937               0.451937             0.0383204
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_96

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002379220335527066   0.0006110747344791889  0.0         -0.003882217357103257  0.30521953105926514  -0.0054535313208092994  0.37179434299468994
    3        26       Softmax                 0.0   0.0   0.0028623305118589295  0.001052475068718195   0.0         0.0035179028600049733  0.31556832790374756  -0.5502542409619687     0.13952642679214478


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1426594706751882
RMSE: 0.37770288677105474
LogLoss: 0.4912391095240831
Mean Per-Class Error: 0.1457437469878594
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    1.0    6.0    0.0    0.0    0.0    0.0    2.0    4.0    1.0    2.0    2.0    0.0    3.0    7.0    1.0    0.0810126582278481   32 / 395
0.0    319.0  0.0    4.0    6.0    0.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    32.0   11.0   0.0    0.0    1.0    0.0    2.0    3.0    1.0    0.1671018276762402   64 / 383
0.0    0.0    314.0  0.0    14.0   3.0    4.0    1.0    0.0    0.0    10.0   2.0    0.0    0.0    4.0    0.0    2.0    2.0    4.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.14673913043478262  54 / 368
1.0    14.0   0.0    351.0  0.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    5.0    5.0    1.0    2.0    0.0    15.0   1.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.12903225806451613  52 / 403
0.0    5.0    2.0    0.0    331.0  3.0    9.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    8.0    4.0    7.0    4.0    0.0    0.0    0.0    1.0    0.0    7.0    0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   1.0    3.0    0.0    1.0    1.0    0.0    0.0    3.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    1.0    0.0    3.0    7.0    1.0    0.0    0.0    4.0    2.0    8.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    1.0    1.0    0.0    0.0    352.0  5.0    2.0    0.1065989847715736   42 / 394
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    5.0    0.0    1.0    7.0    2.0    2.0    1.0    1.0    361.0  0.0    0.07908163265306123  31 / 392
2.0    0.0    0.0    0.0    20.0   0.0    0.0    0.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    26.0   2.0    0.0    0.0    0.0    0.0    0.0    305.0  0.16893732970027248  62 / 367
390.0  470.0  352.0  419.0  444.0  396.0  326.0  253.0  339.0  366.0  344.0  374.0  420.0  375.0  377.0  358.0  396.0  501.0  390.0  366.0  416.0  361.0  392.0  417.0  425.0  336.0  0.14485654303708886  1,449 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.855143
2    0.925422
3    0.954813
4    0.96771
5    0.976707
6    0.981905
7    0.986304
8    0.989203
9    0.991103
10   0.992302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1422875070798765
RMSE: 0.37721016301244653
LogLoss: 0.49668242173468213
Mean Per-Class Error: 0.14433636117237794
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    1.0   0.0   0.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   82.0   0.0   1.0    3.0    0.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   10.0   4.0    0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    68.0  0.0    3.0    1.0   1.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.17073170731707318  14 / 82
1.0   2.0    0.0   97.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   1.0   2.0    1.0   2.0    0.0   3.0    0.0    0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    83.0   2.0   3.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0    1.0   0.0    0.0   0.0   0.0   0.0    2.0   0.14432989690721648  14 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   1.0    0.0   0.0    1.0   0.0    0.0    0.0   0.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.0   0.0    0.0   0.0   88.0  1.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0    1.0   0.0    0.0   1.0   0.0   100.0  0.0   0.06542056074766354  7 / 107
2.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   2.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0    0.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
91.0  111.0  72.0  115.0  108.0  97.0  86.0  59.0  82.0  106.0  89.0  98.0  92.0  102.0  81.0  106.0  97.0  128.0  101.0  80.0  106.0  81.0  99.0  97.0  125.0  81.0  0.14377510040160643  358 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.856225
2    0.928112
3    0.95261
4    0.96506
5    0.975904
6    0.981928
7    0.985944
8    0.988353
9    0.990763
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:38  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:39  2 min 36.801 sec  24955 obs/sec     1         1             10007      0.527177         0.931614            0.995061       0.262921                         0.525822           0.929327              0.995073         0.264257
    2019-08-04 09:02:42  2 min 40.456 sec  25136 obs/sec     10        10            100070     0.377703         0.491239            0.997465       0.144857                         0.37721            0.496682              0.997465         0.143775
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0902545
C13         0.986245               0.986245             0.089013
C12         0.845615               0.845615             0.0763205
C9          0.84266                0.84266              0.0760538
C8          0.764255               0.764255             0.0689774
C7          0.746756               0.746756             0.0673981
C11         0.710611               0.710611             0.0641358
C10         0.70546                0.70546              0.0636709
C14         0.662677               0.662677             0.0598095
C5          0.643743               0.643743             0.0581007
C6          0.616465               0.616465             0.0556387
C16         0.586079               0.586079             0.0528962
C3          0.5523                 0.5523               0.0498475
C4          0.521008               0.521008             0.0470233
C2          0.452706               0.452706             0.0408587
C1          0.443205               0.443205             0.0400012
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_150

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0023663210189397432  0.0006772777996957302  0.0         -0.002914275751352946  0.3056734800338745  0.03979132633406118  0.3654634952545166
    3        26       Softmax                 0.0   0.0   0.002833458688340985   0.0010640849359333515  0.0         -0.008482702933886362  0.3162214756011963  -0.5519649941140048  0.12872564792633057


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1415990849944575
RMSE: 0.3762965386426741
LogLoss: 0.4863001579784801
Mean Per-Class Error: 0.14262974968510192
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    2.0    1.0    3.0    1.0    0.0    0.0    0.0    3.0    3.0    2.0    1.0    1.0    2.0    3.0    4.0    3.0    0.08354430379746836  33 / 395
0.0    326.0  0.0    7.0    3.0    0.0    1.0    18.0   2.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    8.0    9.0    0.0    0.0    1.0    0.0    1.0    4.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    314.0  1.0    9.0    1.0    11.0   2.0    0.0    0.0    12.0   1.0    0.0    0.0    5.0    0.0    1.0    1.0    3.0    2.0    3.0    0.0    2.0    0.0    0.0    0.0    0.14673913043478262  54 / 368
1.0    17.0   0.0    351.0  0.0    0.0    0.0    5.0    0.0    2.0    1.0    0.0    4.0    5.0    0.0    2.0    0.0    8.0    3.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.12903225806451613  52 / 403
0.0    10.0   1.0    0.0    321.0  6.0    14.0   2.0    1.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    2.0    3.0    6.0    3.0    0.0    0.0    0.0    4.0    0.0    8.0    0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    7.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    1.0    0.0    5.0    4.0    1.0    0.0    3.0    4.0    2.0    6.0    0.0    0.0    0.0    2.0    0.0    4.0    0.0    7.0    1.0    1.0    0.0    0.0    346.0  4.0    3.0    0.1218274111675127   48 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    3.0    0.0    2.0    10.0   3.0    8.0    1.0    1.0    356.0  0.0    0.09414758269720101  37 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    22.0   3.0    0.0    0.0    0.0    1.0    0.0    313.0  0.14713896457765668  54 / 367
388.0  416.0  344.0  423.0  398.0  363.0  349.0  401.0  345.0  349.0  361.0  356.0  394.0  373.0  384.0  410.0  371.0  421.0  451.0  391.0  420.0  345.0  394.0  399.0  406.0  351.0  0.14185744276716986  1,419 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.858143
2    0.925722
3    0.952714
4    0.964911
5    0.974508
6    0.980806
7    0.985704
8    0.988304
9    0.991003
10   0.993302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14420696755478055
RMSE: 0.37974592500088866
LogLoss: 0.49672847375063006
Mean Per-Class Error: 0.14143097767837748
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18     19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   1.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   83.0   0.0   2.0    2.0   0.0   1.0   7.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   3.0    3.0    0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.2169811320754717    23 / 106
0.0   0.0    70.0  0.0    1.0   1.0   1.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0    1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.14634146341463414   12 / 82
1.0   2.0    0.0   97.0   0.0   0.0   0.0   2.0   0.0   1.0   1.0   0.0   1.0   2.0    0.0   2.0    0.0   1.0    0.0    0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.13392857142857142   15 / 112
0.0   2.0    1.0   0.0    74.0  4.0   4.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0    0.0   0.0    0.0   0.0   1.0   0.0    5.0   0.23711340206185566   23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   3.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914   7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   90.0  1.0    1.0   0.1                   10 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    2.0   0.0    1.0   1.0   0.0   100.0  0.0   0.06542056074766354   7 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218   10 / 87
89.0  103.0  75.0  119.0  92.0  83.0  83.0  97.0  84.0  98.0  94.0  95.0  84.0  102.0  81.0  122.0  95.0  104.0  107.0  93.0  109.0  74.0  98.0  99.0  122.0  88.0  0.14056224899598393   350 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.859438
2    0.9249
3    0.950602
4    0.965462
5    0.975502
6    0.981526
7    0.985141
8    0.988755
9    0.991165
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:12  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:13  4 min 11.268 sec  20761 obs/sec     1         1             10007      0.516999         0.910312            0.995251       0.249925                         0.517666           0.910555              0.995225         0.25743
    2019-08-04 09:04:17  4 min 15.018 sec  23986 obs/sec     10        10            100070     0.376297         0.4863              0.997484       0.141857                         0.379746           0.496728              0.99743          0.140562
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0876111
C13         0.97212                0.97212              0.0851685
C9          0.875573               0.875573             0.0767099
C8          0.823114               0.823114             0.0721139
C12         0.818662               0.818662             0.0717238
C7          0.799536               0.799536             0.0700483
C11         0.760195               0.760195             0.0666015
C10         0.687002               0.687002             0.060189
C5          0.661193               0.661193             0.0579278
C16         0.66008                0.66008              0.0578303
C14         0.645482               0.645482             0.0565514
C6          0.642588               0.642588             0.0562979
C3          0.620142               0.620142             0.0543313
C4          0.545181               0.545181             0.0477639
C1          0.455017               0.455017             0.0398645
C2          0.448195               0.448195             0.0392669
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_164

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight              weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  -----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0022301322639179944  0.0006006369367241859  0.0         0.00021276689364135848   0.3027764558792114   -0.04738326662619169  0.3716670274734497
    3        26       Softmax                 0.0   0.0   0.002839354205049788   0.0013257837854325771  0.0         -0.00035444104572993713  0.31846749782562256  -0.5513504274939713   0.12190824747085571


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1435991229349036
RMSE: 0.37894474918502774
LogLoss: 0.49043812277143656
Mean Per-Class Error: 0.14612447992732538
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    3.0    1.0    6.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    1.0    1.0    2.0    2.0    5.0    3.0    0.08607594936708861  34 / 395
0.0    343.0  2.0    8.0    2.0    0.0    1.0    7.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    10.0   0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.10443864229765012  40 / 383
0.0    0.0    323.0  1.0    1.0    0.0    7.0    2.0    0.0    0.0    20.0   0.0    0.0    0.0    2.0    0.0    2.0    0.0    5.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.12228260869565218  45 / 368
0.0    14.0   0.0    367.0  0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    7.0    4.0    1.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    0.08933002481389578  36 / 403
0.0    6.0    5.0    0.0    308.0  6.0    14.0   2.0    1.0    0.0    6.0    7.0    0.0    0.0    0.0    1.0    4.0    2.0    5.0    5.0    0.0    0.0    0.0    5.0    0.0    7.0    0.19791666666666666  76 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    14.0   0.0    4.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    1.0    0.0    6.0    3.0    1.0    0.0    2.0    2.0    4.0    14.0   0.0    0.0    0.0    2.0    0.0    4.0    0.0    6.0    1.0    1.0    0.0    0.0    340.0  5.0    2.0    0.13705583756345177  54 / 394
0.0    0.0    0.0    1.0    0.0    13.0   0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    3.0    4.0    0.0    2.0    15.0   2.0    11.0   1.0    1.0    337.0  0.0    0.14249363867684478  56 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    0.0    27.0   2.0    0.0    0.0    0.0    0.0    0.0    313.0  0.1448087431693989   53 / 366
384.0  501.0  364.0  461.0  354.0  406.0  358.0  322.0  334.0  380.0  423.0  385.0  443.0  366.0  378.0  382.0  362.0  336.0  416.0  369.0  400.0  365.0  389.0  395.0  381.0  349.0  0.14555633310007     1,456 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854444
2    0.926122
3    0.954114
4    0.96801
5    0.975907
6    0.982505
7    0.986204
8    0.989703
9    0.991003
10   0.993102

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1467119455548077
RMSE: 0.38302995386106253
LogLoss: 0.5028617251404142
Mean Per-Class Error: 0.1484586917818819
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11     12    13    14    15     16    17    18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    3.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   1.0   0.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   87.0   1.0   3.0    2.0   0.0   1.0   3.0   0.0   0.0    1.0    0.0    0.0   0.0   0.0   0.0    0.0   2.0   3.0    0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    71.0  0.0    0.0   0.0   2.0   0.0   0.0   0.0    4.0    0.0    0.0   0.0   1.0   0.0    0.0   0.0   3.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.13414634146341464  11 / 82
0.0   1.0    0.0   103.0  0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0    3.0   1.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0    2.0   0.08035714285714286  9 / 112
0.0   0.0    2.0   0.0    72.0  4.0   5.0   0.0   0.0   0.0    3.0    2.0    0.0   0.0   0.0   0.0    0.0   1.0   3.0    2.0   0.0    0.0   0.0   2.0   0.0    1.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    3.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   1.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    1.0   0.0   0.0   1.0   0.0   1.0    6.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   85.0  1.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    2.0    0.0   0.0   0.0   2.0    1.0   0.0   0.0    5.0   0.0    3.0   1.0   0.0   91.0   0.0   0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0    0.0    2.0    0.0   0.0   0.0   0.0    0.0   0.0   5.0    0.0   0.0    0.0   0.0   0.0   0.0    75.0  0.13793103448275862  12 / 87
86.0  122.0  78.0  130.0  79.0  94.0  90.0  78.0  80.0  108.0  109.0  103.0  97.0  98.0  79.0  109.0  92.0  89.0  110.0  88.0  104.0  80.0  96.0  96.0  110.0  85.0  0.14819277108433734  369 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.851807
2    0.9249
3    0.952209
4    0.967068
5    0.976305
6    0.982329
7    0.987149
8    0.989558
9    0.990763
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:38  4 min 36.080 sec  24347 obs/sec     1         1             10007      0.521916         0.924733            0.995159       0.255223                         0.522698           0.926994              0.995132         0.258233
    2019-08-04 09:04:41  4 min 39.713 sec  25124 obs/sec     10        10            100070     0.378945         0.490438            0.997448       0.145556                         0.38303            0.502862              0.997386         0.148193
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.088509
C15         0.990587               0.990587             0.0876758
C12         0.840493               0.840493             0.0743911
C9          0.824276               0.824276             0.0729558
C8          0.807507               0.807507             0.0714716
C7          0.741047               0.741047             0.0655893
C11         0.732032               0.732032             0.0647914
C10         0.705681               0.705681             0.0624591
C5          0.671113               0.671113             0.0593995
C16         0.647258               0.647258             0.0572882
C6          0.638888               0.638888             0.0565473
C14         0.628546               0.628546             0.0556319
C3          0.598128               0.598128             0.0529397
C4          0.564848               0.564848             0.0499941
C2          0.466284               0.466284             0.0412703
C1          0.441606               0.441606             0.0390861
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_77

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0019868411512504736  0.000620388425886631   0.0         -0.0033801826034078886  0.3382343053817749   0.002530813022776995  0.366804838180542
    3        26       Softmax                 0.0   0.0   0.0029467370156383435  0.0009667284321039915  0.0         -0.0020755068072752726  0.44182097911834717  -0.53062181024744     0.10892441868782043


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1441092271813567
RMSE: 0.37961721138715077
LogLoss: 0.4863366582982209
Mean Per-Class Error: 0.1407630021195168
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
372.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    2.0    0.0    1.0    0.0    4.0    3.0    0.05822784810126582  23 / 395
0.0    320.0  0.0    11.0   3.0    1.0    0.0    2.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    29.0   6.0    0.0    0.0    1.0    0.0    2.0    3.0    0.0    0.16449086161879894  63 / 383
0.0    0.0    315.0  1.0    9.0    0.0    9.0    0.0    0.0    0.0    11.0   3.0    0.0    0.0    4.0    0.0    1.0    2.0    2.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.14402173913043478  53 / 368
1.0    13.0   0.0    354.0  0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    4.0    4.0    8.0    1.0    0.0    9.0    1.0    0.0    2.0    0.0    0.0    3.0    0.0    1.0    0.12158808933002481  49 / 403
0.0    9.0    2.0    0.0    314.0  3.0    16.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    1.0    4.0    5.0    8.0    6.0    1.0    0.0    0.0    3.0    0.0    7.0    0.18229166666666666  70 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    5.0    0.0    0.0    2.0    0.0    0.0    7.0    1.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    1.0    0.0    3.0    9.0    2.0    0.0    2.0    2.0    3.0    3.0    2.0    0.0    0.0    2.0    1.0    5.0    2.0    0.0    1.0    1.0    0.0    0.0    347.0  4.0    4.0    0.11928934010152284  47 / 394
0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    4.0    4.0    8.0    1.0    1.0    367.0  0.0    0.06615776081424936  26 / 393
2.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    2.0    14.0   4.0    0.0    0.0    0.0    1.0    0.0    328.0  0.10382513661202186  38 / 366
410.0  423.0  340.0  430.0  394.0  344.0  353.0  260.0  331.0  350.0  354.0  365.0  416.0  378.0  416.0  396.0  401.0  524.0  356.0  400.0  437.0  353.0  381.0  402.0  417.0  372.0  0.13985804258722384  1,399 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.860142
2    0.926722
3    0.953514
4    0.96561
5    0.974408
6    0.981106
7    0.985204
8    0.988304
9    0.991203
10   0.993702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14894844377041266
RMSE: 0.385938393750107
LogLoss: 0.5029387686591169
Mean Per-Class Error: 0.14382405005940788
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   3.0    0.0   0.056179775280898875  5 / 89
0.0   85.0   0.0   3.0    3.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   8.0    2.0   0.0   0.0    1.0   0.0   1.0   2.0    0.0   0.19811320754716982   21 / 106
0.0   0.0    68.0  0.0    3.0    0.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    1.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.17073170731707318   14 / 82
1.0   1.0    0.0   97.0   0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   1.0    4.0   1.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0   1.0   0.0    1.0   0.13392857142857142   15 / 112
0.0   2.0    0.0   0.0    80.0   2.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0   2.0   0.0    0.0   0.0   1.0   0.0    2.0   0.17525773195876287   17 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   4.0    0.0   84.0  0.0   0.0    0.0   0.08695652173913043   8 / 92
0.0   0.0    0.0   1.0    4.0    0.0   0.0   1.0   0.0   1.0    2.0   2.0   0.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0   84.0  1.0    1.0   0.16                  16 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0   0.0    2.0   1.0   0.0   102.0  0.0   0.04672897196261682   5 / 107
1.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   2.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218   10 / 87
91.0  100.0  72.0  118.0  102.0  78.0  89.0  67.0  79.0  101.0  90.0  97.0  92.0  102.0  89.0  111.0  98.0  132.0  93.0  99.0  108.0  77.0  96.0  94.0  127.0  88.0  0.142570281124498     355 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.85743
2    0.926506
3    0.955823
4    0.965462
5    0.973896
6    0.980723
7    0.985542
8    0.986747
9    0.990362
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:09  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:09  2 min  7.263 sec  42764 obs/sec     1         1             10007      0.536883         0.948242            0.994878       0.255823                         0.536956           0.948831              0.994863         0.262249
    2019-08-04 09:02:11  2 min  9.419 sec  42637 obs/sec     10        10            100070     0.379617         0.486337            0.997439       0.139858                         0.385938           0.502939              0.997346         0.14257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0884873
C13         0.976428               0.976428             0.0864015
C12         0.860129               0.860129             0.0761104
C9          0.854095               0.854095             0.0755765
C8          0.839186               0.839186             0.0742572
C11         0.790129               0.790129             0.0699164
C7          0.715227               0.715227             0.0632885
C10         0.701642               0.701642             0.0620864
C5          0.647928               0.647928             0.0573334
C14         0.635839               0.635839             0.0562636
C6          0.632084               0.632084             0.0559314
C16         0.6187                 0.6187               0.0547471
C3          0.566125               0.566125             0.0500948
C4          0.506463               0.506463             0.0448156
C2          0.481765               0.481765             0.0426301
C1          0.475322               0.475322             0.0420599
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_51

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002468373141084612  0.0006632162258028984  0.0         -0.0024319364804306076  0.3092082738876343  -0.0397571186044628  0.3887850046157837
    3        26       Softmax                 0.0   0.0   0.00284284581493921   0.0009666015394032001  0.0         0.0019447790998944252   0.310813307762146   -0.5529665163965602  0.14152175188064575


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1444526995880204
RMSE: 0.3800693352376911
LogLoss: 0.4896652489853543
Mean Per-Class Error: 0.14671532686822455
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    3.0    1.0    8.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    1.0    2.0    1.0    2.0    5.0    3.0    0.09620253164556962  38 / 395
0.0    324.0  0.0    7.0    2.0    0.0    1.0    4.0    2.0    0.0    13.0   1.0    0.0    0.0    0.0    1.0    1.0    10.0   10.0   0.0    0.0    3.0    0.0    1.0    1.0    2.0    0.15404699738903394  59 / 383
0.0    0.0    311.0  1.0    3.0    1.0    6.0    2.0    0.0    0.0    23.0   4.0    0.0    0.0    3.0    0.0    0.0    0.0    5.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
1.0    14.0   0.0    346.0  0.0    0.0    0.0    3.0    1.0    2.0    2.0    0.0    5.0    5.0    8.0    1.0    0.0    4.0    1.0    0.0    2.0    0.0    0.0    3.0    0.0    4.0    0.13930348258706468  56 / 402
0.0    1.0    1.0    0.0    314.0  8.0    9.0    0.0    0.0    0.0    12.0   3.0    0.0    0.0    0.0    0.0    10.0   3.0    7.0    3.0    0.0    0.0    0.0    5.0    0.0    7.0    0.1801566579634465   69 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    18.0   0.0    4.0    0.0    0.0    0.0    0.0    0.0    2.0    8.0    337.0  0.0    0.0    0.0    0.10133333333333333  38 / 375
0.0    0.0    0.0    4.0    4.0    1.0    0.0    1.0    3.0    3.0    17.0   1.0    0.0    0.0    3.0    0.0    4.0    0.0    3.0    2.0    1.0    0.0    0.0    341.0  4.0    2.0    0.13451776649746192  53 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    2.0    8.0    2.0    13.0   1.0    1.0    352.0  1.0    0.10432569974554708  41 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    21.0   3.0    0.0    0.0    0.0    0.0    0.0    315.0  0.14168937329700274  52 / 367
382.0  425.0  337.0  425.0  379.0  405.0  329.0  271.0  339.0  377.0  483.0  374.0  438.0  383.0  417.0  376.0  369.0  364.0  430.0  371.0  412.0  392.0  369.0  408.0  388.0  360.0  0.14605618314505647  1,461 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853944
2    0.926322
3    0.953014
4    0.964211
5    0.976207
6    0.982405
7    0.986004
8    0.989403
9    0.991303
10   0.993302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14811947827289007
RMSE: 0.3848629343972865
LogLoss: 0.5053521025923104
Mean Per-Class Error: 0.15085472194731087
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17    18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0   1.0   1.0    0.0   0.0    1.0   0.0   0.0   3.0    0.0   0.11235955056179775  10 / 89
0.0   85.0   0.0   3.0    2.0   0.0   1.0   3.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   5.0   2.0    0.0   0.0    2.0   0.0   1.0   1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    66.0  0.0    1.0   1.0   1.0   1.0   0.0   0.0    4.0    1.0   0.0   0.0    2.0   0.0    0.0   0.0   3.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.1951219512195122   16 / 82
1.0   1.0    0.0   94.0   0.0   0.0   0.0   3.0   1.0   0.0    1.0    0.0   1.0   2.0    3.0   1.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   1.0   0.0    2.0   0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    76.0  4.0   1.0   0.0   0.0   0.0    4.0    1.0   0.0   0.0    0.0   0.0    3.0   1.0   3.0    1.0   0.0    0.0   0.0   1.0   0.0    2.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    3.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   1.0    8.0    1.0   0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   83.0  1.0    1.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   2.0    2.0   0.0   0.0    1.0   0.0    5.0   1.0   0.0   96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0   4.0    0.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
86.0  111.0  70.0  114.0  92.0  94.0  81.0  72.0  83.0  112.0  120.0  97.0  97.0  103.0  83.0  106.0  97.0  95.0  106.0  85.0  104.0  91.0  94.0  97.0  115.0  85.0  0.1502008032128514   374 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.849799
2    0.923695
3    0.951004
4    0.963052
5    0.975502
6    0.983133
7    0.986345
8    0.989157
9    0.991566
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:32  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:32  1 min 30.221 sec  24955 obs/sec     1         1             10007      0.523427         0.921728            0.995131       0.258323                         0.522167           0.918182              0.995142         0.261446
    2019-08-04 09:01:36  1 min 33.809 sec  25508 obs/sec     10        10            100070     0.380069         0.489665            0.997433       0.146056                         0.384863           0.505352              0.997361         0.150201
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0840655
C15         0.993495               0.993495             0.0835186
C9          0.894044               0.894044             0.0751583
C8          0.887812               0.887812             0.0746343
C12         0.881462               0.881462             0.0741005
C7          0.7869                 0.7869               0.0661511
C10         0.771975               0.771975             0.0648964
C11         0.768988               0.768988             0.0646453
C16         0.699917               0.699917             0.0588388
C5          0.69329                0.69329              0.0582817
C14         0.687505               0.687505             0.0577954
C6          0.642529               0.642529             0.0540145
C3          0.617927               0.617927             0.0519463
C4          0.582714               0.582714             0.0489861
C1          0.504339               0.504339             0.0423975
C2          0.482596               0.482596             0.0405697
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_209

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002382191154381985  0.0007233684882521629  0.0         0.00634888411025436     0.2998720407485962   0.024882285722146878  0.3373417854309082
    3        26       Softmax                 0.0   0.0   0.002985667001614554  0.0013992786407470703  0.0         -0.0030325914900511354  0.31287896633148193  -0.5676894310992058   0.18926608562469482


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1437904003778632
RMSE: 0.37919704690024053
LogLoss: 0.4925124632315252
Mean Per-Class Error: 0.14349626234229873
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    3.0    8.0    0.0    1.0    0.0    0.0    1.0    3.0    0.0    2.0    1.0    1.0    0.0    3.0    3.0    0.08883248730964467  35 / 394
0.0    334.0  1.0    11.0   2.0    0.0    2.0    6.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    8.0    10.0   0.0    0.0    0.0    1.0    1.0    0.0    1.0    0.1256544502617801   48 / 382
0.0    0.0    319.0  1.0    8.0    0.0    4.0    1.0    0.0    0.0    20.0   1.0    0.0    0.0    3.0    1.0    1.0    0.0    5.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.1331521739130435   49 / 368
1.0    10.0   0.0    361.0  0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    7.0    3.0    2.0    2.0    0.0    6.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.10421836228287841  42 / 403
0.0    3.0    3.0    0.0    328.0  5.0    17.0   2.0    1.0    0.0    2.0    3.0    0.0    0.0    0.0    1.0    1.0    3.0    5.0    3.0    1.0    0.0    0.0    1.0    0.0    5.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    13.0   0.0    4.0    0.0    0.0    2.0    0.0    0.0    5.0    1.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    0.0    0.0    8.0    6.0    2.0    0.0    3.0    3.0    3.0    8.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    4.0    1.0    1.0    0.0    0.0    347.0  2.0    1.0    0.11928934010152284  47 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    5.0    0.0    2.0    10.0   2.0    10.0   2.0    0.0    349.0  1.0    0.11195928753180662  44 / 393
2.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    1.0    25.0   3.0    0.0    0.0    0.0    0.0    0.0    306.0  0.16621253405994552  61 / 367
381.0  428.0  352.0  448.0  409.0  386.0  361.0  326.0  340.0  351.0  393.0  367.0  430.0  375.0  412.0  421.0  353.0  401.0  402.0  372.0  419.0  356.0  400.0  398.0  377.0  345.0  0.14255723283015095  1,426 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.857443
2    0.925322
3    0.952714
4    0.964211
5    0.974808
6    0.981905
7    0.986704
8    0.989203
9    0.991902
10   0.993802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14764727867654648
RMSE: 0.3842489800592143
LogLoss: 0.5069204212754344
Mean Per-Class Error: 0.1505976464468781
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0    0.0   3.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   5.0    2.0    0.0   2.0   4.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   5.0    1.0    0.0   0.0    0.0   1.0   1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    69.0  0.0    2.0    0.0   1.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   2.0   1.0    0.0   0.0    3.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   1.0    0.0   98.0   0.0    0.0   0.0   3.0   0.0   0.0    1.0    0.0   3.0   1.0   0.0   2.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.125                14 / 112
0.0   0.0    0.0   0.0    80.0   4.0   5.0   0.0   0.0   0.0    1.0    1.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0    1.0   0.0    0.0   0.0   0.0   0.0    2.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0   3.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   4.0    4.0    1.0   0.0   2.0   0.0   1.0    4.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   83.0  0.0    0.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0   0.0   3.0    2.0   0.0    0.0    2.0   0.0    3.0   2.0   0.0   94.0   0.0   0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    6.0    1.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
87.0  106.0  73.0  126.0  101.0  88.0  90.0  87.0  81.0  102.0  101.0  95.0  99.0  97.0  82.0  123.0  92.0  102.0  105.0  87.0  105.0  78.0  98.0  96.0  106.0  83.0  0.1497991967871486   373 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850201
2    0.920884
3    0.953012
4    0.963454
5    0.975502
6    0.979518
7    0.985542
8    0.988353
9    0.991566
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:07  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:08  6 min  5.819 sec  23110 obs/sec     1         1             10007      0.522984         0.920896            0.995138       0.246826                         0.521304           0.924142              0.995158         0.251004
    2019-08-04 09:06:11  6 min  9.416 sec  25206 obs/sec     10        10            100070     0.379197         0.492512            0.997444       0.142557                         0.384249           0.50692               0.997369         0.149799
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0862708
C13         0.975741               0.975741             0.0841779
C9          0.881737               0.881737             0.0760681
C12         0.870604               0.870604             0.0751077
C8          0.863419               0.863419             0.0744878
C7          0.793962               0.793962             0.0684957
C11         0.772086               0.772086             0.0666085
C10         0.719813               0.719813             0.0620989
C14         0.6963                 0.6963               0.0600703
C5          0.676795               0.676795             0.0583877
C6          0.647199               0.647199             0.0558344
C16         0.617498               0.617498             0.0532721
C3          0.596954               0.596954             0.0514997
C4          0.539241               0.539241             0.0465207
C2          0.473343               0.473343             0.0408357
C1          0.466714               0.466714             0.0402638
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_93

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013107598976205281  0.00034684932325035334  0.0         -0.01096286605772434  0.20066750049591064  0.15103216879798656  0.17303484678268433
    3        26       Softmax                      0.0   0.0   0.009678170012893342   0.04219561815261841     0.0         -0.22442263782260433  0.5293724536895752   -0.6173579304552143  0.22752290964126587


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.15763679637430586
RMSE: 0.39703500648470014
LogLoss: 0.5075035183170374
Mean Per-Class Error: 0.1427044501435552
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    2.0    5.0    1.0    2.0    0.0    1.0    0.0    0.0    1.0    5.0    3.0    4.0    1.0    1.0    3.0    4.0    1.0    0.09113924050632911  36 / 395
0.0    342.0  0.0    3.0    3.0    0.0    0.0    11.0   2.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    0.0    8.0    5.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.10704960835509138  41 / 383
0.0    0.0    308.0  1.0    16.0   0.0    10.0   1.0    0.0    0.0    14.0   1.0    0.0    0.0    6.0    0.0    2.0    1.0    2.0    3.0    0.0    0.0    3.0    0.0    0.0    0.0    0.16304347826086957  60 / 368
1.0    18.0   0.0    354.0  0.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    5.0    5.0    1.0    3.0    0.0    3.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.11940298507462686  48 / 402
0.0    5.0    0.0    0.0    316.0  4.0    13.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    9.0    4.0    11.0   7.0    0.0    0.0    0.0    3.0    0.0    10.0   0.17708333333333334  68 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    1.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    1.0    0.0    5.0    6.0    0.0    0.0    1.0    2.0    4.0    8.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    1.0    0.0    0.0    354.0  2.0    4.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    10.0   0.0    12.0   2.0    0.0    356.0  0.0    0.09414758269720101  37 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    12.0   0.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    14.0   2.0    0.0    0.0    0.0    0.0    0.0    323.0  0.11989100817438691  44 / 367
392.0  464.0  339.0  415.0  394.0  366.0  361.0  367.0  342.0  367.0  366.0  354.0  402.0  384.0  395.0  384.0  380.0  401.0  374.0  399.0  405.0  366.0  404.0  410.0  393.0  379.0  0.14195741277616716  1,420 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.858043
2    0.924623
3    0.953514
4    0.96681
5    0.976407
6    0.982605
7    0.987204
8    0.990103
9    0.992502
10   0.994302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16059204796946355
RMSE: 0.4007393766146067
LogLoss: 0.5168974690956737
Mean Per-Class Error: 0.14566838319392875
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0    1.0   0.0   1.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   91.0   0.0   0.0    2.0   0.0   0.0   4.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0    3.0    0.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.14150943396226415  15 / 106
0.0   0.0    67.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    1.0    0.0    1.0   2.0   0.0    0.0   1.0   0.0   0.0    0.0   0.18292682926829268  15 / 82
1.0   3.0    0.0   95.0   0.0   0.0   0.0   3.0   0.0   1.0    0.0   0.0   1.0   2.0    0.0   2.0    0.0    0.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0    1.0   0.15178571428571427  17 / 112
0.0   1.0    0.0   0.0    78.0  3.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0    1.0    2.0   3.0   0.0    0.0   0.0   1.0   0.0    3.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   87.0  0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   3.0    4.0   0.0   0.0   0.0   0.0   1.0    4.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   86.0  0.0    1.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0    0.0    0.0   3.0   0.0    3.0   1.0   0.0   96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0    76.0  0.12643678160919541  11 / 87
93.0  120.0  72.0  110.0  96.0  87.0  87.0  92.0  83.0  103.0  92.0  92.0  89.0  102.0  86.0  110.0  100.0  100.0  86.0  97.0  105.0  83.0  99.0  97.0  110.0  99.0  0.14497991967871485  361 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.85502
2    0.926908
3    0.955823
4    0.965863
5    0.976305
6    0.982329
7    0.987149
8    0.990763
9    0.991968
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:35  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:35  2 min 33.571 sec  70971 obs/sec     1         1             10007      0.567522         1.0029              0.994277       0.272218                         0.566649           0.999854              0.994279         0.276707
    2019-08-04 09:02:37  2 min 34.794 sec  74958 obs/sec     10        10            100070     0.397035         0.507504            0.997199       0.141957                         0.400739           0.516897              0.997138         0.14498
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0895426
C13         0.96774                0.96774              0.086654
C8          0.85207                0.85207              0.0762966
C9          0.813783               0.813783             0.0728683
C12         0.797027               0.797027             0.0713679
C7          0.747533               0.747533             0.0669361
C10         0.713921               0.713921             0.0639264
C11         0.684846               0.684846             0.0613229
C6          0.680792               0.680792             0.0609599
C5          0.678819               0.678819             0.0607833
C14         0.616138               0.616138             0.0551706
C16         0.593048               0.593048             0.0531031
C3          0.578332               0.578332             0.0517853
C4          0.548111               0.548111             0.0490793
C2          0.456621               0.456621             0.0408871
C1          0.439084               0.439084             0.0393168
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_85

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0012883186798831048  0.0003565453225746751  0.0         -0.011811295524232435  0.20281970500946045  0.14482759889346047  0.14378619194030762
    3        26       Softmax                      0.0   0.0   0.009544445631910583   0.04192274808883667    0.0         -0.2461544077313446    0.526007890701294    -0.6185885860281919  0.3070106506347656


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1607072466519638
RMSE: 0.4008830835193271
LogLoss: 0.5161677800041451
Mean Per-Class Error: 0.15025247074800036
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    4.0    5.0    1.0    2.0    0.0    3.0    0.0    0.0    1.0    6.0    0.0    3.0    0.0    2.0    4.0    4.0    0.0    0.09137055837563451  36 / 394
0.0    340.0  0.0    6.0    2.0    1.0    1.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    8.0    10.0   1.0    0.0    3.0    0.0    2.0    1.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    306.0  0.0    14.0   0.0    8.0    0.0    0.0    0.0    12.0   5.0    0.0    0.0    8.0    0.0    2.0    0.0    2.0    3.0    1.0    0.0    7.0    0.0    0.0    0.0    0.16847826086956522  62 / 368
2.0    18.0   0.0    352.0  0.0    1.0    0.0    0.0    1.0    3.0    2.0    0.0    5.0    4.0    3.0    1.0    0.0    4.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    2.0    0.12655086848635236  51 / 403
0.0    4.0    2.0    0.0    315.0  3.0    17.0   0.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    9.0    7.0    0.0    0.0    0.0    6.0    0.0    12.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    12.0   1.0    3.0    0.0    0.0    3.0    0.0    0.0    3.0    0.0    350.0  0.0    1.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    3.0    5.0    0.0    0.0    1.0    1.0    2.0    5.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    0.0    360.0  1.0    5.0    0.08629441624365482  34 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    12.0   2.0    6.0    1.0    0.0    358.0  0.0    0.089058524173028    35 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    21.0   4.0    0.0    0.0    0.0    0.0    0.0    316.0  0.13896457765667575  51 / 367
390.0  472.0  351.0  422.0  404.0  383.0  360.0  273.0  346.0  363.0  351.0  379.0  394.0  384.0  423.0  375.0  329.0  421.0  398.0  389.0  413.0  346.0  425.0  436.0  406.0  370.0  0.1494551634509647   1,495 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850545
2    0.925722
3    0.950915
4    0.96511
5    0.974508
6    0.981706
7    0.987204
8    0.989703
9    0.991902
10   0.993402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16217260544066842
RMSE: 0.4027065996984261
LogLoss: 0.5209996276999541
Mean Per-Class Error: 0.15019287386435914
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11     12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    1.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   87.0   0.0   2.0    1.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   5.0    3.0   0.0   0.0    2.0   0.0    2.0    1.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    65.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    3.0   0.0    1.0   0.0    1.0   2.0   0.0    0.0   2.0    0.0    0.0    0.0   0.2073170731707317   17 / 82
2.0   2.0    0.0   98.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0   0.0    1.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    1.0   0.125                14 / 112
0.0   0.0    0.0   0.0    75.0  1.0   5.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    3.0   4.0   0.0    0.0   0.0    3.0    0.0    5.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    89.0   0.0    3.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   1.0    1.0   0.0    0.0   2.0   0.0    2.0   1.0    0.0    99.0   0.0   0.07476635514018691  8 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0   0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   2.0   0.0    0.0   0.0    0.0    0.0    75.0  0.13793103448275862  12 / 87
93.0  113.0  72.0  117.0  94.0  92.0  90.0  67.0  85.0  99.0  89.0  101.0  89.0  101.0  88.0  106.0  90.0  109.0  94.0  93.0  102.0  78.0  104.0  107.0  120.0  97.0  0.1497991967871486   373 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850201
2    0.925301
3    0.950201
4    0.966265
5    0.973896
6    0.981526
7    0.989157
8    0.991566
9    0.993976
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:25  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:25  2 min 23.037 sec  60648 obs/sec     1         1             10007      0.561837         1.00589             0.99439        0.262221                         0.561652           1.00125               0.994379         0.262651
    2019-08-04 09:02:26  2 min 24.277 sec  72672 obs/sec     10        10            100070     0.400883         0.516168            0.997144       0.149455                         0.402707           0.521                 0.99711          0.149799
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0875266
C15         0.993248               0.993248             0.0869357
C9          0.818585               0.818585             0.071648
C8          0.814295               0.814295             0.0712725
C12         0.793831               0.793831             0.0694813
C7          0.791926               0.791926             0.0693146
C11         0.766594               0.766594             0.0670974
C5          0.720689               0.720689             0.0630794
C10         0.697892               0.697892             0.0610841
C6          0.682761               0.682761             0.0597598
C14         0.641488               0.641488             0.0561473
C3          0.601777               0.601777             0.0526715
C4          0.594009               0.594009             0.0519916
C16         0.562505               0.562505             0.0492342
C1          0.479533               0.479533             0.0419719
C2          0.465961               0.465961             0.040784
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_120

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013295161438691139  0.00036194443237036467  0.0         -0.012645279189945846  0.20263218879699707  0.1432674961613192   0.137285053730011
    3        26       Softmax                      0.0   0.0   0.009855645724673404   0.04466642439365387     0.0         -0.2328282434604335    0.5255029201507568   -0.6204433007491671  0.23398399353027344


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16025361020034734
RMSE: 0.40031688722853964
LogLoss: 0.5137011938615642
Mean Per-Class Error: 0.150736744406081
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    1.0    2.0    0.0    1.0    0.0    0.0    1.0    4.0    1.0    1.0    2.0    1.0    0.0    6.0    0.0    0.07341772151898734  29 / 395
0.0    338.0  0.0    5.0    4.0    0.0    1.0    5.0    1.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    3.0    10.0   5.0    1.0    0.0    3.0    0.0    1.0    1.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    310.0  0.0    12.0   0.0    8.0    0.0    0.0    0.0    12.0   4.0    0.0    0.0    3.0    0.0    3.0    1.0    4.0    4.0    1.0    0.0    6.0    0.0    0.0    0.0    0.15760869565217392  58 / 368
1.0    18.0   0.0    350.0  0.0    0.0    1.0    4.0    0.0    3.0    0.0    0.0    7.0    3.0    1.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.12718204488778054  51 / 401
0.0    10.0   3.0    0.0    303.0  4.0    17.0   0.0    0.0    0.0    1.0    7.0    0.0    0.0    1.0    1.0    3.0    3.0    6.0    6.0    0.0    0.0    0.0    4.0    0.0    15.0   0.2109375            81 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    14.0   1.0    4.0    0.0    0.0    2.0    0.0    0.0    4.0    3.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    3.0    0.0    4.0    2.0    2.0    0.0    3.0    2.0    1.0    9.0    2.0    0.0    0.0    0.0    0.0    7.0    0.0    2.0    4.0    1.0    0.0    0.0    348.0  1.0    3.0    0.116751269035533    46 / 394
1.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    0.0    2.0    14.0   2.0    20.0   1.0    0.0    341.0  0.0    0.13231552162849872  52 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    20.0   3.0    0.0    0.0    0.0    2.0    0.0    313.0  0.14713896457765668  54 / 367
399.0  478.0  345.0  413.0  380.0  367.0  381.0  337.0  344.0  352.0  379.0  372.0  412.0  378.0  380.0  379.0  401.0  425.0  335.0  397.0  395.0  390.0  396.0  397.0  392.0  379.0  0.1500549835049485   1,501 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.849945
2    0.923223
3    0.952014
4    0.96681
5    0.976207
6    0.983205
7    0.987304
8    0.990003
9    0.992802
10   0.994402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16299380589404336
RMSE: 0.40372491364051755
LogLoss: 0.5223524038907366
Mean Per-Class Error: 0.15460537501747895
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    2.0   0.0   0.0   3.0    0.0   0.06741573033707865  6 / 89
0.0   87.0   0.0   1.0    3.0   0.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    1.0   0.0    1.0    5.0    1.0   0.0   0.0    2.0   0.0   1.0   1.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    65.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    2.0    0.0    2.0   2.0   0.0    0.0   2.0   0.0   0.0    0.0   0.2073170731707317   17 / 82
1.0   4.0    0.0   98.0   0.0   0.0   1.0   2.0   0.0   1.0    0.0   0.0   3.0   1.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.125                14 / 112
0.0   2.0    0.0   0.0    71.0  3.0   5.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   3.0   0.0    0.0   0.0   2.0   0.0    7.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   1.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   2.0    1.0   1.0   0.0   2.0   0.0   0.0    5.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.0   0.0    0.0   0.0   85.0  0.0    1.0   0.15                 15 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0    0.0    0.0   3.0   0.0    8.0   1.0   0.0   91.0   0.0   0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0   1.0   0.0    0.0   0.0   1.0   0.0    74.0  0.14942528735632185  13 / 87
92.0  120.0  70.0  115.0  89.0  84.0  95.0  83.0  81.0  106.0  96.0  98.0  90.0  101.0  82.0  111.0  102.0  103.0  82.0  96.0  100.0  90.0  98.0  97.0  110.0  99.0  0.15421686746987953  384 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.845783
2    0.926506
3    0.953012
4    0.967871
5    0.976707
6    0.983132
7    0.985542
8    0.987148
9    0.991566
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:20  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:20  3 min 18.168 sec  51056 obs/sec     1         1             10007      0.571106         1.0315              0.994203       0.280516                         0.571692           1.02793               0.994176         0.278715
    2019-08-04 09:03:21  3 min 19.436 sec  69589 obs/sec     10        10            100070     0.400317         0.513701            0.997152       0.150055                         0.403725           0.522352              0.997096         0.154217
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0896216
C13         0.98981                0.98981              0.0887083
C8          0.82057                0.82057              0.0735408
C9          0.808399               0.808399             0.07245
C7          0.797355               0.797355             0.0714602
C12         0.778872               0.778872             0.0698038
C11         0.719138               0.719138             0.0644503
C5          0.705265               0.705265             0.063207
C10         0.633817               0.633817             0.0568037
C3          0.614499               0.614499             0.0550724
C6          0.613468               0.613468             0.05498
C4          0.60253                0.60253              0.0539997
C14         0.577249               0.577249             0.051734
C16         0.573213               0.573213             0.0513723
C2          0.469996               0.469996             0.0421218
C1          0.453843               0.453843             0.0406741
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_201

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013267777289058813  0.00036063697189092636  0.0         -0.011611998018871361  0.2034987211227417  0.13424726001180665  0.17151665687561035
    3        26       Softmax                      0.0   0.0   0.008573545185177304   0.03335936367511749     0.0         -0.2364317633482407    0.5223791599273682  -0.6263559456685622  0.26083648204803467


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.15919034654497102
RMSE: 0.3989866495823777
LogLoss: 0.5135122507997897
Mean Per-Class Error: 0.14670375151606296
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    1.0    2.0    0.0    1.0    0.0    0.0    3.0    5.0    0.0    1.0    1.0    2.0    1.0    6.0    1.0    0.07088607594936709  28 / 395
0.0    333.0  0.0    2.0    1.0    1.0    4.0    4.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    1.0    15.0   10.0   0.0    0.0    2.0    0.0    2.0    3.0    0.0    0.13054830287206268  50 / 383
0.0    0.0    317.0  0.0    18.0   0.0    7.0    0.0    0.0    0.0    6.0    2.0    1.0    0.0    6.0    0.0    0.0    2.0    2.0    1.0    3.0    0.0    2.0    0.0    0.0    0.0    0.1362397820163488   50 / 367
1.0    23.0   0.0    346.0  0.0    0.0    0.0    2.0    0.0    3.0    3.0    0.0    6.0    4.0    1.0    0.0    0.0    7.0    0.0    2.0    1.0    0.0    0.0    4.0    0.0    0.0    0.141439205955335    57 / 403
0.0    5.0    0.0    0.0    331.0  2.0    18.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    1.0    4.0    3.0    3.0    0.0    0.0    0.0    6.0    0.0    8.0    0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    11.0   1.0    4.0    0.0    0.0    3.0    0.0    0.0    4.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    1.0    0.0    4.0    3.0    1.0    0.0    3.0    1.0    4.0    5.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    0.0    0.0    358.0  2.0    3.0    0.09137055837563451  36 / 394
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    8.0    2.0    13.0   1.0    0.0    360.0  0.0    0.08396946564885496  33 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    20.0   3.0    0.0    0.0    0.0    2.0    0.0    310.0  0.15300546448087432  56 / 366
413.0  481.0  356.0  405.0  430.0  369.0  366.0  298.0  337.0  389.0  327.0  374.0  399.0  379.0  395.0  389.0  330.0  451.0  373.0  368.0  411.0  359.0  410.0  428.0  415.0  351.0  0.1459562131360592   1,460 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854044
2    0.925822
3    0.952814
4    0.96581
5    0.975707
6    0.982205
7    0.987104
8    0.990603
9    0.992902
10   0.994902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1608593416963793
RMSE: 0.40107273866018284
LogLoss: 0.5231503542771118
Mean Per-Class Error: 0.14322447084314402
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   0.0   0.0    3.0    0.0   0.056179775280898875  5 / 89
0.0   86.0   0.0   0.0    1.0   1.0   1.0   1.0   1.0   0.0    1.0   0.0    0.0   0.0    1.0   0.0    1.0   5.0    3.0   0.0   0.0    2.0   0.0   1.0    1.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    70.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.14634146341463414   12 / 82
1.0   4.0    0.0   98.0   0.0   0.0   0.0   0.0   0.0   2.0    1.0   0.0    2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    0.0   0.125                 14 / 112
0.0   0.0    0.0   0.0    81.0  1.0   5.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    2.0   2.0   0.0    0.0   0.0   2.0    0.0    3.0   0.16494845360824742   16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652   5 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   2.0   1.0   1.0    2.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   89.0   0.0    0.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0    0.0   1.0   0.0    3.0   1.0   0.0    100.0  0.0   0.06542056074766354   7 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    4.0   1.0   0.0    0.0   0.0   0.0    0.0    74.0  0.14942528735632185   13 / 87
96.0  116.0  77.0  112.0  99.0  85.0  95.0  72.0  81.0  115.0  84.0  100.0  88.0  100.0  80.0  111.0  89.0  112.0  96.0  88.0  103.0  83.0  97.0  104.0  122.0  85.0  0.14216867469879518   354 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.857831
2    0.928112
3    0.952209
4    0.965462
5    0.975502
6    0.981526
7    0.985141
8    0.988353
9    0.991566
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:53  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:54  5 min 51.783 sec  61392 obs/sec     1         1             10007      0.572036         1.02708             0.994183       0.277817                         0.570419           1.0218                0.994202         0.277912
    2019-08-04 09:05:55  5 min 53.084 sec  69686 obs/sec     10        10            100070     0.398987         0.513512            0.99717        0.145956                         0.401073           0.52315               0.997134         0.142169
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0822594
C13         0.980399               0.980399             0.080647
C8          0.940256               0.940256             0.0773448
C7          0.876835               0.876835             0.0721279
C9          0.861398               0.861398             0.070858
C12         0.853366               0.853366             0.0701973
C11         0.815547               0.815547             0.0670863
C10         0.760905               0.760905             0.0625916
C5          0.71598                0.71598              0.0588961
C6          0.713274               0.713274             0.0586734
C14         0.6731                 0.6731               0.0553688
C3          0.666325               0.666325             0.0548114
C4          0.656596               0.656596             0.0540112
C16         0.637455               0.637455             0.0524367
C2          0.503045               0.503045             0.0413801
C1          0.502193               0.502193             0.0413101
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_28

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.001331190874751087  0.00036236108280718327  0.0         -0.014679901560645359  0.20150542259216309  0.13475723634142442  0.14319860935211182
    3        26       Softmax                      0.0   0.0   0.009495715967222377  0.045358628034591675    0.0         -0.26139358004137025   0.5294628143310547   -0.6449474721383258  0.26130521297454834


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.161917048435649
RMSE: 0.4023891753460187
LogLoss: 0.5220963984661672
Mean Per-Class Error: 0.1485732329347343
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    1.0    4.0    0.0    2.0    0.0    0.0    2.0    7.0    1.0    2.0    1.0    2.0    0.0    4.0    0.0    0.07848101265822785  31 / 395
0.0    331.0  0.0    5.0    4.0    0.0    1.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    5.0    3.0    16.0   9.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.13577023498694518  52 / 383
0.0    0.0    313.0  0.0    20.0   0.0    9.0    0.0    0.0    0.0    9.0    2.0    1.0    0.0    4.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.14945652173913043  55 / 368
1.0    13.0   0.0    348.0  0.0    1.0    0.0    5.0    0.0    7.0    1.0    0.0    6.0    2.0    2.0    1.0    0.0    7.0    0.0    0.0    2.0    0.0    0.0    4.0    0.0    3.0    0.13647642679900746  55 / 403
0.0    2.0    2.0    0.0    326.0  4.0    14.0   1.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    4.0    7.0    2.0    0.0    0.0    0.0    4.0    0.0    12.0   0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    2.0    7.0    1.0    0.0    2.0    2.0    4.0    7.0    2.0    0.0    0.0    2.0    0.0    4.0    2.0    1.0    1.0    2.0    0.0    0.0    348.0  1.0    5.0    0.116751269035533    46 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    9.0    2.0    6.0    1.0    0.0    362.0  0.0    0.07888040712468193  31 / 393
0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    24.0   2.0    0.0    0.0    0.0    0.0    0.0    319.0  0.1307901907356948   48 / 367
391.0  459.0  349.0  428.0  423.0  375.0  377.0  314.0  330.0  377.0  337.0  380.0  393.0  380.0  409.0  374.0  338.0  433.0  403.0  364.0  409.0  358.0  413.0  408.0  403.0  378.0  0.1478556433070079   1,479 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.852144
2    0.919424
3    0.949715
4    0.964011
5    0.973308
6    0.978906
7    0.984105
8    0.988403
9    0.991802
10   0.994602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16343101426071804
RMSE: 0.404266019176381
LogLoss: 0.5251063938039032
Mean Per-Class Error: 0.15506443798690794
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   83.0   0.0   0.0    2.0   0.0   1.0   1.0   1.0   0.0    1.0   0.0    0.0   0.0    1.0   2.0    1.0   7.0    3.0   0.0   0.0    2.0   0.0    1.0    0.0    0.0   0.2169811320754717    23 / 106
0.0   0.0    68.0  0.0    4.0   0.0   3.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0    1.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   1.0    0.0    0.0    0.0   0.17073170731707318   14 / 82
1.0   2.0    0.0   95.0   0.0   1.0   0.0   2.0   0.0   3.0    1.0   0.0    3.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    0.0   0.15178571428571427   17 / 112
0.0   0.0    0.0   0.0    78.0  2.0   3.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    2.0   1.0    4.0   1.0   0.0    0.0   0.0    2.0    0.0    3.0   0.1958762886597938    19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   1.0    2.0   0.0   0.0   1.0   0.0   1.0    3.0   2.0    0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    87.0   0.0    1.0   0.13                  13 / 100
0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    2.0   0.0    0.0   3.0   0.0    2.0   1.0    0.0    96.0   0.0   0.102803738317757     11 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0   0.0    0.0    0.0    76.0  0.12643678160919541   11 / 87
91.0  112.0  74.0  117.0  99.0  87.0  95.0  79.0  78.0  112.0  87.0  103.0  87.0  102.0  83.0  107.0  90.0  106.0  99.0  83.0  105.0  80.0  100.0  104.0  117.0  93.0  0.15502008032128514   386 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.84498
2    0.925703
3    0.954217
4    0.968273
5    0.973494
6    0.980723
7    0.984739
8    0.989157
9    0.991566
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:55  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:56  53.827 sec  60283 obs/sec     1         1             10007      0.574046         1.04706             0.994144       0.279116                         0.575335           1.0457                0.994102         0.283936
    2019-08-04 09:00:57  55.109 sec  70571 obs/sec     10        10            100070     0.402389         0.522096            0.997123       0.147856                         0.404266           0.525106              0.997088         0.15502
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0899427
C15         0.969389               0.969389             0.0871895
C9          0.805866               0.805866             0.0724818
C8          0.797703               0.797703             0.0717476
C7          0.777275               0.777275             0.0699102
C12         0.771054               0.771054             0.0693507
C5          0.712931               0.712931             0.064123
C10         0.708099               0.708099             0.0636884
C11         0.699269               0.699269             0.0628941
C6          0.618805               0.618805             0.055657
C3          0.608178               0.608178             0.0547012
C4          0.591769               0.591769             0.0532253
C16         0.570963               0.570963             0.051354
C14         0.566423               0.566423             0.0509456
C1          0.4624                 0.4624               0.0415895
C2          0.45806                0.45806              0.0411992
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_137

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013466937825796776  0.00035343924537301064  0.0         -0.012661054014309059  0.20154112577438354  0.1602017961565493   0.13233739137649536
    3        26       Softmax                      0.0   0.0   0.008421829028678145   0.031037040054798126    0.0         -0.235656746447017     0.5277369022369385   -0.6237963375394489  0.24751609563827515


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1613789888977157
RMSE: 0.4017200379589195
LogLoss: 0.5224994230091838
Mean Per-Class Error: 0.14984453489635166
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    5.0    1.0    2.0    0.0    1.0    0.0    0.0    2.0    7.0    0.0    2.0    1.0    1.0    3.0    5.0    0.0    0.08607594936708861  34 / 395
0.0    339.0  0.0    11.0   3.0    1.0    0.0    1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    4.0    8.0    6.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.11488250652741515  44 / 383
0.0    0.0    315.0  0.0    14.0   1.0    4.0    0.0    0.0    0.0    13.0   1.0    0.0    0.0    5.0    0.0    2.0    1.0    2.0    1.0    6.0    0.0    3.0    0.0    0.0    0.0    0.14402173913043478  53 / 368
4.0    16.0   0.0    350.0  0.0    1.0    0.0    1.0    0.0    1.0    1.0    0.0    7.0    4.0    0.0    5.0    0.0    8.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    1.0    0.1315136476426799   53 / 403
0.0    12.0   1.0    0.0    315.0  3.0    9.0    0.0    0.0    0.0    4.0    4.0    0.0    0.0    0.0    0.0    7.0    4.0    8.0    3.0    0.0    0.0    0.0    6.0    0.0    8.0    0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    17.0   1.0    6.0    0.0    0.0    3.0    0.0    0.0    4.0    1.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    2.0    0.0    3.0    6.0    0.0    0.0    1.0    2.0    2.0    9.0    1.0    0.0    0.0    2.0    1.0    4.0    1.0    5.0    2.0    1.0    0.0    0.0    347.0  1.0    3.0    0.11704834605597965  46 / 393
0.0    1.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    2.0    13.0   0.0    8.0    1.0    0.0    358.0  0.0    0.089058524173028    35 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    6.0    1.0    30.0   2.0    0.0    0.0    0.0    1.0    0.0    302.0  0.1771117166212534   65 / 367
390.0  469.0  347.0  434.0  413.0  380.0  336.0  299.0  341.0  353.0  382.0  372.0  428.0  377.0  386.0  415.0  367.0  444.0  410.0  366.0  400.0  368.0  375.0  414.0  404.0  333.0  0.1490552834149755   1,491 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850945
2    0.919624
3    0.948215
4    0.963511
5    0.974008
6    0.981406
7    0.984704
8    0.987804
9    0.990503
10   0.993202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16228726886550754
RMSE: 0.4028489405043875
LogLoss: 0.5259328640091109
Mean Per-Class Error: 0.14861921833555705
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    1.0   0.0   1.0    3.0    0.0   0.06741573033707865  6 / 89
0.0   87.0   0.0   3.0    2.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    0.0   2.0    1.0   4.0    3.0    0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    66.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    2.0    1.0   1.0    0.0   1.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
3.0   2.0    0.0   97.0   0.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0    3.0   1.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.13392857142857142  15 / 112
0.0   2.0    0.0   0.0    80.0  1.0   2.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    2.0   1.0    3.0    1.0   0.0    0.0   0.0   1.0    0.0    3.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   1.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   0.0    5.0   1.0    0.0   0.0    0.0   0.0    0.0   1.0    2.0    0.0   0.0    0.0   0.0   86.0   0.0    1.0   0.14                 14 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0    2.0   0.0    3.0   1.0   0.0    98.0   0.0   0.08411214953271028  9 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0    4.0    0.0   0.0    0.0   0.0   0.0    0.0    75.0  0.13793103448275862  12 / 87
93.0  112.0  72.0  122.0  99.0  89.0  80.0  69.0  80.0  103.0  95.0  100.0  96.0  101.0  82.0  117.0  94.0  111.0  106.0  82.0  100.0  82.0  96.0  103.0  119.0  87.0  0.14779116465863454  368 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.852209
2    0.924096
3    0.947791
4    0.964659
5    0.973896
6    0.981124
7    0.98514
8    0.988353
9    0.990361
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:48  3 min 46.520 sec  60648 obs/sec     1         1             10007      0.56951          1.01135             0.994237       0.269019                         0.565787           0.993868              0.994296         0.269076
    2019-08-04 09:03:50  3 min 47.838 sec  68918 obs/sec     10        10            100070     0.40172          0.522499            0.997133       0.149055                         0.402849           0.525933              0.997108         0.147791
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0882934
C15         0.969032               0.969032             0.0855591
C8          0.825402               0.825402             0.0728776
C7          0.800998               0.800998             0.0707229
C9          0.786873               0.786873             0.0694758
C12         0.765142               0.765142             0.067557
C11         0.731001               0.731001             0.0645426
C10         0.716682               0.716682             0.0632784
C5          0.682622               0.682622             0.060271
C6          0.658044               0.658044             0.058101
C14         0.645509               0.645509             0.0569943
C3          0.617403               0.617403             0.0545126
C4          0.592257               0.592257             0.0522924
C16         0.556777               0.556777             0.0491598
C2          0.489097               0.489097             0.0431841
C1          0.489029               0.489029             0.0431781
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_128

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0012851259833155382  0.0003571228589862585  0.0         -0.01104409912793794  0.2041214108467102  0.13465010137247163  0.15180623531341553
    3        26       Softmax                      0.0   0.0   0.009203740186771588   0.04097685217857361    0.0         -0.22547778277589275  0.5263373851776123  -0.6363457344546531  0.2817215919494629


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16157124432693795
RMSE: 0.4019592570484451
LogLoss: 0.5227241652660227
Mean Per-Class Error: 0.1460522113471055
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    2.0    7.0    0.0    1.0    0.0    0.0    1.0    3.0    1.0    1.0    3.0    2.0    1.0    4.0    1.0    0.08860759493670886  35 / 395
0.0    326.0  0.0    14.0   3.0    2.0    2.0    7.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    13.0   7.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    306.0  0.0    15.0   0.0    10.0   0.0    0.0    0.0    14.0   1.0    1.0    0.0    6.0    0.0    0.0    1.0    3.0    1.0    4.0    0.0    6.0    0.0    0.0    0.0    0.16847826086956522  62 / 368
1.0    19.0   0.0    354.0  0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    6.0    4.0    1.0    0.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    2.0    0.12158808933002481  49 / 403
0.0    5.0    0.0    0.0    319.0  6.0    15.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    3.0    4.0    3.0    6.0    0.0    0.0    0.0    5.0    0.0    12.0   0.1671018276762402   64 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    3.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    2.0    0.0    4.0    7.0    0.0    0.0    1.0    2.0    2.0    8.0    0.0    0.0    0.0    2.0    0.0    3.0    2.0    0.0    4.0    1.0    0.0    0.0    349.0  2.0    5.0    0.11421319796954314  45 / 394
0.0    0.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    3.0    0.0    7.0    1.0    0.0    364.0  0.0    0.0737913486005089   29 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    10.0   3.0    0.0    0.0    0.0    0.0    0.0    322.0  0.12021857923497267  44 / 366
388.0  454.0  325.0  424.0  412.0  410.0  378.0  340.0  332.0  368.0  389.0  364.0  421.0  396.0  396.0  370.0  364.0  394.0  320.0  368.0  401.0  368.0  405.0  397.0  415.0  404.0  0.14525642307307807  1,453 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854744
2    0.920024
3    0.947616
4    0.962311
5    0.972508
6    0.979906
7    0.983905
8    0.987904
9    0.990903
10   0.993802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1627740026543985
RMSE: 0.4034526027359329
LogLoss: 0.5267097376225416
Mean Per-Class Error: 0.14579269275187628
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11    12    13     14    15     16    17     18    19    20     21    22    23    24     25     Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   3.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    2.0   1.0   0.0   2.0    0.0    0.10112359550561797  9 / 89
0.0   85.0   0.0   3.0    2.0   2.0    1.0   3.0   0.0   0.0    0.0    0.0   0.0   0.0    1.0   1.0    0.0   4.0    2.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0    0.19811320754716982  21 / 106
0.0   0.0    65.0  0.0    4.0   0.0    1.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   1.0    0.0   2.0   0.0   0.0    0.0    0.2073170731707317   17 / 82
1.0   3.0    0.0   99.0   0.0   0.0    0.0   2.0   0.0   1.0    0.0    0.0   2.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0    0.11607142857142858  13 / 112
0.0   0.0    0.0   0.0    75.0  4.0    4.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   3.0   0.0    0.0   0.0   2.0   0.0    5.0    0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    2.0    0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   87.0  0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   0.0    0.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0   86.0  1.0    2.0    0.14                 14 / 100
0.0   0.0    0.0   1.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   1.0   0.0    2.0   1.0   0.0   97.0   0.0    0.09345794392523364  10 / 107
1.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    76.0   0.12643678160919541  11 / 87
90.0  107.0  68.0  117.0  93.0  100.0  91.0  80.0  79.0  108.0  101.0  93.0  95.0  105.0  85.0  106.0  98.0  100.0  87.0  88.0  103.0  84.0  99.0  98.0  115.0  100.0  0.14538152610441768  362 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854618
2    0.924096
3    0.947791
4    0.961847
5    0.973092
6    0.979116
7    0.985141
8    0.987952
9    0.990361
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:35  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:35  3 min 33.736 sec  53513 obs/sec     1         1             10007      0.570259         1.02854             0.99422        0.276617                         0.568776           1.02099               0.994236         0.275502
    2019-08-04 09:03:37  3 min 35.013 sec  69832 obs/sec     10        10            100070     0.401959         0.522724            0.997128       0.145256                         0.403453           0.52671               0.9971           0.145382
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0910367
C15         0.873137               0.873137             0.0794875
C9          0.795399               0.795399             0.0724105
C7          0.792288               0.792288             0.0721273
C12         0.778908               0.778908             0.0709093
C8          0.769862               0.769862             0.0700857
C11         0.707941               0.707941             0.0644486
C5          0.672887               0.672887             0.0612574
C10         0.646813               0.646813             0.0588837
C14         0.636792               0.636792             0.0579714
C6          0.634554               0.634554             0.0577677
C3          0.579442               0.579442             0.0527505
C16         0.57076                0.57076              0.0519601
C4          0.565861               0.565861             0.0515141
C2          0.501159               0.501159             0.0456239
C1          0.458779               0.458779             0.0417657
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_114

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.00133600110537202   0.0003672561142593622  0.0         -0.009344563276991735  0.20038020610809326  0.15034136861622235  0.14499878883361816
    3        26       Softmax                      0.0   0.0   0.008355441100845313  0.030905939638614655   0.0         -0.25041651154848393   0.5204310417175293   -0.6260371858144844  0.25130677223205566


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16226218731043635
RMSE: 0.40281780907804504
LogLoss: 0.5243938969968437
Mean Per-Class Error: 0.14954252725948597
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    3.0    3.0    0.0    4.0    0.0    0.0    1.0    7.0    0.0    1.0    0.0    2.0    0.0    5.0    0.0    0.07848101265822785  31 / 395
0.0    328.0  0.0    9.0    2.0    1.0    1.0    4.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    14.0   8.0    0.0    0.0    2.0    0.0    3.0    2.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    318.0  0.0    17.0   0.0    3.0    0.0    0.0    0.0    13.0   3.0    0.0    0.0    7.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.1358695652173913   50 / 368
0.0    16.0   0.0    358.0  0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    6.0    3.0    2.0    0.0    0.0    4.0    0.0    1.0    1.0    0.0    0.0    4.0    0.0    1.0    0.11166253101736973  45 / 403
0.0    6.0    1.0    0.0    319.0  2.0    17.0   0.0    0.0    0.0    4.0    7.0    0.0    0.0    0.0    0.0    1.0    3.0    8.0    2.0    0.0    0.0    0.0    5.0    0.0    9.0    0.16927083333333334  65 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    0.0    10.0   0.0    5.0    0.0    0.0    2.0    0.0    0.0    2.0    2.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    0.0    0.0    6.0    5.0    0.0    0.0    2.0    1.0    3.0    4.0    6.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    2.0    1.0    0.0    0.0    354.0  3.0    3.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    13.0   3.0    14.0   1.0    0.0    353.0  0.0    0.10178117048346055  40 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    12.0   0.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    23.0   1.0    0.0    0.0    0.0    0.0    0.0    315.0  0.14168937329700274  52 / 367
388.0  456.0  367.0  437.0  399.0  365.0  336.0  310.0  346.0  366.0  366.0  400.0  412.0  359.0  411.0  387.0  335.0  425.0  395.0  382.0  395.0  380.0  408.0  415.0  401.0  362.0  0.1488553433969809   1,489 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.851145
2    0.920324
3    0.950615
4    0.963811
5    0.976207
6    0.981106
7    0.986204
8    0.988803
9    0.991903
10   0.993402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16155781337534214
RMSE: 0.40194254984430566
LogLoss: 0.5269912408774489
Mean Per-Class Error: 0.14409723348788722
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15     16    17     18    19    20    21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    0.0   3.0    0.0   0.056179775280898875  5 / 89
0.0   86.0   0.0   4.0    1.0   0.0   1.0   2.0   1.0   0.0    1.0   0.0    0.0   0.0   0.0   1.0    1.0   4.0    1.0   0.0   0.0   2.0   0.0    1.0   0.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    67.0  0.0    4.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    2.0   1.0   0.0   0.0   1.0    0.0   0.0    0.0   0.18292682926829268   15 / 82
0.0   3.0    0.0   101.0  0.0   0.0   0.0   1.0   0.0   2.0    0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    1.0   0.0    0.0   0.09821428571428571   11 / 112
0.0   0.0    0.0   0.0    76.0  2.0   6.0   0.0   0.0   0.0    1.0   2.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0   1.0   0.0   0.0   0.0    2.0   0.0    3.0   0.21649484536082475   21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   87.0   0.0   0.0    0.0   0.05434782608695652   5 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   1.0   0.0   0.0    2.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    87.0  1.0    1.0   0.13                  13 / 100
0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    0.0   3.0   0.0   3.0   1.0    0.0   98.0   0.0   0.08411214953271028   9 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0    75.0  0.13793103448275862   12 / 87
88.0  116.0  76.0  120.0  92.0  91.0  84.0  78.0  86.0  106.0  95.0  107.0  91.0  96.0  85.0  108.0  90.0  106.0  96.0  90.0  99.0  86.0  101.0  98.0  116.0  89.0  0.14377510040160643   358 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.856225
2    0.92249
3    0.95261
4    0.96506
5    0.976707
6    0.982731
7    0.98755
8    0.989157
9    0.990763
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:13  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:13  3 min 11.588 sec  60283 obs/sec     1         1             10007      0.572951         1.04441             0.994167       0.277817                         0.570809           1.03367               0.994194         0.283133
    2019-08-04 09:03:15  3 min 12.876 sec  70224 obs/sec     10        10            100070     0.402818         0.524394            0.997117       0.148855                         0.401943           0.526991              0.997121         0.143775
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0846903
C15         0.971845               0.971845             0.0823059
C9          0.887365               0.887365             0.0751512
C8          0.860884               0.860884             0.0729085
C12         0.85114                0.85114              0.0720833
C7          0.813858               0.813858             0.0689259
C6          0.731833               0.731833             0.0619792
C5          0.728653               0.728653             0.0617098
C11         0.724789               0.724789             0.0613826
C10         0.706792               0.706792             0.0598584
C3          0.666176               0.666176             0.0564187
C4          0.654292               0.654292             0.0554122
C14         0.619117               0.619117             0.0524332
C16         0.57688                0.57688              0.0488562
C2          0.53905                0.53905              0.0456523
C1          0.47505                0.47505              0.0402321
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_227

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.001303850166792131  0.0003645322285592556  0.0         -0.011870918267064212  0.20196759700775146  0.1368085162926232   0.15964478254318237
    3        26       Softmax                      0.0   0.0   0.009366161779133528  0.037484005093574524   0.0         -0.2522146631111862    0.5254664421081543   -0.6371417724416968  0.22688162326812744


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16201802341274602
RMSE: 0.4025146250917425
LogLoss: 0.5231481715904023
Mean Per-Class Error: 0.14749086435295497
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    2.0    4.0    0.0    3.0    0.0    0.0    2.0    2.0    0.0    3.0    0.0    2.0    0.0    5.0    3.0    0.0810126582278481   32 / 395
0.0    340.0  0.0    4.0    3.0    0.0    1.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    4.0    0.0    12.0   6.0    0.0    0.0    2.0    0.0    3.0    0.0    1.0    0.1122715404699739   43 / 383
0.0    0.0    310.0  1.0    14.0   0.0    6.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    6.0    0.0    2.0    1.0    4.0    1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.1553133514986376   57 / 367
1.0    13.0   0.0    354.0  0.0    2.0    0.0    0.0    0.0    1.0    1.0    0.0    6.0    4.0    4.0    1.0    0.0    10.0   0.0    0.0    1.0    0.0    0.0    2.0    0.0    3.0    0.12158808933002481  49 / 403
0.0    5.0    2.0    0.0    331.0  3.0    17.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    2.0    4.0    2.0    2.0    1.0    0.0    0.0    4.0    0.0    8.0    0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    3.0    0.0    0.0    6.0    0.0    348.0  0.0    0.0    0.0    0.072                27 / 375
0.0    1.0    0.0    3.0    7.0    0.0    0.0    2.0    2.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    3.0    0.0    0.0    354.0  3.0    7.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    5.0    0.0    2.0    8.0    2.0    6.0    1.0    0.0    359.0  0.0    0.08418367346938775  33 / 392
2.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    13.0   3.0    0.0    0.0    0.0    0.0    0.0    318.0  0.1335149863760218   49 / 367
395.0  468.0  353.0  424.0  440.0  360.0  327.0  290.0  341.0  355.0  384.0  364.0  406.0  387.0  417.0  377.0  363.0  435.0  345.0  382.0  412.0  352.0  413.0  415.0  408.0  390.0  0.1467559732080376   1,468 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853244
2    0.922023
3    0.948715
4    0.962311
5    0.973408
6    0.981306
7    0.985304
8    0.989103
9    0.991702
10   0.994302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16335431372993506
RMSE: 0.404171144108452
LogLoss: 0.5293736601400998
Mean Per-Class Error: 0.1482086406012242
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   92.0   0.0   1.0    2.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0   4.0    0.0   0.0   0.0    2.0   0.0    2.0    0.0    0.0   0.1320754716981132   14 / 106
0.0   0.0    65.0  0.0    3.0    0.0   3.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.2073170731707317   17 / 82
1.0   1.0    0.0   100.0  0.0    1.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0   1.0    0.0   1.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    1.0    0.0    2.0   0.10714285714285714  12 / 112
0.0   1.0    1.0   0.0    81.0   1.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0   1.0   0.0    0.0   0.0    2.0    0.0    2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0   2.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    86.0   1.0    2.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   2.0   0.0    1.0   1.0    0.0    100.0  0.0   0.06542056074766354  7 / 107
1.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0    0.0    0.0    75.0  0.13793103448275862  12 / 87
91.0  119.0  75.0  120.0  109.0  82.0  83.0  68.0  84.0  104.0  97.0  97.0  91.0  101.0  89.0  105.0  93.0  109.0  84.0  94.0  101.0  79.0  100.0  100.0  119.0  96.0  0.14698795180722893  366 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853012
2    0.925301
3    0.947791
4    0.961446
5    0.972289
6    0.979116
7    0.983534
8    0.989157
9    0.989558
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:41  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:41  6 min 39.098 sec  62155 obs/sec     1         1             10007      0.573841         1.03255             0.994146       0.26772                          0.571192           1.02265               0.994187         0.268675
    2019-08-04 09:06:42  6 min 40.391 sec  70372 obs/sec     10        10            100070     0.402515         0.523148            0.99712        0.146756                         0.404171           0.529374              0.997089         0.146988
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0848316
C13         0.996393               0.996393             0.0845256
C9          0.90838                0.90838              0.0770594
C12         0.831304               0.831304             0.0705209
C8          0.789793               0.789793             0.0669995
C11         0.782576               0.782576             0.0663872
C7          0.778038               0.778038             0.0660022
C5          0.769927               0.769927             0.0653142
C10         0.727344               0.727344             0.0617018
C14         0.686854               0.686854             0.058267
C6          0.64295                0.64295              0.0545425
C4          0.62639                0.62639              0.0531377
C3          0.621664               0.621664             0.0527368
C16         0.575489               0.575489             0.0488197
C1          0.53432                0.53432              0.0453272
C2          0.516633               0.516633             0.0438268
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_11

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013313078787291488  0.0003511755494400859  0.0         -0.00878644237307924  0.19873666763305664  0.1497226710980313   0.14868199825286865
    3        26       Softmax                      0.0   0.0   0.008886951769909501   0.03112562745809555    0.0         -0.23706797674152888  0.522730827331543    -0.6369581172019038  0.254422664642334


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16401157095798025
RMSE: 0.4049834205964242
LogLoss: 0.5314003594587596
Mean Per-Class Error: 0.15068173088491682
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    6.0    1.0    5.0    0.0    1.0    0.0    0.0    1.0    7.0    0.0    1.0    1.0    2.0    2.0    5.0    0.0    0.09873417721518987  39 / 395
0.0    340.0  0.0    4.0    3.0    1.0    1.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    2.0    1.0    2.0    16.0   5.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    304.0  0.0    17.0   0.0    9.0    1.0    0.0    0.0    19.0   0.0    0.0    0.0    6.0    0.0    3.0    0.0    3.0    1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.17166212534059946  63 / 367
1.0    23.0   0.0    353.0  0.0    1.0    0.0    2.0    0.0    2.0    0.0    0.0    7.0    4.0    1.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.12406947890818859  50 / 403
0.0    6.0    1.0    0.0    332.0  2.0    16.0   1.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    1.0    4.0    8.0    1.0    1.0    0.0    0.0    0.0    0.0    7.0    0.13541666666666666  52 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    14.0   1.0    1.0    0.0    0.0    11.0   0.0    0.0    2.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    3.0    0.0    5.0    4.0    1.0    0.0    1.0    2.0    2.0    7.0    1.0    0.0    0.0    2.0    0.0    6.0    1.0    0.0    2.0    1.0    0.0    0.0    350.0  2.0    4.0    0.1116751269035533   44 / 394
1.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    2.0    11.0   0.0    22.0   1.0    0.0    340.0  0.0    0.13486005089058525  53 / 393
1.0    0.0    0.0    0.0    21.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    30.0   1.0    0.0    0.0    0.0    0.0    1.0    302.0  0.1771117166212534   65 / 367
390.0  481.0  340.0  431.0  439.0  388.0  344.0  306.0  341.0  363.0  387.0  356.0  433.0  384.0  405.0  391.0  356.0  441.0  411.0  352.0  387.0  374.0  387.0  404.0  379.0  333.0  0.14995501349595122  1,500 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850045
2    0.921224
3    0.948116
4    0.961312
5    0.973008
6    0.979306
7    0.985305
8    0.988803
9    0.991203
10   0.993402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16500059013777452
RMSE: 0.40620264664053396
LogLoss: 0.5342755897792854
Mean Per-Class Error: 0.14720210092751254
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18     19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   1.0   1.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   88.0   0.0   0.0    2.0    1.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   2.0   1.0    0.0   6.0    2.0    0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    66.0  0.0    3.0    0.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    2.0    1.0   0.0   0.0   1.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
1.0   3.0    0.0   100.0  0.0    1.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.10714285714285714  12 / 112
0.0   1.0    0.0   0.0    82.0   1.0   5.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    3.0    1.0   0.0   0.0   0.0   0.0    0.0    2.0   0.15463917525773196  15 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   1.0    0.0   2.0    2.0    1.0   0.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    1.0   1.0    0.0    0.0   0.0   0.0   0.0   87.0   0.0    1.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    3.0   0.0    0.0    2.0   0.0   8.0   1.0   0.0    90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   0.0    1.0    72.0  0.1724137931034483   15 / 87
90.0  116.0  72.0  124.0  104.0  95.0  89.0  71.0  82.0  102.0  99.0  95.0  98.0  99.0  86.0  109.0  95.0  111.0  101.0  82.0  98.0  85.0  96.0  102.0  106.0  83.0  0.14698795180722893  366 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853012
2    0.926908
3    0.948594
4    0.961446
5    0.972289
6    0.979518
7    0.986747
8    0.989157
9    0.990763
10   0.993976
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:25  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:25  23.263 sec  57511 obs/sec     1         1             10007      0.568231         1.02273             0.994262       0.270319                         0.567241           1.01549               0.994267         0.271888
    2019-08-04 09:00:26  24.603 sec  67798 obs/sec     10        10            100070     0.404983         0.5314              0.997085       0.149955                         0.406203           0.534276              0.99706          0.146988
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0853588
C13         0.999778               0.999778             0.0853399
C9          0.847319               0.847319             0.0723261
C7          0.844466               0.844466             0.0720826
C12         0.844279               0.844279             0.0720666
C8          0.839892               0.839892             0.0716922
C5          0.76019                0.76019              0.0648889
C11         0.749565               0.749565             0.063982
C14         0.682904               0.682904             0.0582919
C6          0.664224               0.664224             0.0566974
C10         0.661472               0.661472             0.0564624
C3          0.636085               0.636085             0.0542955
C16         0.60817                0.60817              0.0519126
C4          0.58727                0.58727              0.0501287
C1          0.504422               0.504422             0.0430568
C2          0.485217               0.485217             0.0414175
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_101

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017981464871468233  0.00046022050082683563  0.0         -0.0188320413772729    0.4561493396759033   -0.03320780989982223  0.5014350414276123
    3        26       Softmax                 0.0   0.0   0.002306292207322258   0.0007750643417239189   0.0         0.0026354901562387367  0.41214466094970703  -0.4848666789559115   0.16843253374099731


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.15914470234880743
RMSE: 0.3989294453268741
LogLoss: 0.5409799795416546
Mean Per-Class Error: 0.15772037701383007
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    1.0    5.0    2.0    4.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    2.0    1.0    2.0    2.0    5.0    3.0    0.08860759493670886  35 / 395
0.0    328.0  0.0    5.0    1.0    2.0    1.0    3.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    16.0   10.0   0.0    1.0    2.0    0.0    3.0    2.0    1.0    0.14360313315926893  55 / 383
0.0    0.0    305.0  1.0    13.0   1.0    8.0    1.0    0.0    0.0    27.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    4.0    1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
2.0    15.0   0.0    344.0  0.0    1.0    0.0    1.0    0.0    2.0    0.0    0.0    6.0    5.0    3.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    9.0    0.0    5.0    0.14427860696517414  58 / 402
0.0    4.0    1.0    0.0    301.0  8.0    14.0   0.0    0.0    0.0    12.0   1.0    0.0    0.0    0.0    0.0    8.0    5.0    9.0    5.0    1.0    0.0    0.0    5.0    0.0    10.0   0.21614583333333334  83 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    12.0   0.0    5.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    2.0    0.0    6.0    4.0    1.0    0.0    1.0    3.0    0.0    14.0   2.0    0.0    0.0    2.0    0.0    3.0    0.0    2.0    1.0    1.0    0.0    0.0    348.0  1.0    2.0    0.11450381679389313  45 / 393
0.0    0.0    0.0    2.0    1.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    5.0    0.0    1.0    12.0   1.0    14.0   0.0    1.0    346.0  0.0    0.11959287531806616  47 / 393
2.0    1.0    0.0    1.0    13.0   0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    29.0   3.0    0.0    0.0    0.0    3.0    0.0    304.0  0.17166212534059946  63 / 367
393.0  454.0  324.0  440.0  364.0  387.0  353.0  305.0  330.0  349.0  435.0  357.0  417.0  394.0  385.0  395.0  384.0  423.0  394.0  392.0  390.0  363.0  395.0  445.0  382.0  353.0  0.15685294411676498  1,569 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.843147
2    0.915125
3    0.943617
4    0.960512
5    0.971209
6    0.977707
7    0.982305
8    0.985804
9    0.988803
10   0.991203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1598260462623156
RMSE: 0.3997824986943721
LogLoss: 0.5451426373278127
Mean Per-Class Error: 0.16091433421630452
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   1.0    0.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   86.0   0.0   1.0    1.0   1.0   1.0   1.0   1.0   0.0    1.0    0.0   0.0   0.0    0.0   1.0    0.0   6.0    2.0    0.0   1.0    2.0   0.0    1.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    66.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.1951219512195122   16 / 82
1.0   1.0    0.0   99.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   2.0   2.0    1.0   0.0    0.0   3.0    0.0    0.0   0.0    0.0   0.0    1.0    0.0    1.0   0.11607142857142858  13 / 112
0.0   0.0    0.0   0.0    69.0  3.0   6.0   0.0   0.0   0.0    6.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0    5.0    2.0   0.0    0.0   0.0    1.0    0.0    3.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   2.0   0.0    1.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0   0.0   1.0   0.0    7.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    84.0   0.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0    0.0   3.0    2.0   0.0    0.0    2.0   0.0    4.0   0.0    0.0    94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   1.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    6.0    1.0   0.0    0.0   0.0    1.0    0.0    70.0  0.19540229885057472  17 / 87
93.0  109.0  68.0  125.0  84.0  89.0  90.0  71.0  81.0  103.0  111.0  93.0  87.0  107.0  81.0  115.0  99.0  106.0  109.0  94.0  103.0  81.0  100.0  102.0  106.0  83.0  0.15943775100401605  397 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840562
2    0.916466
3    0.945783
4    0.960642
5    0.971084
6    0.976305
7    0.980723
8    0.985944
9    0.989157
10   0.990361
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:49  2 min 46.968 sec  45903 obs/sec     1         1             10007      0.54681          0.974146            0.994686       0.26672                          0.545815           0.973385              0.994692         0.268273
    2019-08-04 09:02:51  2 min 48.964 sec  45945 obs/sec     10        10            100070     0.398929         0.54098             0.997172       0.156853                         0.399782           0.545143              0.997152         0.159438
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0917395
C13         0.91857                0.91857              0.0842691
C12         0.842605               0.842605             0.0773001
C9          0.842024               0.842024             0.0772468
C7          0.762226               0.762226             0.0699262
C8          0.724862               0.724862             0.0664984
C11         0.706471               0.706471             0.0648113
C10         0.689588               0.689588             0.0632625
C14         0.66658                0.66658              0.0611517
C6          0.625101               0.625101             0.0573464
C16         0.614816               0.614816             0.0564029
C5          0.59239                0.59239              0.0543456
C3          0.563686               0.563686             0.0517122
C4          0.491127               0.491127             0.0450558
C2          0.436847               0.436847             0.0400761
C1          0.423542               0.423542             0.0388555
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_66

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.001036943215183328   0.00027210835833102465  0.0         -0.017971307508137357  0.2473035454750061  0.2677951155083006   0.19036251306533813
    3        26       Softmax                      0.0   0.0   0.0069848239789350305  0.027989692986011505    0.0         -0.2946191225439459    0.7063734531402588  -0.4730224952280156  0.227100670337677


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1691194101796187
RMSE: 0.4112413040778111
LogLoss: 0.5506811835700406
Mean Per-Class Error: 0.15858949987718535
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    6.0    1.0    3.0    0.0    0.0    0.0    0.0    2.0    7.0    0.0    3.0    0.0    2.0    3.0    4.0    0.0    0.09113924050632911  36 / 395
2.0    340.0  0.0    7.0    4.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    3.0    2.0    8.0    7.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    316.0  0.0    14.0   0.0    4.0    1.0    0.0    0.0    18.0   1.0    0.0    0.0    7.0    0.0    0.0    0.0    5.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.14130434782608695  52 / 368
2.0    23.0   0.0    348.0  0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    3.0    9.0    3.0    0.0    1.0    6.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.13647642679900746  55 / 403
0.0    3.0    5.0    0.0    329.0  1.0    7.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    9.0    4.0    11.0   1.0    1.0    0.0    0.0    0.0    0.0    7.0    0.14322916666666666  55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    1.0    0.0    11.0   3.0    3.0    0.0    0.0    3.0    0.0    0.0    5.0    2.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    3.0    0.0    5.0    5.0    0.0    0.0    4.0    6.0    3.0    8.0    1.0    0.0    0.0    0.0    0.0    2.0    2.0    2.0    2.0    1.0    0.0    0.0    344.0  2.0    4.0    0.12690355329949238  50 / 394
0.0    1.0    0.0    3.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    3.0    12.0   1.0    20.0   0.0    0.0    340.0  0.0    0.13486005089058525  53 / 393
2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    1.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    12.0   3.0    0.0    0.0    0.0    1.0    0.0    324.0  0.11716621253405994  43 / 367
396.0  496.0  365.0  436.0  417.0  327.0  332.0  320.0  348.0  337.0  384.0  358.0  398.0  392.0  389.0  413.0  375.0  432.0  379.0  365.0  404.0  376.0  406.0  403.0  388.0  367.0  0.15795261421573528  1,580 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842047
2    0.915625
3    0.945416
4    0.960912
5    0.971808
6    0.977807
7    0.983505
8    0.986304
9    0.990303
10   0.992902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17176788592309067
RMSE: 0.4144488942235106
LogLoss: 0.5554005444428667
Mean Per-Class Error: 0.16332501920718429
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   1.0   1.0   2.0    0.0   0.07865168539325842  7 / 89
1.0   87.0   0.0   2.0    2.0   1.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0    2.0   1.0    1.0    3.0    2.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    67.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    3.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.18292682926829268  15 / 82
1.0   4.0    0.0   97.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   1.0   3.0    1.0   0.0    1.0    0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.13392857142857142  15 / 112
0.0   0.0    1.0   0.0    79.0  1.0   1.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    3.0    1.0    4.0   1.0   0.0    0.0   0.0   0.0   0.0    3.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   1.0    0.0   0.0    0.0    1.0    0.0   0.0   2.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   2.0   0.0   1.0   2.0   1.0   0.0   0.0    0.0   0.0    0.0    2.0    1.0   0.0   0.0    0.0   0.0   85.0  0.0    1.0   0.15                 15 / 100
0.0   1.0    0.0   2.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    2.0    0.0    0.0   4.0   0.0    5.0   0.0   0.0   91.0   0.0   0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    3.0   1.0   0.0    0.0   0.0   0.0   0.0    76.0  0.12643678160919541  11 / 87
90.0  116.0  76.0  124.0  99.0  77.0  82.0  88.0  82.0  97.0  97.0  97.0  85.0  105.0  83.0  121.0  101.0  109.0  95.0  87.0  101.0  83.0  97.0  99.0  107.0  92.0  0.16184738955823294  403 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838153
2    0.913253
3    0.946586
4    0.961446
5    0.970281
6    0.9751
7    0.983534
8    0.986345
9    0.990361
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:50  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:50  1 min 48.154 sec  112438 obs/sec    1         1             10007      0.600436         1.11438             0.993594       0.308108                         0.602791           1.11635               0.993526         0.317671
    2019-08-04 09:01:51  1 min 48.881 sec  125401 obs/sec    10        10            100070     0.411241         0.550681            0.996995       0.157953                         0.414449           0.555401              0.996939         0.161847
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0818308
C8          0.998474               0.998474             0.0817059
C15         0.995174               0.995174             0.0814359
C9          0.912274               0.912274             0.0746521
C12         0.874142               0.874142             0.0715317
C11         0.797013               0.797013             0.0652202
C7          0.779924               0.779924             0.0638217
C5          0.762494               0.762494             0.0623954
C10         0.742326               0.742326             0.0607451
C14         0.742119               0.742119             0.0607282
C4          0.682846               0.682846             0.0558778
C6          0.676237               0.676237             0.055337
C16         0.671422               0.671422             0.0549429
C3          0.569884               0.569884             0.046634
C2          0.530411               0.530411             0.0434039
C1          0.485603               0.485603             0.0397373
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_55

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0016681376493181688  0.00043465953785926104  0.0         0.014969346640469894   0.4470958709716797   0.0025031857776701494  0.4679523706436157
    3        26       Softmax                 0.0   0.0   0.002172079471480314   0.0006267828866839409   0.0         -0.008678827921948176  0.41526615619659424  -0.4875741476197301    0.17130935192108154


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16134632553847042
RMSE: 0.4016793815202249
LogLoss: 0.5496522840909491
Mean Per-Class Error: 0.16204452431290226
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    4.0    2.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    3.0    1.0    2.0    3.0    5.0    2.0    0.07341772151898734  29 / 395
0.0    348.0  0.0    6.0    2.0    1.0    1.0    3.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    6.0    0.0    0.0    3.0    0.0    3.0    3.0    0.0    0.09138381201044386  35 / 383
0.0    0.0    310.0  1.0    11.0   0.0    10.0   0.0    0.0    0.0    14.0   0.0    1.0    0.0    13.0   0.0    1.0    0.0    1.0    1.0    2.0    0.0    3.0    0.0    0.0    0.0    0.15760869565217392  58 / 368
1.0    38.0   0.0    324.0  0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    4.0    6.0    6.0    0.0    0.0    6.0    1.0    1.0    2.0    0.0    0.0    7.0    0.0    1.0    0.19602977667493796  79 / 403
0.0    7.0    0.0    0.0    322.0  4.0    17.0   0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    5.0    2.0    1.0    0.0    0.0    6.0    0.0    12.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    16.0   0.0    6.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    4.0    0.0    4.0    6.0    0.0    0.0    2.0    4.0    0.0    7.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    1.0    3.0    1.0    0.0    0.0    345.0  7.0    3.0    0.12436548223350254  49 / 394
1.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    1.0    5.0    2.0    13.0   1.0    1.0    360.0  0.0    0.08396946564885496  33 / 393
3.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    20.0   3.0    0.0    0.0    0.0    2.0    0.0    319.0  0.1307901907356948   48 / 367
415.0  591.0  330.0  380.0  413.0  381.0  404.0  275.0  340.0  363.0  373.0  348.0  421.0  381.0  422.0  362.0  326.0  366.0  325.0  360.0  406.0  389.0  392.0  436.0  419.0  385.0  0.1613515945216435   1,614 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838648
2    0.913426
3    0.943617
4    0.960912
5    0.970209
6    0.977207
7    0.983005
8    0.986504
9    0.989203
10   0.991502

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16296200230316812
RMSE: 0.4036855240198342
LogLoss: 0.5566239641442685
Mean Per-Class Error: 0.15791269658621676
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17    18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   2.0    1.0   0.056179775280898875  5 / 89
0.0   92.0   0.0   2.0    1.0   0.0   1.0    2.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   1.0   0.0   0.0    3.0   0.0   1.0   1.0    0.0   0.1320754716981132    14 / 106
0.0   0.0    69.0  0.0    2.0   0.0   2.0    0.0   0.0   0.0    2.0   0.0   0.0   0.0    5.0   0.0    0.0   0.0   0.0   1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.15853658536585366   13 / 82
1.0   8.0    0.0   92.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0   0.0   1.0   2.0    1.0   0.0    0.0   2.0   0.0   0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.17857142857142858   20 / 112
0.0   1.0    0.0   0.0    78.0  3.0   5.0    0.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   2.0   1.0   0.0    0.0   0.0   1.0   0.0    4.0   0.1958762886597938    19 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   4.0   0.0    1.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782   6 / 92
0.0   1.0    0.0   2.0    3.0   0.0   0.0    1.0   1.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   84.0  2.0    1.0   0.16                  16 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0   1.0   0.0    5.0   1.0   0.0   98.0   0.0   0.08411214953271028   9 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0    76.0  0.12643678160919541   11 / 87
99.0  146.0  71.0  108.0  97.0  87.0  105.0  71.0  84.0  106.0  96.0  91.0  91.0  103.0  87.0  106.0  83.0  90.0  79.0  84.0  104.0  89.0  97.0  99.0  122.0  95.0  0.1578313253012048    393 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842169
2    0.913655
3    0.944578
4    0.959839
5    0.967871
6    0.976305
7    0.982731
8    0.985141
9    0.988755
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:38  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:38  1 min 36.220 sec  45280 obs/sec     1         1             10007      0.550054         1.00076             0.994625       0.26662                          0.548889           0.992915              0.994632         0.271084
    2019-08-04 09:01:40  1 min 38.222 sec  45735 obs/sec     10        10            100070     0.401679         0.549652            0.997134       0.161352                         0.403686           0.556624              0.997096         0.157831
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0923479
C13         0.879528               0.879528             0.0812225
C12         0.828309               0.828309             0.0764926
C9          0.811929               0.811929             0.0749799
C11         0.793868               0.793868             0.073312
C7          0.769398               0.769398             0.0710523
C8          0.745851               0.745851             0.0688777
C14         0.710958               0.710958             0.0656554
C10         0.684629               0.684629             0.063224
C16         0.663049               0.663049             0.0612312
C6          0.61619                0.61619              0.0569038
C5          0.566479               0.566479             0.0523131
C4          0.506096               0.506096             0.0467369
C3          0.484756               0.484756             0.0447662
C2          0.387296               0.387296             0.035766
C1          0.380286               0.380286             0.0351186
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_7

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0016251750953983901  0.0004170911852270365  0.0         -0.011416877606642117  0.45341956615448    -0.08202968291890086  0.48278284072875977
    3        26       Softmax                 0.0   0.0   0.002176282339930297   0.0006294294726103544  0.0         0.0004227068034434904  0.4134331941604614  -0.498325054168974    0.18401622772216797


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16309223416008697
RMSE: 0.40384679540648455
LogLoss: 0.5543407653622641
Mean Per-Class Error: 0.164793056633593
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    2.0    0.0    6.0    2.0    2.0    0.0    0.0    1.0    3.0    1.0    2.0    1.0    2.0    1.0    7.0    0.0    0.08607594936708861  34 / 395
0.0    328.0  0.0    8.0    6.0    0.0    1.0    9.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    10.0   10.0   0.0    0.0    4.0    0.0    1.0    3.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    309.0  1.0    16.0   0.0    11.0   1.0    0.0    0.0    10.0   0.0    0.0    0.0    6.0    0.0    2.0    0.0    2.0    2.0    6.0    0.0    2.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
1.0    24.0   0.0    336.0  0.0    1.0    0.0    9.0    2.0    1.0    2.0    0.0    4.0    7.0    5.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    0.1662531017369727   67 / 403
0.0    0.0    0.0    0.0    331.0  3.0    11.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    5.0    2.0    0.0    0.0    0.0    1.0    0.0    19.0   0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    10.0   0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    9.0    0.0    8.0    0.0    1.0    2.0    0.0    0.0    2.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    2.0    0.0    4.0    7.0    3.0    0.0    3.0    3.0    1.0    7.0    1.0    0.0    0.0    2.0    0.0    4.0    0.0    7.0    1.0    1.0    2.0    0.0    340.0  3.0    3.0    0.13705583756345177  54 / 394
0.0    1.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    8.0    3.0    8.0    1.0    1.0    357.0  0.0    0.0916030534351145   36 / 393
1.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    22.0   4.0    0.0    0.0    0.0    4.0    1.0    309.0  0.1557377049180328   57 / 366
398.0  485.0  338.0  410.0  448.0  357.0  351.0  323.0  335.0  339.0  363.0  346.0  407.0  392.0  405.0  395.0  388.0  426.0  337.0  379.0  404.0  362.0  406.0  399.0  428.0  382.0  0.16385084474657602  1,639 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836149
2    0.908228
3    0.941518
4    0.957513
5    0.968909
6    0.975707
7    0.981106
8    0.986304
9    0.989003
10   0.991703

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1641878690520389
RMSE: 0.40520102301455124
LogLoss: 0.5633527999326431
Mean Per-Class Error: 0.16449395687323579
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12    13     14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   1.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    0.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   2.0    3.0    0.0   1.0   3.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0    5.0    1.0   0.0   0.0    3.0   0.0    1.0    2.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    66.0  0.0    4.0    0.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0    1.0   2.0   2.0    0.0   1.0    0.0    0.0    0.0   0.1951219512195122   16 / 82
1.0   4.0    0.0   93.0   0.0    0.0   0.0   4.0   1.0   0.0   2.0   0.0   2.0   1.0    1.0   1.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0   0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    77.0   2.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0    3.0   1.0   0.0    0.0   0.0    1.0    0.0    6.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0    1.0    0.0   0.0   0.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0    1.0   0.0   1.0   0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   0.0    86.0   0.0    2.0   0.14                 14 / 100
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0    0.0   1.0   0.0    3.0   1.0    0.0    99.0   0.0   0.07476635514018691  8 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0    3.0   1.0   0.0    0.0   0.0    2.0    1.0    74.0  0.14942528735632185  13 / 87
93.0  120.0  68.0  114.0  104.0  81.0  86.0  82.0  77.0  99.0  97.0  90.0  88.0  107.0  80.0  114.0  100.0  111.0  83.0  92.0  100.0  83.0  100.0  100.0  124.0  97.0  0.1634538152610442   407 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836546
2    0.908835
3    0.938153
4    0.956225
5    0.970281
6    0.976707
7    0.983132
8    0.987148
9    0.989558
10   0.992369
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:18  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:18  16.201 sec  46115 obs/sec     1         1             10007      0.54778          0.987102            0.994667       0.26682                          0.548092           0.986717              0.994647         0.2751
    2019-08-04 09:00:20  18.109 sec  47972 obs/sec     10        10            100070     0.403847         0.554341            0.997101       0.163851                         0.405201           0.563353              0.997074         0.163454
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0867656
C15         0.978823               0.978823             0.0849282
C9          0.905886               0.905886             0.0785998
C12         0.89642                0.89642              0.0777784
C8          0.803695               0.803695             0.0697331
C7          0.782859               0.782859             0.0679252
C11         0.771485               0.771485             0.0669383
C14         0.700925               0.700925             0.0608162
C10         0.69416                0.69416              0.0602293
C5          0.656836               0.656836             0.0569908
C6          0.646546               0.646546             0.056098
C16         0.638695               0.638695             0.0554167
C3          0.586635               0.586635             0.0508997
C4          0.545787               0.545787             0.0473555
C2          0.465548               0.465548             0.0403936
C1          0.451002               0.451002             0.0391315
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_16

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.001768234515026279   0.00045787461567670107  0.0         -0.013287334086046432  0.46519935131073    0.002992521009297046  0.5124413967132568
    3        26       Softmax                 0.0   0.0   0.0022479970410901073  0.0005513282958418131   0.0         0.005535495615167572   0.4142543077468872  -0.4962479273876654   0.19535261392593384


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1647775912022011
RMSE: 0.40592806160969097
LogLoss: 0.5579535074727824
Mean Per-Class Error: 0.16656044991471278
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    3.0    2.0    5.0    1.0    0.0    0.0    1.0    5.0    2.0    0.0    2.0    1.0    1.0    1.0    6.0    1.0    0.09873417721518987  39 / 395
0.0    330.0  0.0    6.0    4.0    0.0    2.0    1.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    22.0   2.0    0.0    0.0    4.0    1.0    1.0    1.0    3.0    0.13838120104438642  53 / 383
0.0    0.0    318.0  1.0    8.0    0.0    5.0    1.0    0.0    0.0    17.0   3.0    0.0    0.0    3.0    0.0    3.0    0.0    3.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.1358695652173913   50 / 368
1.0    17.0   0.0    347.0  0.0    0.0    0.0    5.0    0.0    4.0    0.0    0.0    6.0    4.0    1.0    2.0    0.0    4.0    0.0    1.0    3.0    0.0    1.0    4.0    0.0    3.0    0.13895781637717122  56 / 403
0.0    3.0    0.0    0.0    319.0  5.0    6.0    0.0    2.0    0.0    2.0    5.0    0.0    0.0    0.0    0.0    11.0   5.0    4.0    3.0    0.0    0.0    0.0    6.0    0.0    13.0   0.16927083333333334  65 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    1.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    16.0   2.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    2.0    0.0    6.0    6.0    0.0    0.0    2.0    3.0    3.0    3.0    3.0    0.0    0.0    2.0    1.0    4.0    1.0    1.0    5.0    1.0    0.0    0.0    341.0  5.0    4.0    0.13231552162849872  52 / 393
0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    20.0   2.0    26.0   1.0    1.0    332.0  0.0    0.15306122448979592  60 / 392
0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    9.0    1.0    13.0   4.0    0.0    0.0    0.0    3.0    0.0    311.0  0.15258855585831063  56 / 367
385.0  510.0  363.0  415.0  398.0  374.0  318.0  295.0  350.0  377.0  355.0  364.0  428.0  381.0  379.0  369.0  400.0  465.0  296.0  391.0  407.0  368.0  416.0  414.0  395.0  390.0  0.16575027491752475  1,658 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83425
2    0.913726
3    0.943517
4    0.958413
5    0.969309
6    0.976107
7    0.981706
8    0.985804
9    0.988503
10   0.991703

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16673403140599888
RMSE: 0.40833078674770396
LogLoss: 0.5653093273960068
Mean Per-Class Error: 0.17016105121355674
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   1.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0    1.0   0.06741573033707865  6 / 89
0.0   86.0   0.0   3.0    3.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    8.0    0.0   0.0   0.0    2.0   1.0    1.0   0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    69.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    2.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   1.0    0.0   96.0   0.0   0.0   0.0   3.0   0.0   2.0    0.0   0.0   2.0   1.0    0.0   1.0    0.0    1.0    0.0   0.0   2.0    0.0   0.0    1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    71.0  3.0   2.0   0.0   1.0   0.0    1.0   2.0   0.0   0.0    0.0   0.0    3.0    2.0    2.0   2.0   0.0    0.0   0.0    2.0   0.0    6.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0    1.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   2.0   1.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0    84.0  3.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   4.0   0.0    8.0   1.0    0.0   92.0   0.0   0.14018691588785046  15 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0    2.0   1.0   0.0    0.0   0.0    0.0   0.0    74.0  0.14942528735632185  13 / 87
92.0  122.0  75.0  120.0  91.0  83.0  79.0  72.0  91.0  104.0  89.0  95.0  95.0  102.0  78.0  110.0  105.0  117.0  72.0  92.0  103.0  84.0  103.0  99.0  118.0  99.0  0.16947791164658635  422 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830522
2    0.913655
3    0.945381
4    0.959839
5    0.969879
6    0.976305
7    0.980723
8    0.98514
9    0.988755
10   0.991566
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:33  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:33  31.671 sec  45903 obs/sec     1         1             10007      0.539545         0.957898            0.994825       0.26762                          0.537561           0.950185              0.994851         0.267068
    2019-08-04 09:00:35  33.698 sec  45342 obs/sec     10        10            100070     0.405928         0.557954            0.997071       0.16575                          0.408331           0.565309              0.997029         0.169478
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0868367
C13         0.973336               0.973336             0.0845213
C12         0.859019               0.859019             0.0745944
C9          0.855587               0.855587             0.0742963
C7          0.853547               0.853547             0.0741192
C8          0.825867               0.825867             0.0717155
C11         0.744383               0.744383             0.0646398
C10         0.679102               0.679102             0.0589709
C6          0.660084               0.660084             0.0573195
C14         0.657589               0.657589             0.0571028
C5          0.647341               0.647341             0.0562129
C16         0.601872               0.601872             0.0522645
C3          0.594613               0.594613             0.0516342
C4          0.55578                0.55578              0.0482621
C1          0.512253               0.512253             0.0444823
C2          0.495501               0.495501             0.0430277
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_174

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017442261817279814  0.0004142974503338337  0.0         -0.002234593233652049  0.458050012588501   0.011284666981975267  0.5077285766601562
    3        26       Softmax                 0.0   0.0   0.0022854767895436313  0.0007375818677246571  0.0         0.004452847423843527   0.4158262014389038  -0.4847445093279259   0.2183130979537964


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16237204050473839
RMSE: 0.40295414193768797
LogLoss: 0.5487752556779859
Mean Per-Class Error: 0.16130983591296863
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    6.0    3.0    3.0    8.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    1.0    1.0    2.0    3.0    3.0    3.0    0.10379746835443038  41 / 395
0.0    318.0  0.0    9.0    2.0    1.0    0.0    15.0   1.0    1.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    8.0    19.0   0.0    0.0    3.0    0.0    1.0    1.0    0.0    0.16971279373368145  65 / 383
0.0    0.0    306.0  0.0    6.0    1.0    10.0   0.0    0.0    0.0    23.0   2.0    0.0    0.0    5.0    0.0    3.0    0.0    4.0    2.0    3.0    0.0    2.0    0.0    0.0    0.0    0.16621253405994552  61 / 367
1.0    16.0   0.0    347.0  0.0    3.0    0.0    3.0    0.0    1.0    0.0    1.0    7.0    4.0    1.0    4.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.13895781637717122  56 / 403
0.0    4.0    4.0    0.0    304.0  3.0    23.0   2.0    1.0    0.0    3.0    8.0    0.0    0.0    0.0    0.0    6.0    2.0    9.0    2.0    1.0    0.0    0.0    4.0    0.0    8.0    0.20833333333333334  80 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    3.0    0.0    0.0    6.0    4.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    2.0    0.0    4.0    6.0    1.0    0.0    2.0    4.0    1.0    9.0    0.0    0.0    0.0    2.0    0.0    5.0    1.0    7.0    3.0    2.0    0.0    0.0    342.0  1.0    2.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    3.0    14.0   3.0    8.0    1.0    1.0    350.0  0.0    0.10941475826972011  43 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    2.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    27.0   4.0    0.0    0.0    0.0    4.0    0.0    303.0  0.1721311475409836   63 / 366
378.0  444.0  345.0  426.0  386.0  371.0  345.0  349.0  333.0  372.0  432.0  376.0  433.0  383.0  398.0  386.0  376.0  367.0  410.0  379.0  400.0  370.0  393.0  421.0  387.0  343.0  0.1605518344496651   1,606 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839448
2    0.912926
3    0.943817
4    0.959612
5    0.970609
6    0.977607
7    0.982605
8    0.986904
9    0.990403
10   0.992402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1670193225088357
RMSE: 0.4086799756641322
LogLoss: 0.56601268643087
Mean Per-Class Error: 0.17020361859591274
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17    18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
77.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0    0.0   3.0   1.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   1.0   2.0   2.0    0.0   0.1348314606741573   12 / 89
0.0   81.0   0.0   4.0    1.0   0.0   0.0   6.0   0.0   0.0    0.0    0.0   0.0   0.0    1.0   2.0    0.0   3.0   4.0    0.0   0.0    3.0   0.0   1.0   0.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    68.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    1.0   0.0    0.0   0.0   2.0    1.0   1.0    0.0   1.0   0.0   0.0    0.0   0.17073170731707318  14 / 82
1.0   3.0    0.0   96.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   3.0   1.0    0.0   3.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   1.0    0.0   0.0    72.0  2.0   8.0   0.0   0.0   0.0    1.0    3.0   0.0   0.0    0.0   0.0    1.0   1.0   3.0    1.0   0.0    0.0   0.0   0.0   0.0    4.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   1.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    3.0   1.0   0.0   1.0   2.0   0.0    3.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0   4.0    0.0   1.0    0.0   0.0   81.0  0.0    1.0   0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    3.0   0.0   0.0    4.0   0.0    4.0   1.0   0.0   93.0   0.0   0.1308411214953271   14 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   6.0    1.0   0.0    0.0   0.0   1.0   0.0    73.0  0.16091954022988506  14 / 87
87.0  106.0  74.0  120.0  87.0  88.0  88.0  91.0  76.0  111.0  109.0  96.0  94.0  103.0  78.0  112.0  95.0  96.0  111.0  88.0  104.0  84.0  99.0  95.0  111.0  87.0  0.16947791164658635  422 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830522
2    0.910843
3    0.941767
4    0.959438
5    0.969076
6    0.975904
7    0.981928
8    0.985944
9    0.98996
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:08  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:09  5 min  6.769 sec  46328 obs/sec     1         1             10007      0.548606         0.983805            0.99465        0.277917                         0.547891           0.97619               0.994651         0.27992
    2019-08-04 09:05:11  5 min  8.785 sec  45589 obs/sec     10        10            100070     0.402954         0.548775            0.997114       0.160552                         0.40868            0.566013              0.997024         0.169478
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0882256
C13         0.93358                0.93358              0.0823656
C12         0.86653                0.86653              0.07645
C9          0.851294               0.851294             0.0751059
C7          0.782215               0.782215             0.0690114
C8          0.781766               0.781766             0.0689717
C11         0.764769               0.764769             0.0674722
C10         0.717925               0.717925             0.0633393
C6          0.651231               0.651231             0.0574552
C14         0.632933               0.632933             0.0558408
C5          0.627841               0.627841             0.0553917
C16         0.614403               0.614403             0.0542061
C3          0.58982                0.58982              0.0520372
C4          0.573115               0.573115             0.0505634
C2          0.496586               0.496586             0.0438115
C1          0.450577               0.450577             0.0397524
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_95

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009895509821546966  0.0002575961407274008  0.0         -0.010141808930711704  0.24075162410736084  0.2269552444712442    0.19825279712677002
    3        26       Softmax                      0.0   0.0   0.006958550834252282   0.03146810829639435    0.0         -0.3102843534353759    0.7227456569671631   -0.49498064692063376  0.23429054021835327


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1688648122925703
RMSE: 0.4109316394396644
LogLoss: 0.5544717579627295
Mean Per-Class Error: 0.15833312556884552
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    2.0    1.0    7.0    0.0    1.0    0.0    0.0    1.0    4.0    0.0    1.0    3.0    2.0    6.0    5.0    0.0    0.10886075949367088  43 / 395
2.0    324.0  0.0    9.0    2.0    2.0    2.0    8.0    2.0    0.0    2.0    0.0    1.0    0.0    1.0    7.0    2.0    11.0   2.0    0.0    0.0    1.0    0.0    2.0    2.0    0.0    0.1518324607329843   58 / 382
0.0    0.0    308.0  1.0    11.0   0.0    8.0    0.0    0.0    0.0    24.0   0.0    1.0    0.0    3.0    0.0    0.0    0.0    6.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.16304347826086957  60 / 368
1.0    17.0   0.0    344.0  0.0    2.0    0.0    2.0    0.0    6.0    2.0    0.0    6.0    3.0    5.0    1.0    0.0    2.0    4.0    0.0    2.0    0.0    0.0    5.0    0.0    1.0    0.14640198511166252  59 / 403
0.0    7.0    6.0    1.0    315.0  2.0    12.0   0.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    8.0    4.0    7.0    3.0    0.0    0.0    0.0    2.0    0.0    8.0    0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    18.0   1.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    1.0    0.0    4.0    5.0    0.0    1.0    3.0    4.0    1.0    7.0    2.0    0.0    0.0    2.0    0.0    5.0    0.0    8.0    1.0    1.0    0.0    0.0    341.0  2.0    5.0    0.13231552162849872  52 / 393
2.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    8.0    2.0    18.0   1.0    0.0    346.0  0.0    0.11959287531806616  47 / 393
0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    8.0    0.0    4.0    0.0    0.0    0.0    0.0    3.0    0.0    11.0   2.0    0.0    0.0    0.0    1.0    0.0    323.0  0.11989100817438691  44 / 367
395.0  448.0  352.0  430.0  396.0  404.0  357.0  318.0  338.0  362.0  399.0  362.0  445.0  376.0  389.0  384.0  357.0  402.0  376.0  354.0  395.0  381.0  413.0  405.0  399.0  366.0  0.15775267419774067  1,578 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842247
2    0.916125
3    0.942417
4    0.957613
5    0.969209
6    0.978506
7    0.984505
8    0.987803
9    0.990503
10   0.992102

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17231991890419293
RMSE: 0.41511434437296063
LogLoss: 0.5666539361138663
Mean Per-Class Error: 0.15702106586460177
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   1.0   1.0    3.0   2.0    0.0   0.12359550561797752  11 / 89
1.0   86.0   0.0   2.0    1.0   0.0   2.0   3.0   1.0   0.0    1.0   0.0   0.0   0.0   1.0   2.0    0.0    4.0    0.0   0.0   0.0   1.0   0.0    1.0   0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    65.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    3.0   0.0   1.0   0.0   1.0    0.0   0.0    0.0   0.2073170731707317   17 / 82
0.0   2.0    0.0   96.0   0.0   0.0   0.0   1.0   0.0   3.0    1.0   0.0   2.0   2.0   0.0   1.0    0.0    0.0    1.0   0.0   1.0   0.0   0.0    2.0   0.0    0.0   0.14285714285714285  16 / 112
0.0   1.0    0.0   0.0    78.0  1.0   3.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    3.0    1.0    3.0   1.0   0.0   0.0   0.0    0.0   0.0    3.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   5.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   0.0   1.0   2.0   0.0   0.0    3.0   2.0   0.0   0.0   0.0   0.0    1.0    0.0    2.0   0.0   0.0   0.0   0.0    83.0  1.0    1.0   0.17                 17 / 100
1.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0   2.0   0.0   5.0   1.0    0.0   93.0   0.0   0.1308411214953271   14 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0    76.0  0.12643678160919541  11 / 87
87.0  106.0  71.0  120.0  94.0  95.0  94.0  85.0  81.0  104.0  98.0  98.0  98.0  99.0  79.0  108.0  100.0  105.0  94.0  81.0  99.0  88.0  101.0  99.0  116.0  90.0  0.1570281124497992   391 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842972
2    0.919277
3    0.94498
4    0.95743
5    0.966667
6    0.976305
7    0.983534
8    0.98755
9    0.990763
10   0.992369
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:37  2 min 35.486 sec  100070 obs/sec    1         1             10007      0.585521         1.0773              0.993907       0.283715                         0.586387           1.08079               0.993873         0.292369
    2019-08-04 09:02:38  2 min 36.327 sec  108771 obs/sec    10        10            100070     0.410932         0.554472            0.996999       0.157753                         0.415114           0.566654              0.99693          0.157028
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.084533
C13         0.940847               0.940847             0.0795326
C9          0.917585               0.917585             0.0775662
C8          0.915931               0.915931             0.0774264
C12         0.822949               0.822949             0.0695664
C7          0.752748               0.752748             0.063632
C11         0.72929                0.72929              0.0616491
C5          0.722229               0.722229             0.0610521
C6          0.709201               0.709201             0.0599509
C10         0.688118               0.688118             0.0581686
C14         0.686528               0.686528             0.0580343
C3          0.673812               0.673812             0.0569593
C4          0.6598                 0.6598               0.0557749
C16         0.611484               0.611484             0.0516906
C2          0.505948               0.505948             0.0427693
C1          0.493233               0.493233             0.0416945
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_10

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001475307117061675   0.00041138508822768927  0.0         -0.012887230004153594  0.44405806064605713  0.0539335420957011   0.44004786014556885
    3        26       Softmax                 0.0   0.0   0.0025547863925357186  0.000789581099525094    0.0         -0.020500338210572757  0.5657124519348145   -0.5154329592150245  0.1883113980293274


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17070747643887438
RMSE: 0.4131676130081766
LogLoss: 0.5691850749983847
Mean Per-Class Error: 0.16728714782430906
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    5.0    0.0    0.0    0.0    4.0    0.0    4.0    3.0    1.0    5.0    0.0    0.0    0.0    1.0    4.0    2.0    1.0    1.0    1.0    0.0    0.0    3.0    0.0    0.08860759493670886  35 / 395
0.0    323.0  3.0    8.0    3.0    1.0    1.0    17.0   1.0    0.0    4.0    0.0    0.0    0.0    0.0    3.0    2.0    13.0   2.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.1566579634464752   60 / 383
0.0    0.0    311.0  0.0    12.0   0.0    4.0    1.0    0.0    0.0    21.0   2.0    0.0    0.0    9.0    0.0    3.0    0.0    2.0    1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
2.0    18.0   0.0    335.0  0.0    0.0    0.0    4.0    0.0    4.0    2.0    0.0    4.0    6.0    3.0    2.0    0.0    10.0   2.0    0.0    1.0    0.0    0.0    4.0    0.0    5.0    0.16666666666666666  67 / 402
0.0    5.0    3.0    1.0    323.0  6.0    15.0   1.0    1.0    0.0    4.0    1.0    0.0    0.0    0.0    1.0    4.0    4.0    8.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    12.0   0.0    14.0   0.0    0.0    0.0    0.0    0.0    2.0    1.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    1.0    0.0    3.0    9.0    6.0    0.0    1.0    3.0    3.0    9.0    2.0    0.0    0.0    2.0    0.0    6.0    2.0    7.0    1.0    1.0    0.0    0.0    331.0  3.0    4.0    0.1598984771573604   63 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    2.0    4.0    0.0    2.0    9.0    3.0    9.0    1.0    1.0    354.0  0.0    0.09923664122137404  39 / 393
4.0    1.0    0.0    1.0    16.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    28.0   2.0    0.0    0.0    0.0    0.0    1.0    305.0  0.16893732970027248  62 / 367
394.0  445.0  364.0  437.0  426.0  355.0  321.0  342.0  341.0  350.0  375.0  345.0  405.0  382.0  408.0  413.0  403.0  419.0  373.0  382.0  408.0  355.0  400.0  399.0  420.0  341.0  0.16645006498050585  1,665 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83355
2    0.911926
3    0.938718
4    0.956913
5    0.969809
6    0.976807
7    0.981106
8    0.985504
9    0.988004
10   0.990803

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17055178382167982
RMSE: 0.4129791566431408
LogLoss: 0.5691115041442393
Mean Per-Class Error: 0.16351771149940056
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   82.0   1.0   3.0    2.0    0.0   0.0   8.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0    6.0    0.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    69.0  0.0    2.0    0.0   0.0   1.0   0.0   0.0    5.0   1.0   0.0   0.0    2.0   0.0    0.0    0.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   0.0    0.0   94.0   0.0    0.0   0.0   3.0   0.0   3.0    1.0   0.0   0.0   3.0    0.0   2.0    0.0    1.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    1.0   0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    77.0   4.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0    2.0   1.0   0.0    0.0   0.0    0.0   0.0    3.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    2.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   89.0   0.0   0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    4.0    0.0   0.0   1.0   0.0   1.0    4.0   2.0   0.0   0.0    0.0   0.0    1.0    1.0    2.0   0.0   0.0    0.0   0.0    80.0  1.0    1.0   0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0    0.0   2.0   0.0    2.0   1.0    0.0   99.0   0.0   0.07476635514018691  8 / 107
1.0   0.0    0.0   1.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    6.0   0.0   0.0    0.0   0.0    0.0   1.0    72.0  0.1724137931034483   15 / 87
92.0  105.0  78.0  125.0  100.0  83.0  74.0  93.0  77.0  102.0  98.0  93.0  87.0  101.0  84.0  116.0  104.0  103.0  95.0  94.0  103.0  77.0  100.0  98.0  123.0  85.0  0.16265060240963855  405 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837349
2    0.913253
3    0.941767
4    0.958233
5    0.971486
6    0.978313
7    0.982731
8    0.986345
9    0.988755
10   0.989558
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:23  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:24  21.781 sec  70471 obs/sec     1         1             10007      0.577751         1.06029             0.994069       0.269919                         0.576641           1.05507               0.994075         0.271084
    2019-08-04 09:00:25  23.030 sec  73472 obs/sec     10        10            100070     0.413168         0.569185            0.996967       0.16645                          0.412979           0.569112              0.996961         0.162651
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0929631
C13         0.978917               0.978917             0.0910032
C9          0.861004               0.861004             0.0800416
C12         0.857103               0.857103             0.079679
C11         0.787438               0.787438             0.0732027
C8          0.774792               0.774792             0.0720271
C7          0.713997               0.713997             0.0663754
C6          0.669306               0.669306             0.0622208
C10         0.627303               0.627303             0.058316
C14         0.618786               0.618786             0.0575242
C16         0.609517               0.609517             0.0566626
C5          0.537475               0.537475             0.0499654
C3          0.481389               0.481389             0.0447514
C4          0.465429               0.465429             0.0432678
C2          0.398585               0.398585             0.0370537
C1          0.375909               0.375909             0.0349457
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_125

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017094530322623314  0.0004144401755183935  0.0         -0.01070185149087477  0.17822974920272827  0.1372080108152703   0.12451222538948059
    3        26       Softmax                      0.0   0.0   0.009134282611704783   0.02683008462190628    0.0         -0.1877406462362091   0.40503597259521484  -0.9233728326900524  0.30832231044769287


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1766233038370351
RMSE: 0.4202657538237384
LogLoss: 0.5630400962535745
Mean Per-Class Error: 0.15690098473986178
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    1.0    6.0    0.0    2.0    0.0    0.0    1.0    7.0    1.0    2.0    0.0    2.0    1.0    5.0    0.0    0.08607594936708861  34 / 395
0.0    353.0  0.0    4.0    2.0    0.0    3.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    2.0    2.0    6.0    3.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0783289817232376   30 / 383
0.0    0.0    308.0  0.0    14.0   0.0    8.0    1.0    0.0    0.0    16.0   0.0    0.0    0.0    5.0    0.0    3.0    0.0    1.0    3.0    4.0    0.0    5.0    0.0    0.0    0.0    0.16304347826086957  60 / 368
2.0    26.0   0.0    345.0  0.0    0.0    0.0    3.0    0.0    2.0    2.0    0.0    6.0    5.0    2.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.14392059553349876  58 / 403
0.0    11.0   1.0    0.0    320.0  2.0    13.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    1.0    5.0    4.0    6.0    4.0    0.0    0.0    0.0    3.0    0.0    10.0   0.16449086161879894  63 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    9.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    2.0    1.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    4.0    5.0    1.0    0.0    1.0    2.0    2.0    8.0    0.0    0.0    0.0    2.0    0.0    3.0    1.0    1.0    4.0    1.0    0.0    0.0    349.0  4.0    4.0    0.11421319796954314  45 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    2.0    16.0   0.0    12.0   1.0    0.0    349.0  0.0    0.11195928753180662  44 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    16.0   4.0    0.0    0.0    0.0    1.0    0.0    311.0  0.15258855585831063  56 / 367
401.0  550.0  348.0  417.0  409.0  327.0  347.0  284.0  337.0  364.0  365.0  352.0  403.0  393.0  388.0  402.0  374.0  426.0  352.0  397.0  406.0  367.0  426.0  404.0  409.0  355.0  0.15605318404478657  1,561 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.843947
2    0.913826
3    0.944617
4    0.959912
5    0.970209
6    0.977807
7    0.982205
8    0.987704
9    0.991303
10   0.993502

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1793445507032895
RMSE: 0.4234909098236815
LogLoss: 0.5707676358701267
Mean Per-Class Error: 0.1589539406990996
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   92.0   0.0   0.0    1.0   0.0   2.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    1.0   1.0    0.0   5.0    0.0   0.0   0.0   0.0   1.0    1.0    0.0    0.0   0.1320754716981132   14 / 106
0.0   0.0    62.0  0.0    3.0   0.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    1.0   2.0   1.0   0.0   2.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
2.0   4.0    0.0   96.0   0.0   0.0   0.0   2.0   0.0   0.0    1.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    1.0   0.14285714285714285  16 / 112
0.0   2.0    0.0   0.0    80.0  1.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    2.0   2.0   0.0   0.0   0.0    2.0    0.0    2.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    86.0   1.0    2.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0   0.0    0.0   4.0   0.0   4.0   1.0    0.0    94.0   0.0   0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   1.0   0.0   0.0   0.0    0.0    0.0    74.0  0.14942528735632185  13 / 87
93.0  135.0  68.0  114.0  97.0  74.0  89.0  69.0  80.0  110.0  96.0  92.0  92.0  104.0  85.0  117.0  98.0  106.0  84.0  97.0  99.0  83.0  103.0  101.0  112.0  92.0  0.1566265060240964   390 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.843373
2    0.917269
3    0.943373
4    0.959036
5    0.970281
6    0.979518
7    0.982731
8    0.989157
9    0.990763
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:31  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:31  3 min 29.776 sec  42948 obs/sec     1         1             10007      0.594957         1.08239             0.993711       0.289313                         0.593276           1.07441               0.993728         0.287149
    2019-08-04 09:03:33  3 min 31.625 sec  49319 obs/sec     10        10            100070     0.420266         0.56304             0.996862       0.156053                         0.423491           0.570768              0.996804         0.156627
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0898363
C13         0.886393               0.886393             0.0796302
C12         0.812777               0.812777             0.0730169
C8          0.808619               0.808619             0.0726433
C9          0.804659               0.804659             0.0722876
C7          0.796332               0.796332             0.0715395
C11         0.699869               0.699869             0.0628736
C5          0.692087               0.692087             0.0621745
C6          0.67553                0.67553              0.0606871
C10         0.654238               0.654238             0.0587743
C14         0.633974               0.633974             0.0569539
C3          0.605092               0.605092             0.0543593
C4          0.586482               0.586482             0.0526874
C16         0.567814               0.567814             0.0510103
C2          0.474303               0.474303             0.0426096
C1          0.433188               0.433188             0.038916
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_159

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001551388758343819   0.0004130761371925473  0.0         0.005417823005075206  0.4457588195800781  -0.0665444448089828  0.46922314167022705
    3        26       Softmax                 0.0   0.0   0.0025378430233943686  0.0006721403915435076  0.0         0.025361717679861437  0.5727760791778564  -0.5221594339523753  0.17843931913375854


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16801944755296114
RMSE: 0.4099017535373094
LogLoss: 0.5683920732341676
Mean Per-Class Error: 0.16186615015518477
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    5.0    1.0    5.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    2.0    5.0    8.0    1.0    0.09873417721518987  39 / 395
0.0    326.0  0.0    7.0    2.0    1.0    4.0    1.0    3.0    0.0    1.0    1.0    0.0    0.0    1.0    1.0    1.0    23.0   5.0    0.0    0.0    1.0    0.0    3.0    1.0    1.0    0.14882506527415143  57 / 383
0.0    2.0    302.0  1.0    13.0   1.0    11.0   2.0    0.0    0.0    16.0   4.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    3.0    5.0    0.0    3.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
1.0    18.0   0.0    338.0  0.0    0.0    0.0    5.0    1.0    0.0    2.0    0.0    5.0    6.0    2.0    3.0    0.0    11.0   0.0    3.0    2.0    0.0    0.0    5.0    0.0    0.0    0.15920398009950248  64 / 402
0.0    1.0    1.0    0.0    320.0  7.0    13.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    7.0    3.0    9.0    6.0    0.0    0.0    0.0    3.0    0.0    11.0   0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    4.0    0.0    10.0   1.0    4.0    0.0    1.0    5.0    0.0    0.0    5.0    2.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    1.0    0.0    4.0    5.0    2.0    0.0    3.0    3.0    2.0    8.0    5.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    347.0  7.0    2.0    0.11928934010152284  47 / 394
0.0    0.0    0.0    1.0    0.0    4.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    0.0    2.0    8.0    2.0    7.0    1.0    0.0    358.0  0.0    0.089058524173028    35 / 393
0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    1.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    17.0   4.0    0.0    0.0    0.0    8.0    0.0    303.0  0.17438692098092642  64 / 367
379.0  482.0  325.0  408.0  399.0  393.0  357.0  323.0  334.0  375.0  377.0  362.0  412.0  371.0  389.0  366.0  359.0  467.0  350.0  402.0  412.0  349.0  404.0  422.0  428.0  358.0  0.1610516844946516   1,611 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838948
2    0.908827
3    0.938019
4    0.955613
5    0.96541
6    0.974708
7    0.980206
8    0.984005
9    0.987004
10   0.990103

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17086035578061598
RMSE: 0.4133525804692841
LogLoss: 0.5710518257971923
Mean Per-Class Error: 0.16701367973973957
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19     20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   1.0    3.0    4.0    0.0   0.10112359550561797  9 / 89
0.0   88.0   0.0   1.0    1.0   0.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0   7.0    2.0   0.0    0.0    1.0   0.0    1.0    1.0    0.0   0.16981132075471697  18 / 106
0.0   1.0    65.0  0.0    3.0   0.0   2.0   1.0   0.0   0.0    3.0   1.0   0.0   0.0   1.0   0.0    0.0   0.0    2.0   1.0    1.0    0.0   1.0    0.0    0.0    0.0   0.2073170731707317   17 / 82
1.0   2.0    0.0   95.0   0.0   0.0   0.0   2.0   1.0   0.0    2.0   0.0   2.0   1.0   1.0   2.0    0.0   1.0    0.0   0.0    1.0    0.0   0.0    1.0    0.0    0.0   0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    74.0  3.0   6.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    4.0   3.0    0.0    0.0   0.0    2.0    0.0    3.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    1.0   2.0    0.0   0.0    2.0    0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   2.0   0.0   1.0    2.0   3.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0    0.0   0.0    83.0   3.0    0.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0   2.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   2.0    0.0    1.0   1.0    0.0    98.0   0.0   0.08411214953271028  9 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   1.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    0.0    0.0   0.0    2.0    0.0    73.0  0.16091954022988506  14 / 87
85.0  119.0  69.0  111.0  93.0  88.0  87.0  84.0  79.0  109.0  91.0  96.0  92.0  99.0  80.0  105.0  93.0  120.0  90.0  100.0  103.0  76.0  102.0  103.0  125.0  91.0  0.16626506024096385  414 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.833735
2    0.908835
3    0.936948
4    0.954217
5    0.964659
6    0.975904
7    0.982731
8    0.986747
9    0.987952
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:32  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:32  4 min 30.066 sec  74679 obs/sec     1         1             10007      0.576371         1.04804             0.994097       0.263621                         0.574977           1.03773               0.994109         0.267871
    2019-08-04 09:04:33  4 min 31.268 sec  76098 obs/sec     10        10            100070     0.409902         0.568392            0.997015       0.161052                         0.413353           0.571052              0.996956         0.166265
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.092479
C13         0.945939               0.945939             0.0874795
C9          0.88097                0.88097              0.0814712
C12         0.877826               0.877826             0.0811805
C8          0.788885               0.788885             0.0729553
C7          0.77621                0.77621              0.0717831
C11         0.702804               0.702804             0.0649947
C10         0.702164               0.702164             0.0649355
C14         0.657513               0.657513             0.0608062
C6          0.644356               0.644356             0.0595894
C16         0.587493               0.587493             0.0543308
C5          0.561208               0.561208             0.0518999
C4          0.481909               0.481909             0.0445665
C3          0.458827               0.458827             0.0424319
C2          0.411611               0.411611             0.0380654
C1          0.335548               0.335548             0.0310311
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_74

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009438176765002027  0.00024314038455486298  0.0         -0.016986641864150442  0.2390764355659485  0.2315132200485305   0.18256640434265137
    3        26       Softmax                      0.0   0.0   0.006298843697760066   0.0166206955909729      0.0         -0.2921516745043216    0.7366642951965332  -0.4751402031630002  0.22691810131072998


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17098268956455512
RMSE: 0.4135005315166537
LogLoss: 0.5600600888522032
Mean Per-Class Error: 0.1623610207281671
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    5.0    3.0    2.0    3.0    0.0    6.0    0.0    0.0    0.0    4.0    1.0    4.0    1.0    1.0    1.0    3.0    0.0    0.09113924050632911  36 / 395
0.0    337.0  0.0    5.0    2.0    1.0    3.0    6.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    3.0    10.0   7.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.12010443864229765  46 / 383
0.0    0.0    305.0  0.0    18.0   0.0    9.0    3.0    0.0    0.0    10.0   5.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    8.0    2.0    0.0    2.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
0.0    24.0   0.0    335.0  0.0    0.0    0.0    5.0    0.0    7.0    3.0    0.0    7.0    6.0    1.0    2.0    1.0    6.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.1687344913151365   68 / 403
0.0    10.0   1.0    0.0    320.0  5.0    12.0   0.0    0.0    0.0    3.0    2.0    0.0    0.0    1.0    1.0    6.0    3.0    1.0    2.0    0.0    0.0    0.0    6.0    0.0    10.0   0.16449086161879894  63 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    2.0    0.0    351.0  0.0    0.0    0.0    0.06648936170212766  25 / 376
0.0    5.0    0.0    4.0    6.0    0.0    0.0    1.0    2.0    2.0    4.0    1.0    0.0    0.0    2.0    0.0    4.0    0.0    9.0    9.0    1.0    0.0    0.0    336.0  3.0    5.0    0.14720812182741116  58 / 394
0.0    0.0    0.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    9.0    0.0    4.0    24.0   2.0    15.0   1.0    1.0    328.0  1.0    0.16539440203562342  65 / 393
3.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    22.0   3.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
397.0  478.0  335.0  403.0  402.0  351.0  353.0  329.0  339.0  358.0  369.0  379.0  399.0  397.0  402.0  412.0  380.0  426.0  365.0  413.0  403.0  367.0  404.0  395.0  362.0  385.0  0.16165150454863542  1,617 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838349
2    0.916225
3    0.945616
4    0.961412
5    0.971209
6    0.978107
7    0.983605
8    0.986804
9    0.989403
10   0.990903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17485609907384186
RMSE: 0.4181579833912559
LogLoss: 0.5719513205677041
Mean Per-Class Error: 0.16065489583188203
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   1.0    1.0   2.0    0.0    0.07865168539325842  7 / 89
0.0   89.0   0.0   2.0    1.0   1.0   1.0   2.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0    3.0    2.0   0.0   0.0    2.0   0.0    1.0   0.0    0.0    0.16037735849056603  17 / 106
0.0   0.0    65.0  0.0    3.0   0.0   3.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    3.0   0.0    1.0    0.0    0.0   3.0   0.0    0.0   1.0    0.0   0.0    0.0    0.2073170731707317   17 / 82
0.0   4.0    0.0   94.0   0.0   0.0   0.0   3.0   0.0   2.0    2.0   0.0   2.0   2.0    0.0   1.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.16071428571428573  18 / 112
0.0   3.0    0.0   0.0    79.0  3.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0    1.0   1.0   0.0    0.0   0.0    2.0   0.0    3.0    0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0    0.0   89.0   0.0   0.0    0.0    0.03260869565217391  3 / 92
0.0   2.0    0.0   1.0    2.0   0.0   0.0   1.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    4.0   1.0   0.0    0.0   0.0    83.0  1.0    2.0    0.17                 17 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0    0.0    0.0   7.0   1.0    5.0   1.0    0.0   87.0   0.0    0.18691588785046728  20 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   5.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0    74.0   0.14942528735632185  13 / 87
95.0  118.0  69.0  113.0  96.0  82.0  91.0  81.0  83.0  102.0  93.0  98.0  86.0  105.0  86.0  121.0  100.0  109.0  86.0  97.0  100.0  80.0  101.0  95.0  102.0  101.0  0.1602409638554217   399 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839759
2    0.919277
3    0.94498
4    0.95743
5    0.968675
6    0.975904
7    0.982329
8    0.985141
9    0.987952
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:04  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:04  2 min  1.915 sec  100070 obs/sec    1         1             10007      0.590592         1.09986             0.993802       0.29871                          0.592723           1.11003               0.99374          0.303614
    2019-08-04 09:02:05  2 min  2.757 sec  108653 obs/sec    10        10            100070     0.413501         0.56006             0.996962       0.161652                         0.418158           0.571951              0.996884         0.160241
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0918289
C13         0.906121               0.906121             0.083208
C9          0.798518               0.798518             0.073327
C8          0.784495               0.784495             0.0720393
C12         0.731454               0.731454             0.0671686
C7          0.713996               0.713996             0.0655654
C10         0.695507               0.695507             0.0638676
C5          0.687458               0.687458             0.0631285
C11         0.666706               0.666706             0.0612228
C6          0.662153               0.662153             0.0608047
C4          0.626177               0.626177             0.0575011
C3          0.563309               0.563309             0.051728
C14         0.555534               0.555534             0.051014
C16         0.512093               0.512093             0.0470249
C2          0.506153               0.506153             0.0464795
C1          0.48015                0.48015              0.0440916
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_9

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017594850551176933  0.00044085958506911993  0.0         -0.011176373980122278  0.17957597970962524  0.13448184333637708  0.11957734823226929
    3        26       Softmax                      0.0   0.0   0.009200657944697573   0.03186500072479248     0.0         -0.17584701179821466   0.40240752696990967  -0.922327113280149   0.38412046432495117


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17563998986174703
RMSE: 0.41909424937804507
LogLoss: 0.5629596247296536
Mean Per-Class Error: 0.15932871752425326
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    1.0    4.0    0.0    2.0    0.0    0.0    0.0    7.0    1.0    2.0    0.0    2.0    2.0    5.0    0.0    0.08607594936708861  34 / 395
0.0    342.0  0.0    6.0    3.0    0.0    2.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    1.0    16.0   3.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.10704960835509138  41 / 383
0.0    0.0    306.0  0.0    16.0   0.0    5.0    1.0    0.0    0.0    21.0   2.0    0.0    0.0    4.0    0.0    2.0    0.0    2.0    3.0    1.0    0.0    4.0    0.0    0.0    0.0    0.16621253405994552  61 / 367
4.0    21.0   0.0    341.0  0.0    0.0    1.0    4.0    0.0    5.0    0.0    0.0    5.0    5.0    3.0    0.0    0.0    7.0    0.0    0.0    2.0    0.0    0.0    5.0    0.0    0.0    0.15384615384615385  62 / 403
0.0    5.0    0.0    0.0    329.0  2.0    16.0   0.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    2.0    4.0    2.0    5.0    1.0    0.0    0.0    4.0    0.0    9.0    0.14322916666666666  55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    11.0   1.0    1.0    0.0    0.0    3.0    0.0    0.0    5.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    2.0    0.0    4.0    8.0    0.0    0.0    3.0    2.0    2.0    6.0    2.0    0.0    0.0    0.0    0.0    5.0    2.0    0.0    3.0    2.0    1.0    0.0    345.0  2.0    5.0    0.12436548223350254  49 / 394
0.0    0.0    0.0    0.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    3.0    12.0   2.0    8.0    1.0    0.0    357.0  0.0    0.0916030534351145   36 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    0.0    0.0    5.0    0.0    20.0   3.0    0.0    0.0    0.0    1.0    0.0    311.0  0.15027322404371585  55 / 366
402.0  505.0  338.0  406.0  439.0  362.0  363.0  291.0  341.0  367.0  368.0  367.0  413.0  384.0  397.0  365.0  350.0  441.0  331.0  381.0  419.0  361.0  411.0  413.0  417.0  371.0  0.1584524642607218   1,585 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.841548
2    0.913626
3    0.945316
4    0.960312
5    0.971808
6    0.978606
7    0.983705
8    0.986904
9    0.990503
10   0.992402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1785085399300785
RMSE: 0.42250270996773326
LogLoss: 0.5736878131130981
Mean Per-Class Error: 0.16444665057841085
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0    0.07865168539325842  7 / 89
0.0   91.0   0.0   1.0    2.0    0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0   5.0    0.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0    0.14150943396226415  15 / 106
0.0   0.0    64.0  0.0    3.0    0.0   2.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    1.0   2.0   0.0    0.0   1.0    0.0   0.0    0.0    0.21951219512195122  18 / 82
3.0   4.0    0.0   94.0   0.0    0.0   1.0   2.0   0.0   2.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0    0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    79.0   1.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0   3.0   0.0    0.0   0.0    2.0   0.0    4.0    0.18556701030927836  18 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    4.0    0.0   0.0   2.0   0.0   0.0    3.0   2.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    82.0  1.0    2.0    0.18                 18 / 100
0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   2.0   0.0    3.0   1.0    0.0   99.0   0.0    0.07476635514018691  8 / 107
1.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    76.0   0.12643678160919541  11 / 87
94.0  121.0  69.0  113.0  103.0  84.0  97.0  75.0  83.0  108.0  95.0  97.0  92.0  100.0  84.0  104.0  89.0  111.0  76.0  91.0  102.0  82.0  100.0  96.0  122.0  102.0  0.1634538152610442   407 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836546
2    0.915663
3    0.945381
4    0.959839
5    0.971888
6    0.979116
7    0.982329
8    0.986345
9    0.989157
10   0.991566
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:21  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:21  19.761 sec  41351 obs/sec     1         1             10007      0.590271         1.07576             0.993807       0.283315                         0.589957           1.0756                0.993798         0.293173
    2019-08-04 09:00:23  21.598 sec  49466 obs/sec     10        10            100070     0.419094         0.56296             0.996878       0.158452                         0.422503           0.573688              0.996819         0.163454
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0870734
C13         0.964509               0.964509             0.0839831
C8          0.871473               0.871473             0.0758821
C9          0.870418               0.870418             0.0757903
C12         0.856393               0.856393             0.0745691
C7          0.801051               0.801051             0.0697503
C11         0.73457                0.73457              0.0639616
C5          0.694091               0.694091             0.0604369
C10         0.68085                0.68085              0.0592839
C14         0.661273               0.661273             0.0575793
C6          0.653325               0.653325             0.0568872
C4          0.625952               0.625952             0.0545038
C3          0.593438               0.593438             0.0516727
C16         0.587974               0.587974             0.0511969
C2          0.462586               0.462586             0.040279
C1          0.426656               0.426656             0.0371504
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_113

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0018266589641200426  0.0004830254474654794  0.0         -0.004818722642774276  0.453884482383728    -0.07361133393922165  0.502880334854126
    3        26       Softmax                 0.0   0.0   0.0023345069852299415  0.0006674847099930048  0.0         0.01777188792171868    0.41014528274536133  -0.4841901443734183   0.15300822257995605


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16425627341209692
RMSE: 0.4052854221559134
LogLoss: 0.5557572693618377
Mean Per-Class Error: 0.1626373861770765
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    1.0    7.0    3.0    2.0    0.0    2.0    3.0    5.0    0.0    0.09367088607594937  37 / 395
0.0    324.0  0.0    7.0    3.0    4.0    1.0    5.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    3.0    0.0    16.0   5.0    1.0    0.0    5.0    0.0    3.0    2.0    0.0    0.15404699738903394  59 / 383
0.0    0.0    307.0  0.0    5.0    0.0    7.0    1.0    0.0    0.0    21.0   2.0    0.0    0.0    3.0    0.0    3.0    2.0    8.0    1.0    5.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
2.0    15.0   0.0    343.0  0.0    1.0    0.0    3.0    0.0    6.0    0.0    0.0    7.0    5.0    4.0    1.0    0.0    6.0    0.0    1.0    1.0    0.0    0.0    6.0    0.0    1.0    0.14676616915422885  59 / 402
0.0    7.0    3.0    0.0    311.0  6.0    10.0   0.0    2.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    11.0   3.0    10.0   2.0    1.0    0.0    0.0    5.0    0.0    9.0    0.18798955613577023  72 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    8.0    0.0    0.0    0.0    0.0    3.0    4.0    0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    7.0    0.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    1.0    0.0    4.0    6.0    1.0    0.0    2.0    2.0    2.0    9.0    3.0    0.0    0.0    2.0    0.0    0.0    1.0    2.0    1.0    1.0    0.0    0.0    351.0  4.0    2.0    0.10913705583756345  43 / 394
0.0    0.0    0.0    1.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    1.0    6.0    3.0    12.0   2.0    1.0    351.0  0.0    0.10687022900763359  42 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    32.0   3.0    0.0    0.0    0.0    3.0    0.0    303.0  0.17438692098092642  64 / 367
391.0  470.0  335.0  426.0  362.0  418.0  322.0  311.0  325.0  377.0  403.0  357.0  420.0  377.0  361.0  375.0  392.0  431.0  396.0  357.0  424.0  364.0  413.0  441.0  407.0  348.0  0.16175147455763272  1,618 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838249
2    0.913126
3    0.942517
4    0.957613
5    0.96771
6    0.975507
7    0.981606
8    0.986204
9    0.989403
10   0.992202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16818429396325546
RMSE: 0.4101027846324083
LogLoss: 0.5743185126313292
Mean Per-Class Error: 0.1664499795727504
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11    12    13    14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0    1.0    1.0   0.0   0.0    0.0   1.0    0.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   86.0   0.0   1.0    2.0   1.0    1.0   2.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0    7.0    0.0   0.0   0.0    3.0   0.0    1.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    66.0  0.0    1.0   0.0    2.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0   2.0   0.0    1.0    0.0    3.0   1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.1951219512195122   16 / 82
1.0   2.0    0.0   94.0   0.0   1.0    0.0   1.0   0.0   4.0    0.0    0.0   3.0   1.0   2.0   1.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.16071428571428573  18 / 112
0.0   1.0    0.0   0.0    77.0  4.0    3.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    3.0    1.0    3.0   1.0   0.0    0.0   0.0    2.0    0.0    1.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   3.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    3.0   0.0    0.0   1.0   1.0   0.0    3.0    2.0   0.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0    85.0   2.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   1.0   0.0    4.0   1.0    0.0    96.0   0.0   0.102803738317757    11 / 107
0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0    0.0    9.0   1.0   0.0    0.0   0.0    2.0    0.0    70.0  0.19540229885057472  17 / 87
90.0  114.0  68.0  118.0  85.0  102.0  81.0  85.0  74.0  110.0  101.0  93.0  90.0  99.0  77.0  109.0  100.0  108.0  99.0  82.0  107.0  83.0  106.0  111.0  116.0  82.0  0.16626506024096385  414 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.833735
2    0.909237
3    0.937751
4    0.954217
5    0.968273
6    0.973494
7    0.976707
8    0.983534
9    0.987952
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:11  3 min  9.448 sec  43890 obs/sec     1         1             10007      0.544386         0.974451            0.994733       0.264621                         0.541613           0.959107              0.994773         0.264257
    2019-08-04 09:03:13  3 min 11.379 sec  47113 obs/sec     10        10            100070     0.405285         0.555757            0.997081       0.161751                         0.410103           0.574319              0.997003         0.166265
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0910096
C13         0.912862               0.912862             0.0830792
C12         0.843354               0.843354             0.0767533
C9          0.795653               0.795653             0.072412
C7          0.752505               0.752505             0.0684851
C11         0.749034               0.749034             0.0681693
C8          0.732042               0.732042             0.0666229
C14         0.670258               0.670258             0.0609999
C10         0.669728               0.669728             0.0609517
C5          0.6179                 0.6179               0.0562348
C6          0.617062               0.617062             0.0561586
C3          0.582394               0.582394             0.0530034
C16         0.566648               0.566648             0.0515704
C4          0.543935               0.543935             0.0495033
C2          0.479736               0.479736             0.0436606
C1          0.454743               0.454743             0.041386
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_198

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias           bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  ------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0014170840749443414  0.00041601143311709166  0.0         0.024140622474391193  0.4290800094604492  0.1460321278164784  0.42165422439575195
    3        26       Softmax                 0.0   0.0   0.0025150816027235123  0.0007688805926591158   0.0         -0.02299127452799719  0.574087381362915   -0.523239703562104  0.17656409740447998


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17093206460799323
RMSE: 0.41343931188022415
LogLoss: 0.5697122994198075
Mean Per-Class Error: 0.1648964337299582
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    3.0    6.0    1.0    1.0    0.0    1.0    1.0    5.0    3.0    2.0    1.0    1.0    1.0    4.0    0.0    0.09113924050632911  36 / 395
0.0    335.0  0.0    4.0    3.0    0.0    4.0    6.0    2.0    1.0    1.0    1.0    0.0    0.0    0.0    4.0    0.0    10.0   7.0    0.0    0.0    1.0    1.0    2.0    1.0    0.0    0.12532637075718014  48 / 383
0.0    0.0    312.0  1.0    18.0   0.0    8.0    1.0    0.0    0.0    10.0   4.0    0.0    0.0    2.0    0.0    2.0    0.0    2.0    0.0    6.0    0.0    1.0    1.0    0.0    0.0    0.15217391304347827  56 / 368
0.0    16.0   0.0    344.0  0.0    0.0    1.0    10.0   0.0    3.0    1.0    0.0    5.0    4.0    2.0    2.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.14640198511166252  59 / 403
0.0    2.0    4.0    0.0    317.0  5.0    18.0   2.0    0.0    0.0    2.0    3.0    0.0    0.0    0.0    1.0    1.0    3.0    5.0    5.0    1.0    0.0    0.0    4.0    0.0    11.0   0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   3.0    4.0    1.0    3.0    6.0    0.0    0.0    6.0    0.0    336.0  0.0    1.0    0.0    0.10638297872340426  40 / 376
0.0    1.0    0.0    3.0    5.0    1.0    0.0    5.0    2.0    0.0    5.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    1.0    2.0    1.0    0.0    0.0    352.0  3.0    4.0    0.1065989847715736   42 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    11.0   0.0    1.0    10.0   2.0    24.0   0.0    0.0    338.0  0.0    0.13994910941475827  55 / 393
0.0    0.0    0.0    0.0    22.0   1.0    1.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    22.0   6.0    0.0    0.0    0.0    1.0    2.0    298.0  0.1880108991825613   69 / 367
391.0  481.0  354.0  409.0  445.0  306.0  362.0  340.0  336.0  357.0  350.0  364.0  401.0  398.0  394.0  428.0  371.0  408.0  370.0  388.0  413.0  382.0  374.0  430.0  398.0  353.0  0.16405078476457063  1,641 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835949
2    0.912626
3    0.941618
4    0.957513
5    0.969009
6    0.977207
7    0.982705
8    0.985204
9    0.988803
10   0.991603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17241042772359533
RMSE: 0.4152233467949452
LogLoss: 0.5759834234657999
Mean Per-Class Error: 0.17026121014253423
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   0.0   0.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   86.0   0.0   2.0    3.0    0.0   1.0   2.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   2.0    0.0   3.0    1.0   0.0   0.0    1.0   1.0   1.0    1.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    68.0  0.0    4.0    0.0   3.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
0.0   3.0    0.0   90.0   0.0    0.0   1.0   6.0   0.0   0.0    1.0   0.0   2.0   2.0    0.0   2.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.19642857142857142  22 / 112
0.0   0.0    0.0   0.0    76.0   2.0   5.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   4.0   0.0    0.0   0.0   0.0    0.0    4.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    1.0   0.0    1.0   2.0    0.0   0.0   2.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   1.0    1.0    1.0   0.0   3.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    0.0   0.0   0.0    0.0   0.0   87.0   1.0    1.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   2.0    4.0   0.0    0.0   1.0   0.0    7.0   0.0   0.0    91.0   0.0   0.14953271028037382  16 / 107
0.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   2.0   0.0    0.0   0.0   1.0    1.0    70.0  0.19540229885057472  17 / 87
90.0  123.0  74.0  110.0  105.0  69.0  95.0  90.0  80.0  101.0  89.0  94.0  84.0  104.0  81.0  124.0  99.0  103.0  94.0  92.0  105.0  83.0  95.0  102.0  116.0  88.0  0.1682730923694779   419 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.831727
2    0.915663
3    0.944578
4    0.959036
5    0.966667
6    0.974699
7    0.981526
8    0.983936
9    0.988353
10   0.991968
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:51  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:51  5 min 49.030 sec  68541 obs/sec     1         1             10007      0.576946         1.07105             0.994085       0.275317                         0.575778           1.06571               0.994093         0.283133
    2019-08-04 09:05:52  5 min 50.270 sec  73418 obs/sec     10        10            100070     0.413439         0.569712            0.996963       0.164051                         0.415223           0.575983              0.996928         0.168273
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0901907
C15         0.952994               0.952994             0.0859512
C8          0.894848               0.894848             0.0807069
C9          0.871422               0.871422             0.0785941
C12         0.868862               0.868862             0.0783633
C7          0.814907               0.814907             0.073497
C11         0.745862               0.745862             0.0672698
C14         0.655392               0.655392             0.0591103
C10         0.653732               0.653732             0.0589605
C16         0.631394               0.631394             0.0569458
C6          0.624086               0.624086             0.0562867
C5          0.608199               0.608199             0.0548538
C4          0.514397               0.514397             0.0463938
C3          0.475911               0.475911             0.0429227
C2          0.404333               0.404333             0.0364671
C1          0.371283               0.371283             0.0334862
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_204

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0010152680486044119  0.00024153944104909897  0.0         -0.014499066687918116  0.2383885383605957  0.22198717906515153   0.18479257822036743
    3        26       Softmax                      0.0   0.0   0.005841672457511147   0.014680895954370499    0.0         -0.3243224047820639    0.7273001670837402  -0.49332091357176666  0.23371070623397827


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17222760190264746
RMSE: 0.415003134810627
LogLoss: 0.5644939614965794
Mean Per-Class Error: 0.16080273275908943
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    3.0    4.0    2.0    1.0    3.0    1.0    0.0    0.0    3.0    4.0    2.0    2.0    5.0    1.0    2.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    332.0  0.0    6.0    4.0    2.0    1.0    1.0    2.0    0.0    2.0    1.0    0.0    0.0    1.0    5.0    3.0    13.0   6.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    0.13089005235602094  50 / 382
0.0    1.0    295.0  1.0    13.0   0.0    16.0   0.0    0.0    0.0    20.0   3.0    1.0    0.0    7.0    0.0    1.0    0.0    2.0    2.0    3.0    0.0    2.0    0.0    0.0    0.0    0.19618528610354224  72 / 367
1.0    17.0   0.0    349.0  0.0    2.0    0.0    1.0    0.0    2.0    1.0    0.0    7.0    4.0    1.0    2.0    0.0    10.0   1.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    0.13399503722084366  54 / 403
0.0    6.0    3.0    0.0    311.0  2.0    17.0   1.0    0.0    0.0    9.0    3.0    0.0    0.0    0.0    2.0    4.0    3.0    8.0    6.0    0.0    0.0    0.0    5.0    0.0    4.0    0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    2.0    1.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    14.0   0.0    3.0    0.0    0.0    4.0    0.0    0.0    2.0    2.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    1.0    0.0    2.0    6.0    1.0    0.0    3.0    5.0    1.0    8.0    3.0    0.0    0.0    2.0    0.0    1.0    0.0    7.0    1.0    1.0    0.0    0.0    347.0  1.0    3.0    0.11704834605597965  46 / 393
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    21.0   3.0    10.0   0.0    0.0    343.0  0.0    0.1272264631043257   50 / 393
0.0    1.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    21.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    26.0   2.0    0.0    0.0    0.0    4.0    0.0    290.0  0.2098092643051771   77 / 367
382.0  473.0  336.0  426.0  395.0  378.0  359.0  306.0  356.0  360.0  383.0  378.0  416.0  394.0  391.0  383.0  362.0  433.0  391.0  397.0  402.0  368.0  401.0  414.0  387.0  332.0  0.1599520143956813   1,600 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840048
2    0.910427
3    0.940618
4    0.958812
5    0.970009
6    0.977107
7    0.982305
8    0.986404
9    0.990303
10   0.993402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1754453031630381
RMSE: 0.4188619141949267
LogLoss: 0.575991317640627
Mean Per-Class Error: 0.16163619106240784
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    1.0    0.0   1.0    2.0   0.0   0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   86.0   0.0   1.0    3.0   0.0   1.0   0.0   1.0   0.0    1.0   0.0    0.0   0.0    0.0   2.0    0.0   6.0    2.0    0.0   0.0    1.0   1.0   1.0   0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    59.0  0.0    4.0   0.0   5.0   0.0   0.0   0.0    5.0   0.0    0.0   0.0    4.0   0.0    1.0   0.0    1.0    1.0   1.0    0.0   1.0   0.0   0.0    0.0   0.2804878048780488   23 / 82
1.0   3.0    0.0   96.0   0.0   1.0   0.0   1.0   0.0   1.0    1.0   0.0    3.0   1.0    0.0   1.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    74.0  2.0   6.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    0.0   0.0    2.0   1.0    4.0    3.0   0.0    0.0   0.0   0.0   0.0    2.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0    1.0   0.0    0.0   2.0    0.0    0.0   0.0    1.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   1.0    1.0   1.0   0.0   2.0   0.0   0.0    3.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0    3.0    0.0   0.0    0.0   0.0   86.0  0.0    1.0   0.14                 14 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0    6.0   1.0    3.0   0.0   0.0   94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   8.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0   0.0    71.0  0.1839080459770115   16 / 87
91.0  115.0  66.0  116.0  94.0  85.0  93.0  78.0  88.0  106.0  95.0  101.0  95.0  100.0  81.0  108.0  95.0  111.0  101.0  96.0  104.0  86.0  96.0  95.0  110.0  84.0  0.1610441767068273   401 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838956
2    0.91004
3    0.941365
4    0.959036
5    0.970281
6    0.97751
7    0.982329
8    0.986747
9    0.98996
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:01  5 min 58.837 sec  99079 obs/sec     1         1             10007      0.594686         1.10955             0.993713       0.292012                         0.598313           1.11972               0.993621         0.298394
    2019-08-04 09:06:01  5 min 59.664 sec  110330 obs/sec    10        10            100070     0.415003         0.564494            0.996938       0.159952                         0.418862           0.575991              0.996874         0.161044
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0978472
C13         0.804649               0.804649             0.0787327
C9          0.793259               0.793259             0.0776181
C8          0.767551               0.767551             0.0751027
C12         0.716432               0.716432             0.0701009
C7          0.698123               0.698123             0.0683094
C11         0.650766               0.650766             0.0636756
C5          0.628473               0.628473             0.0614943
C10         0.616303               0.616303             0.0603035
C6          0.606421               0.606421             0.0593366
C14         0.575138               0.575138             0.0562756
C4          0.516424               0.516424             0.0505307
C16         0.515702               0.515702             0.05046
C3          0.50354                0.50354              0.04927
C1          0.415349               0.415349             0.0406407
C2          0.411886               0.411886             0.0403019
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_109

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017240178819832863  0.00040130072738975286  0.0         -0.009368469531851886  0.17786526679992676  0.13841358356968234  0.12415117025375366
    3        26       Softmax                      0.0   0.0   0.009206208699940642   0.033052653074264526    0.0         -0.1814298031169207    0.40155792236328125  -0.9116243124913728  0.3001919984817505


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17783300209074535
RMSE: 0.42170250425002853
LogLoss: 0.5689074358318974
Mean Per-Class Error: 0.15807396847403674
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    4.0    2.0    7.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    4.0    0.0    1.0    3.0    4.0    1.0    0.10379746835443038  41 / 395
0.0    342.0  0.0    4.0    2.0    1.0    1.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    2.0    10.0   8.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.10704960835509138  41 / 383
0.0    0.0    309.0  0.0    12.0   0.0    3.0    1.0    0.0    0.0    23.0   0.0    1.0    0.0    3.0    0.0    2.0    0.0    8.0    1.0    1.0    0.0    4.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
1.0    26.0   0.0    343.0  0.0    0.0    0.0    4.0    0.0    3.0    2.0    0.0    7.0    4.0    1.0    0.0    0.0    4.0    2.0    0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.1488833746898263   60 / 403
0.0    6.0    0.0    0.0    322.0  3.0    17.0   0.0    0.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    1.0    4.0    8.0    4.0    0.0    0.0    0.0    3.0    0.0    10.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    19.0   1.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    2.0    0.0    5.0    5.0    0.0    1.0    1.0    2.0    2.0    7.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    4.0    1.0    1.0    0.0    0.0    352.0  5.0    3.0    0.1065989847715736   42 / 394
0.0    0.0    0.0    2.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    5.0    0.0    2.0    12.0   1.0    9.0    1.0    0.0    350.0  0.0    0.10941475826972011  43 / 393
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    29.0   2.0    0.0    0.0    0.0    0.0    0.0    300.0  0.18256130790190736  67 / 367
376.0  487.0  356.0  412.0  405.0  384.0  337.0  334.0  334.0  365.0  399.0  368.0  458.0  378.0  387.0  383.0  353.0  399.0  438.0  362.0  391.0  363.0  390.0  412.0  393.0  339.0  0.15745276417074877  1,575 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842547
2    0.911127
3    0.943617
4    0.960112
5    0.970809
6    0.977707
7    0.983405
8    0.987104
9    0.990303
10   0.992602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1802992606661748
RMSE: 0.4246166043222695
LogLoss: 0.5764209654168888
Mean Per-Class Error: 0.16054820531730293
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   2.0    0.0   0.0   2.0    2.0    0.0   0.11235955056179775  10 / 89
0.0   90.0   0.0   0.0    1.0   0.0   1.0   1.0   1.0   0.0    1.0    0.0   0.0    0.0   1.0   1.0    0.0   4.0    3.0    0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    67.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    5.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.18292682926829268  15 / 82
1.0   4.0    0.0   95.0   0.0   0.0   0.0   2.0   0.0   1.0    1.0    0.0   3.0    1.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    78.0  2.0   5.0   0.0   0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    3.0    1.0   0.0    0.0   0.0   1.0    0.0    4.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   5.0    0.0   0.0   0.0    0.0   1.0    0.0    0.0   1.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    3.0   0.0   1.0   0.0   0.0   0.0    3.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   86.0   1.0    2.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0    3.0   0.0    0.0    3.0   0.0    3.0   1.0   0.0    95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   5.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0    3.0    0.0   0.0    0.0   0.0   0.0    0.0    72.0  0.1724137931034483   15 / 87
85.0  119.0  77.0  114.0  96.0  88.0  83.0  76.0  79.0  102.0  101.0  99.0  103.0  98.0  80.0  113.0  94.0  104.0  112.0  85.0  102.0  83.0  96.0  102.0  111.0  88.0  0.1598393574297189   398 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840161
2    0.908835
3    0.941365
4    0.958635
5    0.969076
6    0.975904
7    0.983534
8    0.986747
9    0.991165
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:04  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:04  3 min  2.513 sec  43320 obs/sec     1         1             10007      0.596102         1.08614             0.993686       0.280116                         0.595222           1.07962               0.993687         0.283534
    2019-08-04 09:03:06  3 min  4.328 sec  50160 obs/sec     10        10            100070     0.421703         0.568907            0.99684        0.157453                         0.424617           0.576421              0.996787         0.159839
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0863376
C15         0.999347               0.999347             0.0862812
C12         0.854902               0.854902             0.0738102
C8          0.844678               0.844678             0.0729275
C9          0.835115               0.835115             0.0721018
C7          0.834851               0.834851             0.072079
C11         0.727113               0.727113             0.0627772
C5          0.719658               0.719658             0.0621335
C10         0.698307               0.698307             0.0602902
C14         0.663117               0.663117             0.057252
C6          0.66207                0.66207              0.0571616
C3          0.610775               0.610775             0.0527328
C4          0.608755               0.608755             0.0525584
C16         0.567896               0.567896             0.0490308
C2          0.481598               0.481598             0.04158
C1          0.474257               0.474257             0.0409462
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_38

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001505941188838733   0.00041490979492664337  0.0         0.004723011038221259   0.4307422637939453  -0.03732218370739874  0.4811410903930664
    3        26       Softmax                 0.0   0.0   0.0025737517868877216  0.000806374941021204    0.0         -0.021249551402119184  0.564868688583374   -0.526620031316688    0.19007521867752075


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16870366562971767
RMSE: 0.41073551785755963
LogLoss: 0.5628014412630289
Mean Per-Class Error: 0.16185014334837694
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    1.0    1.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    2.0    3.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    1.0    1.0    3.0    0.0    5.0    3.0    0.0759493670886076   30 / 395
0.0    323.0  0.0    7.0    5.0    1.0    2.0    4.0    2.0    0.0    3.0    0.0    0.0    0.0    2.0    3.0    5.0    16.0   3.0    1.0    1.0    3.0    0.0    1.0    1.0    0.0    0.1566579634464752   60 / 383
0.0    2.0    313.0  0.0    11.0   0.0    9.0    2.0    0.0    0.0    11.0   2.0    0.0    0.0    3.0    0.0    2.0    1.0    4.0    2.0    4.0    0.0    2.0    0.0    0.0    0.0    0.14945652173913043  55 / 368
0.0    10.0   0.0    344.0  0.0    1.0    0.0    5.0    0.0    8.0    3.0    0.0    5.0    2.0    4.0    6.0    0.0    7.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.14427860696517414  58 / 402
0.0    5.0    6.0    0.0    308.0  3.0    18.0   3.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    2.0    6.0    1.0    0.0    0.0    8.0    0.0    9.0    0.19791666666666666  76 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    1.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    7.0    5.0    4.0    0.0    1.0    2.0    0.0    0.0    6.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    3.0    0.0    6.0    6.0    2.0    0.0    3.0    4.0    1.0    9.0    0.0    0.0    0.0    2.0    0.0    2.0    1.0    5.0    2.0    3.0    0.0    0.0    340.0  2.0    2.0    0.13486005089058525  53 / 393
0.0    1.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    9.0    0.0    1.0    11.0   3.0    12.0   0.0    0.0    343.0  1.0    0.1272264631043257   50 / 393
3.0    0.0    0.0    0.0    14.0   1.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    8.0    0.0    33.0   6.0    0.0    0.0    0.0    0.0    1.0    292.0  0.20435967302452315  75 / 367
391.0  447.0  377.0  423.0  403.0  356.0  335.0  329.0  346.0  370.0  350.0  361.0  402.0  383.0  410.0  417.0  392.0  460.0  354.0  395.0  408.0  365.0  397.0  402.0  386.0  344.0  0.1609517144856543   1,610 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839048
2    0.909927
3    0.938319
4    0.957313
5    0.96711
6    0.975207
7    0.979906
8    0.984405
9    0.988603
10   0.990503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17446649524017988
RMSE: 0.417691866380206
LogLoss: 0.5773239533006836
Mean Per-Class Error: 0.16874005763288194
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0   3.0    1.0   0.06741573033707865  6 / 89
0.0   83.0   0.0   2.0    4.0   0.0   1.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0   2.0   1.0    0.0   4.0    1.0   0.0   1.0    2.0   0.0   1.0   1.0    0.0   0.2169811320754717   23 / 106
0.0   1.0    68.0  0.0    3.0   0.0   1.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   3.0   0.0    1.0   0.0    1.0   1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.17073170731707318  14 / 82
0.0   2.0    0.0   96.0   0.0   1.0   0.0   1.0   0.0   2.0    2.0   0.0   2.0   1.0   0.0   2.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    2.0   0.0    75.0  2.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   3.0   0.0    0.0   0.0   2.0   0.0    3.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0   2.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   3.0    3.0   1.0   0.0   3.0   0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    3.0   0.0   1.0    0.0   0.0   78.0  1.0    0.0   0.22                 22 / 100
0.0   1.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    2.0   0.0    0.0   3.0   2.0    4.0   0.0   0.0   91.0   0.0   0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    2.0   0.0    7.0   2.0   0.0    0.0   0.0   0.0   1.0    69.0  0.20689655172413793  18 / 87
92.0  116.0  80.0  119.0  99.0  81.0  75.0  84.0  84.0  104.0  93.0  92.0  91.0  99.0  83.0  125.0  99.0  114.0  93.0  92.0  106.0  85.0  97.0  91.0  111.0  85.0  0.1686746987951807   420 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.831325
2    0.909639
3    0.940161
4    0.959839
5    0.966667
6    0.976707
7    0.980723
8    0.985944
9    0.988353
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:09  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:09  1 min  7.689 sec  76389 obs/sec     1         1             10007      0.594166         1.11634             0.993725       0.297211                         0.594357           1.11474               0.993705         0.300803
    2019-08-04 09:01:11  1 min  8.895 sec  76041 obs/sec     10        10            100070     0.410736         0.562801            0.997001       0.160952                         0.417692           0.577324              0.996891         0.168675
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.097181
C13         0.92938                0.92938              0.0903181
C12         0.903771               0.903771             0.0878294
C9          0.796531               0.796531             0.0774077
C8          0.787513               0.787513             0.0765313
C11         0.688003               0.688003             0.0668609
C10         0.678316               0.678316             0.0659195
C7          0.630377               0.630377             0.0612606
C16         0.60067                0.60067              0.0583737
C6          0.592887               0.592887             0.0576173
C14         0.5826                 0.5826               0.0566176
C5          0.54968                0.54968              0.0534184
C4          0.463535               0.463535             0.0450468
C3          0.435646               0.435646             0.0423365
C1          0.354591               0.354591             0.0344595
C2          0.296576               0.296576             0.0288215
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_84

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017051691587113282  0.00040737411472946405  0.0         -0.010461290966591097  0.1787542700767517  0.13804222251273668  0.11727571487426758
    3        26       Softmax                      0.0   0.0   0.00849584715130137    0.03100801259279251     0.0         -0.17533398653730276   0.4013267755508423  -0.9006089891499477  0.3708460330963135


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17876119983118224
RMSE: 0.4228016081227486
LogLoss: 0.5717633631185345
Mean Per-Class Error: 0.16078701224698205
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    10.0   4.0    2.0    5.0    0.0    1.0    0.0    0.0    1.0    4.0    0.0    2.0    0.0    2.0    2.0    5.0    0.0    0.09873417721518987  39 / 395
0.0    336.0  0.0    4.0    2.0    0.0    4.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    2.0    1.0    0.0    18.0   6.0    1.0    0.0    2.0    0.0    1.0    1.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    299.0  0.0    13.0   0.0    11.0   0.0    0.0    0.0    21.0   2.0    1.0    0.0    9.0    0.0    2.0    0.0    2.0    1.0    2.0    0.0    5.0    0.0    0.0    0.0    0.1875               69 / 368
1.0    23.0   0.0    345.0  0.0    0.0    1.0    4.0    0.0    5.0    0.0    0.0    7.0    3.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.1417910447761194   57 / 402
0.0    6.0    1.0    0.0    318.0  3.0    19.0   0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    4.0    8.0    2.0    1.0    0.0    0.0    3.0    0.0    14.0   0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    1.0    5.0    0.0    0.0    3.0    1.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    3.0    0.0    4.0    6.0    1.0    0.0    2.0    2.0    2.0    4.0    4.0    0.0    0.0    0.0    0.0    6.0    2.0    1.0    2.0    3.0    0.0    0.0    344.0  3.0    5.0    0.12690355329949238  50 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    6.0    2.0    10.0   1.0    0.0    361.0  0.0    0.08142493638676845  32 / 393
0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    19.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    16.0   3.0    0.0    0.0    0.0    3.0    0.0    307.0  0.16348773841961853  60 / 367
389.0  491.0  326.0  413.0  408.0  371.0  379.0  291.0  338.0  379.0  365.0  379.0  405.0  385.0  421.0  359.0  351.0  430.0  351.0  370.0  403.0  369.0  422.0  410.0  424.0  374.0  0.1599520143956813   1,600 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840048
2    0.910527
3    0.943917
4    0.959212
5    0.971608
6    0.978606
7    0.983005
8    0.986904
9    0.990203
10   0.993102

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18089246633198647
RMSE: 0.4253145498710178
LogLoss: 0.5783158663015261
Mean Per-Class Error: 0.16634085161292594
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   85.0   0.0   1.0    2.0   0.0   1.0   1.0   1.0   0.0    1.0   0.0    0.0   0.0    2.0   0.0    0.0   8.0    1.0   0.0   0.0    2.0   0.0    1.0    0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    61.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0    3.0   1.0    0.0   0.0    5.0   0.0    1.0   0.0    0.0   1.0   0.0    0.0   2.0    0.0    0.0    0.0   0.25609756097560976  21 / 82
1.0   4.0    0.0   96.0   0.0   0.0   1.0   2.0   0.0   1.0    0.0   0.0    3.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    78.0  1.0   5.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   1.0    2.0   1.0   0.0    0.0   0.0    1.0    0.0    7.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   1.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    3.0   0.0   0.0   2.0   0.0   0.0    2.0   3.0    0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    83.0   1.0    1.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    2.0   0.0    0.0   1.0   0.0    3.0   1.0    0.0    99.0   0.0   0.07476635514018691  8 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   7.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0    1.0    0.0    72.0  0.1724137931034483   15 / 87
92.0  117.0  65.0  114.0  97.0  85.0  96.0  74.0  80.0  112.0  93.0  102.0  90.0  102.0  90.0  104.0  92.0  114.0  80.0  87.0  100.0  83.0  101.0  100.0  122.0  98.0  0.1650602409638554   411 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83494
2    0.909237
3    0.94498
4    0.961044
5    0.970683
6    0.975904
7    0.981526
8    0.985944
9    0.98996
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:22  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:23  2 min 20.934 sec  42948 obs/sec     1         1             10007      0.593411         1.08965             0.993743       0.283315                         0.593692           1.09003               0.993719         0.288755
    2019-08-04 09:02:25  2 min 22.831 sec  48436 obs/sec     10        10            100070     0.422802         0.571763            0.996823       0.159952                         0.425315           0.578316              0.996777         0.16506
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0882331
C13         0.958933               0.958933             0.0846096
C8          0.843474               0.843474             0.0744223
C12         0.835408               0.835408             0.0737106
C9          0.83157                0.83157              0.073372
C7          0.802935               0.802935             0.0708454
C11         0.731614               0.731614             0.0645526
C5          0.718938               0.718938             0.0634342
C10         0.661994               0.661994             0.0584098
C14         0.641748               0.641748             0.0566234
C6          0.624318               0.624318             0.0550855
C3          0.609279               0.609279             0.0537585
C4          0.580708               0.580708             0.0512376
C16         0.57578                0.57578              0.0508028
C1          0.462641               0.462641             0.0408203
C2          0.454278               0.454278             0.0400823
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_179

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017444423265970954  0.0004092440940439701  0.0         -0.009459646684101486  0.17742127180099487  0.14367568730262664  0.12406069040298462
    3        26       Softmax                      0.0   0.0   0.008911845091880912   0.029612228274345398   0.0         -0.1820522983356308    0.4031531810760498   -0.907458109301584   0.32822632789611816


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1784857262300285
RMSE: 0.42247571081664387
LogLoss: 0.5680136254831661
Mean Per-Class Error: 0.1616712781796415
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    4.0    2.0    6.0    0.0    2.0    0.0    0.0    2.0    6.0    1.0    1.0    4.0    2.0    1.0    3.0    0.0    0.09620253164556962  38 / 395
0.0    342.0  0.0    5.0    2.0    1.0    2.0    5.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    2.0    10.0   5.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.10704960835509138  41 / 383
0.0    0.0    313.0  0.0    9.0    0.0    4.0    0.0    0.0    0.0    21.0   1.0    1.0    0.0    4.0    0.0    2.0    0.0    5.0    2.0    0.0    0.0    6.0    0.0    0.0    0.0    0.14945652173913043  55 / 368
0.0    21.0   0.0    351.0  0.0    0.0    0.0    5.0    0.0    4.0    1.0    0.0    7.0    2.0    1.0    1.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.12903225806451613  52 / 403
0.0    7.0    5.0    0.0    308.0  3.0    14.0   0.0    0.0    0.0    6.0    5.0    0.0    0.0    0.0    1.0    5.0    4.0    10.0   2.0    0.0    0.0    0.0    3.0    0.0    11.0   0.19791666666666666  76 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    21.0   0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    342.0  0.0    0.0    0.0    0.088                33 / 375
0.0    2.0    0.0    3.0    3.0    1.0    0.0    2.0    2.0    2.0    7.0    4.0    0.0    0.0    2.0    0.0    5.0    0.0    3.0    2.0    1.0    0.0    0.0    350.0  1.0    4.0    0.1116751269035533   44 / 394
1.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    6.0    0.0    3.0    12.0   1.0    23.0   1.0    0.0    337.0  0.0    0.14249363867684478  56 / 393
1.0    1.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    16.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    28.0   1.0    0.0    0.0    0.0    2.0    0.0    298.0  0.18579234972677597  68 / 366
399.0  501.0  370.0  425.0  382.0  385.0  338.0  303.0  345.0  367.0  394.0  373.0  456.0  370.0  398.0  386.0  333.0  409.0  425.0  357.0  386.0  389.0  407.0  405.0  369.0  331.0  0.1610516844946516   1,611 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838948
2    0.913626
3    0.944617
4    0.961412
5    0.973408
6    0.979606
7    0.984105
8    0.988004
9    0.990403
10   0.992702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18091339786210053
RMSE: 0.42533915627661245
LogLoss: 0.5783885312693577
Mean Per-Class Error: 0.16311410542769417
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17     18     19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0   2.0   1.0    0.0   2.0    0.0   0.10112359550561797  9 / 89
0.0   90.0   0.0   0.0    1.0   0.0   0.0   1.0   1.0   0.0    1.0   0.0   0.0    0.0   1.0   1.0    1.0   5.0    1.0    0.0   0.0   2.0   0.0    1.0   0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    65.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0   2.0   0.0    1.0   0.0    3.0    1.0   0.0   0.0   2.0    0.0   0.0    0.0   0.2073170731707317   17 / 82
0.0   4.0    0.0   95.0   0.0   0.0   0.0   2.0   0.0   3.0    1.0   0.0   3.0    1.0   0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0   0.15178571428571427  17 / 112
0.0   1.0    1.0   0.0    72.0  2.0   3.0   0.0   0.0   0.0    2.0   2.0   0.0    0.0   0.0   0.0    2.0   1.0    5.0    0.0   0.0   0.0   0.0    1.0   0.0    5.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0   1.0   0.0   0.0    3.0   2.0   0.0    0.0   0.0   0.0    1.0   0.0    1.0    0.0   0.0   0.0   0.0    86.0  0.0    1.0   0.14                 14 / 100
1.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    3.0   0.0    0.0    4.0   0.0   8.0   1.0    0.0   89.0   0.0   0.16822429906542055  18 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0    0.0   0.0    73.0  0.16091954022988506  14 / 87
92.0  124.0  78.0  115.0  87.0  90.0  86.0  74.0  86.0  104.0  98.0  99.0  104.0  99.0  82.0  111.0  92.0  102.0  108.0  84.0  97.0  92.0  102.0  99.0  100.0  85.0  0.16305220883534136  406 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836948
2    0.913655
3    0.94498
4    0.961446
5    0.971888
6    0.978715
7    0.981928
8    0.987952
9    0.98996
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:20  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:20  5 min 18.128 sec  42223 obs/sec     1         1             10007      0.597865         1.10216             0.993647       0.292612                         0.599056           1.10322               0.993605         0.299598
    2019-08-04 09:05:22  5 min 20.017 sec  48273 obs/sec     10        10            100070     0.422476         0.568014            0.996828       0.161052                         0.425339           0.578389              0.996776         0.163052
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0879421
C13         0.957783               0.957783             0.0842294
C8          0.852524               0.852524             0.0749727
C9          0.827905               0.827905             0.0728077
C12         0.827181               0.827181             0.072744
C7          0.801413               0.801413             0.0704779
C11         0.735673               0.735673             0.0646966
C10         0.694993               0.694993             0.0611191
C5          0.678228               0.678228             0.0596448
C14         0.63497                0.63497              0.0558406
C6          0.630876               0.630876             0.0554805
C3          0.615109               0.615109             0.0540939
C16         0.608272               0.608272             0.0534927
C4          0.60614                0.60614              0.0533052
C1          0.457893               0.457893             0.0402681
C2          0.442161               0.442161             0.0388845
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_73

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009689460204356237  0.0002418771618977189  0.0         -0.007723382782558019  0.23496872186660767  0.21863225203075917  0.20335251092910767
    3        26       Softmax                      0.0   0.0   0.00676596322259334    0.029056698083877563   0.0         -0.3055776215151127    0.7290880680084229   -0.4886973364182534  0.2522839307785034


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17388598110660275
RMSE: 0.4169963802080334
LogLoss: 0.5719482018654763
Mean Per-Class Error: 0.16276198266254382
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    5.0    6.0    1.0    1.0    0.0    5.0    0.0    0.0    1.0    2.0    0.0    1.0    4.0    1.0    0.0    5.0    3.0    0.09367088607594937  37 / 395
0.0    342.0  0.0    2.0    4.0    0.0    3.0    2.0    3.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    1.0    9.0    5.0    0.0    0.0    1.0    1.0    1.0    2.0    1.0    0.10704960835509138  41 / 383
0.0    0.0    309.0  0.0    10.0   0.0    8.0    0.0    0.0    0.0    25.0   0.0    2.0    0.0    7.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.15803814713896458  58 / 367
4.0    20.0   0.0    333.0  0.0    0.0    3.0    2.0    3.0    3.0    0.0    0.0    7.0    4.0    2.0    3.0    0.0    10.0   1.0    1.0    0.0    0.0    0.0    4.0    0.0    3.0    0.17369727047146402  70 / 403
0.0    0.0    5.0    0.0    319.0  3.0    17.0   2.0    1.0    0.0    4.0    4.0    0.0    0.0    0.0    0.0    2.0    3.0    8.0    4.0    0.0    0.0    0.0    3.0    1.0    8.0    0.16927083333333334  65 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    12.0   2.0    2.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    4.0    7.0    0.0    0.0    1.0    2.0    2.0    6.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    5.0    3.0    3.0    0.0    0.0    348.0  2.0    5.0    0.116751269035533    46 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    3.0    0.0    2.0    7.0    0.0    19.0   1.0    0.0    349.0  0.0    0.11195928753180662  44 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    24.0   3.0    0.0    0.0    0.0    2.0    1.0    304.0  0.17166212534059946  63 / 367
395.0  490.0  344.0  405.0  427.0  392.0  384.0  315.0  357.0  369.0  376.0  375.0  421.0  380.0  417.0  364.0  322.0  399.0  348.0  377.0  387.0  382.0  411.0  406.0  386.0  374.0  0.16205138458462462  1,621 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837949
2    0.912826
3    0.941917
4    0.957913
5    0.968609
6    0.976707
7    0.981006
8    0.986504
9    0.989603
10   0.992802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17530764345823377
RMSE: 0.418697556069096
LogLoss: 0.5794071499372369
Mean Per-Class Error: 0.16027732684844792
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   3.0   0.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   84.0   0.0   1.0    3.0    0.0   1.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0   4.0    3.0   0.0   0.0   1.0   1.0    1.0    1.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    66.0  0.0    2.0    0.0   2.0    0.0   0.0   0.0    5.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   0.0   0.0   1.0    0.0    0.0    0.0   0.1951219512195122   16 / 82
3.0   2.0    0.0   93.0   0.0    0.0   1.0    2.0   1.0   0.0    0.0   0.0   3.0   1.0    0.0   2.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0    2.0    0.0    1.0   0.16964285714285715  19 / 112
0.0   0.0    2.0   0.0    78.0   2.0   5.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   1.0   0.0   0.0   0.0    1.0    0.0    3.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   89.0   0.0    0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0    1.0   0.0   0.0    3.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    87.0   0.0    2.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0   1.0   0.0   6.0   1.0    0.0    96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0    0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    4.0   0.0   0.0   0.0   0.0    1.0    1.0    71.0  0.1839080459770115   16 / 87
94.0  108.0  72.0  115.0  104.0  95.0  104.0  82.0  87.0  107.0  91.0  97.0  87.0  100.0  87.0  104.0  83.0  101.0  86.0  89.0  97.0  91.0  103.0  102.0  109.0  95.0  0.1610441767068273   401 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838956
2    0.911647
3    0.942169
4    0.957831
5    0.96988
6    0.975904
7    0.980321
8    0.985542
9    0.989157
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:03  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:03  2 min  0.970 sec  99079 obs/sec     1         1             10007      0.592004         1.09821             0.993772       0.291613                         0.595948           1.1167                0.993672         0.305622
    2019-08-04 09:02:04  2 min  1.786 sec  111436 obs/sec    10        10            100070     0.416996         0.571948            0.99691        0.162051                         0.418698           0.579407              0.996876         0.161044
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0877655
C13         0.993236               0.993236             0.0871719
C12         0.871563               0.871563             0.0764932
C9          0.809789               0.809789             0.0710716
C7          0.785585               0.785585             0.0689473
C8          0.78111                0.78111              0.0685545
C6          0.722029               0.722029             0.0633693
C5          0.717064               0.717064             0.0629335
C11         0.685181               0.685181             0.0601353
C10         0.647989               0.647989             0.0568711
C14         0.634897               0.634897             0.0557221
C16         0.605319               0.605319             0.0531262
C4          0.598642               0.598642             0.0525402
C3          0.570414               0.570414             0.0500627
C2          0.493575               0.493575             0.0433188
C1          0.4776                 0.4776               0.0419168
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_181

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017229524561628295  0.0004011387936770916  0.0         -0.009941586639403255  0.17619895935058594  0.14193357519376987  0.1187720000743866
    3        26       Softmax                      0.0   0.0   0.008798580664102492   0.027271807193756104   0.0         -0.18037234499788551   0.40283656120300293  -0.909350252588001   0.3542454242706299


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1793892943909398
RMSE: 0.4235437337406136
LogLoss: 0.5781394643716872
Mean Per-Class Error: 0.15939748496176093
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    8.0    0.0    2.0    0.0    2.0    0.0    9.0    1.0    1.0    0.0    2.0    1.0    6.0    0.0    0.08860759493670886  35 / 395
0.0    343.0  0.0    6.0    4.0    0.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    2.0    0.0    13.0   5.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.10443864229765012  40 / 383
0.0    0.0    313.0  1.0    14.0   0.0    11.0   0.0    0.0    0.0    13.0   1.0    1.0    0.0    4.0    0.0    1.0    0.0    3.0    1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.14713896457765668  54 / 367
2.0    19.0   0.0    355.0  0.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    6.0    4.0    2.0    0.0    0.0    5.0    1.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    0.11910669975186104  48 / 403
0.0    7.0    0.0    0.0    321.0  3.0    14.0   0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    6.0    4.0    9.0    2.0    1.0    0.0    0.0    4.0    0.0    10.0   0.1618798955613577   62 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    2.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    2.0    0.0    4.0    7.0    0.0    1.0    2.0    2.0    2.0    4.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    2.0    1.0    1.0    0.0    0.0    349.0  4.0    3.0    0.11195928753180662  44 / 393
0.0    0.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    24.0   1.0    11.0   1.0    0.0    341.0  0.0    0.13231552162849872  52 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    23.0   4.0    0.0    0.0    0.0    3.0    0.0    307.0  0.16348773841961853  60 / 367
402.0  515.0  362.0  439.0  423.0  368.0  336.0  310.0  331.0  359.0  342.0  367.0  410.0  384.0  408.0  384.0  324.0  447.0  389.0  380.0  400.0  353.0  410.0  427.0  388.0  345.0  0.15865240427871638  1,587 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.841348
2    0.911926
3    0.941518
4    0.957913
5    0.969009
6    0.978107
7    0.982805
8    0.986404
9    0.989503
10   0.992202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18065186918130097
RMSE: 0.42503160962603825
LogLoss: 0.5794521322095172
Mean Per-Class Error: 0.16270921553244813
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0   1.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   87.0   0.0   1.0    3.0   0.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    2.0   1.0    0.0   5.0    1.0   0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    65.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    2.0   1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.2073170731707317   17 / 82
2.0   4.0    0.0   97.0   0.0   0.0   0.0   2.0   0.0   1.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    78.0  1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   2.0   0.0    0.0   0.0   2.0    0.0    4.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    4.0   0.0   1.0   1.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0   84.0   1.0    2.0   0.16                 16 / 100
0.0   0.0    0.0   1.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   6.0   0.0    4.0   1.0   0.0    91.0   0.0   0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0   1.0   0.0    0.0   0.0   0.0    0.0    74.0  0.14942528735632185  13 / 87
96.0  123.0  76.0  120.0  99.0  89.0  84.0  76.0  81.0  103.0  90.0  98.0  91.0  101.0  84.0  111.0  88.0  112.0  96.0  92.0  100.0  80.0  99.0  103.0  108.0  90.0  0.16224899598393575  404 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837751
2    0.91486
3    0.940562
4    0.959839
5    0.971084
6    0.980321
7    0.982731
8    0.985944
9    0.989558
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:24  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:25  5 min 22.787 sec  41695 obs/sec     1         1             10007      0.599084         1.10611             0.99362        0.288114                         0.599895           1.10655               0.993588         0.293976
    2019-08-04 09:05:26  5 min 24.639 sec  49053 obs/sec     10        10            100070     0.423544         0.578139            0.996811       0.158652                         0.425032           0.579452              0.996781         0.162249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0894597
C13         0.957871               0.957871             0.0856908
C7          0.84659                0.84659              0.0757357
C8          0.804775               0.804775             0.0719949
C12         0.795022               0.795022             0.0711224
C9          0.791109               0.791109             0.0707724
C11         0.707987               0.707987             0.0633363
C5          0.702077               0.702077             0.0628076
C10         0.665295               0.665295             0.0595171
C6          0.637919               0.637919             0.057068
C14         0.612431               0.612431             0.0547879
C3          0.590283               0.590283             0.0528066
C16         0.580678               0.580678             0.0519473
C4          0.576497               0.576497             0.0515733
C1          0.460716               0.460716             0.0412155
C2          0.44897                0.44897              0.0401647
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_171

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017607501100940226  0.0004512585001066327  0.0         -0.0019099044620105587  0.4470405578613281   -0.02342704373027494  0.5045769214630127
    3        26       Softmax                 0.0   0.0   0.00228461418394615    0.0005778667982667685  0.0         -0.005024374440549851   0.41383790969848633  -0.4909756541881966   0.19409584999084473


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.165797911507049
RMSE: 0.4071828968744255
LogLoss: 0.573110870242512
Mean Per-Class Error: 0.16701896089554755
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    5.0    4.0    2.0    3.0    0.0    1.0    0.0    0.0    2.0    4.0    1.0    3.0    0.0    2.0    1.0    6.0    1.0    0.09620253164556962  38 / 395
0.0    332.0  1.0    5.0    3.0    0.0    1.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    15.0   11.0   0.0    0.0    0.0    1.0    3.0    1.0    2.0    0.13315926892950392  51 / 383
0.0    0.0    299.0  1.0    19.0   1.0    8.0    1.0    0.0    0.0    13.0   1.0    0.0    0.0    6.0    0.0    1.0    2.0    5.0    0.0    5.0    0.0    6.0    0.0    0.0    0.0    0.1875               69 / 368
1.0    22.0   0.0    335.0  0.0    2.0    0.0    4.0    2.0    1.0    0.0    0.0    8.0    1.0    3.0    2.0    0.0    11.0   1.0    0.0    2.0    0.0    1.0    3.0    0.0    4.0    0.1687344913151365   68 / 403
0.0    3.0    1.0    0.0    315.0  6.0    16.0   1.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    3.0    12.0   2.0    0.0    0.0    0.0    4.0    0.0    15.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    4.0    0.0    0.0    4.0    0.0    0.0    7.0    1.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    4.0    0.0    4.0    9.0    0.0    0.0    3.0    3.0    0.0    7.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    1.0    2.0    0.0    0.0    342.0  4.0    5.0    0.1297709923664122   51 / 393
0.0    1.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    0.0    3.0    13.0   1.0    18.0   2.0    0.0    341.0  0.0    0.13231552162849872  52 / 393
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    26.0   3.0    0.0    0.0    0.0    1.0    1.0    309.0  0.15803814713896458  58 / 367
395.0  507.0  330.0  414.0  407.0  382.0  364.0  322.0  344.0  342.0  352.0  351.0  392.0  366.0  388.0  380.0  344.0  471.0  372.0  378.0  424.0  368.0  421.0  418.0  395.0  376.0  0.16615015495351396  1,662 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83385
2    0.908827
3    0.940318
4    0.955613
5    0.96741
6    0.975607
7    0.981306
8    0.984805
9    0.987604
10   0.991503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1677167140030144
RMSE: 0.4095323113052429
LogLoss: 0.5794985329760949
Mean Per-Class Error: 0.17009861032375165
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   1.0    0.0   1.0    1.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   90.0   0.0   1.0    2.0   0.0   1.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   6.0    2.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    61.0  0.0    5.0   1.0   4.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   5.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   2.0    0.0   0.0    0.0   0.25609756097560976  21 / 82
1.0   1.0    0.0   93.0   0.0   1.0   0.0   1.0   1.0   0.0   0.0   0.0   3.0   1.0   1.0   2.0    0.0   3.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0    2.0   0.16964285714285715  19 / 112
0.0   0.0    1.0   0.0    74.0  5.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    4.0   1.0   0.0    0.0   0.0    0.0   0.0    7.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   3.0    1.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   2.0    0.0   2.0    3.0   0.0   0.0   2.0   0.0   0.0   4.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    80.0  2.0    2.0   0.2                  20 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    2.0   0.0    0.0   4.0   0.0    5.0   1.0    0.0   93.0   0.0   0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   0.0    0.0   1.0    75.0  0.13793103448275862  12 / 87
92.0  126.0  66.0  118.0  92.0  93.0  91.0  79.0  84.0  95.0  88.0  97.0  87.0  98.0  81.0  107.0  87.0  121.0  93.0  91.0  110.0  81.0  106.0  98.0  114.0  95.0  0.16947791164658635  422 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830522
2    0.912048
3    0.940161
4    0.956225
5    0.969478
6    0.97751
7    0.983133
8    0.98755
9    0.989157
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:00  4 min 58.603 sec  44083 obs/sec     1         1             10007      0.548462         0.997513            0.994654       0.26832                          0.549033           0.991997              0.994629         0.277108
    2019-08-04 09:05:02  5 min  0.653 sec  44634 obs/sec     10        10            100070     0.407183         0.573111            0.997053       0.16615                          0.409532           0.579499              0.997012         0.169478
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0869614
C15         0.987834               0.987834             0.0859034
C9          0.894127               0.894127             0.0777546
C12         0.819617               0.819617             0.0712751
C8          0.808733               0.808733             0.0703285
C7          0.790708               0.790708             0.068761
C11         0.739279               0.739279             0.0642887
C14         0.71808                0.71808              0.0624452
C10         0.709812               0.709812             0.0617263
C5          0.627559               0.627559             0.0545734
C6          0.615727               0.615727             0.0535445
C16         0.613112               0.613112             0.0533171
C4          0.600659               0.600659             0.0522342
C3          0.590213               0.590213             0.0513257
C2          0.50685                0.50685              0.0440764
C1          0.477044               0.477044             0.0414844
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_217

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017380980883672237  0.00041699607390910387  0.0         -0.01035833950859888  0.17840778827667236  0.12601392811112574  0.11991646885871887
    3        26       Softmax                      0.0   0.0   0.008124471111308105   0.024409286677837372    0.0         -0.18310721658884596  0.4019879102706909   -0.9287998525190975  0.38297581672668457


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.18035136703954766
RMSE: 0.42467795685618964
LogLoss: 0.573385537125349
Mean Per-Class Error: 0.16216928876595396
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    1.0    5.0    0.0    2.0    0.0    1.0    1.0    7.0    1.0    1.0    1.0    2.0    0.0    5.0    0.0    0.08629441624365482  34 / 394
0.0    329.0  0.0    4.0    4.0    1.0    4.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    7.0    0.0    16.0   5.0    0.0    0.0    2.0    0.0    2.0    2.0    0.0    0.1409921671018277   54 / 383
0.0    0.0    307.0  0.0    11.0   1.0    5.0    0.0    0.0    0.0    22.0   3.0    1.0    0.0    4.0    0.0    1.0    0.0    5.0    1.0    1.0    0.0    6.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
1.0    16.0   0.0    351.0  0.0    0.0    0.0    1.0    0.0    4.0    1.0    0.0    7.0    4.0    1.0    1.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.12686567164179105  51 / 402
0.0    8.0    0.0    0.0    318.0  6.0    16.0   0.0    0.0    0.0    6.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    5.0    2.0    0.0    0.0    0.0    4.0    0.0    12.0   0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    20.0   1.0    1.0    0.0    0.0    1.0    0.0    0.0    6.0    0.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    1.0    0.0    5.0    7.0    0.0    0.0    2.0    2.0    3.0    4.0    3.0    0.0    0.0    2.0    0.0    3.0    1.0    1.0    1.0    1.0    0.0    0.0    352.0  3.0    3.0    0.1065989847715736   42 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    3.0    14.0   1.0    25.0   1.0    0.0    335.0  0.0    0.1475826972010178   58 / 393
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    24.0   1.0    0.0    0.0    0.0    0.0    0.0    308.0  0.16076294277929154  59 / 367
402.0  470.0  356.0  433.0  408.0  397.0  338.0  310.0  348.0  354.0  405.0  375.0  445.0  379.0  396.0  381.0  330.0  417.0  375.0  364.0  397.0  384.0  385.0  403.0  382.0  369.0  0.1614515645306408   1,615 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838548
2    0.911926
3    0.940218
4    0.957813
5    0.970109
6    0.977607
7    0.984205
8    0.987504
9    0.990603
10   0.992702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18222701663694488
RMSE: 0.4268805648386266
LogLoss: 0.5795729479627055
Mean Per-Class Error: 0.16668969164794273
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11     12     13    14    15     16    17     18    19    20    21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    3.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0   0.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   0.0    3.0   0.0   2.0   1.0   1.0   0.0    1.0    0.0    0.0    0.0   1.0   2.0    0.0   6.0    1.0   0.0   0.0   2.0   0.0   1.0   1.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    64.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    5.0    1.0    0.0    0.0   2.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   2.0   0.0   0.0    0.0   0.21951219512195122  18 / 82
1.0   3.0    0.0   98.0   0.0   0.0   0.0   1.0   0.0   1.0    1.0    0.0    3.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.125                14 / 112
0.0   1.0    0.0   0.0    75.0  4.0   5.0   0.0   0.0   0.0    2.0    0.0    0.0    0.0   0.0   0.0    0.0   1.0    2.0   1.0   0.0   0.0   0.0   1.0   0.0    5.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0    4.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0   0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    2.0    2.0    0.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   87.0  1.0    1.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0   0.0    2.0   0.0    0.0   4.0   0.0   9.0   1.0   0.0   90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0    1.0    0.0    0.0   0.0   0.0    1.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
94.0  112.0  74.0  118.0  95.0  95.0  86.0  76.0  84.0  104.0  100.0  100.0  102.0  99.0  83.0  106.0  86.0  106.0  93.0  87.0  98.0  92.0  97.0  99.0  110.0  94.0  0.16666666666666666  415 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.833333
2    0.915663
3    0.940161
4    0.957831
5    0.96747
6    0.974297
7    0.983132
8    0.986747
9    0.989558
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:20  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:20  6 min 18.109 sec  44083 obs/sec     1         1             10007      0.58946          1.06936             0.993823       0.281416                         0.588295           1.06188               0.993833         0.284739
    2019-08-04 09:06:22  6 min 19.933 sec  50085 obs/sec     10        10            100070     0.424678         0.573386            0.996794       0.161452                         0.426881           0.579573              0.996753         0.166667
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0892944
C13         0.916982               0.916982             0.0818813
C8          0.825366               0.825366             0.0737006
C7          0.792152               0.792152             0.0707348
C9          0.790359               0.790359             0.0705747
C12         0.785784               0.785784             0.0701661
C11         0.712349               0.712349             0.0636088
C10         0.702889               0.702889             0.062764
C5          0.68058                0.68058              0.060772
C6          0.652204               0.652204             0.0582382
C14         0.632131               0.632131             0.0564458
C3          0.619884               0.619884             0.0553522
C16         0.598123               0.598123             0.053409
C4          0.570556               0.570556             0.0509475
C2          0.470689               0.470689             0.0420299
C1          0.448861               0.448861             0.0400808
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_239

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017076441103398565  0.0004069217247888446  0.0         -0.010084829501969206  0.17550116777420044  0.13661510285439812  0.11817282438278198
    3        26       Softmax                      0.0   0.0   0.009001209122979721   0.032733410596847534   0.0         -0.18450395566653938   0.40554726123809814  -0.9256437180217929  0.37086427211761475


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17747286921807118
RMSE: 0.42127528911398443
LogLoss: 0.5692059749405989
Mean Per-Class Error: 0.15928977696959976
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    6.0    4.0    1.0    5.0    0.0    1.0    0.0    0.0    1.0    6.0    1.0    2.0    0.0    2.0    0.0    5.0    0.0    0.09113924050632911  36 / 395
0.0    327.0  0.0    5.0    3.0    0.0    4.0    6.0    2.0    0.0    2.0    0.0    0.0    0.0    2.0    3.0    0.0    17.0   8.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.14397905759162305  55 / 382
0.0    0.0    303.0  0.0    14.0   0.0    8.0    1.0    0.0    0.0    19.0   0.0    0.0    0.0    7.0    0.0    2.0    0.0    4.0    3.0    2.0    0.0    5.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
0.0    18.0   0.0    357.0  0.0    0.0    0.0    2.0    0.0    2.0    2.0    0.0    7.0    3.0    3.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.1141439205955335   46 / 403
0.0    6.0    1.0    0.0    315.0  2.0    16.0   0.0    0.0    0.0    6.0    2.0    0.0    0.0    1.0    0.0    6.0    3.0    7.0    2.0    0.0    0.0    0.0    4.0    0.0    13.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    0.0    16.0   0.0    1.0    0.0    0.0    3.0    0.0    0.0    2.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    2.0    0.0    6.0    5.0    0.0    0.0    2.0    3.0    1.0    6.0    2.0    0.0    0.0    2.0    0.0    4.0    0.0    2.0    2.0    1.0    1.0    0.0    347.0  3.0    5.0    0.11928934010152284  47 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    3.0    5.0    0.0    8.0    2.0    0.0    356.0  0.0    0.09414758269720101  37 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    22.0   3.0    0.0    0.0    0.0    0.0    0.0    313.0  0.1448087431693989   53 / 366
394.0  485.0  334.0  432.0  389.0  370.0  376.0  316.0  341.0  362.0  403.0  359.0  432.0  390.0  413.0  377.0  355.0  402.0  371.0  363.0  378.0  364.0  403.0  405.0  413.0  376.0  0.15855243426971907  1,586 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.841448
2    0.913826
3    0.943617
4    0.959112
5    0.970509
6    0.979006
7    0.983305
8    0.986904
9    0.990303
10   0.992702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1804765034297182
RMSE: 0.42482526223109446
LogLoss: 0.5799173171788976
Mean Per-Class Error: 0.16291497446355138
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20    21    22    23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0   0.0    3.0    0.0    0.07865168539325842  7 / 89
0.0   85.0   0.0   1.0    2.0   0.0   1.0   2.0   1.0   0.0    1.0   0.0    0.0   0.0    2.0   1.0    0.0   6.0    2.0   0.0   0.0   1.0   0.0   1.0    0.0    0.0    0.19811320754716982  21 / 106
0.0   0.0    64.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    3.0   0.0    1.0   0.0    3.0   1.0   1.0   0.0   2.0   0.0    0.0    0.0    0.21951219512195122  18 / 82
0.0   3.0    0.0   96.0   0.0   0.0   0.0   2.0   0.0   2.0    1.0   0.0    3.0   1.0    0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0    1.0    0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    76.0  1.0   2.0   0.0   0.0   0.0    2.0   1.0    0.0   0.0    0.0   0.0    3.0   1.0    3.0   1.0   0.0   0.0   0.0   1.0    0.0    6.0    0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   86.0  0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    3.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   86.0   1.0    2.0    0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    4.0   0.0    0.0   1.0   0.0   3.0   1.0   0.0    95.0   0.0    0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0    2.0   1.0   0.0   0.0   0.0   0.0    0.0    75.0   0.13793103448275862  12 / 87
93.0  116.0  70.0  114.0  93.0  87.0  93.0  79.0  84.0  105.0  98.0  100.0  99.0  103.0  85.0  108.0  92.0  105.0  87.0  83.0  96.0  82.0  99.0  100.0  116.0  103.0  0.16224899598393575  404 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837751
2    0.917671
3    0.946988
4    0.959438
5    0.969076
6    0.977109
7    0.981928
8    0.987149
9    0.990362
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:59  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:07:00  6 min 57.834 sec  43698 obs/sec     1         1             10007      0.589351         1.07891             0.993826       0.281216                         0.588343           1.07289               0.993832         0.285944
    2019-08-04 09:07:01  6 min 59.718 sec  48507 obs/sec     10        10            100070     0.421275         0.569206            0.996845       0.158552                         0.424825           0.579917              0.996784         0.162249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0907406
C13         0.943946               0.943946             0.0856543
C7          0.793419               0.793419             0.0719954
C9          0.791896               0.791896             0.0718571
C8          0.771397               0.771397             0.0699971
C12         0.752573               0.752573             0.0682889
C11         0.739207               0.739207             0.0670761
C5          0.691369               0.691369             0.0627353
C10         0.663171               0.663171             0.0601765
C6          0.634718               0.634718             0.0575947
C14         0.632099               0.632099             0.057357
C3          0.605455               0.605455             0.0549394
C16         0.5693                 0.5693               0.0516587
C4          0.566288               0.566288             0.0513854
C1          0.439592               0.439592             0.0398888
C2          0.425993               0.425993             0.0386548
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_108

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017469238759701966  0.0004268242046236992  0.0         0.006078836824698897   0.46796393394470215  -0.01937157440752095  0.4897909164428711
    3        26       Softmax                 0.0   0.0   0.002154428444170592   0.0005206605419516563  0.0         -0.001588122588049583  0.40971481800079346  -0.4783043873018071   0.20494627952575684


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16994725236565536
RMSE: 0.41224659169683303
LogLoss: 0.5689384481780366
Mean Per-Class Error: 0.1736310319166829
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    1.0    6.0    0.0    1.0    0.0    2.0    1.0    3.0    2.0    3.0    1.0    2.0    3.0    4.0    0.0    0.10126582278481013  40 / 395
0.0    323.0  0.0    6.0    5.0    1.0    1.0    4.0    1.0    0.0    5.0    1.0    3.0    0.0    0.0    0.0    1.0    18.0   9.0    0.0    0.0    3.0    0.0    1.0    1.0    0.0    0.1566579634464752   60 / 383
0.0    0.0    303.0  1.0    14.0   1.0    11.0   1.0    0.0    0.0    19.0   0.0    0.0    0.0    3.0    0.0    2.0    0.0    6.0    2.0    1.0    0.0    4.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
4.0    17.0   0.0    326.0  0.0    0.0    0.0    12.0   0.0    5.0    2.0    0.0    7.0    3.0    1.0    3.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    4.0    0.1890547263681592   76 / 402
0.0    1.0    1.0    0.0    315.0  5.0    13.0   1.0    1.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    6.0    3.0    10.0   0.0    1.0    0.0    0.0    3.0    0.0    13.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    17.0   0.0    7.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    335.0  0.0    0.0    0.0    0.10666666666666667  40 / 375
0.0    4.0    0.0    4.0    7.0    0.0    2.0    3.0    2.0    3.0    11.0   0.0    0.0    0.0    2.0    0.0    5.0    0.0    4.0    1.0    3.0    1.0    0.0    335.0  5.0    2.0    0.14974619289340102  59 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    8.0    0.0    3.0    6.0    4.0    10.0   2.0    1.0    349.0  0.0    0.11195928753180662  44 / 393
0.0    0.0    0.0    1.0    18.0   0.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    10.0   1.0    42.0   4.0    0.0    0.0    0.0    0.0    0.0    278.0  0.24250681198910082  89 / 367
402.0  484.0  347.0  400.0  416.0  369.0  329.0  336.0  332.0  374.0  413.0  336.0  449.0  357.0  385.0  396.0  387.0  403.0  416.0  366.0  410.0  380.0  391.0  403.0  403.0  319.0  0.1728481455563331   1,729 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827152
2    0.908428
3    0.939318
4    0.956313
5    0.968909
6    0.977807
7    0.982405
8    0.985904
9    0.988503
10   0.990703

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1730394385834323
RMSE: 0.4159800939749789
LogLoss: 0.5810277460119311
Mean Per-Class Error: 0.17819323012335103
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17    18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0   1.0    0.0   1.0   1.0   2.0    0.0   0.10112359550561797  9 / 89
0.0   85.0   0.0   1.0    2.0   0.0   1.0   3.0   0.0   0.0    1.0    0.0   1.0    0.0   0.0   0.0    0.0   7.0   2.0    0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    64.0  0.0    4.0   0.0   3.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0   2.0    2.0   0.0    0.0   1.0   0.0   0.0    0.0   0.21951219512195122  18 / 82
2.0   1.0    0.0   92.0   0.0   0.0   0.0   7.0   0.0   1.0    0.0    0.0   3.0    1.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0   0.0    2.0   0.17857142857142858  20 / 112
0.0   0.0    0.0   0.0    73.0  3.0   5.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   0.0   0.0    1.0   1.0   4.0    0.0   0.0    0.0   0.0   0.0   0.0    6.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   2.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    3.0   0.0   1.0   2.0   0.0   1.0    4.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   2.0    0.0   0.0    0.0   0.0   82.0  2.0    0.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   2.0    3.0   0.0   0.0    0.0   2.0    3.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0    1.0   0.0    0.0   0.0   0.0    1.0   0.0   11.0   1.0   0.0    0.0   0.0   0.0   0.0    65.0  0.25287356321839083  22 / 87
95.0  120.0  72.0  110.0  93.0  91.0  80.0  89.0  76.0  110.0  105.0  89.0  103.0  97.0  76.0  111.0  98.0  96.0  110.0  83.0  108.0  85.0  98.0  99.0  117.0  79.0  0.17670682730923695  440 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.823293
2    0.907631
3    0.939357
4    0.95502
5    0.969478
6    0.977912
7    0.981928
8    0.985542
9    0.987149
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:02  3 min  0.339 sec  45694 obs/sec     1         1             10007      0.551374         0.989831            0.994597       0.268919                         0.548251           0.975051              0.994644         0.269076
    2019-08-04 09:03:04  3 min  2.210 sec  48719 obs/sec     10        10            100070     0.412247         0.568938            0.99698        0.172848                         0.41598            0.581028              0.996917         0.176707
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0878803
C15         0.989746               0.989746             0.0869792
C12         0.855989               0.855989             0.0752246
C9          0.851523               0.851523             0.0748321
C8          0.762179               0.762179             0.0669805
C7          0.76152                0.76152              0.0669227
C11         0.730302               0.730302             0.0641791
C10         0.702442               0.702442             0.0617309
C14         0.689707               0.689707             0.0606117
C6          0.653613               0.653613             0.0574397
C16         0.64263                0.64263              0.0564745
C3          0.63071                0.63071              0.055427
C5          0.607822               0.607822             0.0534156
C4          0.545268               0.545268             0.0479183
C1          0.483773               0.483773             0.0425141
C2          0.471888               0.471888             0.0414696
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_80

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017242256442955295  0.00042820756789296865  0.0         0.010644267876980251   0.45861637592315674  0.06617318100622817   0.510761022567749
    3        26       Softmax                 0.0   0.0   0.002284707363427375   0.0006972425617277622   0.0         -0.010394913500820079  0.4101734161376953   -0.48475135225260735  0.19664287567138672


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16706520211642534
RMSE: 0.40873610327009935
LogLoss: 0.5684931402847847
Mean Per-Class Error: 0.1668396894637545
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    4.0    0.0    1.0    0.0    0.0    3.0    3.0    3.0    3.0    3.0    1.0    1.0    7.0    0.0    0.08860759493670886  35 / 395
0.0    323.0  0.0    8.0    3.0    0.0    0.0    8.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    4.0    0.0    21.0   9.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.1566579634464752   60 / 383
0.0    0.0    307.0  0.0    11.0   0.0    7.0    1.0    0.0    0.0    18.0   2.0    0.0    0.0    7.0    1.0    0.0    0.0    3.0    2.0    6.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
1.0    17.0   0.0    344.0  0.0    2.0    0.0    3.0    0.0    2.0    1.0    0.0    4.0    6.0    5.0    1.0    0.0    10.0   1.0    1.0    0.0    0.0    0.0    3.0    0.0    2.0    0.14640198511166252  59 / 403
0.0    1.0    3.0    0.0    315.0  5.0    7.0    2.0    1.0    0.0    4.0    1.0    0.0    0.0    0.0    1.0    9.0    3.0    12.0   4.0    0.0    0.0    0.0    6.0    0.0    10.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    18.0   0.0    2.0    0.0    1.0    4.0    0.0    0.0    2.0    1.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    2.0    0.0    7.0    6.0    1.0    0.0    1.0    2.0    0.0    8.0    1.0    0.0    0.0    2.0    0.0    4.0    0.0    6.0    2.0    2.0    0.0    0.0    343.0  3.0    4.0    0.12944162436548223  51 / 394
1.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    5.0    0.0    2.0    22.0   3.0    22.0   1.0    2.0    324.0  0.0    0.17557251908396945  69 / 393
1.0    0.0    0.0    1.0    18.0   1.0    0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    8.0    0.0    25.0   2.0    0.0    0.0    0.0    4.0    0.0    302.0  0.1771117166212534   65 / 367
392.0  439.0  343.0  437.0  394.0  347.0  310.0  324.0  333.0  343.0  384.0  356.0  436.0  371.0  398.0  434.0  372.0  463.0  422.0  410.0  402.0  377.0  397.0  412.0  361.0  346.0  0.16595021493551934  1,660 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83405
2    0.910327
3    0.942617
4    0.958812
5    0.969209
6    0.976407
7    0.981606
8    0.985204
9    0.988104
10   0.991603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1707285906308533
RMSE: 0.4131931638239593
LogLoss: 0.5834162637591863
Mean Per-Class Error: 0.16852911096354964
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    2.0   0.0   0.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   85.0   0.0   1.0    2.0   0.0   0.0   3.0   1.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    0.0   8.0    1.0    0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    64.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    4.0   1.0    0.0   0.0    1.0    1.0   1.0    0.0   1.0   0.0    0.0    0.0   0.21951219512195122  18 / 82
1.0   2.0    0.0   98.0   0.0   1.0   0.0   3.0   0.0   0.0   1.0   0.0   1.0   3.0    0.0   1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0    0.0    0.0   0.125                14 / 112
0.0   0.0    1.0   0.0    73.0  3.0   1.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    4.0    2.0   0.0    0.0   0.0   2.0    0.0    5.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   1.0    0.0   0.0   85.0   2.0    2.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    3.0   0.0    0.0    6.0   1.0    5.0   1.0   0.0    90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0    1.0   0.0    3.0    0.0   0.0    0.0   0.0   1.0    0.0    74.0  0.14942528735632185  13 / 87
93.0  108.0  67.0  125.0  91.0  78.0  77.0  80.0  79.0  98.0  96.0  96.0  96.0  104.0  84.0  123.0  96.0  117.0  104.0  97.0  100.0  85.0  98.0  100.0  108.0  90.0  0.1674698795180723   417 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83253
2    0.909639
3    0.944177
4    0.957028
5    0.969076
6    0.9751
7    0.980723
8    0.984739
9    0.989157
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:14  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:14  2 min 12.124 sec  43698 obs/sec     1         1             10007      0.550783         0.996093            0.994611       0.270019                         0.549316           0.993699              0.994623         0.270281
    2019-08-04 09:02:16  2 min 14.127 sec  45569 obs/sec     10        10            100070     0.408736         0.568493            0.997032       0.16595                          0.413193           0.583416              0.996958         0.16747
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0879095
C13         0.931213               0.931213             0.0818624
C9          0.843878               0.843878             0.0741849
C12         0.838891               0.838891             0.0737464
C7          0.800448               0.800448             0.0703669
C8          0.770199               0.770199             0.0677077
C11         0.747635               0.747635             0.0657242
C10         0.721596               0.721596             0.0634351
C14         0.680616               0.680616             0.0598326
C5          0.645519               0.645519             0.0567473
C6          0.642656               0.642656             0.0564955
C3          0.624375               0.624375             0.0548884
C16         0.616035               0.616035             0.0541553
C4          0.554904               0.554904             0.0487813
C1          0.48567                0.48567              0.042695
C2          0.471707               0.471707             0.0414675
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_140

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009984425425102472  0.00024296646006405354  0.0         -0.019695515733445745  0.24005430936813354  0.24356896895079622  0.2003994584083557
    3        26       Softmax                      0.0   0.0   0.0072533825646132755  0.03309950232505798     0.0         -0.27499915331839897   0.7010407447814941   -0.501321243260329   0.2191210389137268


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17751061052313843
RMSE: 0.42132008084488265
LogLoss: 0.5805861099950014
Mean Per-Class Error: 0.16887002228238934
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    5.0    2.0    1.0    0.0    1.0    0.0    0.0    1.0    4.0    1.0    2.0    1.0    3.0    3.0    5.0    0.0    0.08607594936708861   34 / 395
1.0    330.0  0.0    0.0    3.0    0.0    3.0    8.0    2.0    1.0    1.0    0.0    0.0    1.0    3.0    7.0    2.0    10.0   3.0    1.0    0.0    3.0    1.0    1.0    2.0    0.0    0.13838120104438642   53 / 383
0.0    0.0    306.0  0.0    6.0    1.0    10.0   1.0    0.0    0.0    18.0   0.0    0.0    0.0    9.0    0.0    2.0    1.0    4.0    2.0    2.0    1.0    5.0    0.0    0.0    0.0    0.16847826086956522   62 / 368
3.0    21.0   0.0    324.0  0.0    1.0    1.0    6.0    0.0    6.0    0.0    0.0    6.0    2.0    7.0    1.0    0.0    11.0   1.0    1.0    1.0    0.0    0.0    4.0    0.0    7.0    0.19602977667493796   79 / 403
0.0    5.0    5.0    0.0    299.0  2.0    12.0   0.0    0.0    0.0    5.0    2.0    0.0    0.0    1.0    0.0    8.0    3.0    20.0   4.0    1.0    0.0    0.0    8.0    0.0    9.0    0.22135416666666666   85 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    14.0   2.0    6.0    0.0    1.0    2.0    0.0    0.0    1.0    4.0    337.0  0.0    0.0    0.0    0.10372340425531915   39 / 376
0.0    2.0    0.0    2.0    3.0    0.0    0.0    1.0    3.0    7.0    5.0    3.0    0.0    0.0    0.0    0.0    7.0    1.0    0.0    3.0    2.0    0.0    0.0    348.0  5.0    2.0    0.116751269035533     46 / 394
0.0    1.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    3.0    0.0    2.0    2.0    1.0    6.0    0.0    0.0    368.0  1.0    0.061224489795918366  24 / 392
2.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    15.0   0.0    3.0    0.0    0.0    0.0    0.0    4.0    0.0    15.0   3.0    0.0    0.0    0.0    1.0    0.0    309.0  0.15803814713896458   58 / 367
418.0  459.0  354.0  359.0  376.0  351.0  354.0  327.0  341.0  383.0  355.0  346.0  402.0  392.0  424.0  375.0  399.0  443.0  357.0  371.0  401.0  377.0  400.0  437.0  432.0  370.0  0.16804958512446266   1,681 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83195
2    0.905328
3    0.935619
4    0.954214
5    0.96691
6    0.974108
7    0.980306
8    0.985804
9    0.988503
10   0.992602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1788364432797511
RMSE: 0.4228905807413439
LogLoss: 0.5841319128253877
Mean Per-Class Error: 0.16706331879204514
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0   1.0   0.0   2.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   85.0   0.0   0.0    1.0   0.0   2.0   3.0   1.0   0.0    1.0   0.0   0.0   1.0    1.0   3.0    0.0    3.0    1.0   0.0   0.0   2.0   1.0   1.0    0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    66.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    1.0    0.0    2.0   1.0   0.0   1.0   1.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
2.0   2.0    0.0   93.0   0.0   0.0   0.0   2.0   0.0   1.0    0.0   0.0   3.0   1.0    2.0   0.0    0.0    1.0    0.0   0.0   1.0   0.0   0.0   2.0    0.0    2.0   0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    73.0  2.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    3.0    1.0    6.0   2.0   0.0   0.0   0.0   2.0    0.0    3.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0   0.0    2.0   0.0    0.0    0.0    0.0   0.0   0.0   1.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   1.0    0.0   1.0    1.0   0.0   0.0   0.0   0.0   1.0    2.0   2.0   0.0   0.0    0.0   0.0    1.0    1.0    0.0   0.0   0.0   0.0   0.0   89.0   1.0    0.0   0.11                 11 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    1.0    0.0    0.0   0.0   0.0   1.0   0.0   0.0    102.0  0.0   0.04672897196261682  5 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0   1.0   0.0   0.0   0.0   0.0    0.0    73.0  0.16091954022988506  14 / 87
99.0  114.0  72.0  101.0  93.0  77.0  85.0  80.0  83.0  108.0  86.0  94.0  90.0  105.0  94.0  107.0  105.0  110.0  94.0  88.0  99.0  86.0  96.0  113.0  124.0  87.0  0.16586345381526105  413 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.834137
2    0.906024
3    0.935743
4    0.951406
5    0.966667
6    0.974297
7    0.977912
8    0.985141
9    0.988353
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:51  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:51  3 min 49.577 sec  97155 obs/sec     1         1             10007      0.59517          1.11886             0.993705       0.290413                         0.593296           1.10362               0.993728         0.292771
    2019-08-04 09:03:52  3 min 50.402 sec  109967 obs/sec    10        10            100070     0.42132          0.580586            0.996845       0.16805                          0.422891           0.584132              0.996813         0.165863
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.100065
C13         0.878853               0.878853             0.0879427
C12         0.741984               0.741984             0.0742468
C8          0.711352               0.711352             0.0711816
C7          0.706876               0.706876             0.0707338
C11         0.688016               0.688016             0.0688466
C9          0.675019               0.675019             0.067546
C5          0.674214               0.674214             0.0674655
C6          0.60034                0.60034              0.0600732
C14         0.546723               0.546723             0.054708
C10         0.541861               0.541861             0.0542215
C4          0.526304               0.526304             0.0526648
C3          0.478703               0.478703             0.0479016
C16         0.464313               0.464313             0.0464617
C2          0.394891               0.394891             0.0395149
C1          0.364021               0.364021             0.0364259
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_230

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0014934423911086014  0.0004105278057977557  0.0         0.00565422802918647    0.4467132091522217  0.04996849798176575  0.5187325477600098
    3        26       Softmax                 0.0   0.0   0.0025181467209012434  0.0008544272277504206  0.0         -0.028347996031173422  0.5566577911376953  -0.5209443047876207  0.15015071630477905


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.172647733367588
RMSE: 0.41550900515823724
LogLoss: 0.5740463717626485
Mean Per-Class Error: 0.16747550163021163
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    6.0    5.0    2.0    7.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    3.0    1.0    1.0    1.0    3.0    3.0    0.09873417721518987  39 / 395
0.0    317.0  0.0    3.0    4.0    0.0    2.0    9.0    2.0    0.0    2.0    0.0    2.0    0.0    1.0    0.0    5.0    15.0   12.0   2.0    0.0    2.0    0.0    3.0    1.0    1.0    0.17232375979112272  66 / 383
0.0    0.0    304.0  0.0    15.0   2.0    13.0   0.0    0.0    0.0    10.0   0.0    0.0    0.0    6.0    1.0    1.0    0.0    7.0    1.0    6.0    0.0    2.0    0.0    0.0    0.0    0.17391304347826086  64 / 368
5.0    19.0   0.0    328.0  0.0    0.0    0.0    8.0    2.0    2.0    5.0    0.0    4.0    5.0    4.0    3.0    1.0    2.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    11.0   0.18610421836228289  75 / 403
0.0    4.0    2.0    0.0    310.0  7.0    8.0    3.0    1.0    0.0    7.0    3.0    0.0    0.0    0.0    1.0    10.0   1.0    12.0   6.0    0.0    0.0    0.0    2.0    0.0    7.0    0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    0.0    0.0    3.0    3.0    3.0    0.0    9.0    3.0    1.0    8.0    1.0    0.0    0.0    2.0    0.0    0.0    6.0    3.0    3.0    1.0    0.0    0.0    343.0  1.0    4.0    0.12944162436548223  51 / 394
0.0    1.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    0.0    4.0    13.0   4.0    14.0   1.0    2.0    343.0  0.0    0.1272264631043257   50 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    24.0   6.0    0.0    0.0    0.0    0.0    0.0    300.0  0.18032786885245902  66 / 366
398.0  425.0  336.0  410.0  400.0  408.0  366.0  361.0  340.0  385.0  400.0  348.0  424.0  384.0  412.0  381.0  358.0  386.0  361.0  404.0  403.0  368.0  395.0  403.0  372.0  375.0  0.16665000499850044  1,667 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83335
2    0.910827
3    0.941617
4    0.957813
5    0.968809
6    0.976307
7    0.981006
8    0.985004
9    0.989303
10   0.990903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17550115589872808
RMSE: 0.4189285809045834
LogLoss: 0.5851475792939757
Mean Per-Class Error: 0.16958892979416487
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17    18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   1.0    0.0   1.0    1.0    2.0    0.0   0.10112359550561797   9 / 89
0.0   82.0   0.0   1.0    3.0   0.0   2.0   4.0   1.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0    2.0   3.0   2.0   0.0   0.0    2.0   0.0    1.0    0.0    1.0   0.22641509433962265   24 / 106
0.0   0.0    65.0  0.0    4.0   0.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   3.0   1.0   1.0    0.0   0.0    0.0    0.0    0.0   0.2073170731707317    17 / 82
3.0   2.0    0.0   90.0   0.0   0.0   0.0   3.0   1.0   0.0    0.0   0.0   2.0   2.0    1.0   2.0    1.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0    3.0   0.19642857142857142   22 / 112
0.0   0.0    0.0   0.0    76.0  4.0   3.0   1.0   0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    2.0   0.0   4.0   1.0   0.0    0.0   0.0    1.0    0.0    2.0   0.21649484536082475   21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   1.0   0.0   2.0   1.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    0.0   2.0   1.0   0.0   0.0    0.0   0.0    84.0   0.0    2.0   0.16                  16 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0   2.0   1.0    4.0   1.0    2.0    94.0   0.0   0.12149532710280374   13 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   6.0   2.0   0.0    0.0   0.0    0.0    0.0    71.0  0.1839080459770115    16 / 87
93.0  105.0  71.0  113.0  99.0  95.0  88.0  99.0  85.0  110.0  93.0  89.0  95.0  100.0  84.0  111.0  96.0  94.0  95.0  92.0  102.0  84.0  100.0  100.0  104.0  93.0  0.16907630522088354   421 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830924
2    0.906426
3    0.938153
4    0.953012
5    0.966667
6    0.973896
7    0.980321
8    0.984337
9    0.988755
10   0.990763
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:45  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:45  6 min 43.493 sec  75810 obs/sec     1         1             10007      0.58743          1.08104             0.993867       0.284015                         0.587245           1.07855               0.993855         0.283936
    2019-08-04 09:06:46  6 min 44.652 sec  78671 obs/sec     10        10            100070     0.415509         0.574046            0.996932       0.16665                          0.418929           0.585148              0.996873         0.169076
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0955595
C15         0.979068               0.979068             0.0935593
C12         0.839988               0.839988             0.0802689
C9          0.828015               0.828015             0.0791247
C8          0.803844               0.803844             0.076815
C7          0.712119               0.712119             0.0680498
C11         0.705074               0.705074             0.0673766
C10         0.613979               0.613979             0.0586716
C14         0.604914               0.604914             0.0578053
C16         0.590406               0.590406             0.056419
C6          0.559747               0.559747             0.0534892
C5          0.55698                0.55698              0.0532248
C3          0.474324               0.474324             0.0453262
C4          0.471654               0.471654             0.045071
C1          0.377669               0.377669             0.0360899
C2          0.346897               0.346897             0.0331494
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_235

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate            rate_rms              momentum    mean_weight          weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  -------------------  --------------------  ----------  -------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.00171620366356251  0.000409215921536088  0.0         -0.0092751667164519  0.17777866125106812  0.1447702256078734   0.12081336975097656
    3        26       Softmax                      0.0   0.0   0.00838194262890878  0.029044486582279205  0.0         -0.1873619886555815  0.401763916015625    -0.9323380812829247  0.2733738422393799


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.18124654418585903
RMSE: 0.4257306004809368
LogLoss: 0.5773843515977488
Mean Per-Class Error: 0.16376436355563995
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    5.0    2.0    2.0    0.0    4.0    0.0    0.0    1.0    5.0    0.0    3.0    1.0    1.0    2.0    4.0    1.0    0.09367088607594937  37 / 395
0.0    326.0  0.0    6.0    3.0    0.0    1.0    8.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    3.0    16.0   9.0    0.0    0.0    2.0    0.0    1.0    2.0    0.0    0.14659685863874344  56 / 382
0.0    0.0    298.0  0.0    12.0   0.0    12.0   1.0    0.0    0.0    23.0   1.0    0.0    0.0    7.0    0.0    2.0    0.0    4.0    3.0    3.0    0.0    2.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
2.0    16.0   0.0    349.0  0.0    1.0    0.0    4.0    0.0    4.0    2.0    0.0    7.0    4.0    2.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.13399503722084366  54 / 403
0.0    6.0    0.0    0.0    318.0  4.0    19.0   1.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    3.0    3.0    9.0    1.0    1.0    0.0    0.0    2.0    0.0    10.0   0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    18.0   1.0    2.0    0.0    0.0    2.0    0.0    0.0    4.0    2.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    2.0    0.0    5.0    8.0    0.0    0.0    1.0    2.0    2.0    9.0    1.0    0.0    0.0    2.0    0.0    4.0    1.0    2.0    2.0    1.0    0.0    0.0    345.0  3.0    4.0    0.12436548223350254  49 / 394
1.0    0.0    0.0    2.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    6.0    0.0    2.0    10.0   1.0    25.0   0.0    0.0    334.0  0.0    0.15012722646310434  59 / 393
0.0    0.0    0.0    0.0    19.0   0.0    0.0    0.0    0.0    19.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    27.0   3.0    0.0    0.0    0.0    0.0    0.0    296.0  0.19346049046321526  71 / 367
401.0  452.0  339.0  432.0  419.0  378.0  340.0  344.0  338.0  370.0  392.0  369.0  415.0  388.0  399.0  384.0  338.0  434.0  417.0  357.0  398.0  397.0  386.0  405.0  373.0  338.0  0.16295111466560033  1,630 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837049
2    0.910927
3    0.940418
4    0.957013
5    0.970109
6    0.978506
7    0.983905
8    0.988104
9    0.991103
10   0.993502

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18424151039713965
RMSE: 0.4292336314842299
LogLoss: 0.5862887430881131
Mean Per-Class Error: 0.16651900328318486
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20     21    22    23    24    25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  ----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   1.0    1.0   0.0   0.0   2.0   0.0   0.06741573033707865  6 / 89
0.0   82.0   0.0   1.0    2.0    0.0   1.0   4.0   1.0   0.0    0.0    0.0   0.0   0.0    1.0   1.0    1.0   6.0    3.0    0.0   0.0    2.0   0.0   1.0   0.0   0.0   0.22641509433962265  24 / 106
0.0   0.0    62.0  0.0    2.0    0.0   5.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0    2.0   1.0    0.0   1.0   0.0   0.0   0.0   0.24390243902439024  20 / 82
2.0   3.0    0.0   95.0   0.0    0.0   0.0   2.0   0.0   2.0    1.0    0.0   3.0   1.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    79.0   1.0   7.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0    1.0   0.0    0.0   0.0   1.0   0.0   3.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   1.0    1.0   85.0  0.0   0.0   0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    4.0    0.0   0.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   86.0  1.0   2.0   0.14                 14 / 100
1.0   0.0    0.0   0.0    0.0    3.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   1.0    0.0   1.0    3.0   0.0    0.0    2.0   0.0    9.0   0.0   0.0   87.0  0.0   0.18691588785046728  20 / 107
0.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   5.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    5.0    1.0   0.0    0.0   0.0   0.0   0.0   70.0  0.19540229885057472  17 / 87
98.0  107.0  71.0  115.0  102.0  89.0  88.0  84.0  80.0  111.0  100.0  95.0  93.0  102.0  81.0  108.0  88.0  109.0  107.0  87.0  101.0  96.0  96.0  99.0  99.0  84.0  0.16586345381526105  413 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.834137
2    0.914056
3    0.94257
4    0.958634
5    0.969076
6    0.979116
7    0.985944
8    0.988755
9    0.990361
10   0.992369
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:55  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:55  6 min 53.428 sec  42582 obs/sec     1         1             10007      0.595658         1.09331             0.993694       0.285214                         0.595173           1.0965                0.993688         0.283534
    2019-08-04 09:06:57  6 min 55.165 sec  52146 obs/sec     10        10            100070     0.425731         0.577384            0.996779       0.162951                         0.429234           0.586289              0.996717         0.165863
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0871405
C13         0.923772               0.923772             0.080498
C9          0.881427               0.881427             0.076808
C12         0.835418               0.835418             0.0727988
C8          0.825785               0.825785             0.0719593
C7          0.815154               0.815154             0.0710329
C11         0.758161               0.758161             0.0660666
C5          0.702725               0.702725             0.0612359
C14         0.681352               0.681352             0.0593734
C6          0.676893               0.676893             0.0589848
C10         0.660753               0.660753             0.0575784
C3          0.60655                0.60655              0.0528551
C4          0.605946               0.605946             0.0528025
C16         0.578372               0.578372             0.0503996
C2          0.479903               0.479903             0.041819
C1          0.443505               0.443505             0.0386473
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_48

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias           bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0010071620899054778  0.0002626371569931507  0.0         -0.010276150287069186  0.23678630590438843  0.2705023985115875  0.20405268669128418
    3        26       Softmax                      0.0   0.0   0.006438892954555251   0.02819761633872986    0.0         -0.2705629160890777    0.7185468673706055   -0.481285196424168  0.19096386432647705


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1742990572684113
RMSE: 0.41749138586132684
LogLoss: 0.5765425726693517
Mean Per-Class Error: 0.16668531285645294
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    4.0    1.0    6.0    0.0    2.0    0.0    0.0    2.0    6.0    1.0    3.0    0.0    1.0    1.0    4.0    0.0    0.09620253164556962  38 / 395
0.0    341.0  0.0    5.0    4.0    0.0    1.0    1.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    20.0   4.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.10966057441253264  42 / 383
0.0    0.0    306.0  1.0    15.0   0.0    6.0    1.0    0.0    0.0    19.0   0.0    1.0    0.0    9.0    0.0    1.0    0.0    0.0    1.0    6.0    0.0    2.0    0.0    0.0    0.0    0.16847826086956522  62 / 368
1.0    18.0   0.0    337.0  0.0    0.0    0.0    4.0    0.0    3.0    0.0    1.0    6.0    3.0    3.0    3.0    1.0    11.0   0.0    0.0    3.0    0.0    0.0    3.0    0.0    6.0    0.16377171215880892  66 / 403
0.0    8.0    3.0    0.0    321.0  2.0    15.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    11.0   1.0    1.0    0.0    0.0    3.0    1.0    6.0    0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    12.0   1.0    3.0    0.0    0.0    3.0    0.0    0.0    3.0    1.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    3.0    0.0    3.0    7.0    0.0    2.0    1.0    2.0    2.0    7.0    0.0    0.0    0.0    2.0    1.0    5.0    1.0    3.0    2.0    1.0    0.0    0.0    347.0  2.0    3.0    0.11928934010152284  47 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    3.0    14.0   0.0    17.0   1.0    0.0    340.0  0.0    0.1326530612244898   52 / 392
2.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    6.0    1.0    29.0   2.0    0.0    0.0    0.0    2.0    0.0    303.0  0.17438692098092642  64 / 367
397.0  512.0  358.0  407.0  439.0  356.0  338.0  302.0  345.0  358.0  376.0  360.0  433.0  379.0  389.0  386.0  357.0  450.0  372.0  350.0  405.0  390.0  396.0  414.0  394.0  340.0  0.16595021493551934  1,660 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83405
2    0.910127
3    0.938518
4    0.955313
5    0.968709
6    0.976007
7    0.981306
8    0.985404
9    0.988703
10   0.991103

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17565894550473435
RMSE: 0.4191168637799419
LogLoss: 0.5875184879929278
Mean Per-Class Error: 0.16672735057925475
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   87.0   0.0   1.0    2.0    0.0   1.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   10.0   1.0   0.0   0.0    2.0   0.0    1.0    0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    65.0  0.0    3.0    0.0   3.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0    0.0   1.0   2.0    0.0   1.0    0.0    0.0    0.0   0.2073170731707317   17 / 82
0.0   2.0    0.0   96.0   0.0    0.0   0.0   1.0   0.0   1.0    0.0   0.0   2.0   2.0   1.0   2.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    1.0   0.14285714285714285  16 / 112
0.0   2.0    0.0   0.0    82.0   1.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    4.0   0.0   0.0    0.0   0.0    1.0    0.0    2.0   0.15463917525773196  15 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   1.0    0.0   2.0    3.0    0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    1.0   0.0   0.0    0.0   0.0    85.0   0.0    2.0   0.15                 15 / 100
0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    2.0   0.0    0.0   3.0   0.0    5.0   1.0    0.0    93.0   0.0   0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0   0.0   0.0    0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
95.0  128.0  75.0  115.0  104.0  80.0  86.0  73.0  82.0  106.0  91.0  94.0  97.0  98.0  79.0  112.0  96.0  112.0  92.0  79.0  102.0  91.0  100.0  101.0  112.0  90.0  0.16546184738955824  412 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.834538
2    0.914458
3    0.934538
4    0.954619
5    0.966667
6    0.973092
7    0.978715
8    0.983133
9    0.987149
10   0.990361
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:26  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:26  1 min 24.710 sec  97155 obs/sec     1         1             10007      0.598748         1.13913             0.993629       0.303809                         0.598222           1.13198               0.993623         0.302008
    2019-08-04 09:01:27  1 min 25.544 sec  108890 obs/sec    10        10            100070     0.417491         0.576543            0.996902       0.16595                          0.419117           0.587518              0.99687          0.165462
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0891947
C13         0.984763               0.984763             0.0878357
C9          0.893046               0.893046             0.079655
C8          0.838099               0.838099             0.074754
C7          0.811092               0.811092             0.0723451
C12         0.779648               0.779648             0.0695405
C11         0.703388               0.703388             0.0627385
C5          0.689487               0.689487             0.0614985
C10         0.684481               0.684481             0.0610521
C6          0.614171               0.614171             0.0547808
C14         0.601906               0.601906             0.0536868
C4          0.576473               0.576473             0.0514183
C3          0.568505               0.568505             0.0507077
C16         0.553462               0.553462             0.0493659
C1          0.483042               0.483042             0.0430847
C2          0.429867               0.429867             0.0383419
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_32

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0010064833882950097  0.0002853110199794173  0.0         -0.00501805473817285  0.23228991031646729  0.2515756915715434   0.2108529806137085
    3        26       Softmax                      0.0   0.0   0.006250463149486817   0.01968412846326828    0.0         -0.2857892882543288   0.7120561599731445   -0.4853087304029063  0.21845513582229614


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17813055430421323
RMSE: 0.4220551555237932
LogLoss: 0.5836935807113703
Mean Per-Class Error: 0.17164791408705313
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    2.0    5.0    1.0    3.0    0.0    0.0    2.0    2.0    4.0    1.0    2.0    3.0    4.0    3.0    4.0    0.10379746835443038  41 / 395
0.0    332.0  0.0    3.0    1.0    0.0    2.0    5.0    2.0    0.0    2.0    0.0    0.0    0.0    2.0    2.0    4.0    12.0   12.0   0.0    0.0    1.0    1.0    1.0    0.0    0.0    0.13089005235602094  50 / 382
0.0    0.0    311.0  0.0    12.0   1.0    7.0    1.0    0.0    0.0    15.0   2.0    0.0    0.0    4.0    0.0    1.0    1.0    1.0    5.0    0.0    0.0    6.0    0.0    0.0    0.0    0.15258855585831063  56 / 367
1.0    23.0   0.0    346.0  0.0    1.0    0.0    3.0    0.0    0.0    1.0    0.0    7.0    2.0    3.0    1.0    0.0    5.0    1.0    3.0    1.0    0.0    1.0    4.0    0.0    0.0    0.141439205955335    57 / 403
0.0    6.0    1.0    0.0    314.0  3.0    10.0   0.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    1.0    7.0    4.0    6.0    4.0    0.0    0.0    0.0    5.0    0.0    16.0   0.18229166666666666  70 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    1.0    2.0    0.0    0.0    1.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    2.0    0.0    4.0    6.0    0.0    0.0    2.0    3.0    1.0    4.0    5.0    0.0    0.0    2.0    0.0    0.0    0.0    9.0    3.0    1.0    0.0    0.0    345.0  1.0    6.0    0.12436548223350254  49 / 394
1.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    7.0    0.0    2.0    17.0   0.0    14.0   1.0    1.0    340.0  0.0    0.13486005089058525  53 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    30.0   3.0    0.0    0.0    0.0    0.0    0.0    304.0  0.17166212534059946  63 / 367
397.0  486.0  375.0  406.0  413.0  323.0  319.0  312.0  338.0  339.0  373.0  364.0  413.0  393.0  396.0  413.0  368.0  453.0  381.0  426.0  390.0  361.0  411.0  407.0  382.0  364.0  0.17084874537638708  1,709 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.829151
2    0.907828
3    0.939018
4    0.958512
5    0.970209
6    0.977307
7    0.982305
8    0.987404
9    0.990303
10   0.992602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17936822124203936
RMSE: 0.4235188558282138
LogLoss: 0.5875421277904781
Mean Per-Class Error: 0.17161850800724657
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19     20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  -----  -----  ----  ----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0    0.0    1.0   1.0   1.0   2.0    1.0   0.10112359550561797  9 / 89
0.0   84.0   0.0   0.0    1.0   0.0   0.0   1.0   1.0   0.0    1.0   0.0   0.0   0.0    1.0   1.0    2.0   6.0    5.0    0.0    0.0    1.0   1.0   1.0   0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    66.0  0.0    3.0   0.0   4.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0    2.0    0.0    0.0   2.0   0.0   0.0    0.0   0.1951219512195122   16 / 82
1.0   4.0    0.0   96.0   0.0   1.0   0.0   2.0   0.0   0.0    1.0   0.0   3.0   1.0    0.0   1.0    0.0   0.0    0.0    0.0    0.0    0.0   0.0   2.0   0.0    0.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    73.0  2.0   3.0   0.0   0.0   0.0    1.0   2.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0    2.0    0.0    0.0   0.0   2.0   0.0    7.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---    ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0    0.0    0.0   87.0  0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    2.0   3.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0    0.0    0.0    0.0   0.0   84.0  0.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0   0.0    0.0    4.0    0.0    4.0   1.0   0.0   93.0   0.0   0.1308411214953271   14 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0    1.0    0.0    0.0   0.0   0.0   0.0    75.0  0.13793103448275862  12 / 87
90.0  114.0  81.0  112.0  93.0  71.0  85.0  82.0  81.0  103.0  95.0  98.0  92.0  102.0  80.0  117.0  98.0  114.0  104.0  103.0  100.0  81.0  98.0  96.0  108.0  92.0  0.17028112449799196  424 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.829719
2    0.905622
3    0.940161
4    0.959839
5    0.96988
6    0.97751
7    0.982329
8    0.986747
9    0.988755
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:01  59.559 sec        87780 obs/sec     1         1             10007      0.602224         1.13524             0.993554       0.304009                         0.603018           1.13494               0.993521         0.305221
    2019-08-04 09:01:02  1 min  0.395 sec  107486 obs/sec    10        10            100070     0.422055         0.583694            0.996834       0.170849                         0.423519           0.587542              0.996804         0.170281
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0950204
C13         0.895074               0.895074             0.0850503
C7          0.774815               0.774815             0.0736232
C9          0.771894               0.771894             0.0733457
C12         0.757544               0.757544             0.0719821
C8          0.730458               0.730458             0.0694084
C11         0.710583               0.710583             0.0675199
C5          0.637168               0.637168             0.0605439
C3          0.605721               0.605721             0.0575558
C6          0.58188                0.58188              0.0552905
C16         0.564846               0.564846             0.0536719
C10         0.547101               0.547101             0.0519857
C14         0.536465               0.536465             0.0509751
C4          0.493052               0.493052             0.04685
C1          0.475312               0.475312             0.0451643
C2          0.442142               0.442142             0.0420125
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_81

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.001696385289037039  0.0003954764688387513  0.0         -0.009719558049212318  0.17467308044433594  0.14101792885932246  0.11951011419296265
    3        26       Softmax                      0.0   0.0   0.008327221059473162  0.02682635188102722    0.0         -0.1836048987624985    0.4039090871810913   -0.9068015390763817  0.3341282606124878


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.18076047169741538
RMSE: 0.4251593485946362
LogLoss: 0.5794416377322623
Mean Per-Class Error: 0.16235704363985703
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    1.0    8.0    0.0    2.0    0.0    0.0    1.0    7.0    1.0    1.0    0.0    2.0    1.0    6.0    0.0    0.09113924050632911  36 / 395
0.0    337.0  0.0    6.0    3.0    0.0    1.0    7.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    4.0    11.0   4.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.12010443864229765  46 / 383
0.0    0.0    310.0  1.0    11.0   0.0    5.0    0.0    0.0    0.0    22.0   0.0    0.0    0.0    6.0    0.0    1.0    0.0    5.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.1553133514986376   57 / 367
1.0    22.0   0.0    354.0  0.0    0.0    0.0    2.0    0.0    2.0    0.0    1.0    7.0    3.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.12158808933002481  49 / 403
0.0    3.0    1.0    0.0    330.0  3.0    16.0   1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    4.0    7.0    1.0    1.0    0.0    0.0    3.0    0.0    10.0   0.13838120104438642  53 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    2.0    0.0    8.0    1.0    1.0    0.0    0.0    2.0    0.0    0.0    5.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    2.0    0.0    5.0    5.0    0.0    0.0    3.0    2.0    2.0    4.0    1.0    0.0    0.0    2.0    0.0    3.0    2.0    1.0    2.0    1.0    0.0    0.0    351.0  4.0    4.0    0.10913705583756345  43 / 394
1.0    1.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    20.0   3.0    14.0   1.0    0.0    339.0  0.0    0.13740458015267176  54 / 393
0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    22.0   3.0    0.0    0.0    0.0    1.0    0.0    305.0  0.16893732970027248  62 / 367
399.0  502.0  362.0  442.0  428.0  361.0  319.0  331.0  331.0  362.0  383.0  362.0  410.0  381.0  391.0  396.0  340.0  419.0  369.0  387.0  406.0  361.0  407.0  415.0  386.0  353.0  0.1615515345396381   1,616 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838448
2    0.910427
3    0.941018
4    0.956813
5    0.969109
6    0.976607
7    0.982705
8    0.987304
9    0.990803
10   0.993102

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1837370836227163
RMSE: 0.42864563875387357
LogLoss: 0.5886506940561727
Mean Per-Class Error: 0.1657330738089013
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   86.0   0.0   0.0    2.0    0.0   1.0   2.0   1.0   0.0    0.0    0.0   0.0   0.0    1.0   1.0    1.0   7.0    1.0   0.0   0.0    2.0   0.0    1.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    67.0  0.0    3.0    0.0   1.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.18292682926829268  15 / 82
1.0   4.0    0.0   98.0   0.0    0.0   0.0   1.0   0.0   0.0    0.0    1.0   3.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    1.0   0.125                14 / 112
0.0   0.0    0.0   0.0    82.0   2.0   5.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0   0.0   0.0    0.0   0.0    1.0    0.0    3.0   0.15463917525773196  15 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0   2.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0   2.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    86.0   1.0    2.0   0.14                 14 / 100
1.0   1.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   5.0   0.0    5.0   1.0    0.0    90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   5.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
90.0  123.0  78.0  122.0  101.0  82.0  78.0  77.0  80.0  107.0  100.0  99.0  93.0  100.0  83.0  112.0  88.0  106.0  88.0  96.0  102.0  84.0  100.0  102.0  107.0  92.0  0.1646586345381526   410 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835341
2    0.913253
3    0.940562
4    0.957028
5    0.969478
6    0.9751
7    0.981125
8    0.986345
9    0.98996
10   0.99237
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:16  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:16  2 min 14.430 sec  41870 obs/sec     1         1             10007      0.585741         1.06647             0.993903       0.264121                         0.586003           1.06529               0.993881         0.268273
    2019-08-04 09:02:18  2 min 16.143 sec  52613 obs/sec     10        10            100070     0.425159         0.579442            0.996788       0.161552                         0.428646           0.588651              0.996726         0.164659
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0897014
C13         0.933249               0.933249             0.0837138
C8          0.816753               0.816753             0.0732639
C9          0.812017               0.812017             0.072839
C12         0.800574               0.800574             0.0718126
C7          0.772793               0.772793             0.0693206
C11         0.726512               0.726512             0.0651692
C5          0.708802               0.708802             0.0635805
C6          0.678584               0.678584             0.06087
C14         0.62266                0.62266              0.0558535
C10         0.61624                0.61624              0.0552776
C3          0.60208                0.60208              0.0540075
C4          0.590095               0.590095             0.0529324
C16         0.569571               0.569571             0.0510913
C2          0.452285               0.452285             0.0405706
C1          0.445881               0.445881             0.0399961
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_173

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0015324475497777712  0.0004467405378818512  0.0         -0.011242818189465709  0.43545353412628174  -0.020238821791750496  0.46921980381011963
    3        26       Softmax                 0.0   0.0   0.0027198324844273604  0.0014447546564042568  0.0         0.014895181037747288   0.571286678314209    -0.5265902808563138    0.16231900453567505


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17310342049635424
RMSE: 0.4160569918849511
LogLoss: 0.5812594814307125
Mean Per-Class Error: 0.16668015711677853
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    7.0    1.0    2.0    1.0    1.0    0.0    1.0    5.0    0.0    1.0    2.0    2.0    0.0    0.0    6.0    1.0    0.09367088607594937  37 / 395
0.0    314.0  0.0    8.0    4.0    1.0    0.0    15.0   2.0    0.0    1.0    0.0    1.0    0.0    0.0    4.0    0.0    22.0   4.0    0.0    0.0    3.0    0.0    3.0    1.0    0.0    0.1801566579634465   69 / 383
0.0    0.0    310.0  0.0    6.0    1.0    7.0    0.0    0.0    0.0    19.0   5.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    2.0    4.0    0.0    0.0    0.0    0.0    0.0    0.15300546448087432  56 / 366
1.0    14.0   0.0    352.0  0.0    2.0    0.0    5.0    1.0    5.0    0.0    2.0    2.0    8.0    1.0    2.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    4.0    0.0    1.0    0.12655086848635236  51 / 403
0.0    6.0    3.0    0.0    316.0  9.0    10.0   0.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    2.0    8.0    3.0    4.0    7.0    0.0    0.0    0.0    4.0    0.0    7.0    0.17708333333333334  68 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
2.0    1.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    0.0    21.0   2.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    3.0    0.0    6.0    2.0    0.0    0.0    1.0    2.0    0.0    11.0   5.0    0.0    0.0    2.0    0.0    5.0    5.0    4.0    4.0    3.0    0.0    0.0    336.0  1.0    4.0    0.14720812182741116  58 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    11.0   0.0    2.0    15.0   1.0    19.0   1.0    0.0    333.0  0.0    0.15267175572519084  60 / 393
3.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    8.0    1.0    20.0   3.0    0.0    0.0    0.0    0.0    2.0    307.0  0.16348773841961853  60 / 367
414.0  452.0  332.0  431.0  389.0  413.0  345.0  318.0  342.0  361.0  363.0  386.0  425.0  384.0  415.0  397.0  364.0  453.0  334.0  377.0  398.0  392.0  386.0  392.0  378.0  362.0  0.16595021493551934  1,660 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83405
2    0.906128
3    0.935119
4    0.953314
5    0.96601
6    0.973908
7    0.979406
8    0.983605
9    0.987404
10   0.989303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17631088831432265
RMSE: 0.41989390125878545
LogLoss: 0.5898874628740914
Mean Per-Class Error: 0.16895712505441424
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   1.0    1.0   0.0   0.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   83.0   0.0   3.0    2.0   0.0   0.0   6.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   1.0    0.0   5.0    1.0   0.0   0.0    3.0   0.0   1.0   0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    70.0  0.0    2.0   0.0   0.0   0.0   0.0   0.0    5.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.14634146341463414  12 / 82
1.0   3.0    0.0   92.0   0.0   1.0   0.0   4.0   1.0   1.0    0.0   1.0    0.0   3.0    0.0   2.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0    0.0   0.17857142857142858  20 / 112
0.0   1.0    1.0   0.0    73.0  6.0   3.0   0.0   0.0   0.0    2.0   1.0    0.0   0.0    0.0   0.0    2.0   1.0    1.0   4.0   0.0    0.0   0.0   0.0   0.0    2.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
1.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    5.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   83.0  0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   1.0   0.0    3.0   2.0    0.0   0.0    0.0   0.0    1.0   3.0    1.0   0.0   0.0    0.0   0.0   81.0  1.0    2.0   0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   2.0    3.0   0.0    0.0   4.0   0.0    7.0   1.0   0.0   88.0   0.0   0.17757009345794392  19 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0    0.0   0.0    0.0   0.0    2.0   0.0    5.0   1.0   0.0    0.0   0.0   0.0   1.0    71.0  0.1839080459770115   16 / 87
93.0  113.0  74.0  113.0  90.0  95.0  86.0  91.0  80.0  107.0  93.0  101.0  87.0  105.0  80.0  120.0  96.0  110.0  87.0  94.0  101.0  94.0  95.0  93.0  104.0  88.0  0.16907630522088354  421 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830924
2    0.904819
3    0.935341
4    0.955422
5    0.967068
6    0.973494
7    0.980723
8    0.983936
9    0.988755
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:07  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:07  5 min  5.305 sec  78179 obs/sec     1         1             10007      0.586785         1.09502             0.99388        0.290413                         0.584039           1.08325               0.993922         0.295582
    2019-08-04 09:05:08  5 min  6.506 sec  76564 obs/sec     10        10            100070     0.416057         0.581259            0.996923       0.16595                          0.419894           0.589887              0.996858         0.169076
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0869342
C13         0.99909                0.99909              0.086855
C9          0.974192               0.974192             0.0846906
C12         0.894684               0.894684             0.0777786
C11         0.795778               0.795778             0.0691803
C8          0.784203               0.784203             0.0681741
C7          0.769724               0.769724             0.0669153
C14         0.728934               0.728934             0.0633693
C10         0.725801               0.725801             0.0630969
C6          0.6855                 0.6855               0.0595934
C16         0.650974               0.650974             0.0565918
C5          0.565803               0.565803             0.0491876
C4          0.562878               0.562878             0.0489333
C3          0.526494               0.526494             0.0457703
C1          0.430964               0.430964             0.0374655
C2          0.407939               0.407939             0.0354638
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_36

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009975717138388518  0.00024990260135382414  0.0         -0.01831418875534041  0.23667532205581665  0.23946825878291159   0.21135729551315308
    3        26       Softmax                      0.0   0.0   0.005859536121114126   0.017259329557418823    0.0         -0.3164295667446092   0.7216861248016357   -0.49818231521241996  0.23756736516952515


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1740193838645273
RMSE: 0.4171563062744315
LogLoss: 0.5758829838431471
Mean Per-Class Error: 0.16134271539781905
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  1.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    4.0    3.0    1.0    5.0    2.0    4.0    1.0    2.0    3.0    5.0    1.0    2.0    0.0    1.0    1.0    4.0    0.0    0.11139240506329114  44 / 395
0.0    332.0  0.0    6.0    1.0    2.0    2.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    16.0   13.0   0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.13315926892950392  51 / 383
0.0    0.0    318.0  0.0    3.0    2.0    1.0    0.0    0.0    0.0    20.0   3.0    0.0    0.0    4.0    0.0    2.0    0.0    8.0    1.0    0.0    0.0    6.0    0.0    0.0    0.0    0.1358695652173913   50 / 368
1.0    15.0   0.0    353.0  0.0    0.0    1.0    3.0    0.0    2.0    1.0    1.0    7.0    3.0    2.0    1.0    0.0    7.0    3.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    0.12406947890818859  50 / 403
0.0    10.0   5.0    0.0    308.0  12.0   14.0   0.0    0.0    0.0    2.0    4.0    0.0    0.0    0.0    0.0    7.0    4.0    7.0    2.0    0.0    0.0    0.0    3.0    0.0    6.0    0.19791666666666666  76 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    12.0   0.0    2.0    0.0    0.0    3.0    0.0    0.0    4.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
1.0    2.0    0.0    4.0    7.0    0.0    0.0    4.0    1.0    2.0    9.0    4.0    0.0    0.0    2.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    346.0  1.0    2.0    0.11959287531806616  47 / 393
0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    5.0    0.0    2.0    12.0   2.0    13.0   1.0    0.0    342.0  0.0    0.1297709923664122   51 / 393
2.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    2.0    36.0   2.0    0.0    0.0    0.0    2.0    0.0    297.0  0.1907356948228883   70 / 367
389.0  461.0  384.0  441.0  374.0  423.0  320.0  313.0  342.0  379.0  410.0  368.0  428.0  385.0  388.0  377.0  338.0  426.0  439.0  348.0  390.0  365.0  413.0  393.0  382.0  327.0  0.160851744476657    1,609 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839148
2    0.914726
3    0.941318
4    0.958912
5    0.969109
6    0.976107
7    0.981805
8    0.985004
9    0.988603
10   0.990503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17784231612924167
RMSE: 0.4217135474812751
LogLoss: 0.5903293643631881
Mean Per-Class Error: 0.16767520642700603
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11    12    13    14    15     16    17    18     19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0    0.0    0.0   3.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.11235955056179775  10 / 89
0.0   88.0   0.0   1.0    1.0   1.0    0.0   1.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0   5.0   4.0    0.0   0.0   1.0   0.0    1.0   1.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    69.0  0.0    1.0   0.0    0.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   2.0   0.0    1.0   0.0   3.0    1.0   0.0   0.0   2.0    0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   2.0    0.0   97.0   0.0   0.0    0.0   1.0   0.0   1.0    0.0    1.0   3.0   1.0   1.0   0.0    0.0   1.0   2.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.13392857142857142  15 / 112
0.0   1.0    0.0   0.0    72.0  5.0    4.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    3.0   1.0   4.0    1.0   0.0   0.0   0.0    1.0   0.0    4.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    1.0    0.0   2.0   0.0   0.0   0.0    0.0   1.0   0.0    0.0   2.0   0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0   0.0    0.0   2.0   0.0   1.0    3.0    3.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0   0.0    83.0  0.0    1.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    2.0   0.0   2.0   1.0    0.0   95.0   0.0   0.11214953271028037  12 / 107
2.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0   0.0   2.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   6.0    0.0   0.0   0.0   0.0    1.0   0.0    71.0  0.1839080459770115   16 / 87
93.0  116.0  83.0  125.0  87.0  100.0  79.0  80.0  79.0  106.0  104.0  97.0  98.0  99.0  76.0  111.0  91.0  98.0  114.0  81.0  98.0  79.0  101.0  94.0  116.0  85.0  0.1670682730923695   416 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.832932
2    0.91245
3    0.936546
4    0.957831
5    0.970683
6    0.976305
7    0.980321
8    0.983132
9    0.987148
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:06  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:06  1 min  4.741 sec  101080 obs/sec    1         1             10007      0.5924           1.11419             0.993764       0.285514                         0.592949           1.1169                0.993735         0.288353
    2019-08-04 09:01:07  1 min  5.570 sec  109967 obs/sec    10        10            100070     0.417156         0.575883            0.996908       0.160852                         0.421714           0.590329              0.996831         0.167068
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0841153
C13         0.920421               0.920421             0.0774215
C12         0.901401               0.901401             0.0758216
C8          0.847437               0.847437             0.0712825
C7          0.838783               0.838783             0.0705545
C11         0.764003               0.764003             0.0642643
C9          0.757071               0.757071             0.0636813
C5          0.741735               0.741735             0.0623913
C10         0.72769                0.72769              0.0612099
C6          0.725905               0.725905             0.0610597
C14         0.702615               0.702615             0.0591007
C16         0.66707                0.66707              0.0561108
C3          0.631015               0.631015             0.0530781
C4          0.608454               0.608454             0.0511803
C1          0.530406               0.530406             0.0446152
C2          0.524434               0.524434             0.0441129
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_157

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009422926467550496  0.00024926429614424706  0.0         -0.016066067514270088  0.2358461618423462  0.22895002410383372  0.19734394550323486
    3        26       Softmax                      0.0   0.0   0.0063617152797213255  0.026390574872493744    0.0         -0.3241676956695301    0.7232904434204102  -0.5060939161575324  0.2639714479446411


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17630103747576475
RMSE: 0.4198821709429501
LogLoss: 0.5814205260881693
Mean Per-Class Error: 0.16556865681622077
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    2.0    2.0    5.0    1.0    3.0    0.0    3.0    0.0    2.0    0.0    1.0    3.0    1.0    1.0    3.0    3.0    0.0810126582278481   32 / 395
0.0    332.0  0.0    11.0   1.0    1.0    0.0    5.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    10.0   14.0   0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.13315926892950392  51 / 383
0.0    0.0    314.0  0.0    9.0    0.0    10.0   0.0    0.0    0.0    17.0   0.0    1.0    1.0    7.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    3.0    0.0    0.0    0.0    0.14673913043478262  54 / 368
2.0    18.0   0.0    342.0  0.0    0.0    1.0    1.0    0.0    4.0    2.0    0.0    5.0    5.0    1.0    5.0    0.0    7.0    2.0    4.0    2.0    0.0    0.0    2.0    0.0    0.0    0.1513647642679901   61 / 403
0.0    11.0   2.0    0.0    324.0  5.0    17.0   0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    2.0    3.0    6.0    3.0    0.0    0.0    0.0    3.0    0.0    5.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    1.0    0.0    0.0    1.0    2.0    0.0    0.0    1.0    0.0    16.0   0.0    0.0    1.0    1.0    2.0    0.0    0.0    2.0    1.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    0.0    0.0    5.0    12.0   0.0    0.0    2.0    4.0    3.0    7.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    3.0    2.0    2.0    0.0    0.0    343.0  1.0    3.0    0.12944162436548223  51 / 394
1.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    2.0    19.0   2.0    13.0   2.0    0.0    342.0  1.0    0.1297709923664122   51 / 393
1.0    0.0    0.0    1.0    14.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    27.0   3.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
420.0  490.0  343.0  427.0  422.0  336.0  344.0  291.0  349.0  352.0  370.0  345.0  410.0  400.0  415.0  415.0  351.0  439.0  397.0  397.0  397.0  363.0  391.0  400.0  390.0  349.0  0.16485054483654904  1,649 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835149
2    0.908428
3    0.939018
4    0.957413
5    0.969009
6    0.977007
7    0.981905
8    0.985804
9    0.989003
10   0.992202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17942116941761582
RMSE: 0.4235813610365969
LogLoss: 0.593154453149349
Mean Per-Class Error: 0.16524194622777372
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    2.0   0.0   0.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   87.0   0.0   2.0    1.0    1.0   0.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   6.0    3.0    0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    66.0  0.0    2.0    0.0   4.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    0.0    2.0   1.0    0.0   1.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
1.0   3.0    0.0   95.0   0.0    0.0   0.0   1.0   0.0   2.0    1.0   0.0   2.0   2.0    0.0   2.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.15178571428571427  17 / 112
0.0   2.0    0.0   0.0    80.0   2.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0    2.0   0.0    0.0   0.0   2.0    0.0    1.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    1.0   1.0    0.0    0.0   1.0    0.0   86.0  0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    3.0    0.0   0.0   1.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0    0.0   0.0    0.0   0.0   86.0   0.0    1.0   0.14                 14 / 100
1.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0    6.0   0.0    4.0   2.0   0.0    90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   1.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    5.0    0.0   0.0    0.0   0.0   0.0    0.0    75.0  0.13793103448275862  12 / 87
97.0  123.0  69.0  119.0  100.0  81.0  87.0  71.0  81.0  101.0  92.0  91.0  89.0  107.0  86.0  118.0  90.0  111.0  105.0  97.0  104.0  82.0  94.0  100.0  110.0  85.0  0.1650602409638554   411 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83494
2    0.907631
3    0.938153
4    0.958233
5    0.966667
6    0.977109
7    0.982329
8    0.984739
9    0.988354
10   0.990362
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:27  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:27  4 min 25.644 sec  96221 obs/sec     1         1             10007      0.610663         1.16401             0.993375       0.29941                          0.614218           1.17412               0.993278         0.311245
    2019-08-04 09:04:28  4 min 26.488 sec  107717 obs/sec    10        10            100070     0.419882         0.581421            0.996868       0.164851                         0.423581           0.593154              0.996803         0.16506
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0883365
C13         0.90451                0.90451              0.0799012
C7          0.827503               0.827503             0.0730987
C8          0.819465               0.819465             0.0723886
C9          0.801361               0.801361             0.0707894
C12         0.790323               0.790323             0.0698144
C5          0.763332               0.763332             0.06743
C11         0.701142               0.701142             0.0619364
C10         0.662804               0.662804             0.0585498
C14         0.644152               0.644152             0.0569021
C6          0.64137                0.64137              0.0566564
C3          0.626448               0.626448             0.0553382
C16         0.594577               0.594577             0.0525229
C4          0.569024               0.569024             0.0502656
C1          0.496497               0.496497             0.0438588
C2          0.477842               0.477842             0.0422109
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_56

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0014716467092057428  0.00043456233106553555  0.0         0.014495960277344011   0.4390941858291626  0.0369686442212106   0.48085618019104004
    3        26       Softmax                 0.0   0.0   0.002565438380350735   0.0008173019159585238   0.0         -0.006142754216713142  0.5726101398468018  -0.5183983130654651  0.20217901468276978


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16944892968463715
RMSE: 0.4116417492002447
LogLoss: 0.5844664317947731
Mean Per-Class Error: 0.164318780379643
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    5.0    1.0    1.0    6.0    0.0    1.0    0.0    3.0    2.0    2.0    2.0    2.0    0.0    3.0    1.0    4.0    1.0    0.09620253164556962  38 / 395
0.0    320.0  0.0    4.0    5.0    3.0    2.0    5.0    2.0    1.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    24.0   5.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.16449086161879894  63 / 383
0.0    0.0    309.0  1.0    16.0   1.0    7.0    1.0    0.0    0.0    6.0    3.0    0.0    0.0    4.0    0.0    0.0    0.0    6.0    1.0    10.0   0.0    3.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
0.0    21.0   0.0    341.0  0.0    0.0    0.0    9.0    0.0    2.0    1.0    0.0    4.0    2.0    3.0    2.0    0.0    8.0    2.0    0.0    2.0    0.0    1.0    4.0    0.0    1.0    0.15384615384615385  62 / 403
0.0    6.0    3.0    0.0    304.0  8.0    12.0   1.0    1.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    8.0    5.0    6.0    8.0    0.0    0.0    0.0    4.0    0.0    13.0   0.206266318537859    79 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    14.0   0.0    0.0    1.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    0.0    0.0    3.0    8.0    0.0    0.0    2.0    2.0    1.0    8.0    0.0    0.0    1.0    2.0    0.0    3.0    5.0    11.0   3.0    1.0    0.0    0.0    334.0  8.0    2.0    0.15228426395939088  60 / 394
1.0    2.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    2.0    11.0   1.0    6.0    1.0    1.0    363.0  0.0    0.07633587786259542  30 / 393
0.0    1.0    0.0    0.0    13.0   1.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    23.0   6.0    0.0    0.0    0.0    0.0    0.0    304.0  0.16939890710382513  62 / 366
375.0  480.0  352.0  407.0  407.0  387.0  345.0  317.0  326.0  377.0  332.0  366.0  417.0  365.0  366.0  359.0  382.0  516.0  371.0  388.0  419.0  338.0  419.0  409.0  429.0  354.0  0.16355093471958412  1,636 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836449
2    0.910827
3    0.940918
4    0.957013
5    0.96681
6    0.972608
7    0.977707
8    0.980906
9    0.985204
10   0.988104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17255903926478225
RMSE: 0.4154022619880424
LogLoss: 0.5937963306675956
Mean Per-Class Error: 0.16470602016792102
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    1.0   2.0    0.0   0.06741573033707865   6 / 89
0.0   83.0   0.0   0.0    3.0   0.0   2.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0   1.0   1.0    1.0   9.0    1.0   0.0   0.0    2.0   0.0    2.0   0.0    0.0   0.2169811320754717    23 / 106
0.0   0.0    69.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    3.0   1.0   2.0    0.0   1.0    0.0   0.0    0.0   0.15853658536585366   13 / 82
0.0   2.0    0.0   94.0   0.0   0.0   0.0   4.0   0.0   0.0    1.0   0.0   2.0   1.0   0.0   2.0    0.0   2.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    1.0   0.16071428571428573   18 / 112
0.0   1.0    0.0   0.0    72.0  5.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    3.0   4.0   0.0    0.0   0.0    0.0   0.0    5.0   0.25773195876288657   25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    5.0   0.0   0.0   1.0   1.0   0.0    4.0   0.0   0.0   1.0   0.0   0.0    0.0   2.0    3.0   0.0   0.0    0.0   0.0    77.0  3.0    1.0   0.23                  23 / 100
0.0   2.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   1.0   0.0    3.0   1.0    0.0   98.0   0.0   0.08411214953271028   9 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   2.0   0.0    0.0   0.0    0.0   0.0    73.0  0.16091954022988506   14 / 87
88.0  124.0  76.0  107.0  92.0  88.0  90.0  84.0  79.0  109.0  85.0  93.0  89.0  96.0  75.0  107.0  92.0  132.0  92.0  91.0  109.0  77.0  108.0  98.0  119.0  90.0  0.1642570281124498    409 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835743
2    0.906827
3    0.935743
4    0.956627
5    0.966667
6    0.973896
7    0.980723
8    0.982329
9    0.986345
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:40  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:40  1 min 38.387 sec  75240 obs/sec     1         1             10007      0.582349         1.09759             0.993972       0.288813                         0.579518           1.08446               0.994016         0.290763
    2019-08-04 09:01:41  1 min 39.564 sec  77694 obs/sec     10        10            100070     0.411642         0.584466            0.996988       0.163551                         0.415402           0.593796              0.996925         0.164257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0901412
C12         0.942035               0.942035             0.0849162
C13         0.922282               0.922282             0.0831356
C9          0.862369               0.862369             0.077735
C8          0.802765               0.802765             0.0723622
C7          0.781529               0.781529             0.070448
C11         0.737915               0.737915             0.0665166
C14         0.708862               0.708862             0.0638977
C10         0.684963               0.684963             0.0617434
C6          0.664684               0.664684             0.0599154
C16         0.634776               0.634776             0.0572195
C5          0.596038               0.596038             0.0537276
C3          0.518839               0.518839             0.0467688
C1          0.434813               0.434813             0.0391946
C4          0.42527                0.42527              0.0383344
C2          0.376564               0.376564             0.033944
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_61

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017322918771185414  0.0004301422741264105  0.0         0.005847526927428959   0.47591376304626465  -0.060426413771978035  0.5109374523162842
    3        26       Softmax                 0.0   0.0   0.0021901217620464964  0.0005622978787869215  0.0         -0.002346276073403977  0.4083365201950073   -0.48914656347424246   0.18380600214004517


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1670680509975457
RMSE: 0.4087395882435976
LogLoss: 0.5736928915121607
Mean Per-Class Error: 0.16771745308907035
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    3.0    1.0    1.0    7.0    1.0    1.0    0.0    0.0    0.0    4.0    2.0    1.0    0.0    2.0    0.0    5.0    2.0    0.08354430379746836  33 / 395
0.0    326.0  0.0    6.0    2.0    2.0    1.0    17.0   1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    13.0   5.0    0.0    0.0    1.0    0.0    2.0    3.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    314.0  0.0    6.0    1.0    12.0   1.0    0.0    0.0    10.0   3.0    0.0    0.0    4.0    0.0    1.0    1.0    2.0    6.0    2.0    0.0    5.0    0.0    0.0    0.0    0.14673913043478262  54 / 368
2.0    21.0   0.0    349.0  0.0    1.0    0.0    7.0    0.0    1.0    0.0    0.0    7.0    2.0    0.0    1.0    0.0    3.0    2.0    1.0    1.0    0.0    0.0    3.0    0.0    1.0    0.1318407960199005   53 / 402
0.0    15.0   4.0    0.0    303.0  5.0    10.0   3.0    1.0    0.0    6.0    1.0    0.0    0.0    0.0    1.0    9.0    3.0    4.0    3.0    0.0    0.0    0.0    1.0    0.0    15.0   0.2109375            81 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    12.0   0.0    3.0    0.0    0.0    2.0    0.0    0.0    1.0    1.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    4.0    0.0    6.0    5.0    1.0    0.0    4.0    2.0    0.0    14.0   0.0    0.0    0.0    2.0    0.0    5.0    1.0    5.0    1.0    1.0    0.0    0.0    332.0  5.0    6.0    0.15736040609137056  62 / 394
1.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    2.0    5.0    0.0    2.0    14.0   1.0    13.0   3.0    1.0    345.0  0.0    0.12213740458015267  48 / 393
1.0    1.0    0.0    0.0    13.0   1.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    21.0   4.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
409.0  531.0  353.0  426.0  378.0  371.0  349.0  344.0  331.0  360.0  357.0  340.0  421.0  378.0  391.0  395.0  359.0  418.0  379.0  379.0  399.0  361.0  426.0  375.0  407.0  366.0  0.16694991502549236  1,670 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83305
2    0.907128
3    0.940718
4    0.958412
5    0.96831
6    0.974708
7    0.979806
8    0.983505
9    0.986704
10   0.988803

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17296899446865324
RMSE: 0.4158954128968643
LogLoss: 0.5978354134769435
Mean Per-Class Error: 0.17517742971040834
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   83.0   0.0   2.0    2.0   1.0   1.0   7.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    1.0   3.0    1.0   0.0   0.0    1.0   0.0    1.0   1.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    67.0  0.0    1.0   0.0   1.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    3.0   0.0    1.0   0.0    1.0   3.0   0.0    0.0   2.0    0.0   0.0    0.0   0.18292682926829268  15 / 82
1.0   3.0    0.0   97.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   3.0   1.0    0.0   1.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.13392857142857142  15 / 112
0.0   4.0    1.0   0.0    72.0  3.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    6.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   4.0    2.0   0.0   0.0   3.0   0.0   0.0    5.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0   0.0   0.0    0.0   0.0    79.0  2.0    2.0   0.21                 21 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0   0.0    0.0   3.0   1.0    3.0   2.0    0.0   92.0   0.0   0.14018691588785046  15 / 107
0.0   1.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   1.0   0.0    0.0   0.0    0.0   0.0    76.0  0.12643678160919541  11 / 87
97.0  128.0  72.0  121.0  90.0  82.0  88.0  88.0  80.0  103.0  91.0  89.0  96.0  105.0  76.0  114.0  96.0  103.0  94.0  90.0  100.0  80.0  110.0  89.0  115.0  93.0  0.1742971887550201   434 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.825703
2    0.904418
3    0.934137
4    0.953815
5    0.96747
6    0.9751
7    0.979116
8    0.982329
9    0.986747
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:45  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:45  1 min 43.266 sec  44874 obs/sec     1         1             10007      0.555431         1.00265             0.994518       0.275517                         0.554598           1.00051               0.994519         0.280321
    2019-08-04 09:01:47  1 min 45.273 sec  45652 obs/sec     10        10            100070     0.40874          0.573693            0.997031       0.16695                          0.415895           0.597835              0.996918         0.174297
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0850314
C13         0.991799               0.991799             0.0843341
C12         0.898664               0.898664             0.0764147
C9          0.896406               0.896406             0.0762227
C8          0.846302               0.846302             0.0719622
C7          0.80149                0.80149              0.0681518
C11         0.767236               0.767236             0.0652392
C14         0.693367               0.693367             0.058958
C10         0.691999               0.691999             0.0588416
C5          0.665456               0.665456             0.0565847
C6          0.652006               0.652006             0.055441
C16         0.650208               0.650208             0.0552881
C3          0.649749               0.649749             0.0552491
C4          0.561573               0.561573             0.0477514
C2          0.501795               0.501795             0.0426684
C1          0.492308               0.492308             0.0418616
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_236

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms         mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -----------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001576722420736587  0.0004613617202267051  0.0         -0.010542510371692515  0.439663290977478  -0.02891989864585089  0.4688441753387451
    3        26       Softmax                 0.0   0.0   0.002597668126257374  0.0009209930431097746  0.0         0.013192522815888178   0.560858964920044  -0.5295490126791411   0.2236729860305786


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1719029159610278
RMSE: 0.4146117653432278
LogLoss: 0.5770972862012622
Mean Per-Class Error: 0.1676182719579349
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    2.0    3.0    0.0    4.0    1.0    5.0    0.0    0.0    0.0    2.0    0.0    3.0    0.0    2.0    1.0    4.0    3.0    0.08354430379746836  33 / 395
0.0    336.0  4.0    9.0    5.0    0.0    2.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    10.0   4.0    0.0    0.0    2.0    0.0    3.0    1.0    0.0    0.12041884816753927  46 / 382
0.0    0.0    305.0  0.0    12.0   1.0    11.0   0.0    0.0    0.0    13.0   0.0    0.0    0.0    13.0   0.0    2.0    0.0    2.0    2.0    3.0    0.0    4.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
1.0    26.0   0.0    334.0  0.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    7.0    4.0    5.0    1.0    0.0    12.0   1.0    0.0    1.0    0.0    0.0    2.0    0.0    2.0    0.17121588089330025  69 / 403
0.0    4.0    1.0    0.0    300.0  7.0    19.0   0.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    4.0    3.0    19.0   6.0    1.0    0.0    0.0    7.0    0.0    9.0    0.21875              84 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    4.0    5.0    0.0    0.0    0.0    0.0    8.0    0.0    5.0    0.0    0.0    3.0    0.0    0.0    7.0    0.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    3.0    0.0    6.0    7.0    3.0    0.0    2.0    4.0    2.0    9.0    1.0    0.0    0.0    2.0    1.0    5.0    0.0    3.0    2.0    1.0    0.0    0.0    333.0  6.0    3.0    0.15267175572519084  60 / 393
1.0    1.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    6.0    0.0    2.0    9.0    1.0    20.0   1.0    0.0    340.0  0.0    0.1326530612244898   52 / 392
4.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    4.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    13.0   4.0    0.0    0.0    0.0    2.0    0.0    317.0  0.1362397820163488   50 / 367
410.0  489.0  337.0  418.0  402.0  389.0  384.0  309.0  346.0  349.0  362.0  378.0  412.0  371.0  420.0  386.0  359.0  425.0  338.0  376.0  401.0  373.0  403.0  396.0  390.0  380.0  0.16684994501649505  1,669 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83315
2    0.904929
3    0.937319
4    0.955713
5    0.96711
6    0.976207
7    0.981506
8    0.985504
9    0.988004
10   0.991603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17922052596734528
RMSE: 0.42334445309622903
LogLoss: 0.5995703448861864
Mean Per-Class Error: 0.177564096578068
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   1.0    0.0   2.0    1.0   0.06741573033707865  6 / 89
0.0   85.0   1.0   4.0    2.0   0.0   1.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   6.0    2.0   0.0   0.0    2.0   0.0    1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    67.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   5.0   0.0    0.0   0.0    1.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0   0.18292682926829268  15 / 82
0.0   3.0    0.0   93.0   0.0   0.0   0.0   2.0   0.0   2.0    1.0   0.0    3.0   1.0   1.0   1.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    64.0  5.0   5.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0   0.0   0.0    1.0   1.0    8.0   4.0   0.0    0.0   0.0    2.0   0.0    4.0   0.3402061855670103   33 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   4.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   5.0    3.0   1.0   0.0   1.0   0.0   0.0    4.0   1.0    0.0   0.0   0.0   0.0    1.0   0.0    2.0   0.0   0.0    0.0   0.0    80.0  1.0    1.0   0.2                  20 / 100
1.0   1.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0    2.0   0.0    0.0   3.0   0.0    6.0   1.0    0.0   90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   1.0   1.0    0.0   1.0    0.0   0.0   0.0   0.0    1.0   0.0    2.0   2.0   0.0    0.0   0.0    1.0   0.0    75.0  0.13793103448275862  12 / 87
94.0  117.0  69.0  123.0  84.0  96.0  92.0  82.0  84.0  100.0  92.0  102.0  91.0  96.0  86.0  112.0  91.0  109.0  82.0  95.0  104.0  83.0  101.0  98.0  108.0  99.0  0.17791164658634537  443 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822088
2    0.90241
3    0.934538
4    0.953414
5    0.965462
6    0.9751
7    0.981928
8    0.985542
9    0.988755
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:57  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:57  6 min 55.331 sec  76389 obs/sec     1         1             10007      0.582142         1.07918             0.993976       0.280216                         0.581777           1.07453               0.993969         0.288353
    2019-08-04 09:06:58  6 min 56.521 sec  77214 obs/sec     10        10            100070     0.414612         0.577097            0.996944       0.16685                          0.423344           0.59957               0.996807         0.177912
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0953829
C13         0.948667               0.948667             0.0904866
C9          0.86466                0.86466              0.0824738
C12         0.795925               0.795925             0.0759177
C8          0.758087               0.758087             0.0723086
C10         0.71703                0.71703              0.0683924
C7          0.669141               0.669141             0.0638246
C11         0.623975               0.623975             0.0595166
C14         0.619302               0.619302             0.0590708
C16         0.596118               0.596118             0.0568595
C5          0.593886               0.593886             0.0566466
C6          0.556382               0.556382             0.0530694
C4          0.499588               0.499588             0.0476522
C3          0.471511               0.471511             0.0449741
C1          0.392464               0.392464             0.0374344
C2          0.37732                0.37732              0.0359899
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_207

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0019712451785522944  0.0005122951697558165  0.0         0.007131175929870892   0.41726839542388916  0.008377693787769813  0.49028682708740234
    3        26       Softmax                 0.0   0.0   0.0021686169593872016  0.000576189486309886   0.0         -0.006330765211643279  0.2911553382873535   -0.6090926538072794   0.24797886610031128


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17020097549894217
RMSE: 0.41255420916401053
LogLoss: 0.5924359812033893
Mean Per-Class Error: 0.1732797590117358
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    4.0    1.0    4.0    0.0    1.0    0.0    0.0    0.0    6.0    4.0    3.0    1.0    2.0    2.0    3.0    1.0    0.08607594936708861  34 / 395
0.0    316.0  0.0    10.0   4.0    0.0    2.0    12.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    19.0   10.0   0.0    0.0    2.0    0.0    1.0    1.0    1.0    0.17277486910994763  66 / 382
0.0    0.0    307.0  1.0    15.0   0.0    8.0    1.0    0.0    0.0    21.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    4.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
1.0    20.0   0.0    340.0  0.0    2.0    1.0    5.0    1.0    3.0    0.0    0.0    5.0    6.0    2.0    0.0    0.0    7.0    0.0    1.0    1.0    0.0    0.0    5.0    0.0    3.0    0.15632754342431762  63 / 403
0.0    5.0    4.0    0.0    325.0  4.0    15.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    4.0    5.0    7.0    0.0    0.0    0.0    2.0    0.0    9.0    0.15364583333333334  59 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    26.0   0.0    4.0    0.0    0.0    2.0    0.0    0.0    1.0    2.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    2.0    0.0    7.0    7.0    1.0    0.0    2.0    2.0    0.0    7.0    0.0    0.0    1.0    2.0    0.0    5.0    0.0    2.0    5.0    1.0    0.0    0.0    340.0  5.0    5.0    0.13705583756345177  54 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    9.0    0.0    3.0    18.0   3.0    19.0   2.0    0.0    331.0  0.0    0.15776081424936386  62 / 393
0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    35.0   4.0    0.0    0.0    0.0    0.0    0.0    297.0  0.1907356948228883   70 / 367
393.0  448.0  351.0  426.0  431.0  347.0  356.0  325.0  335.0  354.0  405.0  341.0  434.0  385.0  382.0  400.0  351.0  415.0  410.0  418.0  405.0  377.0  401.0  400.0  366.0  347.0  0.1724482655203439   1,725 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827552
2    0.905228
3    0.936919
4    0.952414
5    0.96661
6    0.974108
7    0.979306
8    0.983605
9    0.987104
10   0.989903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17288052020150618
RMSE: 0.41578903328672123
LogLoss: 0.6020972560017118
Mean Per-Class Error: 0.1736199554588048
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   1.0    0.0   1.0    1.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   82.0   0.0   3.0    2.0    0.0   1.0   4.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    0.0   7.0    3.0    0.0   0.0    2.0   0.0    1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    66.0  0.0    2.0    0.0   1.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    1.0   1.0    0.0   1.0    0.0   0.0    0.0   0.1951219512195122   16 / 82
1.0   4.0    0.0   94.0   0.0    1.0   1.0   4.0   1.0   0.0    0.0    0.0   1.0   3.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    79.0   3.0   5.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0    3.0   0.0    0.0   0.0    1.0   0.0    3.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   6.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    4.0    0.0   0.0   2.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.0   0.0    0.0   0.0    82.0  1.0    3.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    3.0   0.0    0.0    4.0   2.0    4.0   1.0    0.0   92.0   0.0   0.14018691588785046  15 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    7.0    1.0   0.0    0.0   0.0    0.0   0.0    71.0  0.1839080459770115   16 / 87
90.0  111.0  71.0  116.0  100.0  80.0  87.0  90.0  80.0  101.0  104.0  92.0  92.0  102.0  78.0  118.0  92.0  101.0  107.0  98.0  104.0  84.0  101.0  97.0  106.0  88.0  0.17269076305220885  430 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827309
2    0.906827
3    0.937349
4    0.953815
5    0.965863
6    0.972289
7    0.978313
8    0.980723
9    0.984739
10   0.989157
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:03  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:03  6 min  1.556 sec  28030 obs/sec     1         1             10007      0.545038         0.986084            0.994721       0.268819                         0.546052           0.984489              0.994687         0.27751
    2019-08-04 09:06:06  6 min  4.685 sec  29251 obs/sec     10        10            100070     0.412554         0.592436            0.996975       0.172448                         0.415789           0.602097              0.99692          0.172691
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0889625
C13         0.958182               0.958182             0.0852423
C12         0.87589                0.87589              0.0779213
C9          0.855404               0.855404             0.0760989
C8          0.805991               0.805991             0.071703
C7          0.792327               0.792327             0.0704874
C11         0.777482               0.777482             0.0691667
C10         0.686069               0.686069             0.0610344
C14         0.667435               0.667435             0.0593766
C6          0.622992               0.622992             0.0554229
C16         0.59988                0.59988              0.0533668
C5          0.595928               0.595928             0.0530152
C3          0.590138               0.590138             0.0525002
C4          0.536312               0.536312             0.0477116
C2          0.449969               0.449969             0.0400304
C1          0.426695               0.426695             0.0379599
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_100

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001481625207588877  0.0004144733538851142  0.0         -0.023961388851148513  0.428936243057251   -0.08655716981998823  0.4436800479888916
    3        26       Softmax                 0.0   0.0   0.002467695514286998  0.0006888613570481539  0.0         0.029435797171281856   0.5697550773620605  -0.5263786176086694   0.1799604296684265


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17397495882863956
RMSE: 0.4171030554055431
LogLoss: 0.5867406039188239
Mean Per-Class Error: 0.16890692049928935
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    3.0    7.0    0.0    0.0    0.0    2.0    1.0    7.0    0.0    1.0    0.0    2.0    0.0    6.0    0.0    0.08607594936708861  34 / 395
0.0    310.0  0.0    7.0    3.0    0.0    8.0    7.0    3.0    0.0    1.0    1.0    0.0    0.0    1.0    4.0    0.0    15.0   18.0   0.0    0.0    0.0    1.0    2.0    2.0    0.0    0.1906005221932115   73 / 383
0.0    0.0    313.0  0.0    14.0   2.0    3.0    0.0    0.0    0.0    13.0   1.0    3.0    0.0    8.0    0.0    0.0    2.0    3.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.14945652173913043  55 / 368
2.0    12.0   0.0    329.0  0.0    0.0    1.0    7.0    1.0    5.0    1.0    0.0    7.0    4.0    2.0    6.0    0.0    13.0   2.0    0.0    2.0    0.0    0.0    3.0    0.0    6.0    0.18362282878411912  74 / 403
0.0    5.0    1.0    0.0    320.0  2.0    14.0   0.0    0.0    0.0    5.0    2.0    0.0    0.0    0.0    1.0    3.0    3.0    12.0   1.0    0.0    0.0    0.0    4.0    0.0    11.0   0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    3.0    0.0    3.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    0.0    6.0    0.0    0.0    8.0    4.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    2.0    0.0    4.0    7.0    3.0    0.0    1.0    3.0    3.0    11.0   1.0    0.0    0.0    0.0    0.0    7.0    1.0    5.0    1.0    1.0    0.0    0.0    335.0  5.0    4.0    0.14974619289340102  59 / 394
1.0    0.0    0.0    1.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    8.0    3.0    16.0   1.0    0.0    348.0  0.0    0.11450381679389313  45 / 393
0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    21.0   6.0    0.0    0.0    0.0    3.0    2.0    306.0  0.16621253405994552  61 / 367
397.0  426.0  358.0  420.0  415.0  385.0  365.0  290.0  342.0  365.0  370.0  368.0  417.0  366.0  400.0  392.0  354.0  479.0  354.0  378.0  407.0  364.0  408.0  396.0  411.0  376.0  0.16814955513345997  1,682 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83185
2    0.907028
3    0.938518
4    0.956813
5    0.96701
6    0.975407
7    0.981006
8    0.985104
9    0.987804
10   0.989803

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17959854395198813
RMSE: 0.4237906841260059
LogLoss: 0.6055004592845592
Mean Per-Class Error: 0.17479920787308606
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.06741573033707865  6 / 89
0.0   79.0  0.0   2.0    2.0    0.0   2.0   3.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0   5.0    7.0   0.0   0.0    0.0   1.0    1.0   1.0    0.0   0.25471698113207547  27 / 106
0.0   0.0   67.0  0.0    2.0    1.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.18292682926829268  15 / 82
2.0   2.0   0.0   88.0   0.0    0.0   0.0   3.0   1.0   1.0    1.0   0.0   2.0   1.0    0.0   2.0    0.0   2.0    1.0   0.0   2.0    0.0   0.0    2.0   0.0    2.0   0.21428571428571427  24 / 112
0.0   0.0   0.0   0.0    80.0   1.0   6.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0   0.0   0.0    0.0   0.0    1.0   0.0    6.0   0.17525773195876287  17 / 97
---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   5.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0   0.0   2.0    3.0    0.0   0.0   1.0   0.0   0.0    5.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0   0.0   0.0    0.0   0.0    81.0  3.0    2.0   0.19                 19 / 100
1.0   0.0   0.0   0.0    1.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   2.0   0.0    3.0   1.0    0.0   95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0   2.0   0.0    0.0   0.0    0.0   1.0    72.0  0.1724137931034483   15 / 87
94.0  99.0  75.0  119.0  102.0  83.0  96.0  77.0  83.0  104.0  98.0  95.0  85.0  101.0  86.0  110.0  88.0  117.0  89.0  86.0  103.0  82.0  101.0  95.0  123.0  99.0  0.1746987951807229   435 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.825301
2    0.906827
3    0.932932
4    0.952209
5    0.96506
6    0.974699
7    0.980723
8    0.983936
9    0.98755
10   0.989157
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:47  2 min 45.494 sec  75810 obs/sec     1         1             10007      0.586137         1.08797             0.993895       0.286814                         0.58826            1.09566               0.993834         0.295582
    2019-08-04 09:02:48  2 min 46.701 sec  75983 obs/sec     10        10            100070     0.417103         0.586741            0.996909       0.16815                          0.423791           0.6055                0.9968           0.174699
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0871162
C15         0.988266               0.988266             0.0860939
C12         0.962059               0.962059             0.0838109
C8          0.926868               0.926868             0.0807452
C9          0.823191               0.823191             0.0717133
C7          0.770642               0.770642             0.0671354
C11         0.768369               0.768369             0.0669374
C10         0.751003               0.751003             0.0654245
C16         0.710694               0.710694             0.061913
C14         0.704366               0.704366             0.0613617
C6          0.680707               0.680707             0.0593006
C5          0.621198               0.621198             0.0541164
C4          0.503982               0.503982             0.043905
C3          0.493315               0.493315             0.0429757
C1          0.397217               0.397217             0.034604
C2          0.377048               0.377048             0.032847
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_153

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0019781804914345003  0.0005034797359257936  0.0         0.010274357429358005    0.4222296476364136   -0.014750266373150819  0.4601612091064453
    3        26       Softmax                 0.0   0.0   0.0021413442341152123  0.0004947867710143328  0.0         -0.0027221735129687044  0.29175257682800293  -0.5802027346177563    0.23465973138809204


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1702095707062534
RMSE: 0.4125646260966315
LogLoss: 0.5926018578492422
Mean Per-Class Error: 0.1698010697015651
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    2.0    1.0    7.0    0.0    0.0    0.0    0.0    4.0    5.0    0.0    4.0    1.0    2.0    0.0    4.0    0.0    0.09367088607594937  37 / 395
0.0    331.0  0.0    6.0    3.0    0.0    2.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    2.0    14.0   9.0    0.0    0.0    4.0    0.0    2.0    1.0    0.0    0.13577023498694518  52 / 383
0.0    0.0    301.0  1.0    14.0   0.0    5.0    1.0    0.0    0.0    19.0   4.0    0.0    0.0    3.0    0.0    5.0    0.0    6.0    1.0    6.0    0.0    2.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
1.0    20.0   0.0    342.0  0.0    1.0    0.0    4.0    1.0    7.0    0.0    2.0    7.0    3.0    1.0    1.0    0.0    7.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    2.0    0.1513647642679901   61 / 403
0.0    6.0    2.0    0.0    314.0  3.0    15.0   0.0    0.0    0.0    3.0    4.0    0.0    0.0    0.0    1.0    6.0    4.0    10.0   6.0    0.0    0.0    0.0    3.0    0.0    7.0    0.18229166666666666  70 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    2.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    1.0    0.0    14.0   0.0    3.0    0.0    0.0    4.0    0.0    0.0    2.0    8.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    4.0    0.0    6.0    8.0    1.0    0.0    4.0    4.0    2.0    8.0    2.0    0.0    0.0    2.0    0.0    5.0    2.0    2.0    4.0    1.0    0.0    0.0    333.0  4.0    2.0    0.1548223350253807   61 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    1.0    15.0   2.0    24.0   1.0    1.0    335.0  0.0    0.1475826972010178   58 / 393
2.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    15.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    24.0   4.0    0.0    0.0    0.0    0.0    0.0    305.0  0.16893732970027248  62 / 367
392.0  498.0  346.0  426.0  388.0  383.0  331.0  315.0  331.0  394.0  383.0  388.0  431.0  360.0  385.0  379.0  383.0  430.0  371.0  383.0  421.0  393.0  385.0  385.0  378.0  344.0  0.16894931520543838  1,690 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.831051
2    0.903329
3    0.936219
4    0.952814
5    0.96541
6    0.974308
7    0.981506
8    0.985804
9    0.988403
10   0.990803

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17380640426390237
RMSE: 0.41690095258214793
LogLoss: 0.606409215321522
Mean Per-Class Error: 0.17482931590435186
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0   0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   83.0   0.0   2.0    2.0   0.0   1.0   2.0   1.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0    0.0   7.0    2.0   0.0   0.0    3.0   0.0   1.0   0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    64.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0   2.0   0.0    1.0   0.0    3.0   1.0   2.0    0.0   1.0   0.0   0.0    0.0   0.21951219512195122  18 / 82
1.0   3.0    0.0   96.0   0.0   0.0   0.0   2.0   1.0   1.0    0.0   1.0    3.0   1.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   1.0    0.0   0.0    74.0  2.0   5.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0   0.0   0.0    1.0   1.0    3.0   3.0   0.0    0.0   0.0   1.0   0.0    4.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    4.0   0.0   0.0   2.0   0.0   0.0    4.0   2.0    0.0   0.0   0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0   79.0  1.0    1.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    2.0   0.0    0.0   5.0   0.0    6.0   1.0   0.0   90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    74.0  0.14942528735632185  13 / 87
89.0  122.0  73.0  118.0  91.0  88.0  81.0  84.0  78.0  110.0  94.0  105.0  96.0  95.0  83.0  110.0  96.0  113.0  94.0  94.0  104.0  88.0  97.0  93.0  104.0  90.0  0.1746987951807229   435 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.825301
2    0.904016
3    0.935341
4    0.949799
5    0.965863
6    0.973494
7    0.980321
8    0.985542
9    0.987952
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:19  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:19  4 min 17.353 sec  27874 obs/sec     1         1             10007      0.551697         1.00113             0.994592       0.271918                         0.551408           1.00009               0.994582         0.277912
    2019-08-04 09:04:22  4 min 20.531 sec  28788 obs/sec     10        10            100070     0.412565         0.592602            0.996976       0.168949                         0.416901           0.606409              0.996903         0.174699
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0875668
C13         0.964552               0.964552             0.0844627
C9          0.909936               0.909936             0.0796802
C12         0.904588               0.904588             0.0792119
C7          0.81521                0.81521              0.0713853
C8          0.806857               0.806857             0.0706538
C11         0.779855               0.779855             0.0682894
C10         0.696449               0.696449             0.0609858
C14         0.66239                0.66239              0.0580034
C6          0.643996               0.643996             0.0563927
C16         0.633245               0.633245             0.0554512
C5          0.619324               0.619324             0.0542322
C3          0.589467               0.589467             0.0516177
C4          0.548713               0.548713             0.048049
C1          0.425404               0.425404             0.0372513
C2          0.419871               0.419871             0.0367667
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_102

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.001907256186854056   0.0004754320252686739  0.0         -0.0008894096428271325  0.4259183406829834  0.02102339541823433  0.5017070770263672
    3        26       Softmax                 0.0   0.0   0.0021526734122009937  0.000592515803873539   0.0         -0.007573146922325622   0.2909688949584961  -0.6296812718060972  0.23178833723068237


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16956386144947203
RMSE: 0.41178132722292304
LogLoss: 0.595901080225878
Mean Per-Class Error: 0.17122784190918797
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    6.0    1.0    2.0    0.0    0.0    1.0    5.0    1.0    1.0    0.0    1.0    3.0    6.0    2.0    0.08860759493670886  35 / 395
0.0    330.0  0.0    7.0    3.0    0.0    0.0    5.0    2.0    0.0    1.0    1.0    0.0    0.0    0.0    4.0    0.0    21.0   6.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.13838120104438642  53 / 383
0.0    0.0    297.0  0.0    10.0   0.0    17.0   1.0    0.0    0.0    21.0   2.0    0.0    0.0    2.0    0.0    1.0    0.0    6.0    3.0    5.0    0.0    3.0    0.0    0.0    0.0    0.19293478260869565  71 / 368
1.0    17.0   0.0    339.0  0.0    1.0    0.0    8.0    2.0    3.0    0.0    0.0    5.0    6.0    1.0    3.0    0.0    5.0    2.0    0.0    1.0    0.0    0.0    6.0    0.0    3.0    0.1588089330024814   64 / 403
0.0    12.0   0.0    0.0    311.0  2.0    18.0   0.0    1.0    0.0    4.0    1.0    0.0    0.0    0.0    1.0    0.0    5.0    10.0   5.0    0.0    0.0    0.0    5.0    0.0    9.0    0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    11.0   0.0    3.0    0.0    0.0    7.0    0.0    0.0    6.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    2.0    0.0    8.0    6.0    0.0    0.0    2.0    3.0    1.0    8.0    1.0    0.0    0.0    2.0    0.0    5.0    0.0    3.0    1.0    1.0    0.0    0.0    343.0  4.0    3.0    0.1272264631043257   50 / 393
1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    2.0    12.0   3.0    10.0   1.0    1.0    350.0  0.0    0.10714285714285714  42 / 392
3.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    21.0   3.0    0.0    0.0    0.0    0.0    0.0    310.0  0.1553133514986376   57 / 367
393.0  483.0  323.0  415.0  396.0  352.0  369.0  325.0  344.0  359.0  383.0  354.0  416.0  397.0  385.0  401.0  359.0  453.0  344.0  368.0  416.0  352.0  405.0  437.0  404.0  370.0  0.17034889533140057  1,704 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.829651
2    0.902829
3    0.93332
4    0.950915
5    0.963211
6    0.972308
7    0.978506
8    0.983105
9    0.987004
10   0.989503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17414898086533834
RMSE: 0.4173116112275554
LogLoss: 0.6134180875052598
Mean Per-Class Error: 0.17516512928242
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   86.0   0.0   2.0    2.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0   9.0    1.0   0.0   0.0    1.0   0.0   1.0    1.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    61.0  0.0    2.0   0.0   8.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0   1.0   0.0    0.0    0.0   0.25609756097560976  21 / 82
1.0   1.0    0.0   94.0   0.0   1.0   0.0   5.0   1.0   1.0    0.0   0.0   2.0   2.0    0.0   2.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0   0.16071428571428573  18 / 112
0.0   2.0    0.0   0.0    76.0  1.0   6.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0   2.0   0.0    0.0   0.0   2.0    0.0    3.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   4.0    4.0   0.0   0.0   1.0   0.0   0.0    4.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   81.0   1.0    2.0   0.19                 19 / 100
1.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    4.0   0.0    0.0   2.0   0.0    4.0   1.0   0.0    93.0   0.0   0.1308411214953271   14 / 107
2.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   1.0   0.0    0.0   0.0   0.0    0.0    73.0  0.16091954022988506  14 / 87
92.0  120.0  65.0  113.0  96.0  80.0  94.0  86.0  85.0  105.0  98.0  97.0  94.0  105.0  79.0  118.0  97.0  110.0  84.0  86.0  106.0  79.0  97.0  101.0  114.0  89.0  0.17349397590361446  432 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826506
2    0.898795
3    0.93253
4    0.951004
5    0.961847
6    0.972289
7    0.97751
8    0.983133
9    0.987952
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:51  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:51  2 min 49.408 sec  27874 obs/sec     1         1             10007      0.540102         0.976901            0.994816       0.26632                          0.540144           0.971132              0.994801         0.274699
    2019-08-04 09:02:54  2 min 52.597 sec  28730 obs/sec     10        10            100070     0.411781         0.595901            0.996986       0.170349                         0.417312           0.613418              0.996897         0.173494
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0870518
C13         0.985739               0.985739             0.0858104
C9          0.901524               0.901524             0.0784793
C12         0.87136                0.87136              0.0758535
C7          0.845623               0.845623             0.073613
C11         0.789291               0.789291             0.0687092
C8          0.785225               0.785225             0.0683553
C10         0.695265               0.695265             0.060524
C14         0.686055               0.686055             0.0597223
C5          0.637923               0.637923             0.0555324
C6          0.629163               0.629163             0.0547698
C16         0.607532               0.607532             0.0528868
C3          0.604115               0.604115             0.0525893
C4          0.568353               0.568353             0.0494762
C1          0.458183               0.458183             0.0398856
C2          0.422061               0.422061             0.0367412
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_76

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0020100458086602657  0.0004927611444145441  0.0         -0.0038253782889476895  0.4262605905532837   0.0312037581230507   0.49699723720550537
    3        26       Softmax                 0.0   0.0   0.002110546761304459   0.000552373705431819   0.0         -0.006592260925145865   0.29003608226776123  -0.6101422081332432  0.2713437080383301


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17294643709193827
RMSE: 0.41586829296297434
LogLoss: 0.6031976592018677
Mean Per-Class Error: 0.17542488949580634
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    1.0    7.0    0.0    1.0    0.0    0.0    1.0    7.0    2.0    2.0    0.0    2.0    2.0    6.0    0.0    0.09113924050632911  36 / 395
0.0    329.0  0.0    8.0    4.0    0.0    3.0    3.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    10.0   13.0   0.0    0.0    4.0    0.0    2.0    1.0    0.0    0.1409921671018277   54 / 383
0.0    0.0    304.0  1.0    9.0    0.0    14.0   1.0    0.0    0.0    14.0   1.0    0.0    0.0    5.0    0.0    1.0    1.0    5.0    4.0    3.0    0.0    5.0    0.0    0.0    0.0    0.17391304347826086  64 / 368
1.0    22.0   0.0    341.0  0.0    1.0    0.0    2.0    1.0    2.0    1.0    0.0    7.0    2.0    6.0    3.0    0.0    3.0    0.0    2.0    1.0    0.0    0.0    7.0    0.0    1.0    0.15384615384615385  62 / 403
0.0    9.0    1.0    0.0    307.0  3.0    16.0   1.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    10.0   2.0    6.0    9.0    0.0    0.0    0.0    3.0    0.0    13.0   0.20052083333333334  77 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    15.0   0.0    9.0    0.0    0.0    2.0    0.0    0.0    1.0    2.0    336.0  0.0    0.0    0.0    0.104                39 / 375
0.0    4.0    0.0    5.0    5.0    1.0    0.0    3.0    3.0    1.0    9.0    5.0    0.0    0.0    2.0    0.0    5.0    1.0    4.0    8.0    1.0    0.0    0.0    328.0  7.0    2.0    0.16751269035532995  66 / 394
0.0    1.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    3.0    0.0    2.0    6.0    3.0    13.0   1.0    0.0    354.0  0.0    0.09923664122137404  39 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    6.0    1.0    22.0   4.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
401.0  548.0  338.0  418.0  375.0  356.0  360.0  297.0  325.0  358.0  360.0  352.0  443.0  364.0  399.0  379.0  372.0  421.0  365.0  415.0  406.0  380.0  392.0  394.0  423.0  362.0  0.1744476657002899   1,745 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.825552
2    0.90123
3    0.93272
4    0.951914
5    0.962711
6    0.970909
7    0.978606
8    0.982805
9    0.986704
10   0.989303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1760305678070285
RMSE: 0.4195599692618786
LogLoss: 0.6151649035134202
Mean Per-Class Error: 0.18039194069954834
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   1.0    3.0   0.0   1.0   2.0   1.0   0.0    0.0   0.0   0.0    0.0    2.0   0.0    0.0   4.0    3.0   0.0   0.0    3.0   0.0    1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    66.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0    2.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   2.0    0.0   0.0    0.0   0.1951219512195122   16 / 82
1.0   4.0    0.0   93.0   0.0   0.0   0.0   1.0   1.0   0.0    0.0   0.0   3.0    1.0    1.0   3.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    1.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    76.0  2.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    3.0   1.0    1.0   4.0   0.0    0.0   0.0    0.0   0.0    6.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0    0.0    1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    2.0   0.0   0.0   2.0   0.0   0.0    4.0   3.0   0.0    0.0    0.0   0.0    1.0   1.0    0.0   0.0   0.0    0.0   0.0    80.0  2.0    1.0   0.2                  20 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    1.0   1.0    1.0   0.0    0.0   1.0   0.0    4.0   1.0    0.0   97.0   0.0   0.09345794392523364  10 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0   2.0   0.0    0.0    0.0   0.0    0.0   0.0    5.0   1.0   0.0    0.0   0.0    0.0   0.0    73.0  0.16091954022988506  14 / 87
93.0  129.0  70.0  115.0  90.0  84.0  87.0  81.0  78.0  103.0  87.0  95.0  103.0  100.0  86.0  110.0  92.0  107.0  87.0  95.0  100.0  86.0  100.0  96.0  120.0  96.0  0.17951807228915662  447 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.820482
2    0.902008
3    0.934137
4    0.951004
5    0.961446
6    0.968273
7    0.97751
8    0.982731
9    0.986345
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:05  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:05  2 min  3.743 sec  29432 obs/sec     1         1             10007      0.543171         0.982158            0.994757       0.255323                         0.543285           0.978032              0.994741         0.257831
    2019-08-04 09:02:09  2 min  6.980 sec  28477 obs/sec     10        10            100070     0.415868         0.603198            0.996927       0.174448                         0.41956            0.615165              0.996863         0.179518
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0885753
C13         0.962224               0.962224             0.0852293
C12         0.904608               0.904608             0.080126
C9          0.885104               0.885104             0.0783984
C7          0.768465               0.768465             0.068067
C8          0.760766               0.760766             0.0673851
C11         0.757828               0.757828             0.0671248
C10         0.691893               0.691893             0.0612846
C14         0.647541               0.647541             0.0573561
C16         0.614978               0.614978             0.0544719
C6          0.613391               0.613391             0.0543313
C5          0.613019               0.613019             0.0542984
C3          0.611832               0.611832             0.0541932
C4          0.543924               0.543924             0.0481782
C2          0.458315               0.458315             0.0405954
C1          0.455939               0.455939             0.0403849
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_224

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0019484181919295906  0.0004788219230249524  0.0         -0.0022351703532876854  0.4134424924850464  0.006415865554750121  0.4576152563095093
    3        26       Softmax                 0.0   0.0   0.002167050084993277   0.0005660203751176596  0.0         0.0006453649277390766   0.295865535736084   -0.6171090050694462   0.2784477472305298


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1718875570962989
RMSE: 0.4145932429457804
LogLoss: 0.6022424393443437
Mean Per-Class Error: 0.17462040999533573
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    5.0    3.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.0    2.0    0.0    6.0    1.0    0.0810126582278481   32 / 395
0.0    316.0  0.0    11.0   3.0    1.0    4.0    5.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    20.0   6.0    0.0    0.0    1.0    1.0    2.0    0.0    0.0    0.17493472584856398  67 / 383
0.0    1.0    298.0  1.0    16.0   0.0    10.0   1.0    0.0    0.0    20.0   1.0    0.0    0.0    4.0    0.0    1.0    0.0    4.0    2.0    6.0    0.0    3.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
4.0    18.0   0.0    335.0  0.0    1.0    1.0    3.0    3.0    5.0    0.0    2.0    5.0    4.0    2.0    2.0    0.0    9.0    0.0    0.0    3.0    0.0    0.0    5.0    0.0    0.0    0.16666666666666666  67 / 402
0.0    2.0    2.0    0.0    318.0  4.0    11.0   0.0    3.0    0.0    3.0    3.0    0.0    0.0    0.0    1.0    8.0    4.0    5.0    5.0    0.0    0.0    0.0    6.0    0.0    9.0    0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    1.0    0.0    3.0    7.0    0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    5.0    1.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    2.0    0.0    4.0    4.0    2.0    0.0    2.0    3.0    1.0    8.0    4.0    0.0    0.0    3.0    0.0    5.0    2.0    1.0    2.0    1.0    0.0    0.0    340.0  6.0    4.0    0.13705583756345177  54 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    6.0    0.0    1.0    17.0   2.0    17.0   1.0    1.0    337.0  0.0    0.14249363867684478  56 / 393
4.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    1.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    15.0   6.0    0.0    0.0    0.0    0.0    0.0    317.0  0.1362397820163488   50 / 367
415.0  443.0  333.0  423.0  396.0  394.0  355.0  286.0  363.0  361.0  386.0  372.0  403.0  360.0  371.0  389.0  370.0  474.0  298.0  370.0  428.0  365.0  431.0  424.0  403.0  390.0  0.1736479056283115   1,737 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826352
2    0.903129
3    0.93382
4    0.951315
5    0.964611
6    0.972908
7    0.977607
8    0.982705
9    0.986304
10   0.989903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17510657600840282
RMSE: 0.4184573765730541
LogLoss: 0.6153492794245671
Mean Per-Class Error: 0.1839791248575335
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   82.0   0.0   3.0    3.0   0.0   1.0   1.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   8.0    1.0   0.0   0.0    1.0   1.0    1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    64.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0   0.21951219512195122  18 / 82
3.0   2.0    0.0   92.0   0.0   1.0   0.0   2.0   1.0   1.0    0.0   1.0    3.0   1.0   1.0   2.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.17857142857142858  20 / 112
0.0   0.0    1.0   0.0    73.0  3.0   4.0   0.0   2.0   0.0    1.0   1.0    0.0   0.0   0.0   0.0    1.0   1.0    2.0   3.0   0.0    0.0   0.0    2.0   0.0    3.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   2.0   0.0   0.0    4.0   3.0    0.0   0.0   1.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0    79.0  2.0    2.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    3.0   0.0    0.0   6.0   0.0    6.0   1.0    0.0   89.0   0.0   0.16822429906542055  18 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   2.0   0.0    0.0   0.0    0.0   0.0    76.0  0.12643678160919541  11 / 87
97.0  109.0  70.0  116.0  89.0  91.0  92.0  73.0  92.0  100.0  94.0  101.0  92.0  99.0  78.0  110.0  93.0  123.0  78.0  90.0  104.0  84.0  107.0  96.0  113.0  99.0  0.18393574297188756  458 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816064
2    0.905622
3    0.935341
4    0.952209
5    0.96506
6    0.973092
7    0.978313
8    0.982731
9    0.985542
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:36  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:36  6 min 34.356 sec  28348 obs/sec     1         1             10007      0.543179         0.98088             0.994757       0.260922                         0.541043           0.972437              0.994784         0.264659
    2019-08-04 09:06:39  6 min 37.489 sec  29217 obs/sec     10        10            100070     0.414593         0.602242            0.996946       0.173648                         0.418457           0.615349              0.99688          0.183936
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0866245
C13         0.991964               0.991964             0.0859283
C9          0.87576                0.87576              0.0758622
C12         0.871982               0.871982             0.075535
C7          0.847772               0.847772             0.0734378
C8          0.812923               0.812923             0.070419
C11         0.801272               0.801272             0.0694098
C10         0.687603               0.687603             0.0595632
C14         0.666989               0.666989             0.0577776
C6          0.639885               0.639885             0.0554297
C5          0.631885               0.631885             0.0547367
C16         0.615148               0.615148             0.0532869
C3          0.607388               0.607388             0.0526146
C4          0.58638                0.58638              0.0507948
C2          0.458274               0.458274             0.0396978
C1          0.448859               0.448859             0.0388822
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_156

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0020308309796774893  0.0005081465933471918  0.0         -0.015225957838666204   0.42358529567718506  0.008282861226943376  0.5008673667907715
    3        26       Softmax                 0.0   0.0   0.002184398838748026   0.0005861721001565456  0.0         -0.0017303355351621428  0.2885313034057617   -0.6220246220283543   0.2452695369720459


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1726052968710766
RMSE: 0.4154579363438332
LogLoss: 0.6055118844474815
Mean Per-Class Error: 0.1792550825708628
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    3.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    1.0    1.0    2.0    1.0    6.0    1.0    0.08354430379746836  33 / 395
0.0    339.0  0.0    7.0    3.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    22.0   4.0    0.0    0.0    1.0    1.0    1.0    1.0    0.0    0.11488250652741515  44 / 383
1.0    0.0    302.0  0.0    13.0   0.0    8.0    1.0    0.0    0.0    23.0   0.0    0.0    0.0    3.0    0.0    2.0    0.0    6.0    3.0    4.0    0.0    2.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
4.0    12.0   0.0    354.0  0.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    5.0    5.0    2.0    4.0    0.0    4.0    0.0    0.0    1.0    0.0    0.0    4.0    0.0    4.0    0.12158808933002481  49 / 403
0.0    13.0   0.0    0.0    317.0  3.0    10.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0    9.0    5.0    4.0    3.0    0.0    0.0    0.0    2.0    0.0    13.0   0.17015706806282724  65 / 382
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    2.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    14.0   0.0    4.0    0.0    0.0    3.0    0.0    0.0    6.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    3.0    0.0    6.0    8.0    0.0    0.0    2.0    2.0    1.0    8.0    0.0    0.0    0.0    0.0    1.0    5.0    3.0    2.0    4.0    1.0    0.0    0.0    339.0  3.0    6.0    0.13959390862944163  55 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    6.0    0.0    2.0    21.0   1.0    37.0   2.0    1.0    316.0  0.0    0.19592875318066158  77 / 393
0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    1.0    17.0   4.0    0.0    0.0    0.0    0.0    0.0    320.0  0.12806539509536785  47 / 367
419.0  540.0  343.0  459.0  406.0  337.0  321.0  289.0  330.0  343.0  365.0  355.0  397.0  372.0  379.0  399.0  367.0  462.0  307.0  390.0  426.0  380.0  433.0  408.0  368.0  408.0  0.17824652604218735  1,783 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.821754
2    0.902729
3    0.93422
4    0.951115
5    0.962711
6    0.971109
7    0.978007
8    0.983805
9    0.986404
10   0.988903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17658789592403926
RMSE: 0.42022362608977526
LogLoss: 0.6154047729944737
Mean Per-Class Error: 0.18694182248549368
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0    1.0    3.0    0.0    0.07865168539325842  7 / 89
0.0   88.0   0.0   1.0    2.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   9.0    1.0   0.0   0.0    1.0   1.0    1.0    0.0    0.0    0.16981132075471697  18 / 106
0.0   0.0    66.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0   1.0    0.0    0.0    0.0    0.1951219512195122   16 / 82
3.0   2.0    0.0   93.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   2.0   2.0    0.0   3.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    2.0    0.16964285714285715  19 / 112
0.0   3.0    0.0   0.0    76.0  1.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    1.0   1.0   0.0    0.0   0.0    0.0    0.0    7.0    0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    5.0   0.0   0.0   1.0   0.0   0.0   4.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    81.0   1.0    3.0    0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   6.0   0.0    10.0  2.0    0.0    87.0   0.0    0.18691588785046728  20 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0   0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   1.0   0.0    0.0   0.0    0.0    0.0    76.0   0.12643678160919541  11 / 87
97.0  130.0  74.0  123.0  96.0  76.0  76.0  74.0  77.0  99.0  90.0  98.0  85.0  101.0  78.0  118.0  95.0  122.0  76.0  90.0  108.0  85.0  108.0  100.0  105.0  109.0  0.1859437751004016   463 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814056
2    0.900803
3    0.93494
4    0.952209
5    0.963454
6    0.971084
7    0.978313
8    0.983936
9    0.985542
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:24  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:24  4 min 22.450 sec  29090 obs/sec     1         1             10007      0.549723         1.00138             0.99463        0.277817                         0.550028           0.99505               0.994609         0.27992
    2019-08-04 09:04:27  4 min 25.504 sec  29970 obs/sec     10        10            100070     0.415458         0.605512            0.996933       0.178247                         0.420224           0.615405              0.996853         0.185944
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0915439
C13         0.938419               0.938419             0.0859065
C9          0.877587               0.877587             0.0803377
C12         0.855074               0.855074             0.0782768
C7          0.767169               0.767169             0.0702296
C11         0.753557               0.753557             0.0689835
C8          0.731674               0.731674             0.0669803
C10         0.655107               0.655107             0.0599711
C14         0.634822               0.634822             0.0581141
C6          0.617706               0.617706             0.0565472
C16         0.615905               0.615905             0.0563823
C5          0.593998               0.593998             0.0543769
C3          0.545504               0.545504             0.0499376
C4          0.511797               0.511797             0.0468519
C2          0.430677               0.430677             0.0394259
C1          0.394727               0.394727             0.0361348
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_127

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  ------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0014561307489771025  0.0004351706011220813  0.0         -0.006714212120471075   0.4444330930709839  -0.033209892472172736  0.419339656829834
    3        26       Softmax                 0.0   0.0   0.0025753252770160683  0.0009313083719462156  0.0         -0.0018315385303559685  0.5628395080566406  -0.5251013504944801    0.22768718004226685


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17706523681176178
RMSE: 0.42079120334408343
LogLoss: 0.6017122972538533
Mean Per-Class Error: 0.17175840012194038
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    1.0    4.0    1.0    6.0    0.0    4.0    0.0    0.0    2.0    5.0    0.0    1.0    0.0    2.0    2.0    6.0    1.0    0.09873417721518987  39 / 395
0.0    327.0  0.0    3.0    4.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    20.0   9.0    1.0    0.0    5.0    1.0    1.0    1.0    0.0    0.1462140992167102   56 / 383
0.0    0.0    330.0  0.0    5.0    1.0    4.0    0.0    0.0    0.0    4.0    3.0    0.0    0.0    6.0    2.0    0.0    0.0    4.0    2.0    4.0    0.0    3.0    0.0    0.0    0.0    0.10326086956521739  38 / 368
4.0    28.0   0.0    336.0  0.0    1.0    0.0    4.0    0.0    1.0    0.0    0.0    5.0    3.0    7.0    3.0    0.0    1.0    1.0    0.0    3.0    0.0    0.0    5.0    0.0    1.0    0.1662531017369727   67 / 403
0.0    3.0    4.0    0.0    328.0  3.0    10.0   2.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    10.0   2.0    4.0    6.0    0.0    0.0    0.0    2.0    0.0    7.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    11.0   1.0    2.0    0.0    0.0    8.0    0.0    0.0    3.0    1.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    4.0    0.0    5.0    7.0    0.0    0.0    7.0    4.0    2.0    11.0   3.0    0.0    0.0    2.0    0.0    6.0    2.0    5.0    1.0    1.0    0.0    0.0    328.0  3.0    3.0    0.16751269035532995  66 / 394
0.0    0.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    8.0    0.0    2.0    19.0   1.0    17.0   1.0    1.0    336.0  0.0    0.1450381679389313   57 / 393
1.0    0.0    0.0    0.0    19.0   0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    35.0   2.0    0.0    0.0    0.0    4.0    0.0    296.0  0.19346049046321526  71 / 367
398.0  490.0  374.0  425.0  421.0  330.0  320.0  358.0  340.0  351.0  348.0  357.0  412.0  404.0  389.0  414.0  371.0  425.0  378.0  394.0  403.0  383.0  387.0  393.0  387.0  351.0  0.17114865540337898  1,712 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.828851
2    0.906228
3    0.935919
4    0.951515
5    0.963511
6    0.971808
7    0.978007
8    0.982605
9    0.986104
10   0.989503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1815973960411937
RMSE: 0.4261424597962443
LogLoss: 0.6157667631482323
Mean Per-Class Error: 0.17443240597298162
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0   0.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   87.0   0.0   0.0    2.0   0.0   0.0   4.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   7.0    1.0   0.0   0.0    1.0   1.0   1.0   1.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    72.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0   0.0    2.0   1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.12195121951219512  10 / 82
3.0   6.0    0.0   92.0   0.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0   3.0   1.0    1.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.17857142857142858  20 / 112
0.0   0.0    1.0   0.0    80.0  1.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0   3.0   0.0    0.0   0.0   1.0   0.0    3.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   1.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   2.0    0.0   3.0    2.0   0.0   0.0   2.0   0.0   0.0    6.0   2.0   0.0   0.0    0.0   0.0    1.0   1.0    0.0   0.0   0.0    0.0   0.0   79.0  0.0    2.0   0.21                 21 / 100
0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    4.0   0.0    0.0   3.0   0.0    5.0   1.0   0.0   90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   0.0   0.0    0.0   0.0   1.0   0.0    72.0  0.1724137931034483   15 / 87
94.0  123.0  83.0  122.0  98.0  76.0  81.0  98.0  80.0  101.0  89.0  94.0  95.0  104.0  73.0  118.0  92.0  105.0  90.0  95.0  100.0  85.0  99.0  95.0  109.0  91.0  0.17389558232931726  433 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826104
2    0.905221
3    0.93494
4    0.954618
5    0.967068
6    0.972691
7    0.979116
8    0.983132
9    0.985944
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:34  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:34  3 min 32.279 sec  74125 obs/sec     1         1             10007      0.579158         1.07795             0.99404        0.283315                         0.579666           1.07527               0.994013         0.286747
    2019-08-04 09:03:35  3 min 33.497 sec  75184 obs/sec     10        10            100070     0.420791         0.601712            0.996854       0.171149                         0.426142           0.615767              0.996764         0.173896
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0923184
C13         0.983116               0.983116             0.0907597
C9          0.96027                0.96027              0.0886506
C12         0.816873               0.816873             0.0754124
C8          0.806647               0.806647             0.0744683
C10         0.74977                0.74977              0.0692176
C11         0.728263               0.728263             0.0672321
C7          0.727166               0.727166             0.0671308
C14         0.629397               0.629397             0.0581049
C6          0.570424               0.570424             0.0526607
C5          0.552303               0.552303             0.0509877
C16         0.549767               0.549767             0.0507536
C3          0.547193               0.547193             0.050516
C4          0.509162               0.509162             0.0470051
C1          0.398887               0.398887             0.0368247
C2          0.302836               0.302836             0.0279573
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_184

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0019440574407951772  0.0004803360207006335  0.0         0.00755108479774913    0.4184354543685913  0.008173178656546636  0.4861161708831787
    3        26       Softmax                 0.0   0.0   0.0022429221610484372  0.0006044814363121986  0.0         0.0032434337755788624  0.2950594425201416  -0.6343351963175867   0.2373971939086914


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17360732466910378
RMSE: 0.416662122911483
LogLoss: 0.6049640145027978
Mean Per-Class Error: 0.1765633698018858
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    5.0    4.0    0.0    9.0    0.0    0.0    0.0    1.0    2.0    3.0    1.0    2.0    0.0    2.0    4.0    7.0    1.0    0.10886075949367088  43 / 395
0.0    323.0  0.0    7.0    2.0    2.0    1.0    4.0    3.0    0.0    4.0    0.0    1.0    0.0    0.0    2.0    1.0    14.0   13.0   0.0    0.0    3.0    0.0    1.0    1.0    0.0    0.1544502617801047   59 / 382
0.0    1.0    292.0  1.0    16.0   1.0    11.0   1.0    0.0    0.0    24.0   1.0    0.0    0.0    2.0    0.0    2.0    0.0    5.0    5.0    3.0    0.0    2.0    0.0    0.0    0.0    0.20435967302452315  75 / 367
1.0    18.0   0.0    341.0  0.0    1.0    0.0    2.0    1.0    3.0    0.0    0.0    7.0    4.0    2.0    3.0    0.0    12.0   3.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.15384615384615385  62 / 403
0.0    6.0    0.0    0.0    313.0  2.0    17.0   1.0    1.0    0.0    4.0    1.0    0.0    0.0    0.0    1.0    2.0    3.0    13.0   5.0    0.0    0.0    0.0    4.0    0.0    11.0   0.18489583333333334  71 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    26.0   1.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    5.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    3.0    0.0    7.0    8.0    0.0    0.0    2.0    4.0    2.0    6.0    1.0    0.0    0.0    1.0    0.0    8.0    0.0    10.0   3.0    1.0    0.0    0.0    330.0  6.0    2.0    0.16243654822335024  64 / 394
0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    6.0    0.0    2.0    9.0    1.0    17.0   1.0    1.0    348.0  0.0    0.11450381679389313  45 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    31.0   4.0    0.0    0.0    0.0    1.0    0.0    302.0  0.1771117166212534   65 / 367
388.0  483.0  335.0  431.0  402.0  396.0  348.0  292.0  349.0  366.0  408.0  353.0  475.0  376.0  362.0  381.0  366.0  409.0  400.0  374.0  403.0  378.0  379.0  401.0  399.0  349.0  0.17564730580825752  1,757 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.824353
2    0.902229
3    0.935319
4    0.953314
5    0.96541
6    0.973708
7    0.978506
8    0.983305
9    0.986804
10   0.989203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17746218097255587
RMSE: 0.42126260333971716
LogLoss: 0.6208551480401745
Mean Per-Class Error: 0.17652596734239492
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13     14    15     16    17     18     19    20    21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  ----  -----  ----  -------------------  -----------
77.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0    0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   1.0   2.0   3.0    0.0   0.1348314606741573   12 / 89
0.0   86.0   0.0   1.0    2.0   1.0   1.0   2.0   1.0   0.0    1.0    0.0   0.0    0.0    0.0   1.0    0.0   4.0    3.0    0.0   0.0   2.0   0.0   1.0   0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    62.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0    6.0    0.0   0.0    0.0    2.0   0.0    0.0   0.0    2.0    2.0   1.0   0.0   1.0   0.0   0.0    0.0   0.24390243902439024  20 / 82
1.0   3.0    0.0   96.0   0.0   0.0   0.0   1.0   1.0   0.0    0.0    0.0   3.0    1.0    0.0   1.0    0.0   2.0    1.0    0.0   0.0   0.0   0.0   1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    73.0  1.0   6.0   0.0   0.0   0.0    2.0    0.0   0.0    0.0    0.0   0.0    0.0   1.0    4.0    3.0   0.0   0.0   0.0   1.0   0.0    6.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   5.0    0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    4.0   0.0   0.0   1.0   0.0   0.0    3.0    1.0   0.0    0.0    1.0   0.0    1.0   0.0    2.0    0.0   0.0   0.0   0.0   78.0  3.0    2.0   0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   2.0    2.0   0.0    0.0    1.0   0.0   6.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    5.0    1.0   0.0   0.0   0.0   1.0   0.0    73.0  0.16091954022988506  14 / 87
87.0  124.0  70.0  118.0  91.0  89.0  89.0  72.0  86.0  101.0  104.0  95.0  107.0  101.0  76.0  108.0  93.0  103.0  102.0  89.0  98.0  89.0  96.0  94.0  116.0  92.0  0.1755020080321285   437 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.824498
2    0.906024
3    0.93494
4    0.95261
5    0.963855
6    0.971486
7    0.97751
8    0.982731
9    0.985944
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:28  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:28  5 min 26.279 sec  28921 obs/sec     1         1             10007      0.543015         0.98501             0.994759       0.26632                          0.541371           0.974568              0.994778         0.26988
    2019-08-04 09:05:31  5 min 29.539 sec  28244 obs/sec     10        10            100070     0.416662         0.604964            0.996914       0.175647                         0.421263           0.620855              0.996838         0.175502
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0892345
C13         0.973727               0.973727             0.08689
C9          0.873279               0.873279             0.0779266
C12         0.842367               0.842367             0.0751682
C8          0.803322               0.803322             0.071684
C7          0.791431               0.791431             0.0706229
C11         0.727579               0.727579             0.0649251
C14         0.694032               0.694032             0.0619316
C10         0.675865               0.675865             0.0603105
C6          0.638437               0.638437             0.0569705
C16         0.617812               0.617812             0.0551301
C5          0.595032               0.595032             0.0530973
C3          0.583922               0.583922             0.052106
C4          0.552091               0.552091             0.0492655
C2          0.435042               0.435042             0.0388208
C1          0.402494               0.402494             0.0359163
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_69

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0020712556190858322  0.0004693131195381284  0.0         0.0121550581708183    0.4256923198699951  0.08591653534483579  0.4987034797668457
    3        26       Softmax                 0.0   0.0   0.002191946614804972   0.0005533115472644567  0.0         -0.00122647704358332  0.2904396057128906  -0.5957892580817812  0.20565587282180786


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17341855698198988
RMSE: 0.4164355376069505
LogLoss: 0.5994923614734816
Mean Per-Class Error: 0.17454778323317902
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    3.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    2.0    2.0    6.0    1.0    0.08607594936708861  34 / 395
0.0    327.0  0.0    4.0    3.0    0.0    1.0    10.0   3.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    2.0    16.0   10.0   0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.1462140992167102   56 / 383
0.0    0.0    294.0  1.0    16.0   2.0    10.0   2.0    0.0    0.0    23.0   1.0    0.0    0.0    2.0    0.0    1.0    0.0    7.0    2.0    2.0    0.0    5.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
1.0    23.0   0.0    338.0  0.0    0.0    0.0    9.0    0.0    1.0    1.0    0.0    7.0    3.0    2.0    2.0    0.0    6.0    2.0    1.0    1.0    0.0    0.0    4.0    0.0    2.0    0.16129032258064516  65 / 403
0.0    9.0    0.0    0.0    308.0  6.0    8.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    2.0    9.0    5.0    13.0   3.0    0.0    0.0    0.0    4.0    0.0    12.0   0.195822454308094    75 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    23.0   0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    5.0    0.0    5.0    4.0    1.0    0.0    1.0    3.0    1.0    8.0    1.0    0.0    0.0    2.0    0.0    5.0    0.0    5.0    2.0    2.0    0.0    0.0    336.0  9.0    4.0    0.14720812182741116  58 / 394
1.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    2.0    13.0   3.0    6.0    1.0    1.0    353.0  0.0    0.10178117048346055  40 / 393
1.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    26.0   3.0    0.0    0.0    0.0    4.0    0.0    313.0  0.1448087431693989   53 / 366
403.0  498.0  325.0  413.0  391.0  374.0  323.0  341.0  329.0  354.0  392.0  347.0  467.0  371.0  406.0  386.0  361.0  410.0  378.0  387.0  395.0  362.0  384.0  403.0  428.0  375.0  0.1736479056283115   1,737 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826352
2    0.902929
3    0.93442
4    0.954814
5    0.96731
6    0.974808
7    0.979606
8    0.983805
9    0.986404
10   0.989703

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17926696887194404
RMSE: 0.423399301926614
LogLoss: 0.621443174289041
Mean Per-Class Error: 0.17772520185425197
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0   1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   1.0    2.0   0.0   1.0   6.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0   5.0    3.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    65.0  0.0    2.0   1.0   2.0   1.0   0.0   0.0    4.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    2.0   2.0   0.0    0.0   2.0   0.0   0.0    0.0   0.2073170731707317   17 / 82
1.0   3.0    0.0   93.0   0.0   0.0   0.0   4.0   0.0   0.0    1.0   0.0   3.0    1.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0    2.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    70.0  4.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    4.0   2.0   0.0    0.0   0.0   2.0   0.0    6.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   6.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   2.0    3.0   0.0   0.0   1.0   1.0   0.0    3.0   1.0   0.0    0.0   0.0   0.0    1.0   0.0    2.0   0.0   0.0    0.0   0.0   80.0  3.0    1.0   0.2                  20 / 100
1.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    3.0   0.0    0.0   2.0   1.0    2.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    4.0   1.0   0.0    0.0   0.0   3.0   0.0    75.0  0.13793103448275862  12 / 87
94.0  117.0  67.0  117.0  87.0  94.0  85.0  94.0  78.0  100.0  97.0  90.0  105.0  98.0  84.0  108.0  91.0  100.0  99.0  88.0  100.0  84.0  96.0  99.0  121.0  97.0  0.17791164658634537  443 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822088
2    0.902008
3    0.934538
4    0.956627
5    0.965863
6    0.972691
7    0.979116
8    0.984337
9    0.986747
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:55  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:55  1 min 53.259 sec  29174 obs/sec     1         1             10007      0.54535          0.985281            0.994714       0.273018                         0.544391           0.980403              0.994719         0.277912
    2019-08-04 09:01:58  1 min 56.454 sec  28739 obs/sec     10        10            100070     0.416436         0.599492            0.996918       0.173648                         0.423399           0.621443              0.996806         0.177912
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0910951
C13         0.948795               0.948795             0.0864305
C9          0.851393               0.851393             0.0775577
C12         0.851118               0.851118             0.0775326
C8          0.793415               0.793415             0.0722762
C7          0.772431               0.772431             0.0703647
C11         0.731533               0.731533             0.066639
C14         0.657366               0.657366             0.0598827
C10         0.632533               0.632533             0.0576206
C6          0.618622               0.618622             0.0563534
C16         0.589748               0.589748             0.0537231
C3          0.574135               0.574135             0.0523008
C5          0.563111               0.563111             0.0512966
C4          0.549206               0.549206             0.0500299
C2          0.440411               0.440411             0.0401192
C1          0.403729               0.403729             0.0367777
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_168

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0019344873680751107  0.00044562353286892176  0.0         0.0022833107010111764  0.42538440227508545  0.006084763890635163  0.4942624568939209
    3        26       Softmax                 0.0   0.0   0.0021967581001088267  0.0006444060709327459   0.0         -0.00612853137698202   0.29441070556640625  -0.5853160297001777   0.20941734313964844


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17296040734160803
RMSE: 0.415885089107085
LogLoss: 0.604702458249457
Mean Per-Class Error: 0.17614237182651232
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    6.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    0.0    2.0    2.0    5.0    2.0    0.09113924050632911  36 / 395
0.0    314.0  0.0    5.0    3.0    2.0    2.0    7.0    3.0    0.0    4.0    1.0    1.0    0.0    0.0    2.0    1.0    20.0   8.0    0.0    1.0    4.0    0.0    4.0    1.0    0.0    0.1801566579634465   69 / 383
0.0    0.0    300.0  0.0    12.0   1.0    8.0    1.0    0.0    0.0    21.0   1.0    0.0    0.0    4.0    0.0    4.0    0.0    7.0    3.0    4.0    0.0    2.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
4.0    22.0   0.0    341.0  0.0    0.0    0.0    3.0    2.0    1.0    4.0    0.0    7.0    4.0    2.0    0.0    0.0    10.0   1.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.15384615384615385  62 / 403
0.0    5.0    1.0    0.0    302.0  4.0    13.0   0.0    1.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    6.0    4.0    12.0   5.0    0.0    0.0    0.0    5.0    0.0    18.0   0.21354166666666666  82 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    13.0   0.0    4.0    0.0    0.0    5.0    0.0    0.0    3.0    3.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    3.0    0.0    4.0    5.0    1.0    0.0    7.0    5.0    2.0    11.0   2.0    0.0    0.0    2.0    0.0    5.0    2.0    2.0    2.0    2.0    0.0    0.0    332.0  5.0    2.0    0.15736040609137056  62 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    6.0    0.0    2.0    15.0   0.0    18.0   1.0    1.0    340.0  0.0    0.13486005089058525  53 / 393
0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    1.0    21.0   4.0    0.0    0.0    0.0    0.0    0.0    320.0  0.12806539509536785  47 / 367
393.0  449.0  335.0  420.0  386.0  367.0  348.0  322.0  349.0  352.0  407.0  354.0  448.0  376.0  383.0  376.0  368.0  445.0  365.0  397.0  404.0  366.0  402.0  407.0  393.0  391.0  0.17534739578126562  1,754 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.824653
2    0.90033
3    0.936119
4    0.952214
5    0.96551
6    0.973508
7    0.978606
8    0.983105
9    0.986504
10   0.990003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17826433349905815
RMSE: 0.42221361121955575
LogLoss: 0.6232642509085753
Mean Per-Class Error: 0.18117443041376063
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0    0.0898876404494382   8 / 89
0.0   82.0   0.0   0.0    3.0   0.0   1.0   2.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   1.0    0.0   8.0    2.0   0.0   1.0    3.0   0.0    1.0   0.0    0.0    0.22641509433962265  24 / 106
0.0   0.0    64.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0    2.0   0.0    1.0   0.0    3.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0    0.21951219512195122  18 / 82
3.0   5.0    0.0   93.0   0.0   0.0   0.0   2.0   1.0   0.0   2.0    0.0   3.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    70.0  2.0   5.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   3.0   0.0    0.0   0.0    0.0   0.0    9.0    0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   1.0    0.0   1.0    3.0   0.0   0.0   4.0   2.0   0.0   4.0    2.0   0.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   1.0    0.0   0.0    76.0  2.0    1.0    0.24                 24 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0    3.0   0.0    0.0   4.0   0.0    6.0   1.0    0.0   91.0   0.0    0.14953271028037382  16 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    77.0   0.11494252873563218  10 / 87
91.0  115.0  70.0  115.0  89.0  91.0  87.0  81.0  88.0  98.0  104.0  95.0  98.0  101.0  81.0  103.0  95.0  108.0  89.0  96.0  106.0  83.0  100.0  91.0  114.0  101.0  0.18152610441767067  452 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818474
2    0.895181
3    0.935341
4    0.952209
5    0.964659
6    0.973896
7    0.980723
8    0.985542
9    0.988755
10   0.990361
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:51  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:51  4 min 49.435 sec  28591 obs/sec     1         1             10007      0.542185         0.989615            0.994777       0.264421                         0.542              0.989379              0.994766         0.276707
    2019-08-04 09:04:54  4 min 52.536 sec  29475 obs/sec     10        10            100070     0.415885         0.604702            0.996927       0.175347                         0.422214           0.623264              0.996824         0.181526
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0878761
C13         0.939191               0.939191             0.0825324
C12         0.878823               0.878823             0.0772275
C9          0.856041               0.856041             0.0752255
C7          0.806734               0.806734             0.0708926
C11         0.799355               0.799355             0.0702442
C8          0.780792               0.780792             0.0686129
C10         0.721542               0.721542             0.0634062
C14         0.679673               0.679673             0.059727
C6          0.635028               0.635028             0.0558038
C16         0.60714                0.60714              0.0533531
C3          0.604158               0.604158             0.053091
C5          0.59955                0.59955              0.0526861
C4          0.56884                0.56884              0.0499874
C1          0.456907               0.456907             0.0401512
C2          0.445891               0.445891             0.0391831
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_2

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0018937782945585013  0.0004700453719124198  0.0         0.00505380034922176    0.4212620258331299   0.014668762752758252  0.4583076238632202
    3        26       Softmax                 0.0   0.0   0.0021142956402749966  0.0005340231582522392  0.0         0.0003616600099308497  0.28986823558807373  -0.6110310507674525   0.24741250276565552


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17526381475812222
RMSE: 0.4186452134661547
LogLoss: 0.6110136398676562
Mean Per-Class Error: 0.17871757818621245
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    2.0    0.0    2.0    0.0    0.0    1.0    5.0    3.0    1.0    0.0    2.0    1.0    6.0    1.0    0.0759493670886076   30 / 395
0.0    320.0  0.0    3.0    4.0    0.0    2.0    6.0    4.0    0.0    1.0    0.0    1.0    0.0    1.0    4.0    0.0    19.0   10.0   0.0    0.0    3.0    0.0    2.0    2.0    1.0    0.16449086161879894  63 / 383
0.0    0.0    295.0  0.0    13.0   2.0    14.0   1.0    0.0    0.0    23.0   0.0    0.0    0.0    1.0    0.0    3.0    0.0    7.0    2.0    4.0    0.0    2.0    0.0    0.0    0.0    0.19618528610354224  72 / 367
2.0    15.0   0.0    351.0  0.0    1.0    0.0    4.0    1.0    2.0    0.0    0.0    5.0    6.0    5.0    2.0    0.0    4.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.12903225806451613  52 / 403
0.0    3.0    2.0    0.0    314.0  3.0    11.0   0.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    1.0    7.0    4.0    12.0   4.0    0.0    0.0    0.0    3.0    0.0    13.0   0.18229166666666666  70 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    12.0   0.0    1.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    0.0    0.0    11.0   7.0    0.0    0.0    3.0    5.0    2.0    7.0    3.0    0.0    0.0    2.0    0.0    5.0    1.0    1.0    2.0    1.0    0.0    0.0    335.0  3.0    6.0    0.14974619289340102  59 / 394
0.0    0.0    0.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    2.0    14.0   2.0    26.0   1.0    1.0    331.0  0.0    0.15776081424936386  62 / 393
0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    24.0   3.0    0.0    0.0    0.0    0.0    0.0    307.0  0.16348773841961853  60 / 367
414.0  434.0  352.0  444.0  422.0  333.0  344.0  316.0  341.0  360.0  382.0  356.0  410.0  390.0  385.0  420.0  361.0  436.0  371.0  390.0  399.0  381.0  420.0  383.0  391.0  368.0  0.17774667599720084  1,778 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822253
2    0.90043
3    0.93282
4    0.952014
5    0.964611
6    0.972708
7    0.978207
8    0.982605
9    0.986004
10   0.989003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18101095944851223
RMSE: 0.4254538276341068
LogLoss: 0.6301171584793943
Mean Per-Class Error: 0.18882897728540132
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.056179775280898875  5 / 89
0.0   82.0   0.0   0.0    2.0   0.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   2.0    0.0   7.0    3.0   0.0   0.0    2.0   0.0    1.0   1.0    0.0   0.22641509433962265   24 / 106
0.0   0.0    63.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0   0.23170731707317074   19 / 82
2.0   3.0    0.0   94.0   0.0   0.0   0.0   3.0   1.0   0.0    0.0   0.0   1.0   3.0    1.0   2.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.16071428571428573   18 / 112
0.0   0.0    0.0   0.0    74.0  2.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    4.0   2.0   0.0    0.0   0.0    0.0   0.0    6.0   0.23711340206185566   23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914   7 / 92
0.0   0.0    0.0   4.0    4.0   0.0   0.0   1.0   1.0   0.0    3.0   2.0   0.0   0.0    0.0   0.0    1.0   1.0    0.0   0.0   0.0    0.0   0.0    79.0  1.0    3.0   0.21                  21 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0   0.0    0.0   5.0   0.0    9.0   1.0    0.0   87.0   0.0   0.18691588785046728   20 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   1.0   0.0    0.0   0.0    0.0   0.0    72.0  0.1724137931034483    15 / 87
99.0  104.0  75.0  121.0  99.0  75.0  87.0  82.0  82.0  101.0  94.0  98.0  93.0  101.0  78.0  120.0  96.0  110.0  96.0  95.0  101.0  88.0  103.0  89.0  110.0  93.0  0.18755020080321286   467 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.81245
2    0.899197
3    0.93253
4    0.951004
5    0.964257
6    0.970683
7    0.977109
8    0.982329
9    0.987149
10   0.988353
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:06  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:07  5.725 sec   26614 obs/sec     1         1             10007      0.548082         0.989081            0.994662       0.270519                         0.546359           0.978006              0.994681         0.272691
    2019-08-04 09:00:12  10.038 sec  21632 obs/sec     10        10            100070     0.418645         0.611014            0.996885       0.177747                         0.425454           0.630117              0.996775         0.18755
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0906313
C15         0.977486               0.977486             0.0885909
C9          0.873942               0.873942             0.0792066
C12         0.83905                0.83905              0.0760442
C8          0.79081                0.79081              0.0716722
C7          0.754736               0.754736             0.0684027
C11         0.733611               0.733611             0.0664881
C14         0.645309               0.645309             0.0584853
C10         0.643282               0.643282             0.0583015
C6          0.616381               0.616381             0.0558634
C3          0.587818               0.587818             0.0532748
C5          0.579008               0.579008             0.0524763
C4          0.573335               0.573335             0.0519621
C16         0.552624               0.552624             0.050085
C2          0.434228               0.434228             0.0393547
C1          0.43209                0.43209              0.0391609
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_194

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009145147814422216  0.000224991119466722  0.0         -0.018423343309621032  0.23966962099075317  0.09552066389196105  0.1828901767730713
    3        26       Softmax                      0.0   0.0   0.006023952677948658   0.015573352575302124  0.0         -0.3010182914042966    0.7370281219482422   -0.5964185791314154  0.388500452041626


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.19941833778155324
RMSE: 0.4465628038490815
LogLoss: 0.640500066004258
Mean Per-Class Error: 0.17781144329736015
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
345.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    2.0    2.0    11.0   0.0    2.0    1.0    4.0    0.0    6.0    3.0    4.0    2.0    0.0    3.0    2.0    0.0    0.12436548223350254  49 / 394
0.0    328.0  0.0    3.0    2.0    0.0    8.0    7.0    2.0    0.0    2.0    0.0    0.0    0.0    2.0    2.0    0.0    17.0   1.0    0.0    0.0    3.0    1.0    3.0    2.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    298.0  1.0    7.0    0.0    19.0   1.0    0.0    0.0    24.0   1.0    2.0    0.0    5.0    0.0    1.0    0.0    5.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
0.0    29.0   0.0    329.0  0.0    0.0    2.0    2.0    0.0    4.0    0.0    0.0    6.0    5.0    5.0    3.0    0.0    6.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    6.0    0.18362282878411912  74 / 403
0.0    11.0   0.0    0.0    298.0  9.0    18.0   1.0    0.0    0.0    9.0    2.0    0.0    0.0    0.0    0.0    4.0    2.0    14.0   2.0    0.0    0.0    0.0    4.0    0.0    10.0   0.22395833333333334  86 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    2.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    2.0    0.0    7.0    7.0    0.0    0.0    1.0    2.0    2.0    6.0    2.0    0.0    0.0    2.0    0.0    0.0    1.0    3.0    2.0    5.0    1.0    0.0    345.0  1.0    5.0    0.12436548223350254  49 / 394
0.0    0.0    0.0    2.0    1.0    4.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    5.0    7.0    1.0    18.0   1.0    0.0    348.0  0.0    0.11450381679389313  45 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    26.0   3.0    0.0    0.0    0.0    1.0    0.0    303.0  0.1721311475409836   63 / 366
368.0  489.0  332.0  407.0  375.0  367.0  358.0  367.0  330.0  373.0  384.0  360.0  437.0  357.0  399.0  393.0  379.0  406.0  368.0  367.0  395.0  374.0  427.0  400.0  400.0  391.0  0.17714685594321702  1,772 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822853
2    0.89893
3    0.93202
4    0.951215
5    0.963411
6    0.973608
7    0.980306
8    0.985304
9    0.988903
10   0.991003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20283276370749506
RMSE: 0.4503695856821318
LogLoss: 0.6462081351095921
Mean Per-Class Error: 0.18472351549273028
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   1.0   1.0   0.0    1.0   2.0    0.0    0.11235955056179775  10 / 89
0.0   83.0   0.0   0.0    1.0   0.0   2.0   4.0   1.0   0.0    1.0   0.0   0.0   0.0   1.0   1.0    0.0    6.0    0.0   0.0   0.0   3.0   1.0    1.0   1.0    0.0    0.2169811320754717   23 / 106
0.0   0.0    61.0  0.0    1.0   0.0   7.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    3.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.25609756097560976  21 / 82
0.0   6.0    0.0   93.0   0.0   0.0   1.0   2.0   0.0   2.0    0.0   0.0   2.0   2.0   2.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0    0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    70.0  5.0   6.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0    3.0   1.0   0.0   0.0   0.0    2.0   0.0    4.0    0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0   1.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    3.0   0.0   0.0   1.0   0.0   0.0    2.0   2.0   0.0   0.0   0.0   0.0    0.0    1.0    1.0   0.0   1.0   0.0   0.0    85.0  0.0    1.0    0.15                 15 / 100
0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   2.0   0.0   6.0   1.0    0.0   96.0   0.0    0.102803738317757    11 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0   0.0   0.0    1.0    0.0    5.0   1.0   0.0   0.0   0.0    0.0   0.0    72.0   0.1724137931034483   15 / 87
85.0  121.0  68.0  109.0  89.0  86.0  90.0  98.0  79.0  106.0  95.0  99.0  99.0  95.0  87.0  110.0  100.0  102.0  84.0  87.0  97.0  85.0  104.0  97.0  118.0  100.0  0.18393574297188756  458 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816064
2    0.898795
3    0.928514
4    0.951004
5    0.963052
6    0.973494
7    0.978715
8    0.983936
9    0.987149
10   0.990763
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:45  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:45  5 min 43.000 sec  119130 obs/sec    1         1             10007      0.634294         1.21135             0.992849       0.316305                         0.637818           1.22406               0.992751         0.319277
    2019-08-04 09:05:45  5 min 43.703 sec  130299 obs/sec    10        10            100070     0.446563         0.6405              0.996455       0.177147                         0.45037            0.646208              0.996386         0.183936
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0938803
C13         0.882819               0.882819             0.0828793
C12         0.820194               0.820194             0.0770001
C9          0.80131                0.80131              0.0752272
C8          0.769485               0.769485             0.0722395
C7          0.757892               0.757892             0.0711511
C11         0.703555               0.703555             0.06605
C5          0.642119               0.642119             0.0602823
C6          0.592098               0.592098             0.0555864
C10         0.588174               0.588174             0.0552179
C3          0.585968               0.585968             0.0550109
C14         0.580356               0.580356             0.054484
C16         0.542273               0.542273             0.0509088
C4          0.490242               0.490242             0.0460241
C1          0.459808               0.459808             0.0431669
C2          0.435567               0.435567             0.0408912
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_52

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009524909135905091  0.00022614089539274573  0.0         -0.01636091790602734  0.2356431484222412  0.12118860508168963  0.19467347860336304
    3        26       Softmax                      0.0   0.0   0.006572455647983588   0.015658006072044373    0.0         -0.29643303522957115  0.7441585063934326  -0.5928713734878539  0.34899353981018066


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.19990718962940507
RMSE: 0.44710981831022795
LogLoss: 0.6382747579380394
Mean Per-Class Error: 0.17913153654797215
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    2.0    1.0    8.0    1.0    1.0    0.0    0.0    0.0    10.0   1.0    2.0    0.0    2.0    1.0    5.0    0.0    0.09620253164556962  38 / 395
0.0    320.0  0.0    7.0    4.0    4.0    1.0    8.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    6.0    4.0    15.0   3.0    0.0    0.0    3.0    0.0    3.0    1.0    0.0    0.16449086161879894  63 / 383
0.0    1.0    305.0  0.0    20.0   0.0    4.0    0.0    0.0    0.0    18.0   0.0    2.0    0.0    3.0    0.0    4.0    0.0    6.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
2.0    11.0   0.0    340.0  0.0    0.0    1.0    6.0    0.0    2.0    1.0    0.0    3.0    5.0    2.0    6.0    1.0    12.0   5.0    0.0    1.0    0.0    0.0    4.0    0.0    0.0    0.15422885572139303  62 / 402
0.0    11.0   2.0    0.0    310.0  3.0    8.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    8.0    4.0    8.0    3.0    0.0    0.0    0.0    5.0    0.0    16.0   0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    10.0   2.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    348.0  0.0    0.0    0.0    0.072                27 / 375
0.0    2.0    0.0    6.0    8.0    0.0    0.0    0.0    2.0    1.0    7.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    4.0    3.0    1.0    0.0    0.0    345.0  1.0    10.0   0.12436548223350254  49 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    4.0    14.0   2.0    40.0   1.0    0.0    316.0  0.0    0.19592875318066158  77 / 393
0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    29.0   1.0    0.0    0.0    0.0    0.0    0.0    308.0  0.15846994535519127  58 / 366
397.0  446.0  367.0  429.0  409.0  356.0  311.0  350.0  348.0  356.0  385.0  356.0  422.0  394.0  409.0  404.0  343.0  418.0  360.0  374.0  389.0  392.0  414.0  420.0  371.0  383.0  0.17844646606018194  1,785 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.821554
2    0.90093
3    0.93232
4    0.950815
5    0.96541
6    0.973608
7    0.980306
8    0.983905
9    0.987204
10   0.989403

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2029546876292622
RMSE: 0.45050492519978313
LogLoss: 0.6467525635600406
Mean Per-Class Error: 0.1846625051038209
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22    23     24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0   1.0    3.0    0.0    0.10112359550561797  9 / 89
0.0   81.0   0.0   1.0    2.0    1.0   1.0   5.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   6.0    1.0   0.0   0.0   3.0   0.0   1.0    0.0    0.0    0.2358490566037736   25 / 106
0.0   0.0    67.0  0.0    5.0    0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    0.18292682926829268  15 / 82
2.0   0.0    0.0   93.0   0.0    0.0   0.0   2.0   0.0   0.0    1.0   0.0   1.0   3.0    0.0   3.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0    0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    76.0   2.0   1.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0    7.0    0.21649484536082475  21 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   87.0  0.0    0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    4.0    0.0   0.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0    1.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   85.0   0.0    3.0    0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   2.0   0.0   13.0  1.0   0.0    87.0   0.0    0.18691588785046728  20 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   0.0   0.0   0.0   0.0   0.0    0.0    74.0   0.14942528735632185  13 / 87
95.0  105.0  77.0  116.0  101.0  85.0  76.0  96.0  86.0  100.0  96.0  95.0  91.0  106.0  80.0  116.0  97.0  102.0  86.0  84.0  97.0  93.0  99.0  102.0  109.0  100.0  0.18473895582329317  460 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.815261
2    0.900803
3    0.931325
4    0.950201
5    0.96506
6    0.974297
7    0.981526
8    0.984337
9    0.986747
10   0.989157
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:36  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:36  1 min 33.930 sec  111188 obs/sec    1         1             10007      0.653582         1.28618             0.992407       0.335199                         0.65468            1.28762               0.992363         0.340964
    2019-08-04 09:01:36  1 min 34.647 sec  127640 obs/sec    10        10            100070     0.44711          0.638275            0.996447       0.178446                         0.450505           0.646753              0.996384         0.184739
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0883595
C13         0.933051               0.933051             0.0824439
C9          0.885135               0.885135             0.0782101
C11         0.823114               0.823114             0.07273
C7          0.813595               0.813595             0.0718889
C8          0.787505               0.787505             0.0695836
C12         0.76142                0.76142              0.0672787
C6          0.699217               0.699217             0.0617825
C5          0.676029               0.676029             0.0597336
C10         0.636428               0.636428             0.0562345
C14         0.634134               0.634134             0.0560318
C3          0.58062                0.58062              0.0513033
C4          0.573317               0.573317             0.050658
C16         0.532491               0.532491             0.0470507
C1          0.504911               0.504911             0.0446137
C2          0.476434               0.476434             0.0420975
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_189

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.00091397734283305    0.00022128195269033313  0.0         -0.006687211575595597  0.2373097538948059  0.10952910442470808  0.16869229078292847
    3        26       Softmax                      0.0   0.0   0.0073912973783500585  0.030604951083660126    0.0         -0.2813929402901924    0.7384793758392334  -0.6136614828244666  0.37881481647491455


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20384498032909731
RMSE: 0.45149194935136694
LogLoss: 0.647683126131005
Mean Per-Class Error: 0.18149532145903874
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    5.0    1.0    3.0    0.0    4.0    0.0    1.0    0.0    5.0    0.0    3.0    1.0    2.0    3.0    4.0    0.0    0.09367088607594937  37 / 395
0.0    327.0  0.0    2.0    1.0    0.0    1.0    8.0    2.0    0.0    0.0    1.0    0.0    0.0    4.0    5.0    0.0    17.0   8.0    0.0    0.0    3.0    0.0    2.0    2.0    0.0    0.1462140992167102   56 / 383
0.0    0.0    299.0  0.0    15.0   2.0    11.0   1.0    0.0    0.0    18.0   1.0    1.0    0.0    2.0    0.0    0.0    0.0    4.0    3.0    8.0    0.0    3.0    0.0    0.0    0.0    0.1875               69 / 368
3.0    19.0   0.0    342.0  0.0    0.0    0.0    3.0    0.0    3.0    0.0    1.0    7.0    6.0    3.0    3.0    0.0    3.0    4.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    0.1513647642679901   61 / 403
0.0    8.0    1.0    0.0    317.0  2.0    13.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    4.0    3.0    8.0    7.0    0.0    0.0    0.0    4.0    0.0    12.0   0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    348.0  0.0    0.0    0.0    0.072                27 / 375
0.0    3.0    0.0    5.0    7.0    0.0    0.0    0.0    2.0    1.0    9.0    1.0    0.0    1.0    2.0    0.0    1.0    3.0    7.0    7.0    0.0    0.0    0.0    343.0  0.0    2.0    0.12944162436548223  51 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    10.0   0.0    3.0    14.0   1.0    8.0    1.0    0.0    345.0  0.0    0.11989795918367346  47 / 392
3.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    23.0   2.0    0.0    0.0    0.0    1.0    0.0    308.0  0.15846994535519127  58 / 366
410.0  509.0  328.0  416.0  411.0  327.0  371.0  348.0  348.0  342.0  373.0  349.0  425.0  393.0  395.0  418.0  335.0  397.0  337.0  394.0  404.0  352.0  421.0  423.0  399.0  378.0  0.18054583624912526  1,806 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.819454
2    0.896331
3    0.930821
4    0.951315
5    0.964411
6    0.972608
7    0.979606
8    0.984305
9    0.987604
10   0.990103

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20671561559683155
RMSE: 0.4546598900242153
LogLoss: 0.6554707021043147
Mean Per-Class Error: 0.18647535991116265
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9     10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.0   0.0   1.0   1.0    2.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   81.0   0.0   0.0    1.0   0.0   1.0    4.0   1.0   0.0   0.0   0.0   0.0   0.0    2.0   2.0    0.0   5.0    4.0   0.0   0.0   3.0   0.0    2.0    0.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    62.0  0.0    4.0   0.0   5.0    1.0   0.0   0.0   3.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    3.0   1.0   1.0   0.0   1.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
2.0   1.0    0.0   95.0   0.0   0.0   0.0    2.0   0.0   1.0   0.0   1.0   3.0   1.0    1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0    2.0    0.0    1.0   0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    75.0  1.0   4.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   3.0   0.0   0.0   0.0    2.0    0.0    5.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0    0.0   0.0   0.0   4.0   1.0   0.0   0.0    0.0   0.0    0.0   3.0    4.0   1.0   0.0   0.0   0.0    81.0   0.0    1.0   0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    4.0   0.0    0.0   3.0   0.0   1.0   1.0    0.0    96.0   0.0   0.102803738317757    11 / 107
2.0   0.0    0.0   0.0    5.0   0.0   0.0    0.0   0.0   2.0   0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   1.0   0.0   0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
96.0  118.0  66.0  115.0  94.0  73.0  100.0  86.0  87.0  97.0  93.0  95.0  94.0  101.0  82.0  119.0  91.0  100.0  90.0  96.0  99.0  76.0  104.0  105.0  117.0  96.0  0.18473895582329317  460 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.815261
2    0.895582
3    0.926104
4    0.951807
5    0.963454
6    0.972289
7    0.977108
8    0.983936
9    0.987952
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:36  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:36  5 min 33.860 sec  115022 obs/sec    1         1             10007      0.640392         1.23936             0.992709       0.314006                         0.640275           1.24247               0.992695         0.318876
    2019-08-04 09:05:36  5 min 34.567 sec  128956 obs/sec    10        10            100070     0.451492         0.647683            0.996376       0.180546                         0.45466            0.655471              0.996317         0.184739
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0866104
C15         0.990565               0.990565             0.0857932
C8          0.912058               0.912058             0.0789937
C7          0.854004               0.854004             0.0739656
C9          0.834334               0.834334             0.072262
C12         0.784183               0.784183             0.0679184
C10         0.75979                0.75979              0.0658057
C11         0.75322                0.75322              0.0652367
C6          0.689058               0.689058             0.0596796
C14         0.644867               0.644867             0.0558522
C5          0.643684               0.643684             0.0557498
C4          0.628855               0.628855             0.0544654
C3          0.575768               0.575768             0.0498675
C16         0.529234               0.529234             0.0458372
C2          0.476986               0.476986             0.041312
C1          0.469349               0.469349             0.0406505
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_199

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009610925432355089  0.00024094252148643136  0.0         -0.019416714658206047  0.23974919319152832  0.11538705700163591  0.17336243391036987
    3        26       Softmax                      0.0   0.0   0.007198693112933632   0.02339278906583786     0.0         -0.29386583749388034   0.7371664047241211   -0.5982105874383077  0.42118704319000244


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20374317832919386
RMSE: 0.45137919572039853
LogLoss: 0.6514894277419354
Mean Per-Class Error: 0.18214665970099508
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    6.0    1.0    3.0    0.0    6.0    0.0    1.0    0.0    4.0    1.0    1.0    1.0    4.0    1.0    4.0    0.0    0.08860759493670886  35 / 395
0.0    344.0  0.0    5.0    1.0    2.0    1.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    14.0   4.0    0.0    0.0    2.0    0.0    3.0    1.0    0.0    0.10182767624020887  39 / 383
0.0    0.0    300.0  0.0    6.0    0.0    17.0   1.0    0.0    0.0    28.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    6.0    2.0    2.0    0.0    2.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
0.0    20.0   0.0    334.0  0.0    0.0    1.0    7.0    0.0    6.0    0.0    0.0    7.0    2.0    4.0    0.0    2.0    7.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    9.0    0.1691542288557214   68 / 402
0.0    5.0    4.0    0.0    298.0  4.0    20.0   1.0    0.0    1.0    3.0    1.0    0.0    0.0    1.0    0.0    1.0    3.0    10.0   3.0    0.0    0.0    0.0    7.0    0.0    22.0   0.22395833333333334  86 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    1.0    0.0    14.0   0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    8.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
1.0    1.0    0.0    3.0    1.0    0.0    0.0    3.0    2.0    3.0    9.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    8.0    8.0    2.0    0.0    0.0    334.0  4.0    5.0    0.15228426395939088  60 / 394
0.0    0.0    0.0    2.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    9.0    0.0    6.0    16.0   2.0    10.0   1.0    1.0    333.0  0.0    0.15267175572519084  60 / 393
2.0    0.0    0.0    1.0    14.0   0.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    18.0   3.0    0.0    0.0    0.0    3.0    0.0    304.0  0.17166212534059946  63 / 367
406.0  512.0  339.0  413.0  358.0  366.0  409.0  290.0  334.0  350.0  405.0  349.0  415.0  387.0  427.0  372.0  347.0  420.0  328.0  393.0  382.0  379.0  409.0  416.0  395.0  402.0  0.18124562631210636  1,813 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818754
2    0.898331
3    0.930721
4    0.948315
5    0.961412
6    0.971409
7    0.977607
8    0.982705
9    0.987104
10   0.990003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2056217715402935
RMSE: 0.4534553688515481
LogLoss: 0.6567529074514183
Mean Per-Class Error: 0.18113837355057066
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   3.0    0.0    2.0    0.0    0.0898876404494382   8 / 89
0.0   89.0   0.0   0.0    1.0   1.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0   5.0    3.0   0.0   0.0   2.0   0.0    2.0    0.0    0.0    0.16037735849056603  17 / 106
0.0   0.0    64.0  0.0    1.0   0.0   4.0    0.0   0.0   0.0    6.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    3.0   1.0   0.0   0.0   0.0    0.0    0.0    0.0    0.21951219512195122  18 / 82
0.0   5.0    0.0   93.0   0.0   0.0   0.0    3.0   0.0   3.0    0.0   0.0   3.0   1.0    0.0   0.0    2.0   1.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0    0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    71.0  2.0   7.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0   1.0   0.0   0.0   0.0    1.0    0.0    10.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   1.0   85.0   0.0    0.0    0.0    0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0    2.0   1.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    2.0   1.0   0.0   0.0   0.0    83.0   0.0    2.0    0.17                 17 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   3.0    3.0   0.0    1.0   3.0   0.0   3.0   1.0    0.0    91.0   0.0    0.14953271028037382  16 / 107
0.0   0.0    0.0   1.0    4.0   0.0   0.0    0.0   0.0   7.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0   0.0   0.0    1.0    0.0    72.0   0.1724137931034483   15 / 87
92.0  127.0  69.0  114.0  82.0  85.0  100.0  74.0  80.0  106.0  98.0  95.0  93.0  103.0  92.0  106.0  94.0  107.0  87.0  87.0  94.0  84.0  102.0  103.0  113.0  103.0  0.18072289156626506  450 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.819277
2    0.897992
3    0.930522
4    0.950602
5    0.962249
6    0.971084
7    0.977912
8    0.981526
9    0.986747
10   0.987952
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:52  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:52  5 min 50.390 sec  113715 obs/sec    1         1             10007      0.646254         1.27824             0.992578       0.327902                         0.647576           1.28591               0.992528         0.329719
    2019-08-04 09:05:53  5 min 51.104 sec  127640 obs/sec    10        10            100070     0.451379         0.651489            0.996379       0.181246                         0.453455           0.656753              0.996336         0.180723
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0875402
C15         0.937938               0.937938             0.0821073
C9          0.904719               0.904719             0.0791993
C8          0.899927               0.899927             0.0787798
C12         0.863334               0.863334             0.0755764
C7          0.752882               0.752882             0.0659074
C11         0.685152               0.685152             0.0599784
C5          0.679865               0.679865             0.0595155
C14         0.656838               0.656838             0.0574997
C4          0.65014                0.65014              0.0569133
C16         0.633646               0.633646             0.0554694
C6          0.630603               0.630603             0.0552031
C10         0.625542               0.625542             0.05476
C3          0.576353               0.576353             0.050454
C2          0.473271               0.473271             0.0414302
C1          0.453118               0.453118             0.039666
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_206

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009264527195114169  0.0002432381152175367  0.0         -0.005862965521470587  0.23983627557754517  0.10524665732116961  0.19981276988983154
    3        26       Softmax                      0.0   0.0   0.006064878055055418   0.01637209951877594    0.0         -0.2773598025559155    0.7332470417022705   -0.6034864748106338  0.3806893825531006


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20292208778677034
RMSE: 0.45046874229714357
LogLoss: 0.6485174971866121
Mean Per-Class Error: 0.18174181779352344
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    3.0    3.0    0.0    8.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    3.0    4.0    5.0    0.0    0.09873417721518987  39 / 395
0.0    328.0  0.0    9.0    3.0    0.0    1.0    2.0    2.0    0.0    3.0    0.0    0.0    0.0    2.0    1.0    0.0    18.0   8.0    0.0    0.0    1.0    1.0    3.0    1.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    303.0  0.0    15.0   0.0    13.0   1.0    0.0    0.0    18.0   2.0    0.0    0.0    7.0    1.0    1.0    0.0    1.0    5.0    0.0    0.0    1.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
0.0    31.0   0.0    335.0  0.0    0.0    0.0    4.0    2.0    2.0    0.0    0.0    3.0    5.0    8.0    0.0    0.0    5.0    3.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    0.16666666666666666  67 / 402
0.0    7.0    2.0    0.0    317.0  1.0    19.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    12.0   4.0    1.0    0.0    0.0    0.0    0.0    13.0   0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    16.0   2.0    4.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    1.0    0.0    3.0    5.0    0.0    0.0    4.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    7.0    3.0    3.0    0.0    0.0    342.0  4.0    4.0    0.1297709923664122   51 / 393
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    2.0    8.0    0.0    10.0   13.0   3.0    15.0   1.0    0.0    329.0  0.0    0.1628498727735369   64 / 393
2.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    31.0   2.0    0.0    0.0    0.0    3.0    0.0    299.0  0.18528610354223432  68 / 367
388.0  515.0  356.0  436.0  416.0  318.0  338.0  297.0  349.0  341.0  373.0  368.0  422.0  385.0  412.0  391.0  361.0  412.0  367.0  398.0  392.0  358.0  410.0  419.0  394.0  387.0  0.18084574627611716  1,809 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.819154
2    0.89913
3    0.929421
4    0.947616
5    0.964011
6    0.972308
7    0.979106
8    0.983905
9    0.988703
10   0.991203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2057653159190452
RMSE: 0.45361361963574814
LogLoss: 0.6570627895704889
Mean Per-Class Error: 0.18500746266826862
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0    3.0    0.0    0.0898876404494382   8 / 89
0.0   83.0   0.0   3.0    3.0   0.0   0.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    0.0   6.0    2.0   0.0   0.0   1.0   1.0    2.0    1.0    0.0    0.2169811320754717   23 / 106
0.0   0.0    62.0  0.0    4.0   0.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    1.0   3.0   0.0   0.0   1.0    0.0    0.0    0.0    0.24390243902439024  20 / 82
0.0   4.0    0.0   98.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0   0.0   1.0   2.0    2.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0    0.125                14 / 112
0.0   2.0    2.0   0.0    75.0  1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0   3.0   0.0   0.0   0.0    0.0    0.0    6.0    0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   85.0   0.0    0.0    0.0    0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   2.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   0.0   0.0   0.0   0.0    86.0   0.0    1.0    0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    4.0   0.0    1.0   3.0   2.0   3.0   1.0    0.0    89.0   0.0    0.16822429906542055  18 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0    0.0    0.0    72.0   0.1724137931034483   15 / 87
90.0  121.0  73.0  125.0  99.0  70.0  84.0  73.0  85.0  100.0  90.0  96.0  90.0  105.0  86.0  111.0  99.0  105.0  90.0  98.0  99.0  79.0  104.0  107.0  110.0  101.0  0.18313253012048192  456 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816867
2    0.896386
3    0.926908
4    0.946586
5    0.963855
6    0.971486
7    0.976305
8    0.981526
9    0.987149
10   0.990362
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:02  6 min  0.420 sec  116360 obs/sec    1         1             10007      0.648612         1.26566             0.992523       0.337299                         0.649684           1.27378               0.992479         0.343775
    2019-08-04 09:06:03  6 min  1.127 sec  129122 obs/sec    10        10            100070     0.450469         0.648517            0.996393       0.180846                         0.453614           0.657063              0.996334         0.183133
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.094363
C13         0.897734               0.897734             0.0847129
C7          0.85873                0.85873              0.0810323
C8          0.775734               0.775734             0.0732005
C12         0.759935               0.759935             0.0717097
C9          0.758916               0.758916             0.0716136
C11         0.690359               0.690359             0.0651443
C14         0.639152               0.639152             0.0603123
C5          0.601576               0.601576             0.0567665
C10         0.595587               0.595587             0.0562013
C6          0.590732               0.590732             0.0557432
C16         0.558113               0.558113             0.0526652
C4          0.549393               0.549393             0.0518424
C3          0.525734               0.525734             0.0496098
C2          0.429337               0.429337             0.0405136
C1          0.366346               0.366346             0.0345695
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_182

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009349369006201869  0.00022638373775407672  0.0         -0.012732652256616461  0.23680317401885986  0.11865166703918859  0.1633797287940979
    3        26       Softmax                      0.0   0.0   0.006589379251356429   0.020853914320468903    0.0         -0.3095149209522368    0.735356330871582    -0.5986450966385581  0.3705472946166992


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2038102766640409
RMSE: 0.4514535155074561
LogLoss: 0.6481103319751756
Mean Per-Class Error: 0.18103369119720833
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    6.0    1.0    4.0    0.0    1.0    0.0    0.0    1.0    7.0    1.0    2.0    0.0    2.0    1.0    6.0    0.0    0.09620253164556962  38 / 395
0.0    341.0  0.0    6.0    1.0    0.0    2.0    3.0    0.0    0.0    1.0    0.0    1.0    0.0    2.0    4.0    1.0    14.0   4.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.10966057441253264  42 / 383
0.0    0.0    299.0  0.0    17.0   0.0    4.0    2.0    0.0    0.0    21.0   2.0    0.0    0.0    1.0    0.0    1.0    0.0    6.0    2.0    9.0    0.0    4.0    0.0    0.0    0.0    0.1875               69 / 368
1.0    30.0   0.0    325.0  0.0    0.0    0.0    5.0    0.0    6.0    2.0    1.0    8.0    2.0    2.0    1.0    0.0    10.0   3.0    1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.1935483870967742   78 / 403
0.0    9.0    8.0    0.0    306.0  3.0    16.0   1.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    2.0    3.0    10.0   4.0    0.0    0.0    0.0    3.0    0.0    11.0   0.203125             78 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    3.0    9.0    0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    3.0    0.0    4.0    7.0    1.0    1.0    1.0    2.0    1.0    10.0   2.0    0.0    0.0    2.0    0.0    6.0    2.0    1.0    1.0    2.0    0.0    0.0    336.0  7.0    4.0    0.1450381679389313   57 / 393
0.0    0.0    0.0    2.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    7.0    12.0   3.0    15.0   1.0    0.0    332.0  0.0    0.15306122448979592  60 / 392
2.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    1.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    27.0   2.0    0.0    0.0    0.0    1.0    0.0    308.0  0.16076294277929154  59 / 367
388.0  544.0  335.0  419.0  391.0  347.0  347.0  304.0  332.0  348.0  442.0  361.0  429.0  374.0  381.0  408.0  347.0  409.0  372.0  372.0  399.0  370.0  412.0  412.0  395.0  365.0  0.18024592622213337  1,803 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.819754
2    0.895431
3    0.93282
4    0.951015
5    0.96551
6    0.973308
7    0.979106
8    0.983505
9    0.987104
10   0.991003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2064592800888613
RMSE: 0.4543779044901516
LogLoss: 0.6573267878972425
Mean Per-Class Error: 0.18491106379763864
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   88.0   0.0   2.0    1.0   0.0   1.0   1.0   0.0   0.0    1.0    0.0   0.0   0.0    2.0   1.0    0.0   6.0    1.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    62.0  0.0    3.0   0.0   1.0   1.0   0.0   0.0    6.0    0.0   0.0   0.0    1.0   0.0    0.0   0.0    3.0   1.0   3.0    0.0   1.0    0.0   0.0    0.0   0.24390243902439024  20 / 82
1.0   6.0    0.0   94.0   0.0   0.0   0.0   2.0   0.0   2.0    1.0    0.0   3.0   1.0    1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.16071428571428573  18 / 112
0.0   1.0    2.0   0.0    74.0  1.0   4.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   1.0   0.0    0.0   0.0    1.0   0.0    6.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0   0.0   1.0   0.0   0.0   0.0    5.0    1.0   0.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0    82.0  2.0    1.0   0.18                 18 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    4.0   0.0    0.0   3.0   1.0    5.0   1.0    0.0   90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0    0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    4.0   1.0   0.0    0.0   0.0    0.0   0.0    76.0  0.12643678160919541  11 / 87
91.0  133.0  70.0  122.0  88.0  78.0  89.0  80.0  77.0  101.0  110.0  95.0  96.0  103.0  74.0  120.0  91.0  101.0  95.0  85.0  101.0  82.0  101.0  99.0  112.0  96.0  0.18313253012048192  456 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816867
2    0.895582
3    0.93253
4    0.95261
5    0.967068
6    0.974699
7    0.980321
8    0.983534
9    0.985944
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:26  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:27  5 min 24.774 sec  103164 obs/sec    1         1             10007      0.653475         1.28358             0.99241        0.344397                         0.652617           1.27741               0.992411         0.348594
    2019-08-04 09:05:27  5 min 25.477 sec  128130 obs/sec    10        10            100070     0.451454         0.64811             0.996378       0.180246                         0.454378           0.657327              0.996321         0.183133
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0909522
C13         0.946962               0.946962             0.0861283
C9          0.888855               0.888855             0.0808433
C8          0.847599               0.847599             0.077091
C12         0.798575               0.798575             0.0726321
C7          0.778283               0.778283             0.0707865
C11         0.688798               0.688798             0.0626477
C4          0.633277               0.633277             0.057598
C10         0.6312                 0.6312               0.057409
C5          0.624409               0.624409             0.0567914
C3          0.603079               0.603079             0.0548514
C6          0.595333               0.595333             0.0541469
C16         0.572032               0.572032             0.0520276
C14         0.567842               0.567842             0.0516465
C1          0.42344                0.42344              0.0385128
C2          0.395105               0.395105             0.0359356
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_58

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009553408364126881  0.00023784005315974355  0.0         -0.014152965923273086  0.23751318454742432  0.11258434826772834  0.1855427622795105
    3        26       Softmax                      0.0   0.0   0.00692108547089167    0.017985373735427856    0.0         -0.3061869833725618    0.7317249774932861   -0.5870177650521466  0.36880064010620117


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20520533623256038
RMSE: 0.4529959560885289
LogLoss: 0.6542535149567665
Mean Per-Class Error: 0.18234259893560584
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    5.0    0.0    1.0    3.0    1.0    1.0    6.0    0.0    0.0810126582278481   32 / 395
0.0    328.0  0.0    4.0    3.0    0.0    1.0    11.0   2.0    1.0    1.0    1.0    0.0    0.0    2.0    6.0    0.0    13.0   6.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.14136125654450263  54 / 382
0.0    0.0    296.0  0.0    10.0   0.0    20.0   1.0    0.0    0.0    21.0   0.0    0.0    0.0    6.0    0.0    4.0    0.0    4.0    2.0    2.0    0.0    1.0    1.0    0.0    0.0    0.1956521739130435   72 / 368
0.0    20.0   0.0    347.0  0.0    1.0    0.0    4.0    0.0    3.0    0.0    0.0    5.0    5.0    3.0    0.0    0.0    2.0    3.0    0.0    1.0    0.0    0.0    9.0    0.0    0.0    0.13895781637717122  56 / 403
0.0    6.0    0.0    0.0    306.0  1.0    20.0   0.0    0.0    0.0    8.0    4.0    0.0    0.0    0.0    1.0    0.0    4.0    15.0   1.0    0.0    0.0    0.0    2.0    0.0    15.0   0.2010443864229765   77 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    14.0   0.0    0.0    0.0    0.0    9.0    0.0    1.0    1.0    0.0    4.0    0.0    0.0    1.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    3.0    0.0    4.0    8.0    0.0    0.0    2.0    3.0    1.0    6.0    4.0    0.0    0.0    2.0    0.0    0.0    0.0    7.0    2.0    2.0    0.0    0.0    344.0  5.0    1.0    0.12690355329949238  50 / 394
2.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    7.0    19.0   2.0    19.0   0.0    1.0    319.0  0.0    0.18622448979591838  73 / 392
0.0    0.0    0.0    1.0    14.0   0.0    0.0    0.0    0.0    19.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    31.0   0.0    0.0    0.0    0.0    0.0    0.0    299.0  0.18528610354223432  68 / 367
401.0  500.0  339.0  429.0  426.0  341.0  350.0  351.0  339.0  362.0  386.0  355.0  414.0  377.0  408.0  393.0  340.0  382.0  454.0  368.0  395.0  369.0  407.0  411.0  370.0  336.0  0.18154553633909826  1,816 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818454
2    0.896931
3    0.93212
4    0.949615
5    0.963711
6    0.971209
7    0.978007
8    0.982505
9    0.986404
10   0.989403

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20653967755364647
RMSE: 0.4544663657011886
LogLoss: 0.6587602356357767
Mean Per-Class Error: 0.18937333818746366
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17    18     19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0   0.0    0.0    3.0    0.0   0.06741573033707865  6 / 89
0.0   83.0   0.0   0.0    3.0   0.0   1.0   4.0   1.0   0.0    1.0   0.0   0.0   0.0   2.0   2.0    0.0   5.0   3.0    0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    61.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0   2.0   0.0    1.0   0.0   3.0    1.0   0.0   0.0   1.0    0.0    0.0    0.0   0.25609756097560976  21 / 82
0.0   4.0    0.0   98.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   3.0   1.0   1.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.125                14 / 112
0.0   1.0    0.0   0.0    74.0  1.0   5.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0   3.0    0.0   0.0   0.0   0.0    1.0    0.0    7.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   2.0   0.0    0.0   0.0   0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   1.0   0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0   0.0    86.0   1.0    0.0   0.14                 14 / 100
1.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   1.0    3.0   0.0   0.0    4.0   0.0   8.0   0.0    0.0    87.0   0.0   0.18691588785046728  20 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   6.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0    0.0   0.0   0.0   0.0    0.0    0.0    72.0  0.1724137931034483   15 / 87
94.0  120.0  71.0  120.0  98.0  78.0  92.0  92.0  78.0  105.0  97.0  95.0  92.0  97.0  85.0  112.0  92.0  95.0  114.0  84.0  99.0  86.0  101.0  100.0  106.0  87.0  0.18835341365461847  469 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.811647
2    0.89759
3    0.933333
4    0.951004
5    0.963855
6    0.968675
7    0.976305
8    0.981526
9    0.985141
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:43  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:43  1 min 40.981 sec  116360 obs/sec    1         1             10007      0.660472         1.3225              0.992246       0.358792                         0.657533           1.31401               0.992296         0.357831
    2019-08-04 09:01:43  1 min 41.697 sec  129122 obs/sec    10        10            100070     0.452996         0.654254            0.996352       0.181546                         0.454466           0.65876               0.99632          0.188353
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0970547
C13         0.883425               0.883425             0.0857405
C9          0.775488               0.775488             0.0752648
C7          0.735689               0.735689             0.0714021
C12         0.73159                0.73159              0.0710042
C8          0.723109               0.723109             0.0701811
C5          0.643435               0.643435             0.0624484
C11         0.639909               0.639909             0.0621062
C6          0.600973               0.600973             0.0583272
C14         0.588014               0.588014             0.0570695
C10         0.578304               0.578304             0.0561271
C4          0.54956                0.54956              0.0533373
C3          0.505182               0.505182             0.0490303
C16         0.474299               0.474299             0.046033
C2          0.473619               0.473619             0.045967
C1          0.400873               0.400873             0.0389066
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_176

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009337449411646048  0.0002385569387115538  0.0         -0.01513985487588343  0.23701071739196777  0.10935734309108527  0.1803871989250183
    3        26       Softmax                      0.0   0.0   0.006297796198291157   0.01409175619482994    0.0         -0.2762898342796704   0.7427940368652344   -0.6073053294978318  0.402927041053772


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20256501479857242
RMSE: 0.4500722328677614
LogLoss: 0.6546607509199431
Mean Per-Class Error: 0.18210072238421396
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    1.0    6.0    1.0    3.0    0.0    2.0    0.0    7.0    0.0    1.0    4.0    2.0    1.0    2.0    0.0    0.08651399491094147  34 / 393
0.0    316.0  0.0    8.0    4.0    0.0    1.0    3.0    1.0    0.0    4.0    0.0    1.0    1.0    4.0    2.0    2.0    26.0   7.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.17493472584856398  67 / 383
0.0    0.0    299.0  0.0    14.0   0.0    17.0   0.0    0.0    0.0    14.0   1.0    1.0    0.0    8.0    0.0    1.0    0.0    4.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    0.1875               69 / 368
2.0    17.0   0.0    333.0  0.0    0.0    0.0    6.0    0.0    3.0    4.0    1.0    5.0    5.0    4.0    4.0    0.0    11.0   5.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.17369727047146402  70 / 403
0.0    14.0   2.0    0.0    300.0  1.0    17.0   0.0    0.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    7.0    4.0    13.0   2.0    0.0    0.0    0.0    4.0    0.0    10.0   0.21875              84 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
2.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    3.0    0.0    15.0   2.0    0.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    339.0  0.0    0.0    0.0    0.09358288770053476  35 / 374
0.0    5.0    0.0    4.0    7.0    0.0    3.0    3.0    1.0    2.0    9.0    0.0    0.0    0.0    2.0    0.0    4.0    2.0    6.0    3.0    1.0    0.0    0.0    336.0  5.0    1.0    0.14720812182741116  58 / 394
0.0    0.0    0.0    3.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    2.0    1.0    8.0    0.0    3.0    6.0    1.0    26.0   0.0    0.0    330.0  0.0    0.16030534351145037  63 / 393
2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    25.0   1.0    0.0    0.0    0.0    6.0    0.0    305.0  0.16893732970027248  62 / 367
407.0  487.0  341.0  412.0  403.0  343.0  382.0  334.0  338.0  371.0  398.0  336.0  435.0  395.0  433.0  378.0  328.0  421.0  379.0  356.0  364.0  397.0  410.0  414.0  378.0  363.0  0.18154553633909826  1,816 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818454
2    0.89893
3    0.928521
4    0.945916
5    0.958612
6    0.96771
7    0.975307
8    0.981905
9    0.986904
10   0.990203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20478010843461894
RMSE: 0.4525263621432667
LogLoss: 0.6589928515985347
Mean Per-Class Error: 0.1869145393048757
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10     11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   1.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   81.0   0.0   2.0    3.0   0.0   1.0    2.0   0.0   0.0    1.0    0.0   0.0   1.0    2.0   0.0    0.0   8.0    3.0   0.0   0.0   1.0   0.0    1.0    0.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    61.0  0.0    2.0   0.0   8.0    0.0   0.0   0.0    3.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   0.0   0.0   2.0    0.0    0.0    0.0   0.25609756097560976  21 / 82
2.0   3.0    0.0   94.0   0.0   0.0   0.0    2.0   0.0   1.0    2.0    0.0   3.0   1.0    1.0   1.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.16071428571428573  18 / 112
0.0   2.0    0.0   0.0    72.0  1.0   5.0    0.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0    5.0   0.0   0.0   0.0   0.0    1.0    0.0    4.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0    0.0   3.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    3.0   0.0   1.0    2.0   0.0   0.0    3.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0   0.0    83.0   2.0    0.0   0.17                 17 / 100
0.0   0.0    0.0   2.0    0.0   3.0   0.0    0.0   0.0   0.0    0.0    1.0   0.0   1.0    0.0   0.0    2.0   0.0    0.0   1.0   0.0   7.0   0.0    0.0    90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   4.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0    2.0    0.0    73.0  0.16091954022988506  14 / 87
97.0  114.0  69.0  120.0  92.0  81.0  100.0  93.0  77.0  105.0  105.0  89.0  95.0  102.0  85.0  105.0  85.0  107.0  96.0  80.0  94.0  92.0  101.0  103.0  106.0  97.0  0.18674698795180722  465 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.813253
2    0.895984
3    0.928112
4    0.947791
5    0.961847
6    0.96988
7    0.977108
8    0.983534
9    0.986747
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:12  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:12  5 min 10.220 sec  108771 obs/sec    1         1             10007      0.662685         1.32726             0.992192       0.356193                         0.662723           1.32654               0.992174         0.359036
    2019-08-04 09:05:13  5 min 10.930 sec  127803 obs/sec    10        10            100070     0.450072         0.654661            0.996398       0.181546                         0.452526           0.658993              0.996351         0.186747
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0934627
C13         0.991865               0.991865             0.0927024
C9          0.797797               0.797797             0.0745642
C8          0.788439               0.788439             0.0736896
C12         0.774789               0.774789             0.0724139
C7          0.708082               0.708082             0.0661793
C11         0.695318               0.695318             0.0649863
C5          0.68511                0.68511              0.0640322
C14         0.607195               0.607195             0.0567501
C6          0.598209               0.598209             0.0559103
C10         0.584413               0.584413             0.0546208
C16         0.581377               0.581377             0.054337
C4          0.53791                0.53791              0.0502745
C3          0.530102               0.530102             0.0495448
C2          0.444507               0.444507             0.0415448
C1          0.374344               0.374344             0.0349872
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_44

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009634903240396397  0.0002376293414272368  0.0         -0.011902952269480238  0.2373560667037964  0.13633563799855777  0.19234192371368408
    3        26       Softmax                      0.0   0.0   0.0067992850275774026  0.024604856967926025   0.0         -0.2809982653602324    0.7259280681610107  -0.605587031343859   0.3821476697921753


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20499700953246586
RMSE: 0.4527659544758924
LogLoss: 0.6543120484081022
Mean Per-Class Error: 0.18103397272616947
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    5.0    1.0    5.0    0.0    3.0    0.0    0.0    1.0    4.0    0.0    3.0    1.0    2.0    4.0    3.0    0.0    0.09898477157360407  39 / 394
0.0    316.0  0.0    9.0    1.0    0.0    8.0    6.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    0.0    16.0   17.0   0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.17493472584856398  67 / 383
0.0    0.0    305.0  0.0    16.0   0.0    4.0    1.0    0.0    0.0    22.0   0.0    0.0    0.0    5.0    0.0    2.0    0.0    4.0    3.0    2.0    0.0    4.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
3.0    19.0   0.0    331.0  0.0    0.0    1.0    7.0    0.0    3.0    1.0    0.0    7.0    2.0    2.0    3.0    0.0    10.0   3.0    3.0    0.0    0.0    0.0    7.0    0.0    0.0    0.17661691542288557  71 / 402
0.0    12.0   3.0    0.0    303.0  3.0    19.0   0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    7.0    5.0    1.0    0.0    0.0    5.0    0.0    11.0   0.2109375            81 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    22.0   0.0    2.0    0.0    0.0    2.0    0.0    1.0    1.0    1.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    4.0    0.0    5.0    10.0   0.0    0.0    2.0    1.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    6.0    1.0    1.0    1.0    0.0    347.0  3.0    3.0    0.11928934010152284  47 / 394
1.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    2.0    6.0    0.0    3.0    15.0   1.0    10.0   2.0    0.0    342.0  0.0    0.12755102040816327  50 / 392
1.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    30.0   4.0    0.0    0.0    0.0    2.0    0.0    301.0  0.17983651226158037  66 / 367
401.0  495.0  343.0  409.0  386.0  372.0  350.0  348.0  335.0  358.0  388.0  335.0  454.0  359.0  373.0  390.0  346.0  429.0  428.0  364.0  380.0  367.0  422.0  421.0  399.0  351.0  0.18034589623113065  1,804 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.819654
2    0.89853
3    0.929421
4    0.947016
5    0.961711
6    0.971409
7    0.978107
8    0.982505
9    0.986204
10   0.988903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20785052058450623
RMSE: 0.45590626293626
LogLoss: 0.6609825741230406
Mean Per-Class Error: 0.17983743447657485
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17     18     19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   1.0   0.0   1.0    1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   80.0   0.0   3.0    0.0   0.0   3.0   3.0   1.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0    0.0   5.0    6.0    0.0   0.0   3.0   0.0    1.0    0.0    0.0   0.24528301886792453  26 / 106
0.0   0.0    63.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0   3.0   0.0    1.0   0.0    2.0    2.0   0.0   0.0   2.0    0.0    0.0    0.0   0.23170731707317074  19 / 82
2.0   4.0    0.0   93.0   0.0   0.0   0.0   3.0   0.0   0.0    1.0   0.0   3.0    1.0   0.0   1.0    0.0   2.0    0.0    0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    73.0  1.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0   0.0   0.0    1.0   1.0    2.0    3.0   0.0   0.0   0.0    2.0    0.0    4.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   2.0    4.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0    2.0    0.0   0.0   0.0   0.0    87.0   1.0    0.0   0.13                 13 / 100
1.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0    4.0   0.0    0.0    4.0   0.0   3.0   2.0    0.0    91.0   0.0   0.14953271028037382  16 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    5.0    1.0   0.0   0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
94.0  121.0  69.0  115.0  89.0  86.0  90.0  91.0  80.0  104.0  92.0  90.0  103.0  98.0  80.0  108.0  94.0  105.0  109.0  89.0  96.0  85.0  104.0  105.0  107.0  86.0  0.17951807228915662  447 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.820482
2    0.898795
3    0.93253
4    0.945783
5    0.959839
6    0.968273
7    0.976707
8    0.97992
9    0.984739
10   0.987952
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:17  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:17  1 min 15.545 sec  103164 obs/sec    1         1             10007      0.650281         1.26781             0.992482       0.322503                         0.649549           1.26155               0.992482         0.326908
    2019-08-04 09:01:18  1 min 16.274 sec  124002 obs/sec    10        10            100070     0.452766         0.654312            0.996355       0.180346                         0.455906           0.660983              0.996296         0.179518
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0906201
C15         0.999447               0.999447             0.09057
C7          0.818751               0.818751             0.0741954
C8          0.815783               0.815783             0.0739264
C5          0.780161               0.780161             0.0706983
C9          0.764892               0.764892             0.0693146
C12         0.745183               0.745183             0.0675286
C11         0.739646               0.739646             0.0670268
C10         0.677219               0.677219             0.0613696
C14         0.611894               0.611894             0.0554499
C3          0.578635               0.578635             0.052436
C4          0.578096               0.578096             0.0523871
C6          0.54104                0.54104              0.0490291
C16         0.524975               0.524975             0.0475733
C2          0.456394               0.456394             0.0413584
C1          0.402961               0.402961             0.0365164
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_3

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009279038097247394  0.00022567634005099535  0.0         -0.01405335097303917  0.23521453142166138  0.12188845155741103  0.18017864227294922
    3        26       Softmax                      0.0   0.0   0.006038126831299451   0.012743346393108368    0.0         -0.28397604761007994  0.7372109889984131   -0.5842035618940098  0.36885321140289307


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20870802711038186
RMSE: 0.4568457366665271
LogLoss: 0.666368550620197
Mean Per-Class Error: 0.18582140643889206
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    7.0    2.0    2.0    0.0    3.0    0.0    1.0    1.0    8.0    0.0    1.0    2.0    2.0    3.0    4.0    0.0    0.09620253164556962  38 / 395
0.0    322.0  0.0    8.0    3.0    0.0    4.0    7.0    2.0    0.0    2.0    1.0    0.0    0.0    4.0    2.0    0.0    9.0    13.0   1.0    0.0    1.0    0.0    2.0    2.0    0.0    0.15926892950391644  61 / 383
0.0    0.0    305.0  1.0    13.0   0.0    11.0   2.0    0.0    0.0    17.0   0.0    1.0    0.0    2.0    0.0    2.0    0.0    7.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
1.0    17.0   0.0    336.0  0.0    1.0    1.0    8.0    0.0    5.0    0.0    0.0    6.0    2.0    3.0    0.0    0.0    9.0    4.0    0.0    1.0    0.0    0.0    5.0    0.0    4.0    0.1662531017369727   67 / 403
0.0    4.0    1.0    0.0    314.0  2.0    14.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    2.0    4.0    13.0   6.0    0.0    0.0    0.0    4.0    0.0    13.0   0.1801566579634465   69 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    12.0   2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    4.0    0.0    3.0    5.0    0.0    0.0    3.0    2.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    1.0    1.0    1.0    0.0    339.0  8.0    11.0   0.13959390862944163  55 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    3.0    5.0    0.0    2.0    19.0   1.0    20.0   1.0    0.0    331.0  0.0    0.15776081424936386  62 / 393
0.0    1.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    26.0   3.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
388.0  525.0  343.0  427.0  408.0  348.0  351.0  331.0  336.0  362.0  377.0  350.0  420.0  376.0  367.0  385.0  348.0  424.0  358.0  385.0  387.0  366.0  412.0  412.0  405.0  412.0  0.1850444866540038   1,851 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814956
2    0.892032
3    0.927122
4    0.946316
5    0.960412
6    0.969809
7    0.975807
8    0.980406
9    0.985504
10   0.989303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21033629568423995
RMSE: 0.4586243513860117
LogLoss: 0.6731167608046388
Mean Per-Class Error: 0.18872243745417216
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20    21    22     23     24     25     Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   1.0    1.0    2.0    0.0    0.07865168539325842   7 / 89
0.0   82.0   0.0   3.0    2.0   0.0   1.0   2.0   1.0   0.0    1.0   0.0   0.0   0.0   2.0   1.0    0.0   4.0    3.0   0.0   0.0   1.0   0.0    2.0    1.0    0.0    0.22641509433962265   24 / 106
0.0   0.0    63.0  0.0    2.0   0.0   6.0   1.0   0.0   0.0    3.0   0.0   0.0   0.0   1.0   0.0    1.0   0.0    3.0   0.0   1.0   0.0   1.0    0.0    0.0    0.0    0.23170731707317074   19 / 82
1.0   2.0    0.0   95.0   0.0   1.0   1.0   2.0   0.0   2.0    0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0    2.0    0.0    1.0    0.15178571428571427   17 / 112
0.0   0.0    0.0   0.0    73.0  2.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    1.0   1.0    4.0   3.0   0.0   0.0   0.0    2.0    0.0    5.0    0.24742268041237114   24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   88.0   0.0    0.0    0.0    0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   2.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0   0.0   0.0   0.0    85.0   2.0    2.0    0.15                  15 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   1.0   3.0    1.0   0.0    0.0   5.0   0.0   5.0   1.0    0.0    90.0   0.0    0.1588785046728972    17 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0   2.0   0.0   0.0   0.0    0.0    0.0    70.0   0.19540229885057472   17 / 87
89.0  123.0  68.0  126.0  93.0  80.0  88.0  79.0  80.0  105.0  98.0  96.0  94.0  98.0  75.0  113.0  90.0  104.0  93.0  95.0  99.0  83.0  101.0  106.0  112.0  102.0  0.18755020080321286   467 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.81245
2    0.891968
3    0.926908
4    0.946586
5    0.959438
6    0.969478
7    0.974297
8    0.980321
9    0.984739
10   0.988353
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:12  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:12  10.203 sec  100070 obs/sec    1         1             10007      0.646354         1.25766             0.992577       0.3341                           0.647687           1.26419               0.992525         0.333333
    2019-08-04 09:00:13  10.937 sec  124002 obs/sec    10        10            100070     0.456846         0.666369            0.996292       0.185044                         0.458624           0.673117              0.996252         0.18755
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0871216
C13         0.980597               0.980597             0.0854312
C9          0.902663               0.902663             0.0786414
C8          0.898202               0.898202             0.0782528
C12         0.83518                0.83518              0.0727623
C11         0.799037               0.799037             0.0696134
C7          0.765802               0.765802             0.0667179
C5          0.745181               0.745181             0.0649213
C14         0.649297               0.649297             0.0565678
C6          0.647608               0.647608             0.0564207
C3          0.627126               0.627126             0.0546362
C10         0.623252               0.623252             0.0542987
C4          0.583629               0.583629             0.0508467
C16         0.570698               0.570698             0.0497201
C1          0.461197               0.461197             0.0401802
C2          0.388742               0.388742             0.0338679
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_214

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012711066547126393  0.00036765553522855043  0.0         -0.015096827025587345  0.21045243740081787  0.09531541342784688  0.14468902349472046
    3        26       Softmax                      0.0   0.0   0.007420039387835249   0.023136064410209656    0.0         -0.20368027400792463   0.5354783535003662   -0.878848346496307   0.38728535175323486


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2136702097864443
RMSE: 0.46224475095607553
LogLoss: 0.6695386041842163
Mean Per-Class Error: 0.1837431090483275
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    4.0    5.0    1.0    5.0    1.0    1.0    0.0    0.0    0.0    8.0    1.0    3.0    0.0    2.0    4.0    3.0    0.0    0.10632911392405063  42 / 395
0.0    331.0  0.0    7.0    2.0    0.0    4.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    20.0   6.0    0.0    1.0    1.0    0.0    3.0    1.0    0.0    0.13577023498694518  52 / 383
0.0    0.0    299.0  0.0    16.0   0.0    13.0   0.0    0.0    0.0    20.0   0.0    1.0    0.0    5.0    0.0    1.0    0.0    6.0    1.0    0.0    0.0    5.0    0.0    0.0    1.0    0.1875               69 / 368
4.0    23.0   0.0    340.0  0.0    0.0    0.0    4.0    0.0    2.0    0.0    1.0    5.0    4.0    3.0    0.0    0.0    4.0    2.0    1.0    1.0    0.0    0.0    7.0    0.0    1.0    0.15422885572139303  62 / 402
0.0    7.0    0.0    0.0    310.0  1.0    16.0   0.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    2.0    5.0    3.0    10.0   2.0    0.0    0.0    0.0    5.0    0.0    14.0   0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    1.0    0.0    11.0   0.0    2.0    0.0    0.0    6.0    0.0    0.0    2.0    1.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    2.0    0.0    5.0    9.0    0.0    0.0    1.0    2.0    2.0    5.0    0.0    0.0    0.0    2.0    0.0    5.0    1.0    5.0    2.0    2.0    0.0    0.0    345.0  3.0    2.0    0.12213740458015267  48 / 393
0.0    0.0    0.0    1.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    11.0   0.0    5.0    20.0   2.0    22.0   1.0    0.0    324.0  0.0    0.17557251908396945  69 / 393
0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    16.0   0.0    1.0    0.0    0.0    0.0    0.0    8.0    0.0    31.0   2.0    0.0    0.0    0.0    1.0    0.0    297.0  0.1907356948228883   70 / 367
396.0  525.0  342.0  425.0  407.0  326.0  362.0  317.0  344.0  357.0  375.0  330.0  428.0  388.0  399.0  397.0  344.0  426.0  379.0  391.0  396.0  372.0  403.0  445.0  377.0  352.0  0.18284514645606317  1,829 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.817155
2    0.896531
3    0.931021
4    0.947916
5    0.961811
6    0.971409
7    0.978106
8    0.983205
9    0.987104
10   0.990203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.215156980863772
RMSE: 0.46385017070577
LogLoss: 0.6748967636989195
Mean Per-Class Error: 0.18519749384360354
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   1.0    1.0   0.0   2.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    0.0   7.0    2.0   0.0   1.0    1.0   0.0    2.0    0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    62.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0   2.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
3.0   3.0    0.0   94.0   0.0   0.0   0.0   2.0   0.0   1.0    0.0   1.0   2.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    2.0    0.0    1.0   0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    74.0  1.0   4.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    4.0   1.0   0.0    0.0   0.0    2.0    0.0    6.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    5.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   0.0   0.0    0.0   0.0    84.0   1.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0    0.0   5.0   2.0    5.0   1.0    0.0    90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    5.0   1.0   0.0    0.0   0.0    1.0    0.0    72.0  0.1724137931034483   15 / 87
94.0  123.0  70.0  116.0  93.0  73.0  92.0  80.0  84.0  104.0  90.0  87.0  92.0  101.0  82.0  113.0  95.0  114.0  97.0  96.0  102.0  82.0  101.0  109.0  107.0  93.0  0.18393574297188756  458 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816064
2    0.895582
3    0.932129
4    0.946586
5    0.957831
6    0.967871
7    0.975502
8    0.980723
9    0.985542
10   0.989558
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:17  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:17  6 min 15.157 sec  80701 obs/sec     1         1             10007      0.655525         1.273               0.992362       0.325402                         0.655875           1.27294               0.992335         0.327309
    2019-08-04 09:06:18  6 min 16.119 sec  94673 obs/sec     10        10            100070     0.462245         0.669539            0.996202       0.182845                         0.46385            0.674897              0.996166         0.183936
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.08862
C13         0.965203               0.965203             0.0855363
C8          0.854844               0.854844             0.0757563
C7          0.828394               0.828394             0.0734123
C12         0.81208                0.81208              0.0719665
C9          0.804946               0.804946             0.0713343
C11         0.733534               0.733534             0.0650058
C10         0.68408                0.68408              0.0606232
C6          0.657768               0.657768             0.0582914
C14         0.65718                0.65718              0.0582393
C5          0.65663                0.65663              0.0581906
C3          0.62666                0.62666              0.0555346
C4          0.597307               0.597307             0.0529334
C16         0.574678               0.574678             0.050928
C2          0.449732               0.449732             0.0398553
C1          0.381095               0.381095             0.0337727
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_103

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012565407722462396  0.00034390122164040804  0.0         -0.015269632158315005  0.20632261037826538  0.09233345894848785  0.17449116706848145
    3        26       Softmax                      0.0   0.0   0.007137475598046177   0.017338313162326813    0.0         -0.2375382849095258    0.5392649173736572   -0.8931681325051103  0.40609216690063477


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21646127602482196
RMSE: 0.4652539908746855
LogLoss: 0.6818215487731398
Mean Per-Class Error: 0.18764096031124444
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    4.0    3.0    1.0    5.0    0.0    2.0    0.0    2.0    0.0    6.0    0.0    1.0    3.0    1.0    0.0    7.0    0.0    0.09390862944162437  37 / 394
0.0    342.0  0.0    3.0    2.0    1.0    3.0    1.0    2.0    0.0    1.0    0.0    1.0    0.0    3.0    2.0    0.0    11.0   4.0    2.0    0.0    1.0    1.0    2.0    1.0    0.0    0.10704960835509138  41 / 383
0.0    0.0    301.0  0.0    16.0   0.0    10.0   1.0    0.0    0.0    20.0   0.0    0.0    0.0    6.0    0.0    1.0    0.0    2.0    2.0    2.0    0.0    6.0    0.0    0.0    0.0    0.17983651226158037  66 / 367
3.0    23.0   0.0    335.0  0.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    6.0    3.0    3.0    0.0    0.0    8.0    3.0    0.0    1.0    0.0    0.0    7.0    0.0    4.0    0.1687344913151365   68 / 403
0.0    8.0    1.0    0.0    322.0  4.0    14.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    7.0    4.0    4.0    3.0    0.0    0.0    0.0    2.0    0.0    13.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    2.0    0.0    10.0   0.0    0.0    0.0    0.0    3.0    0.0    0.0    6.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    2.0    0.0    5.0    10.0   0.0    0.0    1.0    3.0    2.0    6.0    1.0    0.0    0.0    0.0    0.0    10.0   1.0    6.0    1.0    3.0    0.0    0.0    335.0  4.0    4.0    0.14974619289340102  59 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    1.0    4.0    0.0    5.0    18.0   3.0    26.0   1.0    0.0    325.0  0.0    0.17302798982188294  68 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    29.0   1.0    0.0    0.0    0.0    1.0    0.0    311.0  0.15258855585831063  56 / 367
396.0  511.0  358.0  410.0  426.0  371.0  341.0  253.0  347.0  338.0  382.0  335.0  422.0  394.0  431.0  365.0  340.0  445.0  355.0  390.0  417.0  377.0  410.0  412.0  390.0  387.0  0.18664400679796062  1,867 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.813356
2    0.892832
3    0.929521
4    0.947116
5    0.960312
6    0.968809
7    0.976107
8    0.981805
9    0.986404
10   0.989503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21742296537545217
RMSE: 0.46628635555359343
LogLoss: 0.6852215311521699
Mean Per-Class Error: 0.18548013888153975
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    2.0   0.0    0.0    3.0    0.0    0.06741573033707865  6 / 89
0.0   91.0   0.0   0.0    1.0   1.0   1.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0    2.0   1.0    0.0   4.0    0.0   0.0   0.0    1.0   1.0    1.0    0.0    0.0    0.14150943396226415  15 / 106
0.0   0.0    62.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   1.0    0.0   2.0    0.0    0.0    0.0    0.24390243902439024  20 / 82
2.0   4.0    0.0   93.0   0.0   0.0   0.0   2.0   0.0   2.0   1.0   0.0   3.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    2.0    0.0    1.0    0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    77.0  2.0   2.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    1.0   1.0   0.0    0.0   0.0    2.0    0.0    6.0    0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   1.0   0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0   0.0   0.0    0.0   0.0    81.0   1.0    2.0    0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    1.0   1.0    1.0   0.0    0.0   5.0   0.0    7.0   1.0    0.0    89.0   0.0    0.16822429906542055  18 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    5.0   0.0   0.0    0.0   0.0    1.0    0.0    74.0   0.14942528735632185  13 / 87
94.0  124.0  74.0  110.0  99.0  91.0  85.0  64.0  86.0  98.0  94.0  90.0  91.0  104.0  88.0  104.0  90.0  117.0  88.0  93.0  106.0  86.0  102.0  102.0  109.0  101.0  0.18473895582329317  460 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.815261
2    0.893976
3    0.929719
4    0.946185
5    0.959839
6    0.968675
7    0.973896
8    0.979518
9    0.983936
10   0.98755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:54  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:55  2 min 52.757 sec  84092 obs/sec     1         1             10007      0.658252         1.28363             0.992297       0.3321                           0.657538           1.27991               0.992296         0.329719
    2019-08-04 09:02:55  2 min 53.742 sec  93348 obs/sec     10        10            100070     0.465254         0.681822            0.996152       0.186644                         0.466286           0.685222              0.996126         0.184739
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0941746
C13         0.871306               0.871306             0.0820549
C9          0.809721               0.809721             0.0762551
C8          0.764206               0.764206             0.0719688
C7          0.758831               0.758831             0.0714626
C12         0.75677                0.75677              0.0712686
C11         0.715833               0.715833             0.0674133
C14         0.626078               0.626078             0.0589607
C5          0.621459               0.621459             0.0585257
C10         0.616924               0.616924             0.0580986
C6          0.604926               0.604926             0.0569687
C3          0.597978               0.597978             0.0563144
C16         0.546207               0.546207             0.0514389
C4          0.526166               0.526166             0.0495515
C1          0.420441               0.420441             0.0395949
C2          0.381724               0.381724             0.0359487
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_20

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias           bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012576039958389629  0.0003631958970800042  0.0         -0.01324291023986035  0.20941567420959473  0.1057118729841539  0.12881100177764893
    3        26       Softmax                      0.0   0.0   0.006387148294257154   0.01685725897550583    0.0         -0.204504058899805    0.525864839553833    -0.888490396729586  0.4090198278427124


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21883770087008195
RMSE: 0.46780092012530494
LogLoss: 0.6863034565343202
Mean Per-Class Error: 0.1884037509574722
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    4.0    3.0    1.0    6.0    0.0    3.0    0.0    0.0    1.0    6.0    0.0    4.0    0.0    2.0    3.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    323.0  0.0    4.0    3.0    1.0    6.0    2.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    3.0    0.0    20.0   8.0    0.0    0.0    2.0    1.0    3.0    2.0    0.0    0.1566579634464752   60 / 383
0.0    0.0    304.0  0.0    15.0   0.0    10.0   0.0    0.0    0.0    18.0   0.0    1.0    0.0    8.0    0.0    2.0    0.0    2.0    2.0    0.0    0.0    6.0    0.0    0.0    0.0    0.17391304347826086  64 / 368
2.0    18.0   0.0    338.0  0.0    0.0    3.0    5.0    0.0    2.0    0.0    0.0    6.0    3.0    1.0    1.0    0.0    6.0    3.0    1.0    0.0    0.0    0.0    5.0    0.0    9.0    0.16129032258064516  65 / 403
0.0    7.0    0.0    0.0    314.0  2.0    11.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    6.0    4.0    11.0   2.0    0.0    0.0    0.0    7.0    0.0    15.0   0.18229166666666666  70 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    11.0   3.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    1.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    2.0    0.0    4.0    11.0   0.0    0.0    0.0    2.0    2.0    5.0    0.0    0.0    0.0    2.0    0.0    5.0    3.0    7.0    3.0    2.0    0.0    0.0    339.0  6.0    1.0    0.13959390862944163  55 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    0.0    8.0    20.0   0.0    16.0   1.0    0.0    335.0  0.0    0.14540816326530612  57 / 392
0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    31.0   1.0    0.0    0.0    0.0    1.0    0.0    308.0  0.16076294277929154  59 / 367
397.0  469.0  357.0  422.0  433.0  326.0  341.0  287.0  336.0  354.0  380.0  339.0  420.0  388.0  402.0  386.0  356.0  451.0  372.0  390.0  381.0  364.0  427.0  425.0  407.0  393.0  0.1876437068879336   1,877 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.812356
2    0.893432
3    0.927322
4    0.949115
5    0.962411
6    0.971209
7    0.977507
8    0.982005
9    0.986204
10   0.989403

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22015600493052692
RMSE: 0.4692078483258
LogLoss: 0.6878929995083356
Mean Per-Class Error: 0.18880172903712036
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0   0.0   1.0    1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   83.0   0.0   0.0    2.0    0.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    2.0   1.0    0.0   8.0    3.0   0.0   0.0   2.0   1.0    1.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    63.0  0.0    3.0    0.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    1.0   2.0   0.0   0.0   2.0    0.0    0.0    0.0   0.23170731707317074  19 / 82
2.0   4.0    0.0   96.0   0.0    0.0   1.0   2.0   0.0   1.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   1.0    0.0   0.0    78.0   1.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   0.0   0.0   0.0   0.0    2.0    0.0    6.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   1.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    6.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   2.0    2.0   0.0   1.0   0.0   0.0    82.0   2.0    0.0   0.18                 18 / 100
0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   3.0   0.0   5.0   1.0    0.0    94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0    0.0    0.0    74.0  0.14942528735632185  13 / 87
95.0  112.0  75.0  117.0  104.0  72.0  87.0  72.0  80.0  101.0  95.0  91.0  92.0  102.0  84.0  111.0  95.0  117.0  94.0  90.0  93.0  86.0  107.0  103.0  116.0  99.0  0.18755020080321286  467 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.81245
2    0.895984
3    0.931727
4    0.952611
5    0.963855
6    0.974297
7    0.97751
8    0.983534
9    0.985944
10   0.988755
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:40  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:40  38.620 sec  79420 obs/sec     1         1             10007      0.657732         1.277               0.992312       0.320404                         0.65724            1.27409               0.992303         0.328112
    2019-08-04 09:00:41  39.595 sec  93610 obs/sec     10        10            100070     0.467801         0.686303            0.996111       0.187644                         0.469208           0.687893              0.996077         0.18755
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0868203
C13         0.985834               0.985834             0.0855904
C8          0.874811               0.874811             0.0759514
C9          0.82546                0.82546              0.0716667
C7          0.806371               0.806371             0.0700093
C11         0.805588               0.805588             0.0699414
C12         0.800926               0.800926             0.0695367
C5          0.695018               0.695018             0.0603417
C14         0.684296               0.684296             0.0594108
C6          0.677642               0.677642             0.0588331
C10         0.671431               0.671431             0.0582939
C3          0.61328                0.61328              0.0532452
C16         0.60443                0.60443              0.0524768
C4          0.592932               0.592932             0.0514785
C2          0.456181               0.456181             0.0396058
C1          0.423842               0.423842             0.0367981
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_139

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012545656120295234  0.00035992497578263283  0.0         -0.011546247624593775  0.20840072631835938  0.07754717971566066  0.15077513456344604
    3        26       Softmax                      0.0   0.0   0.006964099295111317   0.01715521514415741     0.0         -0.23208584568045318   0.529207706451416    -0.9019454256961501  0.42960894107818604


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2198362408019871
RMSE: 0.4688669755932775
LogLoss: 0.6829384439231214
Mean Per-Class Error: 0.1898029209199493
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    4.0    0.0    6.0    0.0    0.0    0.0    4.0    0.0    3.0    1.0    2.0    1.0    5.0    0.0    0.07848101265822785  31 / 395
0.0    322.0  0.0    2.0    3.0    0.0    1.0    2.0    2.0    0.0    1.0    0.0    1.0    0.0    3.0    3.0    2.0    27.0   5.0    0.0    0.0    1.0    0.0    2.0    4.0    0.0    0.15485564304461943  59 / 381
0.0    0.0    302.0  0.0    6.0    0.0    14.0   0.0    0.0    0.0    25.0   0.0    1.0    0.0    8.0    0.0    1.0    0.0    3.0    2.0    0.0    0.0    6.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
4.0    25.0   0.0    324.0  0.0    0.0    0.0    4.0    0.0    4.0    0.0    0.0    7.0    3.0    4.0    2.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    11.0   0.0    5.0    0.19602977667493796  79 / 403
0.0    5.0    0.0    1.0    303.0  1.0    12.0   0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    2.0    11.0   5.0    11.0   3.0    0.0    0.0    0.0    9.0    0.0    17.0   0.2109375            81 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    2.0    0.0    13.0   1.0    1.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    2.0    0.0    2.0    3.0    0.0    0.0    2.0    1.0    1.0    4.0    2.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    2.0    3.0    1.0    0.0    357.0  3.0    4.0    0.09390862944162437  37 / 394
1.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    3.0    8.0    2.0    22.0   1.0    0.0    340.0  0.0    0.13486005089058525  53 / 393
2.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    32.0   3.0    0.0    0.0    0.0    3.0    1.0    302.0  0.1771117166212534   65 / 367
422.0  512.0  352.0  380.0  375.0  368.0  332.0  283.0  339.0  333.0  392.0  334.0  427.0  386.0  421.0  378.0  357.0  447.0  334.0  358.0  392.0  380.0  424.0  469.0  420.0  388.0  0.18884334699590122  1,889 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.811157
2    0.894832
3    0.928521
4    0.949115
5    0.96561
6    0.974808
7    0.980406
8    0.985104
9    0.988403
10   0.991003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22115935979393905
RMSE: 0.4702758337337132
LogLoss: 0.6879320535688606
Mean Per-Class Error: 0.18911733075693554
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16     17     18    19    20    21    22     23     24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0   1.0   1.0    0.0    2.0    0.0    0.06741573033707865  6 / 89
0.0    84.0   0.0   0.0    2.0   0.0   1.0   1.0   1.0   0.0   1.0   0.0   0.0   0.0    2.0   2.0    0.0    8.0    1.0   0.0   0.0   1.0   0.0    1.0    1.0    0.0    0.20754716981132076  22 / 106
0.0    0.0    64.0  0.0    1.0   0.0   5.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    2.0   1.0   0.0   0.0   2.0    0.0    0.0    0.0    0.21951219512195122  18 / 82
3.0    3.0    0.0   91.0   0.0   0.0   0.0   4.0   0.0   1.0   0.0   0.0   3.0   1.0    0.0   1.0    0.0    1.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    2.0    0.1875               21 / 112
0.0    0.0    0.0   0.0    72.0  1.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    1.0    4.0   1.0   0.0   0.0   0.0    3.0    0.0    9.0    0.25773195876288657  25 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0   0.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0    0.0    0.0   1.0    2.0   0.0   0.0   2.0   0.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.0   0.0   0.0   0.0    90.0   1.0    1.0    0.1                  10 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    0.0    0.0   2.0   0.0   8.0   1.0    0.0    91.0   0.0    0.14953271028037382  16 / 107
1.0    0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0    4.0   1.0   0.0   0.0   0.0    1.0    1.0    74.0   0.14942528735632185  13 / 87
102.0  122.0  75.0  105.0  82.0  89.0  84.0  74.0  80.0  97.0  92.0  89.0  95.0  104.0  85.0  106.0  100.0  114.0  80.0  81.0  99.0  89.0  103.0  117.0  119.0  107.0  0.1891566265060241   471 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.810843
2    0.895984
3    0.925703
4    0.950201
5    0.966265
6    0.975904
7    0.97992
8    0.984739
9    0.989157
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:50  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:50  3 min 48.495 sec  80056 obs/sec     1         1             10007      0.664612         1.29921             0.992149       0.3323                           0.665564           1.29844               0.992107         0.33253
    2019-08-04 09:03:51  3 min 49.436 sec  96499 obs/sec     10        10            100070     0.468867         0.682938            0.996092       0.188843                         0.470276           0.687932              0.996059         0.189157
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0942534
C13         0.915175               0.915175             0.0862583
C9          0.798537               0.798537             0.0752648
C8          0.794457               0.794457             0.0748803
C12         0.781306               0.781306             0.0736408
C7          0.770375               0.770375             0.0726104
C11         0.705566               0.705566             0.066502
C6          0.641132               0.641132             0.0604289
C10         0.614803               0.614803             0.0579472
C14         0.610084               0.610084             0.0575025
C5          0.561396               0.561396             0.0529135
C4          0.554904               0.554904             0.0523016
C16         0.550555               0.550555             0.0518917
C3          0.538507               0.538507             0.0507561
C2          0.405599               0.405599             0.0382291
C1          0.367299               0.367299             0.0346191
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_131

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012195122854734564  0.0003407364711165428  0.0         -0.01438442594339051  0.2096327543258667  0.07960598436903443  0.13541239500045776
    3        26       Softmax                      0.0   0.0   0.006791864679283977   0.016018323600292206   0.0         -0.22663444062344168  0.5298166275024414  -0.8882798970267175  0.429534912109375


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21674855823703187
RMSE: 0.4655626254726982
LogLoss: 0.6812582122459668
Mean Per-Class Error: 0.18492643590875554
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  2.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    2.0    1.0    6.0    2.0    1.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    2.0    1.0    6.0    0.0    0.09367088607594937  37 / 395
0.0    337.0  0.0    4.0    2.0    0.0    2.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    6.0    0.0    16.0   4.0    1.0    0.0    2.0    0.0    2.0    1.0    0.0    0.12010443864229765  46 / 383
0.0    0.0    286.0  0.0    13.0   1.0    24.0   0.0    0.0    0.0    25.0   0.0    1.0    0.0    6.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    5.0    0.0    0.0    0.0    0.22282608695652173  82 / 368
4.0    25.0   0.0    330.0  1.0    0.0    2.0    4.0    0.0    5.0    0.0    0.0    5.0    5.0    2.0    1.0    0.0    7.0    1.0    1.0    1.0    0.0    0.0    7.0    0.0    2.0    0.18114143920595532  73 / 403
0.0    8.0    0.0    0.0    309.0  2.0    16.0   0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    1.0    9.0    4.0    3.0    4.0    0.0    0.0    0.0    3.0    0.0    20.0   0.1953125            75 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    1.0    0.0    9.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    351.0  0.0    0.0    0.0    0.06648936170212766  25 / 376
0.0    3.0    0.0    2.0    8.0    2.0    0.0    2.0    2.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    10.0   1.0    8.0    3.0    4.0    0.0    0.0    333.0  2.0    4.0    0.15267175572519084  60 / 393
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    4.0    14.0   0.0    8.0    1.0    0.0    347.0  0.0    0.11479591836734694  45 / 392
0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    34.0   2.0    0.0    0.0    0.0    0.0    0.0    309.0  0.15803814713896458  58 / 367
402.0  545.0  306.0  407.0  403.0  348.0  413.0  288.0  339.0  351.0  409.0  336.0  419.0  382.0  376.0  394.0  365.0  402.0  334.0  373.0  381.0  363.0  454.0  407.0  420.0  386.0  0.18404478656403078  1,841 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.815955
2    0.891533
3    0.928222
4    0.945216
5    0.960212
6    0.970709
7    0.977707
8    0.983105
9    0.986404
10   0.989603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21921737334198751
RMSE: 0.4682065498708743
LogLoss: 0.6881705068881357
Mean Per-Class Error: 0.18680900692122318
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23    24     25     Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  --------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0    0.0898876404494382    8 / 89
0.0   90.0   0.0   0.0    1.0   0.0   0.0    0.0   1.0   0.0    1.0   0.0   0.0   0.0    2.0   2.0    0.0   5.0    1.0   0.0   0.0   2.0   0.0    1.0   0.0    0.0    0.1509433962264151    16 / 106
0.0   0.0    59.0  0.0    2.0   0.0   8.0    0.0   0.0   0.0    5.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.2804878048780488    23 / 82
3.0   3.0    0.0   94.0   0.0   0.0   1.0    2.0   0.0   1.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0    2.0   0.0    1.0    0.16071428571428573   18 / 112
0.0   1.0    0.0   0.0    72.0  1.0   5.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    1.0   2.0   0.0   0.0   0.0    1.0   0.0    10.0   0.25773195876288657   25 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   88.0   0.0   0.0    0.0    0.043478260869565216  4 / 92
0.0   1.0    0.0   1.0    5.0   1.0   0.0    2.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0   0.0   1.0   0.0   0.0    79.0  0.0    2.0    0.21                  21 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    4.0   0.0    0.0   3.0   0.0   2.0   1.0    0.0   95.0   0.0    0.11214953271028037   12 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    7.0   1.0   0.0   0.0   0.0    0.0   0.0    73.0   0.16091954022988506   14 / 87
96.0  134.0  61.0  113.0  92.0  80.0  109.0  77.0  81.0  103.0  97.0  89.0  92.0  103.0  76.0  113.0  96.0  101.0  85.0  88.0  95.0  82.0  110.0  95.0  117.0  105.0  0.18514056224899597   461 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814859
2    0.893574
3    0.929317
4    0.944177
5    0.957831
6    0.968273
7    0.9751
8    0.981928
9    0.986747
10   0.990361
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:41  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:41  3 min 39.178 sec  84805 obs/sec     1         1             10007      0.659913         1.28072             0.99226        0.317405                         0.660273           1.27876               0.992232         0.311647
    2019-08-04 09:03:42  3 min 40.127 sec  96406 obs/sec     10        10            100070     0.465563         0.681258            0.996147       0.184045                         0.468207           0.688171              0.996094         0.185141
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0917293
C13         0.962326               0.962326             0.0882735
C9          0.811167               0.811167             0.0744078
C12         0.810199               0.810199             0.074319
C8          0.792906               0.792906             0.0727327
C7          0.757242               0.757242             0.0694612
C11         0.711303               0.711303             0.0652474
C10         0.652232               0.652232             0.0598288
C14         0.641079               0.641079             0.0588057
C6          0.635058               0.635058             0.0582534
C5          0.614354               0.614354             0.0563542
C4          0.572571               0.572571             0.0525215
C3          0.558208               0.558208             0.051204
C16         0.552955               0.552955             0.0507221
C2          0.431194               0.431194             0.0395531
C1          0.398851               0.398851             0.0365863
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_83

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012541840749378252  0.00036352884490042925  0.0         -0.010267414937743524  0.21076470613479614  0.08108313589798644  0.15356719493865967
    3        26       Softmax                      0.0   0.0   0.006917728432479355   0.015524115413427353    0.0         -0.2144828806800114    0.5370869636535645   -0.9054075687266219  0.40831589698791504


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21741630254977348
RMSE: 0.46627921093457886
LogLoss: 0.6824603670110874
Mean Per-Class Error: 0.1843805593319382
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    6.0    1.0    3.0    0.0    2.0    0.0    0.0    0.0    7.0    0.0    1.0    1.0    2.0    2.0    6.0    0.0    0.08860759493670886  35 / 395
0.0    334.0  0.0    8.0    2.0    0.0    1.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    7.0    0.0    19.0   4.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.1279373368146214   49 / 383
0.0    0.0    304.0  0.0    13.0   1.0    9.0    1.0    0.0    0.0    22.0   0.0    0.0    0.0    5.0    0.0    2.0    0.0    5.0    3.0    0.0    0.0    3.0    0.0    0.0    0.0    0.17391304347826086  64 / 368
2.0    18.0   0.0    341.0  0.0    0.0    0.0    5.0    0.0    6.0    0.0    0.0    6.0    4.0    1.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.15384615384615385  62 / 403
0.0    6.0    0.0    0.0    311.0  1.0    13.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    7.0    4.0    12.0   4.0    0.0    0.0    0.0    4.0    0.0    17.0   0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    11.0   2.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    3.0    0.0    3.0    7.0    0.0    0.0    1.0    2.0    2.0    11.0   0.0    0.0    0.0    2.0    0.0    6.0    0.0    11.0   3.0    3.0    0.0    0.0    334.0  2.0    3.0    0.15012722646310434  59 / 393
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    4.0    18.0   4.0    11.0   1.0    0.0    339.0  0.0    0.13740458015267176  54 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    37.0   2.0    0.0    0.0    0.0    2.0    0.0    299.0  0.18528610354223432  68 / 367
416.0  484.0  360.0  437.0  399.0  363.0  334.0  320.0  337.0  349.0  389.0  339.0  430.0  385.0  411.0  384.0  331.0  441.0  408.0  384.0  372.0  352.0  423.0  408.0  385.0  362.0  0.1835449365190443   1,836 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816455
2    0.894832
3    0.927522
4    0.948016
5    0.961312
6    0.970709
7    0.976407
8    0.981605
9    0.985504
10   0.988304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22004422951250932
RMSE: 0.46908872243159855
LogLoss: 0.6906025621235776
Mean Per-Class Error: 0.1877863014877946
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0    3.0    0.0   0.07865168539325842  7 / 89
0.0    88.0   0.0   2.0    1.0   0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   2.0    0.0   5.0    1.0   0.0   0.0   0.0   1.0    1.0    0.0    0.0   0.16981132075471697  18 / 106
0.0    0.0    65.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    2.0   1.0   0.0   0.0   1.0    0.0    0.0    0.0   0.2073170731707317   17 / 82
2.0    3.0    0.0   95.0   0.0   0.0   0.0   2.0   0.0   3.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.15178571428571427  17 / 112
0.0    0.0    0.0   0.0    74.0  1.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    3.0   1.0   0.0   0.0   0.0    2.0    0.0    9.0   0.23711340206185566  23 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0    1.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    5.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    3.0   1.0   0.0   0.0   0.0    82.0   0.0    1.0   0.18                 18 / 100
0.0    0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    4.0   0.0    0.0   3.0   1.0   3.0   1.0    0.0    92.0   0.0   0.14018691588785046  15 / 107
1.0    0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0   1.0   0.0   0.0   0.0    1.0    0.0    71.0  0.1839080459770115   16 / 87
100.0  120.0  75.0  126.0  91.0  85.0  81.0  80.0  81.0  101.0  97.0  90.0  99.0  104.0  82.0  111.0  92.0  107.0  98.0  89.0  92.0  76.0  104.0  103.0  110.0  96.0  0.18714859437751005  466 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.812851
2    0.893976
3    0.9249
4    0.949799
5    0.962249
6    0.971486
7    0.97751
8    0.981526
9    0.985141
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:21  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:21  2 min 19.655 sec  83391 obs/sec     1         1             10007      0.659098         1.28261             0.99228        0.325202                         0.657562           1.27711               0.992295         0.326104
    2019-08-04 09:02:22  2 min 20.630 sec  94494 obs/sec     10        10            100070     0.466279         0.68246             0.996136       0.183545                         0.469089           0.690603              0.996079         0.187149
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0920786
C13         0.942893               0.942893             0.0868203
C9          0.835763               0.835763             0.0769559
C12         0.789752               0.789752             0.0727192
C7          0.783473               0.783473             0.0721411
C8          0.765916               0.765916             0.0705244
C11         0.69946                0.69946              0.0644053
C6          0.639189               0.639189             0.0588556
C14         0.638786               0.638786             0.0588185
C5          0.626328               0.626328             0.0576714
C10         0.605777               0.605777             0.0557791
C4          0.571557               0.571557             0.0526281
C3          0.571516               0.571516             0.0526243
C16         0.563313               0.563313             0.0518691
C2          0.415671               0.415671             0.0382744
C1          0.410895               0.410895             0.0378347
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_98

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013976687751551253  0.0003794271033257246  0.0         0.01825740360470718   0.7418949604034424  -0.14258320950993675  0.7976455688476562
    3        26       Softmax                 0.0   0.0   0.0019459413206277532  0.0002642319304868579  0.0         0.011476596574189339  0.5032515525817871  -0.45361157343297154  0.2439483404159546


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20926593165878743
RMSE: 0.4574559341169239
LogLoss: 0.700509202852964
Mean Per-Class Error: 0.20107244098254834
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    5.0    1.0    4.0    4.0    1.0    1.0    0.0    1.0    0.0    3.0    1.0    3.0    1.0    2.0    5.0    3.0    1.0    0.09873417721518987  39 / 395
0.0    318.0  0.0    5.0    1.0    2.0    2.0    2.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    30.0   6.0    2.0    0.0    6.0    1.0    2.0    1.0    0.0    0.16971279373368145  65 / 383
0.0    0.0    309.0  0.0    9.0    1.0    8.0    1.0    0.0    0.0    9.0    4.0    1.0    0.0    3.0    0.0    3.0    2.0    8.0    2.0    4.0    0.0    3.0    0.0    0.0    1.0    0.16032608695652173  59 / 368
1.0    23.0   0.0    317.0  0.0    2.0    0.0    12.0   1.0    6.0    0.0    0.0    7.0    1.0    5.0    4.0    0.0    12.0   1.0    1.0    0.0    0.0    0.0    6.0    0.0    2.0    0.20947630922693267  84 / 401
0.0    8.0    2.0    0.0    305.0  2.0    14.0   0.0    2.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    9.0    6.0    10.0   10.0   0.0    1.0    0.0    3.0    0.0    6.0    0.20365535248041775  78 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    1.0    0.0    24.0   3.0    2.0    0.0    0.0    1.0    0.0    0.0    1.0    2.0    329.0  0.0    0.0    0.0    0.125                47 / 376
0.0    5.0    0.0    3.0    6.0    3.0    0.0    0.0    4.0    2.0    17.0   0.0    0.0    0.0    0.0    0.0    10.0   5.0    10.0   1.0    2.0    2.0    0.0    319.0  1.0    4.0    0.19035532994923857  75 / 394
0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    9.0    25.0   4.0    11.0   1.0    2.0    333.0  1.0    0.15267175572519084  60 / 393
1.0    1.0    0.0    1.0    17.0   1.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    37.0   6.0    0.0    0.0    0.0    0.0    1.0    294.0  0.1989100817438692   73 / 367
398.0  509.0  370.0  420.0  378.0  365.0  310.0  326.0  337.0  349.0  369.0  343.0  473.0  353.0  368.0  386.0  353.0  504.0  398.0  426.0  395.0  380.0  375.0  382.0  382.0  354.0  0.20023992802159352  2,003 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.79976
2    0.884934
3    0.919824
4    0.940918
5    0.954913
6    0.964311
7    0.971808
8    0.977007
9    0.981805
10   0.986004

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2094929799988398
RMSE: 0.45770403100567053
LogLoss: 0.6969392573854402
Mean Per-Class Error: 0.2001680801596288
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18     19     20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0    0.0   1.0   1.0   2.0    1.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   2.0    1.0   0.0   1.0   1.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    0.0   9.0    3.0    0.0    0.0    1.0   1.0   1.0   0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    68.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0    1.0    0.0    0.0   2.0   0.0   0.0    0.0   0.17073170731707318  14 / 82
0.0   4.0    0.0   89.0   0.0   0.0   0.0   4.0   1.0   1.0   0.0   0.0   3.0    0.0   2.0   3.0    0.0   3.0    0.0    0.0    0.0    0.0   0.0   1.0   0.0    1.0   0.20535714285714285  23 / 112
0.0   2.0    0.0   0.0    74.0  2.0   4.0   0.0   1.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    2.0   1.0    3.0    3.0    0.0    0.0   0.0   0.0   0.0    2.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0    1.0   83.0  0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0   3.0    0.0   0.0    4.0   0.0   0.0   0.0   2.0   0.0   6.0   0.0   0.0    0.0   0.0   0.0    2.0   3.0    3.0    0.0    0.0    0.0   0.0   75.0  0.0    2.0   0.25                 25 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    2.0   0.0    2.0    8.0    2.0    1.0   1.0   0.0   91.0   0.0   0.14953271028037382  16 / 107
0.0   0.0    0.0   0.0    5.0   1.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    7.0    2.0    0.0    0.0   0.0   0.0   0.0    69.0  0.20689655172413793  18 / 87
93.0  134.0  77.0  120.0  94.0  83.0  71.0  77.0  84.0  97.0  91.0  90.0  106.0  91.0  69.0  113.0  92.0  133.0  108.0  104.0  102.0  89.0  96.0  89.0  103.0  84.0  0.19959839357429718  497 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.800402
2    0.882329
3    0.921285
4    0.943775
5    0.957831
6    0.96747
7    0.97751
8    0.981124
9    0.983534
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:45  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:45  2 min 43.466 sec  82024 obs/sec     1         1             10007      0.598842         1.13194             0.993627       0.297711                         0.597145           1.11964               0.993646         0.3
    2019-08-04 09:02:46  2 min 44.582 sec  82294 obs/sec     10        10            100070     0.457456         0.700509            0.996281       0.20024                          0.457704           0.696939              0.996267         0.199598
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0944307
C13         0.931366               0.931366             0.0879495
C9          0.853147               0.853147             0.0805632
C12         0.833864               0.833864             0.0787423
C8          0.737386               0.737386             0.0696319
C11         0.732245               0.732245             0.0691464
C7          0.705841               0.705841             0.066653
C10         0.647831               0.647831             0.0611751
C14         0.606765               0.606765             0.0572972
C16         0.584374               0.584374             0.0551828
C6          0.58114                0.58114              0.0548775
C3          0.557713               0.557713             0.0526652
C5          0.543204               0.543204             0.0512951
C4          0.467377               0.467377             0.0441348
C2          0.412548               0.412548             0.0389572
C1          0.394979               0.394979             0.0372981
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_151

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012734271268897146  0.0003606237005442381  0.0         -0.01283046783611752  0.20696264505386353  0.11169619952623475  0.14847582578659058
    3        26       Softmax                      0.0   0.0   0.006213254605864467   0.01457538828253746    0.0         -0.22590902276467026  0.530301570892334    -0.9204233542326355  0.40077638626098633


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2194444359335344
RMSE: 0.4684489683343687
LogLoss: 0.6929633430161027
Mean Per-Class Error: 0.1891785086241691
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    12.0   3.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    1.0    1.0    2.0    1.0    6.0    0.0    0.10126582278481013  40 / 395
0.0    329.0  0.0    6.0    3.0    1.0    4.0    3.0    2.0    0.0    1.0    0.0    1.0    0.0    1.0    3.0    0.0    20.0   5.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.1409921671018277   54 / 383
0.0    0.0    300.0  0.0    13.0   1.0    7.0    1.0    0.0    0.0    24.0   0.0    0.0    0.0    7.0    0.0    2.0    0.0    3.0    4.0    1.0    0.0    5.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
0.0    10.0   0.0    345.0  0.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    6.0    3.0    4.0    1.0    0.0    8.0    5.0    1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.1417910447761194   57 / 402
0.0    6.0    1.0    0.0    307.0  3.0    21.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    5.0    11.0   5.0    0.0    0.0    0.0    6.0    0.0    12.0   0.20052083333333334  77 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    2.0    0.0    18.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    2.0    6.0    0.0    0.0    0.0    2.0    1.0    7.0    0.0    0.0    0.0    2.0    0.0    6.0    0.0    13.0   2.0    1.0    0.0    0.0    347.0  4.0    0.0    0.11928934010152284  47 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    4.0    13.0   2.0    17.0   1.0    0.0    343.0  0.0    0.1272264631043257   50 / 393
3.0    0.0    0.0    0.0    18.0   0.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    30.0   3.0    0.0    0.0    0.0    0.0    0.0    299.0  0.18528610354223432  68 / 367
399.0  492.0  344.0  439.0  404.0  357.0  357.0  281.0  332.0  363.0  424.0  326.0  459.0  366.0  396.0  387.0  323.0  414.0  392.0  374.0  380.0  378.0  429.0  417.0  419.0  351.0  0.18824352694191743  1,883 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.811756
2    0.890833
3    0.925522
4    0.943817
5    0.957613
6    0.96791
7    0.974908
8    0.980606
9    0.985204
10   0.989403

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22107694969619252
RMSE: 0.4701882066749362
LogLoss: 0.697502445831119
Mean Per-Class Error: 0.18692952193032575
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17    18     19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   1.0    1.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   87.0   0.0   0.0    2.0   0.0   1.0   1.0   1.0   0.0    1.0    0.0   0.0    0.0   1.0   1.0    0.0   6.0   2.0    0.0   0.0   1.0   0.0    1.0    1.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    62.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   4.0   0.0    1.0   0.0   2.0    1.0   1.0   0.0   2.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
0.0   1.0    0.0   98.0   0.0   0.0   0.0   2.0   0.0   2.0    0.0    0.0   2.0    2.0   1.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.125                14 / 112
0.0   0.0    0.0   0.0    74.0  1.0   4.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    3.0   1.0   4.0    2.0   0.0   0.0   0.0    2.0    0.0    6.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   5.0    0.0   0.0   0.0   0.0    87.0   1.0    0.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0    2.0   0.0   0.0    3.0   0.0   5.0   1.0    0.0    95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    7.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   4.0    1.0   0.0   0.0   0.0    0.0    0.0    69.0  0.20689655172413793  18 / 87
94.0  118.0  71.0  122.0  98.0  81.0  92.0  72.0  79.0  105.0  103.0  87.0  106.0  98.0  81.0  108.0  88.0  99.0  102.0  89.0  94.0  85.0  108.0  103.0  120.0  87.0  0.1855421686746988   462 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814458
2    0.893976
3    0.928514
4    0.943373
5    0.958233
6    0.970683
7    0.976707
8    0.982329
9    0.984337
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:17  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:17  4 min 15.164 sec  94405 obs/sec     1         1             10007      0.658792         1.283               0.992287       0.324203                         0.658123           1.27727               0.992282         0.323695
    2019-08-04 09:04:18  4 min 16.078 sec  101490 obs/sec    10        10            100070     0.468449         0.692963            0.9961         0.188244                         0.470188           0.697502              0.996061         0.185542
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0876282
C13         0.938087               0.938087             0.0822028
C8          0.890986               0.890986             0.0780755
C12         0.835836               0.835836             0.0732428
C7          0.830858               0.830858             0.0728066
C9          0.80919                0.80919              0.0709079
C11         0.766743               0.766743             0.0671883
C6          0.71226                0.71226              0.062414
C5          0.68112                0.68112              0.0596853
C14         0.652197               0.652197             0.0571508
C10         0.612952               0.612952             0.0537119
C3          0.611225               0.611225             0.0535606
C4          0.600898               0.600898             0.0526556
C16         0.562657               0.562657             0.0493046
C2          0.464832               0.464832             0.0407324
C1          0.442013               0.442013             0.0387328
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_186

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012434923541491116  0.00036869081668555737  0.0         -0.011874208713253509  0.20922040939331055  0.0929543880519481   0.15648531913757324
    3        26       Softmax                      0.0   0.0   0.006275664701591337   0.013878859579563141    0.0         -0.2354568247017666    0.5296306610107422   -0.8859284231241575  0.38220322132110596


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21918156625877608
RMSE: 0.4681683097549172
LogLoss: 0.68455833479971
Mean Per-Class Error: 0.18975654588196028
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    7.0    5.0    1.0    5.0    0.0    4.0    0.0    0.0    1.0    6.0    0.0    1.0    2.0    2.0    0.0    7.0    0.0    0.10886075949367088  43 / 395
0.0    320.0  0.0    5.0    3.0    0.0    3.0    3.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    21.0   10.0   0.0    0.0    5.0    0.0    4.0    2.0    0.0    0.16449086161879894  63 / 383
0.0    0.0    299.0  0.0    11.0   2.0    16.0   2.0    0.0    0.0    18.0   1.0    0.0    0.0    4.0    0.0    1.0    0.0    7.0    1.0    0.0    0.0    6.0    0.0    0.0    0.0    0.1875               69 / 368
4.0    18.0   0.0    341.0  0.0    3.0    1.0    3.0    0.0    4.0    0.0    0.0    6.0    3.0    1.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.15384615384615385  62 / 403
0.0    7.0    0.0    0.0    312.0  1.0    14.0   0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    10.0   4.0    0.0    0.0    0.0    5.0    0.0    19.0   0.1875               72 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    16.0   0.0    0.0    1.0    0.0    11.0   1.0    3.0    0.0    0.0    1.0    0.0    0.0    2.0    3.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    2.0    0.0    3.0    8.0    0.0    0.0    1.0    2.0    1.0    6.0    3.0    0.0    0.0    2.0    0.0    1.0    0.0    3.0    2.0    5.0    0.0    0.0    345.0  3.0    6.0    0.12213740458015267  48 / 393
0.0    0.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    6.0    0.0    2.0    15.0   1.0    25.0   1.0    0.0    327.0  0.0    0.16793893129770993  66 / 393
1.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    18.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    30.0   2.0    0.0    0.0    0.0    2.0    0.0    298.0  0.1880108991825613   69 / 367
407.0  478.0  337.0  425.0  410.0  374.0  374.0  302.0  335.0  375.0  385.0  344.0  414.0  368.0  402.0  375.0  303.0  444.0  346.0  385.0  391.0  394.0  427.0  424.0  397.0  387.0  0.18884334699590122  1,889 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.811157
2    0.892232
3    0.926722
4    0.944417
5    0.960512
6    0.971009
7    0.978206
8    0.982705
9    0.986504
10   0.989303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22235554596191037
RMSE: 0.471545910767881
LogLoss: 0.6991026071760381
Mean Per-Class Error: 0.19119169336485825
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20    21    22     23     24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   1.0    0.0    3.0    0.0    0.0898876404494382   8 / 89
0.0    83.0   0.0   1.0    2.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   9.0    2.0   0.0   0.0   4.0   0.0    2.0    0.0    0.0    0.2169811320754717   23 / 106
0.0    0.0    62.0  0.0    3.0   0.0   5.0   1.0   0.0   0.0    4.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   2.0    0.0    0.0    0.0    0.24390243902439024  20 / 82
3.0    3.0    0.0   95.0   0.0   1.0   1.0   2.0   0.0   1.0    0.0   0.0   2.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0    0.15178571428571427  17 / 112
0.0    1.0    0.0   0.0    72.0  1.0   3.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    4.0   1.0   0.0   0.0   0.0    2.0    0.0    9.0    0.25773195876288657  25 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   84.0   0.0    0.0    0.0    0.08695652173913043  8 / 92
0.0    0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    3.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0   0.0   0.0    84.0   0.0    3.0    0.16                 16 / 100
0.0    0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    3.0   0.0    0.0   3.0   0.0   9.0   1.0    0.0    87.0   0.0    0.18691588785046728  20 / 107
1.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   5.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0    0.0    0.0    71.0   0.1839080459770115   16 / 87
100.0  110.0  70.0  115.0  93.0  89.0  95.0  78.0  80.0  107.0  96.0  92.0  93.0  99.0  79.0  106.0  83.0  118.0  85.0  92.0  98.0  97.0  102.0  102.0  107.0  104.0  0.19076305220883535  475 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.809237
2    0.88996
3    0.926104
4    0.944177
5    0.960241
6    0.968675
7    0.97751
8    0.980723
9    0.983936
10   0.98755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:33  5 min 31.378 sec  83391 obs/sec     1         1             10007      0.654263         1.27271             0.992393       0.315005                         0.654862           1.2753                0.992359         0.320482
    2019-08-04 09:05:34  5 min 32.342 sec  95033 obs/sec     10        10            100070     0.468168         0.684558            0.996105       0.188843                         0.471546           0.699103              0.996038         0.190763
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0915483
C13         0.932518               0.932518             0.0853704
C9          0.834783               0.834783             0.076423
C8          0.826496               0.826496             0.0756643
C12         0.790077               0.790077             0.0723302
C7          0.768287               0.768287             0.0703353
C11         0.723931               0.723931             0.0662746
C5          0.661391               0.661391             0.0605493
C6          0.62799                0.62799              0.0574915
C14         0.619096               0.619096             0.0566772
C4          0.595294               0.595294             0.0544982
C10         0.586771               0.586771             0.0537179
C3          0.564572               0.564572             0.0516856
C16         0.559699               0.559699             0.0512395
C1          0.419682               0.419682             0.0384211
C2          0.412607               0.412607             0.0377735
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_130

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012384640605205277  0.00034927879460155964  0.0         -0.011822587919411376  0.20528066158294678  0.10808791007747216  0.14519351720809937
    3        26       Softmax                      0.0   0.0   0.007676444808671827   0.02811911702156067     0.0         -0.22507299440833498   0.5351357460021973   -0.9094211061697499  0.3641470670700073


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21873303934027197
RMSE: 0.4676890412873408
LogLoss: 0.6922935839382682
Mean Per-Class Error: 0.1841312572707947
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    4.0    5.0    1.0    5.0    0.0    4.0    0.0    0.0    0.0    6.0    0.0    1.0    2.0    2.0    2.0    5.0    1.0    0.10152284263959391  40 / 394
0.0    330.0  0.0    4.0    3.0    1.0    2.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    18.0   8.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.13612565445026178  52 / 382
0.0    0.0    302.0  0.0    11.0   0.0    8.0    0.0    0.0    0.0    24.0   0.0    1.0    0.0    5.0    0.0    5.0    0.0    5.0    2.0    2.0    0.0    3.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
4.0    17.0   0.0    346.0  0.0    0.0    1.0    4.0    0.0    4.0    0.0    0.0    6.0    4.0    2.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.141439205955335    57 / 403
0.0    5.0    0.0    0.0    306.0  2.0    10.0   0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    1.0    11.0   4.0    16.0   4.0    0.0    0.0    0.0    5.0    1.0    14.0   0.203125             78 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    12.0   1.0    3.0    0.0    0.0    4.0    0.0    0.0    3.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    3.0    0.0    4.0    3.0    0.0    0.0    1.0    2.0    1.0    9.0    1.0    0.0    0.0    0.0    0.0    8.0    1.0    8.0    2.0    1.0    1.0    0.0    342.0  4.0    3.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    4.0    26.0   2.0    26.0   1.0    0.0    313.0  0.0    0.2035623409669211   80 / 393
0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    49.0   2.0    0.0    0.0    0.0    3.0    0.0    291.0  0.20708446866485014  76 / 367
402.0  475.0  357.0  433.0  387.0  390.0  317.0  325.0  338.0  340.0  390.0  349.0  417.0  376.0  397.0  361.0  364.0  421.0  427.0  384.0  390.0  407.0  420.0  427.0  361.0  348.0  0.18334499650104968  1,834 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816655
2    0.892632
3    0.923823
4    0.942617
5    0.957813
6    0.969009
7    0.976507
8    0.981306
9    0.984704
10   0.987803

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22042127942903292
RMSE: 0.4694904465790895
LogLoss: 0.6991506875630369
Mean Per-Class Error: 0.18138081811942433
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   1.0   1.0    0.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   88.0   0.0   0.0    2.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    0.0   7.0    2.0    0.0   0.0   2.0   0.0    1.0    0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    62.0  0.0    3.0   0.0   3.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    3.0   0.0    2.0   0.0    2.0    1.0   0.0   0.0   1.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
3.0   1.0    0.0   96.0   0.0   0.0   1.0   2.0   0.0   1.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0    2.0    0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    74.0  1.0   3.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    5.0    2.0   0.0   0.0   0.0    1.0    0.0    6.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    1.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0    0.0   0.0   0.0   0.0    85.0   1.0    2.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    5.0   0.0    0.0    5.0   0.0   7.0   1.0    0.0    88.0   0.0   0.17757009345794392  19 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    11.0   1.0   0.0   0.0   0.0    1.0    0.0    68.0  0.21839080459770116  19 / 87
98.0  112.0  76.0  119.0  91.0  92.0  76.0  78.0  79.0  101.0  99.0  94.0  94.0  101.0  81.0  103.0  98.0  110.0  110.0  87.0  95.0  96.0  102.0  104.0  103.0  91.0  0.18112449799196786  451 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818875
2    0.892369
3    0.924498
4    0.945381
5    0.959036
6    0.96988
7    0.976707
8    0.979518
9    0.983133
10   0.987149
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:40  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:40  3 min 38.176 sec  79420 obs/sec     1         1             10007      0.662082         1.30446             0.992209       0.313606                         0.663755           1.30758               0.99215          0.323695
    2019-08-04 09:03:41  3 min 39.015 sec  106570 obs/sec    10        10            100070     0.467689         0.692294            0.996112       0.183345                         0.46949            0.699151              0.996072         0.181124
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0924637
C13         0.948461               0.948461             0.0876983
C8          0.832962               0.832962             0.0770188
C7          0.8279                 0.8279               0.0765507
C12         0.773167               0.773167             0.0714899
C9          0.771501               0.771501             0.0713359
C11         0.724669               0.724669             0.0670056
C5          0.644668               0.644668             0.0596084
C6          0.6252                 0.6252               0.0578083
C14         0.617216               0.617216             0.0570701
C16         0.57536                0.57536              0.0531999
C4          0.570603               0.570603             0.0527601
C10         0.57054                0.57054              0.0527542
C3          0.532013               0.532013             0.0491919
C2          0.427956               0.427956             0.0395704
C1          0.372836               0.372836             0.0344738
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_216

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012394196734533125  0.00036531698424369097  0.0         -0.010407796381329604  0.20741522312164307  0.0981267530746626   0.13851654529571533
    3        26       Softmax                      0.0   0.0   0.006913956101225967   0.017656370997428894    0.0         -0.21951950077284174   0.5303506851196289   -0.8946997025911079  0.3830314874649048


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22121833257446327
RMSE: 0.4703385297575176
LogLoss: 0.6969356261672198
Mean Per-Class Error: 0.19089847145308056
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    3.0    2.0    1.0    9.0    0.0    1.0    0.0    0.0    1.0    7.0    1.0    2.0    2.0    1.0    0.0    5.0    0.0    0.09873417721518987  39 / 395
0.0    338.0  0.0    3.0    3.0    0.0    1.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    3.0    0.0    15.0   6.0    0.0    0.0    2.0    0.0    2.0    2.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    296.0  0.0    18.0   0.0    10.0   1.0    0.0    0.0    20.0   0.0    0.0    0.0    5.0    0.0    1.0    0.0    6.0    5.0    0.0    0.0    6.0    0.0    0.0    0.0    0.1956521739130435   72 / 368
1.0    21.0   0.0    345.0  0.0    0.0    0.0    3.0    0.0    3.0    1.0    0.0    7.0    3.0    3.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.14392059553349876  58 / 403
0.0    14.0   0.0    0.0    298.0  2.0    6.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    2.0    10.0   3.0    13.0   4.0    0.0    0.0    0.0    7.0    0.0    16.0   0.22395833333333334  86 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    1.0    0.0    8.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    347.0  0.0    0.0    0.0    0.07466666666666667  28 / 375
0.0    2.0    0.0    2.0    4.0    0.0    0.0    0.0    2.0    1.0    4.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    7.0    2.0    5.0    0.0    0.0    346.0  3.0    6.0    0.11959287531806616  47 / 393
0.0    0.0    0.0    1.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    4.0    29.0   2.0    8.0    1.0    0.0    333.0  0.0    0.15267175572519084  60 / 393
4.0    0.0    0.0    1.0    13.0   0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    26.0   5.0    0.0    0.0    0.0    2.0    0.0    303.0  0.17438692098092642  64 / 367
404.0  538.0  343.0  422.0  387.0  334.0  297.0  308.0  341.0  341.0  392.0  330.0  429.0  385.0  390.0  392.0  341.0  408.0  394.0  418.0  397.0  367.0  424.0  451.0  391.0  379.0  0.18994301709487155  1,900 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.810057
2    0.890033
3    0.921923
4    0.943417
5    0.959212
6    0.970409
7    0.975807
8    0.980006
9    0.984305
10   0.988503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2238904487268469
RMSE: 0.4731706338382031
LogLoss: 0.7042393956927807
Mean Per-Class Error: 0.1921758220549895
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19     20    21    22     23     24     25     Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  -----  ----  ----  -----  -----  -----  -----  --------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0    0.0   2.0   0.0    0.0    3.0    0.0    0.10112359550561797   9 / 89
0.0   86.0   0.0   1.0    2.0   0.0   0.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0   5.0    3.0    0.0    0.0   2.0   0.0    2.0    0.0    0.0    0.18867924528301888   20 / 106
0.0   0.0    62.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0    2.0    0.0   0.0   2.0    0.0    0.0    0.0    0.24390243902439024   20 / 82
1.0   3.0    0.0   99.0   0.0   0.0   0.0   2.0   0.0   0.0    1.0   0.0   3.0   1.0    0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    2.0    0.0    0.0    0.11607142857142858   13 / 112
0.0   2.0    0.0   0.0    72.0  2.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    3.0    1.0    0.0   0.0   0.0    1.0    0.0    8.0    0.25773195876288657   25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---    ---   ---   ---    ---    ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   88.0   0.0    0.0    0.0    0.043478260869565216  4 / 92
0.0   0.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0    0.0    1.0   0.0   0.0    89.0   0.0    2.0    0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    1.0    6.0    1.0   1.0   1.0    0.0    92.0   0.0    0.14018691588785046   15 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0    2.0    0.0   0.0   0.0    0.0    0.0    72.0   0.1724137931034483    15 / 87
94.0  121.0  74.0  115.0  91.0  78.0  74.0  76.0  81.0  100.0  99.0  87.0  96.0  103.0  80.0  109.0  92.0  108.0  100.0  101.0  99.0  85.0  105.0  112.0  109.0  101.0  0.19076305220883535   475 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.809237
2    0.888755
3    0.920482
4    0.943373
5    0.961044
6    0.973092
7    0.977912
8    0.981928
9    0.986345
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:19  6 min 16.845 sec  84805 obs/sec     1         1             10007      0.662287         1.2945              0.992204       0.311906                         0.661247           1.28879               0.992209         0.31245
    2019-08-04 09:06:20  6 min 17.821 sec  94405 obs/sec     10        10            100070     0.470339         0.696936            0.996068       0.189943                         0.473171           0.704239              0.996011         0.190763
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.094761
C13         0.949129               0.949129             0.0899404
C9          0.787883               0.787883             0.0746606
C12         0.770625               0.770625             0.0730252
C8          0.740466               0.740466             0.0701673
C7          0.736335               0.736335             0.0697758
C11         0.719883               0.719883             0.0682168
C5          0.618565               0.618565             0.0586158
C6          0.615192               0.615192             0.0582962
C14         0.60651                0.60651              0.0574736
C10         0.604533               0.604533             0.0572861
C3          0.553226               0.553226             0.0524243
C16         0.536788               0.536788             0.0508666
C4          0.527972               0.527972             0.0500312
C2          0.398683               0.398683             0.0377796
C1          0.387074               0.387074             0.0366795
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_161

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007616720770329266  0.00015603238716721535  0.0         -0.02383222957405451  0.29260730743408203  0.161750913321824    0.2070983648300171
    3        26       Softmax                      0.0   0.0   0.005636793646352509   0.01573096215724945     0.0         -0.382515135678869    0.8832988739013672   -0.4772205145361145  0.521709680557251


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21976306510984384
RMSE: 0.46878893450021175
LogLoss: 0.7130274383807625
Mean Per-Class Error: 0.19942325532621932
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    2.0    0.0    0.0    2.0    1.0    0.0    1.0    3.0    1.0    6.0    0.0    2.0    0.0    3.0    0.0    3.0    2.0    0.0    0.0    5.0    2.0    4.0    0.0    0.09367088607594937  37 / 395
1.0    321.0  0.0    2.0    1.0    0.0    4.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    5.0    33.0   4.0    0.0    0.0    2.0    0.0    3.0    1.0    0.0    0.1618798955613577   62 / 383
0.0    0.0    289.0  0.0    16.0   0.0    11.0   6.0    1.0    0.0    17.0   0.0    1.0    1.0    3.0    0.0    6.0    0.0    6.0    4.0    1.0    0.0    6.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
1.0    26.0   0.0    325.0  1.0    0.0    1.0    8.0    2.0    5.0    0.0    1.0    6.0    2.0    4.0    2.0    2.0    8.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    5.0    0.1935483870967742   78 / 403
0.0    2.0    3.0    0.0    310.0  2.0    15.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    13.0   4.0    6.0    8.0    0.0    0.0    0.0    2.0    0.0    13.0   0.1906005221932115   73 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    13.0   1.0    3.0    0.0    1.0    6.0    0.0    0.0    1.0    1.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
16.0   5.0    1.0    6.0    8.0    0.0    1.0    2.0    3.0    4.0    1.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    5.0    5.0    2.0    0.0    0.0    315.0  9.0    7.0    0.20050761421319796  79 / 394
1.0    0.0    0.0    3.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    7.0    7.0    1.0    32.0   1.0    0.0    318.0  0.0    0.19083969465648856  75 / 393
5.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    1.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    17.0   3.0    0.0    0.0    0.0    0.0    0.0    315.0  0.14168937329700274  52 / 367
437.0  491.0  334.0  408.0  396.0  339.0  366.0  297.0  340.0  352.0  354.0  339.0  422.0  388.0  394.0  412.0  407.0  498.0  305.0  376.0  371.0  362.0  422.0  406.0  384.0  403.0  0.19844046785964212  1,985 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.801559
2    0.886034
3    0.921324
4    0.939818
5    0.954913
6    0.963811
7    0.971009
8    0.976007
9    0.981306
10   0.984805

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22119889272224658
RMSE: 0.47031786349472904
LogLoss: 0.7136506170713429
Mean Per-Class Error: 0.2004019286366526
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20    21    22     23     24     25    Error                 Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  -----  ----  --------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.0   2.0    1.0    2.0    0.0   0.0898876404494382    8 / 89
0.0    85.0   0.0   0.0    1.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0    9.0    0.0   0.0   0.0   1.0   0.0    1.0    1.0    0.0   0.19811320754716982   21 / 106
0.0    0.0    60.0  0.0    4.0   0.0   2.0   3.0   0.0   0.0    3.0   0.0   0.0   1.0    1.0   0.0    2.0    0.0    3.0   1.0   0.0   0.0   2.0    0.0    0.0    0.0   0.2682926829268293    22 / 82
1.0    4.0    0.0   92.0   0.0   0.0   1.0   2.0   1.0   1.0    0.0   1.0   2.0   1.0    1.0   1.0    0.0    1.0    0.0   0.0   1.0   0.0   0.0    2.0    0.0    0.0   0.17857142857142858   20 / 112
0.0    0.0    0.0   0.0    72.0  1.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    3.0    1.0    3.0   4.0   0.0   0.0   0.0    1.0    0.0    7.0   0.25773195876288657   25 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                   ---
0.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0   1.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
4.0    2.0    0.0   1.0    3.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    3.0   0.0   0.0   0.0   0.0    80.0   3.0    1.0   0.2                   20 / 100
1.0    0.0    0.0   1.0    0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    5.0    0.0    0.0   2.0   0.0   12.0  1.0    0.0    82.0   0.0   0.2336448598130841    25 / 107
2.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    3.0   0.0   0.0   0.0   0.0    0.0    0.0    75.0  0.13793103448275862   12 / 87
101.0  123.0  68.0  113.0  94.0  80.0  91.0  79.0  82.0  102.0  81.0  91.0  92.0  102.0  76.0  115.0  108.0  134.0  74.0  89.0  95.0  85.0  106.0  105.0  105.0  99.0  0.19919678714859437   496 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.800803
2    0.887952
3    0.921687
4    0.938554
5    0.953012
6    0.961847
7    0.970281
8    0.975502
9    0.97992
10   0.983936
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:35  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:35  4 min 33.159 sec  181945 obs/sec    1         1             10007      0.698625         1.49635             0.991327       0.408677                         0.699786           1.48824               0.991274         0.420482
    2019-08-04 09:04:35  4 min 33.575 sec  218971 obs/sec    10        10            100070     0.468789         0.713027            0.996095       0.19844                          0.470318           0.713651              0.996059         0.199197
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.105487
C8          0.797369               0.797369             0.084112
C13         0.758838               0.758838             0.0800474
C9          0.691871               0.691871             0.0729833
C11         0.657613               0.657613             0.0693695
C12         0.604684               0.604684             0.0637863
C6          0.592328               0.592328             0.0624828
C14         0.576828               0.576828             0.0608477
C7          0.574045               0.574045             0.0605542
C5          0.56944                0.56944              0.0600684
C3          0.536608               0.536608             0.0566051
C10         0.471002               0.471002             0.0496845
C4          0.462251               0.462251             0.0487614
C16         0.446261               0.446261             0.0470747
C1          0.372008               0.372008             0.0392419
C2          0.368708               0.368708             0.0388939
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_87

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013048974701064253  0.0003662845119833946   0.0         -0.027897181920877756   0.6975476741790771  -0.10822625688354809  0.8335297107696533
    3        26       Softmax                 0.0   0.0   0.0019361433605109386  0.00038254796527326107  0.0         -0.0003325293177322937  0.5057628154754639  -0.45689969553584514  0.1845141053199768


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21029800716336855
RMSE: 0.4585826066952044
LogLoss: 0.7145458679302079
Mean Per-Class Error: 0.21111896199020663
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    1.0    6.0    0.0    6.0    0.0    2.0    0.0    5.0    1.0    2.0    3.0    5.0    0.0    3.0    1.0    0.09873417721518987  39 / 395
1.0    325.0  0.0    13.0   2.0    3.0    0.0    1.0    3.0    0.0    7.0    0.0    1.0    0.0    0.0    1.0    0.0    14.0   4.0    0.0    1.0    1.0    0.0    5.0    1.0    0.0    0.1514360313315927   58 / 383
0.0    0.0    283.0  0.0    21.0   1.0    22.0   0.0    0.0    0.0    13.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    12.0   1.0    7.0    0.0    6.0    0.0    0.0    0.0    0.23097826086956522  85 / 368
4.0    10.0   0.0    326.0  0.0    5.0    0.0    12.0   0.0    4.0    1.0    0.0    2.0    5.0    8.0    0.0    0.0    14.0   0.0    0.0    5.0    0.0    0.0    7.0    0.0    0.0    0.19106699751861042  77 / 403
0.0    16.0   3.0    0.0    286.0  1.0    19.0   0.0    1.0    0.0    4.0    1.0    0.0    0.0    1.0    2.0    8.0    3.0    4.0    3.0    0.0    0.0    0.0    3.0    0.0    29.0   0.2552083333333333   98 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    2.0    9.0    0.0    0.0    0.0    0.0    11.0   3.0    4.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    337.0  0.0    0.0    0.0    0.10133333333333333  38 / 375
0.0    6.0    0.0    12.0   10.0   5.0    2.0    5.0    10.0   1.0    11.0   0.0    0.0    0.0    0.0    0.0    13.0   0.0    2.0    2.0    1.0    0.0    0.0    305.0  6.0    3.0    0.22588832487309646  89 / 394
0.0    0.0    0.0    1.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    1.0    6.0    0.0    3.0    14.0   3.0    14.0   1.0    0.0    341.0  0.0    0.13231552162849872  52 / 393
2.0    3.0    0.0    0.0    9.0    4.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    24.0   4.0    0.0    0.0    0.0    4.0    0.0    303.0  0.17438692098092642  64 / 367
401.0  556.0  317.0  436.0  374.0  353.0  386.0  313.0  347.0  351.0  356.0  338.0  426.0  361.0  393.0  373.0  408.0  418.0  261.0  374.0  441.0  343.0  440.0  381.0  451.0  405.0  0.2099370188943317   2,100 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790063
2    0.879636
3    0.914526
4    0.935719
5    0.951115
6    0.961112
7    0.969809
8    0.976407
9    0.981706
10   0.985004

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21235708358714256
RMSE: 0.4608221821778359
LogLoss: 0.7182573895828723
Mean Per-Class Error: 0.21404694511274902
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0   1.0    0.0   2.0    0.0   2.0    0.0    0.0898876404494382   8 / 89
0.0   89.0   0.0   2.0    1.0   1.0   0.0   0.0   1.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    0.0    5.0    1.0   0.0   1.0    1.0   0.0    2.0   0.0    0.0    0.16037735849056603  17 / 106
0.0   0.0    56.0  0.0    4.0   1.0   10.0  0.0   0.0   0.0    3.0   0.0   0.0   0.0   1.0   0.0    0.0    0.0    4.0   0.0   1.0    0.0   2.0    0.0   0.0    0.0    0.3170731707317073   26 / 82
3.0   0.0    0.0   93.0   0.0   1.0   0.0   3.0   0.0   1.0    0.0   0.0   1.0   1.0   1.0   0.0    0.0    3.0    0.0   0.0   2.0    0.0   0.0    3.0   0.0    0.0    0.16964285714285715  19 / 112
0.0   2.0    1.0   0.0    70.0  1.0   6.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    1.0    1.0    1.0   1.0   0.0    0.0   0.0    1.0   0.0    10.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   1.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   2.0    0.0   5.0    4.0   1.0   1.0   2.0   3.0   0.0    5.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0    1.0   0.0   0.0    0.0   0.0    70.0  2.0    1.0    0.3                  30 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   1.0   0.0    3.0    0.0    0.0   2.0   1.0    3.0   1.0    0.0   95.0   0.0    0.11214953271028037  12 / 107
1.0   1.0    0.0   0.0    3.0   1.0   0.0   0.0   1.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    3.0   0.0   0.0    0.0   0.0    1.0   0.0    73.0   0.16091954022988506  14 / 87
95.0  137.0  62.0  126.0  92.0  79.0  96.0  77.0  81.0  106.0  92.0  87.0  94.0  88.0  77.0  108.0  108.0  101.0  65.0  87.0  116.0  78.0  115.0  92.0  124.0  107.0  0.21164658634538153  527 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788353
2    0.8751
3    0.916867
4    0.935341
5    0.951406
6    0.961847
7    0.970683
8    0.976305
9    0.982731
10   0.985944
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:27  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:27  2 min 25.050 sec  83391 obs/sec     1         1             10007      0.599808         1.14463             0.993606       0.307908                         0.599717           1.13676               0.993591         0.309237
    2019-08-04 09:02:28  2 min 26.140 sec  84234 obs/sec     10        10            100070     0.458583         0.714546            0.996263       0.209937                         0.460822           0.718257              0.996216         0.211647
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0892855
C13         0.988227               0.988227             0.0882344
C9          0.94374                0.94374              0.0842624
C12         0.888013               0.888013             0.0792867
C11         0.813975               0.813975             0.0726762
C8          0.808855               0.808855             0.072219
C7          0.79989                0.79989              0.0714186
C14         0.71015                0.71015              0.0634061
C10         0.703048               0.703048             0.062772
C6          0.642316               0.642316             0.0573495
C16         0.594178               0.594178             0.0530515
C5          0.531536               0.531536             0.0474585
C3          0.528907               0.528907             0.0472237
C4          0.493417               0.493417             0.044055
C1          0.383893               0.383893             0.0342761
C2          0.369879               0.369879             0.0330248
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_75

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007881723407194841  0.00018157745944336057  0.0         -0.02431640380010336  0.28253984451293945  0.26203843202988725  0.22414875030517578
    3        26       Softmax                      0.0   0.0   0.005066859364678049   0.013224765658378601    0.0         -0.3743733970453692   0.8990259170532227   -0.4730596351140543  0.4125097990036011


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.218760882314794
RMSE: 0.4677188068859258
LogLoss: 0.7102568865659201
Mean Per-Class Error: 0.20498443504209252
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    4.0    1.0    3.0    1.0    7.0    0.0    2.0    1.0    6.0    0.0    1.0    1.0    0.0    7.0    5.0    0.0    0.10632911392405063  42 / 395
0.0    315.0  0.0    7.0    2.0    1.0    7.0    6.0    1.0    0.0    6.0    0.0    0.0    0.0    2.0    8.0    1.0    11.0   9.0    0.0    1.0    0.0    2.0    3.0    1.0    0.0    0.17754569190600522  68 / 383
0.0    0.0    295.0  0.0    18.0   2.0    5.0    2.0    0.0    0.0    28.0   0.0    0.0    0.0    2.0    0.0    2.0    0.0    8.0    1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.19618528610354224  72 / 367
2.0    23.0   0.0    306.0  0.0    1.0    0.0    15.0   1.0    3.0    2.0    0.0    2.0    3.0    2.0    4.0    2.0    14.0   2.0    0.0    7.0    0.0    0.0    13.0   0.0    1.0    0.24069478908188585  97 / 403
0.0    13.0   0.0    0.0    299.0  4.0    20.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    19.0   5.0    0.0    0.0    0.0    3.0    0.0    9.0    0.22135416666666666  85 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    0.0    2.0    0.0    13.0   9.0    1.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    332.0  0.0    0.0    0.0    0.11702127659574468  44 / 376
0.0    2.0    0.0    2.0    13.0   0.0    1.0    2.0    2.0    1.0    2.0    1.0    0.0    0.0    2.0    0.0    4.0    1.0    1.0    3.0    2.0    1.0    0.0    341.0  5.0    8.0    0.13451776649746192  53 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    18.0   0.0    2.0    33.0   1.0    33.0   1.0    1.0    289.0  0.0    0.26463104325699743  104 / 393
0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    33.0   2.0    0.0    0.0    0.0    3.0    0.0    298.0  0.1880108991825613   69 / 367
392.0  470.0  342.0  380.0  429.0  329.0  349.0  346.0  338.0  342.0  415.0  317.0  422.0  383.0  395.0  449.0  364.0  425.0  436.0  389.0  382.0  380.0  397.0  450.0  340.0  342.0  0.20443866839948016  2,045 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.795561
2    0.885234
3    0.920824
4    0.941318
5    0.956613
6    0.96651
7    0.972608
8    0.977907
9    0.982105
10   0.986104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22111853324279884
RMSE: 0.4702324247037829
LogLoss: 0.7192464901840898
Mean Per-Class Error: 0.209210199277382
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10     11    12    13     14    15     16     17     18     19    20    21    22    23     24    25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0    0.0   0.0   1.0   0.0   1.0    3.0   0.0   0.07865168539325842  7 / 89
0.0   81.0   0.0   1.0    1.0    0.0   2.0   3.0   0.0   0.0   1.0    0.0   0.0   0.0    1.0   3.0    1.0    6.0    3.0    0.0   0.0   0.0   2.0   1.0    0.0   0.0   0.2358490566037736   25 / 106
0.0   0.0    60.0  0.0    4.0    0.0   0.0   1.0   0.0   0.0   10.0   0.0   0.0   0.0    1.0   0.0    1.0    0.0    3.0    1.0   0.0   0.0   1.0   0.0    0.0   0.0   0.2682926829268293   22 / 82
2.0   3.0    0.0   86.0   0.0    0.0   0.0   4.0   1.0   2.0   1.0    0.0   1.0   2.0    0.0   2.0    0.0    3.0    0.0    0.0   3.0   0.0   0.0   2.0    0.0   0.0   0.23214285714285715  26 / 112
0.0   1.0    0.0   0.0    72.0   4.0   6.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   1.0    0.0    1.0    5.0    2.0   0.0   0.0   0.0   1.0    0.0   2.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---   ---   ---   ---   ---    ---   ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   4.0   4.0    0.0   0.0    1.0    0.0    0.0    0.0   0.0   0.0   81.0  0.0    0.0   0.0   0.11956521739130435  11 / 92
0.0   0.0    0.0   1.0    8.0    0.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0    0.0   0.0   0.0   0.0   83.0   2.0   2.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   5.0    6.0    0.0    0.0    8.0   0.0   8.0   1.0   0.0    78.0  0.0   0.27102803738317754  29 / 107
0.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    7.0    1.0   0.0   0.0   0.0   1.0    0.0   72.0  0.1724137931034483   15 / 87
98.0  122.0  72.0  102.0  101.0  80.0  84.0  88.0  79.0  97.0  104.0  83.0  92.0  102.0  80.0  124.0  100.0  107.0  117.0  92.0  99.0  86.0  92.0  110.0  96.0  83.0  0.20923694779116467  521 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790763
2    0.883936
3    0.920482
4    0.944578
5    0.956225
6    0.96506
7    0.971486
8    0.976707
9    0.982329
10   0.986747
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:05  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:05  2 min  2.843 sec  169610 obs/sec    1         1             10007      0.686362         1.44813             0.991629       0.394482                         0.688044           1.45942               0.991565         0.39759
    2019-08-04 09:02:05  2 min  3.326 sec  189168 obs/sec    10        10            100070     0.467719         0.710257            0.996113       0.204439                         0.470232           0.719246              0.99606          0.209237
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0897279
C13         0.973933               0.973933             0.0873889
C8          0.924109               0.924109             0.0829183
C9          0.820133               0.820133             0.0735888
C7          0.812061               0.812061             0.0728645
C12         0.770735               0.770735             0.0691564
C11         0.710838               0.710838             0.063782
C6          0.665297               0.665297             0.0596957
C16         0.629133               0.629133             0.0564507
C4          0.626002               0.626002             0.0561699
C5          0.61249                0.61249              0.0549575
C10         0.609729               0.609729             0.0547097
C14         0.602653               0.602653             0.0540747
C3          0.527295               0.527295             0.047313
C1          0.441254               0.441254             0.0395928
C2          0.419147               0.419147             0.0376092
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_34

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.001400662822106824   0.00036465178709477186  0.0         -0.0007486034604085035  0.7418274879455566  -0.05045195517521808  0.7590360641479492
    3        26       Softmax                 0.0   0.0   0.0019548680495343152  0.00034764246083796024  0.0         0.00251011227678296     0.50132155418396    -0.44774432209195936  0.21437925100326538


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21418354664519815
RMSE: 0.46279968306514446
LogLoss: 0.7199972402287931
Mean Per-Class Error: 0.21243909962493912
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    5.0    3.0    3.0    4.0    0.0    4.0    0.0    2.0    1.0    2.0    1.0    1.0    0.0    3.0    3.0    5.0    0.0    0.10126582278481013  40 / 395
0.0    318.0  0.0    7.0    2.0    0.0    6.0    9.0    2.0    1.0    5.0    0.0    1.0    0.0    0.0    4.0    0.0    16.0   5.0    0.0    1.0    0.0    3.0    1.0    1.0    1.0    0.16971279373368145  65 / 383
0.0    0.0    293.0  0.0    12.0   5.0    14.0   0.0    0.0    0.0    19.0   2.0    0.0    0.0    11.0   0.0    3.0    0.0    2.0    0.0    3.0    0.0    2.0    1.0    0.0    1.0    0.20380434782608695  75 / 368
5.0    14.0   0.0    326.0  0.0    1.0    0.0    10.0   0.0    4.0    0.0    2.0    6.0    8.0    2.0    3.0    1.0    8.0    3.0    0.0    2.0    0.0    0.0    6.0    0.0    2.0    0.19106699751861042  77 / 403
0.0    3.0    3.0    0.0    285.0  4.0    31.0   1.0    0.0    0.0    2.0    2.0    0.0    0.0    1.0    1.0    4.0    4.0    9.0    5.0    0.0    0.0    0.0    10.0   2.0    17.0   0.2578125            99 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    19.0   0.0    0.0    0.0    0.0    12.0   2.0    0.0    1.0    0.0    1.0    0.0    0.0    2.0    3.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
1.0    3.0    0.0    14.0   6.0    0.0    0.0    2.0    7.0    0.0    6.0    4.0    0.0    0.0    2.0    1.0    0.0    2.0    9.0    3.0    2.0    0.0    0.0    316.0  7.0    7.0    0.19387755102040816  76 / 392
0.0    2.0    0.0    1.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    8.0    0.0    3.0    17.0   1.0    16.0   1.0    0.0    326.0  0.0    0.17048346055979643  67 / 393
2.0    0.0    0.0    1.0    21.0   1.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    9.0    1.0    32.0   4.0    0.0    0.0    0.0    3.0    0.0    284.0  0.22615803814713897  83 / 367
414.0  460.0  356.0  438.0  399.0  360.0  333.0  348.0  335.0  361.0  385.0  359.0  432.0  375.0  396.0  394.0  372.0  414.0  327.0  379.0  385.0  363.0  410.0  403.0  408.0  397.0  0.21133659902029392  2,114 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788663
2    0.882435
3    0.921024
4    0.938718
5    0.954414
6    0.963711
7    0.971309
8    0.975907
9    0.980106
10   0.984005

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21776970980728133
RMSE: 0.46665802233250137
LogLoss: 0.728620247953157
Mean Per-Class Error: 0.21498358118897062
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20    21    22     23     24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0   0.0   1.0    2.0    2.0    0.0    0.0898876404494382   8 / 89
0.0    84.0   0.0   1.0    2.0   0.0   4.0   4.0   1.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0    1.0   0.0   1.0   0.0   2.0    1.0    0.0    0.0    0.20754716981132076  22 / 106
0.0    0.0    63.0  0.0    2.0   1.0   5.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   6.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0    0.0    0.0    0.23170731707317074  19 / 82
3.0    1.0    0.0   92.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   2.0   2.0   0.0   2.0    0.0   0.0    2.0   0.0   1.0   0.0   0.0    2.0    0.0    1.0    0.17857142857142858  20 / 112
0.0    1.0    0.0   0.0    66.0  4.0   7.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    3.0   3.0   0.0   0.0   0.0    2.0    0.0    9.0    0.31958762886597936  31 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   4.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   83.0   0.0    0.0    0.0    0.09782608695652174  9 / 92
1.0    1.0    0.0   5.0    2.0   0.0   0.0   1.0   0.0   0.0    3.0   2.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0   1.0   0.0   0.0   0.0    78.0   2.0    1.0    0.22                 22 / 100
0.0    1.0    0.0   0.0    0.0   4.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0   1.0    2.0   0.0    0.0   4.0   0.0   4.0   1.0    0.0    89.0   0.0    0.16822429906542055  18 / 107
0.0    0.0    0.0   1.0    7.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    5.0   2.0   0.0   0.0   0.0    0.0    0.0    69.0   0.20689655172413793  18 / 87
102.0  118.0  75.0  127.0  91.0  83.0  82.0  92.0  75.0  101.0  94.0  94.0  95.0  99.0  79.0  115.0  95.0  104.0  80.0  89.0  98.0  82.0  104.0  101.0  113.0  102.0  0.21325301204819277  531 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.786747
2    0.883534
3    0.927711
4    0.941365
5    0.955823
6    0.963052
7    0.970683
8    0.975904
9    0.979518
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:04  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:04  1 min  2.380 sec  78795 obs/sec     1         1             10007      0.606069         1.15157             0.993471       0.322603                         0.606972           1.14224               0.993435         0.320482
    2019-08-04 09:01:05  1 min  3.499 sec  81756 obs/sec     10        10            100070     0.4628           0.719997            0.996193       0.211337                         0.466658           0.72862               0.99612          0.213253
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0892596
C9          0.936595               0.936595             0.0836001
C13         0.87728                0.87728              0.0783056
C11         0.85287                0.85287              0.0761268
C12         0.84513                0.84513              0.0754359
C8          0.814914               0.814914             0.0727389
C7          0.770656               0.770656             0.0687884
C10         0.729183               0.729183             0.0650865
C14         0.696738               0.696738             0.0621906
C6          0.648237               0.648237             0.0578614
C16         0.615457               0.615457             0.0549354
C5          0.592297               0.592297             0.0528682
C4          0.496235               0.496235             0.0442937
C3          0.461506               0.461506             0.0411938
C1          0.448472               0.448472             0.0400304
C2          0.41771                0.41771              0.0372847
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_50

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013470863485167683  0.0003830416826531291  0.0         -0.015524939105930002  0.7360155582427979  -0.024219823072000428  0.7580232620239258
    3        26       Softmax                 0.0   0.0   0.0019209562219307723  0.0002537879627197981  0.0         0.011893771159485858   0.5032718181610107  -0.46782165380547336   0.2514854669570923


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21569086271188295
RMSE: 0.4644253036946662
LogLoss: 0.7179910460311433
Mean Per-Class Error: 0.21220549298724806
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  2.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    1.0    8.0    0.0    1.0    0.0    0.0    1.0    4.0    0.0    1.0    0.0    3.0    0.0    8.0    3.0    0.09620253164556962  38 / 395
0.0    285.0  0.0    8.0    1.0    8.0    2.0    10.0   2.0    0.0    6.0    0.0    0.0    0.0    0.0    6.0    0.0    30.0   18.0   0.0    0.0    1.0    1.0    3.0    2.0    0.0    0.2558746736292428   98 / 383
0.0    0.0    298.0  1.0    9.0    0.0    10.0   0.0    0.0    0.0    26.0   0.0    1.0    0.0    3.0    0.0    2.0    0.0    7.0    2.0    4.0    0.0    4.0    0.0    0.0    1.0    0.19021739130434784  70 / 368
2.0    23.0   0.0    306.0  0.0    3.0    0.0    7.0    0.0    1.0    3.0    0.0    3.0    2.0    4.0    4.0    0.0    27.0   4.0    0.0    4.0    0.0    1.0    6.0    0.0    3.0    0.24069478908188585  97 / 403
0.0    11.0   1.0    1.0    277.0  5.0    14.0   0.0    1.0    0.0    8.0    1.0    0.0    0.0    0.0    3.0    10.0   9.0    11.0   4.0    0.0    1.0    0.0    4.0    0.0    23.0   0.2786458333333333   107 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    2.0    10.0   0.0    0.0    3.0    0.0    10.0   2.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    8.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    4.0    0.0    6.0    4.0    0.0    0.0    3.0    3.0    0.0    11.0   0.0    0.0    2.0    0.0    0.0    10.0   1.0    5.0    3.0    2.0    0.0    0.0    322.0  13.0   5.0    0.18274111675126903  72 / 394
0.0    0.0    0.0    3.0    0.0    9.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    7.0    10.0   0.0    6.0    23.0   0.0    35.0   2.0    1.0    293.0  0.0    0.2544529262086514   100 / 393
3.0    1.0    0.0    1.0    14.0   6.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    29.0   2.0    0.0    0.0    0.0    3.0    2.0    296.0  0.1912568306010929   70 / 366
402.0  437.0  337.0  389.0  349.0  398.0  313.0  298.0  323.0  338.0  428.0  340.0  408.0  366.0  377.0  403.0  402.0  495.0  365.0  399.0  407.0  394.0  429.0  411.0  382.0  413.0  0.2112366290112966   2,113 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788763
2    0.878736
3    0.918025
4    0.939618
5    0.954614
6    0.963911
7    0.972108
8    0.977407
9    0.982505
10   0.985404

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21948189311605584
RMSE: 0.4684889466316744
LogLoss: 0.7296771559187839
Mean Per-Class Error: 0.2149874762724474
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    0.0   4.0    0.0    0.0898876404494382   8 / 89
0.0   76.0   0.0   4.0    0.0   1.0   0.0   2.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   2.0    0.0    8.0    7.0   0.0   0.0    1.0   1.0    1.0   1.0    0.0    0.2830188679245283   30 / 106
0.0   0.0    62.0  0.0    1.0   0.0   3.0   0.0   0.0   0.0   8.0    0.0   0.0   0.0    2.0   0.0    0.0    0.0    3.0   2.0   0.0    0.0   1.0    0.0   0.0    0.0    0.24390243902439024  20 / 82
2.0   1.0    0.0   87.0   0.0   0.0   0.0   4.0   0.0   0.0   1.0    0.0   1.0   2.0    0.0   2.0    0.0    8.0    2.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    0.22321428571428573  25 / 112
0.0   3.0    0.0   0.0    65.0  4.0   4.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   1.0    1.0    2.0    4.0   2.0   0.0    1.0   0.0    2.0   0.0    6.0    0.32989690721649484  32 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   1.0    0.0   3.0   1.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    2.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0   1.0    0.0   2.0    2.0   0.0   0.0   1.0   1.0   0.0   7.0    0.0   0.0   0.0    0.0   0.0    2.0    1.0    2.0   0.0   0.0    0.0   0.0    76.0  3.0    2.0    0.24                 24 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   5.0    2.0    0.0    0.0   4.0   0.0    9.0   2.0    0.0   81.0   0.0    0.24299065420560748  26 / 107
0.0   0.0    0.0   1.0    5.0   2.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    3.0   0.0   0.0    0.0   0.0    1.0   2.0    71.0   0.1839080459770115   16 / 87
89.0  103.0  67.0  107.0  77.0  93.0  78.0  80.0  74.0  98.0  117.0  97.0  86.0  100.0  77.0  115.0  107.0  119.0  90.0  94.0  105.0  96.0  105.0  98.0  111.0  107.0  0.21445783132530122  534 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785542
2    0.882731
3    0.916466
4    0.935743
5    0.95261
6    0.961044
7    0.970683
8    0.977108
9    0.983133
10   0.98755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:30  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:30  1 min 28.643 sec  74679 obs/sec     1         1             10007      0.602368         1.15322             0.993552       0.325202                         0.601426           1.14468               0.993555         0.325301
    2019-08-04 09:01:32  1 min 29.751 sec  82024 obs/sec     10        10            100070     0.464425         0.717991            0.996167       0.211237                         0.468489           0.729677              0.996089         0.214458
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0878121
C13         0.949523               0.949523             0.0833796
C9          0.949051               0.949051             0.0833381
C12         0.928738               0.928738             0.0815544
C11         0.799372               0.799372             0.0701946
C7          0.785526               0.785526             0.0689787
C8          0.779429               0.779429             0.0684433
C14         0.710855               0.710855             0.0624217
C6          0.678156               0.678156             0.0595503
C10         0.670405               0.670405             0.0588697
C16         0.610865               0.610865             0.0536413
C3          0.589133               0.589133             0.051733
C5          0.557016               0.557016             0.0489128
C4          0.52181                0.52181              0.0458213
C1          0.435325               0.435325             0.0382268
C2          0.422747               0.422747             0.0371223
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_67

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015230914713413313  0.00036415853537619114  0.0         -0.019108193534478346  0.7517895698547363  -0.0775630818295764  0.7186563014984131
    3        26       Softmax                 0.0   0.0   0.0018140954217205245  0.0002660087775439024   0.0         -0.016355130468626227  0.3850604295730591  -0.5558781405425439  0.27006447315216064


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21373882693120497
RMSE: 0.462318966657442
LogLoss: 0.7249420023175936
Mean Per-Class Error: 0.20474437614473104
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    4.0    0.0    5.0    0.0    4.0    0.0    0.0    2.0    5.0    2.0    2.0    0.0    2.0    1.0    3.0    0.0    0.08354430379746836  33 / 395
0.0    329.0  0.0    9.0    3.0    0.0    1.0    2.0    3.0    0.0    0.0    0.0    2.0    0.0    4.0    3.0    4.0    8.0    9.0    0.0    0.0    1.0    1.0    1.0    2.0    0.0    0.1387434554973822   53 / 382
0.0    0.0    297.0  0.0    17.0   0.0    11.0   1.0    0.0    0.0    21.0   0.0    0.0    0.0    3.0    0.0    3.0    0.0    7.0    2.0    1.0    0.0    5.0    0.0    0.0    0.0    0.19293478260869565  71 / 368
4.0    25.0   0.0    325.0  0.0    1.0    0.0    1.0    0.0    3.0    0.0    1.0    8.0    7.0    7.0    3.0    0.0    4.0    10.0   1.0    1.0    0.0    0.0    2.0    0.0    0.0    0.1935483870967742   78 / 403
0.0    7.0    0.0    0.0    295.0  2.0    18.0   1.0    1.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    9.0    3.0    13.0   6.0    1.0    0.0    0.0    3.0    1.0    21.0   0.23177083333333334  89 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    30.0   0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    3.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
1.0    4.0    0.0    7.0    4.0    1.0    0.0    1.0    7.0    0.0    12.0   6.0    0.0    0.0    2.0    0.0    9.0    0.0    11.0   4.0    2.0    0.0    0.0    309.0  5.0    9.0    0.21573604060913706  85 / 394
0.0    1.0    0.0    1.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    10.0   0.0    3.0    9.0    4.0    25.0   1.0    3.0    326.0  0.0    0.17048346055979643  67 / 393
3.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    32.0   6.0    0.0    0.0    0.0    3.0    0.0    296.0  0.19346049046321526  71 / 367
427.0  552.0  334.0  423.0  382.0  336.0  345.0  301.0  339.0  348.0  389.0  347.0  488.0  360.0  402.0  393.0  372.0  369.0  367.0  383.0  394.0  373.0  441.0  363.0  386.0  389.0  0.20383884834549634  2,039 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796161
2    0.881935
3    0.916025
4    0.936919
5    0.951015
6    0.962511
7    0.971109
8    0.978806
9    0.983205
10   0.986604

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21593197768303185
RMSE: 0.46468481542119694
LogLoss: 0.73163973194582
Mean Per-Class Error: 0.20986259564664145
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17    18    19    20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0   1.0   0.0   1.0    0.0   1.0    0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0    85.0   0.0   1.0    2.0   0.0   1.0   1.0   1.0   0.0   0.0    0.0   1.0    0.0   2.0   1.0    1.0   6.0   1.0   0.0   0.0    1.0   1.0    1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0    0.0    63.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0   5.0    0.0   0.0    0.0   2.0   0.0    1.0   0.0   3.0   1.0   0.0    0.0   2.0    0.0   0.0    0.0   0.23170731707317074  19 / 82
2.0    6.0    0.0   90.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   3.0    2.0   3.0   1.0    0.0   1.0   3.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.19642857142857142  22 / 112
0.0    1.0    0.0   0.0    69.0  2.0   6.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0   0.0    1.0   1.0   4.0   4.0   0.0    0.0   0.0    1.0   0.0    7.0   0.28865979381443296  28 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   6.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
1.0    0.0    0.0   3.0    3.0   0.0   0.0   1.0   2.0   0.0   5.0    2.0   0.0    0.0   0.0   0.0    2.0   0.0   2.0   1.0   1.0    0.0   0.0    74.0  1.0    2.0   0.26                 26 / 100
0.0    1.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    4.0   0.0   0.0   0.0   2.0    7.0   1.0    0.0   89.0   0.0   0.16822429906542055  18 / 107
1.0    0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   6.0   3.0   0.0    0.0   0.0    1.0   0.0    70.0  0.19540229885057472  17 / 87
105.0  136.0  70.0  120.0  84.0  81.0  83.0  76.0  79.0  97.0  101.0  94.0  109.0  97.0  81.0  109.0  97.0  93.0  94.0  91.0  103.0  86.0  112.0  91.0  107.0  94.0  0.20923694779116467  521 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790763
2    0.878313
3    0.917671
4    0.938554
5    0.953012
6    0.961847
7    0.970281
8    0.977912
9    0.983133
10   0.98755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:51  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:51  1 min 49.121 sec  52119 obs/sec     1         1             10007      0.584976         1.10061             0.993918       0.30051                          0.582523           1.08961               0.993954         0.300402
    2019-08-04 09:01:53  1 min 50.853 sec  52947 obs/sec     10        10            100070     0.462319         0.724942            0.996201       0.203839                         0.464685           0.73164               0.996152         0.209237
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0880493
C13         0.989829               0.989829             0.0871538
C12         0.936083               0.936083             0.0824215
C9          0.934525               0.934525             0.0822843
C8          0.814123               0.814123             0.071683
C11         0.813019               0.813019             0.0715858
C7          0.799576               0.799576             0.0704021
C14         0.730184               0.730184             0.0642922
C10         0.679673               0.679673             0.0598448
C16         0.596134               0.596134             0.0524892
C3          0.594088               0.594088             0.0523091
C6          0.588267               0.588267             0.0517965
C5          0.522297               0.522297             0.0459879
C4          0.513498               0.513498             0.0452131
C2          0.442425               0.442425             0.0389552
C1          0.403549               0.403549             0.0355322
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_5

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007670183385926066  0.00017179513815790415  0.0         -0.011369346491653332  0.28325319290161133  0.21120445093369306  0.25944674015045166
    3        26       Softmax                      0.0   0.0   0.005332839310120527   0.019745655357837677    0.0         -0.3997686676183058    0.8652384281158447   -0.4687288312760715  0.3144814968109131


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22118284774833927
RMSE: 0.47030080560035115
LogLoss: 0.7266280597939735
Mean Per-Class Error: 0.20033285160912853
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    2.0    2.0    1.0    5.0    0.0    1.0    0.0    2.0    2.0    7.0    0.0    1.0    0.0    6.0    1.0    4.0    3.0    0.09873417721518987  39 / 395
0.0    312.0  0.0    11.0   3.0    1.0    3.0    10.0   2.0    0.0    1.0    0.0    0.0    0.0    2.0    9.0    0.0    10.0   7.0    0.0    0.0    0.0    1.0    10.0   0.0    1.0    0.185378590078329    71 / 383
0.0    0.0    301.0  0.0    13.0   0.0    24.0   0.0    0.0    0.0    14.0   1.0    0.0    0.0    6.0    0.0    2.0    0.0    1.0    4.0    1.0    1.0    0.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
1.0    15.0   0.0    326.0  0.0    0.0    0.0    5.0    1.0    6.0    0.0    1.0    6.0    5.0    6.0    4.0    1.0    12.0   1.0    0.0    0.0    0.0    0.0    5.0    1.0    6.0    0.1890547263681592   76 / 402
0.0    12.0   3.0    0.0    288.0  1.0    21.0   5.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    1.0    1.0    5.0    10.0   6.0    0.0    0.0    0.0    7.0    0.0    16.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    19.0   0.0    2.0    0.0    0.0    1.0    0.0    0.0    6.0    1.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    4.0    0.0    3.0    5.0    0.0    1.0    5.0    1.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    18.0   5.0    2.0    0.0    0.0    332.0  2.0    2.0    0.15736040609137056  62 / 394
0.0    0.0    0.0    0.0    0.0    8.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    24.0   2.0    33.0   1.0    0.0    316.0  1.0    0.19592875318066158  77 / 393
2.0    0.0    0.0    1.0    18.0   0.0    1.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    40.0   2.0    0.0    0.0    0.0    4.0    1.0    282.0  0.23160762942779292  85 / 367
392.0  494.0  355.0  402.0  359.0  379.0  411.0  325.0  318.0  365.0  398.0  351.0  453.0  356.0  414.0  383.0  310.0  406.0  423.0  388.0  382.0  385.0  412.0  424.0  368.0  350.0  0.19964010796760973  1,997 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.80036
2    0.881736
3    0.916625
4    0.936719
5    0.952514
6    0.963011
7    0.971409
8    0.977007
9    0.981206
10   0.985904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22536193947567112
RMSE: 0.4747230134253775
LogLoss: 0.7324268428774897
Mean Per-Class Error: 0.20684311310379916
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13    14    15     16    17     18     19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   3.0    0.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   79.0   0.0   4.0    0.0   0.0   2.0    1.0   1.0   0.0    1.0   0.0   0.0   0.0   2.0   4.0    0.0   5.0    3.0    0.0   0.0   0.0   1.0    3.0    0.0    0.0   0.25471698113207547  27 / 106
0.0   0.0    63.0  0.0    2.0   0.0   8.0    0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    1.0    2.0   0.0   1.0   0.0    0.0    0.0    0.0   0.23170731707317074  19 / 82
1.0   2.0    0.0   93.0   0.0   0.0   0.0    3.0   0.0   2.0    0.0   1.0   2.0   2.0   1.0   1.0    0.0   2.0    0.0    0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   2.0    1.0   0.0    65.0  1.0   7.0    1.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    4.0    2.0   0.0   0.0   0.0    3.0    0.0    6.0   0.32989690721649484  32 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   2.0   0.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    1.0   0.0   1.0    2.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    6.0    0.0   0.0   0.0   0.0    80.0   1.0    1.0   0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0    7.0   0.0   8.0   1.0    0.0    84.0   1.0   0.21495327102803738  23 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    11.0   1.0   0.0   0.0   0.0    2.0    0.0    65.0  0.25287356321839083  22 / 87
90.0  125.0  74.0  119.0  77.0  89.0  100.0  84.0  73.0  103.0  95.0  93.0  99.0  95.0  85.0  107.0  86.0  107.0  117.0  93.0  97.0  86.0  106.0  104.0  101.0  85.0  0.20722891566265061  516 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792771
2    0.87992
3    0.921687
4    0.941365
5    0.953414
6    0.963454
7    0.972289
8    0.97751
9    0.982731
10   0.985944
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:16  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:16  14.547 sec  153953 obs/sec    1         1             10007      0.710981         1.54336             0.991018       0.413576                         0.712129           1.55169               0.990964         0.425703
    2019-08-04 09:00:17  15.036 sec  187046 obs/sec    10        10            100070     0.470301         0.726628            0.99607        0.19964                          0.474723           0.732427              0.995984         0.207229
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0891053
C13         0.955008               0.955008             0.0850963
C9          0.887034               0.887034             0.0790395
C7          0.881301               0.881301             0.0785286
C12         0.792506               0.792506             0.0706165
C8          0.721225               0.721225             0.064265
C11         0.706318               0.706318             0.0629367
C5          0.685025               0.685025             0.0610394
C10         0.680111               0.680111             0.0606015
C14         0.658032               0.658032             0.0586342
C4          0.648233               0.648233             0.057761
C6          0.595891               0.595891             0.053097
C3          0.580992               0.580992             0.0517695
C16         0.565762               0.565762             0.0504124
C1          0.439134               0.439134             0.0391291
C2          0.426103               0.426103             0.037968
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_221

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013373403356808922  0.00034468132071197033  0.0         0.005657983027404612  0.7083313465118408  -0.11497770361463115  0.7164809703826904
    3        26       Softmax                 0.0   0.0   0.0019813878957043365  0.000331241637468338    0.0         -0.013646457667549    0.4981193542480469  -0.4556772245187366   0.2606465816497803


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21216136019023632
RMSE: 0.4606097699682849
LogLoss: 0.7202715131593111
Mean Per-Class Error: 0.205905409282487
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    2.0    2.0    0.0    7.0    1.0    3.0    0.0    0.0    2.0    2.0    1.0    1.0    0.0    2.0    2.0    7.0    1.0    0.09898477157360407  39 / 394
0.0    322.0  0.0    5.0    3.0    0.0    8.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    4.0    15.0   2.0    1.0    0.0    2.0    1.0    2.0    5.0    0.0    0.15926892950391644  61 / 383
0.0    0.0    297.0  0.0    17.0   1.0    13.0   1.0    0.0    0.0    13.0   0.0    0.0    0.0    6.0    0.0    2.0    0.0    10.0   1.0    3.0    0.0    4.0    0.0    0.0    0.0    0.19293478260869565  71 / 368
4.0    25.0   0.0    311.0  0.0    1.0    0.0    3.0    0.0    9.0    1.0    0.0    7.0    1.0    3.0    9.0    0.0    15.0   1.0    3.0    2.0    0.0    0.0    4.0    1.0    3.0    0.228287841191067    92 / 403
0.0    4.0    3.0    0.0    297.0  6.0    18.0   1.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    5.0    4.0    7.0    7.0    1.0    0.0    0.0    12.0   1.0    13.0   0.2265625            87 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    15.0   0.0    0.0    1.0    0.0    14.0   2.0    3.0    0.0    0.0    2.0    1.0    0.0    2.0    1.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    7.0    0.0    2.0    13.0   1.0    0.0    3.0    4.0    0.0    5.0    4.0    0.0    0.0    3.0    0.0    8.0    0.0    11.0   3.0    2.0    0.0    0.0    319.0  3.0    5.0    0.18829516539440203  74 / 393
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    4.0    12.0   0.0    1.0    20.0   2.0    10.0   0.0    4.0    334.0  0.0    0.15012722646310434  59 / 393
0.0    0.0    0.0    1.0    19.0   2.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    40.0   5.0    0.0    0.0    0.0    2.0    1.0    285.0  0.22343324250681199  82 / 367
401.0  491.0  338.0  414.0  413.0  378.0  364.0  335.0  326.0  358.0  357.0  341.0  435.0  363.0  406.0  382.0  357.0  433.0  366.0  400.0  389.0  356.0  413.0  415.0  417.0  355.0  0.20493851844446667  2,050 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.795061
2    0.878436
3    0.918324
4    0.940418
5    0.954114
6    0.964911
7    0.972408
8    0.978106
9    0.982605
10   0.985304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21465906580075933
RMSE: 0.46331314011234276
LogLoss: 0.7332025717782958
Mean Per-Class Error: 0.20798393062204423
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   1.0    1.0   4.0    0.0   0.11235955056179775  10 / 89
0.0   82.0   0.0   0.0    1.0    0.0   3.0   4.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    3.0   7.0    0.0   0.0   0.0   1.0   1.0    1.0   2.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    63.0  0.0    3.0    0.0   6.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   1.0    0.0   0.0    0.0   0.23170731707317074  19 / 82
3.0   3.0    0.0   93.0   0.0    0.0   0.0   2.0   0.0   1.0    0.0   0.0   3.0   0.0   0.0   2.0    0.0   3.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    73.0   3.0   6.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    3.0   3.0   0.0   0.0   0.0    1.0   0.0    6.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0   1.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   1.0    6.0    0.0   0.0   3.0   2.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    2.0   0.0    4.0   0.0   1.0   0.0   0.0    75.0  1.0    1.0   0.25                 25 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    4.0   0.0    0.0   3.0   0.0   4.0   0.0    1.0   92.0   0.0   0.14018691588785046  15 / 107
0.0   0.0    0.0   1.0    7.0    1.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    9.0   2.0   0.0   0.0   0.0    0.0   0.0    64.0  0.26436781609195403  23 / 87
94.0  117.0  67.0  124.0  100.0  86.0  94.0  93.0  77.0  102.0  94.0  89.0  96.0  92.0  80.0  114.0  89.0  107.0  98.0  89.0  99.0  84.0  103.0  95.0  121.0  86.0  0.20682730923694778  515 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793173
2    0.877912
3    0.916064
4    0.937751
5    0.951807
6    0.962651
7    0.971888
8    0.978715
9    0.982329
10   0.984739
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:28  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:28  6 min 26.276 sec  80056 obs/sec     1         1             10007      0.601049         1.15567             0.993579       0.304909                         0.598769           1.14505               0.993612         0.308032
    2019-08-04 09:06:29  6 min 27.418 sec  80313 obs/sec     10        10            100070     0.46061          0.720272            0.996229       0.204939                         0.463313           0.733203              0.996175         0.206827
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0834117
C13         0.958924               0.958924             0.0799855
C12         0.956701               0.956701             0.0798001
C15         0.955071               0.955071             0.0796641
C7          0.87036                0.87036              0.0725982
C11         0.867043               0.867043             0.0723215
C8          0.857468               0.857468             0.0715228
C10         0.831237               0.831237             0.0693349
C14         0.736236               0.736236             0.0614107
C6          0.673635               0.673635             0.056189
C16         0.663123               0.663123             0.0553122
C5          0.608881               0.608881             0.0507878
C3          0.575643               0.575643             0.0480153
C4          0.527582               0.527582             0.0440065
C1          0.455594               0.455594             0.0380019
C2          0.451231               0.451231             0.0376379
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_31

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007718166576751173  0.00016657606465741992  0.0         -0.02829216895797515  0.29031336307525635  0.22597213628610588  0.231434166431427
    3        26       Softmax                      0.0   0.0   0.0049062993800991815  0.012389864772558212    0.0         -0.4033020286662857   0.8630020618438721   -0.4587193522929335  0.3763389587402344


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22212143675730886
RMSE: 0.47129760953914124
LogLoss: 0.7209670142789121
Mean Per-Class Error: 0.20633699315534276
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    9.0    5.0    0.0    2.0    0.0    1.0    0.0    4.0    2.0    7.0    0.0    1.0    4.0    2.0    2.0    5.0    0.0    0.11645569620253164  46 / 395
0.0    334.0  0.0    0.0    3.0    1.0    5.0    7.0    4.0    1.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    12.0   5.0    0.0    2.0    1.0    0.0    3.0    0.0    0.0    0.1256544502617801   48 / 382
0.0    0.0    292.0  0.0    14.0   0.0    9.0    2.0    0.0    0.0    24.0   0.0    1.0    0.0    4.0    0.0    3.0    2.0    7.0    5.0    1.0    0.0    3.0    0.0    0.0    1.0    0.20652173913043478  76 / 368
0.0    23.0   0.0    321.0  0.0    1.0    0.0    10.0   0.0    6.0    0.0    2.0    4.0    6.0    3.0    2.0    0.0    6.0    2.0    0.0    0.0    0.0    0.0    8.0    0.0    9.0    0.20347394540942929  82 / 403
0.0    6.0    0.0    0.0    305.0  2.0    20.0   3.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    4.0    0.0    4.0    5.0    2.0    0.0    1.0    0.0    4.0    0.0    24.0   0.20572916666666666  79 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    11.0   0.0    0.0    3.0    0.0    7.0    2.0    2.0    1.0    0.0    0.0    0.0    0.0    7.0    4.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    3.0    1.0    10.0   11.0   0.0    1.0    0.0    9.0    2.0    6.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    6.0    10.0   3.0    2.0    0.0    314.0  8.0    5.0    0.2010178117048346   79 / 393
0.0    0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    15.0   0.0    3.0    16.0   8.0    32.0   0.0    0.0    306.0  0.0    0.22137404580152673  87 / 393
1.0    0.0    0.0    0.0    15.0   1.0    0.0    0.0    1.0    16.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    20.0   3.0    0.0    0.0    0.0    4.0    0.0    302.0  0.17486338797814208  64 / 366
408.0  522.0  357.0  395.0  409.0  384.0  336.0  324.0  366.0  371.0  391.0  340.0  408.0  355.0  400.0  385.0  327.0  426.0  315.0  362.0  402.0  406.0  433.0  379.0  388.0  414.0  0.20573827851644508  2,058 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.794262
2    0.884735
3    0.921624
4    0.941118
5    0.954614
6    0.964311
7    0.971509
8    0.977107
9    0.981706
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22530757200898788
RMSE: 0.474665747667754
LogLoss: 0.7337270094674286
Mean Per-Class Error: 0.20706929158178944
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    2.0   1.0    1.0   2.0    0.0    0.11235955056179775  10 / 89
0.0   86.0   0.0   0.0    2.0    0.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0   2.0   1.0    0.0   4.0    2.0   0.0   1.0    1.0   0.0    2.0   0.0    0.0    0.18867924528301888  20 / 106
0.0   0.0    64.0  0.0    4.0    0.0   1.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0   1.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0    0.21951219512195122  18 / 82
0.0   4.0    0.0   91.0   0.0    0.0   0.0   4.0   0.0   2.0    0.0   1.0   2.0   2.0   0.0   2.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    1.0    0.1875               21 / 112
0.0   0.0    0.0   0.0    73.0   2.0   6.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0    3.0   0.0   0.0    0.0   0.0    2.0   0.0    9.0    0.24742268041237114  24 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    1.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    5.0    0.0   1.0   0.0   2.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0   0.0    77.0  3.0    1.0    0.23                 23 / 100
0.0   0.0    0.0   0.0    0.0    3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    7.0   0.0    0.0   4.0   3.0    11.0  0.0    0.0   78.0   0.0    0.27102803738317754  29 / 107
1.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    4.0   1.0   0.0    0.0   0.0    1.0   0.0    69.0   0.20689655172413793  18 / 87
96.0  125.0  77.0  113.0  103.0  89.0  83.0  85.0  89.0  101.0  98.0  92.0  92.0  99.0  80.0  111.0  92.0  105.0  80.0  82.0  102.0  99.0  104.0  93.0  100.0  100.0  0.20763052208835342  517 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792369
2    0.885944
3    0.920884
4    0.937751
5    0.952209
6    0.961446
7    0.968273
8    0.972289
9    0.97751
10   0.982731
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:01  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:01  58.944 sec  169610 obs/sec    1         1             10007      0.698346         1.46665             0.99133        0.389583                         0.698381           1.4663                0.991309         0.390361
    2019-08-04 09:01:01  59.406 sec  196988 obs/sec    10        10            100070     0.471298         0.720967            0.996051       0.205738                         0.474666           0.733727              0.995985         0.207631
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0985985
C13         0.890852               0.890852             0.0878367
C8          0.799565               0.799565             0.0788359
C7          0.781574               0.781574             0.0770621
C12         0.768234               0.768234             0.0757467
C9          0.740327               0.740327             0.0729951
C11         0.681998               0.681998             0.067244
C14         0.62854                0.62854              0.0619732
C5          0.597062               0.597062             0.0588695
C16         0.549721               0.549721             0.0542017
C3          0.514164               0.514164             0.0506958
C6          0.50632                0.50632              0.0499224
C10         0.504969               0.504969             0.0497892
C4          0.475837               0.475837             0.0469169
C2          0.35238                0.35238              0.0347441
C1          0.350594               0.350594             0.0345681
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_106

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007672982865756239  0.00017378188204020262  0.0         -0.028582909754277352  0.28552162647247314  0.23226317187637324   0.24108970165252686
    3        26       Softmax                      0.0   0.0   0.007505669284560449   0.04903732240200043     0.0         -0.42894691790430584   0.8848898410797119   -0.48953348148291337  0.3713572025299072


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22415662455982446
RMSE: 0.47345181862553287
LogLoss: 0.731662473196187
Mean Per-Class Error: 0.2074788132164801
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    9.0    2.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    6.0    1.0    2.0    0.0    3.0    3.0    7.0    3.0    0.10379746835443038  41 / 395
0.0    306.0  0.0    11.0   1.0    2.0    4.0    5.0    3.0    1.0    1.0    0.0    0.0    0.0    4.0    2.0    1.0    16.0   11.0   0.0    0.0    9.0    0.0    5.0    0.0    1.0    0.2010443864229765   77 / 383
0.0    0.0    294.0  0.0    21.0   0.0    12.0   0.0    0.0    0.0    15.0   0.0    0.0    0.0    5.0    0.0    2.0    0.0    3.0    3.0    5.0    0.0    6.0    0.0    0.0    0.0    0.19672131147540983  72 / 366
1.0    16.0   0.0    321.0  0.0    1.0    0.0    4.0    0.0    8.0    0.0    0.0    3.0    6.0    8.0    3.0    0.0    17.0   1.0    0.0    1.0    0.0    0.0    6.0    0.0    7.0    0.20347394540942929  82 / 403
0.0    8.0    2.0    0.0    310.0  1.0    17.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    8.0    4.0    11.0   7.0    0.0    0.0    0.0    3.0    0.0    10.0   0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    18.0   0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    2.0    0.0    3.0    9.0    0.0    0.0    6.0    3.0    1.0    3.0    1.0    0.0    0.0    2.0    0.0    5.0    1.0    3.0    11.0   3.0    1.0    0.0    327.0  4.0    9.0    0.1700507614213198   67 / 394
0.0    0.0    0.0    2.0    0.0    5.0    1.0    2.0    1.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    8.0    0.0    2.0    29.0   2.0    35.0   1.0    0.0    302.0  0.0    0.23155216284987276  91 / 393
3.0    0.0    0.0    0.0    20.0   0.0    1.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    32.0   3.0    0.0    0.0    0.0    0.0    0.0    294.0  0.1989100817438692   73 / 367
401.0  461.0  353.0  422.0  433.0  353.0  344.0  332.0  357.0  356.0  378.0  349.0  388.0  375.0  394.0  364.0  354.0  408.0  343.0  408.0  411.0  410.0  427.0  417.0  368.0  397.0  0.20653803858842348  2,066 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793462
2    0.882435
3    0.913726
4    0.93382
5    0.949515
6    0.961212
7    0.971009
8    0.977107
9    0.981905
10   0.985704

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22527335532759998
RMSE: 0.47462970337685356
LogLoss: 0.7344832209627293
Mean Per-Class Error: 0.20601405448546461
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12    13     14    15     16    17    18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   1.0    0.0   0.0    0.0    4.0    0.0    0.06741573033707865  6 / 89
0.0   81.0   0.0   4.0    1.0    0.0   1.0   3.0   1.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0    0.0   3.0   4.0   0.0   0.0    3.0   0.0    1.0    0.0    0.0    0.2358490566037736   25 / 106
0.0   0.0    62.0  0.0    5.0    0.0   4.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0   2.0   1.0   1.0    0.0   2.0    0.0    0.0    0.0    0.24390243902439024  20 / 82
1.0   1.0    0.0   92.0   0.0    0.0   0.0   2.0   0.0   3.0   0.0   0.0   1.0   2.0    2.0   1.0    0.0   2.0   0.0   0.0   1.0    0.0   0.0    2.0    0.0    2.0    0.17857142857142858  20 / 112
0.0   2.0    1.0   0.0    75.0   1.0   5.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0   2.0   3.0   0.0    0.0   0.0    1.0    0.0    2.0    0.2268041237113402   22 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    2.0   85.0   0.0    0.0    0.0    0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    4.0    0.0   0.0   3.0   1.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    1.0   1.0   2.0   0.0   1.0    0.0   0.0    78.0   1.0    3.0    0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0    0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    4.0   0.0   0.0   9.0   0.0    10.0  1.0    0.0    80.0   0.0    0.2523364485981308   27 / 107
2.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   4.0   1.0   0.0    0.0   0.0    0.0    0.0    72.0   0.1724137931034483   15 / 87
96.0  114.0  76.0  120.0  101.0  71.0  87.0  83.0  85.0  96.0  94.0  96.0  87.0  107.0  86.0  109.0  98.0  97.0  86.0  99.0  103.0  96.0  100.0  100.0  101.0  102.0  0.20562248995983937  512 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.794377
2    0.884739
3    0.918875
4    0.934538
5    0.950201
6    0.958233
7    0.971888
8    0.976707
9    0.981124
10   0.987149
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:00  2 min 58.470 sec  185314 obs/sec    1         1             10007      0.680667         1.42371             0.991766       0.382585                         0.679724           1.41429               0.991767         0.383936
    2019-08-04 09:03:01  2 min 58.942 sec  195068 obs/sec    10        10            100070     0.473452         0.731662            0.996016       0.206538                         0.47463            0.734483              0.995986         0.205622
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0951017
C9          0.840663               0.840663             0.0799485
C13         0.835154               0.835154             0.0794245
C8          0.823581               0.823581             0.0783239
C12         0.773413               0.773413             0.0735529
C7          0.729759               0.729759             0.0694013
C11         0.701982               0.701982             0.0667597
C5          0.666779               0.666779             0.0634118
C3          0.611053               0.611053             0.0581121
C10         0.592752               0.592752             0.0563717
C6          0.589569               0.589569             0.056069
C4          0.565194               0.565194             0.0537509
C14         0.550974               0.550974             0.0523985
C16         0.513906               0.513906             0.0488733
C2          0.375313               0.375313             0.0356929
C1          0.34497                0.34497              0.0328072
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_222

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015380894095926578  0.00032348325476050377  0.0         -0.00464304918561087  0.7558164596557617   -0.03543586793281127  0.787879228591919
    3        26       Softmax                 0.0   0.0   0.001813785881320375   0.00023972371127456427  0.0         0.007214152279494521  0.38752734661102295  -0.554433291770424    0.26643121242523193


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20981786892357104
RMSE: 0.4580588050933756
LogLoss: 0.7208486029493558
Mean Per-Class Error: 0.20489141171180886
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    7.0    1.0    8.0    0.0    0.0    2.0    4.0    0.0    3.0    0.0    2.0    2.0    5.0    0.0    0.09873417721518987  39 / 395
0.0    322.0  0.0    4.0    3.0    6.0    3.0    0.0    5.0    0.0    3.0    0.0    1.0    0.0    2.0    0.0    2.0    19.0   4.0    0.0    0.0    1.0    2.0    3.0    3.0    0.0    0.15926892950391644  61 / 383
0.0    0.0    276.0  0.0    19.0   3.0    16.0   0.0    0.0    0.0    24.0   1.0    1.0    0.0    5.0    0.0    3.0    0.0    7.0    5.0    3.0    0.0    5.0    0.0    0.0    0.0    0.25                 92 / 368
5.0    19.0   0.0    323.0  0.0    3.0    0.0    5.0    1.0    5.0    0.0    1.0    4.0    7.0    5.0    1.0    1.0    13.0   1.0    0.0    1.0    0.0    0.0    7.0    0.0    1.0    0.19851116625310175  80 / 403
0.0    6.0    0.0    0.0    306.0  3.0    17.0   1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    8.0    2.0    9.0    5.0    0.0    0.0    0.0    5.0    0.0    14.0   0.19895287958115182  76 / 382
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    16.0   1.0    3.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    5.0    0.0    6.0    8.0    0.0    0.0    3.0    4.0    2.0    10.0   2.0    0.0    0.0    2.0    0.0    8.0    2.0    13.0   6.0    4.0    0.0    0.0    305.0  11.0   3.0    0.22588832487309646  89 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    2.0    11.0   0.0    1.0    13.0   1.0    36.0   1.0    0.0    320.0  0.0    0.1836734693877551   72 / 392
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    1.0    29.0   5.0    0.0    0.0    0.0    2.0    0.0    305.0  0.16893732970027248  62 / 367
404.0  513.0  318.0  416.0  398.0  353.0  356.0  291.0  344.0  346.0  414.0  337.0  459.0  383.0  423.0  373.0  400.0  408.0  308.0  395.0  383.0  390.0  418.0  374.0  404.0  395.0  0.20393881835449365  2,040 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796061
2    0.879836
3    0.917625
4    0.936419
5    0.951115
6    0.962211
7    0.969709
8    0.976307
9    0.980506
10   0.983805

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21208720489467786
RMSE: 0.46052926605665123
LogLoss: 0.7345164161808744
Mean Per-Class Error: 0.2072990383963656
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16     17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0   0.0   1.0    1.0   2.0    0.0    0.0898876404494382   8 / 89
0.0   83.0   0.0   1.0    2.0   1.0   2.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    2.0   0.0    1.0    7.0    1.0   0.0   0.0   1.0   1.0    2.0   0.0    0.0    0.2169811320754717   23 / 106
0.0   0.0    57.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    2.0   0.0    1.0    0.0    4.0   2.0   1.0   0.0   2.0    0.0   0.0    0.0    0.3048780487804878   25 / 82
3.0   3.0    0.0   90.0   0.0   1.0   0.0   3.0   1.0   1.0   0.0    1.0   1.0   3.0    0.0   0.0    0.0    3.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0    0.19642857142857142  22 / 112
0.0   0.0    0.0   0.0    71.0  3.0   6.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0    1.0    3.0   3.0   0.0   0.0   0.0    1.0   0.0    6.0    0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0   0.0   87.0   0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    5.0   0.0   0.0   2.0   1.0   0.0   4.0    1.0   0.0   0.0    0.0   0.0    2.0    2.0    4.0   0.0   1.0   0.0   0.0    69.0  5.0    2.0    0.31                 31 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   2.0    5.0    0.0    0.0   4.0   0.0   12.0  1.0    0.0   83.0   0.0    0.22429906542056074  24 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    4.0   1.0   0.0   0.0   0.0    0.0   0.0    75.0   0.13793103448275862  12 / 87
97.0  122.0  66.0  119.0  89.0  82.0  91.0  80.0  81.0  98.0  104.0  94.0  99.0  102.0  81.0  107.0  104.0  104.0  84.0  93.0  99.0  92.0  104.0  88.0  108.0  102.0  0.20722891566265061  516 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792771
2    0.882329
3    0.92008
4    0.936948
5    0.949398
6    0.956225
7    0.963454
8    0.973494
9    0.978313
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:29  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:29  6 min 27.658 sec  53513 obs/sec     1         1             10007      0.588792         1.12634             0.993838       0.29871                          0.588554           1.121                 0.993828         0.3
    2019-08-04 09:06:31  6 min 29.395 sec  52975 obs/sec     10        10            100070     0.458059         0.720849            0.99627        0.203939                         0.460529           0.734516              0.996221         0.207229
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0872956
C13         0.988727               0.988727             0.0863115
C9          0.961188               0.961188             0.0839075
C12         0.892236               0.892236             0.0778882
C7          0.825432               0.825432             0.0720566
C11         0.796492               0.796492             0.0695302
C8          0.79072                0.79072              0.0690264
C10         0.695993               0.695993             0.0607571
C14         0.693591               0.693591             0.0605475
C6          0.64424                0.64424              0.0562393
C16         0.640192               0.640192             0.0558859
C3          0.567984               0.567984             0.0495825
C4          0.56314                0.56314              0.0491596
C5          0.552106               0.552106             0.0481964
C2          0.432262               0.432262             0.0377346
C1          0.411028               0.411028             0.0358809
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_133

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007409059047063238  0.00017101143021136522  0.0         -0.01499717009012258  0.2933274507522583  0.1473596380196308    0.21813136339187622
    3        26       Softmax                      0.0   0.0   0.005244549952294619   0.014303620904684067    0.0         -0.4067354310996227   0.88421630859375    -0.44309294318947623  0.46385276317596436


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22236429889993212
RMSE: 0.4715551917855768
LogLoss: 0.721642983686956
Mean Per-Class Error: 0.20308649710331095
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    3.0    0.0    0.0    0.0    3.0    0.0    2.0    1.0    3.0    8.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    2.0    0.0    3.0    2.0    7.0    0.0    0.10379746835443038  41 / 395
0.0    306.0  0.0    14.0   2.0    2.0    21.0   4.0    1.0    0.0    7.0    0.0    1.0    0.0    2.0    2.0    0.0    9.0    5.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    0.2010443864229765   77 / 383
0.0    0.0    300.0  0.0    10.0   1.0    14.0   1.0    0.0    0.0    17.0   0.0    0.0    0.0    11.0   0.0    5.0    0.0    1.0    2.0    2.0    1.0    2.0    1.0    0.0    0.0    0.18478260869565216  68 / 368
3.0    14.0   0.0    346.0  0.0    1.0    0.0    14.0   0.0    2.0    0.0    0.0    6.0    2.0    1.0    0.0    1.0    6.0    2.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.141439205955335    57 / 403
0.0    12.0   2.0    0.0    293.0  5.0    22.0   1.0    0.0    0.0    12.0   1.0    0.0    0.0    0.0    1.0    5.0    3.0    5.0    1.0    0.0    0.0    0.0    5.0    3.0    13.0   0.23697916666666666  91 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    1.0    0.0    1.0    4.0    0.0    0.0    1.0    0.0    17.0   0.0    3.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    4.0    1.0    7.0    6.0    1.0    0.0    0.0    2.0    3.0    12.0   0.0    0.0    0.0    0.0    0.0    2.0    3.0    3.0    5.0    2.0    1.0    0.0    336.0  3.0    3.0    0.14720812182741116  58 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    20.0   0.0    9.0    12.0   0.0    29.0   2.0    0.0    312.0  1.0    0.20610687022900764  81 / 393
2.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    32.0   2.0    0.0    0.0    0.0    2.0    0.0    302.0  0.1771117166212534   65 / 367
403.0  449.0  341.0  458.0  373.0  347.0  438.0  341.0  335.0  345.0  401.0  329.0  442.0  350.0  394.0  383.0  355.0  390.0  339.0  367.0  379.0  415.0  425.0  410.0  400.0  394.0  0.20223932820153953  2,023 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.797761
2    0.879936
3    0.914126
4    0.936319
5    0.951415
6    0.963211
7    0.971608
8    0.977807
9    0.982005
10   0.985304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22523046527313892
RMSE: 0.4745845185771855
LogLoss: 0.7353555028653928
Mean Per-Class Error: 0.20368375687757112
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   80.0   0.0   2.0    2.0   0.0   8.0    1.0   0.0   0.0    2.0   0.0   1.0   0.0   2.0   0.0    0.0   4.0    0.0   0.0   0.0    2.0   0.0    2.0   0.0    0.0   0.24528301886792453  26 / 106
0.0   0.0    61.0  0.0    3.0   0.0   3.0    0.0   0.0   0.0    4.0   0.0   0.0   0.0   4.0   0.0    2.0   0.0    1.0   2.0   0.0    1.0   1.0    0.0   0.0    0.0   0.25609756097560976  21 / 82
2.0   4.0    0.0   94.0   0.0   0.0   0.0    4.0   0.0   1.0    0.0   0.0   2.0   1.0   0.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    0.0   0.16071428571428573  18 / 112
0.0   2.0    1.0   0.0    74.0  2.0   6.0    0.0   0.0   0.0    4.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    4.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   4.0   0.0   1.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   2.0    2.0   1.0   0.0    0.0   0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    1.0   1.0   0.0    0.0   0.0    83.0  0.0    2.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    8.0   0.0    0.0   3.0   0.0    9.0   1.0    0.0   84.0   0.0   0.21495327102803738  23 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    6.0   0.0   0.0    0.0   0.0    1.0   0.0    72.0  0.1724137931034483   15 / 87
97.0  110.0  70.0  124.0  94.0  86.0  110.0  81.0  77.0  106.0  99.0  88.0  96.0  93.0  79.0  107.0  92.0  104.0  80.0  87.0  102.0  97.0  110.0  99.0  103.0  99.0  0.20321285140562248  506 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796787
2    0.877912
3    0.913655
4    0.931727
5    0.947791
6    0.957028
7    0.967872
8    0.9751
9    0.979116
10   0.982329
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:43  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:43  3 min 41.049 sec  175561 obs/sec    1         1             10007      0.70569          1.5256              0.991151       0.40018                          0.705814           1.52816               0.991123         0.405221
    2019-08-04 09:03:43  3 min 41.509 sec  198551 obs/sec    10        10            100070     0.471555         0.721643            0.996049       0.202239                         0.474585           0.735356              0.995987         0.203213
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0986754
C13         0.900298               0.900298             0.0888373
C8          0.818752               0.818752             0.0807907
C7          0.797382               0.797382             0.0786821
C9          0.667214               0.667214             0.0658377
C12         0.659327               0.659327             0.0650593
C5          0.629971               0.629971             0.0621627
C11         0.614446               0.614446             0.0606307
C14         0.607861               0.607861             0.0599809
C10         0.572748               0.572748             0.0565162
C3          0.518897               0.518897             0.0512024
C6          0.510991               0.510991             0.0504223
C4          0.503592               0.503592             0.0496922
C1          0.471625               0.471625             0.0465378
C16         0.461466               0.461466             0.0455354
C2          0.399663               0.399663             0.0394369
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_68

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015500847285352393  0.0003333037020638585  0.0         -0.05206075946700395  0.752894401550293   -0.019023588583491614  0.7454867362976074
    3        26       Softmax                 0.0   0.0   0.0019100615117727453  0.0003435674589127302  0.0         0.009586470448116283  0.3891040086746216  -0.5491983805751018    0.2743542194366455


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21203762525799716
RMSE: 0.4604754339354024
LogLoss: 0.7198899597577142
Mean Per-Class Error: 0.20844263103783806
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    2.0    0.0    8.0    0.0    1.0    0.0    0.0    1.0    7.0    2.0    2.0    0.0    3.0    5.0    5.0    0.0    0.09873417721518987  39 / 395
0.0    326.0  0.0    4.0    3.0    1.0    0.0    3.0    5.0    0.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    19.0   11.0   0.0    1.0    3.0    0.0    2.0    1.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    287.0  0.0    21.0   1.0    14.0   0.0    0.0    0.0    20.0   0.0    0.0    0.0    3.0    0.0    2.0    0.0    3.0    5.0    7.0    0.0    5.0    0.0    0.0    0.0    0.22010869565217392  81 / 368
2.0    21.0   0.0    325.0  0.0    0.0    0.0    11.0   0.0    7.0    0.0    0.0    7.0    4.0    4.0    2.0    0.0    12.0   3.0    0.0    1.0    0.0    0.0    4.0    0.0    0.0    0.1935483870967742   78 / 403
0.0    11.0   2.0    0.0    296.0  6.0    12.0   1.0    2.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    11.0   3.0    12.0   5.0    0.0    0.0    0.0    5.0    0.0    10.0   0.22916666666666666  88 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    15.0   1.0    2.0    0.0    0.0    2.0    0.0    0.0    1.0    2.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    9.0    0.0    5.0    7.0    0.0    6.0    3.0    7.0    2.0    11.0   5.0    0.0    0.0    2.0    1.0    8.0    1.0    7.0    4.0    2.0    0.0    0.0    306.0  7.0    1.0    0.2233502538071066   88 / 394
0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    3.0    17.0   3.0    25.0   3.0    1.0    325.0  1.0    0.17302798982188294  68 / 393
0.0    0.0    0.0    0.0    20.0   1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    26.0   4.0    0.0    0.0    0.0    0.0    0.0    297.0  0.1863013698630137   68 / 365
395.0  514.0  337.0  419.0  410.0  348.0  331.0  328.0  334.0  380.0  379.0  342.0  458.0  384.0  369.0  398.0  371.0  426.0  351.0  400.0  399.0  369.0  424.0  379.0  400.0  358.0  0.20743776866939917  2,075 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792562
2    0.884235
3    0.920024
4    0.940118
5    0.955213
6    0.963711
7    0.971209
8    0.977607
9    0.981706
10   0.985204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21670869435735432
RMSE: 0.4655198109182404
LogLoss: 0.7365934450035051
Mean Per-Class Error: 0.21608342514654447
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   2.0    2.0   2.0    0.0   0.10112359550561797  9 / 89
0.0   83.0   0.0   1.0    2.0   1.0   0.0   2.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0    8.0    3.0   0.0   1.0    2.0   0.0    2.0   0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    59.0  0.0    3.0   0.0   7.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0    2.0   0.0    0.0    0.0    2.0   2.0   1.0    0.0   2.0    0.0   0.0    0.0   0.2804878048780488   23 / 82
1.0   4.0    0.0   86.0   0.0   0.0   0.0   6.0   0.0   3.0    0.0   0.0   3.0    1.0    0.0   2.0    0.0    4.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.23214285714285715  26 / 112
0.0   3.0    1.0   0.0    70.0  3.0   1.0   0.0   1.0   0.0    2.0   0.0   0.0    0.0    0.0   0.0    4.0    1.0    4.0   2.0   0.0    0.0   0.0    0.0   0.0    5.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   1.0    0.0   3.0    2.0   0.0   1.0   2.0   2.0   0.0    5.0   2.0   0.0    0.0    0.0   0.0    2.0    1.0    1.0   0.0   1.0    0.0   0.0    73.0  3.0    1.0   0.27                 27 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   1.0    4.0    0.0    0.0   4.0   2.0    8.0   2.0    0.0   86.0   0.0   0.19626168224299065  21 / 107
0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0    0.0    0.0   1.0    1.0    0.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    71.0  0.1839080459770115   16 / 87
89.0  122.0  67.0  116.0  90.0  81.0  85.0  86.0  78.0  113.0  93.0  95.0  104.0  103.0  72.0  111.0  102.0  109.0  88.0  93.0  104.0  89.0  107.0  89.0  107.0  97.0  0.21566265060240963  537 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.784337
2    0.881928
3    0.917269
4    0.937349
5    0.955422
6    0.962651
7    0.969076
8    0.977109
9    0.981928
10   0.984739
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:53  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:53  1 min 51.087 sec  53513 obs/sec     1         1             10007      0.5819           1.08314             0.99398        0.284915                         0.581189           1.07288               0.993981         0.284739
    2019-08-04 09:01:55  1 min 52.833 sec  52723 obs/sec     10        10            100070     0.460475         0.71989             0.99623        0.207438                         0.46552            0.736593              0.996139         0.215663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0936653
C13         0.900167               0.900167             0.0843144
C12         0.865279               0.865279             0.0810467
C9          0.814166               0.814166             0.0762591
C11         0.799714               0.799714             0.0749055
C7          0.739669               0.739669             0.0692814
C8          0.731677               0.731677             0.0685327
C10         0.652765               0.652765             0.0611415
C14         0.633281               0.633281             0.0593165
C6          0.595181               0.595181             0.0557478
C16         0.566071               0.566071             0.0530212
C3          0.550254               0.550254             0.0515397
C5          0.506793               0.506793             0.0474689
C4          0.502119               0.502119             0.0470312
C2          0.434436               0.434436             0.0406916
C1          0.384738               0.384738             0.0360366
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_94

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias           bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  ------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007848928997873372  0.0001857407041825354  0.0         -0.02136579595173771  0.2886298894882202  0.2424203833216185  0.2118268609046936
    3        26       Softmax                      0.0   0.0   0.004858119752987897   0.028862185776233673   0.0         -0.36725643647195316  0.8651301860809326  -0.458373977044939  0.33450400829315186


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22514865337288148
RMSE: 0.47449831756591243
LogLoss: 0.7352308493326619
Mean Per-Class Error: 0.20511984230051317
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    4.0    4.0    1.0    5.0    0.0    6.0    0.0    0.0    0.0    4.0    0.0    2.0    1.0    2.0    2.0    7.0    1.0    0.10379746835443038  41 / 395
0.0    324.0  1.0    8.0    1.0    0.0    2.0    14.0   0.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    0.0    16.0   8.0    0.0    0.0    1.0    1.0    2.0    0.0    0.0    0.15404699738903394  59 / 383
0.0    0.0    304.0  0.0    5.0    0.0    9.0    3.0    0.0    0.0    25.0   0.0    1.0    0.0    1.0    0.0    1.0    0.0    8.0    2.0    4.0    0.0    4.0    0.0    0.0    0.0    0.17166212534059946  63 / 367
2.0    19.0   0.0    333.0  0.0    0.0    1.0    7.0    0.0    5.0    3.0    0.0    7.0    5.0    2.0    1.0    0.0    6.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    6.0    0.17369727047146402  70 / 403
0.0    5.0    3.0    0.0    301.0  7.0    11.0   1.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    9.0    5.0    16.0   1.0    0.0    0.0    0.0    4.0    0.0    16.0   0.21614583333333334  83 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    13.0   0.0    0.0    0.0    0.0    11.0   3.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    5.0    0.0    3.0    3.0    0.0    2.0    2.0    1.0    1.0    11.0   3.0    0.0    0.0    2.0    1.0    8.0    1.0    8.0    1.0    2.0    0.0    0.0    326.0  4.0    10.0   0.17258883248730963  68 / 394
1.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    0.0    1.0    4.0    0.0    4.0    13.0   2.0    25.0   1.0    1.0    329.0  0.0    0.1628498727735369   64 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    33.0   2.0    0.0    0.0    0.0    0.0    1.0    299.0  0.18528610354223432  68 / 367
395.0  513.0  363.0  412.0  368.0  365.0  348.0  333.0  336.0  364.0  403.0  345.0  432.0  384.0  393.0  397.0  311.0  408.0  398.0  335.0  384.0  392.0  440.0  392.0  399.0  393.0  0.20443866839948016  2,045 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.795561
2    0.882735
3    0.916625
4    0.938118
5    0.956513
6    0.96651
7    0.974008
8    0.979006
9    0.982705
10   0.986004

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22590633588348263
RMSE: 0.47529605077623216
LogLoss: 0.7366714118722673
Mean Per-Class Error: 0.2053696189525187
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    2.0   3.0    0.0    0.0898876404494382   8 / 89
0.0   79.0   0.0   3.0    1.0   0.0   1.0   7.0   0.0   0.0    1.0    0.0   0.0   0.0    1.0   1.0    0.0   5.0    4.0   0.0   0.0   1.0   1.0    1.0   0.0    0.0    0.25471698113207547  27 / 106
0.0   0.0    65.0  0.0    1.0   0.0   3.0   1.0   0.0   0.0    5.0    0.0   0.0   0.0    1.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.2073170731707317   17 / 82
2.0   3.0    0.0   93.0   0.0   0.0   0.0   2.0   0.0   2.0    2.0    0.0   4.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    2.0    0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    71.0  2.0   3.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   0.0    3.0   2.0    5.0   0.0   0.0   0.0   0.0    0.0   0.0    8.0    0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0   4.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   1.0    0.0   1.0    1.0   0.0   1.0   0.0   0.0   0.0    5.0    2.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0   0.0   0.0   0.0   0.0    80.0  1.0    3.0    0.2                  20 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0   2.0    0.0   0.0    1.0   0.0    0.0   4.0   0.0   8.0   1.0    0.0   89.0   0.0    0.16822429906542055  18 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0   1.0   0.0   0.0   0.0    0.0   1.0    71.0   0.1839080459770115   16 / 87
94.0  121.0  73.0  114.0  85.0  87.0  83.0  90.0  79.0  105.0  104.0  93.0  97.0  103.0  76.0  114.0  90.0  105.0  98.0  78.0  97.0  89.0  106.0  98.0  110.0  101.0  0.20522088353413653  511 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.794779
2    0.884337
3    0.918875
4    0.939357
5    0.959839
6    0.971084
7    0.975502
8    0.97992
9    0.982731
10   0.983936
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:37  2 min 34.874 sec  178696 obs/sec    1         1             10007      0.689114         1.4358              0.991561       0.385084                         0.689041           1.42815               0.99154          0.390763
    2019-08-04 09:02:37  2 min 35.358 sec  190609 obs/sec    10        10            100070     0.474498         0.735231            0.995999       0.204439                         0.475296           0.736671              0.995975         0.205221
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0908296
C13         0.957519               0.957519             0.0869711
C12         0.840827               0.840827             0.076372
C8          0.830383               0.830383             0.0754233
C9          0.804965               0.804965             0.0731147
C7          0.699211               0.699211             0.0635091
C11         0.690632               0.690632             0.0627299
C6          0.637029               0.637029             0.0578611
C5          0.612366               0.612366             0.055621
C3          0.611881               0.611881             0.0555769
C4          0.608921               0.608921             0.0553081
C14         0.596785               0.596785             0.0542058
C10         0.570658               0.570658             0.0518327
C16         0.55235                0.55235              0.0501697
C2          0.517128               0.517128             0.0469706
C1          0.478968               0.478968             0.0435045
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_12

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.001159931960216909  0.0003669401630759239  0.0         -0.012624820739347342  0.5532457828521729  -0.02507887627686842  0.6083667278289795
    3        26       Softmax                 0.0   0.0   0.002308605366264461  0.0006158198229968548  0.0         -0.025875605932014878  0.7350995540618896  -0.5238344077652045   0.25131404399871826


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2184115004290642
RMSE: 0.467345161983158
LogLoss: 0.7413200208584182
Mean Per-Class Error: 0.20755522315414582
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    5.0    1.0    3.0    1.0    7.0    0.0    0.0    1.0    1.0    0.0    3.0    0.0    2.0    1.0    6.0    1.0    0.09367088607594937  37 / 395
0.0    295.0  0.0    9.0    3.0    2.0    5.0    2.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    3.0    1.0    31.0   19.0   1.0    0.0    5.0    1.0    3.0    0.0    0.0    0.2297650130548303   88 / 383
0.0    0.0    286.0  1.0    14.0   0.0    21.0   0.0    0.0    0.0    22.0   2.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    2.0    2.0    0.0    2.0    0.0    0.0    1.0    0.22282608695652173  82 / 368
0.0    16.0   0.0    337.0  0.0    1.0    0.0    9.0    0.0    4.0    2.0    0.0    2.0    8.0    7.0    5.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.16377171215880892  66 / 403
0.0    1.0    4.0    0.0    302.0  5.0    13.0   0.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    1.0    9.0    8.0    8.0    1.0    1.0    0.0    0.0    5.0    0.0    17.0   0.21148825065274152  81 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    10.0   8.0    6.0    0.0    0.0    3.0    0.0    0.0    1.0    4.0    330.0  0.0    0.0    0.0    0.12234042553191489  46 / 376
0.0    3.0    0.0    8.0    7.0    2.0    0.0    1.0    0.0    0.0    8.0    2.0    0.0    0.0    2.0    1.0    8.0    4.0    5.0    6.0    5.0    0.0    0.0    325.0  3.0    4.0    0.1751269035532995   69 / 394
0.0    0.0    0.0    1.0    0.0    9.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    3.0    0.0    3.0    19.0   1.0    27.0   2.0    0.0    321.0  0.0    0.183206106870229    72 / 393
2.0    0.0    0.0    1.0    28.0   1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    41.0   1.0    0.0    0.0    0.0    2.0    0.0    275.0  0.2506811989100817   92 / 367
393.0  459.0  349.0  444.0  413.0  370.0  358.0  305.0  317.0  362.0  374.0  338.0  395.0  398.0  411.0  414.0  370.0  437.0  350.0  383.0  400.0  375.0  411.0  414.0  394.0  369.0  0.20623812856143156  2,063 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793762
2    0.880536
3    0.917025
4    0.938718
5    0.951315
6    0.961611
7    0.96771
8    0.974408
9    0.980106
10   0.984205

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22119205019815075
RMSE: 0.47031058907720835
LogLoss: 0.7377661850945538
Mean Per-Class Error: 0.2108902072847677
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   0.0    1.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   77.0   0.0   3.0    2.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    0.0   11.0   5.0   0.0   0.0    3.0   0.0    2.0    0.0    0.0   0.27358490566037735  29 / 106
0.0   0.0    61.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    5.0   0.0    2.0   0.0    0.0   1.0   1.0    0.0   1.0    0.0    0.0    0.0   0.25609756097560976  21 / 82
0.0   2.0    0.0   93.0   0.0   0.0   0.0   4.0   0.0   1.0    0.0   0.0   1.0   3.0    2.0   1.0    0.0   3.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    69.0  4.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    3.0   2.0    1.0   0.0   0.0    0.0   0.0    2.0    0.0    8.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0    1.0   82.0   0.0    0.0    0.0   0.10869565217391304  10 / 92
0.0   1.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    3.0   2.0   0.0   0.0    0.0   0.0    2.0   3.0    0.0   1.0   1.0    0.0   0.0    79.0   1.0    1.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   3.0   1.0    7.0   2.0    0.0    89.0   0.0   0.16822429906542055  18 / 107
0.0   0.0    0.0   1.0    9.0   1.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    7.0   0.0   0.0    0.0   0.0    0.0    0.0    64.0  0.26436781609195403  23 / 87
90.0  111.0  76.0  123.0  94.0  83.0  82.0  81.0  70.0  107.0  95.0  89.0  87.0  105.0  82.0  119.0  99.0  113.0  86.0  87.0  103.0  87.0  102.0  108.0  115.0  96.0  0.20963855421686747  522 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790361
2    0.882329
3    0.921285
4    0.938153
5    0.953012
6    0.962651
7    0.968675
8    0.974699
9    0.982329
10   0.986345
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:26  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:26  24.721 sec  123543 obs/sec    1         1             10007      0.669111         1.39259             0.992045       0.388783                         0.665821           1.37734               0.992101         0.386345
    2019-08-04 09:00:27  25.406 sec  133249 obs/sec    10        10            100070     0.467345         0.74132             0.996119       0.206238                         0.470311           0.737766              0.996059         0.209639
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0950959
C13         0.952021               0.952021             0.0905333
C12         0.882646               0.882646             0.083936
C9          0.859838               0.859838             0.0817671
C8          0.835114               0.835114             0.0794159
C7          0.782972               0.782972             0.0744574
C11         0.762887               0.762887             0.0725474
C14         0.662932               0.662932             0.0630422
C16         0.624479               0.624479             0.0593854
C6          0.60976                0.60976              0.0579857
C10         0.60924                0.60924              0.0579362
C5          0.465407               0.465407             0.0442583
C4          0.428558               0.428558             0.0407541
C3          0.407369               0.407369             0.0387391
C1          0.31657                0.31657              0.0301045
C2          0.315907               0.315907             0.0300415
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_72

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015213415007337971  0.00031294499058276415  0.0         -0.0025600459547234777  0.7539641857147217  0.07605176492496321  0.7715473175048828
    3        26       Softmax                 0.0   0.0   0.0018220547579473462  0.00030581257306039333  0.0         0.0015748693940673174   0.386452317237854   -0.5468791573560724  0.23987209796905518


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21731320044678348
RMSE: 0.466168639493031
LogLoss: 0.7392077909884956
Mean Per-Class Error: 0.21360580865892262
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    2.0    0.0    8.0    0.0    1.0    0.0    2.0    3.0    2.0    0.0    1.0    1.0    4.0    1.0    8.0    1.0    0.09873417721518987  39 / 395
0.0    310.0  0.0    8.0    2.0    0.0    3.0    6.0    7.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    19.0   13.0   0.0    0.0    6.0    0.0    1.0    2.0    1.0    0.1906005221932115   73 / 383
0.0    0.0    296.0  0.0    18.0   1.0    10.0   1.0    0.0    0.0    20.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    5.0    4.0    5.0    0.0    4.0    0.0    0.0    0.0    0.1956521739130435   72 / 368
4.0    21.0   0.0    330.0  0.0    0.0    1.0    6.0    0.0    8.0    0.0    1.0    7.0    3.0    2.0    5.0    0.0    3.0    0.0    0.0    2.0    0.0    0.0    8.0    0.0    2.0    0.18114143920595532  73 / 403
0.0    5.0    3.0    0.0    302.0  4.0    11.0   3.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    10.0   4.0    9.0    3.0    0.0    0.0    0.0    2.0    0.0    20.0   0.21354166666666666  82 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    22.0   1.0    2.0    0.0    0.0    2.0    0.0    0.0    1.0    2.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    3.0    0.0    5.0    8.0    1.0    0.0    1.0    10.0   0.0    13.0   2.0    0.0    1.0    2.0    0.0    8.0    0.0    14.0   2.0    2.0    1.0    0.0    305.0  8.0    8.0    0.22588832487309646  89 / 394
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    3.0    0.0    4.0    27.0   3.0    21.0   5.0    1.0    317.0  0.0    0.19338422391857507  76 / 393
3.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    33.0   5.0    0.0    0.0    0.0    0.0    1.0    293.0  0.2016348773841962   74 / 367
396.0  512.0  362.0  432.0  399.0  321.0  300.0  330.0  351.0  355.0  410.0  334.0  448.0  367.0  377.0  391.0  348.0  414.0  386.0  415.0  396.0  394.0  426.0  374.0  397.0  368.0  0.21273617914625612  2,128 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787264
2    0.881136
3    0.917525
4    0.938118
5    0.952914
6    0.963411
7    0.972008
8    0.976507
9    0.981805
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2188010041593193
RMSE: 0.46776169590863176
LogLoss: 0.7429957671140319
Mean Per-Class Error: 0.2208461948852525
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17     18    19     20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.0   2.0    1.0   3.0    0.0   0.10112359550561797  9 / 89
0.0   79.0   0.0   3.0    2.0   0.0   1.0   1.0   2.0   0.0    1.0    0.0   0.0    0.0   0.0   0.0    1.0   7.0    4.0   0.0    0.0    4.0   0.0    1.0   0.0    0.0   0.25471698113207547  27 / 106
0.0   0.0    62.0  0.0    3.0   0.0   3.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0    3.0   2.0    1.0    0.0   2.0    0.0   0.0    0.0   0.24390243902439024  20 / 82
2.0   4.0    0.0   93.0   0.0   0.0   1.0   3.0   0.0   0.0    0.0    0.0   3.0    1.0   1.0   2.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    1.0   0.0    0.0   0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    71.0  3.0   4.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0   0.0   0.0    3.0   1.0    3.0   1.0    0.0    0.0   0.0    0.0   0.0    6.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0    0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   1.0    0.0   3.0    4.0   0.0   0.0   1.0   4.0   0.0    6.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0    2.0   0.0    0.0    0.0   0.0    71.0  4.0    2.0   0.29                 29 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0    1.0   0.0    0.0   6.0    2.0    5.0   3.0    0.0   87.0   0.0   0.18691588785046728  20 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0    6.0   2.0    0.0    0.0   0.0    0.0   1.0    69.0  0.20689655172413793  18 / 87
91.0  128.0  74.0  127.0  94.0  71.0  75.0  85.0  83.0  100.0  103.0  89.0  100.0  98.0  72.0  115.0  89.0  106.0  99.0  101.0  100.0  89.0  113.0  86.0  116.0  86.0  0.21927710843373494  546 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780723
2    0.885542
3    0.92008
4    0.939759
5    0.955422
6    0.963454
7    0.973896
8    0.978313
9    0.980723
10   0.985542
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:01  1 min 59.106 sec  51317 obs/sec     1         1             10007      0.585112         1.09758             0.993917       0.293712                         0.583537           1.08318               0.993933         0.290763
    2019-08-04 09:02:03  2 min  0.840 sec  52807 obs/sec     10        10            100070     0.466169         0.739208            0.996138       0.212736                         0.467762           0.742996              0.996101         0.219277
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0886338
C13         0.995259               0.995259             0.0882135
C9          0.9512                 0.9512               0.0843084
C12         0.882782               0.882782             0.0782443
C7          0.805825               0.805825             0.0714233
C11         0.794175               0.794175             0.0703907
C8          0.762378               0.762378             0.0675725
C14         0.69536                0.69536              0.0616324
C10         0.657985               0.657985             0.0583197
C6          0.652209               0.652209             0.0578077
C3          0.592372               0.592372             0.0525041
C16         0.56969                0.56969              0.0504938
C4          0.563373               0.563373             0.0499339
C5          0.524691               0.524691             0.0465053
C2          0.438382               0.438382             0.0388554
C1          0.396704               0.396704             0.0351613
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_175

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013032645506427798  0.0003311373293399811  0.0         -0.052996090415717845  0.7413976192474365  -0.08725399524783303  0.7374172210693359
    3        26       Softmax                 0.0   0.0   0.0018871069073261775  0.0002587222261354327  0.0         0.007518036497108719   0.5002071857452393  -0.45677002994163013  0.23107212781906128


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21487175404576844
RMSE: 0.4635426129772412
LogLoss: 0.7214184882629228
Mean Per-Class Error: 0.21255609414269733
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    3.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    0.0    3.0    0.0    1.0    0.0    3.0    2.0    1.0    1.0    3.0    0.0    2.0    3.0    5.0    4.0    0.09873417721518987  39 / 395
1.0    315.0  0.0    1.0    3.0    4.0    10.0   5.0    2.0    0.0    1.0    0.0    2.0    0.0    0.0    1.0    0.0    22.0   2.0    1.0    0.0    4.0    0.0    4.0    5.0    0.0    0.17754569190600522  68 / 383
0.0    0.0    287.0  0.0    19.0   2.0    22.0   1.0    0.0    0.0    10.0   0.0    0.0    0.0    2.0    0.0    5.0    0.0    8.0    3.0    5.0    0.0    3.0    0.0    0.0    1.0    0.22010869565217392  81 / 368
5.0    16.0   0.0    308.0  0.0    7.0    4.0    13.0   1.0    5.0    0.0    0.0    3.0    6.0    9.0    8.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    7.0    1.0    0.0    0.23573200992555832  95 / 403
0.0    7.0    3.0    0.0    291.0  4.0    10.0   0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    12.0   5.0    4.0    6.0    0.0    0.0    0.0    6.0    0.0    29.0   0.2421875            93 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    8.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    4.0    4.0    5.0    0.0    0.0    3.0    0.0    0.0    0.0    4.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    2.0    0.0    10.0   8.0    1.0    0.0    5.0    5.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    5.0    0.0    0.0    321.0  5.0    13.0   0.18527918781725888  73 / 394
1.0    1.0    0.0    1.0    1.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    10.0   0.0    2.0    30.0   1.0    48.0   1.0    2.0    284.0  0.0    0.27735368956743     109 / 393
0.0    0.0    0.0    0.0    11.0   1.0    0.0    0.0    1.0    6.0    0.0    1.0    0.0    0.0    0.0    4.0    5.0    1.0    20.0   9.0    0.0    0.0    0.0    2.0    2.0    304.0  0.17166212534059946  63 / 367
420.0  535.0  346.0  396.0  384.0  406.0  333.0  306.0  347.0  342.0  361.0  332.0  390.0  388.0  388.0  383.0  369.0  454.0  306.0  403.0  398.0  414.0  426.0  398.0  352.0  426.0  0.2118364490652804   2,119 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788164
2    0.880236
3    0.919524
4    0.943617
5    0.957413
6    0.96641
7    0.973308
8    0.978107
9    0.982305
10   0.985304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22054938453081932
RMSE: 0.4696268566966963
LogLoss: 0.7433285998090502
Mean Per-Class Error: 0.2174119339713344
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   1.0    2.0   2.0    1.0    0.07865168539325842  7 / 89
0.0    82.0   0.0   0.0    2.0   0.0   4.0   2.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   7.0    0.0   0.0   0.0    3.0   0.0    2.0   2.0    0.0    0.22641509433962265  24 / 106
0.0    0.0    59.0  0.0    5.0   0.0   8.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    3.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0    0.2804878048780488   23 / 82
3.0    3.0    0.0   86.0   0.0   1.0   1.0   4.0   1.0   1.0   0.0   0.0   1.0   2.0    2.0   4.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0    0.23214285714285715  26 / 112
0.0    2.0    0.0   0.0    70.0  1.0   4.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    1.0   3.0   0.0    0.0   0.0    1.0   0.0    11.0   0.27835051546391754  27 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0    2.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0    1.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0    1.0    0.0   4.0    3.0   0.0   0.0   1.0   0.0   0.0   4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   3.0    0.0   0.0    77.0  2.0    4.0    0.23                 23 / 100
1.0    1.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0    0.0   8.0   0.0    12.0  1.0    0.0   78.0   0.0    0.27102803738317754  29 / 107
0.0    0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   1.0    1.0   0.0    3.0   3.0   0.0    0.0   0.0    0.0   2.0    74.0   0.14942528735632185  13 / 87
103.0  136.0  68.0  115.0  90.0  90.0  90.0  78.0  86.0  96.0  87.0  90.0  83.0  101.0  75.0  110.0  95.0  109.0  75.0  95.0  104.0  98.0  108.0  94.0  105.0  109.0  0.2176706827309237   542 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782329
2    0.874297
3    0.915663
4    0.944177
5    0.955422
6    0.963454
7    0.969879
8    0.976707
9    0.980321
10   0.984739
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:11  5 min  8.941 sec  82024 obs/sec     1         1             10007      0.599772         1.14263             0.993608       0.30031                          0.598733           1.14781               0.993612         0.304418
    2019-08-04 09:05:12  5 min 10.098 sec  80120 obs/sec     10        10            100070     0.463543         0.721418            0.996182       0.211836                         0.469627           0.743329              0.99607          0.217671
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.090485
C13         0.914187               0.914187             0.0827203
C9          0.853704               0.853704             0.0772474
C12         0.848971               0.848971             0.0768192
C7          0.812516               0.812516             0.0735205
C8          0.798329               0.798329             0.0722368
C11         0.786318               0.786318             0.07115
C14         0.716598               0.716598             0.0648414
C10         0.685678               0.685678             0.0620436
C6          0.603803               0.603803             0.0546351
C16         0.60099                0.60099              0.0543806
C5          0.564742               0.564742             0.0511007
C3          0.531276               0.531276             0.0480725
C4          0.495757               0.495757             0.0448586
C2          0.427658               0.427658             0.0386966
C1          0.411025               0.411025             0.0371916
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_210

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007733143660857422  0.00020074617350474   0.0         -0.021405412624659448  0.2830355167388916  0.22922754133195067  0.24212485551834106
    3        26       Softmax                      0.0   0.0   0.00520734475493065    0.012783877551555634  0.0         -0.37306560440307435   0.8794374465942383  -0.4971402852553827  0.26193320751190186


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22779850077905206
RMSE: 0.47728241197330123
LogLoss: 0.7503214825816387
Mean Per-Class Error: 0.20766451475829745
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    10.0   5.0    1.0    1.0    1.0    2.0    0.0    1.0    4.0    0.0    0.0    2.0    2.0    3.0    3.0    2.0    6.0    0.11421319796954314  45 / 394
0.0    325.0  0.0    5.0    2.0    3.0    3.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    4.0    8.0    5.0    17.0   2.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    0.1514360313315927   58 / 383
0.0    0.0    303.0  1.0    16.0   0.0    7.0    4.0    0.0    0.0    22.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    2.0    2.0    1.0    0.0    6.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
1.0    33.0   0.0    323.0  0.0    0.0    2.0    7.0    0.0    8.0    0.0    0.0    7.0    2.0    7.0    3.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.19851116625310175  80 / 403
0.0    13.0   4.0    0.0    306.0  4.0    21.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    6.0    6.0    0.0    0.0    0.0    3.0    1.0    12.0   0.203125             78 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    18.0   0.0    6.0    0.0    0.0    1.0    0.0    0.0    6.0    0.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    6.0    0.0    4.0    6.0    2.0    1.0    2.0    5.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    5.0    4.0    3.0    2.0    0.0    330.0  4.0    5.0    0.16243654822335024  64 / 394
2.0    0.0    0.0    2.0    1.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    9.0    0.0    8.0    21.0   1.0    23.0   1.0    1.0    312.0  2.0    0.20610687022900764  81 / 393
4.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    16.0   4.0    0.0    0.0    0.0    2.0    0.0    318.0  0.1335149863760218   49 / 367
399.0  543.0  348.0  422.0  392.0  380.0  379.0  295.0  333.0  364.0  377.0  324.0  453.0  345.0  385.0  399.0  331.0  386.0  323.0  382.0  391.0  374.0  454.0  427.0  383.0  414.0  0.20683794861541538  2,069 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793162
2    0.875737
3    0.909827
4    0.930121
5    0.945816
6    0.958812
7    0.96641
8    0.972408
9    0.977507
10   0.981306

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2289027406203749
RMSE: 0.47843781269917923
LogLoss: 0.7446443036116388
Mean Per-Class Error: 0.2116076496826655
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17     18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   1.0   0.0   1.0    1.0    2.0    1.0    0.0898876404494382   8 / 89
0.0   84.0   0.0   1.0    1.0   1.0   1.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   2.0   3.0    2.0   6.0    1.0   0.0   0.0   2.0   0.0    1.0    0.0    0.0    0.20754716981132076  22 / 106
0.0   0.0    62.0  1.0    3.0   0.0   4.0   2.0   0.0   0.0    5.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    1.0   1.0   0.0   0.0   2.0    0.0    0.0    0.0    0.24390243902439024  20 / 82
1.0   5.0    0.0   93.0   0.0   0.0   1.0   1.0   0.0   2.0    0.0   0.0   3.0    1.0   1.0   2.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0    0.16964285714285715  19 / 112
0.0   2.0    1.0   0.0    76.0  2.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0   2.0    2.0   2.0   0.0   0.0   0.0    0.0    0.0    5.0    0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    3.0   0.0   0.0   0.0   1.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0    0.0   4.0    2.0   1.0   0.0   0.0   0.0    81.0   1.0    2.0    0.19                 19 / 100
1.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   3.0   0.0    2.0   0.0    0.0   6.0   0.0   6.0   1.0    0.0    85.0   2.0    0.205607476635514    22 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0   0.0   0.0   0.0    1.0    0.0    75.0   0.13793103448275862  12 / 87
98.0  130.0  71.0  119.0  94.0  85.0  97.0  77.0  80.0  106.0  90.0  85.0  105.0  88.0  79.0  116.0  80.0  103.0  80.0  92.0  94.0  85.0  111.0  103.0  110.0  112.0  0.21124497991967872  526 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788755
2    0.881928
3    0.912851
4    0.933735
5    0.949799
6    0.963454
7    0.969879
8    0.974699
9    0.979116
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:11  6 min  9.500 sec  172534 obs/sec    1         1             10007      0.696532         1.49422             0.991378       0.390683                         0.69807            1.50445               0.991317         0.40241
    2019-08-04 09:06:12  6 min  9.989 sec  188455 obs/sec    10        10            100070     0.477282         0.750321            0.995952       0.206838                         0.478438           0.744644              0.995921         0.211245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0993744
C13         0.861928               0.861928             0.0856536
C7          0.752075               0.752075             0.074737
C12         0.750981               0.750981             0.0746283
C8          0.74826                0.74826              0.0743578
C9          0.702626               0.702626             0.069823
C11         0.616721               0.616721             0.0612862
C10         0.608909               0.608909             0.0605099
C5          0.601385               0.601385             0.0597623
C3          0.583386               0.583386             0.0579736
C4          0.55629                0.55629              0.0552809
C14         0.55157                0.55157              0.054812
C6          0.508385               0.508385             0.0505205
C16         0.45391                0.45391              0.045107
C2          0.41302                0.41302              0.0410436
C1          0.353511               0.353511             0.03513
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_47

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0016348151916361076  0.0003644181415438652  0.0         0.007152187381365138  0.7628145217895508  -0.08712871077952064  0.7488837242126465
    3        26       Softmax                 0.0   0.0   0.0018606688265488348  0.0002476263325661421  0.0         0.014607651265737768  0.3814607858657837  -0.5684405631425      0.290763258934021


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2157167960609226
RMSE: 0.464453222683321
LogLoss: 0.7388784715161518
Mean Per-Class Error: 0.2123721185966396
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    7.0    0.0    6.0    0.0    3.0    1.0    6.0    1.0    1.0    1.0    4.0    0.0    6.0    0.0    0.10632911392405063  42 / 395
0.0    320.0  0.0    3.0    3.0    3.0    0.0    5.0    3.0    1.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    27.0   5.0    0.0    0.0    4.0    0.0    2.0    1.0    0.0    0.16449086161879894  63 / 383
0.0    0.0    292.0  0.0    18.0   1.0    9.0    1.0    0.0    0.0    24.0   1.0    0.0    0.0    2.0    0.0    2.0    0.0    8.0    3.0    4.0    0.0    3.0    0.0    0.0    0.0    0.20652173913043478  76 / 368
0.0    20.0   0.0    317.0  0.0    1.0    0.0    9.0    1.0    7.0    0.0    1.0    4.0    6.0    5.0    7.0    1.0    8.0    3.0    1.0    1.0    0.0    0.0    11.0   0.0    0.0    0.21339950372208435  86 / 403
0.0    11.0   2.0    0.0    298.0  7.0    4.0    0.0    2.0    0.0    5.0    3.0    0.0    0.0    0.0    1.0    14.0   4.0    8.0    2.0    0.0    0.0    0.0    11.0   0.0    12.0   0.22395833333333334  86 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    16.0   1.0    1.0    0.0    0.0    5.0    0.0    0.0    2.0    6.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    9.0    0.0    3.0    11.0   0.0    0.0    2.0    5.0    0.0    7.0    1.0    0.0    0.0    2.0    1.0    8.0    2.0    13.0   6.0    3.0    1.0    0.0    310.0  7.0    3.0    0.2131979695431472   84 / 394
1.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    2.0    7.0    0.0    8.0    22.0   1.0    23.0   1.0    0.0    320.0  0.0    0.1836734693877551   72 / 392
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    1.0    8.0    3.0    28.0   4.0    0.0    0.0    0.0    3.0    0.0    302.0  0.1771117166212534   65 / 367
403.0  492.0  338.0  420.0  398.0  389.0  294.0  271.0  343.0  353.0  384.0  340.0  441.0  354.0  390.0  383.0  392.0  474.0  360.0  379.0  410.0  399.0  435.0  406.0  386.0  369.0  0.2114365690292912   2,115 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788563
2    0.877837
3    0.916525
4    0.938818
5    0.952714
6    0.961812
7    0.969809
8    0.975407
9    0.980806
10   0.984505

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21927599087020652
RMSE: 0.46826914362384214
LogLoss: 0.7462293704314886
Mean Per-Class Error: 0.21686828888146678
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    1.0    0.0    1.0   0.0   0.0    0.0   2.0    0.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   81.0   0.0   0.0    2.0   0.0   0.0   3.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0    11.0   2.0   0.0   0.0    3.0   0.0    1.0   0.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    63.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0   6.0   0.0   0.0    0.0   2.0   0.0    1.0    0.0    3.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0   0.23170731707317074  19 / 82
0.0   2.0    0.0   92.0   0.0   0.0   0.0   5.0   1.0   2.0   0.0   0.0   2.0    1.0   0.0   1.0    1.0    2.0    2.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.17857142857142858  20 / 112
0.0   3.0    1.0   0.0    69.0  5.0   1.0   0.0   0.0   0.0   1.0   2.0   0.0    0.0   0.0   0.0    4.0    1.0    1.0   0.0   0.0    0.0   0.0    2.0   0.0    7.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0    1.0   1.0   0.0    0.0    1.0    0.0   0.0   0.0    1.0   83.0   0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0   2.0    0.0   1.0    5.0   0.0   0.0   1.0   1.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    2.0    2.0    5.0   0.0   1.0    0.0   0.0    73.0  3.0    1.0   0.27                 27 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0    2.0    0.0    1.0   3.0   0.0    5.0   1.0    0.0   90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    2.0    1.0    3.0   2.0   0.0    0.0   0.0    2.0   0.0    73.0  0.16091954022988506  14 / 87
94.0  113.0  73.0  116.0  89.0  86.0  71.0  85.0  83.0  98.0  98.0  88.0  103.0  94.0  75.0  110.0  105.0  123.0  91.0  85.0  101.0  93.0  106.0  98.0  115.0  97.0  0.21606425702811244  538 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783936
2    0.875904
3    0.916867
4    0.938554
5    0.953414
6    0.961847
7    0.96988
8    0.975502
9    0.980723
10   0.985542
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:24  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:25  1 min 22.863 sec  54385 obs/sec     1         1             10007      0.58516          1.10822             0.993915       0.294412                         0.582687           1.09398               0.99395          0.29759
    2019-08-04 09:01:26  1 min 24.575 sec  53917 obs/sec     10        10            100070     0.464453         0.738878            0.996166       0.211437                         0.468269           0.746229              0.996093         0.216064
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0896492
C13         0.966647               0.966647             0.0866592
C12         0.891836               0.891836             0.0799524
C9          0.877276               0.877276             0.078647
C11         0.811014               0.811014             0.0727068
C7          0.808487               0.808487             0.0724802
C8          0.78604                0.78604              0.0704679
C10         0.719831               0.719831             0.0645322
C14         0.702282               0.702282             0.062959
C6          0.599107               0.599107             0.0537095
C16         0.576991               0.576991             0.0517267
C3          0.557313               0.557313             0.0499626
C5          0.53487                0.53487              0.0479507
C4          0.497448               0.497448             0.0445958
C2          0.430081               0.430081             0.0385564
C1          0.395369               0.395369             0.0354445
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_18

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011805651390659477  0.00031112530268728733  0.0         -0.05973020595254752  0.566943883895874   -0.017313731734954638  0.6088290214538574
    3        26       Softmax                 0.0   0.0   0.002209661323342096   0.0004856003215536475   0.0         0.02442083547961934   0.7407209873199463  -0.545864774472693     0.25129973888397217


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21838293211427176
RMSE: 0.4673145965131752
LogLoss: 0.7370727983028881
Mean Per-Class Error: 0.20272599326787288
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    9.0    1.0    0.0    3.0    4.0    0.0    0.0    1.0    1.0    0.0    4.0    0.0    0.0    5.0    1.0    6.0    2.0    0.09620253164556962  38 / 395
0.0    314.0  0.0    5.0    1.0    1.0    1.0    8.0    2.0    0.0    3.0    0.0    0.0    0.0    2.0    2.0    1.0    30.0   4.0    1.0    0.0    2.0    0.0    2.0    2.0    1.0    0.17801047120418848  68 / 382
0.0    0.0    296.0  0.0    16.0   0.0    10.0   1.0    1.0    0.0    17.0   1.0    0.0    0.0    8.0    0.0    1.0    0.0    1.0    2.0    8.0    0.0    5.0    0.0    1.0    0.0    0.1956521739130435   72 / 368
1.0    13.0   0.0    333.0  0.0    1.0    0.0    8.0    0.0    4.0    0.0    0.0    5.0    6.0    4.0    3.0    0.0    17.0   1.0    0.0    1.0    0.0    0.0    3.0    0.0    3.0    0.17369727047146402  70 / 403
0.0    2.0    4.0    0.0    291.0  1.0    27.0   0.0    1.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    8.0    7.0    2.0    4.0    0.0    0.0    0.0    4.0    1.0    19.0   0.2402088772845953   92 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    7.0    0.0    0.0    2.0    9.0    0.0    0.0    2.0    2.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    2.0    0.0    0.0    12.0   1.0    1.0    1.0    2.0    2.0    8.0    0.0    0.0    0.0    0.0    0.0    10.0   1.0    10.0   2.0    1.0    0.0    0.0    330.0  8.0    3.0    0.16243654822335024  64 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    4.0    3.0    0.0    5.0    4.0    0.0    14.0   0.0    4.0    350.0  0.0    0.10941475826972011  43 / 393
4.0    0.0    0.0    1.0    15.0   0.0    1.0    0.0    1.0    17.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    20.0   4.0    0.0    0.0    0.0    1.0    3.0    293.0  0.2016348773841962   74 / 367
390.0  487.0  345.0  403.0  403.0  355.0  398.0  349.0  342.0  365.0  365.0  343.0  395.0  388.0  399.0  390.0  351.0  446.0  293.0  365.0  387.0  374.0  425.0  419.0  438.0  388.0  0.20173947815655302  2,018 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.798261
2    0.880336
3    0.914226
4    0.936619
5    0.950615
6    0.959712
7    0.96701
8    0.972908
9    0.978107
10   0.982405

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22520061343810055
RMSE: 0.474553067041085
LogLoss: 0.7483250086926079
Mean Per-Class Error: 0.20694044169860693
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   1.0    0.0   0.0   1.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   83.0   0.0   0.0    1.0   1.0   1.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0   9.0    2.0   0.0   0.0   2.0   0.0    1.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    59.0  0.0    4.0   0.0   5.0    0.0   0.0   0.0    4.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0   1.0   1.0   0.0   3.0    0.0    1.0    0.0   0.2804878048780488   23 / 82
1.0   1.0    0.0   92.0   0.0   0.0   0.0    4.0   0.0   1.0    0.0   0.0   2.0   3.0    0.0   1.0    0.0   5.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    1.0   0.17857142857142858  20 / 112
0.0   0.0    0.0   0.0    71.0  1.0   9.0    0.0   1.0   0.0    5.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    0.0   2.0   0.0   0.0   0.0    0.0    0.0    6.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0   3.0    0.0   0.0    1.0   2.0    0.0   0.0   1.0   0.0   83.0   0.0    0.0    0.0   0.09782608695652174  9 / 92
0.0   1.0    0.0   0.0    5.0   0.0   1.0    1.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0   0.0   0.0   0.0   0.0    77.0   4.0    2.0   0.23                 23 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   2.0    1.0   0.0    1.0   1.0   0.0   4.0   0.0    1.0    95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   1.0    3.0   0.0   1.0    0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    6.0   1.0   0.0   0.0   0.0    1.0    2.0    66.0  0.2413793103448276   21 / 87
87.0  120.0  64.0  107.0  96.0  77.0  105.0  99.0  78.0  102.0  96.0  91.0  87.0  103.0  83.0  113.0  87.0  112.0  77.0  85.0  99.0  88.0  106.0  104.0  128.0  96.0  0.20642570281124498  514 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793574
2    0.876305
3    0.909639
4    0.930924
5    0.950602
6    0.959036
7    0.968273
8    0.974297
9    0.979116
10   0.982329
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:39  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:39  37.076 sec  131671 obs/sec    1         1             10007      0.674844         1.3989              0.991906       0.376387                         0.675169           1.38804               0.991877         0.385542
    2019-08-04 09:00:40  37.780 sec  130810 obs/sec    10        10            100070     0.467315         0.737073            0.996119       0.201739                         0.474553           0.748325              0.995987         0.206426
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.100342
C15         0.940335               0.940335             0.0943555
C9          0.78739                0.78739              0.0790086
C12         0.785629               0.785629             0.078832
C8          0.758362               0.758362             0.0760959
C11         0.705789               0.705789             0.0708205
C14         0.640274               0.640274             0.0642466
C7          0.632982               0.632982             0.063515
C10         0.627988               0.627988             0.0630138
C6          0.626248               0.626248             0.0628393
C16         0.490743               0.490743             0.0492423
C4          0.442165               0.442165             0.044368
C3          0.426068               0.426068             0.0427527
C5          0.406964               0.406964             0.0408357
C2          0.371632               0.371632             0.0372904
C1          0.323306               0.323306             0.0324413
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_212

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0014223913460966742  0.0004009178373962641   0.0         -0.02343565562546246   0.7196671962738037  0.043743371043875365  0.7526445388793945
    3        26       Softmax                 0.0   0.0   0.0019767637581585753  0.00031286373268812895  0.0         -0.007233962677184116  0.5019500255584717  -0.4691308568256648   0.2711871862411499


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2172014118664971
RMSE: 0.4660487226315475
LogLoss: 0.7282679580412847
Mean Per-Class Error: 0.21622340210979282
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    5.0    0.0    4.0    0.0    3.0    4.0    4.0    1.0    1.0    0.0    5.0    2.0    4.0    2.0    0.10379746835443038  41 / 395
0.0    303.0  0.0    9.0    3.0    7.0    3.0    9.0    1.0    0.0    2.0    1.0    1.0    0.0    1.0    4.0    0.0    22.0   8.0    1.0    0.0    2.0    1.0    4.0    1.0    0.0    0.20887728459530025  80 / 383
0.0    0.0    296.0  0.0    27.0   2.0    3.0    1.0    0.0    0.0    12.0   0.0    1.0    0.0    8.0    0.0    2.0    0.0    5.0    2.0    5.0    0.0    4.0    0.0    0.0    0.0    0.1956521739130435   72 / 368
5.0    22.0   0.0    319.0  0.0    0.0    0.0    10.0   0.0    6.0    2.0    0.0    5.0    3.0    2.0    4.0    0.0    10.0   3.0    1.0    1.0    0.0    0.0    6.0    0.0    3.0    0.2064676616915423   83 / 402
0.0    13.0   3.0    0.0    276.0  7.0    9.0    2.0    2.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    10.0   3.0    9.0    3.0    0.0    0.0    0.0    12.0   2.0    19.0   0.28125              108 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    3.0    6.0    0.0    0.0    0.0    0.0    9.0    3.0    11.0   0.0    0.0    4.0    0.0    0.0    0.0    4.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    13.0   0.0    5.0    4.0    0.0    2.0    5.0    5.0    3.0    11.0   1.0    0.0    0.0    0.0    1.0    8.0    1.0    6.0    3.0    2.0    0.0    0.0    311.0  11.0   2.0    0.21065989847715735  83 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    4.0    8.0    0.0    3.0    12.0   0.0    33.0   1.0    2.0    319.0  0.0    0.18829516539440203  74 / 393
3.0    5.0    0.0    2.0    12.0   0.0    0.0    0.0    0.0    3.0    1.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    35.0   4.0    0.0    0.0    0.0    1.0    0.0    295.0  0.19398907103825136  71 / 366
405.0  476.0  370.0  438.0  374.0  387.0  317.0  305.0  338.0  343.0  387.0  331.0  417.0  366.0  429.0  402.0  344.0  456.0  368.0  373.0  402.0  381.0  412.0  400.0  405.0  377.0  0.21543536938918326  2,155 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.784565
2    0.882335
3    0.921224
4    0.943117
5    0.956713
6    0.96561
7    0.972008
8    0.977207
9    0.981406
10   0.984904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2212429002082449
RMSE: 0.4703646460016366
LogLoss: 0.7485886065635383
Mean Per-Class Error: 0.22755538466136885
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   2.0    1.0   2.0    1.0   0.10112359550561797  9 / 89
0.0   77.0   0.0   1.0    2.0   2.0   3.0   4.0   0.0   0.0    0.0   0.0   1.0   0.0   1.0   0.0    0.0   8.0    2.0   0.0   0.0    2.0   1.0    2.0   0.0    0.0   0.27358490566037735  29 / 106
0.0   0.0    63.0  0.0    5.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   4.0   0.0    1.0   0.0    1.0   1.0   1.0    0.0   2.0    0.0   0.0    0.0   0.23170731707317074  19 / 82
2.0   2.0    0.0   92.0   0.0   0.0   0.0   5.0   0.0   2.0    0.0   0.0   1.0   1.0   1.0   1.0    0.0   2.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   0.17857142857142858  20 / 112
0.0   3.0    0.0   0.0    63.0  5.0   3.0   0.0   1.0   0.0    5.0   0.0   0.0   0.0   0.0   0.0    3.0   1.0    2.0   1.0   0.0    0.0   0.0    2.0   0.0    8.0   0.35051546391752575  34 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   3.0    0.0   3.0    2.0   0.0   0.0   2.0   1.0   0.0    5.0   1.0   0.0   0.0   0.0   0.0    2.0   1.0    3.0   0.0   1.0    0.0   0.0    71.0  3.0    2.0   0.29                 29 / 100
0.0   0.0    0.0   1.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   2.0    2.0   0.0    0.0   3.0   0.0    12.0  1.0    1.0   82.0   0.0   0.2336448598130841   25 / 107
1.0   0.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0   1.0    1.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    10.0  1.0   0.0    0.0   0.0    0.0   0.0    69.0  0.20689655172413793  18 / 87
96.0  112.0  73.0  128.0  86.0  87.0  81.0  86.0  84.0  101.0  96.0  88.0  91.0  97.0  86.0  115.0  88.0  117.0  94.0  84.0  102.0  92.0  104.0  94.0  110.0  98.0  0.22690763052208834  565 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773092
2    0.873494
3    0.917269
4    0.936145
5    0.95261
6    0.961044
7    0.967871
8    0.973896
9    0.979518
10   0.983133
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:15  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:15  6 min 13.038 sec  76976 obs/sec     1         1             10007      0.611038         1.1727              0.993364       0.325502                         0.609497           1.17128               0.993381         0.328112
    2019-08-04 09:06:16  6 min 14.197 sec  79231 obs/sec     10        10            100070     0.466049         0.728268            0.996139       0.215435                         0.470365           0.748589              0.996058         0.226908
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0883091
C13         0.991437               0.991437             0.087553
C12         0.894792               0.894792             0.0790184
C9          0.837924               0.837924             0.0739963
C8          0.812082               0.812082             0.0717142
C11         0.79037                0.79037              0.0697969
C7          0.748087               0.748087             0.066063
C14         0.684663               0.684663             0.060462
C10         0.676274               0.676274             0.0597211
C6          0.664006               0.664006             0.0586378
C16         0.632364               0.632364             0.0558436
C3          0.587054               0.587054             0.0518422
C5          0.581734               0.581734             0.0513725
C4          0.540869               0.540869             0.0477637
C2          0.441953               0.441953             0.0390285
C1          0.440246               0.440246             0.0388778
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_39

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011762502469423453  0.00032140896655619144  0.0         -0.011688021531426784  0.5821154117584229  -0.08369945867414243  0.730924129486084
    3        26       Softmax                 0.0   0.0   0.002269864341472455   0.0005413985345512629   0.0         -0.03131085185892656   0.7320294380187988  -0.5162265663324818   0.21481120586395264


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21972222130820634
RMSE: 0.46874536937254785
LogLoss: 0.7453367292779158
Mean Per-Class Error: 0.2075782754563504
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    2.0    0.0    0.0    2.0    0.0    1.0    8.0    3.0    0.0    10.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    2.0    0.0    6.0    0.0    5.0    0.0    0.10632911392405063  42 / 395
0.0    315.0  0.0    8.0    5.0    3.0    2.0    3.0    2.0    1.0    1.0    0.0    1.0    0.0    0.0    2.0    2.0    23.0   8.0    0.0    0.0    2.0    1.0    2.0    1.0    1.0    0.17754569190600522  68 / 383
0.0    0.0    295.0  0.0    7.0    0.0    20.0   1.0    0.0    0.0    29.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    5.0    0.0    5.0    0.0    1.0    1.0    0.0    0.0    0.1983695652173913   73 / 368
2.0    13.0   0.0    316.0  0.0    3.0    0.0    7.0    0.0    5.0    1.0    0.0    8.0    5.0    5.0    3.0    2.0    11.0   1.0    1.0    3.0    0.0    0.0    6.0    0.0    11.0   0.21588089330024815  87 / 403
0.0    11.0   1.0    0.0    292.0  2.0    26.0   0.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    2.0    5.0    20.0   3.0    0.0    0.0    0.0    5.0    0.0    12.0   0.23958333333333334  92 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    10.0   0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    0.0    16.0   3.0    1.0    0.0    3.0    1.0    0.0    0.0    3.0    3.0    327.0  0.0    0.0    0.0    0.13031914893617022  49 / 376
0.0    2.0    0.0    1.0    7.0    0.0    0.0    9.0    2.0    1.0    11.0   2.0    0.0    0.0    2.0    0.0    5.0    3.0    2.0    10.0   0.0    1.0    0.0    330.0  0.0    6.0    0.16243654822335024  64 / 394
1.0    0.0    0.0    3.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    6.0    11.0   0.0    0.0    30.0   2.0    40.0   0.0    0.0    290.0  0.0    0.2602040816326531   102 / 392
2.0    1.0    0.0    0.0    12.0   1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    38.0   6.0    0.0    0.0    0.0    0.0    4.0    287.0  0.21798365122615804  80 / 367
416.0  475.0  342.0  410.0  371.0  385.0  370.0  323.0  334.0  372.0  418.0  343.0  438.0  352.0  383.0  366.0  357.0  435.0  398.0  364.0  404.0  422.0  399.0  400.0  352.0  374.0  0.2069379186244127   2,070 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793062
2    0.879236
3    0.912826
4    0.93442
5    0.949315
6    0.962211
7    0.970309
8    0.975907
9    0.980106
10   0.985104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2195234194992285
RMSE: 0.468533264026396
LogLoss: 0.749323455185967
Mean Per-Class Error: 0.21130854366803042
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20     21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  ----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   0.0   0.0   0.0    1.0   0.0    1.0    0.0   0.0    0.0   3.0    0.0   2.0   0.0   0.11235955056179775  10 / 89
0.0   83.0   0.0   2.0    0.0   0.0   2.0   2.0   1.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0   6.0    3.0    0.0   0.0    2.0   1.0    1.0   1.0   0.0   0.2169811320754717   23 / 106
0.0   0.0    62.0  0.0    1.0   0.0   4.0   0.0   0.0   0.0    9.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0    2.0    0.0   1.0    0.0   1.0    0.0   0.0   0.0   0.24390243902439024  20 / 82
2.0   2.0    0.0   90.0   0.0   1.0   0.0   3.0   0.0   2.0    1.0    0.0   3.0   0.0   2.0   1.0    1.0   1.0    0.0    0.0   0.0    0.0   0.0    2.0   0.0   1.0   0.19642857142857142  22 / 112
0.0   4.0    0.0   0.0    70.0  1.0   8.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    5.0    1.0   0.0    0.0   0.0    0.0   0.0   6.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---   ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   2.0   1.0   0.0   0.0    2.0   0.0    0.0    0.0   1.0    0.0   83.0   0.0   0.0   0.0   0.09782608695652174  9 / 92
0.0   0.0    0.0   1.0    3.0   0.0   0.0   3.0   1.0   0.0    5.0    1.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    1.0   0.0    0.0   0.0    81.0  0.0   3.0   0.19                 19 / 100
0.0   0.0    0.0   1.0    0.0   5.0   1.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    4.0   0.0    0.0    8.0   1.0    11.0  0.0    0.0   75.0  0.0   0.29906542056074764  32 / 107
0.0   0.0    0.0   0.0    5.0   1.0   0.0   0.0   0.0   5.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    8.0    2.0   0.0    0.0   0.0    0.0   0.0   66.0  0.2413793103448276   21 / 87
94.0  125.0  71.0  120.0  84.0  98.0  96.0  75.0  80.0  104.0  109.0  93.0  94.0  97.0  81.0  103.0  95.0  106.0  100.0  84.0  101.0  97.0  101.0  95.0  97.0  90.0  0.21204819277108433  528 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787952
2    0.881526
3    0.913655
4    0.933333
5    0.948996
6    0.961847
7    0.969478
8    0.974297
9    0.978313
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:11  1 min  9.015 sec  113715 obs/sec    1         1             10007      0.660664         1.36266             0.992244       0.373488                         0.656883           1.34436               0.992311         0.371486
    2019-08-04 09:01:11  1 min  9.720 sec  128624 obs/sec    10        10            100070     0.468745         0.745337            0.996096       0.206938                         0.468533           0.749323              0.996088         0.212048
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.103745
C13         0.890678               0.890678             0.0924035
C12         0.784639               0.784639             0.0814024
C8          0.780005               0.780005             0.0809217
C11         0.688303               0.688303             0.0714081
C9          0.683977               0.683977             0.0709593
C7          0.682225               0.682225             0.0707775
C10         0.626403               0.626403             0.0649863
C16         0.605974               0.605974             0.0628669
C14         0.599818               0.599818             0.0622282
C6          0.543149               0.543149             0.0563491
C5          0.487332               0.487332             0.0505583
C3          0.403795               0.403795             0.0418917
C4          0.395028               0.395028             0.0409823
C1          0.250612               0.250612             0.0259997
C2          0.217069               0.217069             0.0225198
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_152

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0012022882234532517  0.0003516384167596698  0.0         0.031547772129371765  0.551659107208252   -0.001148675844468837  0.5923612117767334
    3        26       Softmax                 0.0   0.0   0.002311488327485187   0.0005818125791847706  0.0         0.001997268754866337  0.7049484252929688  -0.525038319353959     0.2720637321472168


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21858832590721083
RMSE: 0.4675343045245031
LogLoss: 0.7379138845850078
Mean Per-Class Error: 0.2050386170844414
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  1.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    4.0    3.0    0.0    9.0    0.0    4.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    5.0    0.0    4.0    0.0    0.10886075949367088  43 / 395
0.0    296.0  0.0    13.0   2.0    1.0    1.0    8.0    4.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    7.0    28.0   13.0   0.0    0.0    1.0    3.0    1.0    1.0    0.0    0.22715404699738903  87 / 383
0.0    0.0    294.0  0.0    12.0   3.0    15.0   2.0    0.0    0.0    11.0   0.0    0.0    0.0    2.0    1.0    3.0    0.0    13.0   5.0    4.0    0.0    3.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
1.0    18.0   0.0    324.0  0.0    2.0    0.0    11.0   0.0    7.0    1.0    0.0    8.0    4.0    5.0    2.0    3.0    7.0    2.0    1.0    1.0    0.0    0.0    5.0    0.0    1.0    0.19602977667493796  79 / 403
0.0    9.0    1.0    0.0    308.0  3.0    15.0   1.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    4.0    5.0    16.0   1.0    1.0    0.0    0.0    3.0    0.0    12.0   0.19791666666666666  76 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    5.0    4.0    1.0    0.0    0.0    3.0    0.0    0.0    1.0    3.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    7.0    0.0    7.0    9.0    2.0    0.0    2.0    2.0    2.0    12.0   3.0    0.0    0.0    2.0    1.0    5.0    2.0    6.0    2.0    1.0    0.0    0.0    317.0  5.0    5.0    0.1913265306122449   75 / 392
0.0    0.0    0.0    3.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    6.0    19.0   0.0    16.0   1.0    0.0    337.0  0.0    0.14249363867684478  56 / 393
2.0    0.0    0.0    1.0    13.0   0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    10.0   0.0    39.0   4.0    0.0    0.0    0.0    1.0    0.0    282.0  0.23160762942779292  85 / 367
409.0  457.0  337.0  450.0  405.0  361.0  341.0  305.0  336.0  366.0  377.0  342.0  425.0  367.0  402.0  396.0  378.0  437.0  356.0  406.0  396.0  363.0  445.0  396.0  382.0  368.0  0.20383884834549634  2,039 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796161
2    0.880836
3    0.916325
4    0.937419
5    0.953114
6    0.964411
7    0.972108
8    0.977707
9    0.982005
10   0.986104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2205416048031797
RMSE: 0.4696185737416906
LogLoss: 0.7526845930665388
Mean Per-Class Error: 0.20766011610391655
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   3.0    0.0    2.0    0.0   0.10112359550561797  9 / 89
0.0   75.0   0.0   3.0    2.0   0.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    2.0    11.0   4.0   0.0   0.0    0.0   2.0    1.0    1.0    0.0   0.29245283018867924  31 / 106
0.0   0.0    60.0  0.0    2.0   0.0   7.0   0.0   0.0   0.0    2.0   0.0   0.0    0.0   2.0   0.0    1.0    0.0    4.0   2.0   1.0    0.0   1.0    0.0    0.0    0.0   0.2682926829268293   22 / 82
0.0   4.0    0.0   93.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   2.0    1.0   1.0   2.0    2.0    2.0    1.0   0.0   1.0    0.0   0.0    1.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   1.0    1.0   0.0    75.0  1.0   3.0   0.0   1.0   0.0    2.0   0.0   0.0    0.0   0.0   0.0    1.0    1.0    6.0   1.0   0.0    0.0   0.0    1.0    0.0    3.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   4.0    0.0   1.0    3.0   0.0   0.0   1.0   0.0   0.0    4.0   1.0   0.0    0.0   0.0   0.0    1.0    0.0    1.0   0.0   0.0    0.0   0.0    80.0   3.0    1.0   0.2                  20 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0    1.0   4.0   0.0    4.0   1.0    0.0    93.0   0.0   0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0    0.0   0.0   0.0    2.0    0.0    10.0  1.0   0.0    0.0   0.0    0.0    0.0    64.0  0.26436781609195403  23 / 87
96.0  110.0  66.0  131.0  96.0  81.0  87.0  81.0  80.0  105.0  98.0  89.0  101.0  95.0  73.0  116.0  103.0  106.0  88.0  93.0  104.0  78.0  114.0  101.0  111.0  87.0  0.20602409638554217  513 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793976
2    0.876707
3    0.912851
4    0.93494
5    0.950602
6    0.961446
7    0.970281
8    0.977108
9    0.981928
10   0.985944
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:18  4 min 16.187 sec  122036 obs/sec    1         1             10007      0.654298         1.31326             0.992392       0.354594                         0.650951           1.30287               0.99245          0.351004
    2019-08-04 09:04:19  4 min 16.919 sec  125716 obs/sec    10        10            100070     0.467534         0.737914            0.996115       0.203839                         0.469619           0.752685              0.99607          0.206024
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0864861
C15         0.999385               0.999385             0.0864329
C9          0.948212               0.948212             0.0820072
C7          0.88686                0.88686              0.0767011
C12         0.881516               0.881516             0.0762388
C11         0.881446               0.881446             0.0762328
C8          0.877537               0.877537             0.0758947
C10         0.708001               0.708001             0.0612322
C6          0.704942               0.704942             0.0609677
C14         0.688152               0.688152             0.0595156
C16         0.643758               0.643758             0.0556761
C5          0.634211               0.634211             0.0548505
C4          0.521968               0.521968             0.045143
C3          0.507536               0.507536             0.0438948
C2          0.353149               0.353149             0.0305425
C1          0.325879               0.325879             0.028184
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_215

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007525210367020918  0.0001900866045616567  0.0         -0.018901012660734295  0.2815331220626831  0.21206547984407167   0.2188044786453247
    3        26       Softmax                      0.0   0.0   0.0050630550105709585  0.017856508493423462   0.0         -0.4342673638908799    0.8707919120788574  -0.46276922990460545  0.37944889068603516


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.23159788127911934
RMSE: 0.48124617533973124
LogLoss: 0.7455676454960692
Mean Per-Class Error: 0.21259698526453039
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    9.0    5.0    1.0    2.0    0.0    0.0    0.0    0.0    4.0    4.0    0.0    1.0    2.0    1.0    6.0    4.0    1.0    0.11645569620253164  46 / 395
0.0    304.0  0.0    9.0    3.0    0.0    6.0    5.0    4.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    3.0    20.0   20.0   0.0    0.0    0.0    1.0    1.0    2.0    0.0    0.206266318537859    79 / 383
0.0    0.0    291.0  0.0    5.0    0.0    24.0   1.0    0.0    0.0    20.0   1.0    1.0    0.0    6.0    1.0    0.0    0.0    6.0    4.0    6.0    0.0    1.0    1.0    0.0    0.0    0.20923913043478262  77 / 368
3.0    30.0   0.0    328.0  0.0    0.0    1.0    3.0    1.0    4.0    0.0    0.0    6.0    6.0    2.0    0.0    0.0    10.0   1.0    3.0    1.0    0.0    0.0    4.0    0.0    0.0    0.18610421836228289  75 / 403
0.0    5.0    4.0    0.0    318.0  5.0    10.0   0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    12.0   6.0    7.0    2.0    0.0    0.0    0.0    2.0    0.0    10.0   0.16971279373368145  65 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    1.0    0.0    20.0   0.0    1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    5.0    0.0    6.0    8.0    0.0    0.0    2.0    3.0    3.0    4.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    3.0    8.0    5.0    0.0    0.0    335.0  2.0    2.0    0.14974619289340102  59 / 394
0.0    0.0    0.0    1.0    0.0    6.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    10.0   0.0    4.0    25.0   2.0    18.0   1.0    0.0    319.0  0.0    0.18829516539440203  74 / 393
0.0    1.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    26.0   3.0    0.0    0.0    0.0    4.0    1.0    298.0  0.1880108991825613   69 / 367
390.0  464.0  348.0  432.0  440.0  349.0  363.0  338.0  354.0  376.0  364.0  345.0  425.0  368.0  398.0  360.0  367.0  466.0  322.0  398.0  401.0  362.0  386.0  410.0  391.0  386.0  0.21163650904728581  2,117 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788363
2    0.879236
3    0.911527
4    0.93492
5    0.949315
6    0.960312
7    0.968509
8    0.975507
9    0.981206
10   0.985704

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.23377610553103298
RMSE: 0.4835039870890756
LogLoss: 0.7545946676604666
Mean Per-Class Error: 0.21621314053909432
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22    23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  ----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   1.0    1.0   0.0   2.0    2.0    0.0    0.0898876404494382   8 / 89
0.0   76.0   0.0   1.0    2.0   0.0   1.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0   1.0   2.0    3.0    7.0    7.0   0.0   0.0    0.0   1.0   1.0    1.0    0.0    0.2830188679245283   30 / 106
0.0   0.0    59.0  0.0    0.0   0.0   7.0   1.0   0.0   0.0    5.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    3.0   2.0   3.0    0.0   0.0   0.0    0.0    0.0    0.2804878048780488   23 / 82
2.0   6.0    0.0   95.0   0.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0   2.0   1.0   0.0   0.0    0.0    1.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    0.0    0.15178571428571427  17 / 112
0.0   1.0    1.0   0.0    72.0  3.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    4.0    2.0    3.0   1.0   0.0    0.0   0.0   1.0    0.0    6.0    0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---   ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   85.0  0.0    0.0    0.0    0.07608695652173914  7 / 92
0.0   2.0    0.0   2.0    4.0   0.0   0.0   2.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0    0.0   2.0   1.0    0.0   0.0   83.0   0.0    1.0    0.17                 17 / 100
0.0   0.0    0.0   1.0    0.0   1.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   3.0    4.0    0.0    0.0   6.0   0.0    6.0   1.0   0.0    84.0   0.0    0.21495327102803738  23 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    2.0   1.0   0.0    0.0   0.0   3.0    1.0    73.0   0.16091954022988506  14 / 87
93.0  117.0  69.0  125.0  99.0  74.0  88.0  85.0  83.0  103.0  96.0  91.0  88.0  99.0  81.0  107.0  100.0  115.0  78.0  98.0  103.0  83.0  97.0  106.0  110.0  102.0  0.21485943775100402  535 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785141
2    0.880321
3    0.913655
4    0.932129
5    0.946586
6    0.958233
7    0.96506
8    0.96988
9    0.975904
10   0.982329
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:18  6 min 16.202 sec  175561 obs/sec    1         1             10007      0.71492          1.54034             0.990919       0.408577                         0.713586           1.53644               0.990927         0.41004
    2019-08-04 09:06:18  6 min 16.686 sec  189526 obs/sec    10        10            100070     0.481246         0.745568            0.995885       0.211637                         0.483504           0.754595              0.995834         0.214859
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0961151
C13         0.990501               0.990501             0.0952021
C9          0.733116               0.733116             0.0704636
C8          0.733007               0.733007             0.0704531
C12         0.724101               0.724101             0.069597
C5          0.705596               0.705596             0.0678184
C11         0.694745               0.694745             0.0667755
C7          0.672305               0.672305             0.0646187
C6          0.639482               0.639482             0.0614639
C3          0.591908               0.591908             0.0568913
C14         0.577102               0.577102             0.0554683
C10         0.56444                0.56444              0.0542513
C4          0.515673               0.515673             0.049564
C16         0.484106               0.484106             0.0465299
C1          0.402158               0.402158             0.0386535
C2          0.37595                0.37595              0.0361344
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_30

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015583557570835183  0.00032522575929760933  0.0         0.02580556894307051   0.7544167041778564  -0.00142261642942028  0.6801843643188477
    3        26       Softmax                 0.0   0.0   0.001802311426707512   0.00024555285926908255  0.0         0.008362173625895454  0.3847922086715698  -0.5481883103250889   0.3064150810241699


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21499808925400687
RMSE: 0.4636788643598141
LogLoss: 0.7373174784297931
Mean Per-Class Error: 0.20746615639190977
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    8.0    0.0    4.0    0.0    0.0    2.0    7.0    1.0    0.0    0.0    2.0    3.0    7.0    0.0    0.09873417721518987  39 / 395
0.0    321.0  0.0    4.0    2.0    1.0    4.0    3.0    3.0    1.0    1.0    0.0    2.0    0.0    1.0    4.0    0.0    27.0   3.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.1618798955613577   62 / 383
0.0    1.0    289.0  0.0    14.0   1.0    24.0   1.0    0.0    0.0    16.0   0.0    1.0    0.0    2.0    0.0    2.0    0.0    9.0    1.0    2.0    0.0    5.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
5.0    25.0   0.0    326.0  0.0    1.0    0.0    6.0    0.0    3.0    1.0    0.0    6.0    6.0    1.0    3.0    0.0    10.0   3.0    0.0    1.0    0.0    0.0    5.0    0.0    1.0    0.19106699751861042  77 / 403
0.0    6.0    2.0    0.0    288.0  7.0    13.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    13.0   6.0    12.0   10.0   0.0    0.0    0.0    10.0   0.0    14.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    9.0    0.0    0.0    5.0    0.0    12.0   0.0    4.0    0.0    0.0    3.0    0.0    0.0    2.0    6.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    4.0    0.0    5.0    7.0    1.0    0.0    0.0    8.0    0.0    6.0    0.0    0.0    0.0    2.0    0.0    8.0    4.0    6.0    10.0   0.0    0.0    0.0    324.0  4.0    5.0    0.17766497461928935  70 / 394
0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    11.0   0.0    2.0    12.0   4.0    41.0   1.0    0.0    308.0  0.0    0.21628498727735368  85 / 393
0.0    0.0    0.0    1.0    10.0   0.0    1.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    30.0   5.0    0.0    0.0    0.0    6.0    0.0    302.0  0.1771117166212534   65 / 367
408.0  507.0  338.0  432.0  366.0  373.0  373.0  283.0  330.0  360.0  397.0  337.0  464.0  395.0  388.0  368.0  374.0  440.0  339.0  389.0  373.0  412.0  397.0  429.0  377.0  354.0  0.20653803858842348  2,066 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793462
2    0.877837
3    0.916425
4    0.937619
5    0.952814
6    0.964411
7    0.971309
8    0.977207
9    0.981805
10   0.986304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2213737577587019
RMSE: 0.4705037276777963
LogLoss: 0.7568205296514607
Mean Per-Class Error: 0.2207704677140385
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13     14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0    0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    2.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   83.0   0.0   1.0    1.0   0.0   2.0   2.0   1.0   0.0    0.0    0.0   0.0    0.0    1.0   1.0    0.0    9.0    1.0   0.0   0.0    2.0   0.0    2.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    57.0  0.0    5.0   0.0   7.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0    2.0   0.0    1.0    0.0    4.0   0.0   1.0    0.0   2.0    0.0    0.0    0.0   0.3048780487804878   25 / 82
3.0   3.0    0.0   91.0   0.0   0.0   0.0   3.0   0.0   0.0    1.0    0.0   2.0    2.0    0.0   1.0    0.0    3.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0   0.1875               21 / 112
0.0   2.0    0.0   0.0    69.0  3.0   4.0   0.0   0.0   0.0    0.0    1.0   0.0    0.0    0.0   0.0    4.0    2.0    2.0   4.0   0.0    0.0   0.0    3.0    0.0    3.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0    0.0   3.0    0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0    1.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   2.0    4.0   0.0   0.0   0.0   3.0   0.0    4.0    0.0   0.0    0.0    0.0   0.0    2.0    2.0    2.0   1.0   0.0    0.0   0.0    75.0   2.0    2.0   0.25                 25 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   1.0    5.0    0.0    0.0   3.0   3.0    15.0  1.0    0.0    76.0   0.0   0.2897196261682243   31 / 107
0.0   0.0    0.0   1.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0    0.0   0.0    1.0    0.0    7.0   2.0   0.0    0.0   0.0    1.0    0.0    69.0  0.20689655172413793  18 / 87
97.0  127.0  68.0  122.0  92.0  86.0  91.0  75.0  79.0  104.0  100.0  91.0  102.0  104.0  80.0  104.0  101.0  105.0  84.0  89.0  100.0  99.0  104.0  100.0  101.0  85.0  0.22048192771084338  549 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779518
2    0.87751
3    0.914859
4    0.936145
5    0.949799
6    0.963052
7    0.969478
8    0.976707
9    0.982329
10   0.986747
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:59  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:59  57.128 sec  52947 obs/sec     1         1             10007      0.585284         1.10665             0.993914       0.295911                         0.587889           1.11557               0.993842         0.299598
    2019-08-04 09:01:01  58.859 sec  53115 obs/sec     10        10            100070     0.463679         0.737317            0.99618        0.206538                         0.470504           0.756821              0.996055         0.220482
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0859977
C15         0.99746                0.99746              0.0857793
C13         0.964544               0.964544             0.0829486
C12         0.929122               0.929122             0.0799023
C7          0.865172               0.865172             0.0744028
C11         0.847028               0.847028             0.0728424
C8          0.809732               0.809732             0.0696351
C14         0.713094               0.713094             0.0613245
C6          0.677053               0.677053             0.058225
C10         0.664859               0.664859             0.0571764
C16         0.597995               0.597995             0.0514262
C3          0.591855               0.591855             0.0508982
C5          0.565988               0.565988             0.0486737
C4          0.551973               0.551973             0.0474684
C2          0.462865               0.462865             0.0398053
C1          0.389476               0.389476             0.033494
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_195

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011627526837969526  0.00030865916050970554  0.0         0.018943460351579233   0.5695028305053711  0.1079731651184133   0.6387789249420166
    3        26       Softmax                 0.0   0.0   0.002231315479478396   0.0005485550500452518   0.0         -0.001274173004416158  0.7364623546600342  -0.5493512126661041  0.27745485305786133


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22275780642655457
RMSE: 0.47197225175486174
LogLoss: 0.742256376544365
Mean Per-Class Error: 0.20830441020112347
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    3.0    0.0    0.0    0.0    2.0    0.0    5.0    9.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    3.0    4.0    1.0    1.0    1.0    1.0    8.0    3.0    0.11139240506329114  44 / 395
0.0    310.0  5.0    7.0    3.0    1.0    3.0    8.0    2.0    0.0    3.0    0.0    1.0    0.0    0.0    4.0    3.0    17.0   10.0   1.0    1.0    2.0    0.0    2.0    0.0    0.0    0.1906005221932115   73 / 383
0.0    0.0    283.0  0.0    14.0   0.0    24.0   1.0    0.0    0.0    25.0   0.0    1.0    0.0    10.0   2.0    1.0    0.0    2.0    3.0    1.0    1.0    0.0    0.0    0.0    0.0    0.23097826086956522  85 / 368
7.0    22.0   0.0    314.0  2.0    1.0    0.0    1.0    0.0    3.0    3.0    0.0    1.0    11.0   7.0    3.0    1.0    13.0   2.0    0.0    3.0    0.0    0.0    6.0    0.0    3.0    0.22084367245657568  89 / 403
0.0    5.0    2.0    0.0    295.0  12.0   6.0    2.0    2.0    0.0    4.0    5.0    0.0    0.0    1.0    0.0    7.0    5.0    4.0    7.0    0.0    0.0    0.0    6.0    0.0    21.0   0.23177083333333334  89 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    14.0   3.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    6.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    3.0    0.0    5.0    8.0    2.0    15.0   3.0    3.0    1.0    9.0    5.0    0.0    0.0    2.0    0.0    5.0    5.0    4.0    1.0    1.0    1.0    0.0    310.0  7.0    4.0    0.2131979695431472   84 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    9.0    0.0    1.0    32.0   4.0    19.0   3.0    1.0    306.0  0.0    0.22137404580152673  87 / 393
0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    16.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    25.0   4.0    0.0    0.0    0.0    1.0    0.0    311.0  0.15258855585831063  56 / 367
393.0  517.0  320.0  412.0  385.0  371.0  380.0  316.0  334.0  377.0  403.0  350.0  411.0  392.0  382.0  401.0  376.0  389.0  293.0  432.0  393.0  395.0  403.0  404.0  368.0  406.0  0.20743776866939917  2,075 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792562
2    0.878636
3    0.913726
4    0.936719
5    0.951515
6    0.961512
7    0.970009
8    0.976207
9    0.980706
10   0.985305

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22737868037178438
RMSE: 0.4768424062222071
LogLoss: 0.7570810398596839
Mean Per-Class Error: 0.21115631192155032
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0    4.0   0.0   0.10112359550561797  9 / 89
0.0   84.0   1.0   1.0    1.0   0.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   8.0    1.0   0.0   1.0    2.0   0.0    1.0    0.0   0.0   0.20754716981132076  22 / 106
0.0   0.0    58.0  0.0    2.0   0.0   9.0   0.0   0.0   0.0    7.0   0.0   0.0   0.0    4.0   1.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0    0.0    0.0   0.0   0.2926829268292683   24 / 82
3.0   6.0    0.0   93.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   3.0    1.0   2.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    1.0    0.0   0.0   0.16964285714285715  19 / 112
0.0   2.0    1.0   0.0    71.0  5.0   1.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    1.0   0.0    1.0   2.0    3.0   3.0   0.0    0.0   0.0    2.0    0.0   4.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---   ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   85.0   0.0    0.0   0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    1.0   1.0   4.0   2.0   0.0   0.0    3.0   3.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0    79.0   1.0   1.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   2.0    4.0   0.0    0.0   10.0  2.0    6.0   2.0    0.0    79.0  0.0   0.2616822429906542   28 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0   1.0   0.0    0.0   0.0    0.0    0.0   73.0  0.16091954022988506  14 / 87
90.0  138.0  65.0  116.0  88.0  82.0  99.0  80.0  80.0  110.0  95.0  94.0  84.0  103.0  80.0  119.0  95.0  100.0  78.0  98.0  103.0  91.0  109.0  100.0  99.0  94.0  0.21004016064257028  523 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.78996
2    0.87751
3    0.91245
4    0.936948
5    0.947791
6    0.956225
7    0.964257
8    0.971084
9    0.975904
10   0.983534
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:45  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:46  5 min 43.808 sec  133426 obs/sec    1         1             10007      0.67768          1.4296              0.99184        0.383485                         0.678786           1.43068               0.99179          0.38755
    2019-08-04 09:05:46  5 min 44.501 sec  132895 obs/sec    10        10            100070     0.471972         0.742256            0.996042       0.207438                         0.476842           0.757081              0.995948         0.21004
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0956503
C13         0.940831               0.940831             0.0899908
C12         0.847644               0.847644             0.0810774
C9          0.835227               0.835227             0.0798897
C8          0.800584               0.800584             0.0765761
C11         0.720074               0.720074             0.0688753
C10         0.67738                0.67738              0.0647916
C7          0.67535                0.67535              0.0645974
C14         0.626392               0.626392             0.0599146
C6          0.620044               0.620044             0.0593074
C16         0.580273               0.580273             0.0555033
C5          0.552539               0.552539             0.0528505
C4          0.487383               0.487383             0.0466184
C3          0.470911               0.470911             0.0450428
C2          0.338423               0.338423             0.0323703
C1          0.281692               0.281692             0.0269439
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_37

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.001532731326932435   0.0003450615331530571   0.0         -0.012747337495440547  0.7677211761474609  0.0717358971535339   0.7387185096740723
    3        26       Softmax                 0.0   0.0   0.0018466828612942593  0.00026064179837703705  0.0         0.002176080829938288   0.3847017288208008  -0.5555636437617693  0.2549546957015991


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21581882690287166
RMSE: 0.46456304943771803
LogLoss: 0.733496365239172
Mean Per-Class Error: 0.21282697578922566
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    10.0   0.0    0.0    0.0    2.0    0.0    7.0    3.0    1.0    0.0    2.0    3.0    6.0    0.0    0.09873417721518987  39 / 395
0.0    315.0  0.0    4.0    4.0    2.0    1.0    6.0    6.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    1.0    27.0   4.0    0.0    0.0    6.0    0.0    2.0    1.0    0.0    0.17754569190600522  68 / 383
0.0    0.0    288.0  0.0    8.0    3.0    17.0   1.0    0.0    0.0    26.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    8.0    5.0    5.0    0.0    4.0    0.0    0.0    0.0    0.21739130434782608  80 / 368
6.0    21.0   0.0    331.0  0.0    2.0    0.0    1.0    0.0    3.0    1.0    1.0    7.0    5.0    3.0    1.0    0.0    11.0   1.0    0.0    1.0    0.0    0.0    6.0    0.0    2.0    0.17866004962779156  72 / 403
0.0    8.0    1.0    0.0    283.0  6.0    13.0   0.0    1.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    13.0   5.0    10.0   6.0    0.0    0.0    0.0    6.0    1.0    23.0   0.26109660574412535  100 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    0.0    1.0    0.0    16.0   0.0    1.0    0.0    0.0    2.0    0.0    0.0    1.0    4.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    3.0    0.0    9.0    9.0    2.0    0.0    1.0    6.0    2.0    8.0    5.0    0.0    0.0    2.0    0.0    10.0   2.0    7.0    3.0    3.0    0.0    0.0    313.0  5.0    4.0    0.20558375634517767  81 / 394
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    1.0    7.0    0.0    2.0    25.0   1.0    34.0   2.0    0.0    312.0  0.0    0.20610687022900764  81 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    8.0    1.0    39.0   6.0    0.0    0.0    0.0    2.0    0.0    294.0  0.1989100817438692   73 / 367
409.0  488.0  337.0  440.0  367.0  376.0  318.0  295.0  343.0  341.0  403.0  353.0  460.0  358.0  392.0  367.0  388.0  463.0  361.0  392.0  397.0  404.0  404.0  381.0  395.0  371.0  0.2119364190742777   2,120 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788064
2    0.877037
3    0.918125
4    0.938518
5    0.953714
6    0.963411
7    0.972208
8    0.977607
9    0.981805
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2221490360869782
RMSE: 0.4713268887799403
LogLoss: 0.7581873624634196
Mean Per-Class Error: 0.22477329853878053
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    2.0   3.0    0.0   0.11235955056179775  10 / 89
0.0   75.0   0.0   1.0    2.0   0.0   1.0   1.0   2.0   0.0   1.0    0.0   1.0    0.0   0.0   0.0    1.0   13.0   3.0   0.0   0.0    4.0   0.0    1.0   0.0    0.0   0.29245283018867924  31 / 106
0.0   0.0    59.0  0.0    2.0   0.0   7.0   0.0   0.0   0.0   7.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0   0.2804878048780488   23 / 82
3.0   4.0    0.0   93.0   0.0   1.0   0.0   1.0   0.0   0.0   1.0    1.0   3.0    1.0   1.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.16964285714285715  19 / 112
0.0   1.0    1.0   0.0    66.0  4.0   3.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    4.0   1.0    2.0   3.0   0.0    0.0   0.0    1.0   0.0    9.0   0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0   0.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   5.0    4.0   1.0   0.0   1.0   2.0   0.0   5.0    2.0   0.0    0.0   0.0   0.0    3.0   0.0    2.0   0.0   0.0    0.0   0.0    73.0  0.0    2.0   0.27                 27 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   1.0    1.0   0.0    0.0   7.0   1.0    12.0  1.0    0.0   81.0   0.0   0.24299065420560748  26 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0    8.0   2.0   0.0    0.0   0.0    1.0   0.0    67.0  0.22988505747126436  20 / 87
96.0  109.0  72.0  131.0  88.0  89.0  80.0  77.0  80.0  97.0  105.0  93.0  105.0  98.0  76.0  102.0  98.0  124.0  88.0  97.0  101.0  95.0  101.0  89.0  105.0  94.0  0.2248995983935743   560 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.7751
2    0.871486
3    0.912851
4    0.934137
5    0.951004
6    0.960241
7    0.969076
8    0.974699
9    0.979116
10   0.98514
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:07  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:08  1 min  5.816 sec  51849 obs/sec     1         1             10007      0.585066         1.09799             0.993917       0.298311                         0.584363           1.09506               0.993915         0.293976
    2019-08-04 09:01:09  1 min  7.521 sec  53714 obs/sec     10        10            100070     0.464563         0.733496            0.996165       0.211936                         0.471327           0.758187              0.996042         0.2249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0866176
C13         0.958616               0.958616             0.083033
C12         0.929188               0.929188             0.0804841
C9          0.88894                0.88894              0.0769978
C7          0.823462               0.823462             0.0713263
C11         0.812062               0.812062             0.0703389
C8          0.795172               0.795172             0.0688759
C10         0.759969               0.759969             0.0658267
C14         0.736186               0.736186             0.0637667
C6          0.604358               0.604358             0.0523481
C16         0.598612               0.598612             0.0518504
C3          0.590338               0.590338             0.0511336
C4          0.58825                0.58825              0.0509528
C5          0.568998               0.568998             0.0492853
C2          0.456382               0.456382             0.0395307
C1          0.434463               0.434463             0.0376321
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_63

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007665937498586572  0.00017227017087861896  0.0         -0.007678973554789081  0.2819126844406128  0.22497015678099977  0.18998992443084717
    3        26       Softmax                      0.0   0.0   0.0055712289630229445  0.016411811113357544    0.0         -0.3781989936989983    0.8838796615600586  -0.4582868125233024  0.3452897071838379


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22697157320480008
RMSE: 0.4764153368698368
LogLoss: 0.7498622692773614
Mean Per-Class Error: 0.21285288121175658
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    3.0    0.0    0.0    1.0    3.0    0.0    9.0    3.0    0.0    6.0    0.0    0.0    0.0    3.0    1.0    3.0    0.0    1.0    0.0    2.0    1.0    4.0    0.0    0.10126582278481013  40 / 395
0.0    314.0  0.0    5.0    0.0    1.0    1.0    13.0   0.0    0.0    7.0    1.0    1.0    0.0    1.0    2.0    0.0    21.0   11.0   0.0    0.0    2.0    2.0    1.0    0.0    0.0    0.1801566579634465   69 / 383
1.0    0.0    300.0  0.0    14.0   5.0    12.0   0.0    0.0    0.0    19.0   0.0    2.0    0.0    3.0    0.0    4.0    0.0    3.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
3.0    26.0   0.0    317.0  0.0    4.0    0.0    9.0    1.0    5.0    1.0    2.0    2.0    9.0    2.0    2.0    0.0    11.0   1.0    1.0    0.0    0.0    0.0    5.0    0.0    2.0    0.21339950372208435  86 / 403
0.0    16.0   3.0    0.0    288.0  1.0    17.0   0.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    7.0    4.0    14.0   5.0    0.0    0.0    0.0    4.0    0.0    18.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    10.0   2.0    0.0    0.0    0.0    11.0   0.0    0.0    9.0    2.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    4.0    0.0    8.0    7.0    0.0    0.0    3.0    5.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    18.0   3.0    1.0    0.0    0.0    326.0  2.0    3.0    0.17258883248730963  68 / 394
0.0    0.0    0.0    0.0    1.0    4.0    0.0    1.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    7.0    51.0   0.0    26.0   1.0    0.0    293.0  1.0    0.25255102040816324  99 / 392
2.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    22.0   5.0    0.0    0.0    0.0    6.0    1.0    300.0  0.18256130790190736  67 / 367
423.0  537.0  343.0  402.0  370.0  345.0  352.0  337.0  346.0  372.0  395.0  340.0  429.0  379.0  317.0  386.0  364.0  471.0  361.0  425.0  394.0  366.0  410.0  412.0  339.0  388.0  0.21213635909227233  2,122 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787864
2    0.876337
3    0.912926
4    0.93392
5    0.950115
6    0.959912
7    0.968909
8    0.974808
9    0.979806
10   0.984105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.23007887690177992
RMSE: 0.47966538013679905
LogLoss: 0.7587641888352706
Mean Per-Class Error: 0.22295719644192277
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19     20    21    22    23     24    25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0    2.0   0.0   0.07865168539325842  7 / 89
0.0    81.0   0.0   1.0    0.0   0.0   0.0   6.0   0.0   0.0    2.0   0.0   0.0   0.0    1.0   0.0    0.0   9.0    4.0   0.0    0.0   1.0   0.0   1.0    0.0   0.0   0.2358490566037736   25 / 106
0.0    0.0    64.0  0.0    0.0   2.0   5.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0   1.0    1.0   0.0   1.0   0.0    0.0   0.0   0.21951219512195122  18 / 82
1.0    3.0    0.0   89.0   0.0   1.0   0.0   4.0   0.0   2.0    0.0   2.0   1.0   3.0    0.0   2.0    0.0   2.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0   1.0   0.20535714285714285  23 / 112
0.0    2.0    0.0   0.0    68.0  1.0   5.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    4.0   2.0    0.0   0.0   0.0   2.0    0.0   8.0   0.29896907216494845  29 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0    2.0   2.0   82.0  0.0    0.0   0.0   0.10869565217391304  10 / 92
0.0    1.0    0.0   4.0    3.0   0.0   0.0   2.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    7.0   0.0    0.0   0.0   0.0   79.0   1.0   0.0   0.21                 21 / 100
0.0    0.0    0.0   0.0    1.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   14.0   0.0   7.0   1.0   0.0    80.0  0.0   0.2523364485981308   27 / 107
1.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   1.0    0.0   0.0   0.0   2.0    1.0   69.0  0.20689655172413793  18 / 87
106.0  126.0  71.0  114.0  86.0  81.0  85.0  90.0  81.0  107.0  99.0  91.0  90.0  100.0  57.0  116.0  94.0  124.0  92.0  104.0  98.0  84.0  99.0  101.0  97.0  97.0  0.22048192771084338  549 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779518
2    0.875502
3    0.913655
4    0.931727
5    0.946988
6    0.956627
7    0.967068
8    0.971486
9    0.978715
10   0.983133
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:48  1 min 45.752 sec  178696 obs/sec    1         1             10007      0.699002         1.51254             0.991318       0.409877                         0.698916           1.50705               0.991296         0.417671
    2019-08-04 09:01:48  1 min 46.257 sec  184290 obs/sec    10        10            100070     0.476415         0.749862            0.995967       0.212136                         0.479665           0.758764              0.9959           0.220482
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0958935
C13         0.93637                0.93637              0.0897918
C9          0.864508               0.864508             0.0829007
C8          0.751436               0.751436             0.0720578
C12         0.739145               0.739145             0.0708792
C7          0.723212               0.723212             0.0693513
C10         0.646508               0.646508             0.0619959
C11         0.613341               0.613341             0.0588154
C5          0.595702               0.595702             0.0571239
C14         0.591328               0.591328             0.0567045
C6          0.584583               0.584583             0.0560577
C3          0.546742               0.546742             0.052429
C4          0.538738               0.538738             0.0516615
C16         0.516404               0.516404             0.0495198
C1          0.420764               0.420764             0.0403486
C2          0.359456               0.359456             0.0344695
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_53

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011237286014988968  0.0003270144807174802  0.0         -0.02482315569879745  0.5727155208587646  0.030563004805089965  0.5972096920013428
    3        26       Softmax                 0.0   0.0   0.002143399676032669   0.0004238075343891978  0.0         0.016340191078038167  0.7361304759979248  -0.5416056468168949   0.2694826126098633


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22719543922455165
RMSE: 0.47665022734134055
LogLoss: 0.7567204459565572
Mean Per-Class Error: 0.21382447750196695
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    1.0    1.0    0.0    0.0    1.0    2.0    0.0    5.0    5.0    4.0    2.0    1.0    0.0    0.0    3.0    1.0    6.0    0.0    1.0    0.0    2.0    1.0    7.0    0.0    0.10913705583756345  43 / 394
0.0    284.0  0.0    10.0   2.0    3.0    4.0    10.0   2.0    2.0    2.0    0.0    0.0    0.0    4.0    2.0    2.0    25.0   19.0   0.0    0.0    4.0    0.0    5.0    3.0    0.0    0.2584856396866841   99 / 383
0.0    0.0    306.0  0.0    6.0    1.0    8.0    0.0    1.0    0.0    20.0   1.0    1.0    0.0    13.0   0.0    0.0    0.0    0.0    1.0    6.0    0.0    4.0    0.0    0.0    0.0    0.16847826086956522  62 / 368
6.0    6.0    0.0    325.0  0.0    3.0    0.0    4.0    0.0    4.0    1.0    2.0    8.0    3.0    10.0   1.0    2.0    18.0   1.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.19154228855721392  77 / 402
0.0    11.0   5.0    0.0    269.0  5.0    27.0   1.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    21.0   3.0    0.0    0.0    0.0    5.0    1.0    21.0   0.2994791666666667   115 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    1.0    0.0    15.0   2.0    5.0    1.0    0.0    1.0    0.0    0.0    2.0    3.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    4.0    0.0    9.0    2.0    1.0    0.0    6.0    6.0    2.0    13.0   0.0    0.0    0.0    0.0    0.0    5.0    2.0    12.0   4.0    2.0    1.0    0.0    309.0  6.0    10.0   0.21573604060913706  85 / 394
0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    0.0    2.0    6.0    0.0    4.0    23.0   3.0    35.0   1.0    0.0    301.0  1.0    0.2340966921119593   92 / 393
1.0    1.0    0.0    2.0    14.0   1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    28.0   2.0    0.0    0.0    0.0    0.0    0.0    306.0  0.16621253405994552  61 / 367
396.0  401.0  352.0  422.0  328.0  395.0  389.0  325.0  337.0  351.0  404.0  322.0  451.0  378.0  410.0  381.0  359.0  449.0  395.0  364.0  395.0  392.0  425.0  409.0  374.0  399.0  0.21313605918224532  2,132 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.786864
2    0.873938
3    0.913526
4    0.93372
5    0.948016
6    0.958712
7    0.968309
8    0.974208
9    0.979306
10   0.983905

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.227425261747861
RMSE: 0.4768912472963422
LogLoss: 0.7638470424497984
Mean Per-Class Error: 0.2100625516699031
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10     11    12     13     14    15     16    17     18     19    20    21    22     23    24     25     Error                Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
80.0  0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   1.0    1.0   3.0    0.0    0.10112359550561797  9 / 89
0.0   76.0  0.0   3.0    2.0   0.0   2.0   5.0   1.0   0.0    0.0    0.0   0.0    0.0    2.0   0.0    0.0   5.0    4.0    0.0   0.0   3.0   0.0    2.0   1.0    0.0    0.2830188679245283   30 / 106
0.0   0.0   67.0  0.0    0.0   0.0   1.0   0.0   0.0   0.0    5.0    0.0   0.0    0.0    6.0   0.0    0.0   0.0    0.0    0.0   2.0   0.0   1.0    0.0   0.0    0.0    0.18292682926829268  15 / 82
3.0   0.0   0.0   92.0   0.0   1.0   0.0   0.0   0.0   2.0    0.0    0.0   3.0    2.0    2.0   0.0    0.0   3.0    0.0    0.0   0.0   0.0   0.0    4.0   0.0    0.0    0.17857142857142858  20 / 112
0.0   1.0   1.0   0.0    64.0  3.0   7.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0    0.0   0.0    1.0   1.0    8.0    0.0   0.0   0.0   0.0    1.0   0.0    7.0    0.3402061855670103   33 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   1.0    1.0    1.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   87.0   0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0   0.0   4.0    2.0   1.0   0.0   1.0   0.0   0.0    5.0    0.0   0.0    0.0    0.0   0.0    1.0   0.0    5.0    0.0   0.0   0.0   0.0    74.0  2.0    5.0    0.26                 26 / 100
0.0   0.0   0.0   0.0    0.0   3.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0    2.0    0.0   1.0    3.0   0.0    0.0    6.0   1.0   7.0   1.0    0.0   82.0   0.0    0.2336448598130841   25 / 107
1.0   1.0   0.0   1.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0    0.0   0.0    73.0   0.16091954022988506  14 / 87
94.0  94.0  75.0  120.0  78.0  93.0  96.0  85.0  75.0  102.0  105.0  89.0  100.0  104.0  87.0  113.0  92.0  109.0  102.0  85.0  98.0  86.0  103.0  98.0  102.0  105.0  0.21084337349397592  525 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789157
2    0.873896
3    0.913253
4    0.934137
5    0.946185
6    0.955823
7    0.96747
8    0.972691
9    0.97751
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:36  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:37  1 min 34.750 sec  131671 obs/sec    1         1             10007      0.675103         1.4279              0.991899       0.379886                         0.675003           1.42151               0.991881         0.386345
    2019-08-04 09:01:37  1 min 35.466 sec  128624 obs/sec    10        10            100070     0.47665          0.75672             0.995962       0.213136                         0.476891           0.763847              0.995948         0.210843
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.102432
C13         0.860683               0.860683             0.0881616
C9          0.839403               0.839403             0.0859818
C8          0.73473                0.73473              0.07526
C7          0.730043               0.730043             0.0747799
C12         0.683546               0.683546             0.0700171
C11         0.6741                 0.6741               0.0690495
C14         0.670269               0.670269             0.0686571
C16         0.609295               0.609295             0.0624114
C10         0.600233               0.600233             0.0614832
C6          0.519225               0.519225             0.0531853
C5          0.460524               0.460524             0.0471725
C3          0.399659               0.399659             0.0409379
C4          0.370833               0.370833             0.0379853
C2          0.321517               0.321517             0.0329337
C1          0.288499               0.288499             0.0295516
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_90

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011537314812812838  0.00035314750857651234  0.0         0.0059910658263717664  0.5605940818786621  0.04558146419103566  0.6574811935424805
    3        26       Softmax                 0.0   0.0   0.002163211005748823   0.00043686735443770885  0.0         -0.02492292088114622   0.736198902130127   -0.5220126716739881  0.2390466332435608


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22154585179077954
RMSE: 0.4706865748996667
LogLoss: 0.7497672009253253
Mean Per-Class Error: 0.21183142286368375
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    0.0    0.0    1.0    0.0    2.0    0.0    4.0    3.0    0.0    6.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    1.0    2.0    1.0    2.0    6.0    2.0    0.09898477157360407  39 / 394
0.0    298.0  0.0    6.0    4.0    0.0    2.0    3.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    7.0    24.0   19.0   0.0    0.0    1.0    0.0    5.0    4.0    2.0    0.22193211488250653  85 / 383
0.0    0.0    289.0  0.0    20.0   0.0    12.0   2.0    0.0    0.0    16.0   0.0    1.0    1.0    5.0    0.0    7.0    0.0    10.0   2.0    1.0    0.0    2.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
5.0    26.0   0.0    323.0  0.0    0.0    0.0    7.0    0.0    5.0    5.0    0.0    5.0    9.0    2.0    2.0    1.0    8.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.19851116625310175  80 / 403
0.0    2.0    2.0    0.0    311.0  5.0    24.0   0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    7.0    4.0    0.0    0.0    0.0    5.0    0.0    14.0   0.18798955613577023  72 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    12.0   1.0    8.0    0.0    0.0    8.0    0.0    0.0    1.0    2.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    4.0    0.0    5.0    11.0   0.0    0.0    1.0    2.0    0.0    5.0    1.0    0.0    2.0    2.0    1.0    0.0    1.0    19.0   3.0    4.0    0.0    0.0    326.0  6.0    1.0    0.17258883248730963  68 / 394
0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    9.0    11.0   0.0    1.0    25.0   2.0    39.0   3.0    0.0    289.0  2.0    0.26463104325699743  104 / 393
3.0    3.0    0.0    0.0    11.0   0.0    0.0    0.0    2.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    9.0    0.0    35.0   4.0    0.0    0.0    0.0    5.0    0.0    281.0  0.23433242506811988  86 / 367
406.0  462.0  333.0  388.0  433.0  382.0  373.0  285.0  320.0  370.0  370.0  346.0  446.0  383.0  400.0  371.0  358.0  488.0  400.0  368.0  386.0  425.0  399.0  415.0  348.0  348.0  0.21093671898430472  2,110 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789063
2    0.876637
3    0.914026
4    0.93352
5    0.949015
6    0.958512
7    0.96701
8    0.973308
9    0.977707
10   0.982105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2261855615847377
RMSE: 0.47558969877903967
LogLoss: 0.764026250667178
Mean Per-Class Error: 0.2125834682877761
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17     18     19    20    21     22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  ----  ----  -----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   1.0    1.0    0.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   78.0   0.0   1.0    2.0   0.0   1.0   2.0   0.0   0.0   1.0    0.0   1.0    0.0   0.0   0.0    3.0   8.0    6.0    0.0   0.0   1.0    0.0    1.0    1.0    0.0   0.2641509433962264   28 / 106
0.0   0.0    59.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0   6.0    0.0   0.0    1.0   1.0   0.0    3.0   0.0    3.0    1.0   0.0   0.0    0.0    0.0    0.0    0.0   0.2804878048780488   23 / 82
3.0   5.0    0.0   93.0   0.0   0.0   0.0   2.0   0.0   1.0   2.0    0.0   2.0    2.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0    0.0    1.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   0.0    1.0   0.0    73.0  3.0   7.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    3.0    0.0   0.0   0.0    0.0    2.0    0.0    6.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---   ---   ---    ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0    0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0    86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0   3.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0    5.0    0.0   1.0   0.0    0.0    79.0   3.0    1.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0   3.0    3.0   0.0    0.0    6.0   1.0   12.0   2.0    0.0    77.0   0.0   0.2803738317757009   30 / 107
2.0   1.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0   0.0    1.0   0.0    0.0   0.0   0.0    2.0   0.0    7.0    2.0   0.0   0.0    0.0    2.0    0.0    65.0  0.25287356321839083  22 / 87
98.0  113.0  67.0  108.0  98.0  87.0  93.0  75.0  77.0  99.0  100.0  96.0  101.0  97.0  79.0  102.0  87.0  120.0  117.0  87.0  98.0  102.0  107.0  100.0  100.0  82.0  0.21285140562248997  530 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787149
2    0.873494
3    0.914056
4    0.935341
5    0.950602
6    0.958233
7    0.967068
8    0.973896
9    0.97751
10   0.982329
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:33  2 min 31.552 sec  126670 obs/sec    1         1             10007      0.658537         1.34766             0.992292       0.36739                          0.659654           1.35589               0.992246         0.3751
    2019-08-04 09:02:34  2 min 32.297 sec  123695 obs/sec    10        10            100070     0.470687         0.749767            0.996062       0.210937                         0.47559            0.764026              0.99597          0.212851
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0955508
C13         0.943001               0.943001             0.0901046
C12         0.898683               0.898683             0.0858699
C9          0.835086               0.835086             0.0797932
C7          0.827722               0.827722             0.0790896
C8          0.775082               0.775082             0.0740597
C10         0.712766               0.712766             0.0681054
C11         0.693531               0.693531             0.0662675
C16         0.664771               0.664771             0.0635195
C14         0.589331               0.589331             0.0563111
C6          0.523073               0.523073             0.04998
C5          0.489394               0.489394             0.046762
C4          0.434484               0.434484             0.0415153
C3          0.415814               0.415814             0.0397314
C2          0.33912                0.33912              0.0324032
C1          0.323774               0.323774             0.0309369
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_57

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013964625134690323  0.00036879058461636305  0.0         0.0251289976333382     0.7408263683319092   0.1835978287115439   0.7544195652008057
    3        26       Softmax                 0.0   0.0   0.001942225699797116   0.0003997484454885125   0.0         -0.016132878003461953  0.49511146545410156  -0.4625867745349126  0.24650698900222778


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2232037447875861
RMSE: 0.4724444356615771
LogLoss: 0.7418714135430883
Mean Per-Class Error: 0.22039214912254013
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  1.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    2.0    3.0    0.0    5.0    0.0    1.0    0.0    5.0    1.0    4.0    0.0    4.0    0.0    4.0    1.0    6.0    2.0    0.10632911392405063  42 / 395
0.0    313.0  0.0    9.0    3.0    1.0    1.0    7.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    7.0    2.0    19.0   13.0   0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.18276762402088773  70 / 383
0.0    0.0    298.0  0.0    19.0   0.0    13.0   2.0    0.0    0.0    15.0   0.0    1.0    0.0    3.0    0.0    1.0    0.0    6.0    3.0    2.0    0.0    5.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
5.0    23.0   0.0    326.0  0.0    1.0    0.0    9.0    0.0    7.0    0.0    0.0    5.0    2.0    1.0    4.0    2.0    10.0   5.0    1.0    1.0    0.0    0.0    0.0    0.0    1.0    0.19106699751861042  77 / 403
0.0    7.0    1.0    1.0    302.0  3.0    12.0   1.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    10.0   5.0    11.0   4.0    0.0    0.0    0.0    5.0    0.0    15.0   0.21148825065274152  81 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    2.0    7.0    0.0    0.0    2.0    0.0    22.0   4.0    5.0    0.0    0.0    5.0    0.0    0.0    4.0    9.0    315.0  0.0    0.0    0.0    0.1622340425531915   61 / 376
1.0    8.0    0.0    5.0    12.0   1.0    0.0    2.0    3.0    1.0    9.0    0.0    0.0    0.0    0.0    1.0    18.0   1.0    15.0   1.0    5.0    0.0    0.0    307.0  3.0    1.0    0.22081218274111675  87 / 394
0.0    1.0    0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    2.0    7.0    0.0    3.0    51.0   4.0    34.0   1.0    0.0    284.0  0.0    0.27735368956743     109 / 393
3.0    1.0    0.0    1.0    15.0   0.0    0.0    1.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    38.0   4.0    0.0    0.0    0.0    3.0    0.0    292.0  0.20435967302452315  75 / 367
396.0  502.0  342.0  423.0  421.0  338.0  328.0  306.0  321.0  352.0  361.0  342.0  455.0  386.0  396.0  412.0  416.0  428.0  411.0  409.0  420.0  371.0  379.0  380.0  362.0  346.0  0.21953413975807257  2,196 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780466
2    0.875937
3    0.916525
4    0.938718
5    0.953314
6    0.962211
7    0.969109
8    0.974408
9    0.979006
10   0.983005

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22727518198010163
RMSE: 0.47673386913465843
LogLoss: 0.7646179031234126
Mean Per-Class Error: 0.224241885906627
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16     17     18     19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0    0.0   1.0    0.0   1.0    1.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   81.0   0.0   2.0    2.0    1.0   0.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0   2.0   3.0    1.0    5.0    4.0    0.0   0.0    0.0   1.0    1.0   0.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    62.0  0.0    3.0    0.0   5.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    2.0    2.0   1.0    0.0   1.0    0.0   0.0    0.0   0.24390243902439024  20 / 82
3.0   5.0    0.0   89.0   0.0    0.0   0.0   5.0   0.0   2.0    0.0   0.0   2.0   0.0   0.0   1.0    1.0    2.0    2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.20535714285714285  23 / 112
0.0   4.0    0.0   0.0    72.0   1.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0    2.0    3.0    3.0   0.0    0.0   0.0    0.0   0.0    5.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0   1.0   1.0   0.0    0.0    1.0    0.0    0.0   1.0    2.0   83.0   0.0   0.0    0.0   0.09782608695652174  9 / 92
1.0   2.0    0.0   3.0    5.0    1.0   0.0   1.0   1.0   0.0    4.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0    1.0    0.0   1.0    0.0   0.0    76.0  0.0    1.0   0.24                 24 / 100
0.0   1.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0    10.0  2.0    7.0   1.0    0.0   82.0   0.0   0.2336448598130841   25 / 107
0.0   0.0    0.0   1.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    7.0    2.0   0.0    0.0   0.0    1.0   0.0    70.0  0.19540229885057472  17 / 87
95.0  133.0  72.0  116.0  101.0  78.0  75.0  82.0  74.0  102.0  86.0  94.0  95.0  95.0  87.0  118.0  103.0  103.0  104.0  97.0  110.0  84.0  100.0  93.0  108.0  85.0  0.22289156626506024  555 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.777108
2    0.86988
3    0.912851
4    0.935743
5    0.951807
6    0.959839
7    0.963855
8    0.969478
9    0.975502
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:41  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:41  1 min 39.723 sec  80056 obs/sec     1         1             10007      0.601318         1.16376             0.993574       0.315905                         0.600132           1.1584                0.993582         0.317671
    2019-08-04 09:01:43  1 min 40.866 sec  80442 obs/sec     10        10            100070     0.472444         0.741871            0.996033       0.219534                         0.476734           0.764618              0.99595          0.222892
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.090457
C15         0.996619               0.996619             0.0901511
C12         0.864049               0.864049             0.0781592
C9          0.835583               0.835583             0.0755843
C8          0.808015               0.808015             0.0730906
C7          0.748398               0.748398             0.0676978
C11         0.740049               0.740049             0.0669426
C14         0.705513               0.705513             0.0638186
C10         0.700068               0.700068             0.0633261
C16         0.641308               0.641308             0.0580108
C5          0.609887               0.609887             0.0551685
C6          0.569038               0.569038             0.0514734
C3          0.56584                0.56584              0.0511842
C4          0.486662               0.486662             0.044022
C1          0.393732               0.393732             0.0356158
C2          0.390219               0.390219             0.0352981
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_145

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015441578240142917  0.00034109153784811497  0.0         -0.026697788801307354  0.7546663284301758   0.013637353939952664  0.7729051113128662
    3        26       Softmax                 0.0   0.0   0.001801841094185455   0.00023691519163548946  0.0         -0.006939071197060378  0.38835442066192627  -0.5728206336464425   0.2811473608016968


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21838987288286693
RMSE: 0.46732202268122025
LogLoss: 0.750361415311668
Mean Per-Class Error: 0.21242204918818036
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  1.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    4.0    4.0    1.0    6.0    0.0    2.0    0.0    0.0    0.0    2.0    2.0    2.0    0.0    2.0    3.0    5.0    1.0    0.09620253164556962  38 / 395
0.0    332.0  0.0    5.0    2.0    0.0    1.0    5.0    3.0    1.0    6.0    0.0    0.0    0.0    0.0    2.0    0.0    20.0   1.0    0.0    0.0    2.0    0.0    1.0    2.0    0.0    0.13315926892950392  51 / 383
0.0    1.0    283.0  0.0    18.0   2.0    20.0   1.0    0.0    0.0    16.0   0.0    1.0    0.0    8.0    0.0    2.0    0.0    5.0    4.0    3.0    0.0    4.0    0.0    0.0    0.0    0.23097826086956522  85 / 368
5.0    32.0   0.0    308.0  0.0    1.0    0.0    6.0    0.0    8.0    1.0    0.0    4.0    4.0    7.0    2.0    0.0    12.0   1.0    1.0    4.0    0.0    0.0    6.0    0.0    1.0    0.23573200992555832  95 / 403
0.0    12.0   1.0    0.0    306.0  2.0    15.0   0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    7.0    4.0    7.0    8.0    0.0    0.0    0.0    4.0    0.0    13.0   0.203125             78 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    7.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    10.0   2.0    3.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    5.0    0.0    1.0    9.0    1.0    2.0    3.0    5.0    2.0    9.0    1.0    0.0    0.0    2.0    0.0    9.0    2.0    3.0    2.0    1.0    0.0    0.0    328.0  7.0    2.0    0.16751269035532995  66 / 394
1.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    2.0    16.0   5.0    23.0   4.0    1.0    323.0  0.0    0.178117048346056    70 / 393
1.0    2.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    15.0   5.0    0.0    0.0    0.0    1.0    1.0    306.0  0.16621253405994552  61 / 367
424.0  636.0  319.0  394.0  423.0  358.0  373.0  294.0  335.0  365.0  372.0  333.0  428.0  359.0  385.0  380.0  370.0  445.0  221.0  387.0  389.0  371.0  447.0  397.0  400.0  398.0  0.21133659902029392  2,114 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788663
2    0.879236
3    0.913826
4    0.93312
5    0.950015
6    0.959812
7    0.96711
8    0.974308
9    0.978906
10   0.983405

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22303775170629295
RMSE: 0.4722687282747958
LogLoss: 0.7648686554910128
Mean Per-Class Error: 0.2210118652183334
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20    21    22     23    24     25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0    89.0   0.0   1.0    1.0    0.0   1.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0   8.0    0.0   0.0   0.0   2.0   0.0    1.0   0.0    0.0   0.16037735849056603  17 / 106
0.0    1.0    58.0  0.0    3.0    1.0   7.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    1.0   2.0   1.0   0.0   2.0    0.0   0.0    0.0   0.2926829268292683   24 / 82
3.0    6.0    0.0   90.0   0.0    0.0   0.0   2.0   0.0   1.0    1.0   0.0   1.0   2.0   1.0   0.0    0.0   3.0    1.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.19642857142857142  22 / 112
0.0    2.0    0.0   0.0    73.0   2.0   5.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    2.0   3.0   0.0   0.0   0.0    0.0   0.0    6.0   0.24742268041237114  24 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0    1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0    3.0    0.0   1.0    3.0    0.0   1.0   2.0   1.0   0.0    5.0   1.0   0.0   0.0   0.0   0.0    2.0   1.0    2.0   0.0   0.0   0.0   0.0    76.0  2.0    0.0   0.24                 24 / 100
0.0    0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0   5.0   2.0   5.0   2.0    0.0   89.0   0.0   0.16822429906542055  18 / 107
0.0    1.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    2.0   2.0   0.0   0.0   0.0    0.0   0.0    71.0  0.1839080459770115   16 / 87
102.0  157.0  64.0  115.0  104.0  80.0  94.0  72.0  79.0  105.0  89.0  86.0  94.0  95.0  83.0  106.0  91.0  117.0  56.0  96.0  98.0  81.0  119.0  93.0  117.0  97.0  0.21967871485943774  547 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780321
2    0.87751
3    0.910843
4    0.935743
5    0.951807
6    0.959839
7    0.968273
8    0.974699
9    0.979116
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:01  3 min 59.001 sec  50796 obs/sec     1         1             10007      0.587313         1.10655             0.993871       0.301809                         0.586324           1.099                 0.993874         0.30241
    2019-08-04 09:04:02  4 min  0.730 sec  52891 obs/sec     10        10            100070     0.467322         0.750361            0.996119       0.211337                         0.472269           0.764869              0.996026         0.219679
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0896412
C13         0.906413               0.906413             0.081252
C9          0.896595               0.896595             0.0803719
C12         0.888009               0.888009             0.0796022
C7          0.836804               0.836804             0.0750121
C11         0.795557               0.795557             0.0713148
C8          0.759589               0.759589             0.0680905
C14         0.692383               0.692383             0.0620661
C10         0.684487               0.684487             0.0613582
C6          0.61873                0.61873              0.0554637
C3          0.561481               0.561481             0.0503319
C16         0.557287               0.557287             0.0499559
C5          0.543285               0.543285             0.0487007
C4          0.531148               0.531148             0.0476128
C2          0.463922               0.463922             0.0415865
C1          0.419891               0.419891             0.0376395
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_147

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015192442026830122  0.000319018610753119    0.0         0.035078556767061286   0.7713751792907715  0.004628313670959042  0.850968599319458
    3        26       Softmax                 0.0   0.0   0.0017980497719830824  0.00031315686646848917  0.0         0.0015057497005426075  0.3870629072189331  -0.5524436155882175   0.27359437942504883


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21809207103803016
RMSE: 0.4670032880377077
LogLoss: 0.745356995309723
Mean Per-Class Error: 0.21562532286476824
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    3.0    2.0    1.0    7.0    0.0    2.0    0.0    0.0    1.0    4.0    0.0    1.0    1.0    3.0    1.0    7.0    2.0    0.09873417721518987  39 / 395
0.0    329.0  0.0    5.0    1.0    0.0    1.0    5.0    2.0    0.0    3.0    0.0    1.0    0.0    0.0    2.0    1.0    21.0   3.0    0.0    0.0    5.0    2.0    1.0    1.0    0.0    0.1409921671018277   54 / 383
0.0    0.0    286.0  0.0    12.0   2.0    14.0   1.0    0.0    0.0    29.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    6.0    3.0    7.0    0.0    3.0    1.0    0.0    0.0    0.22070844686648503  81 / 367
5.0    23.0   0.0    322.0  0.0    0.0    0.0    7.0    0.0    5.0    0.0    0.0    7.0    3.0    3.0    3.0    0.0    15.0   1.0    1.0    1.0    0.0    0.0    4.0    0.0    3.0    0.20099255583126552  81 / 403
0.0    13.0   0.0    0.0    282.0  5.0    26.0   0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    8.0    4.0    10.0   8.0    0.0    0.0    0.0    9.0    1.0    10.0   0.265625             102 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    0.0    18.0   1.0    1.0    0.0    0.0    4.0    0.0    0.0    1.0    2.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    15.0   0.0    4.0    8.0    1.0    0.0    1.0    3.0    3.0    8.0    1.0    0.0    0.0    2.0    0.0    8.0    2.0    3.0    2.0    2.0    0.0    0.0    318.0  6.0    7.0    0.19289340101522842  76 / 394
0.0    1.0    0.0    2.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    6.0    0.0    2.0    12.0   1.0    20.0   1.0    0.0    342.0  0.0    0.1297709923664122   51 / 393
2.0    1.0    0.0    1.0    16.0   5.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    38.0   6.0    0.0    0.0    0.0    4.0    0.0    284.0  0.22615803814713897  83 / 367
405.0  628.0  320.0  427.0  365.0  349.0  358.0  300.0  319.0  350.0  416.0  332.0  453.0  362.0  387.0  383.0  343.0  436.0  310.0  386.0  400.0  377.0  421.0  385.0  428.0  363.0  0.21443566929921024  2,145 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785564
2    0.875737
3    0.914626
4    0.937719
5    0.952414
6    0.960612
7    0.970209
8    0.976107
9    0.980306
10   0.984804

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.224291348720609
RMSE: 0.4735940758926456
LogLoss: 0.7675918631076585
Mean Per-Class Error: 0.22053951171790362
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0    0.0   4.0    0.0   0.10112359550561797  9 / 89
0.0   84.0   0.0   1.0    1.0   0.0   1.0   3.0   1.0   0.0    1.0    0.0   0.0    0.0   0.0   0.0    0.0   8.0    1.0   0.0   0.0    3.0   1.0    1.0   0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    60.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    7.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0    2.0   2.0   1.0    0.0   2.0    0.0   0.0    0.0   0.2682926829268293   22 / 82
3.0   4.0    0.0   90.0   0.0   0.0   0.0   4.0   0.0   0.0    0.0    0.0   3.0    1.0   0.0   1.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.19642857142857142  22 / 112
0.0   3.0    0.0   0.0    69.0  2.0   7.0   0.0   1.0   0.0    3.0    0.0   0.0    0.0   0.0   0.0    1.0   1.0    3.0   4.0   0.0    0.0   0.0    1.0   0.0    2.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   3.0    0.0   1.0    3.0   0.0   0.0   1.0   1.0   0.0    3.0    1.0   0.0    0.0   0.0   0.0    2.0   1.0    3.0   0.0   1.0    0.0   0.0    75.0  3.0    2.0   0.25                 25 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0    0.0   3.0   0.0    5.0   1.0    0.0   93.0   0.0   0.1308411214953271   14 / 107
0.0   0.0    0.0   1.0    5.0   1.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    8.0   2.0   0.0    0.0   0.0    1.0   0.0    67.0  0.22988505747126436  20 / 87
92.0  150.0  67.0  118.0  85.0  78.0  90.0  87.0  75.0  101.0  103.0  89.0  104.0  94.0  74.0  109.0  87.0  111.0  85.0  94.0  102.0  85.0  108.0  88.0  126.0  88.0  0.21927710843373494  546 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780723
2    0.872691
3    0.917671
4    0.942169
5    0.954217
6    0.958635
7    0.969076
8    0.976707
9    0.979116
10   0.983936
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:03  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:03  4 min  1.343 sec  51317 obs/sec     1         1             10007      0.576048         1.07932             0.994104       0.284015                         0.577696           1.0804                0.994053         0.294779
    2019-08-04 09:04:05  4 min  3.126 sec  51662 obs/sec     10        10            100070     0.467003         0.745357            0.996125       0.214436                         0.473594           0.767592              0.996003         0.219277
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0885321
C12         0.940386               0.940386             0.0832544
C13         0.908868               0.908868             0.080464
C9          0.907206               0.907206             0.0803169
C11         0.808361               0.808361             0.0715659
C8          0.799398               0.799398             0.0707724
C7          0.797587               0.797587             0.0706121
C14         0.705166               0.705166             0.0624299
C10         0.677678               0.677678             0.0599963
C6          0.647162               0.647162             0.0572946
C16         0.595158               0.595158             0.0526906
C3          0.568068               0.568068             0.0502922
C4          0.558775               0.558775             0.0494696
C5          0.548018               0.548018             0.0485172
C2          0.435344               0.435344             0.0385419
C1          0.398158               0.398158             0.0352498
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_162

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0014299487007747302  0.0003972825361415744   0.0         -0.023435766449438233  0.7657897472381592   -0.02087265801362674  0.7626924514770508
    3        26       Softmax                 0.0   0.0   0.0019419570498240108  0.00033430824987590313  0.0         0.022509918214718476   0.49619948863983154  -0.4516835739129371   0.21687716245651245


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2244485055095321
RMSE: 0.473759966132146
LogLoss: 0.7485449417427831
Mean Per-Class Error: 0.21718669262380422
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    3.0    4.0    4.0    5.0    0.0    5.0    0.0    4.0    0.0    1.0    2.0    2.0    0.0    6.0    0.0    0.1189873417721519   47 / 395
0.0    299.0  0.0    8.0    3.0    7.0    1.0    6.0    1.0    0.0    1.0    0.0    1.0    0.0    1.0    1.0    1.0    26.0   24.0   0.0    0.0    0.0    1.0    1.0    0.0    1.0    0.2193211488250653   84 / 383
0.0    0.0    295.0  0.0    9.0    2.0    17.0   1.0    0.0    0.0    19.0   1.0    0.0    0.0    2.0    2.0    1.0    0.0    10.0   1.0    5.0    0.0    3.0    0.0    0.0    0.0    0.1983695652173913   73 / 368
3.0    20.0   0.0    328.0  0.0    0.0    0.0    11.0   0.0    6.0    0.0    1.0    5.0    5.0    7.0    5.0    0.0    4.0    3.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    0.18610421836228289  75 / 403
0.0    4.0    2.0    0.0    286.0  6.0    17.0   0.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    7.0    8.0    11.0   6.0    0.0    0.0    0.0    10.0   1.0    21.0   0.2552083333333333   98 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    8.0    1.0    4.0    0.0    0.0    11.0   0.0    0.0    6.0    2.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    6.0    1.0    8.0    9.0    3.0    1.0    2.0    2.0    0.0    9.0    0.0    0.0    0.0    2.0    0.0    3.0    3.0    7.0    4.0    1.0    1.0    0.0    322.0  4.0    5.0    0.1806615776081425   71 / 393
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    3.0    0.0    1.0    19.0   4.0    22.0   2.0    0.0    331.0  0.0    0.15776081424936386  62 / 393
1.0    2.0    0.0    2.0    16.0   2.0    0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    1.0    38.0   6.0    0.0    0.0    0.0    5.0    0.0    288.0  0.21525885558583105  79 / 367
384.0  443.0  356.0  432.0  371.0  411.0  349.0  303.0  321.0  340.0  356.0  332.0  397.0  362.0  424.0  377.0  343.0  507.0  384.0  400.0  409.0  362.0  436.0  396.0  417.0  391.0  0.21603518944316705  2,161 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783965
2    0.874438
3    0.917425
4    0.936319
5    0.950915
6    0.962011
7    0.969709
8    0.975907
9    0.980806
10   0.984705

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22721715798803496
RMSE: 0.47667300950235786
LogLoss: 0.7681444720681572
Mean Per-Class Error: 0.22190936818210164
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0   2.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0    4.0    0.0   0.10112359550561797  9 / 89
0.0   75.0   0.0   2.0    2.0   2.0    1.0   4.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   10.0   6.0   0.0   0.0    0.0   1.0    1.0    0.0    0.0   0.29245283018867924  31 / 106
0.0   0.0    61.0  0.0    0.0   0.0    7.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   1.0   1.0    0.0   0.0    4.0   1.0   2.0    0.0   1.0    0.0    0.0    0.0   0.25609756097560976  21 / 82
2.0   4.0    0.0   91.0   0.0   0.0    0.0   4.0   0.0   1.0    0.0   1.0   1.0   3.0   2.0   1.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.1875               21 / 112
0.0   1.0    0.0   0.0    72.0  3.0    4.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    2.0   3.0   0.0    0.0   0.0    2.0    0.0    6.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0   1.0    0.0   0.0   3.0    1.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   2.0    3.0   1.0    1.0   1.0   0.0   0.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    2.0   0.0   0.0    0.0   0.0    82.0   1.0    0.0   0.18                 18 / 100
0.0   0.0    0.0   1.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   2.0   1.0    6.0   1.0    0.0    92.0   0.0   0.14018691588785046  15 / 107
0.0   0.0    0.0   2.0    4.0   1.0    0.0   0.0   0.0   0.0    0.0   4.0   0.0   0.0   0.0   0.0    0.0   0.0    9.0   2.0   0.0    0.0   0.0    1.0    0.0    64.0  0.26436781609195403  23 / 87
91.0  104.0  72.0  121.0  91.0  100.0  85.0  84.0  71.0  102.0  86.0  93.0  84.0  97.0  87.0  110.0  88.0  138.0  92.0  88.0  105.0  86.0  101.0  104.0  121.0  89.0  0.221285140562249    551 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.778715
2    0.872289
3    0.914859
4    0.93494
5    0.948594
6    0.959438
7    0.96988
8    0.976305
9    0.977912
10   0.983132
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:35  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:35  4 min 33.715 sec  91807 obs/sec     1         1             10007      0.606727         1.15737             0.993458       0.309807                         0.606181           1.15241               0.993452         0.308835
    2019-08-04 09:04:37  4 min 34.784 sec  86565 obs/sec     10        10            100070     0.47376          0.748545            0.996011       0.216035                         0.476673           0.768144              0.995951         0.221285
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.088558
C15         0.955208               0.955208             0.0845913
C9          0.869985               0.869985             0.0770441
C8          0.857677               0.857677             0.0759541
C7          0.812976               0.812976             0.0719955
C12         0.789085               0.789085             0.0698798
C11         0.76378                0.76378              0.0676388
C14         0.690715               0.690715             0.0611683
C10         0.663706               0.663706             0.0587765
C16         0.6052                 0.6052               0.0535953
C5          0.601736               0.601736             0.0532885
C3          0.591538               0.591538             0.0523854
C6          0.562189               0.562189             0.0497863
C4          0.556411               0.556411             0.0492747
C1          0.490386               0.490386             0.0434276
C2          0.481447               0.481447             0.042636
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_46

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015946758397262784  0.00034648505970835686  0.0         0.028084944742374773   0.7690887451171875   0.07932655641233345  0.7675843238830566
    3        26       Softmax                 0.0   0.0   0.0018541509503987841  0.00030266924295574427  0.0         -0.014532741415984254  0.38029181957244873  -0.5492521436128235  0.24121242761611938


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21936047771274972
RMSE: 0.4683593467763291
LogLoss: 0.752435437865884
Mean Per-Class Error: 0.2157769590376352
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    7.0    0.0    2.0    0.0    3.0    0.0    7.0    0.0    1.0    0.0    3.0    3.0    6.0    0.0    0.09620253164556962  38 / 395
0.0    313.0  0.0    14.0   2.0    5.0    3.0    6.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    22.0   7.0    0.0    0.0    4.0    0.0    1.0    2.0    0.0    0.18276762402088773  70 / 383
0.0    1.0    292.0  0.0    20.0   2.0    17.0   0.0    0.0    0.0    14.0   0.0    1.0    0.0    8.0    0.0    1.0    0.0    5.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    0.20652173913043478  76 / 368
5.0    16.0   0.0    332.0  0.0    2.0    0.0    4.0    0.0    4.0    1.0    0.0    7.0    3.0    2.0    4.0    0.0    16.0   0.0    1.0    1.0    0.0    0.0    5.0    0.0    0.0    0.1761786600496278   71 / 403
0.0    4.0    0.0    0.0    306.0  4.0    21.0   1.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    6.0    4.0    14.0   4.0    0.0    0.0    0.0    1.0    0.0    16.0   0.203125             78 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    14.0   2.0    1.0    0.0    0.0    12.0   0.0    0.0    3.0    2.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    3.0    0.0    12.0   6.0    0.0    0.0    3.0    5.0    1.0    7.0    1.0    0.0    2.0    0.0    1.0    8.0    2.0    12.0   5.0    2.0    0.0    0.0    314.0  5.0    4.0    0.2010178117048346   79 / 393
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    8.0    0.0    3.0    34.0   4.0    18.0   2.0    0.0    313.0  0.0    0.2035623409669211   80 / 393
0.0    0.0    0.0    2.0    16.0   2.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    49.0   5.0    0.0    0.0    0.0    0.0    0.0    281.0  0.23433242506811988  86 / 367
414.0  514.0  346.0  456.0  416.0  372.0  347.0  282.0  331.0  349.0  355.0  342.0  438.0  388.0  377.0  386.0  344.0  468.0  374.0  392.0  407.0  374.0  412.0  385.0  377.0  357.0  0.21453563930820754  2,146 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785464
2    0.879536
3    0.912526
4    0.93422
5    0.947916
6    0.958612
7    0.96771
8    0.973708
9    0.978007
10   0.982605

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2226753434731627
RMSE: 0.4718848837091126
LogLoss: 0.7696211041210654
Mean Per-Class Error: 0.21982990098929583
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0    77.0   0.0   3.0    1.0   2.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   10.0   2.0   0.0   0.0    2.0   0.0    1.0   1.0    0.0   0.27358490566037735  29 / 106
0.0    0.0    61.0  0.0    2.0   1.0   6.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0    2.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0   0.25609756097560976  21 / 82
3.0    5.0    0.0   91.0   0.0   0.0   0.0   1.0   0.0   1.0    1.0   0.0   3.0   1.0   0.0   2.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.1875               21 / 112
0.0    1.0    0.0   0.0    75.0  2.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    7.0   0.2268041237113402   22 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   84.0   0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0    0.0    0.0   5.0    3.0   0.0   0.0   2.0   1.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    2.0   0.0    3.0   0.0   1.0    0.0   0.0    73.0  3.0    3.0   0.27                 27 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0   1.0    3.0   0.0    0.0   8.0   2.0    4.0   2.0    0.0   85.0   0.0   0.205607476635514    22 / 107
0.0    0.0    0.0   1.0    6.0   1.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    10.0  3.0   0.0    0.0   0.0    0.0   0.0    63.0  0.27586206896551724  24 / 87
100.0  119.0  71.0  125.0  98.0  83.0  84.0  77.0  77.0  101.0  89.0  92.0  95.0  99.0  81.0  114.0  89.0  120.0  96.0  98.0  107.0  83.0  106.0  91.0  106.0  89.0  0.21927710843373494  546 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780723
2    0.880723
3    0.91486
4    0.934137
5    0.946988
6    0.957028
7    0.965462
8    0.971486
9    0.976305
10   0.980723
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:22  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:23  1 min 20.860 sec  50035 obs/sec     1         1             10007      0.585526         1.09859             0.993908       0.298011                         0.584195           1.09417               0.993919         0.299598
    2019-08-04 09:01:24  1 min 22.629 sec  51796 obs/sec     10        10            100070     0.468359         0.752435            0.996102       0.214536                         0.471885           0.769621              0.996032         0.219277
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0880421
C9          0.933765               0.933765             0.0822106
C12         0.915913               0.915913             0.0806389
C13         0.908671               0.908671             0.0800013
C11         0.837235               0.837235             0.0737119
C7          0.802103               0.802103             0.0706188
C8          0.789349               0.789349             0.0694959
C14         0.708138               0.708138             0.062346
C10         0.651                  0.651                0.0573154
C3          0.616561               0.616561             0.0542833
C6          0.593715               0.593715             0.0522719
C4          0.58222                0.58222              0.0512599
C16         0.57581                0.57581              0.0506955
C5          0.545984               0.545984             0.0480696
C2          0.463298               0.463298             0.0407898
C1          0.43444                0.43444              0.038249
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_196

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011191033554496244  0.00035286787897348404  0.0         0.032379699985881416   0.5583457946777344  -0.031173408405370175  0.5611331462860107
    3        26       Softmax                 0.0   0.0   0.0023085665945053245  0.0006374239455908537   0.0         -0.040638121012727006  0.7403318881988525  -0.5365606297326141    0.2951117753982544


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2220965998544025
RMSE: 0.47127125931293806
LogLoss: 0.7512772350662374
Mean Per-Class Error: 0.21342789434885343
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    0.0    1.0    4.0    1.0    0.0    1.0    0.0    3.0    6.0    0.0    1.0    0.0    3.0    5.0    4.0    0.0    0.08354430379746836  33 / 395
1.0    316.0  0.0    10.0   3.0    3.0    1.0    7.0    2.0    0.0    3.0    0.0    1.0    0.0    0.0    3.0    1.0    19.0   6.0    0.0    0.0    3.0    0.0    3.0    1.0    0.0    0.17493472584856398  67 / 383
0.0    0.0    294.0  0.0    16.0   1.0    7.0    0.0    0.0    0.0    9.0    6.0    1.0    0.0    15.0   1.0    6.0    0.0    3.0    2.0    1.0    0.0    6.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
1.0    25.0   0.0    321.0  0.0    2.0    0.0    2.0    0.0    8.0    0.0    0.0    7.0    5.0    3.0    0.0    5.0    11.0   5.0    3.0    0.0    0.0    0.0    3.0    0.0    2.0    0.20347394540942929  82 / 403
0.0    9.0    5.0    1.0    300.0  1.0    3.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    15.0   6.0    22.0   3.0    1.0    0.0    0.0    5.0    0.0    10.0   0.21875              84 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    10.0   0.0    18.0   2.0    3.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    3.0    0.0    8.0    3.0    4.0    0.0    2.0    3.0    0.0    10.0   0.0    0.0    0.0    2.0    1.0    8.0    0.0    13.0   5.0    2.0    0.0    0.0    319.0  5.0    5.0    0.18829516539440203  74 / 393
0.0    0.0    0.0    3.0    0.0    5.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    34.0   4.0    31.0   2.0    1.0    303.0  0.0    0.22900763358778625  90 / 393
1.0    1.0    0.0    0.0    29.0   0.0    1.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    31.0   3.0    0.0    0.0    0.0    2.0    0.0    282.0  0.23160762942779292  85 / 367
419.0  473.0  356.0  432.0  419.0  394.0  307.0  294.0  331.0  345.0  406.0  341.0  445.0  377.0  389.0  405.0  393.0  433.0  359.0  380.0  397.0  364.0  408.0  413.0  376.0  347.0  0.21243626911926422  2,125 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787564
2    0.873238
3    0.910927
4    0.930121
5    0.946016
6    0.958512
7    0.96771
8    0.975607
9    0.980106
10   0.984005

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22661452146012398
RMSE: 0.4760404619988977
LogLoss: 0.7698981806341563
Mean Per-Class Error: 0.2240927419676222
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10     11    12    13    14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    2.0   2.0    0.0   0.06741573033707865  6 / 89
0.0    81.0   0.0   3.0    2.0    1.0   1.0   2.0   1.0   0.0   2.0    0.0   0.0   0.0   0.0   1.0    0.0    7.0    1.0   0.0   0.0    3.0   0.0    1.0   0.0    0.0   0.2358490566037736   25 / 106
0.0    0.0    59.0  0.0    2.0    0.0   2.0   0.0   0.0   0.0   3.0    2.0   0.0   0.0   6.0   1.0    3.0    0.0    1.0   1.0   0.0    0.0   2.0    0.0   0.0    0.0   0.2804878048780488   23 / 82
1.0    2.0    0.0   87.0   0.0    1.0   0.0   2.0   0.0   3.0   0.0    0.0   3.0   2.0   0.0   0.0    3.0    4.0    2.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.22321428571428573  25 / 112
0.0    2.0    1.0   0.0    74.0   1.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    3.0    2.0    6.0   1.0   0.0    0.0   0.0    1.0   0.0    4.0   0.23711340206185566  23 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0   4.0   1.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0    1.0    0.0   3.0    2.0    0.0   0.0   2.0   1.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    3.0   0.0   1.0    0.0   0.0    78.0  1.0    2.0   0.22                 22 / 100
0.0    0.0    0.0   1.0    0.0    2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   7.0   1.0    10.0  1.0    0.0   83.0   0.0   0.22429906542056074  24 / 107
0.0    0.0    0.0   0.0    9.0    0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0   0.0   0.0   1.0    1.0    1.0    8.0   1.0   0.0    0.0   0.0    0.0   0.0    64.0  0.26436781609195403  23 / 87
102.0  118.0  73.0  117.0  100.0  91.0  78.0  83.0  76.0  99.0  104.0  89.0  97.0  98.0  82.0  115.0  102.0  105.0  95.0  85.0  102.0  87.0  105.0  99.0  102.0  86.0  0.22329317269076304  556 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.776707
2    0.871084
3    0.908434
4    0.926104
5    0.942169
6    0.959036
7    0.966667
8    0.976305
9    0.97992
10   0.984337
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:46  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:46  5 min 44.603 sec  131671 obs/sec    1         1             10007      0.642825         1.28955             0.992657       0.336499                         0.644206           1.29436               0.992605         0.34257
    2019-08-04 09:05:47  5 min 45.306 sec  130810 obs/sec    10        10            100070     0.471271         0.751277            0.996053       0.212436                         0.47604            0.769898              0.995962         0.223293
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0947434
C9          0.934947               0.934947             0.0885801
C13         0.891249               0.891249             0.0844399
C12         0.852161               0.852161             0.0807365
C8          0.818558               0.818558             0.0775529
C11         0.684638               0.684638             0.0648649
C16         0.68141                0.68141              0.064559
C10         0.672462               0.672462             0.0637113
C7          0.656881               0.656881             0.0622351
C14         0.633731               0.633731             0.0600418
C6          0.605615               0.605615             0.057378
C5          0.546409               0.546409             0.0517686
C4          0.489673               0.489673             0.0463933
C3          0.428215               0.428215             0.0405705
C1          0.331497               0.331497             0.0314071
C2          0.327385               0.327385             0.0310175
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_8

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0014121432913043463  0.000375766190700233   0.0         0.033674202871253556   0.754105806350708    0.1796014626135618    0.8229038715362549
    3        26       Softmax                 0.0   0.0   0.0019610350311547965  0.0003433638485148549  0.0         -0.006162163553146736  0.49789273738861084  -0.44837429930837724  0.22235465049743652


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22867224862129348
RMSE: 0.47819687224122814
LogLoss: 0.7686881393107058
Mean Per-Class Error: 0.2258140419784801
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    6.0    3.0    1.0    9.0    1.0    2.0    0.0    1.0    0.0    5.0    0.0    2.0    0.0    0.0    2.0    5.0    2.0    0.10913705583756345  43 / 394
0.0    266.0  0.0    5.0    1.0    5.0    1.0    8.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    42.0   34.0   0.0    1.0    4.0    0.0    4.0    4.0    0.0    0.3036649214659686   116 / 382
0.0    0.0    288.0  1.0    22.0   1.0    6.0    3.0    0.0    0.0    23.0   1.0    1.0    0.0    6.0    0.0    3.0    0.0    5.0    1.0    6.0    0.0    1.0    0.0    0.0    0.0    0.21739130434782608  80 / 368
2.0    12.0   0.0    315.0  0.0    4.0    0.0    9.0    1.0    11.0   0.0    1.0    3.0    7.0    4.0    2.0    0.0    17.0   4.0    1.0    0.0    0.0    0.0    6.0    0.0    4.0    0.21836228287841192  88 / 403
0.0    7.0    1.0    0.0    289.0  2.0    7.0    0.0    2.0    0.0    7.0    4.0    0.0    0.0    0.0    2.0    10.0   3.0    14.0   2.0    2.0    0.0    0.0    13.0   0.0    19.0   0.24739583333333334  95 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    8.0    13.0   5.0    0.0    0.0    5.0    0.0    0.0    7.0    3.0    322.0  0.0    0.0    0.0    0.14361702127659576  54 / 376
0.0    3.0    1.0    13.0   10.0   2.0    1.0    3.0    3.0    1.0    8.0    0.0    0.0    0.0    2.0    0.0    7.0    1.0    5.0    2.0    4.0    0.0    0.0    314.0  9.0    5.0    0.20304568527918782  80 / 394
0.0    0.0    0.0    2.0    0.0    10.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    7.0    0.0    4.0    35.0   2.0    31.0   1.0    1.0    294.0  0.0    0.25190839694656486  99 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    50.0   7.0    0.0    0.0    0.0    2.0    1.0    282.0  0.23160762942779292  85 / 367
413.0  427.0  339.0  417.0  392.0  380.0  335.0  361.0  334.0  379.0  361.0  344.0  424.0  377.0  410.0  410.0  324.0  499.0  424.0  378.0  407.0  382.0  380.0  405.0  366.0  335.0  0.22503249025292413  2,251 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.774968
2    0.873338
3    0.911826
4    0.93432
5    0.951415
6    0.961811
7    0.970109
8    0.975407
9    0.980506
10   0.984105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.23016653627436232
RMSE: 0.47975674698159515
LogLoss: 0.7707070237353327
Mean Per-Class Error: 0.229308624813982
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   1.0    2.0    0.0   0.10112359550561797  9 / 89
0.0   69.0   0.0   1.0    1.0   0.0   1.0   4.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   13.0   8.0    0.0   1.0    3.0   0.0   2.0    1.0    0.0   0.3490566037735849   37 / 106
0.0   0.0    60.0  0.0    3.0   1.0   2.0   0.0   0.0   0.0    7.0   0.0   0.0   0.0   2.0   0.0    2.0   0.0    3.0    1.0   1.0    0.0   0.0   0.0    0.0    0.0   0.2682926829268293   22 / 82
1.0   1.0    0.0   87.0   0.0   1.0   0.0   7.0   0.0   2.0    0.0   0.0   1.0   2.0   2.0   2.0    0.0   4.0    2.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.22321428571428573  25 / 112
0.0   3.0    0.0   0.0    64.0  2.0   3.0   0.0   1.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    3.0   1.0    3.0    1.0   0.0    0.0   0.0   4.0    0.0    10.0  0.3402061855670103   33 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0   2.0    0.0    0.0   2.0    1.0   83.0  0.0    0.0    0.0   0.09782608695652174  9 / 92
0.0   0.0    0.0   5.0    3.0   0.0   0.0   2.0   1.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    2.0    0.0   0.0    0.0   0.0   76.0   3.0    1.0   0.24                 24 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   2.0    4.0   0.0    0.0    6.0   1.0    9.0   1.0   0.0    81.0   0.0   0.24299065420560748  26 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    9.0    3.0   0.0    0.0   0.0   1.0    0.0    68.0  0.21839080459770116  19 / 87
93.0  103.0  69.0  120.0  84.0  92.0  83.0  99.0  77.0  110.0  87.0  90.0  93.0  97.0  81.0  114.0  90.0  131.0  108.0  89.0  102.0  92.0  97.0  104.0  101.0  84.0  0.22971887550200804  572 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.770281
2    0.873494
3    0.912851
4    0.936546
5    0.953815
6    0.961847
7    0.973896
8    0.97751
9    0.980723
10   0.983133
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:20  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:20  18.286 sec  78795 obs/sec     1         1             10007      0.605829         1.16782             0.993476       0.319204                         0.602253           1.15394               0.993537         0.315261
    2019-08-04 09:00:21  19.443 sec  79864 obs/sec     10        10            100070     0.478197         0.768688            0.995935       0.225032                         0.479757           0.770707              0.995899         0.229719
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0869053
C15         0.920772               0.920772             0.08002
C12         0.909677               0.909677             0.0790557
C9          0.87468                0.87468              0.0760143
C11         0.82943                0.82943              0.0720819
C8          0.803781               0.803781             0.0698529
C7          0.765752               0.765752             0.0665479
C14         0.702464               0.702464             0.0610479
C5          0.659917               0.659917             0.0573503
C6          0.657715               0.657715             0.057159
C16         0.65572                0.65572              0.0569856
C10         0.625683               0.625683             0.0543752
C3          0.620097               0.620097             0.0538898
C4          0.598246               0.598246             0.0519908
C1          0.457143               0.457143             0.0397282
C2          0.425698               0.425698             0.0369954
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_163

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.001158256599978813   0.00037336861714720726  0.0         -0.027262133675037603  0.5877654552459717  -0.01219408561443262  0.5810432434082031
    3        26       Softmax                 0.0   0.0   0.0020668544370542243  0.00041223946027457714  0.0         -0.03339025169351281   0.7337281703948975  -0.5421508233595294   0.2817782163619995


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2283347110936276
RMSE: 0.477843814539466
LogLoss: 0.759859240064485
Mean Per-Class Error: 0.2173871433371821
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    5.0    2.0    0.0    8.0    1.0    0.0    0.0    0.0    2.0    3.0    0.0    1.0    0.0    6.0    0.0    6.0    0.0    0.09367088607594937  37 / 395
0.0    316.0  0.0    4.0    3.0    1.0    3.0    12.0   2.0    0.0    3.0    0.0    0.0    0.0    2.0    9.0    1.0    10.0   9.0    3.0    0.0    0.0    0.0    2.0    2.0    0.0    0.17277486910994763  66 / 382
0.0    0.0    280.0  1.0    23.0   1.0    13.0   1.0    1.0    0.0    14.0   2.0    0.0    0.0    6.0    0.0    1.0    0.0    1.0    0.0    9.0    1.0    6.0    1.0    0.0    7.0    0.2391304347826087   88 / 368
2.0    12.0   0.0    311.0  0.0    2.0    3.0    11.0   0.0    9.0    0.0    0.0    5.0    2.0    8.0    5.0    1.0    4.0    2.0    2.0    5.0    0.0    0.0    16.0   1.0    2.0    0.228287841191067    92 / 403
0.0    10.0   1.0    0.0    262.0  2.0    15.0   0.0    0.0    0.0    8.0    5.0    0.0    0.0    1.0    0.0    3.0    5.0    20.0   10.0   0.0    0.0    0.0    18.0   2.0    22.0   0.3177083333333333   122 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    3.0    10.0   0.0    0.0    0.0    0.0    9.0    4.0    3.0    0.0    0.0    2.0    0.0    2.0    0.0    2.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    8.0    0.0    11.0   11.0   0.0    2.0    2.0    2.0    3.0    11.0   0.0    0.0    0.0    3.0    0.0    4.0    1.0    3.0    4.0    2.0    1.0    0.0    317.0  5.0    4.0    0.19543147208121828  77 / 394
1.0    1.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    7.0    0.0    3.0    49.0   1.0    20.0   1.0    1.0    290.0  4.0    0.26208651399491095  103 / 393
2.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    1.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    27.0   2.0    0.0    0.0    0.0    5.0    2.0    297.0  0.1907356948228883   70 / 367
393.0  480.0  308.0  443.0  365.0  348.0  410.0  312.0  334.0  365.0  383.0  341.0  415.0  393.0  411.0  408.0  358.0  377.0  351.0  424.0  409.0  387.0  422.0  400.0  369.0  397.0  0.21653503948815356  2,166 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783465
2    0.872038
3    0.912326
4    0.93452
5    0.949215
6    0.959612
7    0.968509
8    0.974208
9    0.979006
10   0.982205

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.23338669242597554
RMSE: 0.48310112029054075
LogLoss: 0.7727074139407596
Mean Per-Class Error: 0.22577755225291007
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17    18    19     20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   0.0    0.0   0.0    0.0   1.0   1.0   0.0    0.0   0.0   2.0    0.0   2.0    0.0    0.10112359550561797  9 / 89
0.0   84.0   0.0   1.0    2.0   0.0   1.0   4.0   1.0   0.0    3.0    0.0   0.0   0.0    1.0   2.0    0.0   3.0   0.0   2.0    0.0   0.0   0.0    1.0   1.0    0.0    0.20754716981132076  22 / 106
0.0   0.0    57.0  0.0    4.0   0.0   5.0   0.0   0.0   0.0    3.0    1.0   0.0   0.0    3.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0   2.0    1.0   0.0    3.0    0.3048780487804878   25 / 82
2.0   2.0    0.0   90.0   0.0   1.0   2.0   3.0   0.0   2.0    0.0    0.0   2.0   1.0    1.0   0.0    0.0   2.0   0.0   0.0    2.0   0.0   0.0    1.0   0.0    1.0    0.19642857142857142  22 / 112
0.0   3.0    0.0   0.0    66.0  2.0   2.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0    1.0   0.0    1.0   2.0   5.0   3.0    0.0   0.0   0.0    2.0   0.0    7.0    0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0   3.0   2.0    1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0   2.0    0.0   3.0    4.0   0.0   1.0   1.0   0.0   0.0    6.0    0.0   0.0   0.0    1.0   0.0    0.0   1.0   0.0   1.0    0.0   1.0   0.0    75.0  3.0    1.0    0.25                 25 / 100
0.0   1.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   4.0    2.0   0.0   0.0   10.0   0.0   6.0   1.0    0.0   82.0   0.0    0.2336448598130841   25 / 107
0.0   0.0    0.0   0.0    7.0   0.0   0.0   0.0   1.0   3.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   6.0   1.0    0.0   0.0   0.0    1.0   1.0    67.0   0.22988505747126436  20 / 87
92.0  127.0  61.0  127.0  96.0  75.0  98.0  86.0  77.0  102.0  102.0  90.0  94.0  103.0  83.0  118.0  90.0  93.0  87.0  102.0  99.0  89.0  105.0  92.0  102.0  100.0  0.22409638554216868  558 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.775904
2    0.873896
3    0.91245
4    0.936145
5    0.950201
6    0.959839
7    0.967871
8    0.973494
9    0.978313
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:37  4 min 34.900 sec  129961 obs/sec    1         1             10007      0.67476          1.40604             0.991909       0.379686                         0.674316           1.39884               0.991898         0.378715
    2019-08-04 09:04:37  4 min 35.585 sec  133604 obs/sec    10        10            100070     0.477844         0.759859            0.995942       0.216535                         0.483101           0.772707              0.995841         0.224096
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0938219
C13         0.968363               0.968363             0.0908537
C8          0.900903               0.900903             0.0845244
C12         0.863056               0.863056             0.0809736
C9          0.811968               0.811968             0.0761804
C11         0.769285               0.769285             0.0721758
C7          0.758629               0.758629             0.071176
C14         0.677721               0.677721             0.0635851
C10         0.624655               0.624655             0.0586064
C16         0.607032               0.607032             0.0569529
C6          0.570309               0.570309             0.0535075
C5          0.512023               0.512023             0.048039
C4          0.4679                 0.4679               0.0438992
C3          0.465544               0.465544             0.0436782
C1          0.370729               0.370729             0.0347825
C2          0.290375               0.290375             0.0272435
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_132

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.001179506344044512   0.00038065563421696424  0.0         0.003215484051402484  0.603024959564209   -0.0653964272440971   0.6823010444641113
    3        26       Softmax                 0.0   0.0   0.0020863007302978076  0.0004148536827415228   0.0         0.005652443373736997  0.7512011528015137  -0.49707284964966286  0.2343927025794983


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.23540611167002443
RMSE: 0.4851866771357437
LogLoss: 0.782445837566837
Mean Per-Class Error: 0.22525348716040086
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    2.0    1.0    4.0    0.0    0.0    1.0    1.0    4.0    1.0    0.0    3.0    1.0    4.0    0.0    4.0    2.0    0.08607594936708861  34 / 395
1.0    289.0  0.0    8.0    2.0    1.0    5.0    21.0   4.0    1.0    1.0    0.0    0.0    0.0    2.0    4.0    0.0    23.0   13.0   0.0    0.0    1.0    2.0    3.0    2.0    0.0    0.2454308093994778   94 / 383
0.0    0.0    289.0  0.0    21.0   6.0    14.0   2.0    0.0    0.0    12.0   0.0    0.0    0.0    6.0    0.0    3.0    0.0    8.0    0.0    1.0    1.0    5.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
1.0    23.0   0.0    313.0  1.0    2.0    0.0    6.0    0.0    17.0   4.0    1.0    4.0    5.0    10.0   1.0    0.0    7.0    0.0    0.0    1.0    0.0    0.0    7.0    0.0    0.0    0.22332506203473945  90 / 403
0.0    14.0   5.0    1.0    280.0  2.0    20.0   1.0    1.0    0.0    4.0    2.0    0.0    0.0    0.0    1.0    1.0    4.0    21.0   0.0    1.0    0.0    0.0    4.0    0.0    22.0   0.2708333333333333   104 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    2.0    0.0    0.0    0.0    12.0   0.0    0.0    2.0    0.0    15.0   4.0    1.0    1.0    1.0    10.0   0.0    0.0    5.0    3.0    319.0  0.0    0.0    0.0    0.15159574468085107  57 / 376
0.0    5.0    0.0    6.0    6.0    0.0    0.0    4.0    6.0    0.0    6.0    2.0    0.0    0.0    0.0    1.0    5.0    0.0    7.0    8.0    1.0    0.0    0.0    330.0  3.0    4.0    0.16243654822335024  64 / 394
3.0    2.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    2.0    0.0    2.0    11.0   2.0    18.0   0.0    4.0    331.0  0.0    0.15776081424936386  62 / 393
3.0    2.0    0.0    1.0    23.0   2.0    0.0    0.0    1.0    14.0   0.0    3.0    0.0    0.0    0.0    0.0    3.0    0.0    35.0   5.0    0.0    0.0    0.0    0.0    2.0    272.0  0.2568306010928962   94 / 366
396.0  444.0  364.0  425.0  397.0  385.0  347.0  333.0  320.0  366.0  361.0  359.0  428.0  354.0  408.0  401.0  343.0  445.0  371.0  353.0  414.0  375.0  389.0  436.0  426.0  363.0  0.2240327901629511   2,241 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.775967
2    0.86624
3    0.905628
4    0.929221
5    0.945017
6    0.957213
7    0.96511
8    0.970909
9    0.977307
10   0.982105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.24098377707977475
RMSE: 0.4909009850059121
LogLoss: 0.8012975354750083
Mean Per-Class Error: 0.2262070196002188
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   1.0    0.0   2.0   0.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   73.0   0.0   2.0    1.0   1.0   3.0   8.0   1.0   0.0    0.0   0.0   0.0   0.0   2.0   1.0    0.0   8.0    2.0   0.0   0.0    1.0   2.0   1.0    0.0    0.0   0.3113207547169811   33 / 106
0.0   0.0    61.0  0.0    3.0   1.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    4.0   0.0   0.0    0.0   2.0   0.0    0.0    0.0   0.25609756097560976  21 / 82
1.0   5.0    0.0   84.0   0.0   0.0   0.0   4.0   0.0   6.0    1.0   1.0   1.0   2.0   3.0   1.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0   0.25                 28 / 112
0.0   3.0    0.0   0.0    70.0  1.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    7.0   0.0   0.0    0.0   0.0   1.0    0.0    6.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   3.0   3.0   0.0   0.0    1.0   2.0    0.0   0.0   2.0    0.0   79.0  0.0    0.0    0.0   0.14130434782608695  13 / 92
0.0   2.0    0.0   1.0    1.0   0.0   0.0   0.0   1.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   1.0   0.0    0.0   0.0   86.0   1.0    3.0   0.14                 14 / 100
2.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0    0.0   2.0   1.0    5.0   0.0   2.0    89.0   0.0   0.16822429906542055  18 / 107
1.0   0.0    0.0   1.0    8.0   1.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0    6.0   2.0   0.0    0.0   0.0   0.0    2.0    63.0  0.27586206896551724  24 / 87
90.0  109.0  75.0  113.0  99.0  99.0  80.0  92.0  70.0  108.0  87.0  95.0  94.0  95.0  90.0  111.0  89.0  114.0  96.0  77.0  106.0  81.0  97.0  114.0  123.0  86.0  0.22690763052208834  565 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773092
2    0.859438
3    0.900402
4    0.926104
5    0.945381
6    0.957028
7    0.965462
8    0.969478
9    0.976305
10   0.97992
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:42  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:42  3 min 40.245 sec  115022 obs/sec    1         1             10007      0.671288         1.41583             0.991992       0.396181                         0.67098            1.41228               0.991978         0.395181
    2019-08-04 09:03:43  3 min 40.966 sec  126191 obs/sec    10        10            100070     0.485187         0.782446            0.995817       0.224033                         0.490901           0.801298              0.995706         0.226908
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0968996
C13         0.902554               0.902554             0.087457
C11         0.820862               0.820862             0.0795412
C9          0.803635               0.803635             0.0778719
C7          0.797343               0.797343             0.0772622
C12         0.790982               0.790982             0.0766458
C8          0.719192               0.719192             0.0696894
C14         0.69561                0.69561              0.0674043
C6          0.673432               0.673432             0.0652553
C10         0.582379               0.582379             0.0564323
C16         0.528305               0.528305             0.0511925
C5          0.479115               0.479115             0.046426
C3          0.453358               0.453358             0.0439301
C4          0.432371               0.432371             0.0418966
C1          0.337783               0.337783             0.032731
C2          0.303043               0.303043             0.0293648
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_54

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007836416814939184  0.0001850556582212448  0.0         -0.017458875048760092  0.29115188121795654  0.11084094151825365  0.2285955548286438
    3        26       Softmax                      0.0   0.0   0.004938607029893878   0.013058438897132874   0.0         -0.3722038148199107    0.8823604583740234   -0.5972769072551103  0.4256798028945923


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2543161516339987
RMSE: 0.504297681567146
LogLoss: 0.8033600859351279
Mean Per-Class Error: 0.21840074013424965
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    5.0    1.0    1.0    0.0    4.0    0.0    11.0   0.0    1.0    5.0    2.0    0.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    318.0  0.0    11.0   1.0    0.0    1.0    3.0    3.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    2.0    15.0   11.0   0.0    0.0    7.0    1.0    4.0    0.0    1.0    0.16971279373368145  65 / 383
0.0    0.0    305.0  0.0    11.0   0.0    12.0   0.0    0.0    0.0    24.0   0.0    1.0    0.0    1.0    0.0    3.0    1.0    4.0    2.0    1.0    0.0    3.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
1.0    32.0   0.0    317.0  0.0    1.0    1.0    7.0    1.0    7.0    1.0    1.0    7.0    3.0    5.0    2.0    0.0    9.0    3.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.21339950372208435  86 / 403
0.0    11.0   3.0    0.0    288.0  1.0    9.0    0.0    0.0    0.0    14.0   1.0    0.0    0.0    0.0    3.0    11.0   3.0    16.0   2.0    0.0    0.0    0.0    5.0    0.0    15.0   0.24607329842931938  94 / 382
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    2.0    0.0    19.0   11.0   2.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    323.0  0.0    0.0    0.0    0.14095744680851063  53 / 376
0.0    3.0    0.0    7.0    7.0    0.0    1.0    1.0    6.0    1.0    11.0   0.0    0.0    0.0    0.0    0.0    11.0   1.0    19.0   2.0    3.0    0.0    0.0    312.0  6.0    3.0    0.20812182741116753  82 / 394
0.0    1.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    12.0   0.0    10.0   24.0   3.0    35.0   1.0    0.0    294.0  0.0    0.25190839694656486  99 / 393
2.0    1.0    0.0    0.0    15.0   2.0    0.0    0.0    1.0    16.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    40.0   1.0    0.0    0.0    0.0    2.0    0.0    286.0  0.22070844686648503  81 / 367
409.0  534.0  383.0  421.0  381.0  338.0  326.0  292.0  347.0  352.0  434.0  324.0  442.0  380.0  365.0  419.0  358.0  414.0  412.0  365.0  387.0  420.0  414.0  366.0  344.0  376.0  0.21753473957812655  2,176 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782465
2    0.871838
3    0.910427
4    0.93252
5    0.949315
6    0.959612
7    0.96841
8    0.974008
9    0.978206
10   0.981605

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.25662086429460274
RMSE: 0.5065775994796875
LogLoss: 0.8123054818809532
Mean Per-Class Error: 0.22727787950945577
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16     17     18    19    20    21     22    23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0    1.0   0.0   0.0    1.0    0.0    1.0   0.0   0.0   2.0    0.0   0.0   2.0   0.0    0.0898876404494382   8 / 89
0.0   85.0   0.0   1.0    1.0   0.0   1.0   0.0   1.0   0.0    1.0    0.0   0.0    0.0   1.0   2.0    0.0    4.0    3.0   0.0   0.0   4.0    1.0   1.0   0.0   0.0    0.19811320754716982  21 / 106
0.0   0.0    64.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   1.0   0.0    1.0    0.0    3.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.21951219512195122  18 / 82
1.0   5.0    0.0   89.0   0.0   1.0   0.0   2.0   1.0   1.0    1.0    1.0   3.0    1.0   1.0   0.0    0.0    2.0    0.0   0.0   0.0   0.0    0.0   2.0   0.0   1.0    0.20535714285714285  23 / 112
0.0   2.0    0.0   0.0    66.0  1.0   2.0   0.0   0.0   0.0    7.0    0.0   0.0    0.0   0.0   0.0    4.0    1.0    5.0   1.0   0.0   0.0    0.0   1.0   0.0   7.0    0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0    0.0   4.0    0.0   1.0   0.0    0.0    0.0    0.0   0.0   0.0   1.0    84.0  0.0   0.0   0.0    0.08695652173913043  8 / 92
0.0   1.0    0.0   3.0    3.0   0.0   0.0   1.0   2.0   0.0    4.0    0.0   0.0    0.0   0.0   0.0    2.0    1.0    7.0   0.0   1.0   0.0    0.0   73.0  1.0   1.0    0.27                 27 / 100
0.0   1.0    0.0   1.0    0.0   2.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0    0.0   1.0   1.0    5.0    0.0    1.0   7.0   0.0   10.0   1.0   0.0   76.0  0.0    0.2897196261682243   31 / 107
0.0   0.0    0.0   0.0    5.0   1.0   0.0   0.0   0.0   6.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0    7.0   0.0   0.0   0.0    0.0   1.0   0.0   67.0   0.22988505747126436  20 / 87
95.0  134.0  81.0  117.0  91.0  80.0  79.0  74.0  85.0  104.0  107.0  89.0  102.0  99.0  71.0  121.0  100.0  100.0  98.0  86.0  96.0  106.0  98.0  87.0  90.0  100.0  0.22610441767068273  563 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773896
2    0.869076
3    0.904016
4    0.928112
5    0.948594
6    0.959036
7    0.967871
8    0.974699
9    0.977108
10   0.97992
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:37  1 min 35.541 sec  204224 obs/sec    1         1             10007      0.730625         1.58384             0.990513       0.406678                         0.732776           1.59041               0.990432         0.411245
    2019-08-04 09:01:38  1 min 35.954 sec  222377 obs/sec    10        10            100070     0.504298         0.80336             0.99548        0.217535                         0.506578           0.812305              0.995427         0.226104
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.090324
C13         0.97295                0.97295              0.0878807
C12         0.877651               0.877651             0.0792729
C9          0.876715               0.876715             0.0791883
C8          0.794317               0.794317             0.0717459
C11         0.767477               0.767477             0.0693216
C7          0.762432               0.762432             0.0688659
C10         0.653616               0.653616             0.0590372
C14         0.637006               0.637006             0.0575369
C5          0.62603                0.62603              0.0565455
C4          0.605146               0.605146             0.0546592
C6          0.576213               0.576213             0.0520458
C3          0.5509                 0.5509               0.0497595
C16         0.539618               0.539618             0.0487405
C2          0.423778               0.423778             0.0382773
C1          0.407409               0.407409             0.0367988
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_138

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007494588850249784  0.00018455652752891183  0.0         -0.015384818388994859  0.28483760356903076  0.07973903591013472  0.21987247467041016
    3        26       Softmax                      0.0   0.0   0.004685302474661932   0.00970153883099556     0.0         -0.3424334616716246    0.8981170654296875   -0.5993816313589341  0.48072826862335205


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.26198536741206185
RMSE: 0.5118450619201692
LogLoss: 0.8235953170585074
Mean Per-Class Error: 0.22773233170086757
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    3.0    1.0    8.0    0.0    8.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    2.0    0.0    6.0    0.0    0.10632911392405063  42 / 395
0.0    304.0  0.0    2.0    2.0    0.0    0.0    4.0    2.0    0.0    0.0    0.0    1.0    0.0    3.0    6.0    6.0    44.0   2.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    0.206266318537859    79 / 383
0.0    0.0    292.0  1.0    7.0    2.0    15.0   1.0    0.0    0.0    31.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    5.0    5.0    3.0    0.0    2.0    0.0    0.0    0.0    0.20435967302452315  75 / 367
1.0    25.0   0.0    308.0  1.0    1.0    1.0    9.0    0.0    2.0    5.0    0.0    7.0    2.0    8.0    1.0    1.0    10.0   10.0   0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.23573200992555832  95 / 403
0.0    10.0   0.0    0.0    295.0  1.0    18.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    10.0   7.0    8.0    1.0    1.0    0.0    0.0    9.0    1.0    22.0   0.23177083333333334  89 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    24.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    4.0    2.0    4.0    15.0   0.0    0.0    0.0    2.0    1.0    7.0    2.0    0.0    0.0    3.0    0.0    0.0    2.0    9.0    3.0    1.0    0.0    0.0    327.0  8.0    4.0    0.1700507614213198   67 / 394
0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    7.0    0.0    3.0    23.0   0.0    29.0   4.0    0.0    314.0  0.0    0.2010178117048346   79 / 393
0.0    1.0    0.0    0.0    26.0   0.0    1.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    36.0   3.0    0.0    0.0    0.0    0.0    0.0    284.0  0.22404371584699453  82 / 366
404.0  500.0  358.0  404.0  399.0  338.0  359.0  281.0  345.0  335.0  423.0  337.0  463.0  367.0  421.0  378.0  335.0  482.0  328.0  381.0  365.0  373.0  427.0  428.0  409.0  363.0  0.22673198040587825  2,268 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773268
2    0.872838
3    0.907828
4    0.928721
5    0.945017
6    0.958612
7    0.96711
8    0.974108
9    0.978307
10   0.983405

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.26467117263842505
RMSE: 0.5144620225424079
LogLoss: 0.8285286876633455
Mean Per-Class Error: 0.23112213633784465
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   2.0    0.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   78.0   0.0   0.0    2.0   0.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    0.0   2.0   2.0    2.0   13.0   0.0   0.0   0.0   2.0   0.0    2.0    0.0    0.0   0.2641509433962264   28 / 106
0.0   0.0    62.0  0.0    1.0   0.0   6.0   0.0   0.0   0.0   6.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0   2.0   1.0   0.0   0.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
1.0   6.0    0.0   89.0   0.0   0.0   0.0   1.0   0.0   1.0   1.0    0.0   3.0    1.0   2.0   0.0    0.0   4.0    1.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.20535714285714285  23 / 112
0.0   2.0    0.0   0.0    68.0  1.0   4.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    4.0   1.0    2.0   1.0   0.0   0.0   0.0    3.0    0.0    10.0  0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   6.0    0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   2.0    0.0   2.0    5.0   0.0   0.0   0.0   0.0   0.0   4.0    2.0   0.0    0.0   0.0   0.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0    77.0   3.0    2.0   0.23                 23 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0   0.0    3.0   0.0    0.0   8.0   0.0   7.0   2.0    0.0    83.0   0.0   0.22429906542056074  24 / 107
0.0   0.0    0.0   0.0    8.0   0.0   0.0   0.0   0.0   4.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0    0.0    0.0    68.0  0.21839080459770116  19 / 87
93.0  124.0  74.0  115.0  91.0  74.0  88.0  79.0  79.0  96.0  104.0  95.0  103.0  98.0  80.0  116.0  96.0  123.0  80.0  95.0  93.0  83.0  106.0  100.0  106.0  99.0  0.23052208835341365  574 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.769478
2    0.874297
3    0.910843
4    0.928916
5    0.94498
6    0.959839
7    0.966667
8    0.974699
9    0.97992
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:50  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:50  3 min 47.917 sec  185314 obs/sec    1         1             10007      0.756792         1.70343             0.989819       0.453564                         0.755493           1.69605               0.98983          0.45743
    2019-08-04 09:03:50  3 min 48.327 sec  221884 obs/sec    10        10            100070     0.511845         0.823595            0.995343       0.226732                         0.514462           0.828529              0.995284         0.230522
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0945683
C13         0.835548               0.835548             0.0790164
C9          0.822382               0.822382             0.0777713
C7          0.801609               0.801609             0.0758068
C8          0.782194               0.782194             0.0739708
C12         0.773452               0.773452             0.0731441
C5          0.698509               0.698509             0.0660568
C11         0.656529               0.656529             0.0620868
C4          0.643195               0.643195             0.0608259
C3          0.635013               0.635013             0.0600521
C14         0.5947                 0.5947               0.0562398
C6          0.58857                0.58857              0.0556601
C10         0.538409               0.538409             0.0509164
C16         0.470834               0.470834             0.044526
C2          0.380408               0.380408             0.0359745
C1          0.353014               0.353014             0.033384
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_200

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007575885196615673  0.0001936540356837213  0.0         -0.029968129782901087  0.2929260730743408  0.06243173801882172  0.19650310277938843
    3        26       Softmax                      0.0   0.0   0.00508108697368488    0.012317731976509094   0.0         -0.3786686393237827    0.8921682834625244  -0.589456271663704   0.4795224666595459


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2634754432586649
RMSE: 0.5132985907429173
LogLoss: 0.8234642054034876
Mean Per-Class Error: 0.22540771333475065
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    0.0    5.0    0.0    1.0    0.0    1.0    1.0    7.0    1.0    2.0    0.0    3.0    4.0    6.0    0.0    0.10126582278481013  40 / 395
0.0    321.0  0.0    8.0    5.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    12.0   20.0   8.0    0.0    0.0    0.0    1.0    2.0    2.0    0.0    0.1618798955613577   62 / 383
0.0    0.0    302.0  1.0    11.0   1.0    12.0   1.0    0.0    0.0    20.0   0.0    1.0    0.0    2.0    0.0    3.0    0.0    6.0    0.0    4.0    0.0    4.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
4.0    32.0   0.0    318.0  0.0    0.0    0.0    2.0    0.0    12.0   0.0    1.0    6.0    5.0    1.0    2.0    0.0    7.0    5.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.2109181141439206   85 / 403
0.0    11.0   0.0    0.0    292.0  1.0    6.0    2.0    0.0    0.0    3.0    0.0    0.0    0.0    1.0    2.0    16.0   3.0    13.0   5.0    0.0    0.0    0.0    9.0    0.0    19.0   0.23759791122715404  91 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    19.0   1.0    0.0    0.0    2.0    3.0    0.0    0.0    6.0    0.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
1.0    6.0    0.0    1.0    2.0    1.0    1.0    1.0    3.0    1.0    7.0    0.0    0.0    0.0    2.0    0.0    6.0    0.0    15.0   0.0    1.0    0.0    0.0    337.0  5.0    4.0    0.1446700507614213   57 / 394
0.0    0.0    0.0    0.0    0.0    15.0   3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    27.0   0.0    6.0    37.0   1.0    55.0   3.0    0.0    244.0  0.0    0.37755102040816324  148 / 392
1.0    0.0    0.0    0.0    25.0   1.0    1.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    25.0   1.0    0.0    0.0    0.0    8.0    0.0    281.0  0.23433242506811988  86 / 367
407.0  514.0  354.0  399.0  385.0  350.0  298.0  275.0  341.0  343.0  401.0  334.0  447.0  376.0  391.0  388.0  448.0  426.0  385.0  372.0  393.0  387.0  430.0  456.0  314.0  389.0  0.22453264020793762  2,246 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.775467
2    0.86784
3    0.905129
4    0.926622
5    0.942717
6    0.953514
7    0.963411
8    0.970909
9    0.976107
10   0.981905

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2670757134466714
RMSE: 0.5167936855715939
LogLoss: 0.8364491871830573
Mean Per-Class Error: 0.22748339411231322
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16     17     18    19    20    21    22     23     24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.0   1.0    2.0    3.0   0.0    0.0898876404494382   8 / 89
0.0   80.0   0.0   2.0    4.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   1.0   0.0    5.0    7.0    3.0   0.0   0.0   0.0   1.0    1.0    0.0   0.0    0.24528301886792453  26 / 106
0.0   0.0    63.0  0.0    2.0   1.0   4.0   1.0   0.0   0.0   4.0    0.0   0.0   0.0   2.0   0.0    1.0    0.0    2.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.23170731707317074  19 / 82
3.0   7.0    0.0   90.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0    1.0   2.0   2.0   0.0   0.0    0.0    0.0    2.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0    0.19642857142857142  22 / 112
0.0   5.0    0.0   0.0    67.0  1.0   0.0   1.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   1.0    6.0    1.0    3.0   2.0   0.0   0.0   0.0    1.0    0.0   8.0    0.30927835051546393  30 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0   0.0   0.0   0.0    2.0    0.0    0.0   0.0   1.0   0.0   84.0   0.0    0.0   0.0    0.08695652173913043  8 / 92
1.0   4.0    0.0   0.0    1.0   0.0   1.0   1.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    6.0   0.0   0.0   0.0   0.0    82.0   1.0   1.0    0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   3.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0    10.0   0.0    0.0   9.0   0.0   20.0  2.0    0.0    61.0  0.0    0.42990654205607476  46 / 107
0.0   0.0    0.0   0.0    6.0   1.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    5.0   0.0   0.0   0.0   0.0    4.0    0.0   66.0   0.2413793103448276   21 / 87
96.0  129.0  73.0  114.0  85.0  79.0  76.0  70.0  79.0  98.0  100.0  94.0  97.0  98.0  83.0  108.0  126.0  101.0  98.0  93.0  99.0  97.0  107.0  109.0  80.0  101.0  0.22771084337349398  567 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.772289
2    0.865462
3    0.902811
4    0.926104
5    0.941767
6    0.953815
7    0.964257
8    0.970281
9    0.973896
10   0.978313
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:53  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:53  5 min 51.185 sec  200140 obs/sec    1         1             10007      0.743422         1.64777             0.990177       0.440768                         0.744682           1.64959               0.990119         0.440161
    2019-08-04 09:05:53  5 min 51.578 sec  232720 obs/sec    10        10            100070     0.513299         0.823464            0.995317       0.224533                         0.516794           0.836449              0.995241         0.227711
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0946313
C15         0.906268               0.906268             0.0857613
C12         0.82331                0.82331              0.0779108
C9          0.811505               0.811505             0.0767938
C8          0.798021               0.798021             0.0755177
C7          0.75813                0.75813              0.0717428
C5          0.683853               0.683853             0.0647138
C14         0.66903                0.66903              0.0633112
C10         0.654348               0.654348             0.0619218
C3          0.619168               0.619168             0.0585926
C11         0.617362               0.617362             0.0584217
C4          0.589385               0.589385             0.0557743
C6          0.537744               0.537744             0.0508874
C16         0.450297               0.450297             0.0426122
C2          0.351513               0.351513             0.0332641
C1          0.297397               0.297397             0.0281431
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_136

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007778527241271149  0.0001869983389042318  0.0         -0.01880857589844709  0.2815699577331543  0.10019423575341338  0.22951537370681763
    3        26       Softmax                      0.0   0.0   0.004906180697686908   0.008459404110908508   0.0         -0.3566752824321716   0.8960957527160645  -0.5896465326000511  0.4677988290786743


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.26524767854088743
RMSE: 0.5150220175302095
LogLoss: 0.8347239027886666
Mean Per-Class Error: 0.2224498244820869
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    5.0    2.0    4.0    0.0    1.0    0.0    1.0    1.0    11.0   0.0    0.0    1.0    4.0    3.0    3.0    0.0    0.10632911392405063  42 / 395
0.0    331.0  0.0    5.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    1.0    2.0    13.0   14.0   0.0    0.0    2.0    0.0    3.0    1.0    0.0    0.13577023498694518  52 / 383
0.0    0.0    298.0  0.0    11.0   1.0    15.0   0.0    0.0    0.0    24.0   0.0    1.0    0.0    1.0    0.0    2.0    0.0    5.0    3.0    3.0    0.0    4.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
2.0    28.0   0.0    316.0  0.0    0.0    2.0    5.0    0.0    6.0    0.0    0.0    9.0    2.0    12.0   1.0    1.0    6.0    6.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.21393034825870647  86 / 402
0.0    20.0   3.0    0.0    279.0  2.0    27.0   0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    8.0    4.0    9.0    3.0    0.0    0.0    0.0    5.0    0.0    20.0   0.2734375            105 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    7.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    0.0    2.0    0.0    15.0   2.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    332.0  0.0    0.0    0.0    0.11702127659574468  44 / 376
0.0    8.0    0.0    2.0    9.0    0.0    1.0    3.0    2.0    2.0    7.0    0.0    0.0    0.0    2.0    0.0    12.0   1.0    4.0    0.0    3.0    1.0    0.0    331.0  6.0    0.0    0.1598984771573604   63 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0    18.0   0.0    7.0    11.0   1.0    23.0   0.0    1.0    320.0  0.0    0.18575063613231552  73 / 393
2.0    1.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    19.0   0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    30.0   2.0    0.0    0.0    0.0    6.0    0.0    281.0  0.23013698630136986  84 / 365
400.0  561.0  364.0  402.0  355.0  358.0  383.0  274.0  332.0  346.0  416.0  308.0  486.0  343.0  410.0  369.0  379.0  398.0  376.0  338.0  391.0  400.0  420.0  455.0  380.0  359.0  0.2214335699290213   2,215 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.778566
2    0.86514
3    0.90133
4    0.925522
5    0.943217
6    0.956313
7    0.96611
8    0.972008
9    0.977807
10   0.982105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.26528080188610814
RMSE: 0.51505417373914
LogLoss: 0.8374501039386011
Mean Per-Class Error: 0.21974458917407486
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16     17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0    3.0   0.0   0.0   0.0   2.0    1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   90.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   3.0   1.0    0.0    5.0    3.0   0.0   0.0   2.0   0.0    2.0    0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    62.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0   3.0    0.0   0.0    0.0   1.0   0.0    0.0    0.0    3.0   2.0   1.0   0.0   2.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
1.0   5.0    0.0   89.0   0.0   0.0   2.0   2.0   0.0   2.0   0.0    0.0   2.0    1.0   3.0   0.0    1.0    0.0    3.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.20535714285714285  23 / 112
0.0   2.0    0.0   0.0    70.0  2.0   7.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    3.0    1.0    2.0   0.0   0.0   0.0   0.0    2.0    0.0    7.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   4.0    0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0   1.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   2.0    0.0   1.0    5.0   0.0   1.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    3.0    1.0    1.0   0.0   0.0   0.0   0.0    82.0   1.0    0.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    1.0   1.0   0.0    6.0    0.0    0.0   4.0   0.0   3.0   0.0    0.0    90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    7.0   0.0   0.0   0.0   0.0   5.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0    0.0    8.0   0.0   0.0   0.0   0.0    2.0    0.0    64.0  0.26436781609195403  23 / 87
92.0  131.0  75.0  115.0  89.0  83.0  96.0  69.0  75.0  97.0  100.0  85.0  107.0  90.0  85.0  109.0  107.0  109.0  97.0  81.0  97.0  88.0  104.0  109.0  107.0  93.0  0.21847389558232932  544 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781526
2    0.865462
3    0.901205
4    0.923293
5    0.94257
6    0.95261
7    0.962249
8    0.969076
9    0.9751
10   0.97992
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:48  3 min 45.887 sec  192442 obs/sec    1         1             10007      0.742706         1.6291              0.990194       0.43197                          0.742363           1.63222               0.99018          0.432129
    2019-08-04 09:03:48  3 min 46.309 sec  220905 obs/sec    10        10            100070     0.515022         0.834724            0.995285       0.221434                         0.515054           0.83745               0.995273         0.218474
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0946663
C13         0.896776               0.896776             0.0848945
C12         0.809734               0.809734             0.0766546
C9          0.786173               0.786173             0.0744241
C7          0.766005               0.766005             0.0725149
C8          0.759729               0.759729             0.0719208
C6          0.678601               0.678601             0.0642407
C11         0.66375                0.66375              0.0628348
C14         0.619068               0.619068             0.0586049
C4          0.600731               0.600731             0.056869
C16         0.563783               0.563783             0.0533713
C10         0.555299               0.555299             0.0525681
C3          0.551508               0.551508             0.0522093
C5          0.53477                0.53477              0.0506248
C1          0.413658               0.413658             0.0391595
C2          0.363831               0.363831             0.0344425
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_126

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007533862005857372  0.00019908207468688488  0.0         -0.010467140083392223  0.2867398262023926  0.03552427928926966  0.2361791729927063
    3        26       Softmax                      0.0   0.0   0.005262076486920146   0.011883515864610672    0.0         -0.4353476619322604    0.8975589275360107  -0.5568475993344282  0.6557600498199463


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2645960343422254
RMSE: 0.5143889912723886
LogLoss: 0.8287511768910549
Mean Per-Class Error: 0.22969197631528407
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    4.0    7.0    0.0    5.0    0.0    0.0    1.0    3.0    0.0    2.0    3.0    3.0    1.0    4.0    0.0    0.10406091370558376  41 / 394
0.0    313.0  0.0    9.0    1.0    1.0    1.0    0.0    2.0    0.0    4.0    1.0    0.0    0.0    3.0    1.0    0.0    30.0   8.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.18276762402088773  70 / 383
0.0    0.0    294.0  0.0    15.0   0.0    24.0   1.0    0.0    0.0    17.0   0.0    1.0    0.0    3.0    0.0    4.0    1.0    5.0    1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
3.0    17.0   0.0    318.0  0.0    0.0    0.0    6.0    1.0    9.0    0.0    2.0    8.0    4.0    4.0    1.0    0.0    7.0    2.0    0.0    0.0    0.0    0.0    21.0   0.0    0.0    0.2109181141439206   85 / 403
0.0    5.0    7.0    0.0    288.0  1.0    23.0   0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    5.0    4.0    11.0   9.0    2.0    0.0    0.0    0.0    11.0   0.0    11.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    0.0    4.0    0.0    19.0   2.0    1.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    2.0    0.0    8.0    2.0    0.0    0.0    0.0    2.0    1.0    11.0   0.0    0.0    0.0    2.0    0.0    8.0    1.0    17.0   1.0    2.0    1.0    0.0    330.0  5.0    1.0    0.16243654822335024  64 / 394
0.0    1.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    4.0    1.0    5.0    0.0    10.0   30.0   1.0    17.0   1.0    0.0    312.0  0.0    0.20610687022900764  81 / 393
1.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    29.0   0.0    0.0    0.0    0.0    5.0    2.0    295.0  0.19618528610354224  72 / 367
396.0  502.0  372.0  416.0  355.0  390.0  332.0  303.0  345.0  365.0  384.0  366.0  459.0  358.0  370.0  354.0  337.0  512.0  363.0  370.0  352.0  362.0  426.0  481.0  377.0  356.0  0.22903129061281616  2,291 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.770969
2    0.86794
3    0.905428
4    0.928122
5    0.946216
6    0.956313
7    0.96641
8    0.971809
9    0.976807
10   0.981406

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.26888660875618775
RMSE: 0.5185427742782535
LogLoss: 0.8391323256872159
Mean Per-Class Error: 0.24303763993338945
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   1.0    1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   81.0   0.0   2.0    0.0   0.0   0.0   0.0   1.0   0.0    1.0    0.0   0.0    0.0   2.0   0.0    0.0   12.0   3.0   0.0   0.0   1.0   0.0    3.0    0.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    58.0  0.0    4.0   0.0   9.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   2.0   0.0    1.0   0.0    3.0   1.0   0.0   0.0   0.0    0.0    0.0    0.0   0.2926829268292683   24 / 82
3.0   3.0    0.0   89.0   0.0   0.0   0.0   2.0   0.0   3.0    0.0    2.0   3.0    1.0   1.0   0.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.20535714285714285  23 / 112
0.0   0.0    1.0   0.0    68.0  1.0   5.0   0.0   0.0   0.0    2.0    0.0   0.0    0.0   0.0   3.0    0.0   5.0    4.0   0.0   0.0   0.0   0.0    2.0    0.0    6.0   0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   6.0    0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   3.0    1.0   0.0   0.0   0.0   1.0   0.0    4.0    0.0   0.0    0.0   0.0   0.0    2.0   1.0    7.0   0.0   0.0   0.0   0.0    80.0   0.0    1.0   0.2                  20 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0    0.0   2.0   1.0    2.0   0.0    1.0   9.0   0.0   4.0   1.0    0.0    84.0   0.0   0.21495327102803738  23 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0    5.0   0.0   0.0   0.0   0.0    2.0    0.0    71.0  0.1839080459770115   16 / 87
92.0  116.0  76.0  113.0  82.0  87.0  81.0  72.0  86.0  103.0  102.0  98.0  104.0  93.0  80.0  103.0  93.0  140.0  96.0  90.0  90.0  81.0  103.0  114.0  102.0  93.0  0.2421686746987952   603 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.757831
2    0.865462
3    0.904016
4    0.927309
5    0.944177
6    0.953414
7    0.967068
8    0.971887
9    0.975502
10   0.980321
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:33  3 min 31.708 sec  192442 obs/sec    1         1             10007      0.727645         1.60622             0.990591       0.408577                         0.72879            1.6065                0.990536         0.402811
    2019-08-04 09:03:34  3 min 32.102 sec  231108 obs/sec    10        10            100070     0.514389         0.828751            0.995298       0.229031                         0.518543           0.839132              0.995209         0.242169
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.100065
C13         0.823233               0.823233             0.0823771
C9          0.800224               0.800224             0.0800747
C11         0.766988               0.766988             0.076749
C7          0.753493               0.753493             0.0753986
C12         0.726108               0.726108             0.0726582
C8          0.714042               0.714042             0.0714509
C10         0.59489                0.59489              0.0595279
C3          0.57931                0.57931              0.0579689
C6          0.559288               0.559288             0.0559654
C14         0.536812               0.536812             0.0537163
C16         0.506025               0.506025             0.0506356
C4          0.485547               0.485547             0.0485865
C5          0.481573               0.481573             0.0481888
C1          0.342653               0.342653             0.0342877
C2          0.323278               0.323278             0.032349
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_231

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007618275368486138  0.00018703017849475145  0.0         -0.016868045636329043  0.2791593074798584  0.08426974823129472  0.19981324672698975
    3        26       Softmax                      0.0   0.0   0.005228726833733022   0.012337915599346161    0.0         -0.3757821777841085    0.8890373706817627  -0.6041320063019978  0.49465370178222656


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2655134645669554
RMSE: 0.5152799865771573
LogLoss: 0.8312903461431483
Mean Per-Class Error: 0.22283875145988838
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
347.0  0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    5.0    7.0    2.0    5.0    1.0    10.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    2.0    3.0    6.0    0.0    0.12151898734177215  48 / 395
0.0    326.0  0.0    4.0    3.0    1.0    5.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    6.0    4.0    0.0    17.0   7.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.14882506527415143  57 / 383
0.0    3.0    295.0  1.0    14.0   0.0    8.0    1.0    0.0    0.0    27.0   0.0    0.0    0.0    3.0    0.0    3.0    0.0    6.0    0.0    4.0    0.0    1.0    0.0    0.0    1.0    0.19618528610354224  72 / 367
2.0    22.0   0.0    332.0  0.0    1.0    0.0    12.0   0.0    4.0    0.0    0.0    5.0    3.0    1.0    2.0    0.0    10.0   1.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.1761786600496278   71 / 403
0.0    7.0    2.0    0.0    308.0  1.0    12.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    7.0    5.0    14.0   1.0    0.0    0.0    0.0    6.0    0.0    16.0   0.195822454308094    75 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    2.0    0.0    11.0   0.0    1.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    5.0    0.0    10.0   7.0    0.0    4.0    2.0    2.0    2.0    10.0   2.0    0.0    0.0    0.0    0.0    8.0    4.0    5.0    4.0    4.0    0.0    0.0    320.0  3.0    2.0    0.18781725888324874  74 / 394
0.0    0.0    0.0    2.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    17.0   0.0    2.0    17.0   1.0    26.0   1.0    0.0    310.0  0.0    0.21119592875318066  83 / 393
1.0    0.0    0.0    0.0    16.0   0.0    1.0    0.0    2.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    32.0   2.0    0.0    0.0    0.0    2.0    1.0    296.0  0.19346049046321526  71 / 367
411.0  526.0  380.0  423.0  425.0  365.0  296.0  340.0  336.0  344.0  472.0  311.0  423.0  351.0  401.0  367.0  359.0  390.0  387.0  356.0  378.0  351.0  434.0  425.0  384.0  368.0  0.2221333599920024   2,222 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.777867
2    0.86694
3    0.904129
4    0.928821
5    0.946116
6    0.955413
7    0.96581
8    0.971009
9    0.977007
10   0.981406

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2683381701377401
RMSE: 0.5180136775585564
LogLoss: 0.8409244136817584
Mean Per-Class Error: 0.2301100068353444
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10     11    12    13    14    15     16     17    18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   2.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0   1.0    2.0    3.0    0.0    0.11235955056179775  10 / 89
0.0   86.0   0.0   1.0    2.0    0.0   1.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   3.0   1.0    0.0    5.0   2.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0    0.18867924528301888  20 / 106
0.0   1.0    62.0  0.0    3.0    0.0   4.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0   2.0   0.0    1.0    0.0   2.0   0.0   1.0   0.0   0.0    0.0    0.0    0.0    0.24390243902439024  20 / 82
2.0   4.0    0.0   92.0   0.0    0.0   0.0   3.0   0.0   2.0   0.0    0.0   2.0   2.0   0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0   0.0    2.0    0.0    1.0    0.17857142857142858  20 / 112
0.0   0.0    0.0   0.0    73.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    5.0    1.0   4.0   0.0   0.0   0.0   0.0    2.0    0.0    10.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   3.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   1.0    0.0   3.0    3.0    0.0   1.0   1.0   0.0   0.0   4.0    2.0   0.0   0.0   0.0   0.0    1.0    2.0   2.0   0.0   0.0   0.0   0.0    79.0   1.0    0.0    0.21                 21 / 100
0.0   0.0    0.0   1.0    0.0    5.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   2.0   0.0    4.0    0.0   0.0   2.0   0.0   11.0  1.0    0.0    81.0   0.0    0.24299065420560748  26 / 107
0.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   1.0   2.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   6.0   1.0   0.0   0.0   0.0    0.0    1.0    71.0   0.1839080459770115   16 / 87
98.0  129.0  82.0  114.0  100.0  89.0  72.0  87.0  81.0  96.0  116.0  84.0  96.0  89.0  78.0  104.0  104.0  96.0  97.0  78.0  91.0  81.0  112.0  111.0  104.0  101.0  0.22931726907630523  571 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.770683
2    0.857831
3    0.903614
4    0.927711
5    0.944578
6    0.953414
7    0.966667
8    0.971486
9    0.976707
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:46  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:46  6 min 44.721 sec  222377 obs/sec    1         1             10007      0.761362         1.71415             0.989698       0.435469                         0.761614           1.71532               0.989664         0.433735
    2019-08-04 09:06:47  6 min 45.112 sec  236014 obs/sec    10        10            100070     0.51528          0.83129             0.995281       0.222133                         0.518014           0.840924              0.995219         0.229317
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.102686
C9          0.806867               0.806867             0.0828541
C13         0.785236               0.785236             0.0806329
C12         0.738014               0.738014             0.0757838
C8          0.722198               0.722198             0.0741597
C7          0.716842               0.716842             0.0736097
C11         0.678587               0.678587             0.0696815
C14         0.601989               0.601989             0.0618159
C5          0.583666               0.583666             0.0599344
C10         0.561258               0.561258             0.0576335
C3          0.507478               0.507478             0.052111
C4          0.502401               0.502401             0.0515896
C6          0.470455               0.470455             0.0483092
C16         0.395288               0.395288             0.0405906
C1          0.353136               0.353136             0.0362622
C2          0.314999               0.314999             0.032346
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_205

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009517947081860711  0.00026159139815717936  0.0         -0.02234143309368619  0.24801784753799438  0.024842864248885366  0.1751173734664917
    3        26       Softmax                      0.0   0.0   0.005440022591756133   0.009354297071695328    0.0         -0.24239153643901984  0.7390093803405762   -0.8437003305246994   0.573371410369873


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2744893825740897
RMSE: 0.5239173432652232
LogLoss: 0.8387259742566989
Mean Per-Class Error: 0.21953056013568217
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    11.0   0.0    1.0    1.0    5.0    0.0    5.0    0.0    0.09620253164556962  38 / 395
0.0    324.0  0.0    4.0    2.0    0.0    1.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    5.0    26.0   7.0    1.0    0.0    2.0    0.0    1.0    1.0    0.0    0.15404699738903394  59 / 383
0.0    0.0    302.0  0.0    8.0    0.0    14.0   0.0    0.0    0.0    26.0   0.0    0.0    0.0    9.0    0.0    0.0    0.0    3.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
1.0    21.0   0.0    329.0  0.0    0.0    3.0    0.0    0.0    4.0    0.0    0.0    6.0    4.0    2.0    1.0    0.0    10.0   6.0    1.0    0.0    0.0    0.0    9.0    0.0    5.0    0.18159203980099503  73 / 402
0.0    16.0   0.0    0.0    290.0  1.0    10.0   1.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    14.0   4.0    5.0    1.0    1.0    0.0    0.0    5.0    0.0    29.0   0.24479166666666666  94 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    14.0   3.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    2.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    8.0    1.0    2.0    9.0    0.0    0.0    1.0    1.0    1.0    7.0    0.0    2.0    0.0    0.0    0.0    11.0   1.0    9.0    2.0    3.0    0.0    0.0    327.0  4.0    5.0    0.1700507614213198   67 / 394
0.0    1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    19.0   0.0    13.0   33.0   2.0    40.0   0.0    0.0    276.0  0.0    0.29770992366412213  117 / 393
0.0    0.0    0.0    0.0    13.0   0.0    1.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    38.0   3.0    0.0    0.0    0.0    1.0    0.0    293.0  0.1994535519125683   73 / 366
396.0  570.0  352.0  431.0  369.0  334.0  337.0  255.0  330.0  347.0  388.0  322.0  436.0  392.0  450.0  391.0  356.0  442.0  355.0  393.0  373.0  401.0  417.0  423.0  340.0  403.0  0.21853443966809957  2,186 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781466
2    0.871738
3    0.907728
4    0.931021
5    0.947216
6    0.960712
7    0.969509
8    0.975107
9    0.979806
10   0.984005

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.27659151245062785
RMSE: 0.5259196825092477
LogLoss: 0.8414518470178437
Mean Per-Class Error: 0.2193509037794599
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16     17     18    19    20    21    22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0   1.0   2.0    0.0   2.0   0.0    0.0898876404494382   8 / 89
0.0   84.0   0.0   1.0    2.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    2.0    7.0    2.0   0.0   0.0   2.0   0.0    1.0   1.0   0.0    0.20754716981132076  22 / 106
0.0   0.0    62.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0   5.0   0.0   0.0   0.0    4.0   0.0    0.0    0.0    2.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    0.24390243902439024  20 / 82
1.0   3.0    0.0   95.0   0.0   0.0   2.0   0.0   0.0   2.0   0.0   0.0   2.0   2.0    0.0   0.0    0.0    2.0    2.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0    0.15178571428571427  17 / 112
0.0   4.0    0.0   0.0    68.0  1.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    4.0    1.0    1.0   1.0   0.0   0.0   0.0    2.0   0.0   11.0   0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0   1.0   85.0   0.0   0.0   0.0    0.07608695652173914  7 / 92
0.0   4.0    0.0   0.0    5.0   0.0   0.0   1.0   0.0   0.0   3.0   0.0   1.0   0.0    0.0   0.0    2.0    0.0    6.0   1.0   1.0   0.0   0.0    75.0  0.0   1.0    0.25                 25 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0    7.0    0.0    3.0   9.0   0.0   12.0  0.0    0.0   72.0  0.0    0.32710280373831774  35 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   5.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    7.0   1.0   0.0   0.0   0.0    0.0   0.0   69.0   0.20689655172413793  18 / 87
92.0  137.0  70.0  123.0  84.0  81.0  89.0  65.0  80.0  99.0  98.0  87.0  99.0  102.0  90.0  109.0  102.0  114.0  93.0  95.0  93.0  96.0  102.0  95.0  91.0  104.0  0.21887550200803213  545 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781124
2    0.868675
3    0.911245
4    0.935743
5    0.951406
6    0.962249
7    0.971084
8    0.9751
9    0.981928
10   0.985542
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:02  5 min 59.760 sec  156359 obs/sec    1         1             10007      0.738086         1.58978             0.990317       0.389383                         0.739839           1.59349               0.990247         0.392771
    2019-08-04 09:06:02  6 min  0.299 sec  171352 obs/sec    10        10            100070     0.523917         0.838726            0.995121       0.218534                         0.52592            0.841452              0.995072         0.218876
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0986343
C13         0.874641               0.874641             0.0862696
C9          0.80291                0.80291              0.0791945
C8          0.754161               0.754161             0.0743862
C12         0.721624               0.721624             0.0711769
C11         0.703202               0.703202             0.0693599
C7          0.692712               0.692712             0.0683251
C5          0.607986               0.607986             0.0599683
C14         0.598067               0.598067             0.05899
C6          0.562973               0.562973             0.0555284
C10         0.545614               0.545614             0.0538163
C3          0.533867               0.533867             0.0526576
C4          0.526267               0.526267             0.051908
C16         0.457509               0.457509             0.0451261
C1          0.42073                0.42073              0.0414984
C2          0.336195               0.336195             0.0331604
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_240

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009569241856866029  0.0002506118034943938  0.0         -0.017325773107579323  0.24783581495285034  0.04884164345083187  0.17797255516052246
    3        26       Softmax                      0.0   0.0   0.005330769015035213   0.010862946510314941   0.0         -0.2785012143272769    0.7385432720184326   -0.8635999960229377  0.46599268913269043


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.27289702618274275
RMSE: 0.5223954691445387
LogLoss: 0.8374494827466179
Mean Per-Class Error: 0.21818485454417283
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  1.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    7.0    4.0    0.0    6.0    0.0    3.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    2.0    1.0    7.0    0.0    0.10406091370558376  41 / 394
0.0    319.0  0.0    5.0    2.0    0.0    5.0    6.0    2.0    0.0    4.0    0.0    0.0    0.0    1.0    2.0    0.0    26.0   4.0    0.0    0.0    1.0    0.0    4.0    1.0    0.0    0.1649214659685864   63 / 382
0.0    0.0    298.0  1.0    16.0   0.0    16.0   0.0    0.0    0.0    17.0   0.0    1.0    0.0    2.0    0.0    1.0    0.0    8.0    1.0    1.0    0.0    5.0    0.0    0.0    0.0    0.1880108991825613   69 / 367
4.0    22.0   0.0    324.0  0.0    1.0    1.0    6.0    1.0    3.0    1.0    0.0    7.0    3.0    3.0    5.0    0.0    6.0    5.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.19602977667493796  79 / 403
0.0    14.0   1.0    0.0    277.0  3.0    22.0   0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    2.0    5.0    8.0    6.0    0.0    0.0    0.0    14.0   0.0    22.0   0.2786458333333333   107 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    7.0    0.0    25.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    3.0    0.0    9.0    8.0    0.0    4.0    2.0    2.0    1.0    5.0    0.0    0.0    0.0    2.0    0.0    8.0    1.0    15.0   3.0    3.0    0.0    0.0    320.0  5.0    3.0    0.18781725888324874  74 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    6.0    0.0    3.0    18.0   0.0    15.0   1.0    0.0    334.0  0.0    0.15012722646310434  59 / 393
0.0    0.0    0.0    1.0    10.0   0.0    1.0    0.0    0.0    16.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    31.0   2.0    0.0    0.0    0.0    3.0    0.0    301.0  0.17983651226158037  66 / 367
403.0  544.0  354.0  440.0  368.0  319.0  367.0  264.0  346.0  346.0  457.0  321.0  479.0  364.0  410.0  402.0  301.0  382.0  365.0  380.0  372.0  356.0  435.0  412.0  414.0  402.0  0.21723482955113466  2,173 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782765
2    0.872638
3    0.912626
4    0.93492
5    0.949915
6    0.960912
7    0.968409
8    0.975307
9    0.980106
10   0.982905

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.27462465558284027
RMSE: 0.5240464250262951
LogLoss: 0.8427956004595918
Mean Per-Class Error: 0.22221027572219082
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17    18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0    0.0898876404494382   8 / 89
0.0   84.0   0.0   0.0    1.0   0.0   2.0   4.0   1.0   0.0   2.0    0.0   0.0    0.0   1.0   1.0    0.0   8.0   0.0   0.0   0.0   1.0   0.0    1.0   0.0    0.0    0.20754716981132076  22 / 106
0.0   0.0    62.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0   4.0    0.0   0.0    0.0   2.0   0.0    1.0   0.0   3.0   1.0   0.0   0.0   1.0    0.0   0.0    0.0    0.24390243902439024  20 / 82
3.0   4.0    0.0   91.0   0.0   0.0   1.0   3.0   1.0   0.0   0.0    0.0   3.0    1.0   0.0   1.0    0.0   1.0   1.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0    0.1875               21 / 112
0.0   2.0    0.0   0.0    65.0  2.0   6.0   0.0   0.0   0.0   3.0    0.0   0.0    0.0   0.0   0.0    1.0   1.0   2.0   3.0   0.0   0.0   0.0    3.0   0.0    9.0    0.32989690721649484  32 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   5.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    4.0   0.0   2.0   2.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    2.0   1.0   6.0   0.0   0.0   0.0   0.0    75.0  2.0    0.0    0.25                 25 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   3.0   1.0    3.0   0.0   0.0   4.0   0.0   4.0   1.0    0.0   91.0   0.0    0.14953271028037382  16 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   5.0   1.0   0.0   0.0   0.0    0.0   0.0    72.0   0.1724137931034483   15 / 87
99.0  136.0  70.0  123.0  84.0  70.0  99.0  75.0  84.0  97.0  113.0  85.0  107.0  98.0  81.0  117.0  82.0  98.0  86.0  89.0  92.0  78.0  105.0  97.0  116.0  109.0  0.22088353413654618  550 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779116
2    0.873494
3    0.912048
4    0.937349
5    0.951004
6    0.961044
7    0.968675
8    0.975502
9    0.980723
10   0.984739
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:07:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:07:02  6 min 59.820 sec  147161 obs/sec    1         1             10007      0.735702         1.56901             0.990378       0.36549                          0.735605           1.56936               0.990358         0.371084
    2019-08-04 09:07:02  7 min  0.353 sec  173131 obs/sec    10        10            100070     0.522395         0.837449            0.995149       0.217235                         0.524046           0.842796              0.995107         0.220884
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0942278
C13         0.944114               0.944114             0.0889618
C8          0.838736               0.838736             0.0790322
C12         0.816622               0.816622             0.0769484
C9          0.804152               0.804152             0.0757734
C11         0.742193               0.742193             0.0699352
C7          0.698736               0.698736             0.0658403
C10         0.623552               0.623552             0.0587559
C6          0.61053                0.61053              0.0575289
C5          0.580334               0.580334             0.0546836
C3          0.556899               0.556899             0.0524753
C14         0.544337               0.544337             0.0512916
C16         0.53285                0.53285              0.0502092
C4          0.525172               0.525172             0.0494858
C1          0.402156               0.402156             0.0378942
C2          0.392201               0.392201             0.0369563
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_118

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009430283307096943  0.0002349384012632072  0.0         -0.011736309753558771  0.24257242679595947  0.04541292230161143  0.1819121241569519
    3        26       Softmax                      0.0   0.0   0.005406404525344372   0.011533774435520172   0.0         -0.2705475488024656    0.7414669990539551   -0.8775142715707914  0.4981480836868286


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2769170994098574
RMSE: 0.5262291320421717
LogLoss: 0.8477904750744999
Mean Per-Class Error: 0.21712119241011127
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    4.0    1.0    9.0    0.0    5.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    2.0    3.0    6.0    0.0    0.10886075949367088  43 / 395
0.0    313.0  0.0    6.0    2.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    39.0   2.0    0.0    0.0    3.0    0.0    4.0    1.0    0.0    0.18276762402088773  70 / 383
0.0    0.0    300.0  0.0    5.0    1.0    16.0   2.0    0.0    0.0    28.0   0.0    1.0    0.0    0.0    0.0    1.0    0.0    7.0    1.0    0.0    0.0    6.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
3.0    17.0   0.0    320.0  0.0    0.0    1.0    2.0    0.0    5.0    0.0    0.0    3.0    7.0    2.0    4.0    0.0    13.0   2.0    1.0    0.0    0.0    0.0    22.0   0.0    0.0    0.20398009950248755  82 / 402
0.0    9.0    1.0    0.0    293.0  1.0    10.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    10.0   6.0    18.0   3.0    0.0    0.0    0.0    13.0   0.0    17.0   0.23697916666666666  91 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    10.0   1.0    0.0    0.0    0.0    8.0    0.0    0.0    2.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    7.0    0.0    2.0    6.0    0.0    0.0    0.0    3.0    1.0    4.0    1.0    0.0    0.0    0.0    0.0    23.0   3.0    9.0    1.0    4.0    0.0    0.0    321.0  6.0    3.0    0.18527918781725888  73 / 394
0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    10.0   1.0    17.0   0.0    8.0    33.0   0.0    19.0   1.0    0.0    295.0  0.0    0.24936386768447838  98 / 393
2.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    2.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    36.0   1.0    0.0    0.0    0.0    3.0    0.0    301.0  0.17983651226158037  66 / 367
429.0  495.0  357.0  425.0  359.0  323.0  322.0  236.0  363.0  336.0  404.0  333.0  448.0  372.0  381.0  393.0  373.0  498.0  393.0  384.0  381.0  367.0  441.0  446.0  375.0  369.0  0.21633509947015894  2,164 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783665
2    0.873638
3    0.908527
4    0.930121
5    0.948715
6    0.958113
7    0.96841
8    0.973908
9    0.979206
10   0.983405

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2776848017309053
RMSE: 0.5269580644898656
LogLoss: 0.85305121738383
Mean Per-Class Error: 0.22396246949547455
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16     17     18     19    20    21    22     23     24    25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  ----  ----  ----  -----  -----  ----  ----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0   0.0    0.0   0.0    0.0    0.0    1.0    0.0   0.0   0.0   1.0    1.0    3.0   0.0   0.11235955056179775  10 / 89
0.0    79.0   0.0   2.0    2.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    4.0   0.0    0.0    12.0   1.0    0.0   0.0   3.0   0.0    2.0    0.0   0.0   0.25471698113207547  27 / 106
0.0    0.0    61.0  0.0    1.0   0.0   7.0   1.0   0.0   0.0   6.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    3.0    1.0   0.0   0.0   2.0    0.0    0.0   0.0   0.25609756097560976  21 / 82
2.0    5.0    0.0   93.0   0.0   0.0   1.0   0.0   0.0   2.0   0.0    0.0   1.0   3.0    0.0   0.0    0.0    2.0    0.0    0.0   0.0   0.0   0.0    3.0    0.0   0.0   0.16964285714285715  19 / 112
0.0    1.0    0.0   0.0    71.0  1.0   2.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    4.0    1.0    5.0    1.0   0.0   0.0   0.0    3.0    0.0   6.0   0.26804123711340205  26 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---   ---   ---   ---    ---    ---   ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0   0.0    0.0   0.0    0.0    2.0    0.0    0.0   0.0   0.0   87.0   0.0    0.0   0.0   0.05434782608695652  5 / 92
0.0    2.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0   2.0    1.0   0.0   0.0    0.0   0.0    4.0    2.0    5.0    0.0   1.0   0.0   0.0    79.0   0.0   1.0   0.21                 21 / 100
0.0    0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    5.0   1.0    8.0    0.0    1.0    9.0   0.0   5.0   1.0    0.0    75.0  0.0   0.29906542056074764  32 / 107
1.0    0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    8.0    0.0   0.0   0.0   0.0    2.0    0.0   71.0  0.1839080459770115   16 / 87
103.0  117.0  71.0  125.0  83.0  72.0  80.0  59.0  87.0  99.0  104.0  88.0  99.0  106.0  73.0  112.0  106.0  129.0  101.0  94.0  95.0  80.0  108.0  107.0  98.0  94.0  0.22208835341365463  553 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.777912
2    0.871888
3    0.909237
4    0.931325
5    0.946586
6    0.957831
7    0.96747
8    0.972691
9    0.978313
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:19  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:19  3 min 16.918 sec  129961 obs/sec    1         1             10007      0.742431         1.62867             0.990205       0.402079                         0.741792           1.61514               0.990195         0.398394
    2019-08-04 09:03:19  3 min 17.489 sec  159347 obs/sec    10        10            100070     0.526229         0.84779             0.995079       0.216335                         0.526958           0.853051              0.995052         0.222088
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0949744
C13         0.866555               0.866555             0.0823005
C9          0.848618               0.848618             0.080597
C8          0.841973               0.841973             0.0799659
C7          0.795365               0.795365             0.0755393
C12         0.794668               0.794668             0.0754732
C11         0.72755                0.72755              0.0690986
C10         0.593562               0.593562             0.0563732
C6          0.585313               0.585313             0.0555898
C14         0.576984               0.576984             0.0547987
C5          0.571931               0.571931             0.0543188
C3          0.552439               0.552439             0.0524675
C4          0.534263               0.534263             0.0507413
C16         0.5207                 0.5207               0.0494532
C1          0.376014               0.376014             0.0357117
C2          0.343216               0.343216             0.0325967
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_91

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.000771796562844429  0.0001895406749099493  0.0         -0.02125947310594256  0.27976202964782715  0.08444499346559531  0.21025162935256958
    3        26       Softmax                      0.0   0.0   0.004674344863675428  0.0077760908752679825  0.0         -0.40888040789398544  0.8751599788665771   -0.5831630695547645  0.4840822219848633


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.27318099622637554
RMSE: 0.5226671945190128
LogLoss: 0.8493002025310977
Mean Per-Class Error: 0.2295443672672407
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    9.0    2.0    0.0    7.0    0.0    1.0    0.0    3.0    0.0    7.0    0.0    1.0    1.0    5.0    4.0    3.0    0.0    0.11392405063291139  45 / 395
0.0    314.0  0.0    3.0    2.0    0.0    7.0    4.0    3.0    0.0    0.0    0.0    1.0    0.0    1.0    5.0    2.0    28.0   4.0    1.0    1.0    1.0    1.0    3.0    2.0    0.0    0.1801566579634465   69 / 383
0.0    0.0    296.0  1.0    9.0    0.0    15.0   0.0    0.0    0.0    16.0   0.0    1.0    0.0    8.0    0.0    1.0    0.0    1.0    6.0    3.0    0.0    7.0    1.0    3.0    0.0    0.1956521739130435   72 / 368
4.0    29.0   0.0    300.0  0.0    0.0    3.0    11.0   0.0    8.0    0.0    0.0    7.0    4.0    3.0    3.0    2.0    7.0    6.0    1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.2537313432835821   102 / 402
0.0    5.0    0.0    0.0    297.0  1.0    16.0   1.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    2.0    6.0    19.0   0.0    0.0    0.0    0.0    12.0   0.0    18.0   0.2265625            87 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    0.0    3.0    0.0    10.0   2.0    1.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    4.0    0.0    1.0    9.0    0.0    4.0    6.0    2.0    1.0    3.0    2.0    0.0    0.0    0.0    0.0    24.0   1.0    19.0   2.0    5.0    0.0    0.0    300.0  3.0    8.0    0.23857868020304568  94 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    26.0   0.0    9.0    36.0   4.0    40.0   2.0    1.0    269.0  0.0    0.3155216284987277   124 / 393
7.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    27.0   3.0    0.0    0.0    0.0    3.0    0.0    310.0  0.1553133514986376   57 / 367
400.0  497.0  351.0  385.0  376.0  332.0  364.0  264.0  336.0  342.0  372.0  333.0  447.0  375.0  439.0  388.0  356.0  436.0  390.0  414.0  383.0  375.0  470.0  437.0  335.0  406.0  0.22883135059482154  2,289 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.771169
2    0.864441
3    0.904829
4    0.925122
5    0.941018
6    0.951515
7    0.961312
8    0.96801
9    0.973908
10   0.978906

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2748653289354531
RMSE: 0.5242760045390721
LogLoss: 0.8538581153157382
Mean Per-Class Error: 0.23812263230586414
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19     20     21    22     23     24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  -----  -----  ----  -----  -----  ----  -----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   2.0   0.0    0.0   0.0    1.0    0.0    1.0   0.0    0.0    0.0   2.0    1.0    2.0   0.0    0.11235955056179775  10 / 89
0.0   80.0   0.0   0.0    1.0   0.0   3.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   2.0    1.0    11.0   0.0   0.0    1.0    1.0   1.0    2.0    1.0   0.0    0.24528301886792453  26 / 106
0.0   0.0    60.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    1.0   3.0    1.0    0.0   2.0    0.0    1.0   0.0    0.2682926829268293   22 / 82
2.0   4.0    0.0   86.0   0.0   0.0   1.0   4.0   0.0   3.0    0.0   0.0   2.0   2.0    0.0   2.0    0.0    1.0    3.0   0.0    0.0    0.0   0.0    2.0    0.0   0.0    0.23214285714285715  26 / 112
0.0   0.0    0.0   0.0    69.0  1.0   5.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0    2.0    7.0   0.0    0.0    0.0   0.0    4.0    0.0   6.0    0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---    ---    ---   ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0    1.0    0.0   87.0   0.0    0.0   0.0    0.05434782608695652  5 / 92
0.0   2.0    0.0   0.0    5.0   0.0   1.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    5.0    1.0    6.0   0.0    1.0    0.0   0.0    73.0   0.0   3.0    0.27                 27 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    12.0   0.0    0.0   9.0    2.0    11.0  1.0    1.0    71.0  0.0    0.3364485981308411   36 / 107
2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    4.0   1.0    0.0    0.0   0.0    1.0    0.0   75.0   0.13793103448275862  12 / 87
95.0  119.0  71.0  109.0  91.0  72.0  92.0  68.0  76.0  101.0  89.0  89.0  99.0  100.0  85.0  111.0  101.0  116.0  96.0  102.0  100.0  85.0  118.0  108.0  89.0  108.0  0.23815261044176708  593 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.761847
2    0.858635
3    0.899197
4    0.9249
5    0.940562
6    0.953012
7    0.960643
8    0.970683
9    0.977109
10   0.980321
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:34  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:34  2 min 32.373 sec  204224 obs/sec    1         1             10007      0.740259         1.67207             0.990263       0.448765                         0.738811           1.66424               0.990274         0.446988
    2019-08-04 09:02:35  2 min 32.798 sec  217071 obs/sec    10        10            100070     0.522667         0.8493              0.995146       0.228831                         0.524276           0.853858              0.995102         0.238153
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0983458
C9          0.939127               0.939127             0.0923592
C13         0.837199               0.837199             0.082335
C8          0.749364               0.749364             0.0736969
C11         0.733286               0.733286             0.0721156
C12         0.71271                0.71271              0.0700921
C7          0.679787               0.679787             0.0668542
C6          0.639581               0.639581             0.0629001
C16         0.565899               0.565899             0.0556538
C14         0.536046               0.536046             0.0527178
C3          0.532208               0.532208             0.0523404
C5          0.494738               0.494738             0.0486554
C4          0.4829                 0.4829               0.0474912
C10         0.465136               0.465136             0.0457442
C1          0.452272               0.452272             0.0444791
C2          0.347946               0.347946             0.034219
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_105

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007992611608074185  0.00019542314112186432  0.0         -0.018262146245334065  0.30010414123535156  0.037797807317464974  0.21472448110580444
    3        26       Softmax                      0.0   0.0   0.005665664183722514   0.013873964548110962    0.0         -0.42830551917500786   0.8615896701812744   -0.5889322805585755   0.4302339553833008


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.26741591653087665
RMSE: 0.5171227286929831
LogLoss: 0.8446101266887452
Mean Per-Class Error: 0.2235507850171559
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    7.0    4.0    0.0    4.0    0.0    6.0    0.0    0.0    1.0    1.0    2.0    2.0    4.0    1.0    1.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    330.0  0.0    6.0    5.0    0.0    2.0    3.0    3.0    0.0    0.0    1.0    2.0    0.0    2.0    2.0    1.0    12.0   6.0    0.0    0.0    0.0    2.0    4.0    1.0    0.0    0.13612565445026178  52 / 382
0.0    0.0    293.0  0.0    7.0    4.0    32.0   0.0    0.0    0.0    15.0   0.0    0.0    0.0    6.0    0.0    1.0    0.0    4.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.2016348773841962   74 / 367
7.0    27.0   0.0    322.0  0.0    0.0    0.0    2.0    0.0    10.0   1.0    1.0    4.0    2.0    5.0    4.0    0.0    4.0    0.0    0.0    5.0    0.0    0.0    9.0    0.0    0.0    0.20099255583126552  81 / 403
0.0    11.0   9.0    3.0    290.0  1.0    8.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    14.0   4.0    5.0    0.0    1.0    1.0    0.0    12.0   0.0    23.0   0.24479166666666666  94 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    10.0   0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    19.0   1.0    0.0    0.0    2.0    2.0    0.0    0.0    1.0    0.0    334.0  0.0    1.0    0.0    0.11170212765957446  42 / 376
9.0    3.0    0.0    5.0    3.0    0.0    1.0    0.0    1.0    2.0    7.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    9.0    1.0    4.0    2.0    0.0    336.0  4.0    1.0    0.14720812182741116  58 / 394
0.0    3.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    11.0   0.0    3.0    26.0   0.0    36.0   2.0    0.0    301.0  0.0    0.23214285714285715  91 / 392
3.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    36.0   3.0    0.0    0.0    0.0    1.0    0.0    297.0  0.1907356948228883   70 / 367
440.0  574.0  352.0  408.0  380.0  345.0  370.0  242.0  338.0  353.0  381.0  318.0  453.0  319.0  422.0  371.0  351.0  387.0  340.0  368.0  417.0  379.0  475.0  438.0  396.0  386.0  0.2226332100369889   2,227 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.777367
2    0.871738
3    0.911027
4    0.929921
5    0.945216
6    0.956613
7    0.964511
8    0.971309
9    0.976007
10   0.980806

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2695351786575666
RMSE: 0.5191677750569333
LogLoss: 0.854048974407202
Mean Per-Class Error: 0.22646548287254234
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   1.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0    87.0   0.0   1.0    2.0   0.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    0.0   5.0    1.0   0.0   0.0    0.0   2.0    2.0    0.0    0.0   0.1792452830188679   19 / 106
0.0    0.0    62.0  0.0    1.0   2.0   7.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    2.0   0.0   2.0    0.0   0.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
4.0    3.0    0.0   91.0   0.0   0.0   0.0   1.0   0.0   4.0    0.0   1.0   2.0   1.0   1.0   2.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    1.0    0.0    0.0   0.1875               21 / 112
0.0    3.0    1.0   0.0    69.0  1.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    4.0   1.0    1.0   0.0   0.0    0.0   0.0    5.0    0.0    9.0   0.28865979381443296  28 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0    1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    2.0   1.0    0.0   0.0   0.0    0.0   83.0   0.0    0.0    0.0   0.09782608695652174  9 / 92
3.0    1.0    0.0   3.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0    81.0   1.0    1.0   0.19                 19 / 100
0.0    2.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    4.0   0.0    0.0   6.0   0.0    12.0  2.0    0.0    79.0   0.0   0.2616822429906542   28 / 107
0.0    0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0   1.0   0.0    0.0   0.0    0.0    0.0    69.0  0.20689655172413793  18 / 87
106.0  143.0  75.0  111.0  95.0  80.0  82.0  66.0  75.0  106.0  98.0  92.0  99.0  87.0  87.0  107.0  96.0  100.0  83.0  85.0  100.0  87.0  116.0  110.0  107.0  97.0  0.22650602409638554  564 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773494
2    0.871888
3    0.914458
4    0.931727
5    0.944578
6    0.957831
7    0.962651
8    0.968675
9    0.973092
10   0.976707
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:00  2 min 57.980 sec  208479 obs/sec    1         1             10007      0.7459           1.63666             0.99011        0.418175                         0.746669           1.64145               0.990066         0.425703
    2019-08-04 09:03:00  2 min 58.389 sec  226402 obs/sec    10        10            100070     0.517123         0.84461             0.995246       0.222633                         0.519168           0.854049              0.995197         0.226506
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0849651
C13         0.953437               0.953437             0.0810089
C9          0.914947               0.914947             0.0777386
C8          0.893951               0.893951             0.0759546
C12         0.881498               0.881498             0.0748966
C7          0.848238               0.848238             0.0720706
C11         0.73319                0.73319              0.0622956
C3          0.725886               0.725886             0.061675
C6          0.715093               0.715093             0.060758
C5          0.672858               0.672858             0.0571695
C10         0.667828               0.667828             0.0567421
C16         0.641154               0.641154             0.0544757
C14         0.584862               0.584862             0.0496929
C4          0.578413               0.578413             0.0491449
C1          0.532504               0.532504             0.0452443
C2          0.425676               0.425676             0.0361676
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_192

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009513466326609432  0.0002498687244951725  0.0         -0.00767264560097658  0.24742013216018677  0.03262562261618683  0.1755274534225464
    3        26       Softmax                      0.0   0.0   0.005671757544300467   0.011548008769750595   0.0         -0.3304518375476758   0.7323336601257324   -0.851555605012526   0.4451720714569092


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.27820769551295066
RMSE: 0.5274539747816398
LogLoss: 0.8499501225853698
Mean Per-Class Error: 0.2182765050220055
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    6.0    1.0    0.0    8.0    0.0    1.0    0.0    1.0    0.0    9.0    0.0    1.0    0.0    4.0    3.0    6.0    0.0    0.10632911392405063  42 / 395
0.0    316.0  0.0    8.0    1.0    0.0    5.0    3.0    2.0    0.0    3.0    0.0    0.0    0.0    3.0    4.0    2.0    21.0   8.0    0.0    0.0    0.0    1.0    5.0    1.0    0.0    0.17493472584856398  67 / 383
0.0    0.0    294.0  0.0    8.0    2.0    15.0   0.0    0.0    0.0    27.0   0.0    0.0    0.0    5.0    0.0    2.0    0.0    8.0    3.0    1.0    0.0    3.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
2.0    27.0   0.0    334.0  0.0    0.0    1.0    4.0    0.0    3.0    0.0    0.0    5.0    4.0    4.0    0.0    0.0    4.0    2.0    0.0    1.0    0.0    0.0    10.0   0.0    2.0    0.17121588089330025  69 / 403
0.0    8.0    0.0    0.0    305.0  1.0    6.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    15.0   5.0    16.0   5.0    0.0    0.0    0.0    8.0    0.0    11.0   0.20572916666666666  79 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    3.0    0.0    19.0   2.0    9.0    0.0    0.0    4.0    0.0    0.0    2.0    1.0    330.0  0.0    0.0    0.0    0.12                 45 / 375
0.0    5.0    0.0    6.0    7.0    1.0    2.0    0.0    2.0    1.0    5.0    1.0    0.0    0.0    2.0    0.0    4.0    1.0    19.0   3.0    4.0    0.0    0.0    326.0  3.0    2.0    0.17258883248730963  68 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    9.0    0.0    11.0   42.0   3.0    28.0   6.0    0.0    284.0  0.0    0.2755102040816326   108 / 392
6.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    43.0   2.0    0.0    0.0    0.0    6.0    0.0    289.0  0.2125340599455041   78 / 367
416.0  477.0  363.0  444.0  392.0  336.0  344.0  270.0  331.0  330.0  390.0  325.0  445.0  372.0  419.0  378.0  345.0  438.0  450.0  415.0  392.0  371.0  437.0  422.0  348.0  353.0  0.21723482955113466  2,173 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782765
2    0.864841
3    0.905928
4    0.930621
5    0.947016
6    0.958712
7    0.96711
8    0.973608
9    0.978706
10   0.983105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.27983712636969293
RMSE: 0.5289963387110471
LogLoss: 0.854392435909676
Mean Per-Class Error: 0.21952373404470177
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16    17     18     19     20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   3.0    1.0   0.0   1.0   1.0   1.0   0.0   2.0   0.0   0.0    0.0    1.0   0.0    1.0   6.0    2.0    0.0    0.0   0.0   1.0    1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    61.0  0.0    1.0   0.0   7.0   0.0   0.0   0.0   6.0   0.0   0.0    0.0    2.0   0.0    0.0   0.0    3.0    1.0    0.0   0.0   1.0    0.0   0.0    0.0   0.25609756097560976  21 / 82
2.0   5.0    0.0   94.0   0.0   0.0   1.0   2.0   0.0   1.0   0.0   0.0   2.0    2.0    0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.0   0.0    1.0   0.0    1.0   0.16071428571428573  18 / 112
0.0   1.0    0.0   0.0    75.0  1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0    4.0   1.0    5.0    2.0    0.0   0.0   0.0    2.0   0.0    5.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   3.0    0.0    2.0   0.0    0.0   1.0    0.0    0.0    1.0   0.0   83.0   0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0   3.0    0.0   2.0    4.0   0.0   2.0   0.0   0.0   0.0   2.0   1.0   0.0    0.0    0.0   0.0    0.0   0.0    7.0    1.0    1.0   0.0   0.0    76.0  1.0    0.0   0.24                 24 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    4.0   0.0    2.0    9.0    1.0   9.0   2.0    0.0   78.0   0.0   0.27102803738317754  29 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0    7.0    1.0    0.0   0.0   0.0    2.0   0.0    69.0  0.20689655172413793  18 / 87
99.0  121.0  77.0  123.0  93.0  74.0  84.0  69.0  79.0  89.0  98.0  90.0  100.0  102.0  83.0  110.0  98.0  115.0  108.0  101.0  97.0  81.0  105.0  97.0  102.0  95.0  0.21887550200803213  545 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781124
2    0.864257
3    0.906426
4    0.930522
5    0.947389
6    0.960241
7    0.966265
8    0.971888
9    0.977108
10   0.983936
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:41  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:41  5 min 39.469 sec  169610 obs/sec    1         1             10007      0.751466         1.63484             0.989963       0.393882                         0.751019           1.62944               0.98995          0.390361
    2019-08-04 09:05:42  5 min 39.998 sec  175869 obs/sec    10        10            100070     0.527454         0.84995             0.995055       0.217235                         0.528996           0.854392              0.995014         0.218876
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0960473
C13         0.891355               0.891355             0.0856122
C9          0.82036                0.82036              0.0787934
C12         0.808858               0.808858             0.0776887
C8          0.739961               0.739961             0.0710713
C7          0.738706               0.738706             0.0709507
C11         0.659037               0.659037             0.0632988
C10         0.610066               0.610066             0.0585952
C6          0.595955               0.595955             0.0572399
C14         0.579356               0.579356             0.0556456
C3          0.576491               0.576491             0.0553704
C5          0.560881               0.560881             0.0538711
C4          0.539463               0.539463             0.0518139
C16         0.525623               0.525623             0.0504847
C2          0.384962               0.384962             0.0369746
C1          0.38046                0.38046              0.0365422
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_188

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009646082826293423  0.0002718903124332428  0.0         -0.011086108454259502  0.2456800937652588  0.06948955398720733  0.18544983863830566
    3        26       Softmax                      0.0   0.0   0.005247480515068814   0.008778352290391922   0.0         -0.2835561492846374    0.7315864562988281  -0.8514392034776868  0.38486766815185547


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.278165226141333
RMSE: 0.5274137144039136
LogLoss: 0.8492026988196364
Mean Per-Class Error: 0.21908376254071696
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    4.0    2.0    0.0    9.0    0.0    1.0    0.0    0.0    2.0    9.0    0.0    2.0    0.0    3.0    1.0    7.0    0.0    0.10632911392405063  42 / 395
1.0    330.0  0.0    3.0    1.0    0.0    8.0    12.0   1.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    13.0   1.0    0.0    0.0    0.0    1.0    2.0    3.0    0.0    0.13612565445026178  52 / 382
0.0    0.0    292.0  0.0    13.0   0.0    17.0   0.0    0.0    0.0    24.0   0.0    2.0    0.0    3.0    0.0    2.0    0.0    5.0    5.0    0.0    0.0    5.0    0.0    0.0    0.0    0.20652173913043478  76 / 368
3.0    27.0   0.0    326.0  0.0    0.0    1.0    3.0    0.0    3.0    0.0    0.0    5.0    6.0    5.0    2.0    0.0    11.0   3.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.19106699751861042  77 / 403
0.0    20.0   0.0    0.0    286.0  2.0    14.0   1.0    0.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    9.0    3.0    14.0   2.0    0.0    0.0    0.0    12.0   0.0    11.0   0.2552083333333333   98 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    20.0   0.0    0.0    7.0    0.0    16.0   0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    329.0  0.0    0.0    0.0    0.125                47 / 376
0.0    3.0    0.0    4.0    10.0   0.0    1.0    3.0    3.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    13.0   2.0    22.0   1.0    3.0    0.0    0.0    317.0  6.0    1.0    0.19543147208121828  77 / 394
0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    11.0   0.0    11.0   27.0   1.0    18.0   1.0    0.0    305.0  0.0    0.22391857506361323  88 / 393
3.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    39.0   2.0    0.0    0.0    0.0    1.0    0.0    297.0  0.1907356948228883   70 / 367
400.0  511.0  338.0  423.0  369.0  322.0  360.0  328.0  345.0  325.0  411.0  339.0  462.0  359.0  430.0  409.0  344.0  424.0  401.0  376.0  368.0  348.0  418.0  427.0  394.0  372.0  0.21823452964110768  2,183 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781765
2    0.870339
3    0.906628
4    0.929421
5    0.945216
6    0.957913
7    0.96771
8    0.974408
9    0.978806
10   0.983605

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.28017382078206443
RMSE: 0.5293144819311715
LogLoss: 0.8558729746329258
Mean Per-Class Error: 0.22037802661149378
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   86.0   0.0   0.0    1.0   0.0   1.0   6.0   0.0   0.0   0.0    0.0   0.0    0.0   3.0   1.0    0.0   5.0    0.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    59.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0   7.0    0.0   1.0    0.0   2.0   0.0    0.0   0.0    2.0   3.0   0.0   0.0   1.0    0.0    0.0    0.0   0.2804878048780488   23 / 82
3.0   6.0    0.0   93.0   0.0   0.0   1.0   2.0   0.0   0.0   0.0    0.0   1.0    3.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    1.0   0.16964285714285715  19 / 112
0.0   3.0    0.0   0.0    71.0  1.0   4.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    3.0   1.0    3.0   1.0   0.0   0.0   0.0    3.0    0.0    5.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   2.0    0.0   4.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   82.0   0.0    0.0    0.0   0.10869565217391304  10 / 92
0.0   1.0    0.0   1.0    4.0   0.0   1.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    3.0   2.0    5.0   0.0   0.0   0.0   0.0    77.0   2.0    1.0   0.23                 23 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0   1.0    5.0   0.0    2.0   6.0   0.0   6.0   1.0    0.0    82.0   0.0   0.2336448598130841   25 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    5.0   1.0   0.0   0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
95.0  128.0  70.0  119.0  93.0  73.0  89.0  86.0  82.0  92.0  106.0  91.0  107.0  97.0  84.0  118.0  97.0  108.0  86.0  88.0  90.0  80.0  102.0  100.0  110.0  99.0  0.21967871485943774  547 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780321
2    0.865863
3    0.905221
4    0.928112
5    0.945783
6    0.958635
7    0.967068
8    0.974297
9    0.979518
10   0.983534
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:35  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:35  5 min 33.204 sec  138986 obs/sec    1         1             10007      0.757478         1.65487             0.989804       0.390883                         0.757984           1.6575                0.989763         0.405622
    2019-08-04 09:05:35  5 min 33.740 sec  169898 obs/sec    10        10            100070     0.527414         0.849203            0.995057       0.218235                         0.529314           0.855873              0.995008         0.219679
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.094993
C13         0.97372                0.97372              0.0924966
C9          0.795973               0.795973             0.0756119
C12         0.778868               0.778868             0.0739871
C8          0.762002               0.762002             0.0723849
C7          0.749969               0.749969             0.0712418
C11         0.741741               0.741741             0.0704602
C14         0.667694               0.667694             0.0634263
C6          0.631494               0.631494             0.0599875
C10         0.538489               0.538489             0.0511527
C16         0.531325               0.531325             0.0504721
C3          0.529105               0.529105             0.0502613
C4          0.499015               0.499015             0.0474029
C5          0.495909               0.495909             0.0471079
C1          0.421604               0.421604             0.0400495
C2          0.41018                0.41018              0.0389642
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_64

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009472871015816509  0.00025561207439750433  0.0         -0.015979671701348508  0.24651867151260376  0.03246734407176647  0.14691942930221558
    3        26       Softmax                      0.0   0.0   0.0052432696755624     0.011642459779977798    0.0         -0.28390317866627324   0.7362711429595947   -0.8619197353983944  0.43336594104766846


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2788348412215433
RMSE: 0.5280481429013298
LogLoss: 0.8511737599142656
Mean Per-Class Error: 0.22157566513581478
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
347.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    4.0    3.0    1.0    12.0   1.0    6.0    0.0    0.0    0.0    5.0    0.0    1.0    2.0    3.0    3.0    4.0    1.0    0.12151898734177215  48 / 395
0.0    313.0  0.0    4.0    4.0    0.0    4.0    3.0    1.0    0.0    2.0    0.0    1.0    0.0    4.0    2.0    0.0    28.0   10.0   0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.18276762402088773  70 / 383
0.0    0.0    289.0  0.0    9.0    0.0    16.0   0.0    0.0    0.0    28.0   1.0    1.0    0.0    7.0    0.0    1.0    0.0    6.0    1.0    3.0    0.0    6.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
4.0    28.0   0.0    318.0  2.0    0.0    1.0    8.0    0.0    3.0    0.0    0.0    3.0    7.0    2.0    0.0    0.0    11.0   1.0    1.0    1.0    0.0    0.0    11.0   0.0    2.0    0.2109181141439206   85 / 403
0.0    14.0   0.0    0.0    287.0  1.0    23.0   0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    7.0    3.0    1.0    0.0    0.0    7.0    1.0    24.0   0.2506527415143603   96 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    1.0    0.0    19.0   2.0    3.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    335.0  0.0    0.0    0.0    0.10666666666666667  40 / 375
0.0    5.0    0.0    7.0    5.0    0.0    2.0    2.0    3.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    10.0   0.0    8.0    3.0    4.0    1.0    0.0    323.0  7.0    4.0    0.1802030456852792   71 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    3.0    0.0    16.0   0.0    10.0   30.0   1.0    23.0   1.0    0.0    302.0  0.0    0.23155216284987276  91 / 393
1.0    1.0    0.0    2.0    17.0   0.0    1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    45.0   2.0    0.0    0.0    0.0    0.0    0.0    292.0  0.20435967302452315  75 / 367
394.0  565.0  344.0  418.0  392.0  341.0  365.0  283.0  344.0  335.0  403.0  331.0  446.0  373.0  417.0  381.0  352.0  447.0  345.0  397.0  371.0  365.0  443.0  419.0  357.0  375.0  0.2206338098570429   2,207 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779366
2    0.873638
3    0.909027
4    0.930621
5    0.946816
6    0.958512
7    0.96661
8    0.972508
9    0.977607
10   0.981905

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.28039090028212393
RMSE: 0.5295194994352181
LogLoss: 0.8576112112756461
Mean Per-Class Error: 0.22450957892390033
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16    17     18    19    20    21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   2.0   0.0    1.0   2.0   0.0   0.12359550561797752  11 / 89
0.0   82.0   0.0   1.0    1.0   0.0   3.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   0.0    0.0   7.0    5.0   0.0   0.0   0.0   1.0    2.0   0.0   0.0   0.22641509433962265  24 / 106
0.0   0.0    61.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0    4.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   2.0    0.0   0.0   0.0   0.25609756097560976  21 / 82
3.0   4.0    0.0   92.0   1.0   0.0   1.0   3.0   0.0   0.0   0.0    0.0   1.0   3.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0   1.0   0.17857142857142858  20 / 112
0.0   3.0    0.0   0.0    67.0  1.0   7.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   1.0   0.0   0.0   0.0    2.0   0.0   9.0   0.30927835051546393  30 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   4.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   84.0   0.0   0.0   0.0   0.08695652173913043  8 / 92
0.0   2.0    0.0   2.0    2.0   0.0   1.0   1.0   0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    3.0   0.0   0.0   0.0   0.0    77.0  3.0   2.0   0.23                 23 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0    1.0   0.0    7.0   0.0    0.0   7.0   0.0   6.0   1.0    0.0   83.0  0.0   0.22429906542056074  24 / 107
0.0   0.0    0.0   1.0    6.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    9.0   1.0   0.0   0.0   0.0    0.0   0.0   70.0  0.19540229885057472  17 / 87
95.0  141.0  74.0  120.0  88.0  77.0  94.0  71.0  79.0  93.0  101.0  88.0  99.0  103.0  87.0  107.0  96.0  110.0  92.0  96.0  94.0  83.0  107.0  98.0  98.0  99.0  0.22289156626506024  555 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.777108
2    0.871486
3    0.907631
4    0.928514
5    0.945783
6    0.95743
7    0.965863
8    0.969076
9    0.973896
10   0.977912
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:48  1 min 46.354 sec  147161 obs/sec    1         1             10007      0.753741         1.66072             0.989903       0.409677                         0.754993           1.66729               0.989843         0.419277
    2019-08-04 09:01:49  1 min 46.922 sec  161925 obs/sec    10        10            100070     0.528048         0.851174            0.995044       0.220634                         0.529519           0.857611              0.995004         0.222892
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0917063
C13         0.897735               0.897735             0.082328
C12         0.850578               0.850578             0.0780034
C7          0.819667               0.819667             0.0751686
C9          0.814726               0.814726             0.0747155
C8          0.814219               0.814219             0.0746691
C11         0.71517                0.71517              0.0655856
C6          0.679018               0.679018             0.0622703
C14         0.666171               0.666171             0.061092
C16         0.606807               0.606807             0.055648
C3          0.597221               0.597221             0.0547689
C10         0.587381               0.587381             0.0538666
C5          0.566185               0.566185             0.0519228
C4          0.522987               0.522987             0.0479612
C2          0.39046                0.39046              0.0358077
C1          0.37605                0.37605              0.0344862
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_40

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007561097417010387  0.0001814384013414383  0.0         -0.014486501552056552  0.27329230308532715  0.13089990740348023  0.19751399755477905
    3        26       Softmax                      0.0   0.0   0.0047448478983194665  0.008232682943344116   0.0         -0.3687442286132304    0.9059600830078125   -0.6059048773820371  0.46007227897644043


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.27082220818844155
RMSE: 0.5204058110632909
LogLoss: 0.8516631361850571
Mean Per-Class Error: 0.23177007190460527
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    4.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    5.0    2.0    0.0    3.0    3.0    0.09367088607594937  37 / 395
0.0    308.0  0.0    9.0    2.0    0.0    7.0    3.0    3.0    0.0    2.0    0.0    0.0    0.0    7.0    2.0    1.0    23.0   8.0    0.0    0.0    3.0    1.0    3.0    1.0    0.0    0.195822454308094    75 / 383
0.0    0.0    298.0  0.0    25.0   1.0    10.0   1.0    0.0    0.0    13.0   1.0    1.0    0.0    3.0    2.0    4.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
6.0    26.0   0.0    318.0  0.0    1.0    0.0    3.0    1.0    5.0    3.0    0.0    4.0    3.0    4.0    4.0    0.0    7.0    5.0    0.0    1.0    0.0    0.0    9.0    2.0    0.0    0.208955223880597    84 / 402
0.0    16.0   0.0    0.0    291.0  2.0    5.0    0.0    0.0    0.0    7.0    1.0    0.0    0.0    3.0    0.0    12.0   4.0    7.0    2.0    1.0    5.0    0.0    9.0    0.0    19.0   0.2421875            93 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
2.0    4.0    0.0    16.0   13.0   0.0    0.0    1.0    4.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    9.0    7.0    3.0    3.0    0.0    314.0  4.0    1.0    0.20304568527918782  80 / 394
0.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    7.0    13.0   0.0    9.0    16.0   2.0    15.0   1.0    0.0    324.0  0.0    0.17557251908396945  69 / 393
0.0    2.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    2.0    3.0    0.0    32.0   0.0    0.0    0.0    0.0    3.0    0.0    309.0  0.15803814713896458  58 / 367
399.0  543.0  383.0  446.0  413.0  330.0  312.0  211.0  337.0  358.0  405.0  350.0  424.0  376.0  420.0  404.0  369.0  388.0  313.0  381.0  375.0  364.0  457.0  396.0  411.0  438.0  0.23063081075677297  2,307 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.769369
2    0.86554
3    0.903929
4    0.926322
5    0.940818
6    0.953214
7    0.962811
8    0.968609
9    0.975707
10   0.980606

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2743418883918172
RMSE: 0.5237765634235816
LogLoss: 0.8586660271326441
Mean Per-Class Error: 0.23397776833369927
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17    18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0   1.0    0.0    2.0    1.0    0.10112359550561797  9 / 89
0.0   77.0   0.0   3.0    2.0   0.0   3.0   2.0   1.0   0.0   1.0   0.0   0.0   0.0    4.0   0.0    1.0   7.0   2.0   0.0   0.0   1.0   1.0    1.0    0.0    0.0    0.27358490566037735  29 / 106
0.0   0.0    60.0  0.0    4.0   0.0   4.0   1.0   0.0   0.0   4.0   0.0   0.0   0.0    1.0   2.0    2.0   0.0   0.0   4.0   0.0   0.0   0.0    0.0    0.0    0.0    0.2682926829268293   22 / 82
3.0   5.0    0.0   91.0   0.0   0.0   0.0   0.0   1.0   2.0   1.0   0.0   2.0   2.0    1.0   1.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0    0.1875               21 / 112
0.0   3.0    0.0   0.0    71.0  2.0   1.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    1.0   0.0    3.0   2.0   2.0   0.0   0.0   1.0   0.0    1.0    0.0    8.0    0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   89.0   0.0    0.0    0.0    0.03260869565217391  3 / 92
0.0   2.0    0.0   3.0    3.0   0.0   0.0   1.0   1.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   2.0   2.0   0.0   0.0   0.0    83.0   0.0    0.0    0.17                 17 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    3.0   0.0   2.0   5.0   0.0   3.0   1.0    0.0    90.0   0.0    0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0    0.0   1.0    0.0   0.0   6.0   0.0   0.0   0.0   0.0    0.0    0.0    75.0   0.13793103448275862  12 / 87
90.0  127.0  80.0  125.0  96.0  75.0  75.0  61.0  80.0  98.0  99.0  94.0  96.0  103.0  90.0  119.0  99.0  99.0  76.0  92.0  93.0  81.0  112.0  101.0  112.0  117.0  0.2317269076305221   577 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.768273
2    0.864659
3    0.904418
4    0.930121
5    0.943775
6    0.955422
7    0.961446
8    0.966265
9    0.976305
10   0.979518
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:12  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:12  1 min  9.795 sec  204224 obs/sec    1         1             10007      0.752436         1.71678             0.989939       0.443367                         0.756273           1.73068               0.989809         0.45502
    2019-08-04 09:01:12  1 min 10.246 sec  205482 obs/sec    10        10            100070     0.520406         0.851663            0.995187       0.230631                         0.523777           0.858666              0.995112         0.231727
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0999752
C13         0.857145               0.857145             0.0856933
C12         0.842653               0.842653             0.0842444
C7          0.736854               0.736854             0.0736671
C11         0.721997               0.721997             0.0721818
C9          0.716272               0.716272             0.0716094
C8          0.715304               0.715304             0.0715126
C6          0.661144               0.661144             0.066098
C14         0.518776               0.518776             0.0518647
C3          0.514066               0.514066             0.0513939
C10         0.510752               0.510752             0.0510625
C4          0.486086               0.486086             0.0485966
C5          0.479927               0.479927             0.0479808
C16         0.449052               0.449052             0.044894
C1          0.425654               0.425654             0.0425548
C2          0.366798               0.366798             0.0366707
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_190

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009316594803010503  0.00023373827571049333  0.0         -0.009538641882059551  0.23696869611740112  0.06476376596457836  0.17697292566299438
    3        26       Softmax                      0.0   0.0   0.00510815834380852    0.00868426263332367     0.0         -0.2858996520143452    0.7403254508972168   -0.8865780227851014  0.3935285806655884


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2813720179288696
RMSE: 0.5304451130219503
LogLoss: 0.8588424598760593
Mean Per-Class Error: 0.22132821184808746
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    5.0    6.0    0.0    3.0    0.0    6.0    0.0    0.0    0.0    6.0    0.0    1.0    2.0    5.0    1.0    2.0    0.0    0.09873417721518987  39 / 395
0.0    315.0  0.0    15.0   3.0    0.0    0.0    10.0   2.0    0.0    1.0    0.0    0.0    0.0    2.0    4.0    0.0    20.0   4.0    0.0    0.0    0.0    1.0    4.0    1.0    1.0    0.17754569190600522  68 / 383
0.0    1.0    294.0  0.0    12.0   1.0    19.0   0.0    0.0    0.0    29.0   0.0    1.0    0.0    4.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    2.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
4.0    19.0   0.0    330.0  0.0    1.0    1.0    5.0    0.0    7.0    0.0    0.0    7.0    2.0    3.0    1.0    0.0    10.0   1.0    1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.18114143920595532  73 / 403
0.0    16.0   1.0    1.0    280.0  1.0    16.0   0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    12.0   6.0    9.0    2.0    1.0    0.0    0.0    7.0    3.0    20.0   0.2689295039164491   103 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    4.0    0.0    12.0   6.0    2.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    340.0  0.0    0.0    0.0    0.09333333333333334  35 / 375
0.0    5.0    0.0    3.0    9.0    1.0    0.0    0.0    2.0    2.0    7.0    0.0    0.0    0.0    2.0    0.0    8.0    2.0    6.0    2.0    6.0    0.0    0.0    328.0  10.0   1.0    0.16751269035532995  66 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    11.0   19.0   3.0    18.0   4.0    0.0    322.0  0.0    0.1806615776081425   71 / 393
2.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    35.0   1.0    0.0    0.0    0.0    2.0    0.0    309.0  0.15803814713896458  58 / 367
407.0  534.0  350.0  443.0  372.0  345.0  330.0  256.0  346.0  337.0  454.0  313.0  450.0  386.0  423.0  384.0  353.0  421.0  327.0  349.0  378.0  369.0  449.0  405.0  407.0  415.0  0.22033389983005097  2,204 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779666
2    0.872338
3    0.907528
4    0.93202
5    0.946516
6    0.957213
7    0.96591
8    0.972608
9    0.977507
10   0.982105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2834921298634846
RMSE: 0.5324397898950496
LogLoss: 0.8608467241844779
Mean Per-Class Error: 0.22581016136042795
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13     14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   2.0    1.0   2.0    0.0    0.07865168539325842  7 / 89
0.0   82.0   0.0   6.0    1.0   0.0   0.0   3.0   1.0   0.0   1.0    0.0   0.0    0.0    2.0   1.0    0.0   4.0    2.0   0.0   0.0   0.0   1.0    1.0   0.0    1.0    0.22641509433962265  24 / 106
0.0   0.0    60.0  0.0    3.0   0.0   7.0   0.0   0.0   0.0   7.0    0.0   0.0    0.0    1.0   0.0    0.0   0.0    2.0   1.0   1.0   0.0   0.0    0.0   0.0    0.0    0.2682926829268293   22 / 82
3.0   3.0    0.0   93.0   0.0   0.0   1.0   1.0   0.0   3.0   0.0    0.0   3.0    1.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0    0.16964285714285715  19 / 112
0.0   3.0    0.0   0.0    66.0  1.0   4.0   0.0   0.0   0.0   4.0    0.0   0.0    0.0    0.0   0.0    4.0   1.0    3.0   1.0   0.0   0.0   0.0    2.0   1.0    7.0    0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0    2.0    1.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0   1.0    0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0    0.0    0.0   0.0    2.0   2.0    4.0   0.0   2.0   0.0   0.0    78.0  3.0    0.0    0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0    4.0   0.0    2.0   4.0   1.0   5.0   3.0    0.0   87.0   0.0    0.18691588785046728  20 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0    0.0   0.0    73.0   0.16091954022988506  14 / 87
99.0  129.0  72.0  129.0  86.0  74.0  81.0  68.0  81.0  98.0  114.0  87.0  101.0  102.0  80.0  113.0  97.0  106.0  89.0  82.0  96.0  83.0  113.0  95.0  113.0  102.0  0.22449799196787149  559 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.775502
2    0.870281
3    0.905221
4    0.931727
5    0.948193
6    0.958635
7    0.967068
8    0.973494
9    0.97751
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:36  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:36  5 min 34.667 sec  145028 obs/sec    1         1             10007      0.760202         1.68815             0.989729       0.396781                         0.760143           1.683                 0.989704         0.38996
    2019-08-04 09:05:37  5 min 35.210 sec  169610 obs/sec    10        10            100070     0.530445         0.858842            0.994999       0.220334                         0.53244            0.860847              0.994949         0.224498
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0929773
C15         0.950196               0.950196             0.0883466
C12         0.81027                0.81027              0.0753367
C9          0.80815                0.80815              0.0751396
C8          0.753199               0.753199             0.0700304
C11         0.718966               0.718966             0.0668475
C7          0.704832               0.704832             0.0655334
C14         0.673619               0.673619             0.0626313
C6          0.672155               0.672155             0.0624951
C5          0.641133               0.641133             0.0596108
C16         0.565766               0.565766             0.0526034
C3          0.551975               0.551975             0.0513212
C10         0.539898               0.539898             0.0501982
C4          0.494746               0.494746             0.0460001
C1          0.460405               0.460405             0.0428073
C2          0.410003               0.410003             0.038121
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_123

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007607753099136971  0.0002044593566097319  0.0         -0.00825085984158136  0.28091180324554443  0.08050040262514814  0.26822495460510254
    3        26       Softmax                      0.0   0.0   0.005072405353460523   0.01032472774386406    0.0         -0.3816575946474796   0.8972265720367432   -0.5831595758246191  0.3989146947860718


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.27478773985720073
RMSE: 0.5242020029122368
LogLoss: 0.8616561354202413
Mean Per-Class Error: 0.2350900012095592
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  2.0    0.0    6.0    0.0    0.0    0.0    3.0    0.0    0.0    6.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    5.0    2.0    5.0    0.0    0.09367088607594937  37 / 395
0.0    297.0  0.0    9.0    2.0    0.0    5.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    14.0   1.0    42.0   4.0    0.0    0.0    1.0    0.0    4.0    1.0    0.0    0.2245430809399478   86 / 383
0.0    0.0    278.0  1.0    16.0   0.0    20.0   1.0    0.0    0.0    16.0   0.0    1.0    0.0    5.0    0.0    1.0    0.0    13.0   2.0    8.0    0.0    6.0    0.0    0.0    0.0    0.24456521739130435  90 / 368
4.0    18.0   0.0    313.0  0.0    0.0    0.0    11.0   0.0    3.0    1.0    0.0    3.0    6.0    6.0    1.0    0.0    18.0   14.0   0.0    0.0    0.0    0.0    2.0    0.0    3.0    0.22332506203473945  90 / 403
0.0    1.0    1.0    0.0    292.0  2.0    17.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    9.0    8.0    19.0   0.0    1.0    0.0    0.0    7.0    1.0    21.0   0.23958333333333334  92 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    2.0    0.0    0.0    0.0    11.0   0.0    0.0    1.0    0.0    32.0   4.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    1.0    321.0  0.0    0.0    0.0    0.14627659574468085  55 / 376
0.0    1.0    1.0    7.0    7.0    0.0    0.0    0.0    2.0    1.0    5.0    1.0    0.0    0.0    2.0    0.0    8.0    1.0    24.0   4.0    2.0    0.0    0.0    322.0  5.0    1.0    0.18274111675126903  72 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    8.0    0.0    1.0    37.0   3.0    58.0   0.0    4.0    261.0  3.0    0.33587786259541985  132 / 393
0.0    2.0    0.0    0.0    28.0   0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    56.0   1.0    0.0    0.0    0.0    1.0    0.0    273.0  0.2561307901907357   94 / 367
423.0  453.0  350.0  429.0  392.0  323.0  326.0  291.0  350.0  315.0  349.0  346.0  450.0  395.0  414.0  424.0  325.0  526.0  466.0  397.0  377.0  394.0  384.0  422.0  326.0  356.0  0.2340297910626812   2,341 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.76597
2    0.861742
3    0.89993
4    0.924423
5    0.942517
6    0.955313
7    0.964711
8    0.971409
9    0.977107
10   0.981206

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.27742469375986645
RMSE: 0.5267112052727438
LogLoss: 0.8616689287340434
Mean Per-Class Error: 0.2405826339697601
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18     19    20    21    22    23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   1.0   1.0    3.0   0.0   0.07865168539325842  7 / 89
0.0   75.0   0.0   1.0    0.0   0.0   2.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   5.0    0.0   15.0   1.0    0.0   0.0   1.0   0.0   3.0    1.0   0.0   0.29245283018867924  31 / 106
0.0   0.0    57.0  0.0    2.0   0.0   8.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    4.0    1.0   2.0   0.0   2.0   0.0    0.0   0.0   0.3048780487804878   25 / 82
1.0   3.0    0.0   89.0   0.0   0.0   0.0   4.0   0.0   2.0   1.0   0.0   1.0   3.0    1.0   0.0    0.0   4.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.20535714285714285  23 / 112
0.0   0.0    0.0   0.0    66.0  1.0   4.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    8.0    0.0   0.0   0.0   0.0   3.0    0.0   8.0   0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   6.0   1.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   83.0  0.0    0.0   0.0   0.09782608695652174  9 / 92
0.0   0.0    1.0   3.0    3.0   0.0   0.0   0.0   0.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    2.0   1.0    7.0    0.0   0.0   0.0   0.0   79.0   1.0   0.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0    2.0   0.0    0.0    8.0   1.0   19.0  0.0   0.0    68.0  0.0   0.3644859813084112   39 / 107
0.0   1.0    0.0   0.0    8.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    14.0   0.0   0.0   0.0   0.0   0.0    0.0   64.0  0.26436781609195403  23 / 87
94.0  115.0  71.0  112.0  87.0  70.0  88.0  78.0  90.0  86.0  86.0  95.0  93.0  104.0  89.0  121.0  85.0  141.0  128.0  94.0  96.0  92.0  97.0  102.0  91.0  85.0  0.24016064257028114  598 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.759839
2    0.865863
3    0.902811
4    0.93012
5    0.946185
6    0.956627
7    0.963052
8    0.968273
9    0.973896
10   0.980321
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:30  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:30  3 min 28.423 sec  196215 obs/sec    1         1             10007      0.743906         1.65365             0.990168       0.439868                         0.745833           1.65777               0.990088         0.439759
    2019-08-04 09:03:31  3 min 28.835 sec  223370 obs/sec    10        10            100070     0.524202         0.861656            0.995118       0.23403                          0.526711           0.861669              0.995057         0.240161
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.107757
C13         0.809459               0.809459             0.0872253
C9          0.730305               0.730305             0.0786959
C11         0.714956               0.714956             0.0770419
C8          0.705437               0.705437             0.0760161
C12         0.657382               0.657382             0.0708378
C7          0.53658                0.53658              0.0578205
C3          0.524628               0.524628             0.0565325
C5          0.52455                0.52455              0.0565242
C6          0.503157               0.503157             0.0542189
C16         0.48125                0.48125              0.0518582
C14         0.476842               0.476842             0.0513833
C4          0.467191               0.467191             0.0503433
C10         0.466294               0.466294             0.0502467
C2          0.351495               0.351495             0.0378762
C1          0.330575               0.330575             0.0356219
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_208

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009438955417522266  0.0002676809672266245  0.0         -0.01758010783555619  0.24638086557388306  0.02019575077686317  0.16644048690795898
    3        26       Softmax                      0.0   0.0   0.005130863510115747   0.008152402937412262   0.0         -0.2634194852742859   0.7246725559234619   -0.8613265685017732  0.533543586730957


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.28258464258891514
RMSE: 0.5315869097230622
LogLoss: 0.8618887601463623
Mean Per-Class Error: 0.22851269827282397
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    3.0    6.0    0.0    5.0    0.0    9.0    0.0    1.0    0.0    2.0    1.0    2.0    1.0    3.0    2.0    4.0    0.0    0.10913705583756345  43 / 394
0.0    324.0  0.0    2.0    4.0    1.0    2.0    7.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    27.0   2.0    0.0    0.0    4.0    1.0    3.0    0.0    0.0    0.15404699738903394  59 / 383
0.0    0.0    285.0  1.0    12.0   0.0    19.0   0.0    1.0    0.0    25.0   0.0    1.0    0.0    4.0    0.0    5.0    0.0    5.0    3.0    2.0    0.0    3.0    0.0    1.0    0.0    0.22343324250681199  82 / 367
3.0    28.0   0.0    321.0  0.0    0.0    1.0    7.0    1.0    3.0    1.0    0.0    3.0    7.0    3.0    1.0    0.0    4.0    10.0   0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.20347394540942929  82 / 403
0.0    8.0    0.0    0.0    317.0  2.0    8.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    9.0    5.0    7.0    3.0    2.0    0.0    0.0    2.0    0.0    17.0   0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    3.0    0.0    14.0   3.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    2.0    0.0    5.0    10.0   0.0    0.0    1.0    3.0    2.0    7.0    0.0    0.0    0.0    2.0    0.0    5.0    4.0    12.0   1.0    1.0    0.0    0.0    333.0  3.0    3.0    0.1548223350253807   61 / 394
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    22.0   0.0    2.0    24.0   5.0    24.0   1.0    2.0    307.0  0.0    0.21882951653944022  86 / 393
2.0    0.0    0.0    0.0    18.0   0.0    1.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    41.0   1.0    0.0    0.0    0.0    1.0    1.0    290.0  0.2098092643051771   77 / 367
399.0  527.0  329.0  415.0  428.0  311.0  341.0  268.0  327.0  331.0  421.0  321.0  434.0  380.0  442.0  406.0  374.0  420.0  308.0  404.0  377.0  385.0  442.0  421.0  367.0  425.0  0.22723183045086473  2,273 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.772768
2    0.86754
3    0.905628
4    0.929921
5    0.947116
6    0.956913
7    0.96611
8    0.972408
9    0.976807
10   0.981605

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.28417200170143986
RMSE: 0.5330778570729043
LogLoss: 0.8691553675833105
Mean Per-Class Error: 0.23321667358164833
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10     11    12     13    14    15     16     17     18    19    20    21    22     23     24    25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   2.0    0.0   0.0   0.0    1.0    0.0    0.0   0.0   0.0   1.0   2.0    0.0    2.0   0.0    0.10112359550561797  9 / 89
0.0   83.0   0.0   0.0    3.0    0.0   1.0   3.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0   1.0    0.0    8.0    0.0   0.0   0.0   2.0   1.0    2.0    0.0   0.0    0.2169811320754717   23 / 106
0.0   0.0    59.0  0.0    2.0    0.0   6.0   0.0   0.0   0.0   6.0    0.0   0.0    0.0   2.0   0.0    2.0    0.0    3.0   0.0   0.0   0.0   1.0    0.0    1.0   0.0    0.2804878048780488   23 / 82
3.0   4.0    0.0   91.0   0.0    0.0   1.0   2.0   1.0   1.0   0.0    0.0   1.0    3.0   0.0   0.0    0.0    0.0    2.0   0.0   0.0   0.0   0.0    2.0    0.0   1.0    0.1875               21 / 112
0.0   1.0    0.0   0.0    77.0   1.0   2.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    3.0    1.0    2.0   2.0   0.0   0.0   0.0    1.0    0.0   6.0    0.20618556701030927  20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0   1.0    0.0   4.0    0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   86.0   0.0    0.0   0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    5.0    0.0   0.0   1.0   0.0   0.0   3.0    0.0   0.0    0.0   0.0   0.0    1.0    3.0    4.0   0.0   0.0   0.0   0.0    80.0   1.0   1.0    0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    9.0    0.0    0.0   6.0   2.0   9.0   1.0    0.0    78.0  0.0    0.27102803738317754  29 / 107
0.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   2.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0    0.0    9.0   0.0   0.0   0.0   0.0    0.0    0.0   69.0   0.20689655172413793  18 / 87
96.0  125.0  69.0  115.0  103.0  70.0  79.0  73.0  74.0  97.0  103.0  90.0  101.0  99.0  87.0  118.0  102.0  109.0  81.0  99.0  95.0  90.0  113.0  103.0  93.0  106.0  0.2317269076305221   577 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.768273
2    0.864659
3    0.905622
4    0.930522
5    0.942972
6    0.957028
7    0.965863
8    0.970683
9    0.976305
10   0.982329
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:06  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:07  6 min  4.787 sec  149358 obs/sec    1         1             10007      0.750845         1.64785             0.989978       0.409177                         0.751927           1.64846               0.989925         0.412048
    2019-08-04 09:06:07  6 min  5.309 sec  177429 obs/sec    10        10            100070     0.531587         0.861889            0.994976       0.227232                         0.533078           0.869155              0.994936         0.231727
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0880696
C13         0.998866               0.998866             0.0879697
C9          0.892029               0.892029             0.0785607
C12         0.855231               0.855231             0.0753199
C8          0.851783               0.851783             0.0750162
C7          0.776421               0.776421             0.0683791
C11         0.764571               0.764571             0.0673355
C14         0.697236               0.697236             0.0614053
C6          0.68952                0.68952              0.0607258
C5          0.623939               0.623939             0.0549501
C10         0.618378               0.618378             0.0544603
C3          0.599895               0.599895             0.0528325
C16         0.585259               0.585259             0.0515436
C4          0.540261               0.540261             0.0475806
C2          0.446279               0.446279             0.0393036
C1          0.414986               0.414986             0.0365476
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_43

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009505569333043695  0.00025515793822705746  0.0         -0.014145001258867751  0.2464105486869812  0.05937042010179691  0.16655343770980835
    3        26       Softmax                      0.0   0.0   0.00553211144058598    0.013660784810781479    0.0         -0.25408776839664754   0.7272799015045166  -0.8406151818251305  0.42196857929229736


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.28531345104597927
RMSE: 0.5341474057280249
LogLoss: 0.8748727897156958
Mean Per-Class Error: 0.23217784073047196
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    2.0    0.0    7.0    0.0    5.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    3.0    3.0    7.0    0.0    0.09620253164556962  38 / 395
0.0    301.0  0.0    6.0    3.0    0.0    0.0    2.0    3.0    0.0    0.0    0.0    0.0    0.0    5.0    2.0    0.0    34.0   6.0    0.0    0.0    3.0    0.0    13.0   5.0    0.0    0.21409921671018275  82 / 383
0.0    0.0    302.0  0.0    19.0   0.0    11.0   0.0    0.0    0.0    18.0   2.0    0.0    0.0    4.0    0.0    1.0    0.0    4.0    2.0    0.0    0.0    5.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
4.0    18.0   0.0    311.0  0.0    1.0    1.0    4.0    1.0    3.0    0.0    0.0    3.0    5.0    8.0    4.0    0.0    13.0   4.0    0.0    1.0    0.0    0.0    21.0   0.0    0.0    0.2263681592039801   91 / 402
0.0    7.0    6.0    0.0    294.0  1.0    9.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    9.0    6.0    13.0   2.0    0.0    0.0    0.0    8.0    0.0    22.0   0.234375             90 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    11.0   0.0    0.0    0.0    0.0    10.0   0.0    0.0    2.0    0.0    344.0  0.0    1.0    0.0    0.0851063829787234   32 / 376
2.0    1.0    0.0    6.0    5.0    0.0    2.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    10.0   6.0    4.0    0.0    0.0    337.0  6.0    0.0    0.1446700507614213   57 / 394
0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    4.0    32.0   3.0    54.0   2.0    0.0    275.0  1.0    0.30025445292620867  118 / 393
2.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    44.0   2.0    0.0    0.0    0.0    10.0   0.0    289.0  0.2125340599455041   78 / 367
414.0  468.0  378.0  407.0  381.0  293.0  332.0  229.0  346.0  327.0  416.0  322.0  420.0  352.0  414.0  391.0  362.0  470.0  381.0  411.0  390.0  413.0  453.0  498.0  346.0  389.0  0.23123063081075676  2,313 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.768769
2    0.86514
3    0.906228
4    0.927922
5    0.942917
6    0.954314
7    0.96571
8    0.972708
9    0.978107
10   0.983005

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2846205531317947
RMSE: 0.5334984096806613
LogLoss: 0.8698469761059631
Mean Per-Class Error: 0.23221369696716687
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16     17     18    19     20     21    22     23     24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -----  -----  ----  -----  -----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0    0.0   1.0    2.0    3.0   0.0    0.10112359550561797  9 / 89
0.0   75.0   0.0   2.0    3.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   3.0   1.0    0.0    8.0    4.0   0.0    0.0    2.0   0.0    5.0    2.0   0.0    0.29245283018867924  31 / 106
0.0   0.0    62.0  0.0    4.0   0.0   4.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   2.0   0.0    0.0    0.0    3.0   1.0    0.0    0.0   2.0    0.0    0.0   0.0    0.24390243902439024  20 / 82
3.0   3.0    0.0   88.0   0.0   0.0   1.0   2.0   1.0   1.0   0.0    0.0   0.0   3.0   2.0   0.0    0.0    2.0    2.0   0.0    1.0    0.0   0.0    3.0    0.0   0.0    0.21428571428571427  24 / 112
0.0   1.0    0.0   0.0    70.0  1.0   1.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0    4.0    1.0    4.0   0.0    0.0    0.0   0.0    1.0    0.0   11.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---    ---    ---   ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   3.0   0.0   0.0   0.0    0.0    2.0    0.0   0.0    0.0    0.0   86.0   0.0    0.0   0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    3.0   0.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    2.0    1.0    2.0   2.0    1.0    0.0   0.0    85.0   1.0   0.0    0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    3.0    0.0    0.0   9.0    2.0    14.0  2.0    0.0    75.0  0.0    0.29906542056074764  32 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0    10.0  1.0    0.0    0.0   0.0    3.0    0.0   67.0   0.22988505747126436  20 / 87
95.0  108.0  78.0  112.0  89.0  70.0  83.0  59.0  85.0  88.0  102.0  86.0  90.0  98.0  89.0  105.0  100.0  116.0  96.0  101.0  103.0  95.0  113.0  128.0  99.0  102.0  0.2321285140562249   578 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.767872
2    0.862651
3    0.906024
4    0.926908
5    0.94257
6    0.953414
7    0.965863
8    0.973494
9    0.97751
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:17  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:17  1 min 14.874 sec  147161 obs/sec    1         1             10007      0.747554         1.61925             0.99007        0.377287                         0.749512           1.61855               0.98999          0.385141
    2019-08-04 09:01:17  1 min 15.407 sec  172237 obs/sec    10        10            100070     0.534147         0.874873            0.99493        0.231231                         0.533498           0.869847              0.994928         0.232129
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0948769
C13         0.901103               0.901103             0.0854939
C12         0.8426                 0.8426               0.0799433
C8          0.772045               0.772045             0.0732492
C7          0.767901               0.767901             0.0728561
C9          0.756675               0.756675             0.071791
C11         0.703563               0.703563             0.0667519
C6          0.646816               0.646816             0.0613679
C14         0.643846               0.643846             0.0610861
C10         0.626597               0.626597             0.0594496
C3          0.537583               0.537583             0.0510042
C4          0.534589               0.534589             0.0507202
C5          0.517241               0.517241             0.0490742
C16         0.501922               0.501922             0.0476208
C2          0.418564               0.418564             0.039712
C1          0.368928               0.368928             0.0350028
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_124

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.000950487285052759  0.00025287666358053684  0.0         -0.011258757888199966  0.2457141876220703  0.04320321135357178  0.16678541898727417
    3        26       Softmax                      0.0   0.0   0.005212179548764722  0.009185265749692917    0.0         -0.28243103113248497   0.7207789421081543  -0.8551414702675084  0.5079927444458008


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.28110067878822964
RMSE: 0.5301892858104826
LogLoss: 0.8636220811771159
Mean Per-Class Error: 0.22421490530082583
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    5.0    0.0    4.0    0.0    3.0    0.0    0.0    0.0    7.0    0.0    2.0    2.0    1.0    3.0    5.0    0.0    0.09113924050632911  36 / 395
0.0    313.0  0.0    6.0    2.0    1.0    6.0    5.0    2.0    0.0    2.0    0.0    1.0    0.0    1.0    0.0    0.0    26.0   7.0    0.0    0.0    4.0    0.0    7.0    0.0    0.0    0.18276762402088773  70 / 383
0.0    0.0    296.0  0.0    15.0   1.0    13.0   2.0    0.0    0.0    24.0   0.0    1.0    0.0    3.0    0.0    2.0    0.0    6.0    2.0    2.0    0.0    0.0    0.0    0.0    1.0    0.1956521739130435   72 / 368
4.0    16.0   0.0    323.0  0.0    1.0    3.0    4.0    0.0    13.0   0.0    0.0    7.0    2.0    1.0    4.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    16.0   0.0    1.0    0.19851116625310175  80 / 403
0.0    11.0   0.0    0.0    288.0  3.0    24.0   0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    9.0    0.0    1.0    0.0    0.0    16.0   0.0    20.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    8.0    0.0    0.0    6.0    0.0    13.0   2.0    0.0    0.0    1.0    1.0    0.0    0.0    2.0    2.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    7.0    0.0    3.0    9.0    0.0    0.0    0.0    3.0    2.0    6.0    0.0    0.0    0.0    0.0    0.0    10.0   1.0    7.0    5.0    6.0    1.0    0.0    329.0  4.0    1.0    0.1649746192893401   65 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    13.0   0.0    13.0   40.0   3.0    46.0   1.0    0.0    269.0  0.0    0.31202046035805625  122 / 391
1.0    0.0    0.0    2.0    18.0   0.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    33.0   1.0    0.0    0.0    0.0    0.0    0.0    296.0  0.19346049046321526  71 / 367
406.0  526.0  346.0  442.0  386.0  340.0  360.0  269.0  345.0  360.0  426.0  318.0  466.0  341.0  369.0  374.0  352.0  404.0  370.0  395.0  399.0  432.0  418.0  460.0  331.0  368.0  0.22333300009997     2,234 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.776667
2    0.869139
3    0.906228
4    0.930821
5    0.947816
6    0.958912
7    0.96761
8    0.973008
9    0.977207
10   0.980706

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.284988859385251
RMSE: 0.53384347835789
LogLoss: 0.8722666550796769
Mean Per-Class Error: 0.2357943852489764
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6      7     8     9      10     11    12     13    14    15     16    17     18    19    20     21     22     23     24    25    Error                Rate
-----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  -----  ----  ----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0    0.0    1.0    3.0   0.0   0.07865168539325842  7 / 89
0.0    80.0   0.0   2.0    1.0   0.0   4.0    3.0   1.0   0.0    2.0    0.0   0.0    0.0   1.0   0.0    0.0   6.0    3.0   0.0   0.0    1.0    0.0    2.0    0.0   0.0   0.24528301886792453  26 / 106
0.0    0.0    61.0  0.0    2.0   0.0   6.0    1.0   0.0   0.0    6.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0    0.0    0.0    0.0   0.0   0.25609756097560976  21 / 82
3.0    3.0    0.0   92.0   0.0   0.0   1.0    2.0   0.0   2.0    0.0    0.0   3.0    0.0   0.0   2.0    0.0   1.0    1.0   0.0   0.0    0.0    0.0    2.0    0.0   0.0   0.17857142857142858  20 / 112
0.0    2.0    0.0   0.0    65.0  2.0   9.0    0.0   0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    3.0   0.0   0.0    0.0    0.0    3.0    0.0   10.0  0.32989690721649484  32 / 97
---    ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---    ---   ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    2.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0    84.0   0.0    0.0   0.0   0.08695652173913043  8 / 92
0.0    3.0    0.0   2.0    4.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0    2.0   1.0    2.0   0.0   2.0    0.0    0.0    80.0   1.0   1.0   0.2                  20 / 100
0.0    0.0    0.0   1.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    5.0   0.0    3.0   12.0  1.0    14.0   1.0    0.0    69.0  0.0   0.35514018691588783  38 / 107
0.0    0.0    0.0   1.0    6.0   0.0   0.0    0.0   0.0   3.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0    6.0   0.0   0.0    0.0    0.0    0.0    0.0   70.0  0.19540229885057472  17 / 87
100.0  127.0  72.0  130.0  86.0  75.0  100.0  67.0  80.0  103.0  107.0  85.0  104.0  88.0  71.0  109.0  97.0  102.0  95.0  92.0  100.0  100.0  103.0  109.0  90.0  98.0  0.23493975903614459  585 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.76506
2    0.866265
3    0.905622
4    0.93012
5    0.947791
6    0.960643
7    0.967068
8    0.971486
9    0.977912
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:31  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:31  3 min 28.938 sec  145028 obs/sec    1         1             10007      0.747449         1.62377             0.990069       0.402379                         0.749777           1.63344               0.989983         0.403213
    2019-08-04 09:03:31  3 min 29.473 sec  170767 obs/sec    10        10            100070     0.530189         0.863622            0.995003       0.223333                         0.533843           0.872267              0.994922         0.23494
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.09221
C15         0.997458               0.997458             0.0919756
C9          0.85354                0.85354              0.0787049
C8          0.819065               0.819065             0.0755261
C7          0.815412               0.815412             0.0751892
C12         0.81233                0.81233              0.074905
C11         0.69804                0.69804              0.0643663
C6          0.651285               0.651285             0.060055
C14         0.625446               0.625446             0.0576724
C10         0.592223               0.592223             0.0546089
C5          0.563836               0.563836             0.0519913
C16         0.5596                 0.5596               0.0516007
C3          0.544078               0.544078             0.0501695
C4          0.515099               0.515099             0.0474973
C1          0.402473               0.402473             0.0371121
C2          0.394921               0.394921             0.0364156
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_15

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.001279995366331832  0.0003263182006776333   0.0         0.0450682618867404    1.2035174369812012  0.24942885081610708  1.0387787818908691
    3        26       Softmax                 0.0   0.0   0.00173563952089003   0.00021753378678113222  0.0         -0.01728226144812722  0.4552299976348877  -0.568971709162647   0.3455665111541748


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.30191981864544615
RMSE: 0.5494723092617554
LogLoss: 0.9768788623941157
Mean Per-Class Error: 0.2791156055759122
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    4.0    0.0    0.0    1.0    0.0    0.0    1.0    2.0    0.0    5.0    1.0    1.0    0.0    3.0    2.0    5.0    0.0    0.0    0.0    9.0    0.0    6.0    0.0    0.10126582278481013  40 / 395
0.0    265.0  0.0    4.0    0.0    3.0    1.0    8.0    1.0    4.0    0.0    0.0    1.0    0.0    0.0    4.0    8.0    53.0   20.0   0.0    0.0    1.0    2.0    1.0    7.0    0.0    0.30809399477806787  118 / 383
0.0    0.0    286.0  0.0    18.0   7.0    8.0    1.0    0.0    0.0    29.0   1.0    0.0    0.0    1.0    0.0    4.0    0.0    4.0    1.0    2.0    0.0    4.0    0.0    0.0    1.0    0.22070844686648503  81 / 367
8.0    17.0   0.0    304.0  0.0    0.0    0.0    12.0   0.0    9.0    0.0    0.0    9.0    3.0    11.0   1.0    0.0    14.0   0.0    2.0    1.0    0.0    0.0    10.0   1.0    1.0    0.2456575682382134   99 / 403
0.0    5.0    8.0    0.0    255.0  1.0    21.0   3.0    4.0    0.0    11.0   1.0    0.0    0.0    0.0    2.0    11.0   9.0    7.0    8.0    0.0    0.0    0.0    10.0   2.0    26.0   0.3359375            129 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    1.0    0.0    23.0   5.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    3.0    330.0  0.0    0.0    0.0    0.12234042553191489  46 / 376
0.0    7.0    0.0    14.0   7.0    0.0    3.0    5.0    5.0    1.0    12.0   1.0    0.0    0.0    0.0    1.0    17.0   7.0    18.0   7.0    3.0    0.0    0.0    279.0  6.0    0.0    0.2900763358778626   114 / 393
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    1.0    10.0   0.0    3.0    72.0   7.0    25.0   2.0    0.0    265.0  0.0    0.3256997455470738   128 / 393
1.0    6.0    0.0    1.0    20.0   2.0    1.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    32.0   5.0    0.0    0.0    0.0    5.0    0.0    288.0  0.21525885558583105  79 / 367
417.0  463.0  402.0  419.0  381.0  367.0  278.0  346.0  320.0  348.0  364.0  336.0  466.0  332.0  370.0  369.0  402.0  492.0  302.0  433.0  377.0  351.0  499.0  375.0  384.0  410.0  0.2782165350394882   2,783 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.721783
2    0.836449
3    0.885434
4    0.914426
5    0.93192
6    0.944517
7    0.955713
8    0.96501
9    0.971808
10   0.977407

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3029926783625864
RMSE: 0.5504477072007716
LogLoss: 0.9841327022828568
Mean Per-Class Error: 0.2867031698079669
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19     20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0    0.0   3.0    0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   68.0   0.0   1.0    0.0   1.0   1.0   3.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0   2.0    4.0    15.0   4.0   0.0    0.0    1.0   1.0    1.0   2.0    0.0   0.3584905660377358   38 / 106
0.0   0.0    60.0  0.0    4.0   2.0   2.0   0.0   0.0   0.0    7.0   0.0   0.0    0.0   1.0   0.0    2.0    0.0    2.0   0.0    1.0    0.0   1.0    0.0   0.0    0.0   0.2682926829268293   22 / 82
4.0   5.0    0.0   83.0   0.0   0.0   0.0   5.0   0.0   1.0    0.0   0.0   4.0    1.0   4.0   1.0    0.0    2.0    0.0   0.0    0.0    0.0   0.0    1.0   0.0    1.0   0.25892857142857145  29 / 112
0.0   1.0    2.0   0.0    62.0  0.0   3.0   2.0   1.0   0.0    3.0   1.0   0.0    0.0   0.0   0.0    3.0    3.0    1.0   4.0    0.0    0.0   0.0    2.0   0.0    9.0   0.36082474226804123  35 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   7.0    2.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0    0.0   81.0   0.0   0.0    0.0   0.11956521739130435  11 / 92
0.0   2.0    0.0   4.0    3.0   0.0   0.0   2.0   3.0   0.0    4.0   1.0   0.0    0.0   0.0   0.0    3.0    3.0    4.0   2.0    2.0    0.0   0.0    67.0  0.0    0.0   0.33                 33 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   1.0   0.0    2.0    0.0    0.0   17.0   2.0    7.0   2.0    0.0   75.0   0.0   0.29906542056074764  32 / 107
0.0   0.0    0.0   1.0    5.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0    9.0   3.0    0.0    0.0   0.0    1.0   0.0    66.0  0.2413793103448276   21 / 87
98.0  115.0  85.0  113.0  93.0  78.0  59.0  97.0  71.0  100.0  90.0  94.0  104.0  86.0  76.0  107.0  109.0  124.0  83.0  107.0  101.0  76.0  129.0  89.0  107.0  99.0  0.28674698795180725  714 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.713253
2    0.835341
3    0.888755
4    0.916466
5    0.931325
6    0.941767
7    0.952611
8    0.965462
9    0.971486
10   0.977109
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:32  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:32  30.436 sec  90972 obs/sec     1         1             10007      0.64647          1.30148             0.992572       0.360692                         0.645691           1.30105               0.992571         0.356627
    2019-08-04 09:00:33  31.403 sec  94943 obs/sec     10        10            100070     0.549472         0.976879            0.994634       0.278217                         0.550448           0.984133              0.994601         0.286747
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0907433
C15         0.959958               0.959958             0.0871098
C9          0.941667               0.941667             0.08545
C13         0.906156               0.906156             0.0822276
C11         0.831272               0.831272             0.0754324
C7          0.810043               0.810043             0.073506
C14         0.762185               0.762185             0.0691632
C8          0.739989               0.739989             0.067149
C10         0.691026               0.691026             0.062706
C6          0.598851               0.598851             0.0543417
C16         0.593901               0.593901             0.0538925
C3          0.50468                0.50468              0.0457964
C4          0.464363               0.464363             0.0421378
C5          0.458462               0.458462             0.0416024
C1          0.385714               0.385714             0.035001
C2          0.371828               0.371828             0.0337409
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_65

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.001309105130133048  0.0003552483394742012   0.0         -0.018048894515032998  1.2416744232177734   0.09475084972433426  1.043614387512207
    3        26       Softmax                 0.0   0.0   0.001760107507065046  0.00021352909971028566  0.0         -0.005517392982010978  0.45283663272857666  -0.5479223860306282  0.3245985507965088


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3028649553874984
RMSE: 0.5503316776158705
LogLoss: 0.9718235729233805
Mean Per-Class Error: 0.27744421918028606
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  1.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    10.0   1.0    0.0    0.0    1.0    0.0    4.0    1.0    1.0    1.0    6.0    0.0    4.0    0.0    0.09367088607594937  37 / 395
0.0    257.0  0.0    11.0   1.0    0.0    2.0    10.0   1.0    1.0    1.0    0.0    0.0    0.0    0.0    2.0    2.0    41.0   44.0   0.0    0.0    0.0    1.0    2.0    6.0    1.0    0.3289817232375979   126 / 383
0.0    0.0    290.0  0.0    7.0    5.0    21.0   0.0    0.0    0.0    14.0   0.0    0.0    0.0    2.0    1.0    6.0    1.0    9.0    2.0    4.0    0.0    5.0    1.0    0.0    0.0    0.21195652173913043  78 / 368
6.0    18.0   0.0    293.0  0.0    1.0    0.0    15.0   1.0    3.0    0.0    5.0    6.0    3.0    12.0   7.0    0.0    13.0   1.0    2.0    0.0    0.0    0.0    16.0   0.0    1.0    0.2729528535980149   110 / 403
0.0    5.0    5.0    0.0    257.0  4.0    17.0   0.0    1.0    0.0    4.0    2.0    0.0    0.0    0.0    0.0    15.0   6.0    10.0   8.0    0.0    0.0    0.0    3.0    4.0    43.0   0.3307291666666667   127 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    15.0   0.0    0.0    0.0    0.0    9.0    9.0    8.0    0.0    0.0    3.0    0.0    0.0    0.0    6.0    324.0  0.0    0.0    0.0    0.13829787234042554  52 / 376
0.0    19.0   0.0    3.0    14.0   1.0    0.0    2.0    13.0   0.0    5.0    4.0    0.0    0.0    2.0    0.0    17.0   0.0    14.0   12.0   3.0    0.0    0.0    266.0  6.0    12.0   0.3231552162849873   127 / 393
0.0    1.0    0.0    1.0    0.0    13.0   0.0    4.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    7.0    1.0    0.0    7.0    68.0   2.0    19.0   2.0    0.0    265.0  0.0    0.3256997455470738   128 / 393
1.0    2.0    0.0    1.0    9.0    7.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    40.0   2.0    0.0    0.0    0.0    4.0    0.0    297.0  0.1907356948228883   70 / 367
410.0  463.0  365.0  395.0  346.0  368.0  322.0  292.0  341.0  335.0  337.0  362.0  441.0  374.0  389.0  379.0  378.0  489.0  381.0  423.0  407.0  350.0  465.0  347.0  400.0  444.0  0.27651704488653406  2,766 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.723483
2    0.839248
3    0.887234
4    0.914626
5    0.93212
6    0.946216
7    0.957313
8    0.96581
9    0.971309
10   0.976607

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3048199216789141
RMSE: 0.5521049915359524
LogLoss: 0.9855034482377024
Mean Per-Class Error: 0.28248160497685004
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11     12     13    14    15     16     17     18     19     20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  -----  -----  -----  -----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0   3.0    0.0   2.0    0.0    0.07865168539325842  7 / 89
0.0   64.0   0.0   3.0    0.0   0.0   2.0   5.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    1.0    15.0   13.0   0.0    0.0    0.0   1.0    1.0   1.0    0.0    0.39622641509433965  42 / 106
0.0   0.0    59.0  0.0    1.0   1.0   5.0   0.0   0.0   0.0   3.0   0.0    0.0    0.0   2.0   1.0    3.0    0.0    3.0    1.0    2.0    0.0   1.0    0.0   0.0    0.0    0.2804878048780488   23 / 82
3.0   3.0    0.0   85.0   0.0   1.0   0.0   3.0   0.0   1.0   0.0   4.0    3.0    1.0   5.0   1.0    0.0    1.0    0.0    0.0    0.0    0.0   0.0    1.0   0.0    0.0    0.24107142857142858  27 / 112
0.0   1.0    0.0   0.0    61.0  3.0   5.0   0.0   0.0   0.0   3.0   2.0    0.0    0.0   0.0   0.0    3.0    1.0    2.0    3.0    0.0    0.0   0.0    0.0   0.0    13.0   0.3711340206185567   36 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---    ---    ---    ---    ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   2.0   0.0   0.0   0.0   0.0    3.0    4.0   1.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0   80.0   0.0   0.0    0.0    0.13043478260869565  12 / 92
0.0   6.0    0.0   1.0    6.0   0.0   0.0   1.0   3.0   0.0   3.0   2.0    0.0    0.0   0.0   0.0    3.0    0.0    5.0    3.0    1.0    0.0   0.0    61.0  2.0    3.0    0.39                 39 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   3.0   0.0   0.0   0.0   0.0    1.0    1.0   0.0   1.0    1.0    0.0    0.0    18.0   0.0    4.0   1.0    0.0   74.0   0.0    0.308411214953271    33 / 107
0.0   1.0    0.0   1.0    2.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0    0.0    6.0    1.0    0.0    0.0   0.0    1.0   0.0    71.0   0.1839080459770115   16 / 87
99.0  112.0  72.0  111.0  81.0  88.0  81.0  79.0  77.0  94.0  88.0  100.0  105.0  98.0  77.0  113.0  100.0  119.0  101.0  101.0  106.0  77.0  113.0  77.0  110.0  111.0  0.2823293172690763   703 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.717671
2    0.837751
3    0.883133
4    0.908835
5    0.928113
6    0.940964
7    0.951004
8    0.963052
9    0.966667
10   0.973092
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:49  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:49  1 min 47.066 sec  92657 obs/sec     1         1             10007      0.641908         1.30126             0.992678       0.357293                         0.639968           1.29847               0.992702         0.360241
    2019-08-04 09:01:50  1 min 48.035 sec  94584 obs/sec     10        10            100070     0.550332         0.971824            0.994618       0.276517                         0.552105           0.985503              0.994569         0.282329
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0926999
C12         0.965489               0.965489             0.0895008
C9          0.915863               0.915863             0.0849004
C13         0.885267               0.885267             0.0820642
C7          0.84583                0.84583              0.0784084
C8          0.785773               0.785773             0.0728411
C11         0.756228               0.756228             0.0701023
C14         0.731364               0.731364             0.0677974
C10         0.676363               0.676363             0.0626988
C16         0.578659               0.578659             0.0536417
C6          0.56304                0.56304              0.0521938
C3          0.479946               0.479946             0.044491
C5          0.445037               0.445037             0.0412549
C4          0.436998               0.436998             0.0405097
C1          0.361042               0.361042             0.0334686
C2          0.360595               0.360595             0.0334271
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_111

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.001146258958897306  0.00030676345340907574  0.0         0.024437005309664528  1.0109515190124512  0.12766136539001638  1.127758502960205
    3        26       Softmax                 0.0   0.0   0.001813905482777045  0.00020576594397425652  0.0         0.007173975062659548  0.5920524597167969  -0.4848212076203975  0.24956941604614258


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3048518310238023
RMSE: 0.5521338886753849
LogLoss: 0.9831623427138695
Mean Per-Class Error: 0.281263912251314
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    5.0    1.0    4.0    3.0    4.0    0.0    3.0    1.0    5.0    0.0    1.0    0.0    1.0    2.0    6.0    0.0    0.09873417721518987  39 / 395
1.0    285.0  0.0    6.0    4.0    3.0    3.0    13.0   0.0    0.0    2.0    0.0    2.0    1.0    0.0    6.0    2.0    32.0   16.0   0.0    0.0    4.0    0.0    2.0    1.0    0.0    0.2558746736292428   98 / 383
0.0    0.0    263.0  0.0    28.0   7.0    30.0   0.0    0.0    0.0    20.0   0.0    0.0    0.0    2.0    0.0    3.0    1.0    3.0    2.0    3.0    0.0    1.0    0.0    0.0    5.0    0.28532608695652173  105 / 368
5.0    18.0   0.0    308.0  0.0    1.0    0.0    5.0    0.0    5.0    0.0    1.0    2.0    5.0    4.0    10.0   0.0    22.0   6.0    2.0    5.0    0.0    0.0    4.0    0.0    0.0    0.23573200992555832  95 / 403
0.0    4.0    16.0   0.0    253.0  0.0    19.0   2.0    2.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    5.0    3.0    6.0    6.0    1.0    0.0    0.0    13.0   3.0    43.0   0.3411458333333333   131 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    12.0   2.0    3.0    4.0    0.0    11.0   0.0    0.0    0.0    0.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    4.0    0.0    11.0   12.0   2.0    2.0    3.0    0.0    7.0    9.0    3.0    0.0    0.0    0.0    0.0    20.0   5.0    12.0   16.0   3.0    0.0    0.0    257.0  15.0   13.0   0.3477157360406091   137 / 394
1.0    0.0    0.0    0.0    0.0    7.0    0.0    5.0    0.0    1.0    1.0    0.0    0.0    2.0    3.0    2.0    6.0    0.0    8.0    63.0   2.0    17.0   2.0    0.0    271.0  1.0    0.3086734693877551   121 / 392
4.0    0.0    0.0    1.0    17.0   3.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    3.0    4.0    0.0    52.0   5.0    0.0    0.0    0.0    4.0    4.0    268.0  0.26975476839237056  99 / 367
450.0  462.0  367.0  466.0  393.0  376.0  360.0  279.0  319.0  341.0  389.0  330.0  433.0  373.0  351.0  390.0  374.0  486.0  305.0  464.0  390.0  358.0  435.0  341.0  356.0  415.0  0.28001599520143955  2,801 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.719984
2    0.835749
3    0.882135
4    0.913126
5    0.929221
6    0.943917
7    0.955713
8    0.963211
9    0.968909
10   0.974508

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.30632304170086017
RMSE: 0.5534645803489688
LogLoss: 0.9887317724110796
Mean Per-Class Error: 0.28285159072970795
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16    17     18    19     20     21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.0   1.0    0.0   3.0    0.0    0.07865168539325842  7 / 89
0.0    74.0   0.0   1.0    1.0   0.0   1.0   7.0   0.0   0.0   1.0   0.0   1.0   0.0    0.0   2.0    1.0   8.0    4.0   0.0    0.0    3.0   0.0    2.0   0.0    0.0    0.3018867924528302   32 / 106
0.0    0.0    56.0  0.0    3.0   3.0   8.0   0.0   0.0   0.0   6.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    2.0   1.0    0.0    0.0   0.0    0.0   0.0    2.0    0.3170731707317073   26 / 82
3.0    3.0    0.0   87.0   0.0   1.0   0.0   3.0   0.0   0.0   0.0   0.0   2.0   1.0    1.0   2.0    0.0   4.0    3.0   0.0    1.0    0.0   0.0    1.0   0.0    0.0    0.22321428571428573  25 / 112
0.0    0.0    2.0   0.0    62.0  0.0   5.0   1.0   1.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   2.0    0.0    0.0   0.0    4.0   0.0    13.0   0.36082474226804123  35 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   2.0    1.0   0.0    0.0   2.0    0.0   0.0    0.0    0.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0    1.0    0.0   5.0    4.0   0.0   0.0   2.0   0.0   1.0   3.0   0.0   0.0   0.0    0.0   0.0    3.0   2.0    1.0   5.0    1.0    0.0   0.0    67.0  3.0    2.0    0.33                 33 / 100
1.0    0.0    0.0   0.0    0.0   1.0   0.0   2.0   0.0   1.0   1.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0    1.0   13.0   1.0    4.0   0.0    0.0   80.0   0.0    0.2523364485981308   27 / 107
1.0    0.0    0.0   1.0    5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    8.0   2.0    0.0    0.0   0.0    1.0   1.0    66.0   0.2413793103448276   21 / 87
111.0  113.0  75.0  140.0  92.0  84.0  83.0  83.0  73.0  97.0  97.0  85.0  93.0  102.0  75.0  114.0  94.0  111.0  72.0  108.0  100.0  80.0  107.0  89.0  104.0  108.0  0.28112449799196787  700 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.718876
2    0.835341
3    0.881124
4    0.910843
5    0.926104
6    0.940562
7    0.954217
8    0.961446
9    0.968273
10   0.974297
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:07  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:07  3 min  5.073 sec  138986 obs/sec    1         1             10007      0.712759         1.57719             0.990972       0.440968                         0.708163           1.55387               0.991064         0.436948
    2019-08-04 09:03:07  3 min  5.720 sec  141943 obs/sec    10        10            100070     0.552134         0.983162            0.994583       0.280016                         0.553465           0.988732              0.994542         0.281124
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0920103
C15         0.975785               0.975785             0.0897822
C9          0.944657               0.944657             0.0869181
C11         0.89527                0.89527              0.082374
C7          0.860693               0.860693             0.0791926
C14         0.825834               0.825834             0.0759852
C13         0.824386               0.824386             0.075852
C10         0.714761               0.714761             0.0657654
C8          0.706084               0.706084             0.064967
C6          0.650252               0.650252             0.0598298
C16         0.581449               0.581449             0.0534993
C5          0.458467               0.458467             0.0421836
C3          0.420832               0.420832             0.0387209
C4          0.364157               0.364157             0.0335061
C2          0.331533               0.331533             0.0305044
C1          0.314194               0.314194             0.0289091
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_143

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.001103019933680116   0.0002512828214094043   0.0         0.01732095400370781    1.0238094329833984  0.10689160471815565  0.8941361904144287
    3        26       Softmax                 0.0   0.0   0.0017780512350257665  0.00016960850916802883  0.0         -0.023036118963948235  0.6024694442749023  -0.4893076449106065  0.28796494007110596


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3002907547508158
RMSE: 0.547987914785368
LogLoss: 0.977569257373528
Mean Per-Class Error: 0.2772517151879629
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    1.0    4.0    1.0    6.0    3.0    0.09390862944162437  37 / 394
0.0    293.0  0.0    11.0   5.0    1.0    2.0    7.0    2.0    3.0    4.0    0.0    2.0    0.0    3.0    2.0    0.0    23.0   17.0   0.0    0.0    0.0    1.0    4.0    2.0    1.0    0.2349869451697128   90 / 383
0.0    0.0    270.0  0.0    16.0   3.0    37.0   2.0    0.0    0.0    19.0   0.0    1.0    0.0    6.0    1.0    1.0    1.0    1.0    3.0    2.0    0.0    5.0    0.0    0.0    0.0    0.266304347826087    98 / 368
7.0    25.0   0.0    291.0  0.0    4.0    0.0    7.0    0.0    12.0   0.0    2.0    7.0    5.0    4.0    11.0   0.0    13.0   5.0    3.0    1.0    0.0    1.0    5.0    0.0    0.0    0.27791563275434245  112 / 403
0.0    8.0    1.0    0.0    263.0  1.0    37.0   2.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    2.0    2.0    6.0    8.0    1.0    2.0    0.0    8.0    1.0    30.0   0.3151041666666667   121 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    13.0   4.0    5.0    0.0    0.0    14.0   0.0    0.0    0.0    7.0    329.0  0.0    0.0    0.0    0.125                47 / 376
2.0    4.0    0.0    0.0    7.0    3.0    16.0   9.0    9.0    7.0    20.0   5.0    0.0    0.0    0.0    1.0    14.0   3.0    7.0    5.0    5.0    0.0    0.0    233.0  9.0    35.0   0.4086294416243655   161 / 394
0.0    0.0    0.0    0.0    0.0    4.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    1.0    4.0    0.0    7.0    60.0   1.0    26.0   1.0    1.0    278.0  0.0    0.2926208651399491   115 / 393
3.0    1.0    0.0    1.0    21.0   2.0    0.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    31.0   4.0    0.0    0.0    0.0    6.0    0.0    286.0  0.22070844686648503  81 / 367
417.0  521.0  381.0  400.0  403.0  318.0  386.0  304.0  333.0  388.0  400.0  325.0  435.0  377.0  389.0  365.0  347.0  455.0  250.0  459.0  378.0  366.0  432.0  326.0  384.0  464.0  0.27641707487753675  2,765 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.723583
2    0.838049
3    0.882435
4    0.911726
5    0.93182
6    0.943317
7    0.953014
8    0.959712
9    0.96781
10   0.973408

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.303360128693962
RMSE: 0.5507813801264182
LogLoss: 0.9916786192495232
Mean Per-Class Error: 0.2797234773862972
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6      7     8     9      10    11    12    13    14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   2.0    0.0   3.0    0.0    0.06741573033707865  6 / 89
0.0    76.0   0.0   4.0    0.0   0.0   2.0    3.0   0.0   1.0    1.0   0.0   0.0   0.0   2.0   0.0    0.0   9.0    5.0   0.0   0.0   0.0   1.0    2.0   0.0    0.0    0.2830188679245283   30 / 106
0.0    0.0    59.0  0.0    4.0   2.0   9.0    0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.2804878048780488   23 / 82
5.0    8.0    0.0   79.0   0.0   1.0   0.0    2.0   0.0   1.0    0.0   1.0   2.0   1.0   1.0   4.0    0.0   3.0    2.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0    0.29464285714285715  33 / 112
0.0    3.0    1.0   0.0    60.0  0.0   11.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   4.0   0.0   1.0   0.0    1.0   0.0    10.0   0.38144329896907214  37 / 97
---    ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   3.0   0.0   1.0   0.0    0.0   2.0    0.0   0.0   0.0   1.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
1.0    1.0    0.0   0.0    2.0   0.0   1.0    5.0   3.0   1.0    5.0   1.0   0.0   0.0   0.0   0.0    3.0   1.0    5.0   0.0   2.0   0.0   0.0    60.0  4.0    5.0    0.4                  40 / 100
0.0    0.0    0.0   0.0    0.0   3.0   4.0    0.0   0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    2.0   0.0    2.0   10.0  0.0   8.0   1.0    0.0   76.0   0.0    0.2897196261682243   31 / 107
0.0    1.0    0.0   1.0    8.0   0.0   0.0    0.0   0.0   2.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    5.0   2.0   0.0   0.0   0.0    2.0   0.0    64.0   0.26436781609195403  23 / 87
103.0  136.0  84.0  112.0  93.0  73.0  100.0  80.0  76.0  114.0  99.0  86.0  96.0  95.0  79.0  110.0  83.0  116.0  64.0  96.0  99.0  87.0  113.0  85.0  105.0  106.0  0.2791164658634538   695 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.720884
2    0.829317
3    0.878313
4    0.910442
5    0.927711
6    0.939357
7    0.950201
8    0.95743
9    0.965863
10   0.972289
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:55  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:55  3 min 53.735 sec  138986 obs/sec    1         1             10007      0.698736         1.50504             0.991324       0.417675                         0.694665           1.48309               0.991401         0.417269
    2019-08-04 09:03:56  3 min 54.425 sec  134502 obs/sec    10        10            100070     0.547988         0.977569            0.994664       0.276417                         0.550781           0.991679              0.994595         0.279116
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0915748
C8          0.896783               0.896783             0.0821226
C9          0.875821               0.875821             0.0802031
C13         0.869567               0.869567             0.0796303
C12         0.837056               0.837056             0.0766532
C14         0.794743               0.794743             0.0727784
C11         0.761534               0.761534             0.0697373
C7          0.748105               0.748105             0.0685076
C16         0.702828               0.702828             0.0643613
C10         0.685422               0.685422             0.0627673
C6          0.602872               0.602872             0.0552079
C5          0.546036               0.546036             0.0500031
C3          0.479854               0.479854             0.0439425
C4          0.434247               0.434247             0.039766
C1          0.363962               0.363962             0.0333297
C2          0.32121                0.32121              0.0294148
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_229

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012742408296162466  0.00035574077628552914  0.0         -0.004667069012612046  1.2554025650024414   -0.22758109736302834  1.141139030456543
    3        26       Softmax                 0.0   0.0   0.001723992112671952   0.00015510531375184655  0.0         0.015515045481151901   0.44950246810913086  -0.5540594873721736   0.31166934967041016


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.31427428098830074
RMSE: 0.5606017133297941
LogLoss: 1.0137104791912912
Mean Per-Class Error: 0.2943166924322775
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    1.0    2.0    0.0    5.0    0.0    4.0    0.0    0.0    2.0    4.0    0.0    1.0    3.0    4.0    0.0    4.0    0.0    0.08860759493670886  35 / 395
0.0    272.0  0.0    3.0    2.0    1.0    1.0    13.0   9.0    1.0    1.0    0.0    0.0    0.0    2.0    4.0    7.0    44.0   15.0   0.0    0.0    1.0    0.0    2.0    5.0    0.0    0.2898172323759791   111 / 383
0.0    0.0    273.0  0.0    25.0   2.0    15.0   0.0    0.0    0.0    19.0   0.0    2.0    0.0    5.0    0.0    4.0    0.0    8.0    6.0    4.0    0.0    4.0    0.0    0.0    1.0    0.25815217391304346  95 / 368
8.0    19.0   0.0    294.0  0.0    3.0    0.0    10.0   0.0    4.0    0.0    2.0    7.0    6.0    4.0    8.0    0.0    23.0   0.0    1.0    0.0    0.0    0.0    9.0    1.0    4.0    0.2704714640198511   109 / 403
0.0    4.0    2.0    0.0    262.0  3.0    19.0   2.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    19.0   2.0    21.0   3.0    0.0    0.0    0.0    7.0    1.0    32.0   0.3177083333333333   122 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    2.0    0.0    20.0   1.0    5.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
1.0    5.0    0.0    3.0    11.0   0.0    6.0    1.0    22.0   5.0    12.0   2.0    0.0    0.0    2.0    2.0    23.0   5.0    10.0   14.0   7.0    0.0    0.0    232.0  11.0   20.0   0.41116751269035534  162 / 394
0.0    0.0    0.0    1.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    9.0    7.0    0.0    8.0    94.0   1.0    70.0   5.0    0.0    191.0  0.0    0.5139949109414759   202 / 393
5.0    2.0    0.0    1.0    24.0   11.0   0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    41.0   3.0    0.0    0.0    0.0    4.0    0.0    269.0  0.2670299727520436   98 / 367
435.0  496.0  347.0  421.0  384.0  324.0  315.0  254.0  369.0  333.0  325.0  330.0  458.0  388.0  402.0  403.0  414.0  466.0  346.0  488.0  384.0  429.0  470.0  323.0  290.0  409.0  0.2932120363890833   2,933 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.706788
2    0.827652
3    0.876837
4    0.905128
5    0.926922
6    0.940518
7    0.952414
8    0.962011
9    0.968809
10   0.974508

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3155033838272659
RMSE: 0.5616968789545354
LogLoss: 1.0083892515610744
Mean Per-Class Error: 0.30026624943491753
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16     17     18    19     20    21    22     23    24    25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0    0.0    1.0    1.0   0.0    0.0   0.0   1.0    0.0   3.0   0.0   0.07865168539325842  7 / 89
0.0    70.0   0.0   0.0    0.0   0.0   0.0   4.0   2.0   0.0   1.0   0.0   0.0    0.0    1.0   1.0    5.0    17.0   2.0   0.0    0.0   1.0   0.0    1.0   1.0   0.0   0.33962264150943394  36 / 106
0.0    0.0    55.0  0.0    6.0   0.0   6.0   0.0   0.0   0.0   5.0   0.0   0.0    0.0    2.0   0.0    0.0    0.0    4.0   1.0    2.0   0.0   1.0    0.0   0.0   0.0   0.32926829268292684  27 / 82
3.0    5.0    0.0   87.0   0.0   0.0   0.0   2.0   0.0   1.0   0.0   0.0   3.0    1.0    2.0   2.0    0.0    5.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.22321428571428573  25 / 112
0.0    0.0    0.0   0.0    70.0  3.0   6.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    5.0    1.0    2.0   0.0    0.0   0.0   0.0    3.0   0.0   7.0   0.27835051546391754  27 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   6.0    0.0    1.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   83.0   0.0   0.0   0.0   0.09782608695652174  9 / 92
0.0    3.0    0.0   0.0    5.0   0.0   1.0   1.0   5.0   0.0   4.0   0.0   0.0    0.0    0.0   2.0    3.0    1.0    4.0   4.0    1.0   0.0   0.0    56.0  3.0   7.0   0.44                 44 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0    2.0    0.0    1.0   24.0   0.0   18.0  3.0    0.0   53.0  0.0   0.5046728971962616   54 / 107
1.0    0.0    0.0   1.0    6.0   4.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0    10.0  1.0    0.0   0.0   0.0    0.0   0.0   62.0  0.28735632183908044  25 / 87
100.0  112.0  70.0  128.0  99.0  69.0  87.0  66.0  84.0  89.0  84.0  88.0  105.0  101.0  78.0  124.0  103.0  119.0  92.0  116.0  99.0  97.0  122.0  78.0  82.0  98.0  0.2987951807228916   744 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.701205
2    0.828916
3    0.878715
4    0.906024
5    0.927711
6    0.941365
7    0.953815
8    0.963052
9    0.971486
10   0.97751
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:44  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:44  6 min 42.307 sec  90153 obs/sec     1         1             10007      0.650937         1.32165             0.992471       0.356993                         0.6491             1.30916               0.992492         0.357831
    2019-08-04 09:06:45  6 min 43.323 sec  90561 obs/sec     10        10            100070     0.560602         1.01371             0.994415       0.293212                         0.561697           1.00839               0.994378         0.298795
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0872603
C12         0.99977                0.99977              0.0872402
C15         0.988522               0.988522             0.0862587
C9          0.981623               0.981623             0.0856567
C11         0.865926               0.865926             0.0755609
C7          0.839261               0.839261             0.0732342
C8          0.800503               0.800503             0.0698521
C14         0.751352               0.751352             0.0655632
C10         0.667744               0.667744             0.0582676
C16         0.654046               0.654046             0.0570723
C6          0.615746               0.615746             0.0537302
C3          0.526947               0.526947             0.0459816
C5          0.52094                0.52094              0.0454574
C4          0.480554               0.480554             0.0419333
C2          0.392762               0.392762             0.0342725
C1          0.374273               0.374273             0.0326592
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_107

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.00133078979581569   0.0003581562777981162   0.0         -0.045206055009003876  1.2835960388183594  -0.20354138784888468  1.079533576965332
    3        26       Softmax                 0.0   0.0   0.001742244200753563  0.00020117068197578192  0.0         0.036964700722399775   0.4480079412460327  -0.5275662142722731   0.3192387819290161


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.30858282341105275
RMSE: 0.5555023162967484
LogLoss: 1.0065650187681725
Mean Per-Class Error: 0.28337366160342065
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  3.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    8.0    2.0    0.0    10.0   4.0    1.0    0.0    1.0    2.0    1.0    0.0    0.0    1.0    4.0    0.0    4.0    0.0    0.11139240506329114  44 / 395
0.0    308.0  0.0    9.0    0.0    2.0    5.0    3.0    4.0    0.0    1.0    0.0    2.0    0.0    3.0    1.0    3.0    25.0   8.0    0.0    0.0    2.0    4.0    2.0    1.0    0.0    0.195822454308094    75 / 383
0.0    0.0    264.0  0.0    22.0   2.0    18.0   0.0    0.0    0.0    23.0   1.0    0.0    0.0    2.0    0.0    6.0    0.0    6.0    2.0    10.0   0.0    5.0    0.0    0.0    6.0    0.28065395095367845  103 / 367
7.0    17.0   0.0    302.0  0.0    3.0    0.0    3.0    0.0    8.0    1.0    0.0    8.0    3.0    5.0    8.0    0.0    21.0   3.0    0.0    2.0    0.0    0.0    10.0   0.0    2.0    0.2506203473945409   101 / 403
0.0    26.0   2.0    0.0    238.0  2.0    11.0   0.0    3.0    1.0    8.0    0.0    0.0    0.0    0.0    1.0    19.0   4.0    5.0    8.0    0.0    0.0    0.0    7.0    0.0    49.0   0.3802083333333333   146 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    14.0   3.0    1.0    0.0    0.0    2.0    0.0    0.0    4.0    3.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
1.0    9.0    0.0    7.0    10.0   2.0    9.0    2.0    11.0   3.0    11.0   3.0    0.0    0.0    0.0    0.0    12.0   4.0    19.0   14.0   4.0    0.0    0.0    210.0  20.0   43.0   0.467005076142132    184 / 394
0.0    1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    4.0    7.0    0.0    7.0    51.0   2.0    64.0   2.0    0.0    243.0  0.0    0.3816793893129771   150 / 393
5.0    7.0    0.0    0.0    13.0   3.0    1.0    0.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    27.0   3.0    0.0    0.0    0.0    4.0    1.0    293.0  0.2016348773841962   74 / 367
439.0  605.0  319.0  420.0  346.0  347.0  398.0  225.0  329.0  341.0  367.0  326.0  469.0  347.0  388.0  406.0  356.0  461.0  244.0  410.0  408.0  408.0  474.0  285.0  376.0  509.0  0.28241527541737477  2,825 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.717585
2    0.830851
3    0.875437
4    0.906728
5    0.928621
6    0.942017
7    0.953114
8    0.961212
9    0.96791
10   0.974408

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3102100469586099
RMSE: 0.5569650320788638
LogLoss: 1.0145504301388832
Mean Per-Class Error: 0.28804648789409915
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   2.0    0.0   2.0    0.0    0.07865168539325842  7 / 89
0.0    79.0   0.0   1.0    0.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   1.0    0.0   1.0   1.0    2.0   12.0   2.0   0.0   0.0    0.0   3.0    1.0   0.0    0.0    0.25471698113207547  27 / 106
0.0    0.0    54.0  0.0    6.0   0.0   4.0   0.0   0.0   0.0   5.0   1.0   0.0    0.0   1.0   0.0    2.0   0.0    2.0   1.0   2.0    0.0   2.0    0.0   0.0    2.0    0.34146341463414637  28 / 82
4.0    3.0    0.0   87.0   0.0   1.0   0.0   1.0   0.0   1.0   0.0   0.0   3.0    1.0   1.0   2.0    0.0   4.0    3.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.22321428571428573  25 / 112
0.0    4.0    0.0   0.0    59.0  1.0   4.0   0.0   1.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    6.0   1.0    1.0   3.0   0.0    0.0   0.0    0.0   0.0    14.0   0.3917525773195876   38 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
1.0    2.0    0.0   4.0    3.0   0.0   1.0   0.0   4.0   0.0   5.0   1.0   0.0    0.0   0.0   0.0    2.0   2.0    5.0   6.0   1.0    0.0   0.0    50.0  5.0    8.0    0.5                  50 / 100
0.0    1.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0    3.0   0.0    0.0   13.0  1.0    15.0  2.0    0.0   68.0   0.0    0.3644859813084112   39 / 107
0.0    1.0    0.0   0.0    5.0   1.0   0.0   0.0   0.0   3.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    5.0   1.0   0.0    0.0   0.0    1.0   1.0    68.0   0.21839080459770116  19 / 87
109.0  150.0  65.0  125.0  90.0  82.0  92.0  65.0  74.0  96.0  92.0  88.0  106.0  89.0  75.0  112.0  96.0  116.0  61.0  95.0  103.0  99.0  121.0  65.0  103.0  121.0  0.28755020080321286  716 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.71245
2    0.834538
3    0.880321
4    0.91004
5    0.929719
6    0.939357
7    0.949799
8    0.959036
9    0.966265
10   0.972691
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:01  2 min 59.095 sec  88557 obs/sec     1         1             10007      0.653656         1.33402             0.992407       0.373788                         0.652102           1.32374               0.992423         0.370683
    2019-08-04 09:03:02  3 min  0.068 sec  94584 obs/sec     10        10            100070     0.555502         1.00657             0.994516       0.282415                         0.556965           1.01455               0.994473         0.28755
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0897716
C15         0.964406               0.964406             0.0865763
C12         0.916791               0.916791             0.0823018
C13         0.913731               0.913731             0.0820271
C11         0.875486               0.875486             0.0785938
C7          0.805449               0.805449             0.0723065
C8          0.781496               0.781496             0.0701562
C14         0.775353               0.775353             0.0696047
C10         0.641238               0.641238             0.057565
C6          0.627312               0.627312             0.0563148
C16         0.601061               0.601061             0.0539583
C3          0.537656               0.537656             0.0482662
C5          0.489248               0.489248             0.0439206
C4          0.473925               0.473925             0.042545
C2          0.391937               0.391937             0.0351848
C1          0.344288               0.344288             0.0309073
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_42

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0013207004158459767  0.0003556138835847378   0.0         -0.005963109138974687  1.342454433441162   -0.05268154444260097  1.0651392936706543
    3        26       Softmax                 0.0   0.0   0.001708918221573605   0.00013085431419312954  0.0         0.025885933261284102   0.4452378749847412  -0.5380290483330534   0.32678651809692383


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.31408959637086664
RMSE: 0.560436969132896
LogLoss: 1.0069981505003627
Mean Per-Class Error: 0.28805162807078816
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  2.0    0.0    6.0    0.0    0.0    0.0    3.0    0.0    0.0    4.0    0.0    6.0    0.0    4.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    3.0    1.0    8.0    0.0    0.10126582278481013  40 / 395
0.0    288.0  0.0    6.0    2.0    5.0    2.0    14.0   11.0   1.0    0.0    0.0    1.0    0.0    0.0    3.0    3.0    27.0   13.0   0.0    0.0    1.0    1.0    5.0    0.0    0.0    0.24804177545691905  95 / 383
0.0    0.0    277.0  0.0    20.0   3.0    26.0   1.0    0.0    0.0    15.0   0.0    0.0    0.0    1.0    0.0    2.0    0.0    4.0    8.0    2.0    0.0    7.0    0.0    0.0    1.0    0.2452316076294278   90 / 367
7.0    19.0   0.0    299.0  0.0    1.0    0.0    4.0    0.0    11.0   0.0    0.0    5.0    8.0    2.0    7.0    0.0    18.0   3.0    1.0    1.0    0.0    1.0    15.0   1.0    0.0    0.25806451612903225  104 / 403
0.0    7.0    3.0    0.0    262.0  6.0    18.0   0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    12.0   6.0    9.0    18.0   1.0    0.0    0.0    7.0    0.0    31.0   0.3177083333333333   122 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    21.0   1.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    6.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
4.0    13.0   0.0    3.0    17.0   0.0    8.0    1.0    8.0    1.0    5.0    2.0    0.0    0.0    1.0    0.0    24.0   1.0    18.0   10.0   2.0    1.0    0.0    255.0  5.0    15.0   0.35279187817258884  139 / 394
0.0    0.0    0.0    1.0    0.0    26.0   0.0    9.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    7.0    5.0    0.0    8.0    50.0   3.0    27.0   1.0    2.0    249.0  0.0    0.366412213740458    144 / 393
2.0    4.0    0.0    1.0    25.0   2.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    5.0    0.0    44.0   7.0    0.0    0.0    0.0    8.0    1.0    263.0  0.28337874659400547  104 / 367
430.0  528.0  357.0  419.0  381.0  372.0  397.0  297.0  349.0  338.0  329.0  325.0  458.0  375.0  348.0  406.0  356.0  439.0  302.0  448.0  381.0  387.0  464.0  373.0  343.0  401.0  0.2867139858042587   2,868 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.713286
2    0.830051
3    0.881736
4    0.909927
5    0.928521
6    0.942117
7    0.951715
8    0.961212
9    0.96811
10   0.974108

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.31876384770330507
RMSE: 0.5645917531307955
LogLoss: 1.022144638592376
Mean Per-Class Error: 0.2964331754615467
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18    19     20    21    22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -------------------  -----------
80.0  0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   1.0    1.0   3.0   0.0    0.10112359550561797  9 / 89
0.0   74.0   0.0   1.0    1.0   2.0   1.0   7.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    1.0   11.0   4.0   0.0    0.0   1.0   0.0    1.0   0.0   0.0    0.3018867924528302   32 / 106
0.0   0.0    56.0  0.0    5.0   1.0   9.0   0.0   0.0   0.0   4.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    1.0   2.0    1.0   0.0   1.0    0.0   0.0   1.0    0.3170731707317073   26 / 82
4.0   3.0    0.0   84.0   0.0   0.0   0.0   1.0   0.0   2.0   0.0   0.0   2.0    2.0   1.0   4.0    0.0   4.0    2.0   0.0    0.0   0.0   1.0    2.0   0.0   0.0    0.25                 28 / 112
0.0   2.0    1.0   0.0    66.0  2.0   2.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    4.0   1.0    2.0   6.0    0.0   0.0   0.0    0.0   0.0   10.0   0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   2.0   83.0   0.0   0.0   0.0    0.09782608695652174  9 / 92
0.0   5.0    0.0   1.0    7.0   0.0   1.0   1.0   2.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    3.0   0.0    6.0   2.0    0.0   0.0   0.0    62.0  2.0   6.0    0.38                 38 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   4.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   1.0    2.0   0.0    0.0   17.0   0.0   9.0   1.0    1.0   67.0  0.0    0.37383177570093457  40 / 107
0.0   1.0    0.0   0.0    7.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0    10.0  3.0    0.0   0.0   0.0    3.0   0.0   60.0   0.3103448275862069   27 / 87
99.0  132.0  74.0  118.0  99.0  85.0  92.0  82.0  78.0  97.0  85.0  89.0  107.0  94.0  64.0  117.0  88.0  109.0  81.0  108.0  95.0  94.0  114.0  88.0  96.0  105.0  0.2955823293172691   736 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.704418
2    0.831727
3    0.876305
4    0.908032
5    0.926908
6    0.941767
7    0.951004
8    0.960642
9    0.968675
10   0.971486
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:15  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:16  1 min 13.810 sec  93523 obs/sec     1         1             10007      0.659514         1.34504             0.99227        0.363491                         0.657143           1.33447               0.992305         0.357831
    2019-08-04 09:01:17  1 min 14.776 sec  95760 obs/sec     10        10            100070     0.560437         1.007               0.994418       0.286714                         0.564592           1.02214               0.99432          0.295582
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0911751
C13         0.966112               0.966112             0.0880854
C12         0.910949               0.910949             0.0830559
C9          0.910792               0.910792             0.0830416
C11         0.770918               0.770918             0.0702885
C7          0.758106               0.758106             0.0691204
C14         0.716822               0.716822             0.0653564
C8          0.687526               0.687526             0.0626853
C10         0.612903               0.612903             0.0558815
C6          0.578444               0.578444             0.0527397
C16         0.573737               0.573737             0.0523105
C3          0.571855               0.571855             0.0521389
C5          0.506252               0.506252             0.0461576
C4          0.501081               0.501081             0.0456862
C2          0.458099               0.458099             0.0417673
C1          0.444307               0.444307             0.0405098
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_35

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012581766916355264  0.0003226350527256727   0.0         0.009091180071209237  1.2501397132873535  -0.20105060074107045  0.9670138359069824
    3        26       Softmax                 0.0   0.0   0.0017342079531422665  0.00018542353063821793  0.0         0.01606177827396821   0.4547961950302124  -0.5453243183107153   0.35205793380737305


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.31296846532793837
RMSE: 0.5594358455872651
LogLoss: 1.0067149555779489
Mean Per-Class Error: 0.2814358458383518
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
346.0  0.0    0.0    6.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    0.0    12.0   0.0    2.0    0.0    0.0    2.0    5.0    0.0    1.0    1.0    5.0    1.0    5.0    0.0    0.1240506329113924   49 / 395
0.0    277.0  0.0    12.0   0.0    2.0    3.0    17.0   4.0    2.0    2.0    0.0    5.0    0.0    0.0    6.0    7.0    25.0   14.0   0.0    0.0    3.0    1.0    1.0    1.0    0.0    0.27486910994764396  105 / 382
0.0    1.0    284.0  0.0    14.0   2.0    27.0   0.0    0.0    0.0    15.0   0.0    1.0    0.0    3.0    0.0    2.0    0.0    7.0    2.0    3.0    0.0    4.0    0.0    3.0    0.0    0.22826086956521738  84 / 368
5.0    15.0   0.0    304.0  0.0    0.0    0.0    12.0   1.0    17.0   4.0    1.0    7.0    1.0    7.0    4.0    1.0    6.0    3.0    1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.2456575682382134   99 / 403
0.0    3.0    9.0    1.0    224.0  1.0    60.0   0.0    4.0    0.0    11.0   0.0    0.0    0.0    1.0    0.0    12.0   4.0    5.0    15.0   1.0    0.0    0.0    15.0   1.0    17.0   0.4166666666666667   160 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    33.0   4.0    2.0    0.0    0.0    4.0    0.0    0.0    0.0    8.0    322.0  0.0    0.0    0.0    0.14361702127659576  54 / 376
0.0    2.0    0.0    8.0    13.0   0.0    5.0    4.0    12.0   2.0    10.0   0.0    0.0    0.0    2.0    0.0    17.0   2.0    15.0   9.0    2.0    1.0    0.0    265.0  15.0   10.0   0.32741116751269034  129 / 394
0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    9.0    0.0    5.0    55.0   3.0    34.0   9.0    1.0    272.0  0.0    0.30788804071246817  121 / 393
1.0    1.0    0.0    4.0    13.0   4.0    1.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    27.0   7.0    0.0    0.0    0.0    4.0    2.0    289.0  0.2125340599455041   78 / 367
394.0  456.0  367.0  468.0  314.0  337.0  422.0  258.0  342.0  377.0  373.0  315.0  541.0  339.0  400.0  374.0  365.0  410.0  288.0  431.0  383.0  381.0  494.0  370.0  406.0  398.0  0.2804158752374288   2,805 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.719584
2    0.83465
3    0.885834
4    0.913426
5    0.93332
6    0.946616
7    0.954913
8    0.962611
9    0.969409
10   0.975307

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.31755439616006575
RMSE: 0.5635196501987005
LogLoss: 1.0261043816877218
Mean Per-Class Error: 0.2957756611767192
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12     13    14    15     16     17    18    19     20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0   3.0    1.0   2.0    0.0    0.12359550561797752  11 / 89
0.0   71.0   0.0   4.0    0.0   0.0   1.0    6.0   1.0   1.0    0.0   0.0   1.0    0.0   0.0   1.0    6.0    8.0   3.0   0.0    0.0   1.0   1.0    1.0   0.0    0.0    0.330188679245283    35 / 106
0.0   0.0    58.0  0.0    3.0   0.0   9.0    0.0   0.0   0.0    3.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0   3.0   0.0    1.0   0.0   2.0    0.0   1.0    0.0    0.2926829268292683   24 / 82
3.0   5.0    0.0   84.0   0.0   0.0   0.0    4.0   1.0   2.0    1.0   1.0   3.0    0.0   4.0   1.0    0.0    1.0   1.0   0.0    0.0   0.0   0.0    1.0   0.0    0.0    0.25                 28 / 112
0.0   1.0    2.0   0.0    54.0  1.0   15.0   0.0   1.0   0.0    6.0   0.0   0.0    0.0   0.0   0.0    1.0    1.0   2.0   7.0    0.0   0.0   0.0    1.0   0.0    5.0    0.44329896907216493  43 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---   ---    ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   5.0    3.0   0.0   0.0    0.0    1.0   0.0   0.0    0.0   3.0   79.0   0.0   0.0    0.0    0.14130434782608695  13 / 92
0.0   1.0    0.0   1.0    3.0   0.0   1.0    3.0   5.0   0.0    5.0   0.0   0.0    0.0   0.0   0.0    3.0    1.0   6.0   2.0    0.0   0.0   0.0    62.0  6.0    1.0    0.38                 38 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    4.0    0.0   1.0   12.0   1.0   7.0   3.0    0.0   77.0   0.0    0.2803738317757009   30 / 107
0.0   0.0    0.0   2.0    2.0   1.0   0.0    0.0   0.0   4.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0    0.0   4.0   3.0    0.0   0.0   0.0    2.0   0.0    68.0   0.21839080459770116  19 / 87
91.0  107.0  80.0  130.0  72.0  75.0  109.0  71.0  84.0  106.0  91.0  86.0  125.0  90.0  84.0  107.0  102.0  99.0  74.0  101.0  96.0  84.0  124.0  84.0  118.0  100.0  0.29518072289156627  735 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.704819
2    0.826104
3    0.881928
4    0.911647
5    0.929317
6    0.942169
7    0.951406
8    0.961847
9    0.969076
10   0.975904
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:05  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:05  1 min  3.646 sec  92657 obs/sec     1         1             10007      0.651562         1.32076             0.992456       0.36699                          0.649322           1.30766               0.992487         0.362249
    2019-08-04 09:01:06  1 min  4.611 sec  95486 obs/sec     10        10            100070     0.559436         1.00671             0.994438       0.280416                         0.56352            1.0261                0.994342         0.295181
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0870302
C13         0.955363               0.955363             0.0831454
C9          0.943023               0.943023             0.0820715
C12         0.924118               0.924118             0.0804262
C8          0.904094               0.904094             0.0786835
C11         0.841032               0.841032             0.0731952
C7          0.821198               0.821198             0.071469
C14         0.786564               0.786564             0.0684548
C10         0.722297               0.722297             0.0628617
C16         0.629194               0.629194             0.0547588
C6          0.574589               0.574589             0.0500066
C3          0.52911                0.52911              0.0460485
C5          0.498251               0.498251             0.0433628
C4          0.484153               0.484153             0.042136
C1          0.44252                0.44252              0.0385126
C2          0.434761               0.434761             0.0378373
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_117

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012986697211658793  0.0003422818845137954   0.0         -0.04710275237096084  1.2976112365722656  -0.1434189656771815  1.1064238548278809
    3        26       Softmax                 0.0   0.0   0.0017310650262935758  0.00018138776067644358  0.0         0.01784886380126129   0.4452277421951294  -0.5531696025728396  0.3509702682495117


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3227950744461221
RMSE: 0.5681505737444275
LogLoss: 1.0231734951277336
Mean Per-Class Error: 0.2935974005639482
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
341.0  6.0    0.0    3.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    10.0   2.0    0.0    0.0    12.0   2.0    3.0    0.0    1.0    0.0    5.0    0.0    6.0    0.0    0.13670886075949368  54 / 395
1.0    310.0  0.0    4.0    3.0    0.0    2.0    4.0    6.0    0.0    1.0    0.0    2.0    0.0    0.0    2.0    0.0    27.0   11.0   1.0    0.0    2.0    2.0    2.0    3.0    0.0    0.1906005221932115   73 / 383
0.0    1.0    270.0  0.0    15.0   3.0    32.0   0.0    0.0    0.0    19.0   2.0    2.0    0.0    4.0    0.0    3.0    1.0    2.0    6.0    6.0    0.0    2.0    0.0    0.0    0.0    0.266304347826087    98 / 368
5.0    20.0   0.0    318.0  0.0    0.0    2.0    7.0    1.0    5.0    0.0    0.0    10.0   2.0    1.0    14.0   0.0    11.0   0.0    0.0    1.0    0.0    0.0    6.0    0.0    0.0    0.2109181141439206   85 / 403
0.0    17.0   10.0   0.0    263.0  3.0    19.0   1.0    3.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    6.0    6.0    14.0   11.0   1.0    0.0    0.0    7.0    0.0    19.0   0.3151041666666667   121 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    26.0   5.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    14.0   310.0  0.0    0.0    0.0    0.17333333333333334  65 / 375
1.0    6.0    0.0    11.0   21.0   0.0    2.0    2.0    18.0   3.0    5.0    2.0    0.0    0.0    2.0    0.0    13.0   1.0    19.0   2.0    1.0    0.0    0.0    258.0  14.0   12.0   0.3435114503816794   135 / 393
1.0    1.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    3.0    6.0    0.0    4.0    42.0   3.0    70.0   4.0    0.0    248.0  0.0    0.36895674300254455  145 / 393
4.0    3.0    0.0    3.0    26.0   9.0    2.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    46.0   8.0    0.0    0.0    0.0    12.0   0.0    248.0  0.3242506811989101   119 / 367
419.0  562.0  374.0  454.0  394.0  337.0  365.0  238.0  354.0  342.0  347.0  308.0  527.0  357.0  348.0  376.0  336.0  471.0  332.0  436.0  381.0  435.0  433.0  390.0  354.0  333.0  0.29221233629911025  2,923 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.707788
2    0.83175
3    0.878636
4    0.909527
5    0.930921
6    0.945516
7    0.955214
8    0.964211
9    0.971809
10   0.976107

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.32464369433081075
RMSE: 0.569775126107494
LogLoss: 1.0290467561270464
Mean Per-Class Error: 0.29464305099705895
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10    11    12     13    14    15     16    17     18    19     20    21     22     23    24     25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -------------------  -----------
76.0   0.0    0.0   1.0    0.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    2.0   1.0    1.0   0.0    0.0   0.0    2.0    0.0   3.0    0.0   0.14606741573033707  13 / 89
1.0    81.0   0.0   1.0    2.0    0.0   1.0   4.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   8.0    2.0   0.0    0.0   2.0    1.0    1.0   0.0    0.0   0.2358490566037736   25 / 106
0.0    0.0    55.0  0.0    4.0    1.0   9.0   0.0   0.0   0.0   5.0   1.0   0.0    0.0   3.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0    1.0    0.0   0.0    0.0   0.32926829268292684  27 / 82
4.0    4.0    0.0   90.0   0.0    0.0   1.0   1.0   0.0   0.0   0.0   0.0   3.0    1.0   0.0   5.0    0.0   2.0    0.0   0.0    0.0   0.0    0.0    1.0   0.0    0.0   0.19642857142857142  22 / 112
0.0    2.0    3.0   0.0    67.0   1.0   4.0   0.0   1.0   0.0   1.0   0.0   0.0    0.0   1.0   0.0    1.0   2.0    4.0   4.0    0.0   0.0    0.0    0.0   0.0    6.0   0.30927835051546393  30 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   5.0    1.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   2.0    82.0   0.0   0.0    0.0   0.10869565217391304  10 / 92
0.0    2.0    0.0   4.0    9.0    0.0   0.0   0.0   4.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    4.0   0.0    0.0   0.0    0.0    62.0  5.0    4.0   0.38                 38 / 100
1.0    1.0    0.0   1.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   1.0    1.0   0.0    0.0   10.0   1.0   20.0   1.0    0.0   67.0   0.0   0.37383177570093457  40 / 107
1.0    1.0    0.0   2.0    9.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    10.0  4.0    0.0   0.0    0.0    2.0   0.0    57.0  0.3448275862068966   30 / 87
102.0  137.0  75.0  139.0  104.0  74.0  88.0  62.0  84.0  89.0  92.0  83.0  119.0  85.0  70.0  111.0  86.0  116.0  82.0  101.0  94.0  101.0  114.0  96.0  101.0  85.0  0.2927710843373494   729 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.707229
2    0.826104
3    0.878313
4    0.913253
5    0.93253
6    0.944578
7    0.952209
8    0.961044
9    0.969478
10   0.971486
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:17  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:18  3 min 15.836 sec  93523 obs/sec     1         1             10007      0.657765         1.3368              0.992311       0.379086                         0.653673           1.319                 0.992386         0.378715
    2019-08-04 09:03:19  3 min 16.803 sec  95214 obs/sec     10        10            100070     0.568151         1.02317             0.994264       0.292212                         0.569775           1.02905               0.994215         0.292771
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0872417
C15         0.99171                0.99171              0.0865185
C12         0.972859               0.972859             0.0848739
C9          0.92297                0.92297              0.0805215
C11         0.847229               0.847229             0.0739137
C7          0.797779               0.797779             0.0695996
C8          0.778094               0.778094             0.0678823
C14         0.744107               0.744107             0.0649172
C10         0.655673               0.655673             0.0572021
C6          0.633078               0.633078             0.0552309
C16         0.60698                0.60698              0.052954
C3          0.579855               0.579855             0.0505875
C5          0.551032               0.551032             0.048073
C4          0.535129               0.535129             0.0466856
C1          0.43308                0.43308              0.0377827
C2          0.412827               0.412827             0.0360158
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_71

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011402061215903814  0.00031333579681813717  0.0         -0.06750312996859975  1.0645179748535156  0.058382905964415234  1.0451807975769043
    3        26       Softmax                 0.0   0.0   0.0017815513168058645  0.00018321361858397722  0.0         0.00222806311615806   0.592648983001709   -0.47317435105464334  0.28796327114105225


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.32363809390052506
RMSE: 0.5688919879032619
LogLoss: 1.0402867825887006
Mean Per-Class Error: 0.3029628819002863
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    4.0    0.0    5.0    1.0    8.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    9.0    0.0    3.0    0.0    0.10152284263959391  40 / 394
0.0    272.0  0.0    10.0   2.0    5.0    0.0    24.0   0.0    1.0    4.0    0.0    6.0    0.0    0.0    2.0    4.0    23.0   13.0   0.0    0.0    4.0    4.0    7.0    2.0    0.0    0.2898172323759791   111 / 383
0.0    2.0    269.0  0.0    23.0   1.0    23.0   0.0    0.0    0.0    14.0   0.0    0.0    0.0    3.0    2.0    0.0    0.0    7.0    2.0    8.0    0.0    13.0   0.0    1.0    0.0    0.26902173913043476  99 / 368
10.0   16.0   0.0    301.0  0.0    3.0    0.0    8.0    0.0    12.0   0.0    0.0    8.0    4.0    1.0    12.0   0.0    18.0   2.0    2.0    2.0    0.0    0.0    3.0    0.0    1.0    0.2531017369727047   102 / 403
0.0    8.0    13.0   0.0    204.0  3.0    33.0   2.0    1.0    0.0    8.0    2.0    0.0    0.0    0.0    0.0    13.0   9.0    9.0    8.0    0.0    0.0    0.0    29.0   1.0    41.0   0.46875              180 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    10.0   0.0    12.0   3.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    9.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    20.0   6.0    19.0   12.0   3.0    1.0    1.0    19.0   0.0    10.0   5.0    0.0    0.0    2.0    0.0    23.0   1.0    20.0   17.0   2.0    0.0    0.0    208.0  0.0    25.0   0.4720812182741117   186 / 394
2.0    0.0    1.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    7.0    5.0    0.0    8.0    58.0   2.0    45.0   6.0    0.0    240.0  0.0    0.3893129770992366   153 / 393
2.0    7.0    0.0    3.0    9.0    7.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    41.0   6.0    0.0    0.0    0.0    6.0    0.0    275.0  0.2506811989100817   92 / 367
424.0  497.0  319.0  451.0  309.0  383.0  382.0  270.0  367.0  327.0  381.0  326.0  455.0  355.0  405.0  387.0  400.0  411.0  292.0  417.0  375.0  401.0  581.0  320.0  350.0  418.0  0.30220933719884036  3,023 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.697791
2    0.814556
3    0.871738
4    0.90133
5    0.923423
6    0.938419
7    0.949515
8    0.957913
9    0.96601
10   0.973808

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.32575962227250194
RMSE: 0.570753556513231
LogLoss: 1.043446908095452
Mean Per-Class Error: 0.30462303529590734
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16     17     18    19    20    21    22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -------------------  -----------
78.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0   2.0   0.0   0.0   1.0   0.0   0.0    0.0    1.0    1.0   0.0   0.0   0.0   2.0    0.0   2.0   0.0    0.12359550561797752  11 / 89
0.0    76.0   0.0   1.0    0.0   1.0   0.0   9.0   0.0   0.0   3.0   0.0   1.0   0.0   0.0   1.0    1.0    6.0    3.0   0.0   0.0   3.0   0.0    1.0   0.0   0.0    0.2830188679245283   30 / 106
0.0    1.0    54.0  0.0    4.0   0.0   9.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   1.0   1.0    0.0    0.0    2.0   1.0   1.0   0.0   3.0    0.0   1.0   0.0    0.34146341463414637  28 / 82
5.0    3.0    0.0   82.0   0.0   0.0   0.0   3.0   0.0   2.0   0.0   0.0   3.0   0.0   0.0   5.0    0.0    5.0    1.0   0.0   1.0   0.0   0.0    1.0   0.0   1.0    0.26785714285714285  30 / 112
0.0    0.0    5.0   0.0    49.0  1.0   10.0  0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0    4.0    1.0    2.0   1.0   0.0   0.0   0.0    6.0   0.0   15.0   0.4948453608247423   48 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   3.0   0.0   0.0   0.0    1.0    0.0    0.0   0.0   0.0   0.0   86.0   0.0   0.0   0.0    0.06521739130434782  6 / 92
0.0    5.0    0.0   7.0    5.0   0.0   0.0   0.0   3.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0    4.0    0.0    8.0   7.0   1.0   0.0   0.0    49.0  0.0   9.0    0.51                 51 / 100
1.0    0.0    1.0   0.0    0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0    2.0    0.0    0.0   15.0  0.0   16.0  2.0    0.0   63.0  0.0    0.411214953271028    44 / 107
0.0    1.0    0.0   1.0    1.0   2.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    7.0   2.0   0.0   0.0   0.0    3.0   0.0   67.0   0.22988505747126436  20 / 87
101.0  125.0  67.0  120.0  71.0  85.0  97.0  80.0  88.0  94.0  97.0  86.0  96.0  91.0  77.0  115.0  106.0  104.0  72.0  98.0  96.0  98.0  146.0  76.0  90.0  114.0  0.3044176706827309   758 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.695582
2    0.813253
3    0.873092
4    0.899598
5    0.921687
6    0.939357
7    0.949799
8    0.957028
9    0.967872
10   0.974699
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:00  1 min 58.213 sec  137082 obs/sec    1         1             10007      0.720827         1.58349             0.990766       0.437369                         0.714049           1.55229               0.990915         0.420884
    2019-08-04 09:02:01  1 min 58.865 sec  140745 obs/sec    10        10            100070     0.568892         1.04029             0.994248       0.302209                         0.570754           1.04345               0.994195         0.304418
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0938494
C15         0.881404               0.881404             0.0827192
C9          0.86248                0.86248              0.0809432
C11         0.843531               0.843531             0.0791649
C7          0.827997               0.827997             0.077707
C12         0.795041               0.795041             0.074614
C14         0.769113               0.769113             0.0721807
C8          0.707131               0.707131             0.0663638
C6          0.64874                0.64874              0.0608838
C10         0.633541               0.633541             0.0594574
C16         0.583817               0.583817             0.0547908
C3          0.492118               0.492118             0.0461849
C5          0.487479               0.487479             0.0457496
C4          0.39627                0.39627              0.0371897
C1          0.377672               0.377672             0.0354442
C2          0.349041               0.349041             0.0327573
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_165

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011302923268203813  0.0003347480669617653  0.0         0.1264185969922096     1.0372843742370605  0.01620159036972852  0.9651036262512207
    3        26       Softmax                 0.0   0.0   0.0018108095947144858  0.0002095844829455018  0.0         -0.001606626036776176  0.6021230220794678  -0.475398694583085   0.29534459114074707


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.32140135533405617
RMSE: 0.5669227066664875
LogLoss: 1.0360078699666815
Mean Per-Class Error: 0.30155562384377305
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    2.0    0.0    0.0    4.0    3.0    0.0    3.0    2.0    0.0    7.0    0.0    1.0    0.0    1.0    1.0    2.0    0.0    1.0    1.0    5.0    1.0    5.0    0.0    0.09873417721518987  39 / 395
1.0    273.0  0.0    10.0   5.0    1.0    2.0    19.0   4.0    0.0    3.0    0.0    0.0    0.0    2.0    0.0    3.0    33.0   11.0   1.0    0.0    0.0    2.0    8.0    4.0    1.0    0.28720626631853785  110 / 383
0.0    0.0    268.0  1.0    25.0   2.0    29.0   1.0    1.0    0.0    11.0   2.0    0.0    0.0    2.0    0.0    6.0    0.0    7.0    2.0    6.0    0.0    3.0    0.0    1.0    1.0    0.2717391304347826   100 / 368
7.0    9.0    0.0    274.0  0.0    1.0    0.0    5.0    0.0    5.0    1.0    0.0    11.0   7.0    30.0   6.0    3.0    30.0   0.0    1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.3200992555831266   129 / 403
0.0    18.0   1.0    0.0    254.0  1.0    8.0    3.0    3.0    1.0    10.0   0.0    0.0    0.0    0.0    0.0    18.0   5.0    22.0   11.0   0.0    1.0    0.0    8.0    2.0    18.0   0.3385416666666667   130 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    24.0   7.0    1.0    0.0    0.0    17.0   0.0    0.0    2.0    20.0   297.0  0.0    0.0    0.0    0.21010638297872342  79 / 376
0.0    13.0   0.0    13.0   13.0   0.0    6.0    1.0    4.0    0.0    13.0   2.0    0.0    2.0    0.0    0.0    20.0   2.0    7.0    5.0    1.0    1.0    0.0    260.0  5.0    26.0   0.3401015228426396   134 / 394
2.0    0.0    0.0    1.0    1.0    12.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    2.0    7.0    0.0    6.0    74.0   3.0    24.0   1.0    0.0    255.0  1.0    0.3511450381679389   138 / 393
4.0    3.0    0.0    5.0    14.0   4.0    0.0    1.0    3.0    6.0    0.0    1.0    0.0    0.0    0.0    1.0    8.0    1.0    47.0   6.0    0.0    0.0    0.0    11.0   0.0    252.0  0.3133514986376022   115 / 367
404.0  508.0  339.0  425.0  391.0  343.0  339.0  268.0  338.0  333.0  385.0  334.0  469.0  382.0  352.0  394.0  438.0  519.0  344.0  426.0  409.0  342.0  417.0  381.0  376.0  347.0  0.3002099370188943   3,003 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.69979
2    0.825652
3    0.879936
4    0.908627
5    0.929321
6    0.943317
7    0.950915
8    0.960612
9    0.96651
10   0.973108

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.32338960296890973
RMSE: 0.5686735469220542
LogLoss: 1.0492433681511582
Mean Per-Class Error: 0.30355496838120766
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0    0.0   3.0    1.0   2.0    0.0   0.10112359550561797  9 / 89
1.0   72.0   0.0   1.0    3.0   0.0   1.0   4.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    2.0    12.0   2.0   0.0    0.0    0.0   2.0    2.0   1.0    0.0   0.32075471698113206  34 / 106
0.0   0.0    52.0  1.0    4.0   0.0   11.0  0.0   0.0   0.0   2.0   0.0   0.0    0.0   1.0   0.0    3.0    0.0    4.0   1.0    2.0    0.0   1.0    0.0   0.0    0.0   0.36585365853658536  30 / 82
2.0   2.0    0.0   80.0   0.0   0.0   0.0   2.0   0.0   1.0   1.0   0.0   4.0    2.0   6.0   1.0    1.0    8.0    0.0   0.0    0.0    0.0   0.0    2.0   0.0    0.0   0.2857142857142857   32 / 112
0.0   5.0    1.0   0.0    63.0  1.0   2.0   0.0   1.0   1.0   2.0   0.0   0.0    0.0   0.0   0.0    4.0    1.0    4.0   4.0    0.0    0.0   0.0    1.0   0.0    7.0   0.35051546391752575  34 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   7.0    1.0   1.0   0.0    0.0    2.0    0.0   0.0    0.0    5.0   76.0   0.0   0.0    0.0   0.17391304347826086  16 / 92
0.0   1.0    0.0   6.0    3.0   0.0   1.0   0.0   1.0   0.0   5.0   2.0   0.0    0.0   0.0   0.0    2.0    1.0    3.0   0.0    0.0    0.0   0.0    66.0  2.0    7.0   0.34                 34 / 100
2.0   0.0    0.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0    0.0   21.0   1.0    7.0   1.0    0.0   71.0   0.0   0.3364485981308411   36 / 107
0.0   0.0    0.0   1.0    5.0   2.0   0.0   1.0   0.0   3.0   0.0   1.0   0.0    0.0   0.0   0.0    1.0    0.0    12.0  3.0    0.0    0.0   0.0    3.0   0.0    55.0  0.367816091954023    32 / 87
97.0  116.0  70.0  118.0  88.0  76.0  80.0  78.0  78.0  90.0  97.0  89.0  110.0  90.0  69.0  113.0  113.0  135.0  94.0  105.0  105.0  83.0  109.0  99.0  103.0  85.0  0.30120481927710846  750 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.698795
2    0.824498
3    0.878313
4    0.905221
5    0.925301
6    0.939759
7    0.94739
8    0.958233
9    0.966265
10   0.972691
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:41  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:42  4 min 39.811 sec  140943 obs/sec    1         1             10007      0.67524          1.40392             0.991899       0.386384                         0.675413           1.40606               0.991871         0.38755
    2019-08-04 09:04:42  4 min 40.454 sec  142957 obs/sec    10        10            100070     0.566923         1.03601             0.994289       0.30021                          0.568674           1.04924               0.994238         0.301205
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0963226
C13         0.913241               0.913241             0.0879658
C12         0.786148               0.786148             0.0757239
C8          0.774299               0.774299             0.0745825
C9          0.759968               0.759968             0.0732022
C14         0.744441               0.744441             0.0717066
C7          0.719799               0.719799             0.069333
C11         0.699612               0.699612             0.0673884
C16         0.632226               0.632226             0.0608977
C10         0.607995               0.607995             0.0585636
C6          0.592313               0.592313             0.0570532
C5          0.529973               0.529973             0.0510484
C3          0.49103                0.49103              0.0472973
C4          0.46143                0.46143              0.0444461
C1          0.342181               0.342181             0.0329598
C2          0.327118               0.327118             0.0315088
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_203

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0013054049434799708  0.0003632208099588752   0.0         0.12262944988751201   1.3294339179992676   0.11614582550497567  1.149515151977539
    3        26       Softmax                 0.0   0.0   0.0017286796681638896  0.00017763936193659902  0.0         0.006587635176261896  0.44074225425720215  -0.5333983498895052  0.3426675796508789


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.32987163033449235
RMSE: 0.5743445223334965
LogLoss: 1.0478146364242695
Mean Per-Class Error: 0.3077928335519636
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
346.0  0.0    0.0    6.0    0.0    0.0    3.0    0.0    0.0    1.0    1.0    0.0    8.0    2.0    3.0    0.0    1.0    4.0    4.0    0.0    2.0    0.0    8.0    1.0    5.0    0.0    0.1240506329113924   49 / 395
0.0    253.0  0.0    9.0    0.0    1.0    1.0    19.0   15.0   0.0    3.0    0.0    2.0    0.0    1.0    1.0    1.0    51.0   18.0   0.0    0.0    3.0    0.0    1.0    4.0    0.0    0.3394255874673629   130 / 383
0.0    0.0    273.0  0.0    19.0   4.0    27.0   0.0    0.0    0.0    19.0   0.0    1.0    0.0    2.0    0.0    5.0    0.0    5.0    3.0    5.0    0.0    4.0    0.0    0.0    1.0    0.25815217391304346  95 / 368
6.0    17.0   0.0    285.0  0.0    0.0    0.0    7.0    0.0    10.0   0.0    2.0    9.0    1.0    16.0   6.0    0.0    24.0   3.0    1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.291044776119403    117 / 402
0.0    11.0   12.0   0.0    239.0  1.0    8.0    0.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    17.0   10.0   12.0   11.0   3.0    0.0    0.0    19.0   4.0    29.0   0.3776041666666667   145 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    23.0   1.0    1.0    0.0    0.0    3.0    0.0    0.0    5.0    0.0    332.0  0.0    0.0    0.0    0.11702127659574468  44 / 376
11.0   7.0    4.0    5.0    9.0    0.0    1.0    2.0    8.0    2.0    9.0    2.0    0.0    2.0    4.0    0.0    11.0   2.0    15.0   16.0   1.0    0.0    0.0    236.0  11.0   36.0   0.4010152284263959   158 / 394
0.0    0.0    0.0    3.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    12.0   18.0   0.0    5.0    102.0  2.0    26.0   5.0    1.0    206.0  0.0    0.4758269720101781   187 / 393
1.0    2.0    0.0    2.0    17.0   4.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    45.0   6.0    0.0    0.0    0.0    7.0    0.0    275.0  0.2506811989100817   92 / 367
404.0  461.0  388.0  426.0  349.0  273.0  305.0  253.0  364.0  340.0  369.0  310.0  476.0  347.0  392.0  446.0  377.0  547.0  326.0  484.0  389.0  350.0  476.0  361.0  362.0  428.0  0.30660801759472156  3,067 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.693392
2    0.820454
3    0.875237
4    0.905928
5    0.929021
6    0.941418
7    0.951415
8    0.958712
9    0.96741
10   0.973008

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.33306391957135867
RMSE: 0.57711690286402
LogLoss: 1.057553428426929
Mean Per-Class Error: 0.3119836928352863
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17     18    19     20    21    22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   0.0   3.0    1.0   2.0   0.0    0.12359550561797752  11 / 89
0.0   67.0   0.0   2.0    0.0   0.0   1.0   8.0   4.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    1.0   15.0   2.0   0.0    0.0   3.0   0.0    1.0   1.0   0.0    0.36792452830188677  39 / 106
0.0   0.0    59.0  0.0    3.0   2.0   6.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0   1.0   0.0    3.0   0.0    2.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0    0.2804878048780488   23 / 82
3.0   3.0    0.0   82.0   0.0   0.0   0.0   2.0   0.0   2.0    0.0   0.0   3.0    0.0   7.0   1.0    0.0   7.0    1.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.26785714285714285  30 / 112
0.0   3.0    3.0   0.0    58.0  1.0   3.0   0.0   1.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    5.0   3.0    3.0   5.0    0.0   0.0   0.0    1.0   1.0   9.0    0.4020618556701031   39 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0    0.0   0.0   0.0    0.0   2.0    0.0   0.0    2.0   0.0   84.0   0.0   0.0   0.0    0.08695652173913043  8 / 92
2.0   3.0    0.0   2.0    5.0   0.0   0.0   1.0   4.0   0.0    4.0   0.0   0.0    0.0   1.0   0.0    2.0   1.0    4.0   4.0    0.0   0.0   0.0    54.0  3.0   10.0   0.46                 46 / 100
0.0   0.0    0.0   1.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   2.0   5.0    8.0   0.0    0.0   27.0   0.0   7.0   2.0    0.0   53.0  0.0    0.5046728971962616   54 / 107
0.0   0.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    12.0  2.0    0.0   0.0   0.0    4.0   0.0   63.0   0.27586206896551724  24 / 87
93.0  113.0  84.0  126.0  81.0  64.0  73.0  77.0  86.0  104.0  90.0  84.0  105.0  94.0  82.0  120.0  98.0  141.0  89.0  116.0  94.0  79.0  121.0  78.0  97.0  101.0  0.3112449799196787   775 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.688755
2    0.816064
3    0.871888
4    0.906827
5    0.931325
6    0.944177
7    0.951807
8    0.958634
9    0.969076
10   0.974699
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:59  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:59  5 min 57.744 sec  100070 obs/sec    1         1             10007      0.657915         1.33983             0.992309       0.368889                         0.657782           1.33423               0.99229          0.375904
    2019-08-04 09:06:00  5 min 58.701 sec  96685 obs/sec     10        10            100070     0.574345         1.04781             0.994138       0.306608                         0.577117           1.05755               0.994065         0.311245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0858268
C9          0.992962               0.992962             0.0852227
C13         0.970576               0.970576             0.0833014
C12         0.936473               0.936473             0.0803745
C11         0.886054               0.886054             0.0760471
C7          0.805438               0.805438             0.0691282
C8          0.79695                0.79695              0.0683996
C14         0.746318               0.746318             0.0640541
C10         0.70982                0.70982              0.0609216
C6          0.647008               0.647008             0.0555306
C16         0.607976               0.607976             0.0521806
C3          0.59169                0.59169              0.0507828
C4          0.526615               0.526615             0.0451977
C5          0.521944               0.521944             0.0447967
C2          0.462587               0.462587             0.0397024
C1          0.448964               0.448964             0.0385331
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_225

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011345664008786116  0.0002916122321039438   0.0         0.026425590744111105  1.095688819885254   -0.43674444148488545  1.0501956939697266
    3        26       Softmax                 0.0   0.0   0.0017737135636147845  0.00017176271649077535  0.0         0.01575157460851747   0.5877466201782227  -0.4567605131835965   0.2490348219871521


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.32786048309289595
RMSE: 0.5725910260324518
LogLoss: 1.0536986074675254
Mean Per-Class Error: 0.3061626528812304
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    6.0    0.0    0.0    0.0    5.0    1.0    0.0    2.0    0.0    5.0    5.0    2.0    0.0    0.0    0.0    2.0    0.0    1.0    3.0    3.0    0.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    245.0  0.0    9.0    3.0    1.0    1.0    33.0   16.0   0.0    0.0    1.0    0.0    0.0    2.0    2.0    3.0    42.0   17.0   0.0    0.0    4.0    0.0    2.0    2.0    0.0    0.360313315926893    138 / 383
0.0    0.0    273.0  0.0    28.0   8.0    26.0   0.0    0.0    0.0    8.0    1.0    5.0    0.0    2.0    0.0    1.0    1.0    3.0    0.0    2.0    0.0    5.0    0.0    0.0    5.0    0.25815217391304346  95 / 368
9.0    16.0   0.0    291.0  0.0    0.0    0.0    28.0   2.0    5.0    0.0    1.0    3.0    5.0    7.0    2.0    0.0    24.0   1.0    3.0    1.0    0.0    0.0    2.0    2.0    0.0    0.27611940298507465  111 / 402
0.0    14.0   6.0    0.0    258.0  7.0    21.0   2.0    3.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    7.0    8.0    7.0    8.0    1.0    0.0    0.0    13.0   0.0    26.0   0.328125             126 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    0.0    2.0    0.0    17.0   5.0    1.0    1.0    0.0    2.0    0.0    0.0    0.0    3.0    331.0  0.0    0.0    0.0    0.11733333333333333  44 / 375
0.0    18.0   0.0    5.0    14.0   0.0    1.0    5.0    15.0   0.0    14.0   2.0    0.0    0.0    1.0    0.0    11.0   3.0    18.0   21.0   5.0    1.0    0.0    236.0  11.0   12.0   0.3994910941475827   157 / 393
0.0    0.0    1.0    0.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    2.0    7.0    0.0    3.0    93.0   0.0    36.0   10.0   1.0    228.0  0.0    0.4198473282442748   165 / 393
3.0    1.0    0.0    4.0    11.0   6.0    3.0    0.0    6.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    3.0    54.0   1.0    0.0    0.0    0.0    13.0   4.0    253.0  0.3106267029972752   114 / 367
436.0  463.0  355.0  399.0  408.0  349.0  319.0  395.0  407.0  344.0  353.0  316.0  432.0  414.0  392.0  376.0  280.0  487.0  310.0  454.0  397.0  406.0  448.0  347.0  349.0  367.0  0.30530840747775667  3,054 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.694692
2    0.817455
3    0.874638
4    0.904229
5    0.925222
6    0.941018
7    0.953514
8    0.961312
9    0.96801
10   0.974008

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.33072308975487213
RMSE: 0.5750852891135994
LogLoss: 1.0656043675268179
Mean Per-Class Error: 0.30376801598328806
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7      8     9     10    11    12    13     14    15     16    17     18    19     20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0    1.0   1.0    0.0   2.0    0.0   0.10112359550561797  9 / 89
0.0    63.0   0.0   2.0    2.0   0.0   0.0   11.0   5.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    3.0   11.0   3.0   0.0    0.0    3.0   0.0    1.0   0.0    0.0   0.4056603773584906   43 / 106
0.0    0.0    61.0  0.0    4.0   3.0   8.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   2.0    0.0   0.0    1.0   0.25609756097560976  21 / 82
5.0    4.0    0.0   85.0   0.0   0.0   0.0   7.0    0.0   1.0   0.0   0.0   2.0   1.0    4.0   0.0    0.0   3.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    0.0   0.24107142857142858  27 / 112
0.0    5.0    2.0   0.0    65.0  3.0   5.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   2.0    2.0   3.0    0.0    0.0   0.0    2.0   0.0    6.0   0.32989690721649484  32 / 97
---    ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   5.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0    2.0   82.0   0.0   0.0    0.0   0.10869565217391304  10 / 92
0.0    5.0    0.0   0.0    4.0   0.0   0.0   2.0    2.0   0.0   4.0   1.0   0.0   0.0    1.0   0.0    2.0   1.0    7.0   5.0    0.0    0.0   0.0    55.0  4.0    7.0   0.45                 45 / 100
0.0    0.0    1.0   0.0    0.0   1.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    2.0   0.0    0.0   18.0   0.0    11.0  4.0    0.0   66.0   0.0   0.38317757009345793  41 / 107
0.0    0.0    0.0   1.0    4.0   2.0   0.0   0.0    1.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    13.0  0.0    0.0    0.0   0.0    4.0   3.0    56.0  0.3563218390804598   31 / 87
101.0  112.0  73.0  112.0  96.0  81.0  81.0  108.0  92.0  98.0  88.0  87.0  95.0  114.0  77.0  113.0  72.0  124.0  82.0  101.0  100.0  96.0  114.0  80.0  105.0  88.0  0.3036144578313253   756 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.696386
2    0.811245
3    0.873494
4    0.902008
5    0.923293
6    0.940964
7    0.953815
8    0.959839
9    0.968273
10   0.974699
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:39  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:39  6 min 37.592 sec  135229 obs/sec    1         1             10007      0.686928         1.46576             0.991613       0.412876                         0.685563           1.46252               0.991625         0.415261
    2019-08-04 09:06:40  6 min 38.231 sec  144193 obs/sec    10        10            100070     0.572591         1.0537              0.994173       0.305308                         0.575085           1.0656                0.994107         0.303614
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0961773
C13         0.973906               0.973906             0.0936677
C9          0.892399               0.892399             0.0858285
C12         0.827301               0.827301             0.0795676
C14         0.732205               0.732205             0.0704215
C7          0.726787               0.726787             0.0699004
C11         0.694854               0.694854             0.0668291
C8          0.63308                0.63308              0.0608879
C16         0.594168               0.594168             0.0571455
C10         0.585974               0.585974             0.0563574
C3          0.538287               0.538287             0.051771
C4          0.499433               0.499433             0.0480341
C5          0.491571               0.491571             0.047278
C6          0.482376               0.482376             0.0463937
C1          0.391505               0.391505             0.0376539
C2          0.333619               0.333619             0.0320866
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_154

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.00125024896414061    0.0003428641939535737   0.0         0.03583040601529319    1.332324504852295    0.0206848859938467   1.0371699333190918
    3        26       Softmax                 0.0   0.0   0.0017073795731378666  0.00015645415987819433  0.0         -0.022719129212859457  0.44490528106689453  -0.5253551262662324  0.3908684253692627


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3313172385959148
RMSE: 0.5756016318565426
LogLoss: 1.0533788654234861
Mean Per-Class Error: 0.29592860690955947
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  1.0    0.0    2.0    0.0    0.0    0.0    4.0    0.0    0.0    3.0    0.0    6.0    1.0    4.0    0.0    1.0    1.0    3.0    0.0    1.0    0.0    2.0    3.0    8.0    0.0    0.10152284263959391  40 / 394
0.0    272.0  0.0    11.0   1.0    0.0    3.0    12.0   8.0    1.0    11.0   0.0    0.0    0.0    0.0    2.0    3.0    41.0   12.0   0.0    0.0    3.0    1.0    1.0    1.0    0.0    0.2898172323759791   111 / 383
0.0    0.0    276.0  0.0    18.0   8.0    23.0   1.0    1.0    0.0    15.0   0.0    4.0    0.0    1.0    0.0    6.0    1.0    5.0    2.0    5.0    0.0    2.0    0.0    0.0    0.0    0.25                 92 / 368
8.0    20.0   0.0    280.0  0.0    3.0    0.0    10.0   0.0    2.0    4.0    1.0    9.0    8.0    14.0   4.0    0.0    29.0   1.0    1.0    1.0    0.0    0.0    8.0    0.0    0.0    0.3052109181141439   123 / 403
0.0    10.0   1.0    0.0    279.0  0.0    13.0   0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    20.0   8.0    9.0    13.0   0.0    0.0    0.0    3.0    0.0    20.0   0.27154046997389036  104 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    18.0   6.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    7.0    332.0  0.0    0.0    0.0    0.11702127659574468  44 / 376
1.0    12.0   0.0    4.0    15.0   1.0    0.0    3.0    14.0   0.0    12.0   2.0    0.0    2.0    0.0    0.0    27.0   15.0   16.0   12.0   1.0    0.0    0.0    213.0  8.0    36.0   0.4593908629441624   181 / 394
0.0    0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    4.0    14.0   0.0    4.0    41.0   2.0    69.0   6.0    0.0    241.0  0.0    0.38676844783715014  152 / 393
4.0    1.0    0.0    3.0    14.0   2.0    0.0    0.0    5.0    2.0    1.0    0.0    0.0    0.0    0.0    6.0    5.0    7.0    39.0   7.0    0.0    0.0    0.0    7.0    0.0    264.0  0.28065395095367845  103 / 367
444.0  498.0  345.0  370.0  393.0  370.0  308.0  250.0  358.0  316.0  433.0  310.0  472.0  402.0  387.0  372.0  484.0  489.0  265.0  413.0  383.0  393.0  449.0  306.0  385.0  408.0  0.2950114965510347   2,951 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.704989
2    0.819954
3    0.874738
4    0.904229
5    0.923323
6    0.938319
7    0.952514
8    0.960912
9    0.96761
10   0.974308

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.33436623121653447
RMSE: 0.5782440931099379
LogLoss: 1.0727498491618053
Mean Per-Class Error: 0.3043145058513286
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16     17     18    19    20    21     22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  ----  -----  -----  ----  -----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.0    1.0    1.0   4.0    0.0    0.0898876404494382   8 / 89
0.0    71.0   0.0   3.0    0.0   0.0   2.0   4.0   2.0   0.0   3.0    0.0   0.0    0.0   0.0   0.0    2.0    13.0   2.0   0.0   0.0   2.0    1.0    1.0   0.0    0.0    0.330188679245283    35 / 106
0.0    0.0    55.0  0.0    4.0   1.0   8.0   1.0   1.0   0.0   3.0    0.0   1.0    0.0   1.0   0.0    2.0    0.0    3.0   0.0   1.0   0.0    1.0    0.0   0.0    0.0    0.32926829268292684  27 / 82
4.0    3.0    0.0   79.0   0.0   1.0   0.0   6.0   0.0   1.0   2.0    1.0   4.0    1.0   3.0   2.0    0.0    4.0    0.0   0.0   0.0   0.0    0.0    1.0   0.0    0.0    0.29464285714285715  33 / 112
0.0    3.0    0.0   0.0    65.0  0.0   3.0   0.0   1.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    6.0    2.0    5.0   5.0   0.0   0.0    0.0    1.0   0.0    5.0    0.32989690721649484  32 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---   ---    ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   4.0    1.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0   1.0    84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0    3.0    0.0   3.0    5.0   1.0   0.0   2.0   4.0   0.0   7.0    0.0   0.0    0.0   0.0   0.0    3.0    1.0    4.0   2.0   0.0   0.0    0.0    49.0  3.0    13.0   0.51                 51 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0    7.0    0.0    0.0   9.0   0.0   21.0   2.0    0.0   64.0   0.0    0.40186915887850466  43 / 107
0.0    0.0    0.0   2.0    4.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   2.0    1.0    3.0    7.0   3.0   0.0   0.0    0.0    4.0   0.0    60.0   0.3103448275862069   27 / 87
107.0  114.0  71.0  108.0  89.0  78.0  79.0  76.0  83.0  89.0  105.0  83.0  112.0  97.0  76.0  115.0  125.0  119.0  74.0  95.0  97.0  100.0  115.0  82.0  101.0  100.0  0.3044176706827309   758 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.695582
2    0.812851
3    0.867068
4    0.900402
5    0.921687
6    0.938554
7    0.951004
8    0.958233
9    0.963052
10   0.970281
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:22  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:22  4 min 20.674 sec  94405 obs/sec     1         1             10007      0.677091         1.39969             0.991852       0.388683                         0.676469           1.39552               0.991846         0.391165
    2019-08-04 09:04:23  4 min 21.639 sec  96221 obs/sec     10        10            100070     0.575602         1.05338             0.994112       0.295011                         0.578244           1.07275               0.994042         0.304418
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0859995
C15         0.983027               0.983027             0.0845398
C9          0.951772               0.951772             0.0818519
C13         0.942736               0.942736             0.0810748
C11         0.889651               0.889651             0.0765095
C7          0.886563               0.886563             0.0762439
C8          0.836496               0.836496             0.0719382
C14         0.831696               0.831696             0.0715254
C10         0.680094               0.680094             0.0584877
C16         0.624723               0.624723             0.0537258
C3          0.587476               0.587476             0.0505226
C4          0.545111               0.545111             0.0468793
C6          0.540138               0.540138             0.0464516
C5          0.507041               0.507041             0.0436053
C1          0.423655               0.423655             0.0364341
C2          0.397801               0.397801             0.0342107
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_213

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0010751839586191636  0.0002578516723588109   0.0         -0.06899654790458953  1.1143474578857422  -0.26467296291356796  1.0307350158691406
    3        26       Softmax                 0.0   0.0   0.0017730935540804728  0.00018071505473926663  0.0         0.026562809064601494  0.5983459949493408  -0.4659933519354365   0.22351306676864624


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3300627317101096
RMSE: 0.5745108630044428
LogLoss: 1.0581213003954084
Mean Per-Class Error: 0.30830715458958075
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
342.0  0.0    0.0    1.0    0.0    0.0    2.0    2.0    0.0    5.0    5.0    4.0    7.0    0.0    0.0    0.0    6.0    2.0    6.0    1.0    2.0    0.0    6.0    1.0    3.0    0.0    0.1341772151898734   53 / 395
0.0    259.0  0.0    7.0    1.0    1.0    5.0    22.0   3.0    0.0    6.0    0.0    2.0    0.0    1.0    0.0    3.0    40.0   18.0   1.0    1.0    5.0    1.0    4.0    1.0    1.0    0.3219895287958115   123 / 382
0.0    2.0    267.0  0.0    18.0   7.0    31.0   0.0    0.0    0.0    8.0    0.0    0.0    0.0    5.0    0.0    5.0    1.0    5.0    2.0    6.0    0.0    3.0    2.0    4.0    1.0    0.2724795640326976   100 / 367
4.0    18.0   0.0    292.0  1.0    5.0    0.0    22.0   0.0    4.0    1.0    3.0    4.0    6.0    7.0    4.0    0.0    19.0   4.0    0.0    0.0    0.0    1.0    6.0    0.0    2.0    0.27543424317617865  111 / 403
0.0    13.0   3.0    0.0    264.0  4.0    16.0   2.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    1.0    3.0    11.0   15.0   10.0   0.0    0.0    0.0    9.0    0.0    22.0   0.3125               120 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    14.0   0.0    0.0    0.0    0.0    10.0   16.0   2.0    3.0    2.0    2.0    0.0    0.0    4.0    3.0    317.0  0.0    0.0    0.0    0.15691489361702127  59 / 376
0.0    10.0   0.0    4.0    30.0   4.0    14.0   7.0    7.0    6.0    10.0   2.0    0.0    2.0    0.0    0.0    8.0    8.0    19.0   6.0    1.0    0.0    0.0    237.0  4.0    15.0   0.39847715736040606  157 / 394
0.0    1.0    0.0    1.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    4.0    18.0   0.0    3.0    79.0   5.0    49.0   1.0    3.0    213.0  0.0    0.45663265306122447  179 / 392
3.0    2.0    0.0    2.0    26.0   5.0    0.0    0.0    1.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    43.0   6.0    0.0    0.0    0.0    2.0    0.0    269.0  0.2670299727520436   98 / 367
407.0  519.0  350.0  404.0  402.0  356.0  431.0  324.0  340.0  322.0  341.0  301.0  437.0  370.0  406.0  395.0  341.0  464.0  353.0  455.0  403.0  366.0  469.0  333.0  314.0  400.0  0.3071078676397081   3,072 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.692892
2    0.817355
3    0.870339
4    0.90063
5    0.920424
6    0.93402
7    0.946716
8    0.955013
9    0.96581
10   0.972808

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.33657256419799336
RMSE: 0.580148743166779
LogLoss: 1.0772994392408355
Mean Per-Class Error: 0.3116193992202042
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9     10    11    12    13    14    15     16    17     18    19    20     21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   1.0   2.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   1.0    0.0   2.0    0.0   1.0   0.0   0.12359550561797752  11 / 89
0.0   68.0   0.0   2.0    0.0   0.0   0.0    11.0  1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    2.0   12.0   3.0   0.0   1.0    2.0   1.0    2.0   0.0   0.0   0.3584905660377358   38 / 106
0.0   1.0    56.0  0.0    3.0   1.0   6.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   3.0   0.0    2.0   0.0    2.0   0.0   1.0    0.0   1.0    1.0   3.0   0.0   0.3170731707317073   26 / 82
1.0   5.0    0.0   84.0   0.0   1.0   0.0    6.0   0.0   2.0   0.0   1.0   2.0   3.0   1.0   0.0    0.0   5.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.25                 28 / 112
0.0   3.0    1.0   0.0    61.0  2.0   4.0    1.0   0.0   0.0   5.0   0.0   0.0   0.0   0.0   0.0    1.0   2.0    7.0   3.0   0.0    0.0   0.0    3.0   0.0   4.0   0.3711340206185567   36 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0   5.0   0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   82.0   0.0   0.0   0.0   0.10869565217391304  10 / 92
0.0   4.0    0.0   1.0    10.0  0.0   3.0    3.0   3.0   1.0   4.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    5.0   1.0   1.0    0.0   0.0    55.0  2.0   4.0   0.45                 45 / 100
0.0   1.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   2.0    7.0   0.0    0.0   12.0  2.0    13.0  0.0    1.0   66.0  0.0   0.38317757009345793  41 / 107
1.0   1.0    0.0   1.0    10.0  1.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    12.0  3.0   0.0    0.0   0.0    0.0   0.0   57.0  0.3448275862068966   30 / 87
97.0  126.0  72.0  116.0  93.0  78.0  105.0  89.0  79.0  92.0  89.0  80.0  90.0  99.0  90.0  120.0  94.0  112.0  98.0  93.0  107.0  86.0  120.0  83.0  99.0  83.0  0.3108433734939759   774 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.689157
2    0.813253
3    0.86988
4    0.901205
5    0.918474
6    0.932932
7    0.944177
8    0.951807
9    0.964659
10   0.972691
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:16  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:16  6 min 14.304 sec  137082 obs/sec    1         1             10007      0.702889         1.50849             0.991217       0.425672                         0.703653           1.50954               0.991178         0.435743
    2019-08-04 09:06:17  6 min 14.984 sec  136521 obs/sec    10        10            100070     0.574511         1.05812             0.994133       0.307108                         0.580149           1.0773                0.994003         0.310843
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0928839
C12         0.899908               0.899908             0.083587
C13         0.875016               0.875016             0.081275
C8          0.847753               0.847753             0.0787426
C9          0.804635               0.804635             0.0747376
C11         0.796783               0.796783             0.0740084
C14         0.791296               0.791296             0.0734987
C7          0.779934               0.779934             0.0724433
C10         0.60833                0.60833              0.0565041
C6          0.600854               0.600854             0.0558097
C3          0.553905               0.553905             0.0514489
C5          0.546319               0.546319             0.0507443
C16         0.513392               0.513392             0.0476858
C1          0.400608               0.400608             0.03721
C2          0.376782               0.376782             0.034997
C4          0.370609               0.370609             0.0344236
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_187

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms         mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -----------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011184930438048468  0.0002927251625806093   0.0         -0.08175750163354678   1.134317398071289  -0.07780326313950914  1.1655774116516113
    3        26       Softmax                 0.0   0.0   0.0017929250954274232  0.00020578416297212243  0.0         0.0033585239843887393  0.603018045425415  -0.43882929837031737  0.2692192792892456


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3350224718809575
RMSE: 0.5788112575623918
LogLoss: 1.0753120341154838
Mean Per-Class Error: 0.31607801646329003
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
340.0  2.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    4.0    7.0    1.0    9.0    0.0    7.0    0.0    1.0    1.0    0.0    0.0    2.0    4.0    7.0    1.0    2.0    3.0    0.13924050632911392  55 / 395
1.0    257.0  0.0    10.0   1.0    0.0    2.0    8.0    5.0    1.0    9.0    0.0    4.0    0.0    0.0    4.0    3.0    30.0   37.0   0.0    0.0    9.0    0.0    1.0    0.0    1.0    0.3289817232375979   126 / 383
0.0    1.0    271.0  0.0    6.0    5.0    13.0   0.0    0.0    0.0    32.0   0.0    4.0    0.0    6.0    0.0    10.0   1.0    8.0    5.0    2.0    0.0    4.0    0.0    0.0    0.0    0.26358695652173914  97 / 368
6.0    31.0   0.0    313.0  0.0    2.0    0.0    4.0    2.0    1.0    0.0    0.0    8.0    0.0    4.0    7.0    0.0    20.0   0.0    0.0    3.0    0.0    0.0    2.0    0.0    0.0    0.22332506203473945  90 / 403
0.0    13.0   10.0   0.0    183.0  6.0    58.0   4.0    8.0    0.0    15.0   1.0    0.0    0.0    1.0    1.0    19.0   7.0    13.0   7.0    0.0    0.0    0.0    14.0   1.0    23.0   0.5234375            201 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    6.0    8.0    0.0    0.0    0.0    0.0    9.0    3.0    0.0    0.0    2.0    1.0    0.0    0.0    3.0    6.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
1.0    28.0   3.0    2.0    15.0   0.0    4.0    2.0    15.0   2.0    17.0   2.0    1.0    1.0    2.0    1.0    21.0   2.0    9.0    17.0   2.0    0.0    0.0    210.0  6.0    31.0   0.467005076142132    184 / 394
0.0    2.0    0.0    0.0    0.0    9.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    14.0   4.0    0.0    1.0    60.0   3.0    23.0   0.0    0.0    269.0  1.0    0.3155216284987277   124 / 393
4.0    15.0   0.0    4.0    10.0   10.0   3.0    0.0    11.0   3.0    3.0    0.0    0.0    0.0    0.0    3.0    6.0    1.0    18.0   5.0    0.0    0.0    0.0    13.0   1.0    257.0  0.2997275204359673   110 / 367
417.0  562.0  358.0  458.0  266.0  307.0  419.0  263.0  371.0  318.0  430.0  324.0  435.0  396.0  372.0  498.0  395.0  447.0  244.0  425.0  376.0  364.0  472.0  309.0  364.0  413.0  0.31450564830550837  3,146 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.685494
2    0.813856
3    0.86764
4    0.897231
5    0.916725
6    0.931821
7    0.943017
8    0.953014
9    0.960612
10   0.96871

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.33676654336292106
RMSE: 0.5803158996296078
LogLoss: 1.0857575130947477
Mean Per-Class Error: 0.31880577319754533
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9     10     11    12    13     14    15     16     17     18    19     20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -------------------  -----------
77.0  0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   1.0   1.0    0.0   3.0   0.0    1.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   3.0    0.0   2.0    0.0   0.1348314606741573   12 / 89
1.0   65.0   0.0   1.0    0.0   0.0   0.0    5.0   1.0   0.0   4.0    0.0   1.0   0.0    0.0   0.0    3.0    10.0   10.0  0.0    0.0   5.0   0.0    0.0   0.0    0.0   0.3867924528301887   41 / 106
0.0   0.0    54.0  0.0    3.0   0.0   3.0    0.0   0.0   0.0   9.0    0.0   1.0   0.0    2.0   0.0    3.0    0.0    3.0   3.0    0.0   0.0   1.0    0.0   0.0    0.0   0.34146341463414637  28 / 82
3.0   6.0    0.0   91.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    0.0   3.0   0.0    1.0   1.0    0.0    4.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.1875               21 / 112
0.0   2.0    1.0   0.0    44.0  2.0   15.0   1.0   2.0   0.0   4.0    0.0   0.0   0.0    0.0   0.0    5.0    3.0    4.0   5.0    0.0   0.0   0.0    2.0   0.0    7.0   0.5463917525773195   53 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0    2.0   0.0   0.0   0.0    0.0   3.0   1.0    0.0   0.0    0.0    0.0    0.0   0.0    1.0   0.0   84.0   0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   7.0    2.0   1.0    3.0   0.0   3.0    1.0   3.0   0.0   5.0    1.0   1.0   0.0    0.0   0.0    3.0    1.0    2.0   6.0    0.0   0.0   0.0    52.0  1.0    8.0   0.48                 48 / 100
0.0   1.0    0.0   0.0    0.0   1.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0    4.0   4.0    1.0    0.0    0.0   12.0   0.0   5.0   0.0    0.0   78.0   0.0   0.27102803738317754  29 / 107
0.0   2.0    0.0   1.0    2.0   2.0   1.0    0.0   2.0   1.0   2.0    0.0   0.0   0.0    0.0   1.0    0.0    0.0    4.0   2.0    0.0   0.0   0.0    6.0   0.0    61.0  0.2988505747126437   26 / 87
99.0  137.0  74.0  129.0  62.0  66.0  101.0  77.0  88.0  90.0  112.0  90.0  98.0  107.0  71.0  137.0  104.0  108.0  67.0  104.0  92.0  85.0  110.0  80.0  104.0  98.0  0.3156626506024096   786 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.684337
2    0.809639
3    0.864659
4    0.88996
5    0.908835
6    0.927711
7    0.940161
8    0.950201
9    0.958233
10   0.969076
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:34  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:34  5 min 32.442 sec  137082 obs/sec    1         1             10007      0.687929         1.49577             0.991592       0.426572                         0.692144           1.5119                0.991464         0.440562
    2019-08-04 09:05:35  5 min 33.097 sec  140154 obs/sec    10        10            100070     0.578811         1.07531             0.994048       0.314506                         0.580316           1.08576               0.993999         0.315663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0882568
C15         0.988507               0.988507             0.0872424
C7          0.877905               0.877905             0.0774811
C9          0.872563               0.872563             0.0770097
C14         0.845668               0.845668             0.0746359
C12         0.825622               0.825622             0.0728667
C8          0.823627               0.823627             0.0726907
C11         0.81301                0.81301              0.0717537
C10         0.62847                0.62847              0.0554667
C6          0.599765               0.599765             0.0529334
C16         0.589001               0.589001             0.0519834
C5          0.570053               0.570053             0.0503111
C3          0.535089               0.535089             0.0472253
C4          0.50572                0.50572              0.0446333
C1          0.449064               0.449064             0.039633
C2          0.406507               0.406507             0.035877
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_218

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0013202013616933073  0.00033229077234864235  0.0         0.012981782590259172  1.3802103996276855  0.11076149771075902  1.0882720947265625
    3        26       Softmax                 0.0   0.0   0.0017035690790670253  0.0001165626454167068   0.0         -0.02010229199913738  0.442874550819397   -0.5283614144992888  0.3598068952560425


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.33820102934214064
RMSE: 0.5815505389406329
LogLoss: 1.0731704361735164
Mean Per-Class Error: 0.308806740147386
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
347.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    3.0    8.0    0.0    7.0    5.0    4.0    0.0    1.0    0.0    2.0    0.0    0.0    1.0    4.0    2.0    6.0    2.0    0.12151898734177215  48 / 395
0.0    268.0  0.0    7.0    2.0    0.0    2.0    5.0    5.0    3.0    2.0    0.0    0.0    1.0    1.0    11.0   11.0   47.0   14.0   0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.3002610966057441   115 / 383
0.0    0.0    288.0  0.0    14.0   2.0    29.0   1.0    0.0    0.0    15.0   0.0    2.0    0.0    2.0    4.0    0.0    0.0    0.0    1.0    3.0    0.0    4.0    1.0    0.0    2.0    0.21739130434782608  80 / 368
4.0    19.0   0.0    287.0  0.0    0.0    0.0    6.0    0.0    6.0    1.0    0.0    9.0    2.0    14.0   9.0    1.0    23.0   6.0    2.0    0.0    0.0    0.0    14.0   0.0    0.0    0.2878411910669975   116 / 403
0.0    18.0   36.0   0.0    234.0  1.0    19.0   0.0    1.0    1.0    9.0    0.0    0.0    0.0    0.0    2.0    18.0   3.0    7.0    4.0    1.0    0.0    0.0    10.0   0.0    20.0   0.390625             150 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    25.0   4.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    6.0    325.0  0.0    0.0    0.0    0.1356382978723404   51 / 376
11.0   14.0   3.0    16.0   8.0    0.0    1.0    4.0    9.0    2.0    11.0   4.0    0.0    0.0    2.0    0.0    17.0   1.0    26.0   5.0    4.0    0.0    0.0    245.0  9.0    2.0    0.37817258883248733  149 / 394
0.0    0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    1.0    0.0    0.0    1.0    2.0    6.0    5.0    12.0   0.0    2.0    51.0   1.0    84.0   2.0    0.0    207.0  3.0    0.4732824427480916   186 / 393
5.0    3.0    0.0    3.0    18.0   3.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    49.0   6.0    0.0    0.0    0.0    7.0    0.0    264.0  0.2786885245901639   102 / 366
442.0  459.0  430.0  412.0  359.0  352.0  334.0  202.0  361.0  318.0  364.0  327.0  503.0  387.0  414.0  407.0  420.0  491.0  294.0  397.0  377.0  421.0  465.0  355.0  316.0  396.0  0.3077076876936919   3,078 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.692292
2    0.821054
3    0.871938
4    0.904029
5    0.924123
6    0.939818
7    0.952114
8    0.960412
9    0.96661
10   0.973008

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3418280507315474
RMSE: 0.5846606286826123
LogLoss: 1.088089623800278
Mean Per-Class Error: 0.311741999313124
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16     17     18    19    20     21    22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  ----  -----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0    1.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   1.0    1.0   3.0   1.0    0.11235955056179775  10 / 89
0.0    72.0   0.0   1.0    2.0   0.0   1.0   0.0   2.0   0.0   2.0   0.0   0.0    1.0    1.0   1.0    5.0    12.0   2.0   0.0   0.0    0.0   3.0    1.0   0.0   0.0    0.32075471698113206  34 / 106
0.0    0.0    58.0  0.0    5.0   0.0   8.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0    1.0   2.0    0.0    0.0    0.0   1.0   1.0    0.0   2.0    0.0   0.0   1.0    0.2926829268292683   24 / 82
2.0    5.0    0.0   87.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   3.0    1.0    4.0   2.0    0.0    4.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0    0.22321428571428573  25 / 112
0.0    3.0    11.0  0.0    54.0  1.0   5.0   0.0   0.0   1.0   4.0   0.0   0.0    0.0    0.0   0.0    4.0    0.0    2.0   2.0   0.0    0.0   0.0    1.0   0.0   9.0    0.44329896907216493  43 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0    1.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0    0.0   84.0   0.0   0.0   0.0    0.08695652173913043  8 / 92
2.0    4.0    1.0   5.0    2.0   0.0   0.0   2.0   3.0   0.0   5.0   1.0   0.0    0.0    0.0   0.0    2.0    1.0    11.0  1.0   0.0    0.0   0.0    53.0  6.0   1.0    0.47                 47 / 100
0.0    0.0    0.0   0.0    0.0   3.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0    3.0   3.0    5.0    0.0    0.0   11.0  0.0    25.0  1.0    0.0   54.0  0.0    0.4953271028037383   53 / 107
0.0    1.0    0.0   2.0    5.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   1.0    0.0    0.0    8.0   4.0   0.0    0.0   0.0    1.0   0.0   64.0   0.26436781609195403  23 / 87
103.0  112.0  90.0  123.0  81.0  79.0  81.0  47.0  87.0  87.0  95.0  89.0  114.0  102.0  88.0  118.0  105.0  131.0  80.0  91.0  100.0  97.0  119.0  79.0  92.0  100.0  0.31204819277108437  777 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.687952
2    0.82008
3    0.872691
4    0.902008
5    0.921285
6    0.940562
7    0.951004
8    0.958233
9    0.963855
10   0.96988
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:22  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:22  6 min 20.071 sec  98107 obs/sec     1         1             10007      0.673366         1.40427             0.991942       0.383485                         0.67348            1.39882               0.991918         0.385944
    2019-08-04 09:06:23  6 min 21.052 sec  95214 obs/sec     10        10            100070     0.581551         1.07317             0.993989       0.307708                         0.584661           1.08809               0.993909         0.312048
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0870373
C9          0.972176               0.972176             0.0846155
C13         0.970337               0.970337             0.0844555
C11         0.87412                0.87412              0.076081
C12         0.837471               0.837471             0.0728912
C14         0.776209               0.776209             0.0675591
C8          0.767737               0.767737             0.0668217
C7          0.766797               0.766797             0.0667399
C10         0.703879               0.703879             0.0612637
C3          0.614471               0.614471             0.0534819
C16         0.608612               0.608612             0.0529719
C6          0.58535                0.58535              0.0509472
C5          0.560585               0.560585             0.0487918
C4          0.52627                0.52627              0.0458051
C2          0.463958               0.463958             0.0403816
C1          0.46136                0.46136              0.0401555
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_99

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011431852634586903  0.0002829190343618393  0.0         0.04092120028417412    1.074754238128662   -0.20059926293871772  0.8715136051177979
    3        26       Softmax                 0.0   0.0   0.0017841826492468289  0.0001893362496048212  0.0         -0.004234421267247294  0.5882923603057861  -0.47933585086816005  0.33608293533325195


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3344877339682271
RMSE: 0.5783491453855769
LogLoss: 1.0649384632512457
Mean Per-Class Error: 0.30459854979650014
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
347.0  1.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    3.0    9.0    1.0    6.0    0.0    0.0    5.0    2.0    1.0    2.0    0.0    3.0    1.0    6.0    0.0    0.12151898734177215  48 / 395
1.0    284.0  0.0    26.0   4.0    0.0    3.0    0.0    2.0    3.0    1.0    0.0    0.0    0.0    1.0    2.0    4.0    27.0   17.0   0.0    0.0    4.0    1.0    2.0    1.0    0.0    0.2584856396866841   99 / 383
0.0    0.0    275.0  0.0    22.0   2.0    15.0   0.0    0.0    0.0    29.0   0.0    1.0    0.0    4.0    1.0    0.0    1.0    6.0    4.0    4.0    0.0    1.0    1.0    0.0    2.0    0.25271739130434784  93 / 368
13.0   36.0   0.0    290.0  0.0    2.0    0.0    9.0    0.0    2.0    1.0    0.0    5.0    0.0    11.0   9.0    0.0    19.0   1.0    0.0    3.0    0.0    0.0    2.0    0.0    0.0    0.2803970223325062   113 / 403
0.0    10.0   0.0    0.0    260.0  5.0    18.0   0.0    2.0    0.0    6.0    2.0    0.0    0.0    0.0    0.0    11.0   9.0    22.0   7.0    0.0    0.0    0.0    16.0   1.0    15.0   0.3229166666666667   124 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    30.0   2.0    1.0    0.0    0.0    2.0    0.0    0.0    7.0    6.0    318.0  0.0    0.0    0.0    0.15425531914893617  58 / 376
1.0    10.0   0.0    12.0   21.0   6.0    1.0    0.0    12.0   1.0    8.0    3.0    0.0    0.0    0.0    0.0    28.0   5.0    16.0   16.0   3.0    2.0    0.0    205.0  10.0   34.0   0.4796954314720812   189 / 394
2.0    2.0    0.0    3.0    0.0    5.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    2.0    5.0    0.0    4.0    71.0   0.0    66.0   0.0    3.0    222.0  0.0    0.4351145038167939   171 / 393
0.0    17.0   0.0    1.0    21.0   0.0    0.0    0.0    1.0    2.0    1.0    5.0    0.0    0.0    0.0    0.0    1.0    6.0    28.0   12.0   0.0    0.0    0.0    2.0    1.0    269.0  0.2670299727520436   98 / 367
437.0  537.0  338.0  453.0  409.0  336.0  335.0  186.0  344.0  325.0  370.0  350.0  485.0  388.0  369.0  378.0  369.0  483.0  350.0  465.0  416.0  437.0  436.0  284.0  322.0  401.0  0.30340897730680794  3,035 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.696591
2    0.818155
3    0.869139
4    0.90073
5    0.919824
6    0.93432
7    0.947416
8    0.957613
9    0.96621
10   0.972908

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3407566930732916
RMSE: 0.5837436878230818
LogLoss: 1.0941268374877313
Mean Per-Class Error: 0.3159125080569003
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10    11    12     13     14    15     16    17     18    19     20     21     22     23    24    25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  -----  -----  -----  -----  ----  ----  ----  -------------------  -----------
78.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0   1.0   0.0   2.0    1.0    0.0   0.0    0.0   2.0    1.0   0.0    0.0    0.0    1.0    0.0   2.0   0.0   0.12359550561797752  11 / 89
0.0    69.0   0.0   7.0    2.0    0.0   1.0   0.0   1.0   2.0   0.0   0.0   0.0    0.0    1.0   0.0    2.0   12.0   5.0   0.0    0.0    3.0    1.0    0.0   0.0   0.0   0.3490566037735849   37 / 106
0.0    0.0    57.0  0.0    7.0    0.0   3.0   0.0   0.0   0.0   8.0   0.0   0.0    0.0    1.0   0.0    0.0   0.0    3.0   2.0    0.0    0.0    1.0    0.0   0.0   0.0   0.3048780487804878   25 / 82
4.0    4.0    0.0   83.0   0.0    0.0   0.0   5.0   0.0   1.0   1.0   0.0   1.0    0.0    2.0   3.0    0.0   5.0    1.0   0.0    1.0    0.0    0.0    1.0   0.0   0.0   0.25892857142857145  29 / 112
0.0    2.0    0.0   0.0    61.0   2.0   3.0   0.0   1.0   0.0   2.0   1.0   0.0    0.0    0.0   0.0    4.0   3.0    7.0   3.0    0.0    0.0    0.0    3.0   0.0   5.0   0.3711340206185567   36 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---    ---    ---    ---    ---   ---   ---   ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0    86.0   0.0   0.0   0.0   0.06521739130434782  6 / 92
0.0    4.0    0.0   5.0    5.0    1.0   0.0   0.0   4.0   0.0   4.0   1.0   0.0    0.0    0.0   0.0    6.0   2.0    4.0   5.0    1.0    0.0    0.0    47.0  2.0   9.0   0.53                 53 / 100
0.0    1.0    0.0   1.0    0.0    0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0    1.0   0.0    3.0   0.0    2.0   15.0   0.0    20.0   0.0    1.0   60.0  0.0   0.4392523364485981   47 / 107
0.0    5.0    0.0   1.0    7.0    0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    0.0    0.0   0.0    0.0   2.0    6.0   4.0    0.0    0.0    0.0    1.0   0.0   59.0  0.3218390804597701   28 / 87
102.0  133.0  68.0  131.0  100.0  80.0  85.0  45.0  83.0  92.0  98.0  98.0  107.0  107.0  78.0  105.0  98.0  118.0  91.0  109.0  101.0  102.0  116.0  69.0  82.0  92.0  0.3152610441767068   785 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.684739
2    0.81245
3    0.866265
4    0.898394
5    0.915663
6    0.932129
7    0.94498
8    0.951807
9    0.960241
10   0.967068
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:46  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:46  2 min 44.680 sec  140943 obs/sec    1         1             10007      0.691411         1.48454             0.991506       0.413776                         0.690423           1.47643               0.991506         0.416466
    2019-08-04 09:02:47  2 min 45.330 sec  143161 obs/sec    10        10            100070     0.578349         1.06494             0.994057       0.303409                         0.583744           1.09413               0.993928         0.315261
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.102788
C12         0.810161               0.810161             0.0832747
C13         0.778408               0.778408             0.0800109
C9          0.769668               0.769668             0.0791125
C11         0.753398               0.753398             0.0774402
C7          0.704656               0.704656             0.0724301
C8          0.657296               0.657296             0.067562
C14         0.644793               0.644793             0.0662769
C10         0.547803               0.547803             0.0563075
C16         0.531683               0.531683             0.0546506
C6          0.511038               0.511038             0.0525285
C5          0.471299               0.471299             0.0484438
C3          0.454526               0.454526             0.0467197
C4          0.385055               0.385055             0.039579
C1          0.358026               0.358026             0.0368007
C2          0.350969               0.350969             0.0360754
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_62

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0007981754392289986  0.00020818918710574508  0.0         -0.018796291012904476  0.2839754819869995  0.04503327447712678  0.20256012678146362
    3        26       Softmax                      0.0   0.0   0.004479252496856554   0.008839331567287445    0.0         -0.36475479079476475   0.8946001529693604  -0.8431834059140536  0.6295435428619385


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3720184899893374
RMSE: 0.6099331848566181
LogLoss: 1.0950427324842316
Mean Per-Class Error: 0.26735548651988633
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  3.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    6.0    0.0    1.0    0.0    2.0    0.0    6.0    0.0    0.0    1.0    8.0    0.0    6.0    0.0    0.10152284263959391  40 / 394
0.0    316.0  0.0    9.0    0.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    12.0   2.0    2.0    17.0   3.0    0.0    0.0    1.0    3.0    8.0    2.0    0.0    0.17493472584856398  67 / 383
0.0    2.0    295.0  0.0    12.0   0.0    15.0   0.0    0.0    0.0    20.0   0.0    0.0    0.0    4.0    1.0    3.0    0.0    3.0    0.0    1.0    0.0    6.0    6.0    0.0    0.0    0.1983695652173913   73 / 368
4.0    15.0   0.0    316.0  0.0    0.0    4.0    1.0    0.0    4.0    0.0    0.0    5.0    8.0    17.0   2.0    0.0    10.0   4.0    0.0    0.0    0.0    0.0    9.0    0.0    4.0    0.21588089330024815  87 / 403
0.0    7.0    2.0    1.0    271.0  2.0    20.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    9.0    7.0    19.0   0.0    1.0    0.0    0.0    18.0   0.0    22.0   0.2924281984334204   112 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    3.0    0.0    14.0   2.0    10.0   0.0    0.0    5.0    0.0    0.0    0.0    0.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    1.0    0.0    7.0    5.0    0.0    0.0    0.0    7.0    1.0    8.0    2.0    0.0    0.0    2.0    0.0    5.0    1.0    22.0   3.0    2.0    1.0    0.0    289.0  10.0   28.0   0.26649746192893403  105 / 394
0.0    0.0    0.0    2.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    3.0    0.0    10.0   54.0   1.0    46.0   6.0    0.0    249.0  0.0    0.366412213740458    144 / 393
5.0    1.0    0.0    0.0    9.0    0.0    1.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    51.0   2.0    0.0    0.0    0.0    3.0    0.0    289.0  0.2125340599455041   78 / 367
417.0  507.0  367.0  493.0  331.0  310.0  335.0  178.0  335.0  330.0  380.0  317.0  461.0  373.0  496.0  386.0  333.0  425.0  405.0  427.0  335.0  379.0  477.0  443.0  333.0  430.0  0.26632010396880934  2,664 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.73368
2    0.837649
3    0.875637
4    0.903029
5    0.927722
6    0.942517
7    0.955113
8    0.963811
9    0.972008
10   0.977507

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.37378428208314324
RMSE: 0.6113790003615951
LogLoss: 1.0942333148141492
Mean Per-Class Error: 0.2696971808575855
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13    14     15     16    17     18    19     20    21    22     23     24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  ----  -----  -----  ----  -----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.0   0.0    1.0   0.0    0.0   0.0   2.0    0.0    3.0   0.0    0.10112359550561797  9 / 89
0.0    83.0   0.0   3.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   6.0    1.0    1.0   4.0    1.0   0.0    0.0   1.0   2.0    3.0    0.0   0.0    0.2169811320754717   23 / 106
0.0    2.0    62.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0   4.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0    1.0   0.0    0.0   0.0   2.0    1.0    0.0   0.0    0.24390243902439024  20 / 82
3.0    1.0    0.0   92.0   0.0   0.0   2.0   1.0   0.0   0.0   0.0   0.0   1.0    4.0   3.0    0.0    0.0   1.0    1.0   0.0    0.0   0.0   0.0    1.0    0.0   2.0    0.17857142857142858  20 / 112
0.0    3.0    0.0   0.0    63.0  1.0   5.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0    2.0   2.0    6.0   0.0    0.0   0.0   0.0    5.0    0.0   9.0    0.35051546391752575  34 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---   ---    ---    ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   3.0    0.0   1.0    0.0    0.0   1.0    0.0   0.0    0.0   0.0   85.0   0.0    0.0   0.0    0.07608695652173914  7 / 92
0.0    0.0    0.0   2.0    2.0   0.0   0.0   0.0   5.0   0.0   3.0   0.0   0.0    0.0   0.0    0.0    1.0   1.0    6.0   1.0    0.0   0.0   0.0    71.0   3.0   5.0    0.29                 29 / 100
0.0    0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0    2.0    1.0   0.0    2.0   14.0   0.0   17.0  2.0    0.0    63.0  0.0    0.411214953271028    44 / 107
1.0    0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    10.0  1.0    0.0   0.0   0.0    2.0    0.0   69.0   0.20689655172413793  18 / 87
101.0  123.0  75.0  136.0  75.0  74.0  86.0  52.0  81.0  94.0  91.0  88.0  101.0  99.0  110.0  108.0  87.0  111.0  98.0  106.0  83.0  92.0  120.0  103.0  84.0  112.0  0.26907630522088355  670 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730924
2    0.841767
3    0.87992
4    0.908434
5    0.929719
6    0.94498
7    0.956627
8    0.965863
9    0.973494
10   0.980321
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:47  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:47  1 min 45.340 sec  256589 obs/sec    1         1             10007      0.85015          2.1555              0.987153       0.538838                         0.850299           2.15239               0.987117         0.548193
    2019-08-04 09:01:47  1 min 45.667 sec  286733 obs/sec    10        10            100070     0.609933         1.09504             0.993388       0.26632                          0.611379           1.09423               0.99334          0.269076
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.106177
C15         0.944151               0.944151             0.100247
C9          0.780373               0.780373             0.0828577
C8          0.681013               0.681013             0.072308
C7          0.670026               0.670026             0.0711414
C11         0.641483               0.641483             0.0681108
C14         0.618144               0.618144             0.0656327
C12         0.560777               0.560777             0.0595416
C6          0.523633               0.523633             0.0555979
C3          0.523308               0.523308             0.0555633
C10         0.517934               0.517934             0.0549927
C16         0.499539               0.499539             0.0530396
C5          0.493895               0.493895             0.0524403
C4          0.400549               0.400549             0.0425292
C1          0.304918               0.304918             0.0323753
C2          0.258485               0.258485             0.0274452
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_183

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.000798083487097756  0.00023347855312749743  0.0         -0.016560025300918824  0.29032087326049805  -0.0014474976691308211  0.21080780029296875
    3        26       Softmax                      0.0   0.0   0.004781034906185456  0.007549131289124489    0.0         -0.3476261346859246    0.8896079063415527   -0.8060795668455221     0.4495244026184082


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3677795769586084
RMSE: 0.6064483299990268
LogLoss: 1.0882205095582504
Mean Per-Class Error: 0.27029960969611594
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  3.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    0.0    11.0   0.0    1.0    0.0    4.0    0.0    5.0    0.0    1.0    0.0    4.0    4.0    5.0    0.0    0.11645569620253164  46 / 395
0.0    325.0  0.0    1.0    0.0    0.0    2.0    2.0    1.0    0.0    4.0    0.0    0.0    0.0    1.0    2.0    1.0    25.0   4.0    0.0    0.0    0.0    1.0    14.0   0.0    0.0    0.1514360313315927   58 / 383
0.0    0.0    293.0  0.0    19.0   0.0    5.0    0.0    0.0    0.0    25.0   0.0    0.0    0.0    2.0    0.0    2.0    0.0    7.0    2.0    12.0   0.0    0.0    0.0    0.0    1.0    0.20380434782608695  75 / 368
3.0    26.0   0.0    300.0  0.0    0.0    0.0    8.0    0.0    6.0    2.0    0.0    6.0    8.0    5.0    0.0    0.0    21.0   4.0    0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.2555831265508685   103 / 403
0.0    7.0    2.0    0.0    286.0  1.0    11.0   0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    8.0    5.0    7.0    6.0    0.0    0.0    0.0    18.0   0.0    23.0   0.25326370757180156  97 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    0.0    10.0   0.0    12.0   7.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    1.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
10.0   6.0    0.0    12.0   12.0   0.0    3.0    0.0    0.0    0.0    6.0    1.0    0.0    2.0    0.0    0.0    1.0    2.0    18.0   4.0    3.0    0.0    0.0    301.0  11.0   1.0    0.2340966921119593   92 / 393
0.0    0.0    0.0    1.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    19.0   0.0    10.0   74.0   0.0    51.0   1.0    3.0    225.0  0.0    0.42748091603053434  168 / 393
2.0    1.0    0.0    0.0    25.0   1.0    1.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    47.0   1.0    0.0    0.0    0.0    4.0    0.0    273.0  0.2561307901907357   94 / 367
411.0  531.0  363.0  412.0  450.0  282.0  286.0  211.0  339.0  331.0  396.0  305.0  470.0  377.0  392.0  403.0  357.0  462.0  364.0  459.0  393.0  394.0  474.0  488.0  290.0  363.0  0.2691192642207338   2,692 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730881
2    0.836649
3    0.881236
4    0.909827
5    0.928421
6    0.941917
7    0.952214
8    0.960512
9    0.96631
10   0.972208

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3718097109842645
RMSE: 0.609762011758903
LogLoss: 1.0975367661931943
Mean Per-Class Error: 0.2778618081431711
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10     11    12     13    14    15     16     17     18    19     20    21    22     23     24    25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  ----  -----  -----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0   0.0   1.0    1.0    3.0   0.0   0.10112359550561797  9 / 89
0.0   84.0   0.0   0.0    0.0    0.0   1.0   2.0   0.0   0.0   2.0    0.0   0.0    0.0   1.0   0.0    0.0    9.0    0.0   0.0    0.0   0.0   1.0    6.0    0.0   0.0   0.20754716981132076  22 / 106
0.0   0.0    59.0  0.0    5.0    0.0   2.0   0.0   0.0   0.0   7.0    0.0   0.0    0.0   1.0   0.0    1.0    0.0    3.0   1.0    3.0   0.0   0.0    0.0    0.0   0.0   0.2804878048780488   23 / 82
2.0   3.0    0.0   87.0   0.0    0.0   0.0   3.0   0.0   3.0   1.0    0.0   1.0    4.0   1.0   0.0    0.0    4.0    2.0   0.0    0.0   0.0   0.0    1.0    0.0   0.0   0.22321428571428573  25 / 112
0.0   3.0    0.0   0.0    69.0   1.0   3.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    2.0    1.0    1.0   3.0    0.0   0.0   0.0    4.0    0.0   8.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---   ---    ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0   3.0    0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   1.0   86.0   0.0    0.0   0.0   0.06521739130434782  6 / 92
3.0   3.0    0.0   2.0    5.0    0.0   1.0   0.0   0.0   0.0   3.0    0.0   0.0    0.0   0.0   0.0    0.0    1.0    5.0   3.0    0.0   0.0   0.0    70.0   3.0   1.0   0.3                  30 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    9.0    0.0    1.0   18.0   0.0   14.0  1.0    3.0    58.0  0.0   0.45794392523364486  49 / 107
0.0   0.0    0.0   0.0    9.0    0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0    11.0  1.0    0.0   0.0   0.0    1.0    0.0   62.0  0.28735632183908044  25 / 87
99.0  127.0  75.0  118.0  105.0  62.0  72.0  61.0  79.0  99.0  100.0  85.0  103.0  95.0  76.0  112.0  104.0  117.0  88.0  117.0  96.0  90.0  123.0  116.0  78.0  93.0  0.27630522088353415  688 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.723695
2    0.830924
3    0.883534
4    0.911245
5    0.930121
6    0.942169
7    0.953414
8    0.961847
9    0.966667
10   0.971486
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:05:27  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:05:27  5 min 25.540 sec  263342 obs/sec    1         1             10007      0.834432         2.0419              0.987625       0.491852                         0.83561            2.05144               0.987558         0.501606
    2019-08-04 09:05:28  5 min 25.859 sec  290901 obs/sec    10        10            100070     0.606448         1.08822             0.993463       0.269119                         0.609762           1.09754               0.993375         0.276305
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.105596
C15         0.906206               0.906206             0.095692
C9          0.784562               0.784562             0.0828468
C8          0.76821                0.76821              0.0811201
C12         0.755876               0.755876             0.0798177
C7          0.647752               0.647752             0.0684002
C11         0.610446               0.610446             0.0644608
C4          0.529102               0.529102             0.0558711
C14         0.510849               0.510849             0.0539438
C6          0.503235               0.503235             0.0531397
C10         0.490684               0.490684             0.0518144
C3          0.489117               0.489117             0.0516489
C16         0.428255               0.428255             0.0452221
C5          0.404861               0.404861             0.0427518
C1          0.353123               0.353123             0.0372885
C2          0.287755               0.287755             0.0303858
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_116

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0007828265446505611  0.0002227906370535493  0.0         -0.012412129416528472  0.28158867359161377  -0.0016969917398231445  0.20308786630630493
    3        26       Softmax                      0.0   0.0   0.004709370308214252   0.007747266441583633   0.0         -0.3895997893571173    0.8820536136627197   -0.8459024023943679     0.5058021545410156


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.37013455831607284
RMSE: 0.6083868492300543
LogLoss: 1.0915047263218058
Mean Per-Class Error: 0.26911772114262544
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0    3.0    8.0    0.0    5.0    1.0    7.0    0.0    0.0    0.0    5.0    0.0    1.0    3.0    2.0    1.0    3.0    0.0    0.10886075949367088  43 / 395
0.0    296.0  0.0    5.0    1.0    0.0    10.0   2.0    2.0    0.0    0.0    0.0    0.0    0.0    7.0    3.0    2.0    18.0   9.0    0.0    0.0    6.0    1.0    17.0   3.0    1.0    0.22715404699738903  87 / 383
0.0    0.0    289.0  0.0    24.0   2.0    10.0   0.0    0.0    0.0    18.0   0.0    1.0    0.0    3.0    1.0    4.0    0.0    3.0    5.0    2.0    0.0    6.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
9.0    26.0   0.0    309.0  0.0    1.0    0.0    0.0    0.0    10.0   1.0    0.0    2.0    9.0    3.0    0.0    0.0    7.0    7.0    0.0    0.0    0.0    0.0    18.0   1.0    0.0    0.23325062034739455  94 / 403
0.0    6.0    13.0   0.0    257.0  3.0    12.0   1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    16.0   5.0    8.0    4.0    1.0    0.0    0.0    19.0   0.0    38.0   0.3307291666666667   127 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    3.0    0.0    13.0   7.0    1.0    0.0    0.0    7.0    0.0    0.0    0.0    1.0    339.0  1.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    3.0    0.0    3.0    15.0   0.0    2.0    0.0    3.0    1.0    5.0    2.0    2.0    0.0    0.0    0.0    11.0   4.0    13.0   2.0    8.0    3.0    0.0    290.0  16.0   11.0   0.2639593908629442   104 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    22.0   0.0    15.0   57.0   1.0    19.0   1.0    0.0    273.0  0.0    0.3053435114503817   120 / 393
1.0    1.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    10.0   1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    53.0   2.0    0.0    0.0    0.0    7.0    0.0    280.0  0.23705722070844687  87 / 367
432.0  484.0  365.0  407.0  370.0  280.0  374.0  193.0  348.0  329.0  364.0  308.0  414.0  403.0  375.0  381.0  412.0  403.0  386.0  442.0  368.0  365.0  512.0  497.0  367.0  424.0  0.26781965410376884  2,679 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.73218
2    0.836749
3    0.881735
4    0.910527
5    0.929721
6    0.943917
7    0.954314
8    0.962111
9    0.969209
10   0.976107

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3728933476621154
RMSE: 0.610649938722764
LogLoss: 1.0979082586561952
Mean Per-Class Error: 0.27749654207037694
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16     17    18     19     20    21    22     23     24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  -----  ----  ----  -----  -----  ----  -----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0    0.0   1.0   2.0    0.0    2.0   0.0    0.10112359550561797  9 / 89
0.0    76.0   0.0   2.0    1.0   0.0   4.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0    4.0   0.0    1.0    4.0   2.0    0.0    0.0   4.0   0.0    6.0    0.0   0.0    0.2830188679245283   30 / 106
0.0    0.0    61.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    1.0   1.0    1.0    0.0   2.0    1.0    1.0   0.0   2.0    0.0    0.0   0.0    0.25609756097560976  21 / 82
3.0    2.0    0.0   90.0   0.0   0.0   0.0   0.0   0.0   4.0   1.0   0.0   1.0   3.0    1.0   0.0    0.0    1.0   4.0    0.0    0.0   0.0   0.0    2.0    0.0   0.0    0.19642857142857142  22 / 112
0.0    0.0    7.0   0.0    60.0  1.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    2.0   2.0    2.0    0.0   0.0   0.0    5.0    0.0   11.0   0.38144329896907214  37 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---    ---   ---   ---    ---    ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   1.0    0.0   0.0    0.0    2.0   0.0    0.0    0.0   1.0   86.0   0.0    0.0   0.0    0.06521739130434782  6 / 92
0.0    1.0    0.0   2.0    7.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    3.0    2.0   2.0    2.0    2.0   1.0   0.0    69.0   3.0   4.0    0.31                 31 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    9.0    0.0   4.0    17.0   0.0   5.0   1.0    0.0    70.0  0.0    0.34579439252336447  37 / 107
1.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   11.0   1.0    0.0   0.0   0.0    2.0    0.0   64.0   0.26436781609195403  23 / 87
102.0  113.0  79.0  119.0  87.0  58.0  94.0  49.0  78.0  98.0  92.0  84.0  90.0  103.0  80.0  116.0  119.0  96.0  102.0  111.0  94.0  83.0  129.0  116.0  92.0  106.0  0.27429718875502007  683 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.725703
2    0.830121
3    0.881526
4    0.910442
5    0.932129
6    0.946988
7    0.954217
8    0.959438
9    0.96747
10   0.975502
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:17  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:17  3 min 15.377 sec  238261 obs/sec    1         1             10007      0.847313         2.12292             0.987244       0.511647                         0.8489             2.12736               0.987159         0.517671
    2019-08-04 09:03:17  3 min 15.696 sec  287557 obs/sec    10        10            100070     0.608387         1.0915              0.993423       0.26782                          0.61065            1.09791               0.993356         0.274297
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.100907
C13         0.93134                0.93134              0.0939786
C12         0.801284               0.801284             0.0808551
C9          0.763272               0.763272             0.0770194
C7          0.714442               0.714442             0.0720922
C11         0.708072               0.708072             0.0714493
C8          0.676772               0.676772             0.068291
C14         0.627549               0.627549             0.0633241
C6          0.623674               0.623674             0.062933
C4          0.507851               0.507851             0.0512457
C10         0.504401               0.504401             0.0508976
C16         0.487193               0.487193             0.0491611
C5          0.462293               0.462293             0.0466485
C3          0.417674               0.417674             0.0421462
C2          0.348989               0.348989             0.0352155
C1          0.335315               0.335315             0.0338356
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_238

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008076430666505985  0.0002433181507512927  0.0         -0.017511343191927153  0.2846107482910156  0.0069121715297950585  0.2066274881362915
    3        26       Softmax                      0.0   0.0   0.004584758928453643   0.006669027730822563   0.0         -0.3089303495230874    0.8843770027160645  -0.8397055821774617    0.49330687522888184


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.36622697939782994
RMSE: 0.6051669021004288
LogLoss: 1.08195406831427
Mean Per-Class Error: 0.2699946600498706
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0    5.0    6.0    0.0    6.0    1.0    3.0    0.0    1.0    0.0    6.0    0.0    0.0    1.0    1.0    1.0    6.0    0.0    0.10126582278481013  40 / 395
0.0    309.0  0.0    5.0    2.0    0.0    6.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0    4.0    5.0    20.0   15.0   11.0   0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.19321148825065274  74 / 383
0.0    3.0    294.0  0.0    5.0    0.0    28.0   2.0    0.0    0.0    18.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    5.0    0.0    6.0    0.0    0.0    1.0    0.20108695652173914  74 / 368
7.0    14.0   0.0    304.0  0.0    0.0    0.0    7.0    0.0    9.0    0.0    1.0    6.0    2.0    2.0    9.0    0.0    17.0   11.0   0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.2456575682382134   99 / 403
0.0    14.0   3.0    0.0    288.0  1.0    18.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    9.0    4.0    9.0    8.0    0.0    0.0    0.0    7.0    0.0    18.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    3.0    0.0    19.0   4.0    10.0   0.0    0.0    0.0    0.0    0.0    1.0    0.0    336.0  0.0    0.0    0.0    0.104                39 / 375
0.0    4.0    2.0    4.0    17.0   0.0    0.0    0.0    7.0    5.0    5.0    1.0    0.0    0.0    2.0    0.0    8.0    1.0    16.0   23.0   4.0    1.0    0.0    261.0  4.0    29.0   0.33756345177664976  133 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    29.0   0.0    2.0    67.0   1.0    30.0   1.0    0.0    255.0  0.0    0.3511450381679389   138 / 393
0.0    0.0    0.0    1.0    11.0   0.0    1.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    33.0   2.0    0.0    0.0    0.0    4.0    1.0    295.0  0.19618528610354224  72 / 367
429.0  603.0  375.0  405.0  381.0  336.0  338.0  256.0  337.0  317.0  323.0  315.0  468.0  381.0  381.0  399.0  413.0  425.0  305.0  433.0  397.0  382.0  447.0  373.0  355.0  429.0  0.26881935419374187  2,689 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.731181
2    0.839248
3    0.881136
4    0.910527
5    0.929921
6    0.943517
7    0.954614
8    0.962311
9    0.969209
10   0.975307

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.37092745439380415
RMSE: 0.6090381387021704
LogLoss: 1.0985480964010839
Mean Per-Class Error: 0.27614201281561046
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16     17     18    19     20    21    22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    1.0    0.0   0.0    0.0    0.0    1.0   0.0    0.0   0.0   0.0    1.0   3.0   0.0    0.0898876404494382   8 / 89
0.0    77.0   0.0   0.0    2.0   0.0   2.0   0.0   0.0   1.0   1.0   0.0   0.0    0.0    1.0   2.0    10.0   6.0    2.0   0.0    0.0   1.0   0.0    1.0   0.0   0.0    0.27358490566037735  29 / 106
0.0    2.0    58.0  0.0    1.0   0.0   9.0   1.0   0.0   0.0   5.0   0.0   0.0    0.0    1.0   0.0    0.0    0.0    1.0   0.0    2.0   0.0   2.0    0.0   0.0   0.0    0.2926829268292683   24 / 82
3.0    0.0    0.0   88.0   0.0   0.0   0.0   3.0   0.0   2.0   0.0   0.0   2.0    1.0    1.0   2.0    0.0    5.0    3.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0    0.21428571428571427  24 / 112
0.0    4.0    0.0   0.0    67.0  1.0   6.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0    2.0    1.0    2.0   3.0    0.0   0.0   0.0    1.0   0.0   8.0    0.30927835051546393  30 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   4.0    1.0    2.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   84.0   0.0   0.0   0.0    0.08695652173913043  8 / 92
0.0    2.0    0.0   1.0    7.0   0.0   0.0   0.0   1.0   0.0   3.0   1.0   0.0    0.0    0.0   0.0    2.0    1.0    5.0   8.0    1.0   0.0   0.0    59.0  1.0   8.0    0.41                 41 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0    12.0   0.0    0.0   18.0   1.0   10.0  1.0    0.0   63.0  0.0    0.411214953271028    44 / 107
0.0    0.0    0.0   1.0    4.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0   0.0    2.0    0.0    5.0   0.0    0.0   0.0   0.0    1.0   1.0   71.0   0.1839080459770115   16 / 87
102.0  141.0  74.0  120.0  86.0  72.0  83.0  62.0  76.0  86.0  86.0  91.0  105.0  102.0  76.0  117.0  130.0  107.0  78.0  105.0  99.0  90.0  107.0  88.0  93.0  114.0  0.2751004016064257   685 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.7249
2    0.834137
3    0.879518
4    0.908032
5    0.926104
6    0.936546
7    0.951004
8    0.959438
9    0.968273
10   0.972691
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:59  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:59  6 min 57.225 sec  244073 obs/sec    1         1             10007      0.841007         2.09278             0.987431       0.495251                         0.842413           2.10509               0.987355         0.491968
    2019-08-04 09:06:59  6 min 57.536 sec  295191 obs/sec    10        10            100070     0.605167         1.08195             0.993492       0.268819                         0.609038           1.09855               0.993391         0.2751
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.100721
C13         0.907161               0.907161             0.0913698
C8          0.826454               0.826454             0.083241
C9          0.76857                0.76857              0.0774109
C11         0.727907               0.727907             0.0733152
C12         0.715481               0.715481             0.0720637
C6          0.592081               0.592081             0.0596347
C14         0.586411               0.586411             0.0590637
C5          0.567705               0.567705             0.0571796
C7          0.565295               0.565295             0.0569369
C16         0.540896               0.540896             0.0544794
C10         0.518403               0.518403             0.0522139
C4          0.495076               0.495076             0.0498643
C3          0.474886               0.474886             0.0478308
C1          0.35149                0.35149              0.0354023
C2          0.290635               0.290635             0.0292729
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_6

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0010856584138423386  0.0002825257834047079   0.0         -0.004713631059303225  1.1275310516357422  -0.10281666405522781  1.030625343322754
    3        26       Softmax                 0.0   0.0   0.0017405062918931856  0.00019260565750300884  0.0         -0.02026991556844083   0.5807895660400391  -0.4634284275587849   0.2571709156036377


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3431664635733884
RMSE: 0.5858041170676325
LogLoss: 1.101906849409854
Mean Per-Class Error: 0.31772327470536277
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    17.0   1.0    0.0    0.0    1.0    0.0    6.0    0.0    2.0    1.0    3.0    2.0    5.0    0.0    0.10886075949367088  43 / 395
1.0    282.0  0.0    7.0    1.0    0.0    0.0    12.0   5.0    0.0    10.0   0.0    2.0    0.0    11.0   3.0    8.0    24.0   11.0   0.0    0.0    1.0    0.0    0.0    5.0    0.0    0.26370757180156656  101 / 383
0.0    2.0    264.0  0.0    21.0   3.0    25.0   4.0    0.0    0.0    15.0   0.0    1.0    0.0    2.0    0.0    4.0    0.0    6.0    3.0    6.0    0.0    5.0    0.0    0.0    6.0    0.28065395095367845  103 / 367
2.0    12.0   0.0    301.0  0.0    1.0    0.0    16.0   0.0    3.0    3.0    0.0    7.0    5.0    18.0   3.0    0.0    16.0   5.0    2.0    0.0    0.0    1.0    7.0    1.0    0.0    0.2531017369727047   102 / 403
0.0    17.0   46.0   0.0    187.0  3.0    48.0   0.0    4.0    0.0    5.0    3.0    0.0    0.0    0.0    1.0    9.0    5.0    4.0    2.0    1.0    0.0    0.0    23.0   0.0    26.0   0.5130208333333334   197 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    20.0   5.0    0.0    0.0    3.0    5.0    0.0    0.0    0.0    3.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    15.0   0.0    2.0    25.0   0.0    0.0    3.0    13.0   5.0    7.0    3.0    0.0    0.0    4.0    0.0    21.0   5.0    16.0   11.0   1.0    2.0    0.0    215.0  10.0   36.0   0.4543147208121827   179 / 394
1.0    0.0    0.0    1.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    10.0   8.0    0.0    10.0   65.0   1.0    28.0   1.0    0.0    251.0  0.0    0.361323155216285    142 / 393
3.0    7.0    0.0    2.0    16.0   11.0   2.0    0.0    2.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    40.0   1.0    0.0    0.0    0.0    14.0   3.0    258.0  0.2970027247956403   109 / 367
421.0  597.0  390.0  415.0  305.0  364.0  416.0  323.0  337.0  309.0  275.0  319.0  530.0  358.0  403.0  375.0  417.0  422.0  255.0  431.0  367.0  380.0  452.0  349.0  384.0  409.0  0.31640507847645705  3,165 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.683595
2    0.811257
3    0.863341
4    0.894232
5    0.917025
6    0.93322
7    0.944317
8    0.953914
9    0.961812
10   0.96801

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.34571969239918743
RMSE: 0.5879793299081078
LogLoss: 1.0997903662637836
Mean Per-Class Error: 0.3218064874181939
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9     10    11    12     13    14    15     16     17     18    19     20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   4.0    1.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0   0.0   2.0    1.0   2.0    0.0   0.12359550561797752  11 / 89
0.0   75.0   0.0   1.0    0.0   0.0   0.0    2.0   2.0   0.0   3.0   0.0   1.0    0.0   3.0   2.0    4.0    9.0    1.0   0.0    0.0   1.0   0.0    0.0   2.0    0.0   0.29245283018867924  31 / 106
0.0   2.0    53.0  0.0    4.0   0.0   8.0    2.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0    2.0   0.0    2.0   0.0   1.0    0.0   0.0    3.0   0.35365853658536583  29 / 82
1.0   1.0    0.0   88.0   0.0   1.0   0.0    1.0   0.0   1.0   1.0   0.0   2.0    1.0   7.0   0.0    0.0    4.0    2.0   0.0    0.0   0.0   0.0    2.0   0.0    0.0   0.21428571428571427  24 / 112
0.0   7.0    12.0  0.0    47.0  1.0   13.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    1.0    1.0    0.0   0.0    0.0   0.0   0.0    5.0   0.0    7.0   0.5154639175257731   50 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   4.0    1.0   0.0   0.0    0.0    1.0    0.0   0.0    0.0   1.0   84.0   0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   5.0    0.0   0.0    8.0   0.0   0.0    1.0   4.0   1.0   3.0   0.0   0.0    0.0   1.0   0.0    2.0    3.0    5.0   2.0    0.0   0.0   0.0    49.0  5.0    11.0  0.51                 51 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   3.0    4.0    0.0    1.0   17.0   0.0   8.0   1.0    0.0   70.0   0.0   0.34579439252336447  37 / 107
1.0   0.0    0.0   1.0    3.0   3.0   0.0    0.0   1.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0    1.0    0.0    13.0  0.0    0.0   0.0   0.0    7.0   2.0    54.0  0.3793103448275862   33 / 87
99.0  151.0  81.0  121.0  73.0  89.0  103.0  82.0  75.0  85.0  73.0  86.0  135.0  87.0  88.0  107.0  104.0  100.0  75.0  100.0  93.0  89.0  112.0  85.0  105.0  92.0  0.3208835341365462   799 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.679117
2    0.804418
3    0.862651
4    0.897992
5    0.92008
6    0.936546
7    0.947791
8    0.95743
9    0.965462
10   0.970683
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:17  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:17  15.209 sec  80701 obs/sec     1         1             10007      0.685602         1.48066             0.991647       0.411377                         0.683018           1.46124               0.991687         0.408835
    2019-08-04 09:00:18  15.917 sec  123695 obs/sec    10        10            100070     0.585804         1.10191             0.993902       0.316405                         0.587979           1.09979               0.99384          0.320884
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0877063
C13         0.9314                 0.9314               0.0816897
C11         0.908866               0.908866             0.0797133
C9          0.899445               0.899445             0.078887
C12         0.860554               0.860554             0.075476
C14         0.798822               0.798822             0.0700617
C8          0.779727               0.779727             0.068387
C7          0.734502               0.734502             0.0644204
C6          0.676872               0.676872             0.0593659
C16         0.670776               0.670776             0.0588313
C5          0.592927               0.592927             0.0520035
C3          0.565143               0.565143             0.0495666
C10         0.537988               0.537988             0.047185
C4          0.512989               0.512989             0.0449924
C1          0.501323               0.501323             0.0439692
C2          0.430354               0.430354             0.0377448
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_155

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0007867283968039374  0.0002040599938482046  0.0         -0.021905267010481566  0.272613525390625   0.028403085377423965  0.16567909717559814
    3        26       Softmax                      0.0   0.0   0.004219171952872085   0.006624799221754074   0.0         -0.40925792096802      0.8955583572387695  -0.8774683665376067   0.5020947456359863


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3743089359991625
RMSE: 0.6118079241062202
LogLoss: 1.1015047644334344
Mean Per-Class Error: 0.2741889305984868
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    1.0    8.0    0.0    6.0    0.0    3.0    0.0    5.0    0.0    1.0    2.0    3.0    0.0    7.0    0.0    0.10126582278481013  40 / 395
0.0    314.0  0.0    3.0    0.0    1.0    5.0    8.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    3.0    21.0   15.0   0.0    0.0    2.0    0.0    2.0    1.0    0.0    0.1801566579634465   69 / 383
0.0    0.0    295.0  0.0    23.0   1.0    13.0   1.0    0.0    0.0    18.0   0.0    0.0    0.0    1.0    1.0    3.0    0.0    4.0    2.0    2.0    0.0    3.0    0.0    0.0    1.0    0.1983695652173913   73 / 368
5.0    19.0   0.0    314.0  0.0    0.0    0.0    0.0    0.0    13.0   0.0    1.0    6.0    5.0    3.0    0.0    0.0    19.0   6.0    0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.22084367245657568  89 / 403
0.0    11.0   7.0    0.0    226.0  3.0    55.0   1.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    0.0    12.0   2.0    6.0    2.0    2.0    0.0    0.0    21.0   0.0    26.0   0.4114583333333333   158 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    21.0   10.0   1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    332.0  0.0    0.0    0.0    0.11702127659574468  44 / 376
0.0    13.0   0.0    2.0    6.0    0.0    0.0    0.0    4.0    3.0    6.0    2.0    0.0    2.0    0.0    0.0    9.0    2.0    35.0   5.0    4.0    0.0    0.0    291.0  6.0    4.0    0.2614213197969543   103 / 394
0.0    1.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    1.0    22.0   0.0    1.0    48.0   3.0    77.0   1.0    0.0    228.0  0.0    0.4198473282442748   165 / 393
8.0    0.0    0.0    0.0    16.0   6.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    33.0   3.0    0.0    0.0    0.0    4.0    0.0    292.0  0.20435967302452315  75 / 367
426.0  566.0  405.0  420.0  322.0  360.0  312.0  273.0  339.0  328.0  367.0  305.0  446.0  406.0  395.0  383.0  360.0  408.0  340.0  423.0  380.0  407.0  448.0  452.0  283.0  449.0  0.2732180345896231   2,733 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.726782
2    0.838548
3    0.883035
4    0.910027
5    0.929821
6    0.942817
7    0.953114
8    0.961711
9    0.969309
10   0.975907

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.37540624545277973
RMSE: 0.6127040439337574
LogLoss: 1.1002175109429364
Mean Per-Class Error: 0.27109944267692687
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16     17     18    19     20    21    22     23     24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0    0.0   1.0   1.0    0.0    3.0   0.0    0.07865168539325842  7 / 89
0.0    84.0   0.0   0.0    0.0   0.0   3.0   3.0   1.0   0.0   0.0    0.0   0.0   0.0    1.0   1.0    2.0    6.0    2.0   0.0    0.0   2.0   0.0    1.0    0.0   0.0    0.20754716981132076  22 / 106
0.0    0.0    63.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    1.0   1.0    0.0    0.0    2.0   1.0    0.0   0.0   1.0    0.0    0.0   0.0    0.23170731707317074  19 / 82
3.0    3.0    0.0   91.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   2.0   2.0    0.0   0.0    0.0    5.0    1.0   0.0    0.0   0.0   0.0    2.0    0.0   1.0    0.1875               21 / 112
0.0    1.0    0.0   0.0    51.0  2.0   13.0  0.0   0.0   0.0   6.0    0.0   0.0   0.0    0.0   0.0    4.0    0.0    2.0   2.0    0.0   0.0   0.0    7.0    0.0   9.0    0.4742268041237113   46 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---    ---   ---   ---    ---    ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   5.0   2.0    0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   84.0   0.0    0.0   0.0    0.08695652173913043  8 / 92
0.0    3.0    0.0   2.0    3.0   0.0   0.0   0.0   1.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0    2.0    1.0    11.0  3.0    1.0   0.0   0.0    68.0   1.0   1.0    0.32                 32 / 100
0.0    0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    8.0    0.0    0.0   11.0   1.0   24.0  1.0    0.0    57.0  0.0    0.4672897196261682   50 / 107
1.0    0.0    0.0   0.0    4.0   1.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    5.0   2.0    0.0   0.0   0.0    1.0    0.0   71.0   0.1839080459770115   16 / 87
104.0  131.0  84.0  122.0  69.0  78.0  79.0  75.0  81.0  91.0  100.0  84.0  97.0  103.0  85.0  112.0  106.0  100.0  86.0  106.0  94.0  96.0  109.0  108.0  72.0  118.0  0.2714859437751004   676 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.728514
2    0.842972
3    0.884337
4    0.912851
5    0.934538
6    0.945381
7    0.953414
8    0.961446
9    0.967871
10   0.973092
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:23  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:23  4 min 21.702 sec  256589 obs/sec    1         1             10007      0.847738         2.18495             0.987229       0.529541                         0.847651           2.18158               0.987197         0.530924
    2019-08-04 09:04:24  4 min 22.028 sec  284289 obs/sec    10        10            100070     0.611808         1.1015              0.993348       0.273218                         0.612704           1.10022               0.993311         0.271486
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0936226
C13         0.970194               0.970194             0.0908321
C12         0.871884               0.871884             0.0816281
C8          0.77293                0.77293              0.0723637
C11         0.772361               0.772361             0.0723105
C9          0.769022               0.769022             0.0719979
C14         0.697485               0.697485             0.0653004
C7          0.666573               0.666573             0.0624063
C6          0.659768               0.659768             0.0617692
C10         0.623862               0.623862             0.0584076
C16         0.57241                0.57241              0.0535906
C5          0.555107               0.555107             0.0519705
C3          0.523873               0.523873             0.0490464
C4          0.456149               0.456149             0.0427059
C2          0.418233               0.418233             0.039156
C1          0.35133                0.35133              0.0328924
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_146

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008150166109430756  0.00024663738440722227  0.0         -0.022801408837267445  0.28701555728912354  -0.004801604864310961  0.18725544214248657
    3        26       Softmax                      0.0   0.0   0.0046354356488966285  0.007660288363695145    0.0         -0.3682740871454371    0.8868570327758789   -0.8687262093893042    0.5859730243682861


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.37318780934082185
RMSE: 0.6108909962839704
LogLoss: 1.095947150562328
Mean Per-Class Error: 0.2623801136229993
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  1.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    3.0    1.0    1.0    8.0    1.0    7.0    0.0    0.0    0.0    5.0    0.0    1.0    3.0    5.0    0.0    4.0    0.0    0.11392405063291139  45 / 395
0.0    244.0  0.0    5.0    1.0    1.0    5.0    5.0    2.0    0.0    5.0    0.0    0.0    0.0    4.0    3.0    12.0   36.0   49.0   0.0    2.0    6.0    0.0    3.0    0.0    0.0    0.3629242819843342   139 / 383
0.0    0.0    284.0  0.0    30.0   0.0    16.0   7.0    0.0    0.0    17.0   0.0    0.0    1.0    2.0    0.0    0.0    0.0    3.0    1.0    2.0    0.0    5.0    0.0    0.0    0.0    0.22826086956521738  84 / 368
10.0   13.0   0.0    327.0  0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    6.0    3.0    8.0    2.0    0.0    12.0   2.0    0.0    1.0    0.0    0.0    9.0    0.0    0.0    0.18858560794044665  76 / 403
0.0    31.0   0.0    0.0    259.0  4.0    14.0   0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    12.0   5.0    5.0    0.0    1.0    1.0    0.0    10.0   0.0    34.0   0.3255208333333333   125 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    6.0    0.0    11.0   7.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    333.0  0.0    0.0    0.0    0.10962566844919786  41 / 374
0.0    24.0   0.0    10.0   7.0    0.0    0.0    3.0    7.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    10.0   5.0    5.0    4.0    8.0    3.0    0.0    291.0  6.0    2.0    0.2614213197969543   103 / 394
0.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    2.0    7.0    0.0    7.0    23.0   7.0    60.0   1.0    1.0    275.0  0.0    0.29846938775510207  117 / 392
1.0    2.0    0.0    0.0    16.0   0.0    4.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    52.0   1.0    0.0    0.0    0.0    2.0    0.0    282.0  0.23160762942779292  85 / 367
409.0  509.0  347.0  471.0  369.0  324.0  294.0  317.0  369.0  305.0  396.0  316.0  456.0  401.0  373.0  379.0  373.0  473.0  345.0  367.0  398.0  438.0  398.0  399.0  355.0  422.0  0.2613216035189443   2,614 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.738678
2    0.846446
3    0.887634
4    0.910427
5    0.929221
6    0.942917
7    0.955213
8    0.964811
9    0.972708
10   0.978306

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3743468322744668
RMSE: 0.6118388940517485
LogLoss: 1.101054800494622
Mean Per-Class Error: 0.26415032202723376
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16     17     18    19    20     21     22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0    3.0    0.0   2.0    0.0    0.11235955056179775  10 / 89
0.0   59.0   0.0   1.0    1.0   0.0   2.0   1.0   1.0   0.0   4.0    0.0   0.0    0.0   0.0   1.0    5.0    12.0   13.0  0.0   2.0    3.0    0.0    1.0   0.0    0.0    0.44339622641509435  47 / 106
0.0   0.0    56.0  0.0    7.0   0.0   5.0   4.0   0.0   0.0   5.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0    2.0   1.0   0.0    0.0    2.0    0.0   0.0    0.0    0.3170731707317073   26 / 82
4.0   5.0    0.0   94.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   2.0    1.0   2.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0    0.16071428571428573  18 / 112
0.0   6.0    0.0   0.0    64.0  2.0   4.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    4.0    1.0    2.0   0.0   0.0    0.0    0.0    0.0   0.0    12.0   0.3402061855670103   33 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---    ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   2.0    0.0   1.0    1.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0    86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   4.0    0.0   3.0    3.0   0.0   0.0   2.0   1.0   0.0   4.0    0.0   0.0    0.0   0.0   0.0    2.0    2.0    3.0   0.0   1.0    0.0    0.0    70.0  3.0    2.0    0.3                  30 / 100
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   2.0    1.0    0.0    0.0   6.0   3.0    17.0   0.0    1.0   74.0   0.0    0.308411214953271    33 / 107
0.0   0.0    0.0   0.0    4.0   0.0   1.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0    10.0  0.0   0.0    0.0    0.0    1.0   0.0    69.0   0.20689655172413793  18 / 87
94.0  121.0  70.0  132.0  88.0  72.0  72.0  84.0  92.0  89.0  101.0  86.0  106.0  96.0  74.0  108.0  102.0  121.0  82.0  85.0  104.0  100.0  105.0  93.0  100.0  113.0  0.26385542168674697  657 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.736145
2    0.848996
3    0.886747
4    0.910843
5    0.928112
6    0.941767
7    0.953815
8    0.966265
9    0.970683
10   0.977108
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:04:03  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:04:03  4 min  0.793 sec  256589 obs/sec    1         1             10007      0.83778          2.08616             0.987523       0.505148                         0.835992           2.07219               0.987547         0.49759
    2019-08-04 09:04:03  4 min  1.102 sec  298716 obs/sec    10        10            100070     0.610891         1.09595             0.993366       0.261322                         0.611839           1.10105               0.99333          0.263855
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0990798
C15         0.974729               0.974729             0.0965759
C8          0.795243               0.795243             0.0787925
C9          0.779638               0.779638             0.0772463
C7          0.731082               0.731082             0.0724355
C12         0.717969               0.717969             0.0711362
C11         0.712976               0.712976             0.0706415
C14         0.659834               0.659834             0.0653763
C3          0.554969               0.554969             0.0549862
C10         0.543929               0.543929             0.0538924
C6          0.532744               0.532744             0.0527842
C16         0.50422                0.50422              0.049958
C4          0.460267               0.460267             0.0456032
C5          0.417755               0.417755             0.041391
C1          0.360357               0.360357             0.0357041
C2          0.347163               0.347163             0.0343969
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_234

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight          weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  -------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011784056147234878  0.00030917918775230646  0.0         0.02195168520529478  1.1849384307861328  0.2940444677985877    1.1762847900390625
    3        26       Softmax                 0.0   0.0   0.0017291228622735406  0.00014014256885275245  0.0         -0.0855509159934557  0.5734360218048096  -0.46758237039263545  0.29052066802978516


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.34584693258423793
RMSE: 0.5880875211941143
LogLoss: 1.096439245223791
Mean Per-Class Error: 0.32117925077295545
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
343.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    7.0    1.0    1.0    11.0   3.0    4.0    0.0    3.0    0.0    3.0    1.0    1.0    0.0    4.0    5.0    5.0    0.0    0.13164556962025317  52 / 395
0.0    276.0  0.0    19.0   2.0    1.0    8.0    8.0    4.0    0.0    5.0    0.0    2.0    0.0    0.0    11.0   7.0    19.0   12.0   0.0    1.0    1.0    0.0    0.0    4.0    3.0    0.2793733681462141   107 / 383
0.0    0.0    263.0  0.0    26.0   6.0    28.0   3.0    0.0    0.0    18.0   1.0    5.0    0.0    0.0    1.0    1.0    1.0    4.0    1.0    4.0    0.0    4.0    0.0    1.0    1.0    0.28532608695652173  105 / 368
7.0    21.0   0.0    281.0  0.0    1.0    0.0    26.0   0.0    10.0   1.0    0.0    7.0    10.0   3.0    7.0    1.0    17.0   1.0    3.0    0.0    0.0    0.0    6.0    0.0    0.0    0.3009950248756219   121 / 402
0.0    12.0   19.0   0.0    209.0  4.0    21.0   2.0    2.0    0.0    12.0   3.0    0.0    0.0    0.0    1.0    11.0   8.0    14.0   13.0   0.0    0.0    0.0    14.0   1.0    38.0   0.4557291666666667   175 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    32.0   16.0   6.0    0.0    0.0    0.0    0.0    0.0    1.0    28.0   285.0  0.0    0.0    0.0    0.24202127659574468  91 / 376
5.0    23.0   4.0    5.0    19.0   0.0    3.0    5.0    9.0    2.0    13.0   4.0    0.0    0.0    6.0    0.0    8.0    7.0    10.0   14.0   7.0    1.0    0.0    238.0  8.0    3.0    0.39593908629441626  156 / 394
0.0    2.0    0.0    0.0    0.0    21.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    1.0    5.0    0.0    0.0    79.0   6.0    38.0   0.0    1.0    232.0  2.0    0.40966921119592875  161 / 393
1.0    8.0    0.0    1.0    12.0   1.0    3.0    0.0    2.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    36.0   6.0    1.0    0.0    0.0    2.0    4.0    281.0  0.23433242506811988  86 / 367
411.0  579.0  363.0  396.0  355.0  345.0  371.0  311.0  328.0  360.0  321.0  321.0  527.0  398.0  369.0  439.0  360.0  439.0  245.0  451.0  399.0  425.0  401.0  333.0  324.0  432.0  0.3200039988003599   3,201 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.679996
2    0.812156
3    0.863441
4    0.894332
5    0.913526
6    0.93282
7    0.946016
8    0.956613
9    0.963611
10   0.970509

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.35033109330843903
RMSE: 0.591887737082328
LogLoss: 1.10410276309141
Mean Per-Class Error: 0.3298277271385454
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16    17     18    19     20    21     22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  -----  -------------------  -----------
77.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   3.0    1.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    1.0    3.0   2.0    0.0    0.1348314606741573   12 / 89
0.0   68.0   0.0   4.0    0.0   0.0   3.0   3.0   1.0   0.0    3.0   0.0   1.0    0.0    0.0   4.0    2.0   6.0    5.0   0.0    1.0   1.0    0.0    0.0   2.0    2.0    0.3584905660377358   38 / 106
0.0   0.0    54.0  0.0    5.0   1.0   10.0  1.0   0.0   0.0    3.0   0.0   2.0    0.0    0.0   0.0    1.0   0.0    2.0   1.0    0.0   0.0    1.0    0.0   1.0    0.0    0.34146341463414637  28 / 82
5.0   2.0    0.0   80.0   0.0   0.0   0.0   8.0   0.0   2.0    0.0   0.0   3.0    2.0    1.0   1.0    0.0   6.0    1.0   0.0    0.0   0.0    0.0    1.0   0.0    0.0    0.2857142857142857   32 / 112
0.0   5.0    5.0   0.0    49.0  3.0   3.0   1.0   1.0   0.0    5.0   0.0   0.0    0.0    0.0   0.0    3.0   1.0    5.0   5.0    0.0   0.0    0.0    3.0   0.0    8.0    0.4948453608247423   48 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   5.0    5.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   7.0    73.0   0.0   0.0    0.0    0.20652173913043478  19 / 92
0.0   7.0    0.0   2.0    4.0   0.0   1.0   3.0   3.0   0.0    7.0   1.0   0.0    0.0    0.0   0.0    2.0   1.0    1.0   4.0    2.0   0.0    0.0    55.0  6.0    1.0    0.45                 45 / 100
0.0   1.0    0.0   0.0    0.0   4.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    1.0    1.0   1.0    1.0   0.0    0.0   21.0   2.0   11.0   0.0    0.0   64.0   0.0    0.40186915887850466  43 / 107
1.0   2.0    0.0   0.0    4.0   0.0   2.0   0.0   0.0   1.0    0.0   1.0   0.0    0.0    0.0   0.0    0.0   0.0    6.0   2.0    0.0   0.0    0.0    1.0   2.0    65.0   0.25287356321839083  22 / 87
92.0  139.0  79.0  117.0  74.0  77.0  97.0  86.0  73.0  107.0  86.0  88.0  124.0  102.0  75.0  118.0  91.0  101.0  76.0  109.0  95.0  102.0  102.0  79.0  101.0  100.0  0.329718875502008    821 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.670281
2    0.81245
3    0.862249
4    0.897189
5    0.917671
6    0.936145
7    0.950201
8    0.959036
9    0.96747
10   0.973092
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:54  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:54  6 min 52.458 sec  116360 obs/sec    1         1             10007      0.720287         1.61171             0.990781       0.464761                         0.720548           1.59977               0.990749         0.475904
    2019-08-04 09:06:55  6 min 53.129 sec  135596 obs/sec    10        10            100070     0.588088         1.09644             0.993854       0.320004                         0.591888           1.1041                0.993758         0.329719
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0941007
C13         0.904523               0.904523             0.0851163
C12         0.812502               0.812502             0.076457
C7          0.808444               0.808444             0.0760751
C11         0.769144               0.769144             0.0723769
C9          0.704202               0.704202             0.0662658
C14         0.678835               0.678835             0.0638788
C8          0.661987               0.661987             0.0622934
C6          0.604152               0.604152             0.0568511
C5          0.596679               0.596679             0.0561479
C10         0.587846               0.587846             0.0553166
C16         0.572821               0.572821             0.0539028
C3          0.547809               0.547809             0.0515492
C4          0.534592               0.534592             0.0503055
C1          0.445384               0.445384             0.0419109
C2          0.397998               0.397998             0.0374519
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_14

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008149078790893327  0.0002149464562535286  0.0         -0.029275245678491046  0.28557920455932617  0.0288766538078332   0.2136760950088501
    3        26       Softmax                      0.0   0.0   0.004562143627131613   0.007012644782662392   0.0         -0.34341519926210123   0.889392614364624    -0.7711850168425591  0.6257991790771484


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3719999198926759
RMSE: 0.6099179616085068
LogLoss: 1.0942192842864369
Mean Per-Class Error: 0.27036732545343617
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  1.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    5.0    2.0    0.0    7.0    0.0    6.0    0.0    5.0    1.0    2.0    0.0    2.0    3.0    4.0    0.0    4.0    0.0    0.11392405063291139  45 / 395
0.0    322.0  0.0    8.0    1.0    0.0    7.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    2.0    2.0    0.0    24.0   7.0    0.0    0.0    2.0    0.0    1.0    2.0    0.0    0.15926892950391644  61 / 383
0.0    0.0    287.0  0.0    16.0   4.0    17.0   0.0    0.0    0.0    18.0   0.0    4.0    0.0    3.0    0.0    3.0    0.0    7.0    0.0    5.0    0.0    4.0    0.0    0.0    0.0    0.22010869565217392  81 / 368
2.0    32.0   0.0    300.0  1.0    0.0    1.0    12.0   3.0    4.0    0.0    1.0    3.0    7.0    3.0    2.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    19.0   0.0    0.0    0.2555831265508685   103 / 403
0.0    4.0    3.0    0.0    275.0  7.0    10.0   0.0    0.0    1.0    8.0    1.0    0.0    0.0    1.0    0.0    11.0   5.0    16.0   6.0    0.0    0.0    0.0    8.0    0.0    28.0   0.2838541666666667   109 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    38.0   6.0    1.0    0.0    0.0    6.0    0.0    0.0    1.0    2.0    320.0  0.0    0.0    0.0    0.14893617021276595  56 / 376
0.0    8.0    0.0    1.0    16.0   0.0    0.0    0.0    1.0    1.0    7.0    0.0    0.0    0.0    2.0    0.0    39.0   3.0    14.0   7.0    8.0    0.0    0.0    260.0  3.0    24.0   0.3401015228426396   134 / 394
0.0    3.0    0.0    0.0    0.0    9.0    3.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    19.0   0.0    3.0    44.0   0.0    60.0   0.0    0.0    247.0  0.0    0.37150127226463103  146 / 393
0.0    9.0    0.0    0.0    19.0   1.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    9.0    0.0    35.0   3.0    0.0    0.0    0.0    3.0    0.0    282.0  0.23160762942779292  85 / 367
405.0  605.0  347.0  400.0  384.0  325.0  334.0  237.0  352.0  300.0  381.0  315.0  493.0  349.0  386.0  391.0  430.0  417.0  303.0  401.0  404.0  430.0  462.0  368.0  319.0  465.0  0.2692192342297311   2,693 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730781
2    0.841148
3    0.885034
4    0.911427
5    0.930421
6    0.946616
7    0.957613
8    0.96571
9    0.972608
10   0.977307

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3753184427251384
RMSE: 0.6126323879172064
LogLoss: 1.1072491894874914
Mean Per-Class Error: 0.2732254728114315
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19    20     21     22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  -----  -----  ----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   1.0   0.0    1.0    0.0    0.0   0.0   0.0    2.0    2.0    0.0   1.0   0.0    0.10112359550561797  9 / 89
0.0   81.0   0.0   3.0    1.0   0.0   3.0   1.0   1.0   0.0   1.0   0.0   0.0    0.0   1.0   1.0    0.0    9.0    1.0   0.0   0.0    2.0    0.0    1.0   0.0   0.0    0.2358490566037736   25 / 106
0.0   0.0    59.0  0.0    2.0   1.0   4.0   0.0   0.0   0.0   5.0   0.0   0.0    0.0   2.0   0.0    2.0    0.0    4.0   0.0   1.0    0.0    2.0    0.0   0.0   0.0    0.2804878048780488   23 / 82
2.0   6.0    0.0   88.0   0.0   0.0   1.0   4.0   1.0   1.0   0.0   1.0   1.0    3.0   0.0   0.0    0.0    3.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.21428571428571427  24 / 112
0.0   0.0    0.0   0.0    66.0  4.0   4.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    3.0    1.0    5.0   3.0   0.0    0.0    0.0    1.0   0.0   7.0    0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---    ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   7.0    1.0   1.0   0.0    0.0    1.0    0.0   0.0   0.0    1.0    81.0   0.0   0.0   0.0    0.11956521739130435  11 / 92
0.0   3.0    0.0   1.0    7.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    7.0    1.0    5.0   1.0   3.0    0.0    0.0    65.0  1.0   4.0    0.35                 35 / 100
0.0   2.0    0.0   0.0    0.0   2.0   2.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0   0.0    4.0    0.0    0.0   9.0   0.0    12.0   0.0    0.0   73.0  0.0    0.3177570093457944   34 / 107
0.0   2.0    0.0   0.0    7.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    2.0    0.0    7.0   1.0   0.0    0.0    0.0    0.0   0.0   67.0   0.22988505747126436  20 / 87
93.0  142.0  74.0  120.0  95.0  67.0  80.0  61.0  84.0  83.0  96.0  90.0  105.0  93.0  78.0  119.0  112.0  108.0  83.0  99.0  103.0  104.0  115.0  87.0  90.0  109.0  0.27228915662650605  678 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.727711
2    0.833333
3    0.879518
4    0.909237
5    0.926506
6    0.943373
7    0.95502
8    0.963855
9    0.971084
10   0.9751
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:32  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:32  29.947 sec  217543 obs/sec    1         1             10007      0.837674         2.07726             0.987533       0.511247                         0.838582           2.07754               0.98747          0.513655
    2019-08-04 09:00:32  30.283 sec  271192 obs/sec    10        10            100070     0.609918         1.09422             0.993391       0.269219                         0.612632           1.10725               0.993312         0.272289
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.099736
C15         0.994039               0.994039             0.0991415
C12         0.90637                0.90637              0.0903977
C9          0.79113                0.79113              0.0789041
C8          0.720954               0.720954             0.0719051
C7          0.718639               0.718639             0.0716742
C11         0.718338               0.718338             0.0716441
C14         0.635775               0.635775             0.0634097
C10         0.591222               0.591222             0.0589661
C6          0.529798               0.529798             0.0528399
C4          0.474975               0.474975             0.0473721
C16         0.461349               0.461349             0.0460131
C3          0.440659               0.440659             0.0439496
C5          0.4385                 0.4385               0.0437343
C1          0.306065               0.306065             0.0305256
C2          0.298659               0.298659             0.029787
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_23

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.000824342882253859   0.00021841702982783318  0.0         -0.015575540284544331  0.28707313537597656  0.02524720715348089  0.1843288540840149
    3        26       Softmax                      0.0   0.0   0.0042583348052945575  0.0066955797374248505   0.0         -0.3071537211110878    0.8649280071258545   -0.8408290931908388  0.5735459327697754


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3812587867307928
RMSE: 0.6174615670070428
LogLoss: 1.115487255288691
Mean Per-Class Error: 0.27135329141242265
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    2.0    0.0    8.0    0.0    1.0    0.0    2.0    0.0    11.0   0.0    1.0    1.0    5.0    0.0    5.0    0.0    0.10379746835443038  41 / 395
0.0    285.0  0.0    8.0    1.0    0.0    2.0    0.0    3.0    1.0    4.0    0.0    3.0    0.0    3.0    4.0    1.0    33.0   14.0   0.0    0.0    0.0    1.0    20.0   0.0    0.0    0.2558746736292428   98 / 383
0.0    0.0    302.0  0.0    10.0   1.0    12.0   0.0    0.0    0.0    32.0   0.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    3.0    1.0    0.0    2.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
3.0    14.0   0.0    308.0  0.0    0.0    1.0    0.0    1.0    10.0   0.0    1.0    3.0    5.0    3.0    1.0    2.0    11.0   4.0    0.0    0.0    0.0    0.0    36.0   0.0    0.0    0.23573200992555832  95 / 403
0.0    8.0    4.0    1.0    285.0  0.0    15.0   0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    12.0   9.0    2.0    1.0    2.0    0.0    0.0    17.0   3.0    22.0   0.2578125            99 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    21.0   6.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    336.0  0.0    0.0    0.0    0.104                39 / 375
0.0    4.0    0.0    12.0   13.0   0.0    0.0    1.0    5.0    2.0    3.0    4.0    0.0    0.0    0.0    0.0    8.0    5.0    5.0    2.0    13.0   0.0    0.0    300.0  15.0   2.0    0.23857868020304568  94 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    16.0   0.0    8.0    45.0   0.0    35.0   1.0    2.0    275.0  0.0    0.30025445292620867  118 / 393
6.0    0.0    0.0    0.0    15.0   0.0    2.0    0.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    32.0   3.0    0.0    0.0    0.0    7.0    0.0    295.0  0.19618528610354224  72 / 367
401.0  493.0  399.0  444.0  385.0  293.0  251.0  177.0  361.0  334.0  415.0  326.0  486.0  373.0  353.0  396.0  401.0  469.0  269.0  395.0  397.0  336.0  475.0  546.0  400.0  428.0  0.27021893431970406  2,703 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.729781
2    0.840448
3    0.883935
4    0.911127
5    0.930421
6    0.944017
7    0.954614
8    0.962811
9    0.971309
10   0.975907

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3836392734055809
RMSE: 0.6193862069868693
LogLoss: 1.1203295602406074
Mean Per-Class Error: 0.27602999989549426
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16     17     18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.0   2.0    0.0    3.0    0.0    0.0898876404494382   8 / 89
0.0   74.0   0.0   3.0    1.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   2.0   0.0    0.0    12.0   5.0   0.0   0.0   0.0   1.0    7.0    0.0    0.0    0.3018867924528302   32 / 106
0.0   0.0    63.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0   9.0    0.0   0.0    0.0   2.0   0.0    0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0    0.0    0.0    0.23170731707317074  19 / 82
2.0   1.0    0.0   93.0   0.0   0.0   1.0   0.0   1.0   1.0   0.0    0.0   1.0    2.0   0.0   0.0    1.0    2.0    2.0   0.0   0.0   0.0   0.0    5.0    0.0    0.0    0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    69.0  0.0   4.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    4.0    3.0    0.0   1.0   0.0   0.0   0.0    2.0    0.0    11.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0    1.0   0.0   0.0    0.0    2.0    0.0   0.0   0.0   0.0   85.0   0.0    0.0    0.0    0.07608695652173914  7 / 92
0.0   3.0    0.0   4.0    5.0   0.0   0.0   1.0   0.0   0.0   1.0    1.0   0.0    0.0   0.0   0.0    1.0    2.0    0.0   0.0   3.0   0.0   0.0    73.0   5.0    1.0    0.27                 27 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0   1.0    6.0    0.0    2.0   9.0   0.0   11.0  1.0    1.0    74.0   0.0    0.308411214953271    33 / 107
2.0   0.0    0.0   0.0    4.0   0.0   1.0   0.0   0.0   1.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0    0.0    6.0   1.0   0.0   0.0   0.0    2.0    0.0    69.0   0.20689655172413793  18 / 87
95.0  114.0  84.0  130.0  95.0  60.0  59.0  46.0  86.0  95.0  105.0  90.0  106.0  97.0  75.0  112.0  109.0  124.0  68.0  97.0  95.0  76.0  117.0  132.0  108.0  115.0  0.27389558232931727  682 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.726104
2    0.835341
3    0.885944
4    0.918876
5    0.935341
6    0.946586
7    0.955422
8    0.961044
9    0.970683
10   0.973896
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:46  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:46  43.818 sec  238261 obs/sec    1         1             10007      0.84369          2.13302             0.987351       0.539738                         0.842547           2.12887               0.987351         0.532129
    2019-08-04 09:00:46  44.120 sec  303242 obs/sec    10        10            100070     0.617462         1.11549             0.993225       0.270219                         0.619386           1.12033               0.993164         0.273896
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.101218
C15         0.833395               0.833395             0.0843545
C8          0.782084               0.782084             0.0791609
C9          0.747115               0.747115             0.0756214
C7          0.728147               0.728147             0.0737015
C12         0.711051               0.711051             0.0719711
C11         0.67406                0.67406              0.0682269
C14         0.626259               0.626259             0.0633887
C10         0.569556               0.569556             0.0576492
C6          0.568931               0.568931             0.057586
C4          0.537894               0.537894             0.0544445
C5          0.49798                0.49798              0.0504045
C16         0.459022               0.459022             0.0464613
C3          0.440897               0.440897             0.0446267
C1          0.374648               0.374648             0.0379211
C2          0.328634               0.328634             0.0332636
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_141

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0007977047959570882  0.0002451472682878375  0.0         -0.02025190907190222  0.27183473110198975  -0.05566632987252205  0.19533497095108032
    3        26       Softmax                      0.0   0.0   0.004839239650419376   0.008615951985120773   0.0         -0.4126532466594094   0.8835225105285645   -0.8950669099421323   0.6054103374481201


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.38556030711912875
RMSE: 0.6209350264875777
LogLoss: 1.1285994696982748
Mean Per-Class Error: 0.27034179350935506
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
345.0  0.0    0.0    1.0    0.0    0.0    2.0    3.0    0.0    9.0    4.0    0.0    5.0    0.0    8.0    0.0    0.0    1.0    5.0    0.0    0.0    2.0    5.0    0.0    5.0    0.0    0.12658227848101267  50 / 395
0.0    312.0  0.0    9.0    2.0    0.0    9.0    9.0    1.0    1.0    6.0    0.0    0.0    0.0    1.0    1.0    0.0    19.0   2.0    0.0    0.0    3.0    0.0    6.0    2.0    0.0    0.185378590078329    71 / 383
0.0    1.0    290.0  0.0    3.0    1.0    29.0   2.0    0.0    0.0    22.0   0.0    0.0    1.0    1.0    0.0    0.0    0.0    8.0    1.0    3.0    0.0    2.0    0.0    0.0    4.0    0.21195652173913043  78 / 368
7.0    28.0   0.0    300.0  0.0    1.0    2.0    5.0    0.0    3.0    4.0    1.0    5.0    4.0    1.0    5.0    0.0    17.0   3.0    0.0    1.0    0.0    0.0    16.0   0.0    0.0    0.2555831265508685   103 / 403
0.0    16.0   55.0   0.0    206.0  1.0    31.0   1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    8.0    3.0    9.0    1.0    4.0    0.0    0.0    14.0   0.0    30.0   0.4635416666666667   178 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    5.0    0.0    14.0   1.0    7.0    0.0    0.0    2.0    0.0    0.0    4.0    1.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    11.0   0.0    3.0    17.0   0.0    37.0   2.0    4.0    1.0    10.0   4.0    0.0    0.0    0.0    0.0    17.0   4.0    1.0    0.0    4.0    0.0    0.0    271.0  4.0    4.0    0.31218274111675126  123 / 394
0.0    3.0    0.0    1.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    14.0   2.0    17.0   0.0    7.0    47.0   0.0    37.0   3.0    0.0    251.0  0.0    0.361323155216285    142 / 393
0.0    20.0   0.0    1.0    10.0   0.0    1.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    1.0    0.0    6.0    1.0    7.0    2.0    0.0    0.0    0.0    7.0    0.0    293.0  0.2016348773841962   74 / 367
429.0  640.0  414.0  432.0  303.0  330.0  455.0  301.0  343.0  340.0  468.0  303.0  428.0  337.0  357.0  425.0  359.0  372.0  173.0  390.0  398.0  388.0  466.0  383.0  313.0  456.0  0.2693192042387284   2,694 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730681
2    0.835249
3    0.880436
4    0.908028
5    0.926222
6    0.941218
7    0.951315
8    0.958912
9    0.964911
10   0.971109

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3881111813704913
RMSE: 0.6229856991701265
LogLoss: 1.1320542602323138
Mean Per-Class Error: 0.2759273807039193
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6      7     8     9     10     11    12    13    14    15     16     17    18    19    20    21    22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   1.0    0.0   1.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   1.0   2.0    0.0   2.0   0.0    0.10112359550561797  9 / 89
0.0    79.0   0.0   4.0    1.0   0.0   4.0    4.0   0.0   1.0   3.0    0.0   0.0   0.0   1.0   0.0    0.0    4.0   1.0   0.0   0.0   2.0   0.0    2.0   0.0   0.0    0.25471698113207547  27 / 106
0.0    0.0    59.0  0.0    0.0   0.0   9.0    1.0   0.0   0.0   7.0    0.0   0.0   1.0   0.0   0.0    0.0    0.0   3.0   1.0   0.0   0.0   0.0    0.0   0.0   1.0    0.2804878048780488   23 / 82
3.0    6.0    0.0   89.0   0.0   0.0   1.0    3.0   0.0   1.0   1.0    0.0   2.0   1.0   0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0    0.20535714285714285  23 / 112
0.0    5.0    15.0  0.0    45.0  1.0   8.0    0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    4.0    0.0   2.0   0.0   0.0   0.0   0.0    4.0   0.0   12.0   0.5360824742268041   52 / 97
---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0   1.0    0.0   2.0   0.0   1.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0   85.0   0.0   0.0   0.0    0.07608695652173914  7 / 92
0.0    3.0    0.0   1.0    7.0   0.0   6.0    1.0   0.0   0.0   4.0    1.0   0.0   0.0   0.0   0.0    4.0    2.0   0.0   0.0   1.0   0.0   0.0    68.0  0.0   2.0    0.32                 32 / 100
0.0    1.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   7.0   1.0    5.0    0.0   0.0   10.0  0.0   8.0   2.0    0.0   71.0  0.0    0.3364485981308411   36 / 107
0.0    1.0    0.0   1.0    2.0   0.0   0.0    0.0   0.0   6.0   0.0    0.0   0.0   0.0   1.0   0.0    1.0    0.0   1.0   1.0   0.0   0.0   0.0    3.0   0.0   70.0   0.19540229885057472  17 / 87
102.0  159.0  89.0  132.0  66.0  68.0  109.0  86.0  80.0  97.0  116.0  85.0  95.0  87.0  66.0  126.0  102.0  86.0  38.0  87.0  97.0  91.0  119.0  97.0  90.0  120.0  0.2746987951807229   684 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.725301
2    0.83253
3    0.881526
4    0.907631
5    0.926506
6    0.940964
7    0.951807
8    0.958634
9    0.964659
10   0.970683
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:52  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:52  3 min 50.469 sec  244073 obs/sec    1         1             10007      0.855714         2.18954             0.986991       0.520844                         0.857972           2.20208               0.986883         0.5249
    2019-08-04 09:03:53  3 min 50.777 sec  297827 obs/sec    10        10            100070     0.620935         1.1286              0.99315        0.269319                         0.622986           1.13205               0.993084         0.274699
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0997627
C13         0.977833               0.977833             0.0975513
C12         0.833719               0.833719             0.083174
C11         0.782196               0.782196             0.0780339
C9          0.765283               0.765283             0.0763466
C8          0.713958               0.713958             0.0712263
C7          0.688944               0.688944             0.0687309
C10         0.627                  0.627                0.0625512
C14         0.620732               0.620732             0.0619259
C6          0.543357               0.543357             0.0542067
C3          0.463787               0.463787             0.0462687
C5          0.453985               0.453985             0.0452908
C4          0.435996               0.435996             0.0434961
C16         0.404106               0.404106             0.0403147
C1          0.368495               0.368495             0.036762
C2          0.3444                 0.3444               0.0343583
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_119

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0007770834599796217  0.00022454565623775125  0.0         -0.025836257486389513  0.2738140821456909  -0.01067719360067398  0.1683337688446045
    3        26       Softmax                      0.0   0.0   0.004524833128785898   0.006617331877350807    0.0         -0.3430571104758061    0.878563642501831   -0.8685227663091323   0.4087028503417969


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3863914955392411
RMSE: 0.6216039700156694
LogLoss: 1.137494045445916
Mean Per-Class Error: 0.2771291546153322
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    6.0    2.0    0.0    8.0    0.0    1.0    0.0    1.0    0.0    6.0    1.0    0.0    0.0    5.0    3.0    5.0    2.0    0.10886075949367088  43 / 395
0.0    289.0  0.0    2.0    2.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    14.0   3.0    3.0    17.0   41.0   0.0    0.0    2.0    1.0    3.0    1.0    0.0    0.24345549738219896  93 / 382
0.0    0.0    288.0  0.0    23.0   7.0    5.0    1.0    0.0    0.0    22.0   0.0    1.0    0.0    0.0    0.0    5.0    0.0    7.0    0.0    4.0    0.0    5.0    0.0    0.0    0.0    0.21739130434782608  80 / 368
5.0    41.0   0.0    308.0  0.0    1.0    0.0    2.0    1.0    4.0    0.0    0.0    4.0    3.0    2.0    0.0    0.0    13.0   2.0    0.0    1.0    0.0    0.0    14.0   1.0    0.0    0.23383084577114427  94 / 402
0.0    17.0   0.0    0.0    269.0  7.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    14.0   5.0    15.0   1.0    0.0    3.0    0.0    7.0    0.0    36.0   0.2994791666666667   115 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    12.0   3.0    15.0   0.0    1.0    2.0    0.0    0.0    1.0    2.0    334.0  0.0    0.0    0.0    0.10933333333333334  41 / 375
0.0    14.0   0.0    0.0    14.0   0.0    0.0    1.0    12.0   0.0    8.0    0.0    0.0    0.0    0.0    1.0    14.0   3.0    11.0   4.0    6.0    0.0    0.0    292.0  7.0    7.0    0.25888324873096447  102 / 394
0.0    1.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    7.0    1.0    18.0   0.0    13.0   31.0   1.0    57.0   0.0    0.0    253.0  0.0    0.356234096692112    140 / 393
4.0    5.0    0.0    0.0    10.0   0.0    1.0    0.0    3.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    44.0   3.0    0.0    0.0    0.0    6.0    0.0    282.0  0.23160762942779292  85 / 367
415.0  609.0  382.0  431.0  399.0  341.0  270.0  245.0  373.0  312.0  403.0  307.0  437.0  349.0  369.0  363.0  399.0  420.0  368.0  344.0  386.0  414.0  486.0  395.0  351.0  435.0  0.2761171648505448   2,762 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.723883
2    0.83315
3    0.876137
4    0.903329
5    0.924523
6    0.938019
7    0.949315
8    0.959012
9    0.96511
10   0.970509

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.38733335735316105
RMSE: 0.6223611149109182
LogLoss: 1.1412737138840272
Mean Per-Class Error: 0.28613407624466175
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16     17     18     19    20     21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  ----  -----  -----  -----  ----  ----  -----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0    0.0    1.0    0.0   0.0    0.0    2.0    1.0   2.0   0.0    0.10112359550561797  9 / 89
0.0    69.0   0.0   0.0    2.0   0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   8.0   1.0    1.0    7.0    13.0   0.0   0.0    1.0    1.0    1.0   0.0   0.0    0.3490566037735849   37 / 106
0.0    0.0    58.0  0.0    5.0   1.0   2.0   1.0   0.0   0.0   5.0    0.0   0.0   0.0   0.0   0.0    3.0    0.0    5.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0    0.2926829268292683   24 / 82
4.0    7.0    0.0   90.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   2.0   1.0   1.0   0.0    0.0    3.0    1.0    0.0   0.0    0.0    0.0    2.0   0.0   0.0    0.19642857142857142  22 / 112
0.0    3.0    0.0   0.0    63.0  2.0   2.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0    3.0    1.0    5.0    0.0   0.0    1.0    0.0    1.0   0.0   14.0   0.35051546391752575  34 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---   ---    ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0   2.0   0.0    1.0    0.0    0.0    0.0   0.0    0.0    87.0   0.0   0.0   0.0    0.05434782608695652  5 / 92
0.0    7.0    0.0   0.0    5.0   0.0   0.0   1.0   3.0   0.0   2.0    0.0   0.0   0.0   0.0   1.0    3.0    0.0    3.0    2.0   1.0    0.0    0.0    68.0  1.0   3.0    0.32                 32 / 100
0.0    1.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0   4.0   0.0    6.0    0.0    3.0    5.0   0.0    19.0   0.0    0.0   66.0  0.0    0.38317757009345793  41 / 107
0.0    3.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0    8.0    2.0   0.0    0.0    0.0    2.0   0.0   64.0   0.26436781609195403  23 / 87
102.0  153.0  80.0  126.0  94.0  75.0  69.0  54.0  95.0  87.0  100.0  84.0  97.0  88.0  78.0  102.0  107.0  107.0  101.0  81.0  100.0  101.0  122.0  88.0  90.0  109.0  0.28433734939759037  708 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.715663
2    0.827309
3    0.875502
4    0.904819
5    0.921285
6    0.936948
7    0.94739
8    0.960241
9    0.965863
10   0.96988
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:19  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:19  3 min 17.554 sec  256589 obs/sec    1         1             10007      0.836809         2.11206             0.987552       0.539938                         0.838255           2.12514               0.987479         0.538153
    2019-08-04 09:03:20  3 min 17.929 sec  252702 obs/sec    10        10            100070     0.621604         1.13749             0.993131       0.276117                         0.622361           1.14127               0.993098         0.284337
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0990437
C13         0.997124               0.997124             0.0987589
C12         0.814511               0.814511             0.0806722
C14         0.744343               0.744343             0.0737225
C8          0.730861               0.730861             0.0723872
C9          0.684978               0.684978             0.0678428
C6          0.676612               0.676612             0.0670142
C11         0.673411               0.673411             0.0666972
C7          0.663746               0.663746             0.0657398
C5          0.577985               0.577985             0.0572458
C4          0.530276               0.530276             0.0525205
C3          0.448129               0.448129             0.0443843
C10         0.424506               0.424506             0.0420447
C1          0.399451               0.399451             0.0395631
C16         0.384689               0.384689             0.0381011
C2          0.345927               0.345927             0.0342619
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_92

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011571970850354774  0.0003250124864280224   0.0         -0.09534958611675393  2.059971809387207   -0.36085947377165917  1.284592628479004
    3        26       Softmax                 0.0   0.0   0.001693127704129438   0.00011553644435480237  0.0         0.061070805512031257  0.5070455074310303  -0.6023059353925397   0.3698533773422241


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.45798384205335985
RMSE: 0.6767450347459963
LogLoss: 1.3785259076989962
Mean Per-Class Error: 0.37979025161456875
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  2.0    0.0    6.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    1.0    8.0    0.0    4.0    0.0    0.0    5.0    4.0    0.0    2.0    0.0    7.0    0.0    3.0    0.0    0.11392405063291139  45 / 395
0.0    252.0  0.0    14.0   0.0    0.0    1.0    13.0   1.0    14.0   2.0    0.0    7.0    0.0    3.0    7.0    7.0    39.0   16.0   0.0    0.0    3.0    0.0    0.0    3.0    1.0    0.34203655352480417  131 / 383
0.0    2.0    252.0  2.0    30.0   11.0   20.0   4.0    0.0    0.0    16.0   1.0    6.0    2.0    2.0    0.0    6.0    1.0    4.0    2.0    3.0    1.0    1.0    0.0    0.0    2.0    0.31521739130434784  116 / 368
12.0   19.0   0.0    263.0  2.0    2.0    0.0    5.0    0.0    33.0   0.0    2.0    13.0   0.0    6.0    12.0   0.0    23.0   8.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.34577114427860695  139 / 402
0.0    18.0   7.0    0.0    203.0  3.0    28.0   1.0    6.0    1.0    5.0    1.0    1.0    0.0    0.0    1.0    21.0   6.0    10.0   10.0   1.0    0.0    0.0    8.0    7.0    46.0   0.4713541666666667   181 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    1.0    0.0    38.0   21.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    23.0   278.0  0.0    0.0    0.0    0.26063829787234044  98 / 376
38.0   15.0   0.0    4.0    21.0   2.0    2.0    0.0    29.0   3.0    5.0    15.0   0.0    0.0    3.0    0.0    13.0   9.0    33.0   15.0   7.0    1.0    2.0    127.0  20.0   30.0   0.6776649746192893   267 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    3.0    0.0    11.0   110.0  4.0    78.0   8.0    0.0    164.0  0.0    0.5816326530612245   228 / 392
4.0    13.0   0.0    2.0    18.0   1.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    3.0    50.0   7.0    0.0    0.0    0.0    6.0    1.0    256.0  0.3024523160762943   111 / 367
497.0  552.0  354.0  437.0  331.0  305.0  324.0  222.0  348.0  389.0  252.0  354.0  584.0  379.0  337.0  432.0  389.0  445.0  323.0  452.0  412.0  522.0  427.0  210.0  306.0  420.0  0.3783864840547836   3,785 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.621614
2    0.76827
3    0.83455
4    0.870639
5    0.895731
6    0.915925
7    0.931121
8    0.941418
9    0.952314
10   0.961012

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4597232736181603
RMSE: 0.6780289622266591
LogLoss: 1.3843385629447775
Mean Per-Class Error: 0.388792069621017
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19     20     21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  -----  -----  -----  -----  ----  ----  -----  -------------------  -----------
79.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    1.0   0.0    0.0    1.0    2.0   0.0    0.0    0.0    3.0    0.0   2.0   0.0    0.11235955056179775  10 / 89
0.0    66.0   0.0   4.0    0.0   0.0   0.0   4.0   0.0   4.0    1.0   0.0   3.0    0.0    2.0   1.0    3.0    12.0   3.0   0.0    0.0    1.0    0.0    0.0   2.0   0.0    0.37735849056603776  40 / 106
0.0    0.0    56.0  2.0    2.0   3.0   6.0   0.0   0.0   0.0    4.0   0.0   0.0    1.0    1.0   0.0    4.0    1.0    2.0   0.0    0.0    0.0    0.0    0.0   0.0   0.0    0.3170731707317073   26 / 82
6.0    5.0    0.0   72.0   0.0   0.0   0.0   4.0   0.0   7.0    0.0   1.0   6.0    0.0    1.0   3.0    0.0    3.0    2.0   0.0    0.0    0.0    0.0    2.0   0.0   0.0    0.35714285714285715  40 / 112
0.0    8.0    3.0   0.0    46.0  2.0   8.0   0.0   2.0   0.0    1.0   0.0   0.0    0.0    0.0   0.0    7.0    1.0    3.0   2.0    0.0    0.0    0.0    2.0   1.0   11.0   0.5257731958762887   51 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---    ---    ---    ---    ---   ---   ---    ---                  ---
0.0    1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   7.0    7.0    0.0   0.0    0.0    0.0    0.0   0.0    0.0    5.0    70.0   0.0   0.0   0.0    0.2391304347826087   22 / 92
7.0    5.0    0.0   2.0    6.0   1.0   1.0   0.0   5.0   2.0    2.0   2.0   0.0    0.0    0.0   0.0    3.0    6.0    9.0   2.0    2.0    0.0    0.0    25.0  9.0   11.0   0.75                 75 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    0.0    2.0   1.0    1.0    0.0    2.0   22.0   1.0    24.0   1.0    0.0   50.0  0.0    0.5327102803738317   57 / 107
1.0    3.0    0.0   2.0    6.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0    1.0    11.0  2.0    0.0    0.0    0.0    2.0   0.0   59.0   0.3218390804597701   28 / 87
118.0  135.0  78.0  121.0  74.0  66.0  79.0  60.0  76.0  110.0  63.0  95.0  136.0  100.0  72.0  128.0  103.0  113.0  85.0  100.0  104.0  126.0  102.0  43.0  97.0  106.0  0.38795180722891565  966 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.612048
2    0.766265
3    0.832129
4    0.866667
5    0.894378
6    0.915261
7    0.931325
8    0.94257
9    0.951406
10   0.961446
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:35  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:35  2 min 32.890 sec  151621 obs/sec    1         1             10007      0.756979         1.72721             0.989816       0.476357                         0.754085           1.71149               0.989868         0.465863
    2019-08-04 09:02:35  2 min 33.390 sec  181286 obs/sec    10        10            100070     0.676745         1.37853             0.991861       0.378386                         0.678029           1.38434               0.991808         0.387952
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0932944
C9          0.960309               0.960309             0.0895915
C11         0.952248               0.952248             0.0888394
C12         0.917835               0.917835             0.0856289
C13         0.880451               0.880451             0.0821412
C14         0.834704               0.834704             0.0778732
C7          0.827006               0.827006             0.0771551
C8          0.711031               0.711031             0.0663352
C10         0.681343               0.681343             0.0635655
C6          0.639043               0.639043             0.0596192
C16         0.526587               0.526587             0.0491276
C3          0.418368               0.418368             0.0390314
C5          0.381345               0.381345             0.0355774
C1          0.370024               0.370024             0.0345212
C4          0.363264               0.363264             0.0338905
C2          0.255194               0.255194             0.0238082
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_60

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.001099935599370383   0.0003082082839682698   0.0         -0.14411422120306838  2.047191619873047   -0.391542019791291   1.1375603675842285
    3        26       Softmax                 0.0   0.0   0.0016794830743702522  0.00011165745672769845  0.0         -0.03243113318603719  0.5016469955444336  -0.5905222708843236  0.3838909864425659


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.47046458207423125
RMSE: 0.6859042076516452
LogLoss: 1.395436711580791
Mean Per-Class Error: 0.3879437508886744
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    4.0    0.0    0.0    0.0    5.0    0.0    1.0    4.0    1.0    9.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    5.0    0.0    0.11139240506329114  44 / 395
1.0    248.0  0.0    10.0   0.0    1.0    10.0   4.0    4.0    1.0    1.0    0.0    4.0    0.0    4.0    3.0    4.0    58.0   19.0   0.0    1.0    2.0    2.0    2.0    2.0    2.0    0.3524804177545692   135 / 383
0.0    3.0    268.0  0.0    16.0   3.0    25.0   2.0    1.0    0.0    14.0   0.0    3.0    0.0    1.0    2.0    9.0    1.0    5.0    4.0    2.0    0.0    5.0    0.0    3.0    1.0    0.2717391304347826   100 / 368
8.0    10.0   0.0    269.0  0.0    1.0    0.0    6.0    1.0    10.0   3.0    3.0    7.0    6.0    3.0    12.0   0.0    40.0   14.0   1.0    0.0    0.0    0.0    5.0    1.0    3.0    0.3325062034739454   134 / 403
0.0    24.0   29.0   0.0    164.0  4.0    24.0   1.0    12.0   2.0    2.0    1.0    0.0    0.0    0.0    0.0    20.0   6.0    6.0    5.0    3.0    0.0    0.0    18.0   2.0    61.0   0.5729166666666666   220 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    37.0   15.0   1.0    1.0    0.0    4.0    0.0    0.0    1.0    24.0   286.0  0.0    0.0    0.0    0.2393617021276596   90 / 376
26.0   19.0   1.0    8.0    29.0   2.0    0.0    3.0    23.0   16.0   5.0    4.0    0.0    0.0    3.0    0.0    34.0   5.0    29.0   14.0   5.0    0.0    0.0    132.0  8.0    28.0   0.6649746192893401   262 / 394
0.0    0.0    0.0    5.0    0.0    16.0   0.0    3.0    0.0    0.0    0.0    0.0    3.0    4.0    1.0    4.0    12.0   0.0    2.0    62.0   1.0    54.0   0.0    0.0    226.0  0.0    0.42493638676844786  167 / 393
3.0    5.0    0.0    1.0    18.0   13.0   2.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    2.0    1.0    39.0   4.0    0.0    0.0    0.0    4.0    1.0    267.0  0.2724795640326976   100 / 367
465.0  538.0  427.0  429.0  312.0  389.0  303.0  149.0  380.0  385.0  283.0  302.0  540.0  418.0  340.0  395.0  443.0  498.0  301.0  383.0  367.0  386.0  444.0  259.0  402.0  465.0  0.38638408477456765  3,865 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.613616
2    0.760872
3    0.831451
4    0.873138
5    0.90053
6    0.920324
7    0.93482
8    0.947916
9    0.956613
10   0.964611

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4694334854950558
RMSE: 0.6851521622932061
LogLoss: 1.39331950780146
Mean Per-Class Error: 0.3927831287624333
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19    20    21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   1.0    1.0   0.0   1.0    0.0    1.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   3.0    0.0   2.0    0.0    0.11235955056179775  10 / 89
1.0    63.0   0.0   1.0    0.0   0.0   3.0   1.0   1.0   0.0    0.0   0.0   1.0    0.0    1.0   1.0    2.0    22.0   4.0   0.0   1.0   1.0   1.0    1.0   1.0    0.0    0.4056603773584906   43 / 106
0.0    2.0    54.0  0.0    1.0   0.0   8.0   0.0   1.0   0.0    5.0   0.0   0.0    0.0    1.0   1.0    3.0    0.0    1.0   1.0   0.0   0.0   2.0    0.0   2.0    0.0    0.34146341463414637  28 / 82
4.0    2.0    0.0   79.0   0.0   0.0   0.0   2.0   0.0   1.0    2.0   1.0   1.0    3.0    1.0   3.0    0.0    9.0    3.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    0.29464285714285715  33 / 112
0.0    7.0    12.0  0.0    36.0  1.0   8.0   0.0   2.0   0.0    0.0   1.0   0.0    0.0    0.0   0.0    5.0    2.0    2.0   1.0   1.0   0.0   0.0    6.0   0.0    13.0   0.6288659793814433   61 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0    1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   10.0   3.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   3.0   74.0   0.0   0.0    0.0    0.1956521739130435   18 / 92
6.0    6.0    0.0   3.0    7.0   1.0   0.0   3.0   5.0   2.0    0.0   0.0   0.0    0.0    0.0   0.0    6.0    3.0    7.0   5.0   2.0   0.0   0.0    35.0  2.0    7.0    0.65                 65 / 100
0.0    0.0    0.0   1.0    0.0   4.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0    2.0    0.0   1.0    5.0    0.0    0.0   14.0  0.0   17.0  0.0    0.0   59.0   0.0    0.4485981308411215   48 / 107
0.0    1.0    0.0   1.0    4.0   3.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0    0.0   2.0    0.0    0.0    7.0   1.0   0.0   0.0   0.0    3.0   1.0    62.0   0.28735632183908044  25 / 87
108.0  134.0  93.0  122.0  61.0  86.0  81.0  41.0  82.0  109.0  75.0  89.0  124.0  111.0  61.0  107.0  117.0  126.0  80.0  85.0  99.0  90.0  121.0  68.0  107.0  113.0  0.39156626506024095  975 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.608434
2    0.76747
3    0.836948
4    0.874297
5    0.901205
6    0.918875
7    0.931727
8    0.946586
9    0.95502
10   0.964257
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:44  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:44  1 min 42.452 sec  151621 obs/sec    1         1             10007      0.750543         1.70405             0.989991       0.474258                         0.750012           1.70435               0.989977         0.473896
    2019-08-04 09:01:45  1 min 42.998 sec  167621 obs/sec    10        10            100070     0.685904         1.39544             0.991641       0.386384                         0.685152           1.39332               0.991635         0.391566
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0923785
C13         0.96493                0.96493              0.0891388
C15         0.964256               0.964256             0.0890765
C12         0.921674               0.921674             0.0851429
C11         0.792125               0.792125             0.0731753
C14         0.790361               0.790361             0.0730124
C7          0.783415               0.783415             0.0723707
C10         0.739063               0.739063             0.0682735
C8          0.726234               0.726234             0.0670884
C16         0.591361               0.591361             0.0546291
C6          0.566428               0.566428             0.0523258
C3          0.497954               0.497954             0.0460003
C5          0.423057               0.423057             0.0390813
C1          0.380431               0.380431             0.0351436
C4          0.374082               0.374082             0.0345571
C2          0.309658               0.309658             0.0286057
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_22

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011496307713514398  0.00033690594136714935  0.0         0.06583840892744774   2.1060075759887695  -0.3400096761110447  1.3874220848083496
    3        26       Softmax                 0.0   0.0   0.0016675775371438179  9.379407856613398e-05   0.0         0.009253838842386567  0.5110301971435547  -0.5908878288050281  0.3593780994415283


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4701293149873557
RMSE: 0.685659766201398
LogLoss: 1.4115358904689117
Mean Per-Class Error: 0.38788076930287557
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
343.0  1.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    2.0    1.0    3.0    6.0    0.0    0.0    0.0    3.0    7.0    10.0   0.0    1.0    0.0    6.0    0.0    6.0    0.0    0.13164556962025317  52 / 395
1.0    259.0  0.0    8.0    0.0    0.0    5.0    6.0    2.0    15.0   2.0    0.0    7.0    0.0    0.0    3.0    5.0    37.0   29.0   0.0    0.0    2.0    0.0    0.0    2.0    0.0    0.3237597911227154   124 / 383
0.0    0.0    210.0  0.0    42.0   7.0    33.0   0.0    1.0    0.0    17.0   0.0    8.0    0.0    1.0    0.0    16.0   0.0    14.0   6.0    8.0    0.0    3.0    0.0    1.0    1.0    0.42934782608695654  158 / 368
8.0    30.0   0.0    226.0  2.0    2.0    0.0    20.0   0.0    31.0   0.0    0.0    6.0    2.0    31.0   10.0   0.0    25.0   0.0    3.0    0.0    0.0    0.0    7.0    0.0    0.0    0.4392059553349876   177 / 403
0.0    15.0   7.0    0.0    212.0  1.0    23.0   0.0    2.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    23.0   9.0    10.0   11.0   0.0    0.0    0.0    8.0    0.0    53.0   0.4479166666666667   172 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    47.0   5.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    29.0   288.0  0.0    0.0    0.0    0.23404255319148937  88 / 376
43.0   27.0   0.0    2.0    19.0   0.0    6.0    7.0    12.0   9.0    6.0    4.0    0.0    0.0    2.0    1.0    9.0    2.0    18.0   24.0   3.0    0.0    0.0    161.0  11.0   28.0   0.5913705583756346   233 / 394
0.0    0.0    0.0    0.0    0.0    10.0   1.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    6.0    9.0    0.0    5.0    78.0   0.0    99.0   6.0    0.0    172.0  2.0    0.5623409669211196   221 / 393
7.0    7.0    0.0    1.0    4.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    3.0    1.0    41.0   4.0    0.0    0.0    0.0    11.0   1.0    280.0  0.23705722070844687  87 / 367
483.0  560.0  325.0  350.0  342.0  325.0  351.0  179.0  336.0  368.0  227.0  327.0  541.0  379.0  369.0  442.0  395.0  516.0  321.0  485.0  423.0  463.0  450.0  277.0  292.0  477.0  0.3865840247925622   3,867 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.613416
2    0.760472
3    0.830551
4    0.868539
5    0.893732
6    0.913726
7    0.930821
8    0.942517
9    0.953014
10   0.960812

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.46989475207710374
RMSE: 0.6854886958054842
LogLoss: 1.4169478750703866
Mean Per-Class Error: 0.3867929473214084
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19     20     21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -----  -----  ----  ----  -----  -------------------  -----------
78.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0   0.0   0.0    0.0    4.0    1.0   0.0    0.0    0.0    1.0    0.0   3.0   0.0    0.12359550561797752  11 / 89
0.0    70.0   0.0   1.0    0.0   0.0   1.0   2.0   1.0   4.0    2.0   0.0   2.0    0.0   0.0   1.0    5.0    11.0   5.0   0.0    0.0    1.0    0.0    0.0   0.0   0.0    0.33962264150943394  36 / 106
0.0    0.0    45.0  0.0    6.0   0.0   7.0   0.0   1.0   0.0    4.0   0.0   0.0    0.0   1.0   0.0    8.0    0.0    5.0   1.0    1.0    0.0    2.0    0.0   1.0   0.0    0.45121951219512196  37 / 82
4.0    6.0    0.0   72.0   1.0   0.0   0.0   5.0   0.0   7.0    0.0   0.0   2.0    1.0   7.0   2.0    0.0    4.0    0.0   0.0    0.0    0.0    0.0    1.0   0.0   0.0    0.35714285714285715  40 / 112
0.0    3.0    1.0   0.0    53.0  1.0   6.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    7.0    2.0    1.0   3.0    0.0    0.0    0.0    4.0   0.0   15.0   0.4536082474226804   44 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   9.0    1.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0    3.0    78.0   0.0   0.0   0.0    0.15217391304347827  14 / 92
8.0    9.0    0.0   0.0    7.0   0.0   2.0   4.0   3.0   1.0    2.0   2.0   0.0    0.0   0.0   0.0    1.0    1.0    4.0   8.0    2.0    0.0    0.0    32.0  3.0   11.0   0.68                 68 / 100
0.0    0.0    0.0   0.0    0.0   1.0   1.0   3.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   3.0    5.0    0.0    0.0   23.0   0.0    28.0   2.0    0.0   41.0  0.0    0.616822429906542    66 / 107
1.0    0.0    0.0   1.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0   2.0    0.0    0.0    7.0   3.0    0.0    0.0    0.0    1.0   0.0   70.0   0.19540229885057472  17 / 87
117.0  140.0  69.0  102.0  85.0  74.0  83.0  49.0  75.0  101.0  55.0  90.0  115.0  99.0  75.0  122.0  110.0  134.0  72.0  122.0  110.0  103.0  127.0  64.0  76.0  121.0  0.3855421686746988   960 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.614458
2    0.749799
3    0.824498
4    0.864659
5    0.890763
6    0.909639
7    0.928514
8    0.939759
9    0.950602
10   0.959036
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:45  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:45  43.193 sec  164049 obs/sec    1         1             10007      0.746086         1.67102             0.99011        0.445866                         0.743628           1.66468               0.990147         0.440964
    2019-08-04 09:00:46  43.751 sec  165678 obs/sec    10        10            100070     0.68566          1.41154             0.991647       0.386584                         0.685489           1.41695               0.991627         0.385542
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0921669
C13         0.964989               0.964989             0.08894
C9          0.896884               0.896884             0.082663
C12         0.85926                0.85926              0.0791953
C11         0.850158               0.850158             0.0783564
C7          0.827126               0.827126             0.0762336
C8          0.772964               0.772964             0.0712416
C14         0.734922               0.734922             0.0677354
C10         0.659118               0.659118             0.0607488
C16         0.578147               0.578147             0.053286
C3          0.529148               0.529148             0.0487699
C6          0.509676               0.509676             0.0469753
C5          0.452647               0.452647             0.041719
C4          0.441553               0.441553             0.0406966
C1          0.419648               0.419648             0.0386777
C2          0.353646               0.353646             0.0325945
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_79

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.001108466672008035   0.0002972318325191736  0.0         0.045337629766436294   2.0877199172973633  0.20918438730654945  1.526712417602539
    3        26       Softmax                 0.0   0.0   0.0016673468529076602  9.502045577391982e-05  0.0         -0.028940742418713993  0.5019011497497559  -0.5980133007664074  0.3246856927871704


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4718651597811007
RMSE: 0.6869244207197038
LogLoss: 1.4136639480867956
Mean Per-Class Error: 0.3909193781838057
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
344.0  0.0    0.0    1.0    0.0    0.0    1.0    5.0    0.0    4.0    5.0    1.0    10.0   3.0    2.0    0.0    0.0    3.0    3.0    0.0    4.0    0.0    7.0    0.0    2.0    0.0    0.1291139240506329   51 / 395
0.0    192.0  0.0    11.0   2.0    3.0    2.0    15.0   9.0    19.0   1.0    0.0    8.0    1.0    0.0    1.0    5.0    37.0   68.0   0.0    0.0    1.0    5.0    1.0    1.0    1.0    0.49869451697127937  191 / 383
0.0    2.0    226.0  0.0    61.0   9.0    13.0   0.0    0.0    0.0    20.0   0.0    4.0    1.0    2.0    4.0    3.0    0.0    3.0    1.0    14.0   0.0    5.0    0.0    0.0    0.0    0.3858695652173913   142 / 368
7.0    18.0   0.0    251.0  0.0    1.0    3.0    18.0   0.0    24.0   0.0    3.0    2.0    5.0    10.0   12.0   0.0    24.0   8.0    0.0    1.0    0.0    0.0    14.0   1.0    0.0    0.3756218905472637   151 / 402
0.0    15.0   28.0   0.0    167.0  0.0    13.0   0.0    6.0    1.0    8.0    0.0    2.0    0.0    0.0    0.0    17.0   5.0    9.0    10.0   0.0    0.0    0.0    39.0   7.0    57.0   0.5651041666666666   217 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    4.0    0.0    36.0   7.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    38.0   286.0  0.0    0.0    0.0    0.2393617021276596   90 / 376
5.0    12.0   1.0    2.0    21.0   2.0    2.0    3.0    23.0   11.0   11.0   4.0    0.0    1.0    2.0    0.0    32.0   7.0    19.0   12.0   12.0   0.0    0.0    187.0  19.0   6.0    0.5253807106598984   207 / 394
0.0    0.0    0.0    1.0    0.0    17.0   0.0    4.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    11.0   12.0   0.0    6.0    59.0   2.0    115.0  8.0    0.0    152.0  0.0    0.6132315521628499   241 / 393
2.0    14.0   0.0    2.0    32.0   3.0    1.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    0.0    5.0    1.0    2.0    33.0   7.0    0.0    0.0    0.0    11.0   0.0    238.0  0.35149863760217986  129 / 367
417.0  495.0  390.0  382.0  367.0  401.0  262.0  246.0  355.0  429.0  289.0  310.0  561.0  384.0  345.0  399.0  363.0  474.0  313.0  412.0  471.0  487.0  457.0  344.0  264.0  386.0  0.38938318504448666  3,895 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.610617
2    0.763671
3    0.822553
4    0.863041
5    0.887934
6    0.908727
7    0.925422
8    0.938318
9    0.948815
10   0.956813

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4758180008405804
RMSE: 0.6897956225148
LogLoss: 1.4243743720287934
Mean Per-Class Error: 0.3927933496984822
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19    20     21     22     23    24    25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  -----  -----  -----  ----  ----  ----  -------------------  -----------
78.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    2.0   0.0   1.0    1.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0    3.0    0.0   1.0   0.0   0.12359550561797752  11 / 89
0.0    57.0   0.0   3.0    0.0   0.0   0.0   4.0   2.0   5.0    0.0   0.0   3.0    1.0    0.0   1.0    3.0    12.0   11.0  0.0   0.0    1.0    3.0    0.0   0.0   0.0   0.46226415094339623  49 / 106
0.0    1.0    51.0  0.0    12.0  2.0   4.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0    1.0   2.0    1.0    0.0    1.0   0.0   1.0    0.0    2.0    0.0   0.0   0.0   0.3780487804878049   31 / 82
4.0    3.0    0.0   70.0   0.0   1.0   0.0   6.0   0.0   5.0    0.0   1.0   1.0    3.0    3.0   4.0    0.0    7.0    3.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.375                42 / 112
0.0    6.0    10.0  0.0    34.0  0.0   3.0   0.0   1.0   0.0    4.0   0.0   0.0    0.0    0.0   0.0    6.0    1.0    4.0   4.0   0.0    0.0    0.0    8.0   1.0   15.0  0.6494845360824743   63 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---    ---    ---    ---   ---   ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   8.0    2.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    6.0    76.0   0.0   0.0   0.0   0.17391304347826086  16 / 92
0.0    3.0    1.0   1.0    5.0   1.0   1.0   2.0   6.0   1.0    4.0   0.0   0.0    0.0    0.0   0.0    4.0    3.0    5.0   2.0   3.0    0.0    0.0    50.0  6.0   2.0   0.5                  50 / 100
0.0    0.0    0.0   0.0    0.0   3.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0   4.0    6.0    0.0    0.0   12.0  0.0    36.0   4.0    0.0   38.0  0.0   0.6448598130841121   69 / 107
0.0    2.0    0.0   1.0    12.0  1.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0    0.0    0.0   2.0    0.0    0.0    7.0   3.0   0.0    0.0    0.0    2.0   0.0   53.0  0.39080459770114945  34 / 87
100.0  129.0  93.0  110.0  83.0  94.0  57.0  68.0  76.0  124.0  74.0  83.0  130.0  104.0  67.0  116.0  102.0  121.0  78.0  89.0  111.0  114.0  126.0  79.0  72.0  90.0  0.3931726907630522   979 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.606827
2    0.760241
3    0.818875
4    0.855422
5    0.885944
6    0.905221
7    0.923293
8    0.936546
9    0.950201
10   0.95743
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:13  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:13  2 min 11.267 sec  158841 obs/sec    1         1             10007      0.755942         1.73953             0.989847       0.489053                         0.755215           1.73948               0.989837         0.492369
    2019-08-04 09:02:14  2 min 11.845 sec  160884 obs/sec    10        10            100070     0.686924         1.41366             0.991616       0.389383                         0.689796           1.42437               0.991522         0.393173
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.093974
C15         0.975007               0.975007             0.0916253
C12         0.929629               0.929629             0.087361
C13         0.901411               0.901411             0.0847092
C14         0.805563               0.805563             0.0757019
C7          0.803881               0.803881             0.0755439
C11         0.79949                0.79949              0.0751312
C8          0.75677                0.75677              0.0711167
C10         0.630437               0.630437             0.0592447
C6          0.538784               0.538784             0.0506317
C16         0.529359               0.529359             0.049746
C3          0.471365               0.471365             0.0442961
C5          0.420856               0.420856             0.0395495
C4          0.398574               0.398574             0.0374556
C1          0.392386               0.392386             0.0368741
C2          0.287727               0.287727             0.0270389
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_86

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011373135115491095  0.00034635327756404877  0.0         0.014111712398516829  2.118104934692383    -0.0838984162162909  1.5236539840698242
    3        26       Softmax                 0.0   0.0   0.0016685420214344049  9.570704423822463e-05   0.0         -0.04412922968717444  0.49993741512298584  -0.5752662571645863  0.3703879117965698


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4782235258789033
RMSE: 0.6915370748404625
LogLoss: 1.429882264338391
Mean Per-Class Error: 0.409932196026061
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  1.0    0.0    10.0   0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    9.0    2.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    6.0    0.0    0.10632911392405063  42 / 395
1.0    232.0  0.0    18.0   0.0    2.0    1.0    13.0   10.0   0.0    3.0    0.0    1.0    1.0    3.0    0.0    8.0    36.0   19.0   0.0    0.0    0.0    2.0    16.0   3.0    14.0   0.39425587467362927  151 / 383
0.0    0.0    248.0  0.0    34.0   1.0    22.0   0.0    1.0    0.0    15.0   0.0    10.0   0.0    2.0    1.0    11.0   0.0    9.0    3.0    4.0    0.0    6.0    1.0    0.0    0.0    0.32608695652173914  120 / 368
13.0   18.0   0.0    263.0  0.0    2.0    0.0    12.0   0.0    13.0   2.0    1.0    6.0    8.0    2.0    9.0    0.0    21.0   3.0    0.0    0.0    0.0    1.0    29.0   0.0    0.0    0.34739454094292804  140 / 403
0.0    11.0   28.0   0.0    183.0  5.0    18.0   1.0    25.0   0.0    2.0    1.0    0.0    0.0    0.0    0.0    23.0   8.0    20.0   12.0   0.0    1.0    0.0    24.0   0.0    22.0   0.5234375            201 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    24.0   10.0   1.0    1.0    1.0    5.0    0.0    0.0    0.0    37.0   284.0  0.0    0.0    0.0    0.24468085106382978  92 / 376
14.0   21.0   1.0    14.0   15.0   4.0    0.0    1.0    18.0   0.0    3.0    1.0    1.0    0.0    19.0   0.0    34.0   3.0    17.0   26.0   4.0    0.0    0.0    133.0  17.0   48.0   0.6624365482233503   261 / 394
0.0    0.0    0.0    1.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    11.0   18.0   0.0    0.0    154.0  0.0    101.0  1.0    0.0    99.0   2.0    0.7480916030534351   294 / 393
3.0    17.0   0.0    7.0    4.0    6.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    0.0    10.0   5.0    0.0    49.0   3.0    0.0    0.0    0.0    31.0   0.0    228.0  0.3770491803278688   138 / 366
504.0  525.0  352.0  449.0  304.0  319.0  339.0  241.0  421.0  303.0  227.0  314.0  555.0  354.0  334.0  442.0  488.0  413.0  296.0  556.0  357.0  469.0  468.0  314.0  242.0  417.0  0.4084774567629711   4,086 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.591522
2    0.760372
3    0.821354
4    0.861941
5    0.888034
6    0.907328
7    0.924822
8    0.937519
9    0.947916
10   0.957713

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.47940941085338895
RMSE: 0.6923939708384158
LogLoss: 1.43264684825829
Mean Per-Class Error: 0.4193045911947317
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20    21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  -----  -----  ----  ----  -----  -------------------  -------------
81.0   0.0    0.0   1.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    1.0    0.0    0.0   0.0    0.0   0.0    3.0    0.0   2.0   0.0    0.0898876404494382   8 / 89
0.0    61.0   0.0   5.0    0.0   0.0   0.0   6.0   2.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    5.0    14.0   1.0   0.0    0.0   0.0    1.0    5.0   1.0   3.0    0.42452830188679247  45 / 106
0.0    0.0    51.0  0.0    6.0   0.0   5.0   0.0   0.0   0.0   7.0   0.0   0.0    0.0   1.0   0.0    5.0    0.0    4.0   1.0    0.0   0.0    2.0    0.0   0.0   0.0    0.3780487804878049   31 / 82
6.0    4.0    0.0   79.0   0.0   0.0   0.0   5.0   0.0   1.0   0.0   1.0   3.0    3.0   0.0   3.0    0.0    4.0    1.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0    0.29464285714285715  33 / 112
0.0    2.0    9.0   0.0    45.0  1.0   5.0   0.0   4.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    7.0    2.0    7.0   5.0    0.0   0.0    0.0    6.0   0.0   4.0    0.5360824742268041   52 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0    3.0   0.0   1.0    0.0    2.0    0.0   0.0    0.0   6.0    75.0   0.0   0.0   0.0    0.18478260869565216  17 / 92
2.0    6.0    1.0   6.0    5.0   1.0   0.0   1.0   5.0   0.0   1.0   1.0   0.0    0.0   4.0   0.0    5.0    0.0    5.0   9.0    1.0   0.0    0.0    33.0  2.0   12.0   0.67                 67 / 100
0.0    0.0    0.0   1.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0    9.0    0.0    0.0   37.0   0.0   31.0   0.0    0.0   23.0  0.0    0.7850467289719626   84 / 107
0.0    2.0    0.0   4.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0    12.0  1.0    0.0   0.0    0.0    10.0  0.0   54.0   0.3793103448275862   33 / 87
129.0  124.0  81.0  123.0  74.0  63.0  76.0  66.0  97.0  88.0  61.0  87.0  116.0  95.0  59.0  130.0  135.0  103.0  77.0  135.0  95.0  110.0  125.0  80.0  61.0  100.0  0.41767068273092367  1,040 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.582329
2    0.753414
3    0.811647
4    0.859839
5    0.887149
6    0.908835
7    0.924096
8    0.938153
9    0.950201
10   0.95743
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:02:26  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:02:26  2 min 24.362 sec  166783 obs/sec    1         1             10007      0.761435         1.7623              0.989697       0.496351                         0.759445           1.75105               0.989723         0.493574
    2019-08-04 09:02:27  2 min 24.895 sec  173732 obs/sec    10        10            100070     0.691537         1.42988             0.991501       0.408477                         0.692394           1.43265               0.991458         0.417671
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0894719
C9          0.990344               0.990344             0.0886079
C13         0.969674               0.969674             0.0867585
C12         0.905595               0.905595             0.0810253
C11         0.870674               0.870674             0.0779009
C7          0.802846               0.802846             0.0718321
C14         0.802603               0.802603             0.0718104
C8          0.712734               0.712734             0.0637696
C16         0.656715               0.656715             0.0587575
C10         0.601761               0.601761             0.0538407
C6          0.579265               0.579265             0.0518279
C3          0.561215               0.561215             0.050213
C5          0.480257               0.480257             0.0429695
C1          0.433566               0.433566             0.038792
C4          0.421828               0.421828             0.0377417
C2          0.387621               0.387621             0.0346812
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_19

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011143240944875288  0.0003002658486366272  0.0         -0.27167628654925124  2.061455726623535   -0.12585048842080196  1.0948834419250488
    3        26       Softmax                 0.0   0.0   0.00166488445910755    9.847033652476966e-05  0.0         -0.0359355612196693   0.5059833526611328  -0.5943942151230318   0.3867068290710449


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.49218568182453204
RMSE: 0.7015594642113611
LogLoss: 1.456283666768044
Mean Per-Class Error: 0.41054534421763683
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
332.0  0.0    0.0    12.0   0.0    0.0    0.0    1.0    0.0    4.0    1.0    5.0    11.0   0.0    1.0    0.0    5.0    10.0   0.0    0.0    1.0    3.0    4.0    0.0    4.0    0.0    0.15736040609137056  62 / 394
0.0    195.0  1.0    7.0    6.0    1.0    5.0    16.0   9.0    0.0    2.0    0.0    6.0    0.0    0.0    8.0    6.0    59.0   41.0   0.0    1.0    0.0    1.0    1.0    0.0    18.0   0.4908616187989556   188 / 383
0.0    3.0    208.0  0.0    74.0   1.0    24.0   1.0    0.0    0.0    22.0   0.0    4.0    1.0    1.0    1.0    2.0    1.0    4.0    6.0    3.0    0.0    1.0    1.0    0.0    10.0   0.43478260869565216  160 / 368
3.0    27.0   0.0    248.0  0.0    2.0    2.0    4.0    13.0   10.0   0.0    6.0    5.0    11.0   16.0   10.0   0.0    21.0   8.0    2.0    3.0    0.0    0.0    3.0    1.0    8.0    0.38461538461538464  155 / 403
0.0    12.0   36.0   0.0    184.0  3.0    27.0   1.0    5.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    9.0    13.0   10.0   4.0    3.0    6.0    0.0    19.0   0.0    48.0   0.5208333333333334   200 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    6.0    8.0    0.0    0.0    1.0    10.0   0.0    0.0    0.0    22.0   316.0  0.0    0.0    0.0    0.1595744680851064   60 / 376
17.0   3.0    10.0   3.0    19.0   1.0    1.0    1.0    23.0   3.0    6.0    9.0    0.0    0.0    3.0    0.0    27.0   4.0    19.0   23.0   0.0    0.0    0.0    164.0  5.0    53.0   0.583756345177665    230 / 394
0.0    0.0    0.0    1.0    0.0    7.0    2.0    2.0    0.0    0.0    1.0    0.0    1.0    4.0    7.0    14.0   7.0    0.0    4.0    70.0   4.0    84.0   5.0    0.0    180.0  0.0    0.5419847328244275   213 / 393
1.0    16.0   0.0    8.0    22.0   1.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    6.0    7.0    0.0    22.0   1.0    0.0    0.0    0.0    0.0    0.0    279.0  0.23978201634877383  88 / 367
415.0  399.0  334.0  417.0  427.0  332.0  418.0  187.0  392.0  343.0  292.0  296.0  415.0  404.0  398.0  428.0  384.0  553.0  263.0  470.0  327.0  481.0  496.0  280.0  284.0  568.0  0.4091772468259522   4,093 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.590823
2    0.746676
3    0.822653
4    0.864141
5    0.889733
6    0.909027
7    0.925622
8    0.938818
9    0.950515
10   0.960112

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4936405099486036
RMSE: 0.702595552183903
LogLoss: 1.4581017762576571
Mean Per-Class Error: 0.4235994991720852
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6      7     8      9     10    11    12    13     14    15     16    17     18    19     20    21     22     23    24    25     Error                Rate
----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  ----  -----  -------------------  -------------
74.0  0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0   1.0   1.0   0.0    0.0   0.0    0.0   4.0    0.0   0.0    0.0   1.0    2.0    0.0   2.0   0.0    0.16853932584269662  15 / 89
0.0   46.0  0.0   0.0    0.0   0.0   3.0    5.0   3.0    0.0   0.0   0.0   2.0   0.0    0.0   2.0    4.0   23.0   12.0  0.0    1.0   0.0    1.0    1.0   0.0   3.0    0.5660377358490566   60 / 106
0.0   0.0   44.0  0.0    13.0  0.0   9.0    0.0   0.0    0.0   6.0   0.0   0.0   0.0    0.0   1.0    1.0   1.0    1.0   2.0    0.0   0.0    1.0    0.0   0.0   3.0    0.4634146341463415   38 / 82
1.0   5.0   0.0   78.0   0.0   1.0   1.0    2.0   2.0    1.0   0.0   2.0   2.0   3.0    7.0   2.0    0.0   1.0    3.0   0.0    1.0   0.0    0.0    0.0   0.0   0.0    0.30357142857142855  34 / 112
0.0   2.0   12.0  0.0    41.0  1.0   7.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0    0.0   0.0    2.0   5.0    3.0   1.0    1.0   3.0    0.0    3.0   0.0   15.0   0.5773195876288659   56 / 97
---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---   ---    ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0   0.0   3.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   3.0    80.0   0.0   0.0   0.0    0.13043478260869565  12 / 92
4.0   2.0   4.0   1.0    7.0   0.0   0.0    1.0   5.0    1.0   2.0   2.0   0.0   0.0    0.0   0.0    4.0   1.0    6.0   4.0    0.0   0.0    0.0    45.0  2.0   9.0    0.55                 55 / 100
0.0   0.0   0.0   1.0    0.0   1.0   0.0    1.0   0.0    0.0   1.0   0.0   0.0   1.0    2.0   4.0    3.0   0.0    0.0   19.0   1.0   28.0   2.0    0.0   43.0  0.0    0.5981308411214953   64 / 107
0.0   3.0   0.0   3.0    5.0   1.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0    0.0   3.0    1.0   0.0    3.0   0.0    0.0   0.0    0.0    0.0   0.0   67.0   0.22988505747126436  20 / 87
94.0  99.0  78.0  123.0  92.0  65.0  107.0  52.0  100.0  91.0  74.0  81.0  94.0  106.0  85.0  125.0  93.0  140.0  69.0  119.0  79.0  114.0  133.0  67.0  76.0  134.0  0.42248995983935744  1,052 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.57751
2    0.748996
3    0.822892
4    0.861847
5    0.889157
6    0.908032
7    0.924096
8    0.936948
9    0.947791
10   0.959839
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:00:40  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:00:40  37.873 sec  161403 obs/sec    1         1             10007      0.760323         1.72163             0.989726       0.469259                         0.759233           1.71034               0.989729         0.473896
    2019-08-04 09:00:40  38.445 sec  161663 obs/sec    10        10            100070     0.701559         1.45628             0.991253       0.409177                         0.702596           1.4581                0.991204         0.42249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0960399
C13         0.902406               0.902406             0.086667
C12         0.888568               0.888568             0.085338
C9          0.882732               0.882732             0.0847775
C11         0.736805               0.736805             0.0707627
C7          0.73157                0.73157              0.0702599
C8          0.699959               0.699959             0.067224
C14         0.680695               0.680695             0.0653739
C10         0.625888               0.625888             0.0601102
C16         0.548765               0.548765             0.0527033
C6          0.527589               0.527589             0.0506696
C3          0.506238               0.506238             0.0486191
C5          0.50305                0.50305              0.0483129
C1          0.410927               0.410927             0.0394654
C4          0.389918               0.389918             0.0374477
C2          0.377227               0.377227             0.0362288
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_110

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011171470919180138  0.00030266528483480215  0.0         0.11415562644833699   2.1512985229492188  -0.26230569703943285  1.0235199928283691
    3        26       Softmax                 0.0   0.0   0.0016657085950730387  0.00010199937969446182  0.0         0.019715701418905295  0.504340648651123   -0.5784440524134176   0.3739454746246338


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.49331341950110214
RMSE: 0.7023627406839732
LogLoss: 1.4711560638722776
Mean Per-Class Error: 0.416492633550079
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  4.0    0.0    7.0    0.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    7.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    7.0    0.0    7.0    0.0    0.10632911392405063  42 / 395
1.0    275.0  0.0    3.0    0.0    0.0    0.0    8.0    8.0    1.0    3.0    1.0    3.0    1.0    1.0    9.0    5.0    40.0   18.0   0.0    0.0    0.0    2.0    1.0    3.0    0.0    0.2819843342036554   108 / 383
0.0    0.0    247.0  0.0    38.0   6.0    21.0   0.0    1.0    0.0    26.0   0.0    0.0    4.0    1.0    0.0    3.0    1.0    6.0    6.0    1.0    0.0    7.0    0.0    0.0    0.0    0.328804347826087    121 / 368
5.0    51.0   0.0    248.0  0.0    2.0    0.0    3.0    2.0    3.0    0.0    3.0    7.0    9.0    19.0   10.0   0.0    24.0   9.0    0.0    1.0    0.0    0.0    1.0    5.0    1.0    0.38461538461538464  155 / 403
1.0    5.0    14.0   0.0    152.0  2.0    62.0   0.0    14.0   1.0    5.0    0.0    0.0    0.0    0.0    0.0    15.0   16.0   17.0   12.0   1.0    0.0    0.0    12.0   0.0    54.0   0.6031331592689295   231 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    34.0   20.0   0.0    1.0    3.0    4.0    0.0    0.0    0.0    29.0   271.0  0.0    7.0    0.0    0.27540106951871657  103 / 374
33.0   7.0    15.0   1.0    4.0    0.0    1.0    4.0    32.0   8.0    9.0    0.0    1.0    0.0    3.0    0.0    12.0   4.0    26.0   6.0    19.0   0.0    0.0    116.0  8.0    85.0   0.7055837563451777   278 / 394
0.0    1.0    0.0    2.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    3.0    0.0    16.0   7.0    0.0    0.0    117.0  4.0    101.0  8.0    0.0    119.0  6.0    0.6972010178117048   274 / 393
4.0    9.0    0.0    0.0    14.0   0.0    3.0    0.0    3.0    1.0    0.0    5.0    0.0    1.0    0.0    10.0   1.0    5.0    36.0   2.0    0.0    0.0    0.0    3.0    0.0    270.0  0.26430517711171664  97 / 367
469.0  594.0  385.0  413.0  282.0  308.0  406.0  147.0  404.0  312.0  295.0  310.0  511.0  412.0  335.0  432.0  312.0  510.0  281.0  552.0  393.0  413.0  517.0  199.0  260.0  551.0  0.41507547735679295  4,152 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.584924
2    0.743877
3    0.817055
4    0.859142
5    0.889033
6    0.908627
7    0.924023
8    0.938219
9    0.947616
10   0.957913

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4907482279495098
RMSE: 0.7005342446658192
LogLoss: 1.4595122225724821
Mean Per-Class Error: 0.4123941936106705
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16    17     18    19     20    21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  ----  -----  -------------------  -------------
81.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    3.0    0.0   2.0   0.0    0.0898876404494382   8 / 89
0.0    74.0   0.0   0.0    0.0   0.0   0.0   2.0   1.0   1.0   2.0   0.0   1.0    1.0    1.0   2.0    3.0   12.0   4.0   0.0    0.0   0.0    1.0    0.0   1.0   0.0    0.3018867924528302   32 / 106
0.0    0.0    48.0  0.0    10.0  0.0   7.0   0.0   1.0   0.0   6.0   0.0   0.0    0.0    1.0   0.0    2.0   0.0    2.0   3.0    0.0   0.0    2.0    0.0   0.0   0.0    0.4146341463414634   34 / 82
1.0    12.0   0.0   70.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   3.0    2.0    8.0   2.0    0.0   6.0    6.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0    0.375                42 / 112
0.0    2.0    1.0   0.0    40.0  0.0   18.0  0.0   3.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0    4.0   4.0    2.0   6.0    0.0   0.0    0.0    4.0   0.0   12.0   0.5876288659793815   57 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   6.0    7.0    0.0   0.0    1.0   1.0    0.0   0.0    0.0   3.0    73.0   0.0   1.0   0.0    0.20652173913043478  19 / 92
8.0    2.0    7.0   0.0    1.0   0.0   0.0   1.0   5.0   0.0   2.0   0.0   1.0    0.0    1.0   0.0    1.0   1.0    7.0   1.0    5.0   0.0    0.0    32.0  1.0   24.0   0.68                 68 / 100
0.0    0.0    0.0   1.0    0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    2.0    0.0   6.0    3.0   0.0    0.0   32.0   0.0   30.0   2.0    0.0   28.0  0.0    0.7383177570093458   79 / 107
1.0    2.0    0.0   0.0    3.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0    1.0    0.0   3.0    0.0   1.0    12.0  0.0    0.0   0.0    0.0    0.0   0.0   62.0   0.28735632183908044  25 / 87
104.0  148.0  79.0  120.0  68.0  58.0  98.0  41.0  90.0  83.0  81.0  80.0  114.0  103.0  68.0  134.0  83.0  132.0  86.0  133.0  99.0  101.0  134.0  57.0  62.0  134.0  0.41204819277108434  1,026 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.587952
2    0.750201
3    0.818072
4    0.863052
5    0.893976
6    0.912048
7    0.927711
8    0.941767
9    0.948996
10   0.957028
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:03:06  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:03:06  3 min  4.416 sec  166783 obs/sec    1         1             10007      0.750097         1.7004              0.99           0.486554                         0.746967           1.68021               0.990058         0.471084
    2019-08-04 09:03:07  3 min  4.975 sec  165404 obs/sec    10        10            100070     0.702363         1.47116             0.991232       0.415075                         0.700534           1.45951               0.991256         0.412048
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0867488
C12         0.98685                0.98685              0.0856081
C15         0.979646               0.979646             0.084983
C13         0.958011               0.958011             0.0831062
C11         0.919435               0.919435             0.0797599
C7          0.842623               0.842623             0.0730965
C14         0.791403               0.791403             0.0686532
C8          0.781933               0.781933             0.0678317
C10         0.673935               0.673935             0.058463
C6          0.606031               0.606031             0.0525725
C16         0.600754               0.600754             0.0521146
C3          0.561348               0.561348             0.0486963
C5          0.512687               0.512687             0.044475
C2          0.451105               0.451105             0.0391328
C1          0.43218                0.43218              0.0374911
C4          0.4296                 0.4296               0.0372673
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_226

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011755813167155793  0.0003319223178550601  0.0         0.002759216488811944  2.168978691101074    -0.03510093580710372  1.4534239768981934
    3        26       Softmax                 0.0   0.0   0.0016585261494653353  8.824694668874145e-05  0.0         0.018706947321474078  0.48110318183898926  -0.5852906223712429   0.34963440895080566


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5167082848749832
RMSE: 0.7188242378182467
LogLoss: 1.5282015608433166
Mean Per-Class Error: 0.4383571022755587
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  1.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    10.0   0.0    2.0    0.0    7.0    2.0    1.0    0.0    2.0    1.0    5.0    0.0    6.0    0.0    0.11392405063291139  45 / 395
0.0    227.0  0.0    14.0   1.0    0.0    6.0    25.0   12.0   4.0    0.0    0.0    3.0    0.0    1.0    3.0    6.0    49.0   23.0   0.0    0.0    1.0    1.0    4.0    1.0    2.0    0.4073107049608355   156 / 383
0.0    0.0    226.0  0.0    51.0   1.0    21.0   4.0    4.0    0.0    8.0    0.0    5.0    0.0    4.0    0.0    2.0    0.0    6.0    21.0   10.0   0.0    4.0    0.0    0.0    0.0    0.38419618528610355  141 / 367
12.0   23.0   0.0    246.0  0.0    0.0    0.0    13.0   2.0    7.0    0.0    4.0    8.0    2.0    33.0   14.0   0.0    10.0   4.0    1.0    1.0    0.0    0.0    20.0   2.0    1.0    0.38957816377171217  157 / 403
0.0    26.0   28.0   0.0    174.0  1.0    22.0   4.0    28.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    7.0    8.0    11.0   12.0   2.0    0.0    0.0    8.0    1.0    51.0   0.546875             210 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    0.0    1.0    0.0    21.0   13.0   0.0    0.0    6.0    0.0    0.0    1.0    0.0    38.0   282.0  0.0    0.0    0.0    0.25                 94 / 376
13.0   7.0    14.0   11.0   37.0   0.0    3.0    0.0    24.0   1.0    7.0    13.0   0.0    0.0    20.0   0.0    19.0   11.0   10.0   9.0    20.0   0.0    0.0    126.0  5.0    44.0   0.6802030456852792   268 / 394
0.0    5.0    0.0    1.0    0.0    10.0   0.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    15.0   0.0    4.0    73.0   3.0    85.0   16.0   0.0    174.0  2.0    0.5572519083969466   219 / 393
8.0    14.0   1.0    1.0    49.0   3.0    0.0    0.0    48.0   1.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    6.0    17.0   6.0    0.0    0.0    0.0    2.0    3.0    204.0  0.444141689373297    163 / 367
524.0  572.0  419.0  413.0  416.0  422.0  276.0  233.0  505.0  329.0  200.0  312.0  656.0  306.0  385.0  350.0  340.0  457.0  172.0  378.0  372.0  460.0  459.0  269.0  341.0  437.0  0.43706887933619915  4,372 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.562931
2    0.728581
3    0.805458
4    0.852444
5    0.883435
6    0.903229
7    0.919924
8    0.935419
9    0.948116
10   0.957113

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.508823357589645
RMSE: 0.7133185526745012
LogLoss: 1.508066797282446
Mean Per-Class Error: 0.4280898974107791
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8      9     10    11    12     13    14    15     16    17     18    19    20    21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  -----  -------------------  -------------
81.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    2.0    0.0   3.0   0.0    0.0898876404494382   8 / 89
0.0    63.0   0.0   0.0    0.0   0.0   1.0   9.0   3.0    0.0   0.0   0.0   1.0    0.0   0.0   1.0    4.0   16.0   4.0   0.0   0.0   1.0    1.0    1.0   0.0   1.0    0.4056603773584906   43 / 106
0.0    0.0    48.0  0.0    7.0   0.0   7.0   0.0   1.0    0.0   3.0   0.0   1.0    0.0   1.0   0.0    1.0   0.0    2.0   8.0   1.0   0.0    2.0    0.0   0.0   0.0    0.4146341463414634   34 / 82
5.0    3.0    0.0   71.0   0.0   0.0   0.0   5.0   0.0    2.0   0.0   1.0   3.0    1.0   10.0  3.0    0.0   3.0    2.0   0.0   0.0   0.0    0.0    3.0   0.0   0.0    0.36607142857142855  41 / 112
0.0    7.0    7.0   0.0    46.0  0.0   6.0   1.0   5.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    4.0   3.0   0.0   0.0    0.0    2.0   1.0   11.0   0.5257731958762887   51 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0   0.0   4.0    3.0   0.0   0.0    1.0   0.0    0.0   0.0   0.0   8.0    74.0   0.0   0.0   0.0    0.1956521739130435   18 / 92
4.0    3.0    7.0   4.0    8.0   0.0   0.0   0.0   7.0    0.0   2.0   2.0   0.0    0.0   2.0   0.0    3.0   2.0    5.0   2.0   4.0   0.0    0.0    32.0  1.0   12.0   0.68                 68 / 100
0.0    2.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0    7.0   0.0    0.0   21.0  2.0   22.0   5.0    0.0   47.0  0.0    0.5607476635514018   60 / 107
1.0    1.0    0.0   0.0    12.0  0.0   0.0   0.0   9.0    1.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   2.0    3.0   3.0   0.0   0.0    0.0    1.0   1.0   52.0   0.40229885057471265  35 / 87
132.0  139.0  90.0  107.0  95.0  85.0  65.0  60.0  107.0  92.0  55.0  82.0  154.0  77.0  80.0  108.0  98.0  124.0  43.0  95.0  94.0  106.0  118.0  70.0  96.0  118.0  0.42811244979919677  1,066 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.571888
2    0.730522
3    0.812851
4    0.856225
5    0.880321
6    0.901205
7    0.918474
8    0.933333
9    0.947791
10   0.956627
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:40  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:40  6 min 38.321 sec  156359 obs/sec    1         1             10007      0.771348         1.80185             0.989426       0.529041                         0.771535           1.80051               0.989393         0.531727
    2019-08-04 09:06:41  6 min 38.896 sec  160112 obs/sec    10        10            100070     0.718824         1.5282              0.990817       0.437069                         0.713319           1.50807               0.990934         0.428112
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0883484
C11         0.979194               0.979194             0.0865102
C9          0.97487                0.97487              0.0861282
C15         0.968901               0.968901             0.0856008
C14         0.867733               0.867733             0.0766628
C13         0.840108               0.840108             0.0742222
C7          0.805396               0.805396             0.0711555
C8          0.715091               0.715091             0.0631771
C10         0.651492               0.651492             0.0575582
C16         0.618011               0.618011             0.0546002
C3          0.617649               0.617649             0.0545683
C6          0.572699               0.572699             0.050597
C5          0.487767               0.487767             0.0430935
C1          0.463838               0.463838             0.0409793
C4          0.427905               0.427905             0.0378047
C2          0.328173               0.328173             0.0289935
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_59

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias           bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011827233417989191  0.0003643553936854005   0.0         -0.028731085315712335  2.212357521057129   0.1571076730648974  1.0812053680419922
    3        26       Softmax                 0.0   0.0   0.0016655607144527424  0.00011084086145274341  0.0         0.015537116377695033   0.4934535026550293  -0.600292157311865  0.3626211881637573


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5163085145105801
RMSE: 0.7185461116105076
LogLoss: 1.524150624348884
Mean Per-Class Error: 0.4429375274580314
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
344.0  3.0    0.0    5.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    5.0    8.0    1.0    0.0    0.0    0.0    11.0   1.0    0.0    3.0    2.0    6.0    0.0    2.0    0.0    0.1291139240506329   51 / 395
0.0    229.0  0.0    24.0   2.0    1.0    3.0    5.0    6.0    11.0   0.0    0.0    5.0    0.0    0.0    4.0    6.0    42.0   37.0   0.0    0.0    0.0    3.0    3.0    2.0    0.0    0.402088772845953    154 / 383
0.0    2.0    247.0  1.0    23.0   6.0    30.0   1.0    0.0    0.0    24.0   0.0    2.0    0.0    1.0    3.0    2.0    0.0    1.0    3.0    14.0   0.0    1.0    0.0    1.0    6.0    0.328804347826087    121 / 368
7.0    43.0   0.0    214.0  0.0    3.0    0.0    4.0    0.0    45.0   0.0    0.0    5.0    7.0    20.0   15.0   0.0    22.0   14.0   0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.46898263027295284  189 / 403
0.0    3.0    8.0    0.0    213.0  0.0    30.0   2.0    12.0   1.0    6.0    0.0    0.0    0.0    0.0    0.0    15.0   5.0    27.0   14.0   0.0    0.0    0.0    10.0   2.0    35.0   0.44386422976501305  170 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    0.0    0.0    0.0    0.0    62.0   4.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    48.0   250.0  0.0    0.0    0.0    0.3333333333333333   125 / 375
31.0   19.0   4.0    7.0    38.0   1.0    1.0    1.0    31.0   15.0   2.0    0.0    0.0    0.0    0.0    1.0    32.0   7.0    31.0   37.0   4.0    0.0    0.0    74.0   5.0    53.0   0.8121827411167513   320 / 394
0.0    1.0    0.0    1.0    0.0    29.0   0.0    1.0    0.0    0.0    0.0    0.0    6.0    1.0    0.0    17.0   11.0   0.0    5.0    113.0  3.0    129.0  10.0   0.0    66.0   0.0    0.8320610687022901   327 / 393
3.0    26.0   0.0    2.0    21.0   0.0    0.0    0.0    11.0   2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    4.0    45.0   8.0    0.0    0.0    0.0    5.0    0.0    238.0  0.35149863760217986  129 / 367
488.0  594.0  374.0  393.0  433.0  398.0  370.0  185.0  420.0  384.0  196.0  328.0  617.0  279.0  338.0  456.0  357.0  485.0  314.0  432.0  475.0  508.0  421.0  161.0  173.0  424.0  0.44166749975007497  4,418 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.558333
2    0.719684
3    0.807658
4    0.853844
5    0.884735
6    0.905728
7    0.921124
8    0.93472
9    0.946616
10   0.956213

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.514682971790986
RMSE: 0.7174140866967876
LogLoss: 1.5172097202534973
Mean Per-Class Error: 0.4409676474342048
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10    11    12     13    14    15     16    17     18    19     20     21     22     23    24    25     Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -----  -----  ----  ----  -----  -------------------  -------------
80.0   2.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0    0.0    4.0    0.0   1.0   0.0    0.10112359550561797  9 / 89
0.0    57.0   0.0   8.0    1.0    1.0   2.0   2.0   1.0   3.0   0.0   0.0   4.0    0.0   0.0   2.0    3.0   9.0    8.0   0.0    0.0    0.0    2.0    2.0   1.0   0.0    0.46226415094339623  49 / 106
0.0    1.0    54.0  0.0    2.0    1.0   8.0   0.0   0.0   0.0   8.0   0.0   0.0    0.0   1.0   2.0    0.0   0.0    0.0   0.0    2.0    0.0    1.0    0.0   0.0   2.0    0.34146341463414637  28 / 82
4.0    9.0    0.0   67.0   0.0    0.0   0.0   2.0   0.0   9.0   0.0   0.0   2.0    2.0   5.0   3.0    0.0   6.0    3.0   0.0    0.0    0.0    0.0    0.0   0.0   0.0    0.4017857142857143   45 / 112
0.0    1.0    4.0   0.0    45.0   0.0   9.0   0.0   1.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    3.0   2.0    7.0   5.0    0.0    0.0    0.0    4.0   0.0   13.0   0.5360824742268041   52 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   1.0   1.0   0.0   0.0   0.0   0.0   13.0   1.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0    11.0   64.0   0.0   0.0   0.0    0.30434782608695654  28 / 92
4.0    6.0    0.0   3.0    12.0   1.0   0.0   1.0   6.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    7.0   3.0    6.0   9.0    2.0    0.0    0.0    23.0  2.0   14.0   0.77                 77 / 100
0.0    0.0    0.0   0.0    0.0    4.0   0.0   1.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   4.0    5.0   0.0    0.0   29.0   0.0    41.0   3.0    0.0   17.0  0.0    0.8411214953271028   90 / 107
1.0    4.0    0.0   1.0    6.0    0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   2.0    14.0  2.0    0.0    0.0    0.0    1.0   0.0   51.0   0.41379310344827586  36 / 87
114.0  133.0  88.0  120.0  101.0  81.0  96.0  55.0  96.0  93.0  52.0  84.0  157.0  65.0  69.0  127.0  99.0  126.0  76.0  110.0  114.0  128.0  108.0  47.0  47.0  104.0  0.442570281124498    1,102 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.55743
2    0.718876
3    0.809639
4    0.853815
5    0.889157
6    0.91004
7    0.922892
8    0.93494
9    0.947791
10   0.955422
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:01:43  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:01:44  1 min 41.790 sec  156359 obs/sec    1         1             10007      0.777078         1.82977             0.989269       0.527642                         0.775952           1.81222               0.989271         0.5249
    2019-08-04 09:01:44  1 min 42.358 sec  161925 obs/sec    10        10            100070     0.718546         1.52415             0.990824       0.441667                         0.717414           1.51721               0.990829         0.44257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0927648
C9          0.941472               0.941472             0.0873355
C12         0.933334               0.933334             0.0865806
C13         0.907859               0.907859             0.0842174
C11         0.866661               0.866661             0.0803957
C7          0.797443               0.797443             0.0739746
C14         0.751673               0.751673             0.0697289
C8          0.654882               0.654882             0.06075
C10         0.586079               0.586079             0.0543675
C16         0.525451               0.525451             0.0487434
C6          0.525397               0.525397             0.0487384
C3          0.514062               0.514062             0.0476869
C5          0.461525               0.461525             0.0428133
C1          0.456079               0.456079             0.0423081
C4          0.450788               0.450788             0.0418172
C2          0.407242               0.407242             0.0377777
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_237

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0012780510357970343  0.00036825600545853376  0.0         0.16213780078396667   2.3692331314086914   0.08004587611860653  1.045907974243164
    3        26       Softmax                 0.0   0.0   0.0016488212608797208  0.00011362702935002744  0.0         -0.04569059718271372  0.45673084259033203  -0.6180780796167245  0.3818650245666504


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5441556413492387
RMSE: 0.7376690595038121
LogLoss: 1.6127881465108458
Mean Per-Class Error: 0.4565638573157746
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    12.0   3.0    4.0    0.0    6.0    2.0    1.0    0.0    0.0    0.0    6.0    0.0    4.0    0.0    0.11139240506329114  44 / 395
2.0    223.0  0.0    11.0   0.0    0.0    1.0    11.0   36.0   2.0    1.0    0.0    7.0    0.0    4.0    4.0    9.0    28.0   33.0   0.0    0.0    0.0    4.0    4.0    0.0    3.0    0.4177545691906005   160 / 383
0.0    0.0    234.0  1.0    51.0   9.0    13.0   0.0    2.0    1.0    4.0    1.0    12.0   0.0    8.0    0.0    11.0   0.0    1.0    4.0    4.0    0.0    3.0    0.0    8.0    1.0    0.3641304347826087   134 / 368
8.0    55.0   0.0    178.0  0.0    0.0    0.0    3.0    13.0   41.0   4.0    3.0    21.0   6.0    24.0   10.0   1.0    20.0   5.0    3.0    0.0    0.0    0.0    6.0    1.0    1.0    0.5583126550868487   225 / 403
0.0    16.0   3.0    0.0    195.0  1.0    13.0   3.0    33.0   2.0    4.0    4.0    0.0    0.0    2.0    5.0    18.0   4.0    12.0   11.0   5.0    2.0    0.0    22.0   7.0    21.0   0.4908616187989556   188 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    50.0   17.0   0.0    0.0    2.0    0.0    0.0    0.0    0.0    15.0   287.0  0.0    0.0    0.0    0.23670212765957446  89 / 376
8.0    22.0   1.0    4.0    23.0   0.0    1.0    1.0    39.0   9.0    2.0    31.0   0.0    0.0    2.0    1.0    20.0   10.0   22.0   38.0   12.0   1.0    1.0    108.0  4.0    34.0   0.7258883248730964   286 / 394
0.0    3.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    11.0   7.0    18.0   5.0    0.0    3.0    112.0  6.0    91.0   7.0    0.0    113.0  1.0    0.712468193384224    280 / 393
7.0    18.0   0.0    1.0    15.0   8.0    0.0    0.0    32.0   2.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    5.0    31.0   3.0    0.0    0.0    0.0    20.0   0.0    218.0  0.40437158469945356  148 / 366
475.0  591.0  380.0  280.0  406.0  346.0  243.0  139.0  562.0  368.0  159.0  370.0  714.0  361.0  408.0  437.0  420.0  484.0  261.0  522.0  282.0  415.0  501.0  256.0  271.0  352.0  0.455963211036689    4,561 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.544037
2    0.715985
3    0.792562
4    0.838349
5    0.869739
6    0.892132
7    0.909627
8    0.924223
9    0.937619
10   0.950415

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.5456374771816517
RMSE: 0.7386727808587857
LogLoss: 1.6129636446719364
Mean Per-Class Error: 0.46185486143159554
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3     4     5     6     7     8      9     10    11    12     13    14    15     16     17     18    19     20    21     22     23    24    25    Error                Rate
-----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  -----  -----  ----  ----  ----  -------------------  -------------
82.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0   0.0    1.0    0.0    0.0   0.0    0.0   0.0    2.0    0.0   2.0   0.0   0.07865168539325842  7 / 89
2.0    56.0   0.0   3.0   0.0   0.0   1.0   5.0   15.0   0.0   0.0   0.0   3.0    0.0   1.0   1.0    3.0    8.0    5.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.4716981132075472   50 / 106
0.0    0.0    51.0  0.0   8.0   3.0   2.0   0.0   0.0    0.0   3.0   0.0   1.0    0.0   4.0   0.0    5.0    0.0    0.0   1.0    0.0   0.0    2.0    0.0   2.0   0.0   0.3780487804878049   31 / 82
4.0    11.0   0.0   55.0  0.0   0.0   0.0   1.0   6.0    6.0   1.0   0.0   9.0    2.0   5.0   3.0    0.0    9.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.5089285714285714   57 / 112
0.0    5.0    0.0   0.0   52.0  1.0   2.0   1.0   7.0    0.0   0.0   0.0   0.0    0.0   1.0   2.0    7.0    1.0    2.0   4.0    1.0   0.0    0.0    6.0   1.0   4.0   0.4639175257731959   45 / 97
---    ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---    ---    ---   ---   ---   ---                  ---
0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   9.0    2.0   0.0   0.0    1.0    0.0    0.0   0.0    0.0   4.0    76.0   0.0   0.0   0.0   0.17391304347826086  16 / 92
1.0    5.0    1.0   2.0   7.0   0.0   0.0   1.0   5.0    1.0   0.0   6.0   0.0    0.0   0.0   0.0    5.0    5.0    5.0   7.0    4.0   1.0    0.0    31.0  2.0   11.0  0.69                 69 / 100
0.0    1.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   3.0    1.0   2.0   5.0    3.0    0.0    0.0   23.0   1.0   28.0   4.0    0.0   35.0  0.0   0.6728971962616822   72 / 107
1.0    2.0    0.0   1.0   4.0   2.0   0.0   0.0   8.0    1.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0    2.0    10.0  1.0    0.0   0.0    0.0    5.0   0.0   49.0  0.4367816091954023   38 / 87
122.0  141.0  88.0  84.0  89.0  78.0  65.0  37.0  133.0  98.0  35.0  92.0  170.0  84.0  88.0  129.0  111.0  122.0  58.0  122.0  75.0  102.0  131.0  69.0  79.0  88.0  0.4634538152610442   1,154 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.536546
2    0.703615
3    0.788353
4    0.836145
5    0.874297
6    0.899598
7    0.916868
8    0.928916
9    0.940562
10   0.955823
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-08-04 09:06:58  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-08-04 09:06:58  6 min 56.613 sec  166783 obs/sec    1         1             10007      0.801946         1.95905             0.98857        0.526842                         0.799754           1.94613               0.988603         0.520884
    2019-08-04 09:06:59  6 min 57.155 sec  170187 obs/sec    10        10            100070     0.737669         1.61279             0.990329       0.455963                         0.738673           1.61296               0.990278         0.463454
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C11         1                      1                    0.0875665
C13         0.957239               0.957239             0.083822
C15         0.949237               0.949237             0.0831213
C12         0.920633               0.920633             0.0806166
C9          0.880597               0.880597             0.0771108
C14         0.819921               0.819921             0.0717975
C7          0.769062               0.769062             0.067344
C8          0.693034               0.693034             0.0606865
C3          0.670371               0.670371             0.058702
C10         0.616409               0.616409             0.0539767
C6          0.570328               0.570328             0.0499416
C16         0.562729               0.562729             0.0492762
C5          0.5473                 0.5473               0.0479251
C1          0.535717               0.535717             0.0469108
C4          0.498485               0.498485             0.0436506
C2          0.428836               0.428836             0.0375516
[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ]
                  activation  ...                 model_ids              logloss
0       RectifierWithDropout  ...   DL_random_grid_model_41   0.3638058298017319
1       RectifierWithDropout  ...   DL_random_grid_model_21  0.37839525497612897
2       RectifierWithDropout  ...  DL_random_grid_model_220  0.38152252927507474
3       RectifierWithDropout  ...  DL_random_grid_model_169  0.38281506906516327
4       RectifierWithDropout  ...  DL_random_grid_model_197   0.3842824549683893
5       RectifierWithDropout  ...  DL_random_grid_model_112  0.38441140401407786
6       RectifierWithDropout  ...   DL_random_grid_model_17  0.38731681338517787
7       RectifierWithDropout  ...   DL_random_grid_model_82  0.38950430587220863
8       RectifierWithDropout  ...    DL_random_grid_model_4   0.3932605111679277
9       RectifierWithDropout  ...  DL_random_grid_model_158  0.39400225138624645
10           TanhWithDropout  ...  DL_random_grid_model_202   0.4235906091966062
11           TanhWithDropout  ...  DL_random_grid_model_122  0.42838937950685774
12           TanhWithDropout  ...  DL_random_grid_model_144   0.4286010326259021
13           TanhWithDropout  ...   DL_random_grid_model_13   0.4289909612045266
14           TanhWithDropout  ...  DL_random_grid_model_178  0.43059831251856706
15      RectifierWithDropout  ...   DL_random_grid_model_26  0.43154334158772156
16      RectifierWithDropout  ...  DL_random_grid_model_232    0.432818182599059
17      RectifierWithDropout  ...    DL_random_grid_model_1  0.43401299703868323
18           TanhWithDropout  ...  DL_random_grid_model_233   0.4349931213969348
19      RectifierWithDropout  ...  DL_random_grid_model_211   0.4352481667440239
20      RectifierWithDropout  ...  DL_random_grid_model_193  0.43714574063347966
21      RectifierWithDropout  ...  DL_random_grid_model_142  0.43827156641252624
22           TanhWithDropout  ...  DL_random_grid_model_166  0.43902965944744293
23           TanhWithDropout  ...  DL_random_grid_model_223  0.43985315043595086
24      RectifierWithDropout  ...   DL_random_grid_model_27   0.4422159351326902
25      RectifierWithDropout  ...   DL_random_grid_model_97   0.4425308965803657
26      RectifierWithDropout  ...   DL_random_grid_model_49   0.4430326500924669
27      RectifierWithDropout  ...  DL_random_grid_model_129    0.443228845893888
28           TanhWithDropout  ...  DL_random_grid_model_172  0.44334054632345943
29      RectifierWithDropout  ...   DL_random_grid_model_88   0.4455514402270114
..  ..                   ...  ...                       ...                  ...
210          TanhWithDropout  ...  DL_random_grid_model_165   1.0492433681511582
211          TanhWithDropout  ...  DL_random_grid_model_203    1.057553428426929
212          TanhWithDropout  ...  DL_random_grid_model_225   1.0656043675268179
213          TanhWithDropout  ...  DL_random_grid_model_154   1.0727498491618053
214          TanhWithDropout  ...  DL_random_grid_model_213   1.0772994392408355
215          TanhWithDropout  ...  DL_random_grid_model_187   1.0857575130947477
216          TanhWithDropout  ...  DL_random_grid_model_218    1.088089623800278
217          TanhWithDropout  ...   DL_random_grid_model_99   1.0941268374877313
218     RectifierWithDropout  ...   DL_random_grid_model_62   1.0942333148141492
219     RectifierWithDropout  ...  DL_random_grid_model_183   1.0975367661931943
220     RectifierWithDropout  ...  DL_random_grid_model_116   1.0979082586561952
221     RectifierWithDropout  ...  DL_random_grid_model_238   1.0985480964010839
222          TanhWithDropout  ...    DL_random_grid_model_6   1.0997903662637836
223     RectifierWithDropout  ...  DL_random_grid_model_155   1.1002175109429364
224     RectifierWithDropout  ...  DL_random_grid_model_146    1.101054800494622
225          TanhWithDropout  ...  DL_random_grid_model_234     1.10410276309141
226     RectifierWithDropout  ...   DL_random_grid_model_14   1.1072491894874914
227     RectifierWithDropout  ...   DL_random_grid_model_23   1.1203295602406074
228     RectifierWithDropout  ...  DL_random_grid_model_141   1.1320542602323138
229     RectifierWithDropout  ...  DL_random_grid_model_119   1.1412737138840272
230          TanhWithDropout  ...   DL_random_grid_model_92   1.3843385629447775
231          TanhWithDropout  ...   DL_random_grid_model_60     1.39331950780146
232          TanhWithDropout  ...   DL_random_grid_model_22   1.4169478750703866
233          TanhWithDropout  ...   DL_random_grid_model_79   1.4243743720287934
234          TanhWithDropout  ...   DL_random_grid_model_86     1.43264684825829
235          TanhWithDropout  ...   DL_random_grid_model_19   1.4581017762576571
236          TanhWithDropout  ...  DL_random_grid_model_110   1.4595122225724821
237          TanhWithDropout  ...  DL_random_grid_model_226    1.508066797282446
238          TanhWithDropout  ...   DL_random_grid_model_59   1.5172097202534973
239          TanhWithDropout  ...  DL_random_grid_model_237   1.6129636446719364

[240 rows x 7 columns]

--- 429.66253304481506 seconds ---
Evalutation of best performing model:
Final acc, selected model:  87.13099169418594
Time consumed:  0.11938743114471435  hours
H2O session _sid_9e33 closed.
