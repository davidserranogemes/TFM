Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmpscs2gwii
  JVM stdout: /tmp/tmpscs2gwii/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmpscs2gwii/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    18 days
H2O cluster name:           H2O_from_python_davidserranogemes_uer3fv
H2O cluster total nodes:    1
H2O cluster free memory:    3.900 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  imdb
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  imdb with  Guided  mode.

deeplearning Grid Build progress: |███████████████████████████████████████| 100%
deeplearning prediction progress: |███████████████████████████████████████| 100%
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_41

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.047340849695903985    0.11212831735610962    0.0         0.02540082212891735    0.07415378093719482  0.06873314649284791     0.10740438103675842
    3        2        Softmax                      0.0   0.0   0.00020355865761700898  4.778530274052173e-05  0.0         -0.021171642029003124  0.25702762603759766  -0.0026462187236102955  0.06305250525474548


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.012999833005769524
RMSE: 0.11401681018941691
LogLoss: 0.06399040773611225
Mean Per-Class Error: 0.011972793089107814
AUC: 0.9970073886117912
pr_auc: 0.6431964092399688
Gini: 0.9940147772235823
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5835499688965075: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      5005  58    0.0115   (58.0/5063.0)
1      62    4902  0.0125   (62.0/4964.0)
Total  5067  4960  0.012    (120.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.58355      0.987908  182
max f2                       0.43891      0.990276  209
max f0point5                 0.687029     0.989668  162
max accuracy                 0.58355      0.988032  182
max precision                0.999987     0.999431  0
max recall                   1.73121e-05  1         399
max specificity              0.999987     0.999802  0
max absolute_mcc             0.58355      0.976062  182
max min_per_class_accuracy   0.577026     0.987712  183
max mean_per_class_accuracy  0.58355      0.988027  182
Gains/Lift Table: Avg response rate: 49.51 %, avg score: 50.00 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.010372                    1                  2.01994    2.01994            1                1            1                           1                   0.0209508       0.0209508                  101.994   101.994
    2        0.0200459                   1                  2.01994    2.01994            1                1            1                           1                   0.0195407       0.0404915                  101.994   101.994
    3        0.0300189                   1                  2.01994    2.01994            1                1            1                           1                   0.020145        0.0606366                  101.994   101.994
    4        0.0400918                   1                  2.01994    2.01994            1                1            1                           1                   0.0203465       0.0809831                  101.994   101.994
    5        0.0500648                   1                  2.01994    2.01994            1                1            1                           1                   0.020145        0.101128                   101.994   101.994
    6        0.10003                     0.999999           2.01591    2.01793            0.998004         1            0.999003                    1                   0.100725        0.201853                   101.591   101.793
    7        0.149995                    0.999968           2.01994    2.0186             1                0.99999      0.999335                    0.999997            0.100927        0.30278                    101.994   101.86
    8        0.20006                     0.999712           2.01994    2.01894            1                0.999876     0.999501                    0.999966            0.101128        0.403908                   101.994   101.894
    9        0.29999                     0.994587           2.01188    2.01659            0.996008         0.998034     0.998338                    0.999323            0.201048        0.604956                   101.188   101.659
    10       0.40002                     0.962766           1.9998     2.01239            0.99003          0.983181     0.99626                     0.995286            0.20004         0.804996                   99.9805   101.239
    11       0.50005                     0.461482           1.86689    1.98328            0.924227         0.853867     0.981851                    0.966997            0.186745        0.991741                   86.6887   98.3283
    12       0.59998                     0.0422914          0.0544296  1.66202            0.0269461        0.145635     0.822806                    0.830194            0.00543916      0.99718                    -94.557   66.2021
    13       0.70001                     0.00455411         0.0120834  1.42625            0.00598205       0.0177336    0.706083                    0.714095            0.0012087       0.998388                   -98.7917  42.6249
    14       0.79994                     0.000114732        0.0120955  1.24959            0.00598802       0.00136472   0.618626                    0.62506             0.0012087       0.999597                   -98.7905  24.959
    15       0.89997                     9.7384e-08         0.0020139  1.11092            0.000997009      2.05098e-05  0.549978                    0.555588            0.00020145      0.999799                   -99.7986  11.0924
    16       1                           6.45099e-47        0.0020139  1                  0.000997009      8.68122e-09  0.495063                    0.500012            0.00020145      1                          -99.7986  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.012155586448506414
RMSE: 0.11025237615809654
LogLoss: 0.06377824730859294
Mean Per-Class Error: 0.010063726818318686
AUC: 0.9971027878831599
pr_auc: 0.6090539368293422
Gini: 0.9942055757663197
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5392400720360899: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3103  25    0.008    (25.0/3128.0)
1      37    3012  0.0121   (37.0/3049.0)
Total  3140  3037  0.01     (62.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.53924      0.989813  185
max f2                       0.473852     0.990099  195
max f0point5                 0.641269     0.991325  170
max accuracy                 0.53924      0.989963  185
max precision                0.999979     0.998312  0
max recall                   9.86739e-06  1         399
max specificity              0.999979     0.999361  0
max absolute_mcc             0.53924      0.979929  185
max min_per_class_accuracy   0.486769     0.989505  192
max mean_per_class_accuracy  0.53924      0.989936  185
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.68 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999999           2.01935     2.01935            0.996764         1            0.996764                    1                   0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999975           2.02591     2.02154            1                0.999992     0.997843                    0.999997            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.999766           2.02591     2.02263            1                0.999898     0.998382                    0.999972            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.995027           2.01606     2.02044            0.995138         0.998304     0.997302                    0.999417            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.96206            2.01608     2.01935            0.995146         0.983495     0.996762                    0.995435            0.201705        0.807806                   101.608   101.935
    11       0.500081                    0.35425            1.84233     1.98394            0.909385         0.835756     0.979281                    0.963489            0.184323        0.992129                   84.2333   98.3936
    12       0.599968                    0.0389845          0.0591027   1.66348            0.0291734        0.130926     0.821101                    0.824878            0.00590357      0.998032                   -94.0897  66.3477
    13       0.700016                    0.00437762         0.00983452  1.42713            0.00485437       0.0173634    0.70444                     0.709465            0.000983929     0.999016                   -99.0165  42.7133
    14       0.799903                    0.000127444        0.00656697  1.24974            0.00324149       0.00134828   0.616879                    0.62104             0.000655953     0.999672                   -99.3433  24.9742
    15       0.899951                    1.48305e-07        0           1.11081            0                2.48207e-05  0.5483                      0.552001            0               0.999672                   -100      11.0807
    16       1                           7.10149e-51        0.00327817  1                  0.00161812       1.14958e-08  0.493605                    0.496774            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:50:12  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:50:23  43 min 41.751 sec  2323 obs/sec      1         1             25000      0.302717         0.428764            0.633413       0.941856        0.628582           2.01994          0.115289                         0.297932           0.397294              0.644888         0.946811          0.607748             2.02591            0.113809
    2019-08-03 16:50:44  44 min  2.967 sec  2428 obs/sec      3         3             75000      0.227773         0.203438            0.792458       0.977085        0.73977            2.01994          0.0628304                        0.217911           0.18751               0.810028         0.980447          0.757677             2.02591            0.0558524
    2019-08-03 16:50:56  44 min 14.851 sec  2399 obs/sec      4         4             100000     0.207255         0.170159            0.828164       0.983756        0.773234           2.01994          0.0502643                        0.199252           0.158142              0.841168         0.985614          0.753496             2.02591            0.0453294
    2019-08-03 16:51:16  44 min 34.280 sec  2498 obs/sec      6         6             150000     0.177334         0.132798            0.874198       0.989664        0.645152           2.01994          0.0331106                        0.17047            0.125301              0.883741         0.990933          0.699611             2.02591            0.0276833
    2019-08-03 16:51:35  44 min 53.349 sec  2562 obs/sec      8         8             200000     0.139397         0.0936985           0.922266       0.994023        0.736092           2.01994          0.0178518                        0.135141           0.0911918             0.926936         0.994608          0.732686             2.02591            0.0165129
    2019-08-03 16:51:53  45 min 11.844 sec  2618 obs/sec      10        10            250000     0.114017         0.0639904           0.947996       0.997007        0.643196           2.01994          0.0119677                        0.110252           0.0637782             0.95137          0.997103          0.609054             2.02591            0.0100372
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C31         1.0                    1.0                  0.002891731058700068
C35         0.9944199323654175     0.9944199323654175   0.0028755950038114987
C36         0.9928751587867737     0.9928751587867737   0.002871127934075475
C34         0.9294261336326599     0.9294261336326599   0.0026876504173930825
C40         0.9239733219146729     0.9239733219146729   0.0026718823523909354
---         ---                    ---                  ---
C447        0.24893823266029358    0.24893823266029358  0.0007198624190816746
C649        0.24711725115776062    0.24711725115776062  0.0007145966303134817
C388        0.24305090308189392    0.24305090308189392  0.0007028378452870127
C247        0.24235694110393524    0.24235694110393524  0.0007008310938817926
C523        0.24010252952575684    0.24010252952575684  0.0006943119419020812

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_197

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.05659702642613095    0.12111559510231018    0.0         0.025421363729127962  0.07665446400642395  0.08037429820276179     0.10261136293411255
    3        2        Softmax                      0.0   0.0   0.0003130455880864247  8.732825517654419e-05  0.0         0.0150375944147072    0.25058770179748535  0.00018500015661136043  0.07861369848251343


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.013084161997216006
RMSE: 0.11438602186113479
LogLoss: 0.06533976320177236
Mean Per-Class Error: 0.010781861053600128
AUC: 0.997084076182808
pr_auc: 0.658411153424447
Gini: 0.9941681523656161
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4675231659397747: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4979  61    0.0121   (61.0/5040.0)
1      47    4921  0.0095   (47.0/4968.0)
Total  5026  4982  0.0108   (108.0/10008.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.467523     0.989146  210
max f2                       0.467523     0.989981  210
max f0point5                 0.600882     0.989634  186
max accuracy                 0.488307     0.989209  206
max precision                0.995762     0.998483  10
max recall                   6.37059e-06  1         399
max specificity              0.999968     0.999206  0
max absolute_mcc             0.467523     0.97842   210
max min_per_class_accuracy   0.515696     0.988889  201
max mean_per_class_accuracy  0.467523     0.989218  210
Gains/Lift Table: Avg response rate: 49.64 %, avg score: 49.39 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100919                   1                  2.01449     2.01449            1                1            1                           1                   0.0203301       0.0203301                  101.449   101.449
    2        0.0200839                   1                  2.01449     2.01449            1                1            1                           1                   0.0201288       0.0404589                  101.449   101.449
    3        0.0300759                   1                  2.01449     2.01449            1                1            1                           1                   0.0201288       0.0605878                  101.449   101.449
    4        0.0400679                   1                  2.01449     2.01449            1                1            1                           1                   0.0201288       0.0807166                  101.449   101.449
    5        0.05006                     1                  1.9742      2.00645            0.98             1            0.996008                    1                   0.0197262       0.100443                   97.4203   100.645
    6        0.10002                     0.999993           2.01046     2.00846            0.998            0.999998     0.997003                    0.999999            0.100443        0.200886                   101.046   100.846
    7        0.15008                     0.999886           2.01047     2.00913            0.998004         0.999962     0.997337                    0.999987            0.100644        0.30153                    101.047   100.913
    8        0.20004                     0.999198           2.01449     2.01047            1                0.999633     0.998002                    0.999899            0.100644        0.402174                   101.449   101.047
    9        0.30006                     0.990775           2.01047     2.01047            0.998002         0.99609      0.998002                    0.998629            0.201087        0.603261                   101.047   101.047
    10       0.39998                     0.946832           2.01046     2.01047            0.998            0.97448      0.998001                    0.992596            0.200886        0.804147                   101.046   101.047
    11       0.5                         0.407785           1.86758     1.98188            0.927073         0.821525     0.983813                    0.958375            0.186795        0.990942                   86.7582   98.1884
    12       0.60002                     0.036019           0.0643994   1.66225            0.031968         0.130646     0.825146                    0.820397            0.00644122      0.997383                   -93.5601  66.225
    13       0.69994                     0.00432745         0.012087    1.42668            0.006            0.0154446    0.708208                    0.705486            0.00120773      0.998591                   -98.7913  42.6681
    14       0.80006                     0.000118505        0.0100524   1.2494             0.00499002       0.00133014   0.620207                    0.617368            0.00100644      0.999597                   -98.9948  24.9403
    15       0.89998                     9.38071e-08        0.00402899  1.11114            0.002            2.23204e-05  0.551571                    0.548827            0.000402576     1                          -99.5971  11.1136
    16       1                           1.44109e-42        0           1                  0                6.80708e-09  0.496403                    0.493933            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.012209777955380478
RMSE: 0.1104978640308512
LogLoss: 0.06589692409775776
Mean Per-Class Error: 0.009534487429948557
AUC: 0.9969239631626319
pr_auc: 0.6671332964556428
Gini: 0.9938479263252638
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45953953254699054: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3094  34    0.0109   (34.0/3128.0)
1      25    3024  0.0082   (25.0/3049.0)
Total  3119  3058  0.0096   (59.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.45954      0.990339  210
max f2                       0.45954      0.991215  210
max f0point5                 0.610986     0.99128   188
max accuracy                 0.507169     0.990448  203
max precision                0.991492     0.998399  16
max recall                   9.1961e-06   1         399
max specificity              0.999985     0.999041  0
max absolute_mcc             0.45954      0.980899  210
max min_per_class_accuracy   0.507169     0.990409  203
max mean_per_class_accuracy  0.45954      0.990466  210
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999997           2.02591     2.01935            1                0.999999     0.996764                    1                   0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999934           2.02591     2.02154            1                0.999978     0.997843                    0.999992            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.999367           2.01935     2.02099            0.996764         0.999733     0.997573                    0.999928            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.991656           2.02591     2.02263            1                0.996732     0.998381                    0.998864            0.202361        0.606756                   102.591   102.263
    10       0.400032                    0.949026           2.01935     2.02181            0.996764         0.975536     0.997977                    0.993029            0.202033        0.80879                    101.935   102.181
    11       0.500081                    0.35833            1.84561     1.98656            0.911003         0.814656     0.980576                    0.957343            0.184651        0.99344                    84.5611   98.6559
    12       0.599968                    0.0357166          0.0394018   1.66238            0.0194489        0.123291     0.820561                    0.818484            0.00393572      0.997376                   -96.0598  66.2383
    13       0.700016                    0.00458761         0.00983452  1.4262             0.00485437       0.0159738    0.703978                    0.703787            0.000983929     0.99836                    -99.0165  42.6196
    14       0.799903                    0.000131916        0.00985045  1.24933            0.00486224       0.00140075   0.616677                    0.616078            0.000983929     0.999344                   -99.015   24.9332
    15       0.899951                    1.60058e-07        0.00655634  1.11117            0.00323625       2.53956e-05  0.54848                     0.54759             0.000655953     1                          -99.3444  11.1171
    16       1                           1.63785e-47        0           1                  0                1.50162e-08  0.493605                    0.492805            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:07:39  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:07:51  4:01:09.412  2175 obs/sec      1         1             25000      0.300885         0.375642            0.637854       0.944867        0.688401           1.99455          0.119804                         0.297342           0.37569               0.646294         0.946504          0.643079             1.99323            0.116561
    2019-08-03 20:08:02  4:01:20.895  2281 obs/sec      2         2             50000      0.256249         0.249712            0.737332       0.966874        0.745284           2.01449          0.0861311                        0.248924           0.233149              0.752108         0.970557          0.759674             2.02591            0.0806217
    2019-08-03 20:08:14  4:01:31.919  2346 obs/sec      3         3             75000      0.230544         0.207083            0.787387       0.97654         0.752212           2.01449          0.0644484                        0.224756           0.195867              0.797907         0.979008          0.774147             1.99323            0.0590902
    2019-08-03 20:08:24  4:01:42.728  2397 obs/sec      4         4             100000     0.210583         0.171962            0.82261        0.983701        0.820403           2.01449          0.052458                         0.206199           0.169097              0.8299           0.984851          0.800363             2.02591            0.0485673
    2019-08-03 20:08:44  4:02:02.559  2479 obs/sec      6         6             150000     0.174851         0.131534            0.877703       0.989711        0.772769           2.01449          0.0309752                        0.171082           0.129029              0.882905         0.990672          0.75668              2.02591            0.0305974
    2019-08-03 20:09:04  4:02:22.256  2530 obs/sec      8         8             200000     0.148326         0.102229            0.911993       0.993365        0.70131            2.01449          0.0225819                        0.141606           0.0995165             0.919778         0.993705          0.690683             2.02591            0.0191031
    2019-08-03 20:09:23  4:02:41.468  2575 obs/sec      10        10            250000     0.114386         0.0653398           0.947661       0.997084        0.658411           2.01449          0.0107914                        0.110498           0.0658969             0.951153         0.996924          0.667133             2.02591            0.00955156
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.003107788651315656
C34         0.9794266223907471     0.9794266223907471   0.0030438509418623883
C40         0.9755316376686096     0.9755316376686096   0.0030317461525458814
C28         0.9354787468910217     0.9354787468910217   0.0029072702331349085
C31         0.9012550115585327     0.9012550115585327   0.0028009100968629684
---         ---                    ---                  ---
C440        0.2311994433403015     0.2311994433403015   0.0007185190062034861
C573        0.22875091433525085    0.22875091433525085  0.0007109094955491725
C814        0.22446171939373016    0.22446171939373016  0.0006975795841866339
C562        0.22158272564411163    0.22158272564411163  0.0006886322800843608
C583        0.21822725236415863    0.21822725236415863  0.0006782041783051298

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_4

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  --------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.07995536841794468     0.17277228832244873     0.0         0.025883825301228496  0.07428425550460815  0.08756798799961214     0.09838798642158508
    3        2        Softmax                      0.0   0.0   0.00030636290239272057  0.00010150563321076334  0.0         0.01681635547180349   0.24557971954345703  0.00034295303833452653  0.047221407294273376


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.012415197900277742
RMSE: 0.11142350694659427
LogLoss: 0.06606254340278257
Mean Per-Class Error: 0.01025656721116519
AUC: 0.9968564077410573
pr_auc: 0.6639075870304473
Gini: 0.9937128154821147
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48165197062682813: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      5002  58    0.0115   (58.0/5060.0)
1      45    4927  0.0091   (45.0/4972.0)
Total  5047  4985  0.0103   (103.0/10032.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.481652     0.989656  205
max f2                       0.436293     0.99064   212
max f0point5                 0.622117     0.989836  181
max accuracy                 0.481652     0.989733  205
max precision                0.99999      0.998189  0
max recall                   1.25297e-05  1         399
max specificity              0.99999      0.999407  0
max absolute_mcc             0.481652     0.979468  205
max min_per_class_accuracy   0.529095     0.989139  196
max mean_per_class_accuracy  0.481652     0.989743  205
Gains/Lift Table: Avg response rate: 49.56 %, avg score: 49.53 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0105662                   1                  2.0177      2.0177             1                1            1                           1                   0.0213194       0.0213194                  101.77    101.77
    2        0.0200359                   1                  1.99646     2.00766            0.989474         1            0.995025                    1                   0.0189059       0.0402253                  99.646    100.766
    3        0.030004                    1                  2.0177      2.011              1                1            0.996678                    1                   0.0201126       0.0603379                  101.77    101.1
    4        0.0400718                   1                  2.0177      2.01268            1                1            0.997512                    1                   0.0203138       0.0806516                  101.77    101.268
    5        0.0500399                   1                  1.99752     2.00966            0.99             1            0.996016                    1                   0.0199115       0.100563                   99.7522   100.966
    6        0.10008                     0.999999           2.01368     2.01167            0.998008         1            0.997012                    1                   0.100764        0.201327                   101.368   101.167
    7        0.15002                     0.999962           2.0177      2.01368            1                0.999988     0.998007                    0.999996            0.100764        0.302092                   101.77    101.368
    8        0.20006                     0.999621           2.00966     2.01267            0.996016         0.999847     0.997509                    0.999959            0.100563        0.402655                   100.966   101.267
    9        0.30004                     0.992614           2.00563     2.01033            0.994018         0.997331     0.996346                    0.999083            0.200523        0.603178                   100.563   101.033
    10       0.40002                     0.953726           2.00362     2.00865            0.993021         0.978558     0.995515                    0.993953            0.200322        0.8035                     100.362   100.865
    11       0.5                         0.406025           1.88493     1.98391            0.934197         0.836268     0.983254                    0.962422            0.188455        0.991955                   88.4929   98.391
    12       0.59998                     0.0336355          0.0623616   1.66371            0.0309073        0.12642      0.824556                    0.823112            0.00623492      0.99819                    -93.7638  66.3705
    13       0.69996                     0.00346095         0.00804666  1.42722            0.00398804       0.013597     0.707348                    0.707483            0.000804505     0.998994                   -99.1953  42.7216
    14       0.79994                     0.000127048        0.00603499  1.24959            0.00299103       0.00112172   0.619315                    0.619199            0.000603379     0.999598                   -99.3965  24.9591
    15       0.89992                     1.2123e-07         0.00201166  1.11099            0.000997009      2.25319e-05  0.55062                     0.550409            0.000201126     0.999799                   -99.7988  11.0986
    16       1                           9.62781e-43        0.00200966  1                  0.000996016      1.07957e-08  0.495614                    0.495324            0.000201126     1                          -99.799   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.01257861156771347
RMSE: 0.11215440948849702
LogLoss: 0.06608252056628768
Mean Per-Class Error: 0.010022310362963305
AUC: 0.9969477645179879
pr_auc: 0.6294961481637312
Gini: 0.9938955290359759
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5049972378183599: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3093  35    0.0112   (35.0/3128.0)
1      27    3022  0.0089   (27.0/3049.0)
Total  3120  3057  0.01     (62.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.504997     0.989846  202
max f2                       0.434041     0.990829  209
max f0point5                 0.619666     0.989188  185
max accuracy                 0.504997     0.989963  202
max precision                0.999312     0.998556  3
max recall                   1.02927e-05  1         399
max specificity              0.999985     0.999361  0
max absolute_mcc             0.504997     0.979926  202
max min_per_class_accuracy   0.560846     0.98913   197
max mean_per_class_accuracy  0.504997     0.989978  202
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.43 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  1.9927      2.00957            0.983607         1            0.991935                    1                   0.0196786       0.0403411                  99.2698   100.957
    3        0.0301117                   1                  2.02591     2.01502            1                1            0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999999           2.02591     2.01935            1                1            0.996764                    1                   0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999971           2.02591     2.02154            1                0.999989     0.997843                    0.999996            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.999693           2.02591     2.02263            1                0.999876     0.998382                    0.999966            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.992967           2.01934     2.02154            0.996759         0.997533     0.997841                    0.999156            0.201705        0.606428                   101.934   102.154
    10       0.400032                    0.955579           2.00296     2.01689            0.988673         0.978627     0.995548                    0.994022            0.200394        0.806822                   100.296   101.689
    11       0.500081                    0.365135           1.85545     1.98459            0.915858         0.828601     0.979605                    0.960927            0.185635        0.992457                   85.5445   98.4592
    12       0.599968                    0.0353384          0.0591027   1.66402            0.0291734        0.122181     0.821371                    0.821287            0.00590357      0.99836                    -94.0897  66.4023
    13       0.700016                    0.00390906         0.00327817  1.42666            0.00161812       0.0144652    0.704209                    0.705973            0.000327976     0.998688                   -99.6722  42.6664
    14       0.799903                    0.000148989        0.00985045  1.24974            0.00486224       0.00125267   0.616879                    0.617972            0.000983929     0.999672                   -99.015   24.9742
    15       0.899951                    1.76083e-07        0.00327817  1.11117            0.00161812       2.69928e-05  0.54848                     0.549275            0.000327976     1                          -99.6722  11.1171
    16       1                           2.44165e-46        0           1                  0                1.51988e-08  0.493605                    0.494321            0               1                          -100      0

Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:12:17  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:12:28  5 min 46.907 sec  2252 obs/sec      1         1             25000      0.306908         0.408886            0.623202       0.944437        0.665414           2.0177           0.118222                         0.301111           0.397212              0.637268         0.947624          0.687073             2.02591            0.115914
    2019-08-03 16:12:40  5 min 58.354 sec  2326 obs/sec      2         2             50000      0.254062         0.25535             0.741791       0.966472        0.743276           2.0177           0.0804426                        0.247876           0.238256              0.754189         0.969735          0.74369              2.02591            0.0778695
    2019-08-03 16:12:51  6 min  9.460 sec  2376 obs/sec      3         3             75000      0.222092         0.19616             0.802685       0.978229        0.727641           2.0177           0.0572169                        0.219345           0.187215              0.807519         0.980269          0.765987             1.99323            0.0560142
    2019-08-03 16:13:02  6 min 20.268 sec  2420 obs/sec      4         4             100000     0.203571         0.163464            0.834223       0.984711        0.776385           2.0177           0.0469498                        0.198665           0.157146              0.842104         0.985893          0.769434             2.02591            0.0435486
    2019-08-03 16:13:12  6 min 30.757 sec  2456 obs/sec      5         5             125000     0.1765           0.133281            0.875382       0.989803        0.738707           2.0177           0.0320973                        0.17215            0.125317              0.881438         0.990706          0.751458             2.02591            0.0297879
    2019-08-03 16:13:23  6 min 41.332 sec  2483 obs/sec      6         6             150000     0.157824         0.106076            0.900358       0.993388        0.731553           2.0177           0.0246212                        0.15718            0.105841              0.901162         0.993408          0.741026             2.02591            0.0257407
    2019-08-03 16:13:42  7 min  0.760 sec  2539 obs/sec      8         8             200000     0.131994         0.0821752           0.930305       0.995668        0.66042            2.0177           0.0161483                        0.126391           0.0766449             0.936091         0.996253          0.637917             2.02591            0.0135988
    2019-08-03 16:14:01  7 min 19.682 sec  2587 obs/sec      10        10            250000     0.111424         0.0660625           0.950335       0.996856        0.663908           2.0177           0.0102671                        0.112154           0.0660825             0.949677         0.996948          0.629496             2.02591            0.0100372
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.002869848766488051
C28         0.9574391841888428     0.9574391841888428   0.0027477056617316764
C36         0.9180998206138611     0.9180998206138611   0.00263480763770159
C31         0.9045032858848572     0.9045032858848572   0.002595787639281046
C34         0.890967845916748      0.890967845916748    0.002556942973584695
---         ---                    ---                  ---
C752        0.2510663568973541     0.2510663568973541   0.0007205224746485205
C523        0.25052401423454285    0.25052401423454285  0.0007189660332266377
C631        0.2453419715166092     0.2453419715166092   0.0007040943543246874
C985        0.2421126365661621     0.2421126365661621   0.0006948266514005702
C773        0.23766487836837769    0.23766487836837769  0.0006820622580230213

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_169

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  --------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.045880130298382706    0.10366833209991455    0.0         0.025661556660387996   0.07414042949676514  0.07441148189765104    0.10210701823234558
    3        2        Softmax                      0.0   0.0   0.00020953034641024715  7.949498831294477e-05  0.0         -0.013838334314073109  0.26051807403564453  3.767662698312031e-05  0.025798022747039795


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.013793220158201348
RMSE: 0.11744454077649309
LogLoss: 0.07570522796389116
Mean Per-Class Error: 0.012126530075023068
AUC: 0.9954563602062834
pr_auc: 0.6295540253019867
Gini: 0.9909127204125667
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48262683759999786: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4972  88    0.0174   (88.0/5060.0)
1      34    4921  0.0069   (34.0/4955.0)
Total  5006  5009  0.0122   (122.0/10015.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.482627     0.987756  207
max f2                       0.425036     0.991145  216
max f0point5                 0.663488     0.987032  168
max accuracy                 0.482627     0.987818  207
max precision                0.99941      0.994485  2
max recall                   1.31371e-05  1         399
max specificity              0.999989     0.997826  0
max absolute_mcc             0.482627     0.975693  207
max min_per_class_accuracy   0.599134     0.985968  184
max mean_per_class_accuracy  0.482627     0.987873  207
Gains/Lift Table: Avg response rate: 49.48 %, avg score: 49.75 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0128807                   1                  2.02119     2.02119            1                1            1                           1                   0.0260343       0.0260343                  102.119   102.119
    2        0.0200699                   1                  2.02119     2.02119            1                1            1                           1                   0.0145308       0.0405651                  102.119   102.119
    3        0.0300549                   1                  2.02119     2.02119            1                1            1                           1                   0.0201816       0.0607467                  102.119   102.119
    4        0.0400399                   1                  2.00098     2.01615            0.99             1            0.997506                    1                   0.0199798       0.0807265                  100.098   101.615
    5        0.050025                    1                  2.02119     2.01716            1                1            0.998004                    1                   0.0201816       0.100908                   102.119   101.716
    6        0.10005                     0.999999           2.00505     2.0111             0.992016         1            0.99501                     1                   0.100303        0.201211                   100.505   101.11
    7        0.150075                    0.99998            2.01312     2.01178            0.996008         0.999994     0.995343                    0.999998            0.100706        0.301917                   101.312   101.178
    8        0.2                         0.999764           1.99694     2.00807            0.988            0.999905     0.99351                     0.999975            0.0996973       0.401615                   99.6936   100.807
    9        0.30005                     0.99499            2.00707     2.00774            0.993014         0.998244     0.993344                    0.999397            0.200807        0.602422                   100.707   100.774
    10       0.4                         0.95733            2.00706     2.00757            0.993007         0.982044     0.99326                     0.995061            0.200605        0.803027                   100.706   100.757
    11       0.50005                     0.482714           1.89814     1.98567            0.939122         0.842841     0.982428                    0.964605            0.189909        0.992936                   89.8144   98.5675
    12       0.6                         0.0366578          0.0484601   1.66297            0.023976         0.135282     0.822766                    0.826453            0.00484359      0.99778                    -95.154   66.2967
    13       0.69995                     0.00392613         0.0141342   1.42752            0.00699301       0.0152922    0.706277                    0.710623            0.00141271      0.999193                   -98.5866  42.752
    14       0.8                         0.000119383        0.00806863  1.25               0.00399202       0.00130119   0.618447                    0.621913            0.000807265     1                          -99.1931  25
    15       0.89995                     1.05865e-07        0           1.11117            0                2.13167e-05  0.549761                    0.552845            0               1                          -100      11.1173
    16       1                           1.15057e-42        0           1                  0                9.33152e-09  0.494758                    0.497533            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.013336859891145969
RMSE: 0.11548532327160005
LogLoss: 0.06609029688119879
Mean Per-Class Error: 0.011952893867344883
AUC: 0.9968683917162057
pr_auc: 0.6375855847678917
Gini: 0.9937367834324113
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5414987254297081: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3084  44    0.0141   (44.0/3128.0)
1      30    3019  0.0098   (30.0/3049.0)
Total  3114  3063  0.012    (74.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.541499     0.987893  195
max f2                       0.436404     0.991103  212
max f0point5                 0.590173     0.986933  185
max accuracy                 0.541499     0.98802   195
max precision                0.999279     0.997967  3
max recall                   1.91461e-05  1         399
max specificity              0.999992     0.999041  0
max absolute_mcc             0.541499     0.976048  195
max min_per_class_accuracy   0.564794     0.986893  189
max mean_per_class_accuracy  0.541499     0.988047  195
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.58 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.011818                    1                  2.02591     2.02591            1                1            1                           1                   0.0239423       0.0239423                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0167268       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    1                  2.01935     2.02263            0.996764         1            0.998382                    1                   0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999982           2.02591     2.02372            1                0.999995     0.998921                    0.999998            0.101345        0.303706                   102.591   102.372
    8        0.200097                    0.9998             2.0128      2.02099            0.993528         0.999921     0.997573                    0.999979            0.100689        0.404395                   101.28    102.099
    9        0.299984                    0.994895           2.01606     2.01935            0.995138         0.998248     0.996762                    0.999402            0.201378        0.605772                   101.606   101.935
    10       0.400032                    0.955724           2.01608     2.01853            0.995146         0.981764     0.996358                    0.994991            0.201705        0.807478                   101.608   101.853
    11       0.500081                    0.436652           1.85872     1.98656            0.917476         0.82886      0.980576                    0.961754            0.185963        0.99344                    85.8723   98.6559
    12       0.599968                    0.0369936          0.0459688   1.66348            0.0226904        0.130902     0.821101                    0.823428            0.00459167      0.998032                   -95.4031  66.3477
    13       0.700016                    0.00415163         0.00983452  1.42713            0.00485437       0.0160689    0.70444                     0.708038            0.000983929     0.999016                   -99.0165  42.7133
    14       0.799903                    0.000153563        0.00656697  1.24974            0.00324149       0.00140397   0.616879                    0.619798            0.000655953     0.999672                   -99.3433  24.9742
    15       0.899951                    1.7717e-07         0           1.11081            0                3.10578e-05  0.5483                      0.550898            0               0.999672                   -100      11.0807
    16       1                           7.63107e-42        0.00327817  1                  0.00161812       1.71435e-08  0.493605                    0.495781            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:30:02  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:30:14  3:23:32.147  2245 obs/sec      1         1             25000      0.312634         0.461355            0.608996       0.94119         0.625625           2.00118          0.116725                         0.303515           0.414932              0.631454         0.94762           0.597328             2.02591            0.111057
    2019-08-03 19:30:35  3:23:53.298  2406 obs/sec      3         3             75000      0.23386          0.209433            0.781214       0.97575         0.746772           2.02119          0.0682976                        0.224905           0.200929              0.797638         0.978174          0.755511             2.02591            0.0605472
    2019-08-03 19:30:55  3:24:13.027  2509 obs/sec      5         5             125000     0.186592         0.146287            0.860718       0.987334        0.729784           2.02119          0.0378432                        0.180565           0.13542               0.869563         0.989666          0.728344             2.02591            0.0348065
    2019-08-03 19:31:14  3:24:32.396  2572 obs/sec      7         7             175000     0.155179         0.114047            0.903667       0.991732        0.700235           2.00118          0.0232651                        0.149601           0.106298              0.910463         0.993331          0.691449             1.99323            0.0208839
    2019-08-03 19:31:33  3:24:51.403  2618 obs/sec      9         9             225000     0.12626          0.0745063           0.936227       0.99622         0.613341           2.02119          0.014678                         0.122728           0.0779176             0.939742         0.996045          0.632818             2.02591            0.0139226
    2019-08-03 19:31:43  3:25:01.458  2637 obs/sec      10        10            250000     0.117445         0.0757052           0.944821       0.995456        0.629554           2.02119          0.0121817                        0.115485           0.0660903             0.946644         0.996868          0.637586             2.02591            0.0119799
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0028577967861617573
C29         0.9714539051055908     0.9714539051055908   0.0027762178479150464
C38         0.9558403491973877     0.9558403491973877   0.0027315974780200264
C40         0.9496367573738098     0.9496367573738098   0.0027138688732439463
C35         0.9232317805290222     0.9232317805290222   0.002638408815278237
---         ---                    ---                  ---
C562        0.25041723251342773    0.25041723251342773  0.0007156415622763953
C482        0.24904905259609222    0.24904905259609222  0.0007117315821057429
C832        0.2481919676065445     0.2481919676065445   0.0007092822073771459
C633        0.2478584200143814     0.2478584200143814   0.0007083289961402302
C588        0.23365482687950134    0.23365482687950134  0.0006677380133274207

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_158

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.055213084367047645    0.12382972240447998    0.0         0.025546741937321187  0.07418441772460938  0.0855676520609523      0.09978911280632019
    3        2        Softmax                      0.0   0.0   0.00022590175254322276  5.801510997116566e-05  0.0         -0.01844317179313748  0.2579137086868286   -0.0004548130504676319  0.0581909716129303


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.012195463197505337
RMSE: 0.11043307112231071
LogLoss: 0.059252036395066675
Mean Per-Class Error: 0.010786980764792009
AUC: 0.9975715704334868
pr_auc: 0.6751737543291724
Gini: 0.9951431408669735
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48197710035456187: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4980  47    0.0093   (47.0/5027.0)
1      61    4929  0.0122   (61.0/4990.0)
Total  5041  4976  0.0108   (108.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.481977     0.989163  209
max f2                       0.362005     0.98936   233
max f0point5                 0.531477     0.990973  200
max accuracy                 0.528563     0.989218  201
max precision                0.999985     0.999379  0
max recall                   1.36365e-05  1         399
max specificity              0.999985     0.999801  0
max absolute_mcc             0.528563     0.978453  201
max min_per_class_accuracy   0.466522     0.988978  213
max mean_per_class_accuracy  0.481977     0.989213  209
Gains/Lift Table: Avg response rate: 49.82 %, avg score: 49.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   1                  2.00741     2.00741            1                1            1                           1                   0.0202405       0.0202405                  100.741   100.741
    2        0.0200659                   1                  2.00741     2.00741            1                1            1                           1                   0.0200401       0.0402806                  100.741   100.741
    3        0.0300489                   1                  2.00741     2.00741            1                1            1                           1                   0.0200401       0.0603206                  100.741   100.741
    4        0.0400319                   1                  2.00741     2.00741            1                1            1                           1                   0.0200401       0.0803607                  100.741   100.741
    5        0.050015                    1                  2.00741     2.00741            1                1            1                           1                   0.0200401       0.100401                   100.741   100.741
    6        0.10003                     0.999997           2.00341     2.00541            0.998004         0.999999     0.999002                    1                   0.1002          0.200601                   100.341   100.541
    7        0.150045                    0.999928           2.00741     2.00608            1                0.999975     0.999335                    0.999991            0.100401        0.301002                   100.741   100.608
    8        0.20006                     0.999476           2.00341     2.00541            0.998004         0.999764     0.999002                    0.999935            0.1002          0.401202                   100.341   100.541
    9        0.29999                     0.991855           2.0014      2.00407            0.997003         0.996897     0.998336                    0.998923            0.2             0.601202                   100.14    100.407
    10       0.40002                     0.951487           1.9974      2.00241            0.99501          0.976706     0.997504                    0.993367            0.1998          0.801002                   99.7398   100.241
    11       0.50005                     0.426092           1.88521     1.97896            0.939122         0.828363     0.985826                    0.96036             0.188577        0.989579                   88.5207   97.8961
    12       0.59998                     0.0316564          0.0822218   1.66305            0.040959         0.123585     0.828453                    0.82099             0.00821643      0.997796                   -91.7778  66.3048
    13       0.70001                     0.00351585         0.0120204   1.42712            0.00598802       0.0138227    0.710924                    0.705648            0.0012024       0.998998                   -98.798   42.712
    14       0.79994                     8.94696e-05        0.00601623  1.24959            0.002997         0.00106712   0.622488                    0.61763             0.000601202     0.999599                   -99.3984  24.9593
    15       0.89997                     9.53086e-08        0.00400682  1.11115            0.00199601       1.83613e-05  0.553522                    0.548984            0.000400802     1                          -99.5993  11.1148
    16       1                           3.03889e-53        0           1                  0                8.26322e-09  0.498153                    0.494069            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.013210795124875946
RMSE: 0.11493822308038325
LogLoss: 0.06756562145186505
Mean Per-Class Error: 0.01104351432988393
AUC: 0.9966703791188928
pr_auc: 0.6758246549701835
Gini: 0.9933407582377856
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5107427191053745: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3102  26    0.0083   (26.0/3128.0)
1      42    3007  0.0138   (42.0/3049.0)
Total  3144  3033  0.011    (68.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.510743     0.988819  204
max f2                       0.28963      0.987453  246
max f0point5                 0.532555     0.990824  200
max accuracy                 0.510743     0.988991  204
max precision                0.993494     0.998878  14
max recall                   1.01925e-05  1         399
max specificity              0.999987     0.999361  0
max absolute_mcc             0.510743     0.977991  204
max min_per_class_accuracy   0.4598       0.987209  214
max mean_per_class_accuracy  0.510743     0.988956  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.91 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999997           2.01935     2.02263            0.996764         0.999999     0.998382                    1                   0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999936           2.01935     2.02154            0.996764         0.999978     0.997843                    0.999992            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.999462           2.02591     2.02263            1                0.999782     0.998382                    0.99994             0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.991376           2.02263     2.02263            0.998379         0.996602     0.998381                    0.998828            0.202033        0.606756                   102.263   102.263
    10       0.400032                    0.946216           2.01608     2.02099            0.995146         0.975181     0.997572                    0.992914            0.201705        0.808462                   101.608   102.099
    11       0.500081                    0.327718           1.80627     1.97803            0.891586         0.798002     0.976368                    0.953919            0.180715        0.989177                   80.6273   97.8033
    12       0.599968                    0.0307709          0.0820871   1.66238            0.0405186        0.106024     0.820561                    0.812756            0.00819941      0.997376                   -91.7913  66.2383
    13       0.700016                    0.00326934         0.00655634  1.42573            0.00323625       0.0133671    0.703747                    0.698505            0.000655953     0.998032                   -99.3444  42.5727
    14       0.799903                    0.00011597         0.0131339   1.24933            0.00648298       0.0010811    0.616677                    0.611415            0.00131191      0.999344                   -98.6866  24.9332
    15       0.899951                    1.23906e-07        0.00327817  1.11081            0.00161812       2.11882e-05  0.5483                      0.543446            0.000327976     0.999672                   -99.6722  11.0807
    16       1                           2.02635e-45        0.00327817  1                  0.00161812       1.05928e-08  0.493605                    0.489075            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:09:31  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:09:42  3:03:00.869  2218 obs/sec      1         1             25000      0.317684         0.489598            0.596303       0.934184        0.580071           1.98754          0.128681                         0.310712           0.460598              0.61377          0.939521          0.58012              2.02591            0.121904
    2019-08-03 19:09:54  3:03:12.576  2295 obs/sec      2         2             50000      0.259356         0.270773            0.730934       0.964097        0.743712           2.00741          0.0857542                        0.253615           0.261044              0.742676         0.966873          0.710605             2.02591            0.0794884
    2019-08-03 19:10:15  3:03:33.319  2417 obs/sec      4         4             100000     0.21204          0.183024            0.820154       0.98195         0.729207           2.00741          0.0520116                        0.210696           0.187761              0.8224           0.981048          0.717222             2.02591            0.0484054
    2019-08-03 19:10:35  3:03:53.464  2485 obs/sec      6         6             150000     0.162417         0.119004            0.894481       0.991595        0.755203           2.00741          0.026455                         0.155247           0.113607              0.903578         0.992577          0.727719             2.02591            0.0228266
    2019-08-03 19:10:55  3:04:13.293  2530 obs/sec      8         8             200000     0.129031         0.0782303           0.933403       0.996203        0.637006           2.00741          0.0143756                        0.131784           0.0845498             0.93052          0.995297          0.659793             2.02591            0.0144083
    2019-08-03 19:11:14  3:04:32.351  2579 obs/sec      10        10            250000     0.110433         0.059252            0.951217       0.997572        0.675174           2.00741          0.0107817                        0.114938           0.0675656             0.947148         0.99667           0.675825             2.02591            0.0110086
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.002800300258291884
C36         0.986390233039856      0.986390233039856    0.0027621888243581
C38         0.97343510389328       0.97343510389328     0.002725910572862739
C31         0.9710744619369507     0.9710744619369507   0.002719300066582695
C28         0.9596034288406372     0.9596034288406372   0.0026871777296402135
---         ---                    ---                  ---
C726        0.25625327229499817    0.25625327229499817  0.0007175861045958237
C314        0.2511870265007019     0.2511870265007019   0.0007033990951894858
C477        0.25093528628349304    0.25093528628349304  0.0007026941469942134
C446        0.24901333451271057    0.24901333451271057  0.0006973121049540667
C533        0.24567124247550964    0.24567124247550964  0.0006879532437590577

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_82

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.04233256966812259     0.10126039385795593    0.0         0.024817116086198618  0.07613566517829895  0.07689396145922817     0.10950994491577148
    3        2        Softmax                      0.0   0.0   0.00022333570360899557  6.552319973707199e-05  0.0         0.014860355749078735  0.25029659271240234  0.00010935968863711593  0.05203631520271301


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01334029047976858
RMSE: 0.11550017523696049
LogLoss: 0.06599317732968976
Mean Per-Class Error: 0.011464525918039703
AUC: 0.9968981446584473
pr_auc: 0.6574063559424028
Gini: 0.9937962893168946
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47667117403584036: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4949  56    0.0112   (56.0/5005.0)
1      59    4964  0.0117   (59.0/5023.0)
Total  5008  5020  0.0115   (115.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.476671     0.988549  209
max f2                       0.380742     0.989629  228
max f0point5                 0.61282      0.989866  186
max accuracy                 0.516949     0.988532  202
max precision                0.998676     0.99873   4
max recall                   1.9314e-05   1         399
max specificity              0.99998      0.999401  0
max absolute_mcc             0.516949     0.977071  202
max min_per_class_accuracy   0.476671     0.988254  209
max mean_per_class_accuracy  0.516949     0.988535  202
Gains/Lift Table: Avg response rate: 50.09 %, avg score: 49.52 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0102712                   1                  1.99642     1.99642            1                1            1                           1                   0.0205057       0.0205057                  99.6416   99.6416
    2        0.0200439                   1                  1.99642     1.99642            1                1            1                           1                   0.0195103       0.0400159                  99.6416   99.6416
    3        0.030016                    1                  1.99642     1.99642            1                1            1                           1                   0.0199084       0.0599243                  99.6416   99.6416
    4        0.0400878                   1                  1.99642     1.99642            1                1            1                           1                   0.0201075       0.0800319                  99.6416   99.6416
    5        0.0500598                   1                  1.99642     1.99642            1                1            1                           1                   0.0199084       0.0999403                  99.6416   99.6416
    6        0.10002                     0.999998           1.99642     1.99642            1                1            1                           1                   0.0997412       0.199681                   99.6416   99.6416
    7        0.15008                     0.999937           1.98449     1.99244            0.994024         0.999979     0.998007                    0.999993            0.099343        0.299024                   98.4486   99.2437
    8        0.20004                     0.99952            1.99642     1.99343            1                0.999784     0.998504                    0.999941            0.0997412       0.398766                   99.6416   99.3431
    9        0.30006                     0.991652           1.99244     1.9931             0.998006         0.997009     0.998338                    0.998963            0.199283        0.598049                   99.2436   99.3099
    10       0.39998                     0.942286           1.98048     1.98995            0.992016         0.973818     0.996759                    0.992682            0.19789         0.795939                   98.0477   98.9946
    11       0.5                         0.488042           1.91879     1.97571            0.961117         0.827783     0.989629                    0.959695            0.191917        0.987856                   91.8789   97.5712
    12       0.60002                     0.03372            0.0955414   1.6623             0.0478564        0.137897     0.832641                    0.822706            0.00955604      0.997412                   -90.4459  66.2298
    13       0.69994                     0.00371217         0.0119546   1.4267             0.00598802       0.014073     0.714632                    0.707269            0.00119451      0.998606                   -98.8045  42.6703
    14       0.79996                     0.000118835        0.00796178  1.24932            0.00398804       0.00127265   0.625779                    0.618998            0.000796337     0.999403                   -99.2038  24.9316
    15       0.89998                     1.29063e-07        0.00398089  1.11091            0.00199402       2.18209e-05  0.556454                    0.550208            0.000398168     0.999801                   -99.6019  11.0915
    16       1                           1.98376e-46        0.00199045  1                  0.000997009      1.06527e-08  0.500897                    0.495176            0.000199084     1                          -99.801   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.013918676023122592
RMSE: 0.11797743861909611
LogLoss: 0.06880190470230817
Mean Per-Class Error: 0.011981885386093571
AUC: 0.9965373746287198
pr_auc: 0.6700656754811563
Gini: 0.9930747492574397
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5016705524500297: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3091  37    0.0118   (37.0/3128.0)
1      37    3012  0.0121   (37.0/3049.0)
Total  3128  3049  0.012    (74.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.501671     0.987865  213
max f2                       0.374369     0.990773  232
max f0point5                 0.530836     0.988682  206
max accuracy                 0.501671     0.98802   213
max precision                0.999125     0.99855   3
max recall                   5.23662e-06  1         399
max specificity              0.999987     0.999361  0
max absolute_mcc             0.501671     0.976036  213
max min_per_class_accuracy   0.501671     0.987865  213
max mean_per_class_accuracy  0.501671     0.988018  213
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.82 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0108467                   1                  2.02591     2.02591            1                1            1                           1                   0.0219744       0.0219744                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0186947       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999998           2.01935     2.02263            0.996764         1            0.998382                    1                   0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999946           2.01935     2.02154            0.996764         0.999982     0.997843                    0.999994            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.999537           2.02591     2.02263            1                0.999803     0.998382                    0.999946            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.990638           2.01606     2.02044            0.995138         0.996626     0.997302                    0.998841            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.937046           2.00624     2.01689            0.990291         0.970839     0.995548                    0.991837            0.200722        0.806822                   100.624   101.689
    11       0.500081                    0.361658           1.862       1.9859             0.919094         0.792005     0.980253                    0.951858            0.186291        0.993112                   86.2002   98.5903
    12       0.599968                    0.0287101          0.0459688   1.66293            0.0226904        0.109035     0.820831                    0.811539            0.00459167      0.997704                   -95.4031  66.293
    13       0.700016                    0.00332763         0.00983452  1.42666            0.00485437       0.0122826    0.704209                    0.697307            0.000983929     0.998688                   -99.0165  42.6664
    14       0.799903                    0.000116837        0.00656697  1.24933            0.00324149       0.00118959   0.616677                    0.61038             0.000655953     0.999344                   -99.3433  24.9332
    15       0.899951                    1.53019e-07        0.00655634  1.11117            0.00323625       2.09003e-05  0.54848                     0.542526            0.000655953     1                          -99.3444  11.1171
    16       1                           6.10242e-46        0           1                  0                1.38377e-08  0.493605                    0.488247            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:38:36  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:38:47  1:32:05.393  2315 obs/sec      1         1             25000      0.312206         0.438268            0.610109       0.938374        0.653451           1.99642          0.123953                         0.305109           0.436251              0.627573         0.941495          0.647625             1.99323            0.119799
    2019-08-03 17:39:08  1:32:26.600  2427 obs/sec      3         3             75000      0.242201         0.225519            0.765354       0.972591        0.748545           1.99642          0.0738931                        0.235855           0.22336               0.777454         0.974257          0.737642             1.99323            0.068318
    2019-08-03 17:39:28  1:32:46.744  2503 obs/sec      5         5             125000     0.188798         0.144743            0.85742        0.987958        0.783461           1.99642          0.0379936                        0.186221           0.146554              0.861264         0.987918          0.750451             2.02591            0.0364254
    2019-08-03 17:39:48  1:33:06.486  2552 obs/sec      7         7             175000     0.155019         0.10677             0.903876       0.992785        0.733652           1.99642          0.0236338                        0.149437           0.110022              0.910659         0.993531          0.725325             2.02591            0.0212077
    2019-08-03 17:40:07  1:33:25.621  2597 obs/sec      9         9             225000     0.120521         0.072333            0.941898       0.996364        0.634114           1.99642          0.0127643                        0.121148           0.0739835             0.941283         0.996332          0.634335             2.02591            0.0127894
    2019-08-03 17:40:17  1:33:35.643  2616 obs/sec      10        10            250000     0.1155           0.0659932           0.946639       0.996898        0.657406           1.99642          0.0114679                        0.117977           0.0688019             0.944316         0.996537          0.670066             2.02591            0.0119799
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0030492762967198536
C40         0.9231289029121399     0.9231289029121399   0.0028148750824669912
C35         0.9067456126213074     0.9067456126213074   0.002764917903720875
C28         0.8981406092643738     0.8981406092643738   0.0027386788709513827
C38         0.858165979385376      0.858165979385376    0.0026167851795912056
---         ---                    ---                  ---
C462        0.239591583609581      0.239591583609581    0.0007305809367942683
C468        0.23640049993991852    0.23640049993991852  0.0007208504409995167
C426        0.2353697568178177     0.2353697568178177   0.0007177074204292877
C854        0.23346027731895447    0.23346027731895447  0.0007118848898543315
C901        0.2315877377986908     0.2315877377986908   0.0007061749994805203

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_17

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.04441225743477904    0.10304906964302063    0.0         0.02494265409640226    0.0761168897151947  0.08904214971724353     0.10271573066711426
    3        2        Softmax                      0.0   0.0   0.0002578160599000512  6.341063999570906e-05  0.0         -0.010327097133256302  0.2612971067428589  0.00043940321473983496  0.06332617998123169


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.014422381756940638
RMSE: 0.12009322111152085
LogLoss: 0.07067331314501714
Mean Per-Class Error: 0.013347813923620055
AUC: 0.9963660434131594
pr_auc: 0.6054494650887314
Gini: 0.9927320868263187
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5256324497175914: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4933  60    0.012    (60.0/4993.0)
1      74    4966  0.0147   (74.0/5040.0)
Total  5007  5026  0.0134   (134.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525632     0.986688  188
max f2                       0.450066     0.986558  201
max f0point5                 0.635176     0.989174  168
max accuracy                 0.538094     0.986644  185
max precision                0.997731     0.999643  5
max recall                   1.06654e-05  1         399
max specificity              0.999976     0.9998    0
max absolute_mcc             0.538094     0.973294  185
max min_per_class_accuracy   0.498493     0.98631   193
max mean_per_class_accuracy  0.538094     0.986652  185
Gains/Lift Table: Avg response rate: 50.23 %, avg score: 50.46 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101665                   1                  1.99067     1.99067            1                1            1                           1                   0.0202381       0.0202381                  99.0675   99.0675
    2        0.0200339                   1                  1.99067     1.99067            1                1            1                           1                   0.0196429       0.039881                   99.0675   99.0675
    3        0.030001                    1                  1.99067     1.99067            1                1            1                           1                   0.0198413       0.0597222                  99.0675   99.0675
    4        0.0400678                   1                  1.99067     1.99067            1                1            1                           1                   0.0200397       0.0797619                  99.0675   99.0675
    5        0.0500349                   1                  1.97077     1.98671            0.99             1            0.998008                    1                   0.0196429       0.0994048                  97.0768   98.6709
    6        0.10007                     0.999999           1.99067     1.98869            1                1            0.999004                    1                   0.0996032       0.199008                   99.0675   98.8692
    7        0.150005                    0.999975           1.99067     1.98935            1                0.999991     0.999336                    0.999997            0.0994048       0.298413                   99.0675   98.9352
    8        0.20004                     0.999762           1.99067     1.98968            1                0.9999       0.999502                    0.999973            0.0996032       0.398016                   99.0675   98.9683
    9        0.30001                     0.995918           1.98869     1.98935            0.999003         0.998509     0.999336                    0.999485            0.19881         0.596825                   98.869    98.9352
    10       0.39998                     0.969591           1.98472     1.98819            0.997009         0.986539     0.998754                    0.996249            0.198413        0.795238                   98.472    98.8194
    11       0.50005                     0.549167           1.88757     1.96806            0.948207         0.874474     0.988639                    0.97188             0.188889        0.984127                   88.7572   96.8058
    12       0.60002                     0.0484683          0.111144    1.65868            0.0558325        0.163525     0.833223                    0.837199            0.0111111       0.995238                   -88.8856  65.8675
    13       0.69999                     0.00540377         0.0258014   1.42547            0.0129611        0.0208752    0.716076                    0.720614            0.00257937      0.997817                   -97.4199  42.5474
    14       0.79996                     0.000134111        0.0099236   1.24857            0.00498504       0.00171582   0.627212                    0.630774            0.000992063     0.99881                    -99.0076  24.8574
    15       0.89993                     1.13486e-07        0.00793888  1.11076            0.00398804       2.31158e-05  0.55798                     0.560706            0.000793651     0.999603                   -99.2061  11.0756
    16       1                           8.17447e-47        0.00396549  1                  0.00199203       9.00394e-09  0.502342                    0.504597            0.000396825     1                          -99.6035  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.014038399422840098
RMSE: 0.11848375172503653
LogLoss: 0.07066338659248987
Mean Per-Class Error: 0.012641979803029724
AUC: 0.9965887520037177
pr_auc: 0.6548063067238479
Gini: 0.9931775040074353
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5353154152007584: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3092  36    0.0115   (36.0/3128.0)
1      42    3007  0.0138   (42.0/3049.0)
Total  3134  3043  0.0126   (78.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.535315     0.987196  188
max f2                       0.423832     0.98841   207
max f0point5                 0.597364     0.989105  178
max accuracy                 0.535315     0.987373  188
max precision                0.989189     0.99906   21
max recall                   9.77801e-06  1         399
max specificity              0.999991     0.999361  0
max absolute_mcc             0.535315     0.974742  188
max min_per_class_accuracy   0.506295     0.986573  192
max mean_per_class_accuracy  0.535315     0.987358  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.72 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999999           2.01935     2.01935            0.996764         1            0.996764                    1                   0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.99997            2.02591     2.02154            1                0.99999      0.997843                    0.999997            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.999768           2.02591     2.02263            1                0.999898     0.998382                    0.999972            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.995334           2.02591     2.02372            1                0.998424     0.998921                    0.999457            0.202361        0.607084                   102.591   102.372
    10       0.400032                    0.965855           2.00952     2.02017            0.991909         0.98533      0.997167                    0.995923            0.20105         0.808134                   100.952   102.017
    11       0.500081                    0.381344           1.82266     1.98066            0.899676         0.832606     0.977663                    0.963249            0.182355        0.990489                   82.2663   98.0657
    12       0.599968                    0.0450156          0.0722367   1.66293            0.0356564        0.133766     0.820831                    0.825151            0.00721548      0.997704                   -92.7763  66.293
    13       0.700016                    0.00541547         0.00655634  1.4262             0.00323625       0.0193351    0.703978                    0.709982            0.000655953     0.99836                    -99.3444  42.6196
    14       0.799903                    0.000129369        0.00656697  1.24892            0.00324149       0.00164647   0.616474                    0.621529            0.000655953     0.999016                   -99.3433  24.8922
    15       0.899951                    9.98366e-08        0.00655634  1.11081            0.00323625       2.11681e-05  0.5483                      0.552436            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           7.54322e-53        0.00327817  1                  0.00161812       7.19764e-09  0.493605                    0.497165            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:27:45  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:27:56  21 min 14.381 sec  2252 obs/sec      1         1             25000      0.305643         0.40807             0.626321       0.941998        0.685434           1.99067          0.118509                         0.297941           0.373252              0.644867         0.948236          0.661482             1.99323            0.113809
    2019-08-03 16:28:08  21 min 26.216 sec  2282 obs/sec      2         2             50000      0.258375         0.2653              0.732963       0.964728        0.748753           1.99067          0.0841224                        0.251566           0.249073              0.746816         0.968262          0.749121             1.99323            0.0796503
    2019-08-03 16:28:19  21 min 37.295 sec  2355 obs/sec      3         3             75000      0.230932         0.208884            0.786676       0.976098        0.755297           1.99067          0.0627928                        0.221999           0.195525              0.802834         0.979581          0.785471             1.99323            0.0552048
    2019-08-03 16:28:39  21 min 57.872 sec  2437 obs/sec      5         5             125000     0.201444         0.168261            0.837677       0.984304        0.703789           1.97096          0.0444533                        0.192479           0.15382               0.851783         0.98718           0.733375             1.99323            0.039987
    2019-08-03 16:28:59  22 min 17.543 sec  2505 obs/sec      7         7             175000     0.15957          0.112533            0.898148       0.992252        0.71256            1.99067          0.0254161                        0.155234           0.109287              0.903594         0.992515          0.713304             2.02591            0.0236361
    2019-08-03 16:29:18  22 min 36.918 sec  2552 obs/sec      9         9             225000     0.125039         0.0737452           0.937459       0.996363        0.666185           1.99067          0.014552                         0.125763           0.0772234             0.936725         0.99596           0.681801             2.02591            0.0142464
    2019-08-03 16:29:28  22 min 46.760 sec  2576 obs/sec      10        10            250000     0.120093         0.0706733           0.942309       0.996366        0.605449           1.99067          0.0133559                        0.118484           0.0706634             0.943837         0.996589          0.654806             2.02591            0.0126275
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C34         1.0                    1.0                  0.002893503064352308
C31         0.9609410166740417     0.9609410166740417   0.0027804857764081622
C36         0.9440445303916931     0.9440445303916931   0.0027315957415733998
C35         0.9348743557929993     0.9348743557929993   0.002705061813271433
C28         0.8998064994812012     0.8998064994812012   0.0026035928635729792
---         ---                    ---                  ---
C758        0.2533344030380249     0.2533344030380249   0.0007330238714963877
C452        0.2507829964160919     0.2507829964160919   0.0007256413686174158
C523        0.24848444759845734    0.24848444759845734  0.0007189905105700268
C342        0.24551597237586975    0.24551597237586975  0.0007104012184170157
C765        0.2366991639137268     0.2366991639137268   0.0006848897561139977

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_21

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.05973930099515442     0.12316268682479858     0.0         0.02549963602254406    0.07723221182823181  0.08232006329706205     0.10701841115951538
    3        2        Softmax                      0.0   0.0   0.00031718301940486526  0.00010014630970545113  0.0         0.0016603655249696203  0.2577626705169678   0.00020587312863335275  0.05983304977416992


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.014543072667433876
RMSE: 0.12059466268220113
LogLoss: 0.06928432689216259
Mean Per-Class Error: 0.013144858720519847
AUC: 0.9963268785300998
pr_auc: 0.6217135918496339
Gini: 0.9926537570601996
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5300694622361346: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4941  88    0.0175   (88.0/5029.0)
1      44    4961  0.0088   (44.0/5005.0)
Total  4985  5049  0.0132   (132.0/10034.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.530069     0.986871  188
max f2                       0.423737     0.991043  207
max f0point5                 0.669027     0.985588  158
max accuracy                 0.530069     0.986845  188
max precision                0.999988     0.997336  0
max recall                   0.00042525   1         397
max specificity              0.999988     0.999006  0
max absolute_mcc             0.530069     0.973727  188
max min_per_class_accuracy   0.63385      0.985285  168
max mean_per_class_accuracy  0.530069     0.986855  188
Gains/Lift Table: Avg response rate: 49.88 %, avg score: 50.65 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.01176                     1                  2.0048      2.0048             1                1            1                           1                   0.0235764       0.0235764                  100.48    100.48
    2        0.0200319                   1                  2.0048      2.0048             1                1            1                           1                   0.0165834       0.0401598                  100.48    100.48
    3        0.0300977                   1                  2.0048      2.0048             1                1            1                           1                   0.0201798       0.0603397                  100.48    100.48
    4        0.0400638                   1                  2.0048      2.0048             1                1            1                           1                   0.01998         0.0803197                  100.48    100.48
    5        0.0500299                   1                  2.0048      2.0048             1                1            1                           1                   0.01998         0.1003                     100.48    100.48
    6        0.10006                     0.999999           2.0048      2.0048             1                1            1                           1                   0.1003          0.200599                   100.48    100.48
    7        0.14999                     0.999983           1.99679     2.00213            0.996008         0.999995     0.998671                    0.999998            0.0997003       0.3003                     99.6792   100.213
    8        0.20002                     0.999815           1.99281     1.9998             0.994024         0.999925     0.997509                    0.99998             0.0997003       0.4                        99.2814   99.9801
    9        0.29998                     0.995657           1.98081     1.99347            0.988036         0.998503     0.994352                    0.999488            0.198002        0.598002                   98.081    99.3472
    10       0.40004                     0.965134           1.98882     1.99231            0.992032         0.9851       0.993772                    0.995889            0.199001        0.797003                   98.8821   99.2309
    11       0.5                         0.606436           1.90086     1.97403            0.948156         0.874147     0.984652                    0.97155             0.19001         0.987013                   90.0858   97.4026
    12       0.59996                     0.0492537          0.123926    1.66578            0.0618146        0.182681     0.830897                    0.840116            0.0123876       0.999401                   -87.6074  66.5778
    13       0.70002                     0.00654883         0.00199681  1.42796            0.000996016      0.0220421    0.712272                    0.723182            0.0001998       0.9996                     -99.8003  42.796
    14       0.79998                     0.000325497        0.0039976   1.25003            0.00199402       0.00229326   0.623521                    0.633104            0.0003996       1                          -99.6002  25.0031
    15       0.89994                     5.54905e-07        0           1.11118            0                6.96839e-05  0.554264                    0.56279             0               1                          -100      11.1185
    16       1                           3.79876e-36        0           1                  0                5.14592e-08  0.498804                    0.506478            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.015075955446182792
RMSE: 0.12278418239408036
LogLoss: 0.07199418811701501
Mean Per-Class Error: 0.013055253116404764
AUC: 0.995947635759995
pr_auc: 0.5851455173915122
Gini: 0.99189527151999
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5200793531460799: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3073  55    0.0176   (55.0/3128.0)
1      26    3023  0.0085   (26.0/3049.0)
Total  3099  3078  0.0131   (81.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.520079     0.98678   191
max f2                       0.435053     0.99039   203
max f0point5                 0.647861     0.984963  172
max accuracy                 0.520079     0.986887  191
max precision                0.999738     0.998551  1
max recall                   0.000714253  1         396
max specificity              0.999983     0.999361  0
max absolute_mcc             0.520079     0.973815  191
max min_per_class_accuracy   0.62367      0.984974  174
max mean_per_class_accuracy  0.520079     0.986945  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.17 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0131132                   1                  2.02591     2.02591            1                1            1                           1                   0.0265661       0.0265661                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.014103        0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    1                  2.01935     2.02263            0.996764         1            0.998382                    1                   0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999988           2.01935     2.02154            0.996764         0.999996     0.997843                    0.999999            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.999854           2.02591     2.02263            1                0.999945     0.998382                    0.999985            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.995818           2.00293     2.01607            0.988655         0.99855      0.995143                    0.999507            0.200066        0.604788                   100.293   101.607
    10       0.400032                    0.964095           1.98985     2.00951            0.982201         0.984519     0.991906                    0.995759            0.199082        0.80387                    98.985    100.951
    11       0.500081                    0.480483           1.88167     1.98394            0.928803         0.856641     0.979281                    0.967926            0.188258        0.992129                   88.1671   98.3936
    12       0.599968                    0.0458276          0.0623862   1.66402            0.0307942        0.153712     0.821371                    0.83237             0.00623155      0.99836                    -93.7614  66.4023
    13       0.700016                    0.006729           0.00983452  1.4276             0.00485437       0.0210654    0.704672                    0.716416            0.000983929     0.999344                   -99.0165  42.7601
    14       0.799903                    0.00025688         0.00656697  1.25015            0.00324149       0.00233702   0.617082                    0.627247            0.000655953     1                          -99.3433  25.0152
    15       0.899951                    5.19335e-07        0           1.11117            0                5.26325e-05  0.54848                     0.557521            0               1                          -100      11.1171
    16       1                           1.40565e-46        0           1                  0                4.7955e-08   0.493605                    0.501742            0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:31:01  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:31:13  24 min 31.281 sec  2229 obs/sec      1         1             25000      0.300411         0.37282             0.63901        0.945699        0.692091           2.0048           0.118098                         0.295146           0.367489              0.651498         0.947866          0.683951             2.02591            0.110571
    2019-08-03 16:31:34  24 min 52.754 sec  2371 obs/sec      3         3             75000      0.231848         0.202625            0.784984       0.976346        0.780045           2.0048           0.065577                         0.230143           0.198558              0.788102         0.977417          0.769195             2.02591            0.0634612
    2019-08-03 16:31:45  25 min  3.395 sec  2426 obs/sec      4         4             100000     0.208342         0.165526            0.826374       0.984333        0.812501           2.0048           0.0483357                        0.203869           0.161349              0.833723         0.985724          0.82734              2.02591            0.0446819
    2019-08-03 16:31:56  25 min 14.206 sec  2456 obs/sec      5         5             125000     0.195615         0.155265            0.846938       0.985948        0.740497           2.0048           0.0412597                        0.190833           0.148193              0.854307         0.987511          0.722381             2.02591            0.0390157
    2019-08-03 16:32:15  25 min 33.610 sec  2529 obs/sec      7         7             175000     0.158284         0.109087            0.899784       0.992665        0.704483           2.0048           0.0224238                        0.157772           0.115174              0.900416         0.992448          0.695659             2.02591            0.0236361
    2019-08-03 16:32:34  25 min 52.762 sec  2579 obs/sec      9         9             225000     0.130935         0.0843434           0.931424       0.995184        0.66177            2.0048           0.0158461                        0.132398           0.090464              0.929871         0.994197          0.644831             2.02591            0.0150559
    2019-08-03 16:32:45  26 min  3.086 sec  2591 obs/sec      10        10            250000     0.120595         0.0692843           0.941827       0.996327        0.621714           2.0048           0.0131553                        0.122784           0.0719942             0.939686         0.995948          0.585146             2.02591            0.0131132
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0030513847519142386
C31         0.9960021376609802     0.9960021376609802   0.0030391857357327016
C35         0.9885639548301697     0.9885639548301697   0.0030164889780608163
C28         0.880687952041626      0.880687952041626    0.002687317788054396
C47         0.8806009888648987     0.8806009888648987   0.002687052429942952
---         ---                    ---                  ---
C606        0.23143628239631653    0.23143628239631653  0.000706201143143838
C561        0.23139837384223938    0.23139837384223938  0.0007060854695599599
C440        0.23107492923736572    0.23107492923736572  0.0007050985156245595
C626        0.23084448277950287    0.23084448277950287  0.0007043953348169041
C740        0.21875423192977905    0.21875423192977905  0.0006675033277272387

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_160

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.015854210981340853    0.05896303057670593    0.0         0.024324422214493758   0.07981836795806885  0.07303076048949664      0.10709881782531738
    3        2        Softmax                      0.0   0.0   0.00022968417016500098  5.481440166477114e-05  0.0         -0.004628658813089714  0.3715614080429077   -3.7953289849096405e-06  0.0797850489616394


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.015425953125582603
RMSE: 0.12420126056358125
LogLoss: 0.07297043614919677
Mean Per-Class Error: 0.013477242746114948
AUC: 0.9964669592415891
pr_auc: 0.6927331914170682
Gini: 0.9929339184831782
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4518504084953415: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4965  69    0.0137   (69.0/5034.0)
1      66    4916  0.0132   (66.0/4982.0)
Total  5031  4985  0.0135   (135.0/10016.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.45185      0.986455  220
max f2                       0.349987     0.987585  239
max f0point5                 0.62178      0.988178  186
max accuracy                 0.456745     0.986522  219
max precision                0.999984     0.99934   0
max recall                   1.76948e-05  1         399
max specificity              0.999984     0.999801  0
max absolute_mcc             0.45185      0.973043  220
max min_per_class_accuracy   0.456745     0.986492  219
max mean_per_class_accuracy  0.45185      0.986523  220
Gains/Lift Table: Avg response rate: 49.74 %, avg score: 48.88 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100839                   1                  2.01044     2.01044            1                1            1                           1                   0.020273        0.020273                   101.044   101.044
    2        0.0200679                   1                  2.01044     2.01044            1                1            1                           1                   0.0200723       0.0403452                  101.044   101.044
    3        0.0300519                   1                  2.01044     2.01044            1                1            1                           1                   0.0200723       0.0604175                  101.044   101.044
    4        0.0400359                   1                  2.01044     2.01044            1                1            1                           1                   0.0200723       0.0804898                  101.044   101.044
    5        0.05002                     1                  2.01044     2.01044            1                1            1                           1                   0.0200723       0.100562                   101.044   101.044
    6        0.10004                     0.999995           2.01044     2.01044            1                0.999999     1                           0.999999            0.100562        0.201124                   101.044   101.044
    7        0.15006                     0.999873           2.00642     2.0091             0.998004         0.999958     0.999335                    0.999986            0.100361        0.301485                   100.642   100.91
    8        0.20008                     0.998953           2.00241     2.00743            0.996008         0.999555     0.998503                    0.999878            0.100161        0.401646                   100.241   100.743
    9        0.30002                     0.986099           2.00441     2.00642            0.997003         0.994572     0.998003                    0.99811             0.200321        0.601967                   100.441   100.642
    10       0.40006                     0.920418           1.99639     2.00392            0.993014         0.962213     0.996756                    0.989134            0.199719        0.801686                   99.6393   100.392
    11       0.5                         0.39206            1.86583     1.97631            0.928072         0.783447     0.983027                    0.948021            0.186471        0.988157                   86.5831   97.6315
    12       0.60004                     0.0374951          0.0862763   1.6612             0.0429142        0.130518     0.82629                     0.811725            0.00863107      0.996788                   -91.3724  66.1203
    13       0.69998                     0.00447223         0.0100421   1.42546            0.004995         0.0157346    0.709029                    0.698077            0.00100361      0.997792                   -98.9958  42.5458
    14       0.80002                     0.000111111        0.014045    1.24897            0.00698603       0.00137567   0.62124                     0.610957            0.00140506      0.999197                   -98.5955  24.8965
    15       0.89996                     1.20621e-07        0.00803372  1.11116            0.003996         2.1871e-05   0.552696                    0.543113            0.00080289      1                          -99.1966  11.116
    16       1                           4.96205e-48        0           1                  0                9.97858e-09  0.497404                    0.48878             0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.014667440332815957
RMSE: 0.12110920829076523
LogLoss: 0.07299621084518722
Mean Per-Class Error: 0.011695325455748806
AUC: 0.9962971067617657
pr_auc: 0.7081636131596715
Gini: 0.9925942135235315
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48472441678627753: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3101  27    0.0086   (27.0/3128.0)
1      45    3004  0.0148   (45.0/3049.0)
Total  3146  3031  0.0117   (72.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.484724     0.988158  211
max f2                       0.395858     0.988262  225
max f0point5                 0.513894     0.990482  205
max accuracy                 0.484724     0.988344  211
max precision                0.999992     0.998864  0
max recall                   1.67629e-05  1         399
max specificity              0.999992     0.99968   0
max absolute_mcc             0.484724     0.976699  211
max min_per_class_accuracy   0.406992     0.987852  223
max mean_per_class_accuracy  0.484724     0.988305  211
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.42 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999995           2.02591     2.02591            1                0.999999     1                           0.999999            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.999903           2.01935     2.02372            0.996764         0.999967     0.998921                    0.999989            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.999144           2.0128      2.02099            0.993528         0.999635     0.997573                    0.9999              0.100689        0.404395                   101.28    102.099
    9        0.299984                    0.987287           2.02263     2.02154            0.998379         0.995165     0.997841                    0.998324            0.202033        0.606428                   102.263   102.154
    10       0.400032                    0.919284           2.01935     2.02099            0.996764         0.962699     0.997572                    0.989414            0.202033        0.808462                   101.935   102.099
    11       0.500081                    0.320159           1.80955     1.97869            0.893204         0.757293     0.976691                    0.942975            0.181043        0.989505                   80.9551   97.8689
    12       0.599968                    0.0355533          0.0656697   1.6602             0.0324149        0.109841     0.819482                    0.804269            0.00655953      0.996064                   -93.433   66.0197
    13       0.700016                    0.0037895          0.0163909   1.42526            0.00809061       0.015121     0.703515                    0.691481            0.00163988      0.997704                   -98.3609  42.5259
    14       0.799903                    0.000103242        0.0131339   1.24892            0.00648298       0.0011469    0.616474                    0.605277            0.00131191      0.999016                   -98.6866  24.8922
    15       0.899951                    1.62373e-07        0.00983452  1.11117            0.00485437       2.16921e-05  0.54848                     0.53799             0.000983929     1                          -99.0165  11.1171
    16       1                           6.91791e-48        0           1                  0                1.32499e-08  0.493605                    0.484165            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:12:13  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:12:19  3:05:37.395  4333 obs/sec      1         1             25000      0.302125         0.411844            0.634871       0.944121        0.617937           2.01044          0.114217                         0.286247           0.365176              0.672197         0.951868          0.628673             2.02591            0.103772
    2019-08-03 19:12:30  3:05:48.359  4664 obs/sec      3         3             75000      0.233541         0.210889            0.781829       0.975648        0.761115           2.01044          0.0665935                        0.222505           0.191795              0.801935         0.979687          0.761316             2.02591            0.0586045
    2019-08-03 19:12:41  3:05:58.906  4816 obs/sec      5         5             125000     0.188808         0.143852            0.857402       0.987726        0.745296           2.01044          0.0389377                        0.180234           0.134974              0.870042         0.98935           0.727988             2.02591            0.034159
    2019-08-03 19:12:51  3:06:09.306  4894 obs/sec      7         7             175000     0.155656         0.106198            0.903082       0.993052        0.741868           2.01044          0.0229633                        0.148661           0.102433              0.911585         0.993573          0.736009             2.02591            0.0195888
    2019-08-03 19:13:01  3:06:19.430  4978 obs/sec      9         9             225000     0.132367         0.0832578           0.929914       0.995595        0.699353           2.01044          0.0157748                        0.130665           0.0847396             0.931696         0.995552          0.648537             2.02591            0.0145702
    2019-08-03 19:13:07  3:06:24.929  4997 obs/sec      10        10            250000     0.124201         0.0729704           0.938295       0.996467        0.692733           2.01044          0.0134784                        0.121109           0.0729962             0.941321         0.996297          0.708164             2.02591            0.0116561
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0029079987573101085
C35         0.9959703087806702     0.9959703087806702   0.0028962804202519537
C28         0.9651439189910889     0.9651439189910889   0.0028066373170514943
C34         0.898986279964447      0.898986279964447    0.002614250984975449
C33         0.8858287334442139     0.8858287334442139   0.002575988856045361
---         ---                    ---                  ---
C470        0.24097368121147156    0.24097368121147156  0.0007007511655074015
C544        0.23938614130020142    0.23938614130020142  0.0006961346014182477
C446        0.23907588422298431    0.23907588422298431  0.0006952323742232537
C888        0.23656773567199707    0.23656773567199707  0.0006879386813538336
C684        0.23618100583553314    0.23618100583553314  0.0006868140714699818

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_219

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms          mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  ------------------  -----------------------  --------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.015619571238215132    0.05295628309249878    0.0         0.023626637601070873  0.0787457823753357  0.09692203645771266      0.11524707078933716
    3        2        Softmax                      0.0   0.0   0.00026098834877075205  7.029800326563418e-05  0.0         0.02211422243362904   0.336397647857666   -0.00021230331308700126  0.022137299180030823


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.016074678244858108
RMSE: 0.12678595444629545
LogLoss: 0.0736054287374378
Mean Per-Class Error: 0.01499947959767467
AUC: 0.996418143427989
pr_auc: 0.6399949926247887
Gini: 0.9928362868559779
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5036630901487761: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4873  83    0.0167   (83.0/4956.0)
1      67    4989  0.0133   (67.0/5056.0)
Total  4940  5072  0.015    (150.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.503663     0.98519   200
max f2                       0.372674     0.987431  230
max f0point5                 0.625701     0.986011  173
max accuracy                 0.503663     0.985018  200
max precision                0.999766     0.999012  1
max recall                   1.06521e-05  1         399
max specificity              0.999984     0.999596  0
max absolute_mcc             0.503663     0.970037  200
max min_per_class_accuracy   0.530973     0.983858  195
max mean_per_class_accuracy  0.503663     0.985001  200
Gains/Lift Table: Avg response rate: 50.50 %, avg score: 50.67 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0108869                   1                  1.98022     1.98022            1                1            1                           1                   0.0215585       0.0215585                  98.0222   98.0222
    2        0.0200759                   1                  1.98022     1.98022            1                1            1                           1                   0.0181962       0.0397547                  98.0222   98.0222
    3        0.0300639                   1                  1.98022     1.98022            1                1            1                           1                   0.0197785       0.0595332                  98.0222   98.0222
    4        0.0400519                   1                  1.98022     1.98022            1                1            1                           1                   0.0197785       0.0793117                  98.0222   98.0222
    5        0.05004                     1                  1.98022     1.98022            1                1            1                           1                   0.0197785       0.0990902                  98.0222   98.0222
    6        0.10008                     0.999999           1.98022     1.98022            1                1            1                           1                   0.0990902       0.19818                    98.0222   98.0222
    7        0.15002                     0.999971           1.98022     1.98022            1                0.999991     1                           0.999997            0.0988924       0.297073                   98.0222   98.0222
    8        0.20006                     0.999674           1.97232     1.97824            0.996008         0.999864     0.999001                    0.999964            0.0986946       0.395767                   97.2316   97.8244
    9        0.30004                     0.993827           1.97627     1.97758            0.998002         0.99781      0.998668                    0.999246            0.197587        0.593354                   97.6265   97.7585
    10       0.40002                     0.955696           1.96044     1.9733             0.99001          0.979789     0.996504                    0.994383            0.196005        0.789359                   96.0439   97.3299
    11       0.5                         0.606666           1.88724     1.95609            0.953047         0.857502     0.987815                    0.967012            0.188687        0.978046                   88.7244   95.6092
    12       0.59998                     0.057796           0.183977    1.66079            0.0929071        0.203664     0.838688                    0.839809            0.018394        0.99644                    -81.6023  66.0788
    13       0.69996                     0.00744852         0.0217607   1.42668            0.010989         0.0254457    0.720462                    0.723488            0.00217563      0.998616                   -97.8239  42.6675
    14       0.79994                     0.000235254        0.0118695   1.24985            0.00599401       0.00247725   0.631165                    0.633373            0.00118671      0.999802                   -98.8131  24.9846
    15       0.89992                     2.45253e-07        0           1.11099            0                4.65395e-05  0.561043                    0.563011            0               0.999802                   -100      11.099
    16       1                           5.59625e-47        0.00197627  1                  0.000998004      2.05326e-08  0.504994                    0.506665            0.000197785     1                          -99.8024  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.01587146568897038
RMSE: 0.1259820054173229
LogLoss: 0.07367294935271426
Mean Per-Class Error: 0.014055748855647643
AUC: 0.9962310501367687
pr_auc: 0.6350647929275532
Gini: 0.9924621002735374
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4809049451059516: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3077  51    0.0163   (51.0/3128.0)
1      36    3013  0.0118   (36.0/3049.0)
Total  3113  3064  0.0141   (87.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.480905     0.985768  198
max f2                       0.431476     0.988619  211
max f0point5                 0.625792     0.986638  173
max accuracy                 0.480905     0.985915  198
max precision                0.99974      0.998401  1
max recall                   9.74116e-06  1         399
max specificity              0.999985     0.999361  0
max absolute_mcc             0.480905     0.97184   198
max min_per_class_accuracy   0.515959     0.984655  190
max mean_per_class_accuracy  0.480905     0.985944  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.74 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999999           2.02591     2.02591            1                1            1                           1                   0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.999966           2.01935     2.02372            0.996764         0.999989     0.998921                    0.999996            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.999632           2.01935     2.02263            0.996764         0.999852     0.998382                    0.99996             0.101017        0.404723                   101.935   102.263
    9        0.299984                    0.993242           2.01278     2.01935            0.993517         0.997714     0.996762                    0.999212            0.20105         0.605772                   101.278   101.935
    10       0.400032                    0.949429           2.00624     2.01607            0.990291         0.977747     0.995144                    0.993844            0.200722        0.806494                   100.624   101.607
    11       0.500081                    0.436827           1.84233     1.98131            0.909385         0.813814     0.977986                    0.957826            0.184323        0.990817                   84.2333   98.1313
    12       0.599968                    0.0508135          0.0591027   1.66129            0.0291734        0.159635     0.820022                    0.824938            0.00590357      0.99672                    -94.0897  66.129
    13       0.700016                    0.00637954         0.019669    1.42666            0.00970874       0.022484     0.704209                    0.710249            0.00196786      0.998688                   -98.0331  42.6664
    14       0.799903                    0.00021202         0.00985045  1.24974            0.00486224       0.0020968    0.616879                    0.621819            0.000983929     0.999672                   -99.015   24.9742
    15       0.899951                    2.74307e-07        0.00327817  1.11117            0.00161812       4.37666e-05  0.54848                     0.552696            0.000327976     1                          -99.6722  11.1171
    16       1                           3.64358e-45        0           1                  0                2.28172e-08  0.493605                    0.497399            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:31:55  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:32:01  4:25:19.512  4301 obs/sec      1         1             25000      0.310288         0.439728            0.614847       0.941454        0.610301           1.98022          0.122153                         0.304777           0.417722              0.628384         0.945604          0.602865             2.02591            0.115104
    2019-08-03 20:32:12  4:25:30.483  4640 obs/sec      3         3             75000      0.231804         0.21276             0.785045       0.975435        0.728161           1.98022          0.0648222                        0.220976           0.187176              0.804647         0.980031          0.728725             2.02591            0.0597377
    2019-08-03 20:32:23  4:25:41.058  4790 obs/sec      5         5             125000     0.193408         0.151596            0.850358       0.986729        0.721228           1.98022          0.04165                          0.185934           0.142785              0.861692         0.987987          0.739047             2.02591            0.0367492
    2019-08-03 20:32:33  4:25:51.182  4908 obs/sec      7         7             175000     0.157958         0.108689            0.900187       0.99295         0.719918           1.98022          0.0251698                        0.152427           0.103756              0.907049         0.993896          0.749789             2.02591            0.0226647
    2019-08-03 20:32:43  4:26:01.449  4974 obs/sec      9         9             225000     0.13788          0.087388            0.923949       0.994885        0.624602           1.98022          0.017479                         0.139711           0.0923781             0.921911         0.99445           0.628195             2.02591            0.0176461
    2019-08-03 20:32:49  4:26:06.891  4991 obs/sec      10        10            250000     0.126786         0.0736054           0.935695       0.996418        0.639995           1.98022          0.014982                         0.125982           0.0736729             0.936504         0.996231          0.635065             2.02591            0.0140845
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0029455589227165633
C36         0.936669111251831      0.936669111251831    0.0027590140582808243
C34         0.9296243190765381     0.9296243190765381   0.002738263207830206
C31         0.9031516313552856     0.9031516313552856   0.002660286346304582
C35         0.881210446357727      0.881210446357727    0.0025956572930600484
---         ---                    ---                  ---
C901        0.23801983892917633    0.23801983892917633  0.0007011014603413945
C769        0.23662568628787994    0.23662568628787994  0.000696994901589195
C773        0.23556502163410187    0.23556502163410187  0.000693870651354249
C662        0.2320214956998825     0.2320214956998825   0.0006834329869208316
C721        0.2255011349916458     0.2255011349916458   0.0006642268802573546

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_112

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms              momentum    mean_weight           weight_rms          mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  --------------------  ----------  --------------------  ------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.06098256121970373     0.12751948833465576   0.0         0.025808582305114118  0.0753210186958313  0.06355738696190433     0.10845223069190979
    3        2        Softmax                      0.0   0.0   0.00024239654055691062  6.21135113760829e-05  0.0         0.017310345275177497  0.2539299726486206  -5.183955733925952e-05  0.05827690660953522


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.013545054175825138
RMSE: 0.11638322119543323
LogLoss: 0.06826423707575549
Mean Per-Class Error: 0.012579673589180884
AUC: 0.9968908741840685
pr_auc: 0.6899993282120043
Gini: 0.993781748368137
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48812341195022696: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4975  49    0.0098   (49.0/5024.0)
1      77    4921  0.0154   (77.0/4998.0)
Total  5052  4970  0.0126   (126.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.488123     0.98736   206
max f2                       0.385912     0.987728  229
max f0point5                 0.601049     0.990899  183
max accuracy                 0.508979     0.987428  202
max precision                0.999989     1         0
max recall                   1.14776e-05  1         399
max specificity              0.999989     1         0
max absolute_mcc             0.508979     0.974886  202
max min_per_class_accuracy   0.435183     0.986795  218
max mean_per_class_accuracy  0.488123     0.98742   206
Gains/Lift Table: Avg response rate: 49.87 %, avg score: 49.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   1                  2.0052      2.0052             1                1            1                           1                   0.0202081       0.0202081                  100.52    100.52
    2        0.0200559                   1                  2.0052      2.0052             1                1            1                           1                   0.020008        0.0402161                  100.52    100.52
    3        0.0300339                   1                  2.0052      2.0052             1                1            1                           1                   0.020008        0.0602241                  100.52    100.52
    4        0.040012                    1                  2.0052      2.0052             1                1            1                           1                   0.020008        0.0802321                  100.52    100.52
    5        0.0500898                   1                  2.0052      2.0052             1                1            1                           1                   0.0202081       0.10044                    100.52    100.52
    6        0.10008                     0.999997           2.0052      2.0052             1                0.999999     1                           1                   0.10024         0.20068                    100.52    100.52
    7        0.15007                     0.999917           2.0052      2.0052             1                0.999973     1                           0.999991            0.10024         0.30092                    100.52    100.52
    8        0.20006                     0.99942            2.0052      2.0052             1                0.999736     1                           0.999927            0.10024         0.40116                    100.52    100.52
    9        0.30004                     0.991287           2.0032      2.00454            0.999002         0.996764     0.999667                    0.998873            0.20028         0.601441                   100.32    100.454
    10       0.40002                     0.94703            1.9972      2.0027             0.996008         0.975509     0.998753                    0.993033            0.19968         0.80112                    99.7197   100.27
    11       0.5                         0.403792           1.86712     1.97559            0.931138         0.816979     0.985232                    0.95783             0.186675        0.987795                   86.7119   97.559
    12       0.59998                     0.0313795          0.080048    1.65972            0.0399202        0.12531      0.827707                    0.819099            0.0080032       0.995798                   -91.9952  65.9719
    13       0.69996                     0.00263563         0.0160096   1.42494            0.00798403       0.0130125    0.71062                     0.70396             0.00160064      0.997399                   -98.399   42.4937
    14       0.79994                     4.8359e-05         0.0160096   1.24884            0.00798403       0.000769722  0.622802                    0.616073            0.00160064      0.999                      -98.399   24.8843
    15       0.89992                     2.84511e-08        0.0060036   1.11077            0.00299401       8.74277e-06  0.553942                    0.547629            0.00060024      0.9996                     -99.3996  11.0765
    16       1                           1.84868e-55        0.00399841  1                  0.00199402       2.01479e-09  0.498703                    0.492822            0.00040016      1                          -99.6002  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.014500292292739619
RMSE: 0.12041715946134761
LogLoss: 0.07599334562436388
Mean Per-Class Error: 0.013499195577099998
AUC: 0.9957110901314339
pr_auc: 0.6718438258561107
Gini: 0.9914221802628678
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5330144543486864: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3101  27    0.0086   (27.0/3128.0)
1      56    2993  0.0184   (56.0/3049.0)
Total  3157  3020  0.0134   (83.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.533014     0.986324  200
max f2                       0.3536       0.986192  234
max f0point5                 0.645566     0.990172  178
max accuracy                 0.533014     0.986563  200
max precision                0.997751     0.99869   6
max recall                   1.46304e-05  1         399
max specificity              0.999986     0.999361  0
max absolute_mcc             0.533014     0.973161  200
max min_per_class_accuracy   0.435751     0.985241  216
max mean_per_class_accuracy  0.533014     0.986501  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.80 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999996           2.01935     2.02263            0.996764         0.999999     0.998382                    1                   0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999933           2.01935     2.02154            0.996764         0.999977     0.997843                    0.999992            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.999419           2.02591     2.02263            1                0.999732     0.998382                    0.999927            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.990166           2.02263     2.02263            0.998379         0.996382     0.998381                    0.998747            0.202033        0.606756                   102.263   102.263
    10       0.400032                    0.943995           2.01608     2.02099            0.995146         0.973068     0.997572                    0.992324            0.201705        0.808462                   101.608   102.099
    11       0.500081                    0.339571           1.79972     1.97672            0.88835          0.790068     0.97572                     0.95186             0.180059        0.988521                   79.9716   97.6722
    12       0.599968                    0.0291699          0.0591027   1.65746            0.0291734        0.106953     0.818133                    0.811194            0.00590357      0.994424                   -94.0897  65.7463
    13       0.700016                    0.00329816         0.0295035   1.42479            0.0145631        0.0123683    0.703284                    0.697023            0.00295179      0.997376                   -97.0496  42.479
    14       0.799903                    7.81667e-05        0.0164174   1.24892            0.00810373       0.0010631    0.616474                    0.610116            0.00163988      0.999016                   -98.3583  24.8922
    15       0.899951                    5.23071e-08        0.00655634  1.11081            0.00323625       1.49528e-05  0.5483                      0.542291            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           1.49652e-46        0.00327817  1                  0.00161812       4.26765e-09  0.493605                    0.488035            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:12:49  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:13:00  2:06:18.863  2271 obs/sec      1         1             25000      0.296746         0.390783            0.647766       0.946722        0.629262           2.0052           0.111754                         0.292017           0.380329              0.658848         0.949276          0.613277             2.02591            0.103934
    2019-08-03 18:13:12  2:06:30.453  2326 obs/sec      2         2             50000      0.253026         0.255803            0.74391        0.966104        0.736089           2.0052           0.0771303                        0.248097           0.249122              0.75375          0.968299          0.707891             2.02591            0.0749555
    2019-08-03 18:13:33  2:06:51.127  2436 obs/sec      4         4             100000     0.206629         0.167664            0.829217       0.983527        0.769475           2.0052           0.0486929                        0.204564           0.171336              0.832586         0.983654          0.749186             2.02591            0.0469484
    2019-08-03 18:13:53  2:07:11.088  2503 obs/sec      6         6             150000     0.165318         0.112745            0.89068        0.992267        0.707039           2.0052           0.0294352                        0.162885           0.114882              0.893856         0.991911          0.704778             2.02591            0.0280071
    2019-08-03 18:14:12  2:07:30.550  2555 obs/sec      8         8             200000     0.13328          0.0808568           0.928945       0.995839        0.701182           2.0052           0.0168629                        0.138539           0.0940703             0.923215         0.994257          0.670277             2.02591            0.0184556
    2019-08-03 18:14:31  2:07:49.657  2595 obs/sec      10        10            250000     0.116383         0.0682642           0.945819       0.996891        0.689999           2.0052           0.0125723                        0.120417           0.0759933             0.941989         0.995711          0.671844             2.02591            0.0134369
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C34         1.0                    1.0                  0.0030206517193085954
C36         0.9499748349189758     0.9499748349189758   0.0028695431183979035
C28         0.9442200064659119     0.9442200064659119   0.00285215978593683
C31         0.9024909734725952     0.9024909734725952   0.0027261109106804828
C24         0.8773283958435059     0.8773283958435059   0.002650103527302938
---         ---                    ---                  ---
C854        0.23872153460979462    0.23872153460979462  0.0007210946139550625
C919        0.23836520314216614    0.23836520314216614  0.0007200182606947268
C588        0.23778484761714935    0.23778484761714935  0.0007182652087802746
C478        0.2277996838092804     0.2277996838092804   0.0006881035065564572
C721        0.22652781009674072    0.22652781009674072  0.0006842616190399309

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_27

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.026620150052340297    0.0931159257888794     0.0         0.024273189793248356  0.08277913928031921  0.0973753225262571      0.10219234228134155
    3        2        Softmax                      0.0   0.0   0.00035491975137347254  6.031198427081108e-05  0.0         -0.03156397137217937  0.38262736797332764  -0.0007597869587762478  0.036605075001716614


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.015013423950510467
RMSE: 0.1225292779318905
LogLoss: 0.06891626039733205
Mean Per-Class Error: 0.013956208007592785
AUC: 0.9972217725229591
pr_auc: 0.669155803756678
Gini: 0.9944435450459181
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4883442023818841: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4967  67    0.0133   (67.0/5034.0)
1      73    4926  0.0146   (73.0/4999.0)
Total  5040  4993  0.014    (140.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.488344     0.985989  201
max f2                       0.381553     0.987189  221
max f0point5                 0.606035     0.988535  176
max accuracy                 0.52462      0.986046  194
max precision                0.99998      1         0
max recall                   1.38249e-05  1         399
max specificity              0.99998      1         0
max absolute_mcc             0.52462      0.972104  194
max min_per_class_accuracy   0.480355     0.985797  203
max mean_per_class_accuracy  0.488344     0.986044  201
Gains/Lift Table: Avg response rate: 49.83 %, avg score: 49.65 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   1                  2.007       2.007              1                1            1                           1                   0.020204        0.020204                   100.7     100.7
    2        0.0200339                   1                  2.007       2.007              1                1            1                           1                   0.020004        0.040208                   100.7     100.7
    3        0.030001                    1                  2.007       2.007              1                1            1                           1                   0.020004        0.060212                   100.7     100.7
    4        0.0400678                   1                  2.007       2.007              1                1            1                           1                   0.020204        0.0804161                  100.7     100.7
    5        0.0500349                   1                  2.007       2.007              1                1            1                           1                   0.020004        0.10042                    100.7     100.7
    6        0.10007                     0.999996           2.007       2.007              1                0.999999     1                           1                   0.10042         0.20084                    100.7     100.7
    7        0.150005                    0.999912           2.007       2.007              1                0.99997      1                           0.99999             0.10022         0.30106                    100.7     100.7
    8        0.20004                     0.999312           1.99501     2.004              0.994024         0.999692     0.998505                    0.999915            0.09982         0.40088                    99.5007   100.4
    9        0.30001                     0.989611           2.005       2.00433            0.999003         0.996027     0.998671                    0.99862             0.20044         0.60132                    100.5     100.433
    10       0.39998                     0.940796           1.997       2.0025             0.995015         0.971447     0.997757                    0.991828            0.19964         0.80096                    99.6996   100.25
    11       0.50005                     0.450764           1.85308     1.9726             0.923307         0.815689     0.982858                    0.956579            0.185437        0.986397                   85.3078   97.2598
    12       0.60002                     0.0470377          0.114057    1.66294            0.0568295        0.159537     0.828571                    0.823783            0.0114023       0.9978                     -88.5943  66.2944
    13       0.69999                     0.00510342         0.012006    1.42716            0.00598205       0.0202265    0.711092                    0.709022            0.00120024      0.999                      -98.7994  42.7163
    14       0.79996                     0.000158012        0.00800399  1.24981            0.00398804       0.00161725   0.622726                    0.620618            0.00080016      0.9998                     -99.1996  24.9812
    15       0.89993                     2.61881e-07        0           1.11097            0                3.24021e-05  0.55355                     0.55168             0               0.9998                     -100      11.0975
    16       1                           7.52164e-38        0.00199901  1                  0.000996016      2.25653e-08  0.498256                    0.496473            0.00020004      1                          -99.8001  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.015739173415682216
RMSE: 0.12545586242054302
LogLoss: 0.07629833773657306
Mean Per-Class Error: 0.013474345703886836
AUC: 0.9959714895412441
pr_auc: 0.6608689017282795
Gini: 0.9919429790824883
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4947672863463679: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3095  33    0.0105   (33.0/3128.0)
1      50    2999  0.0164   (50.0/3049.0)
Total  3145  3032  0.0134   (83.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.494767     0.986351  199
max f2                       0.410557     0.986303  215
max f0point5                 0.537533     0.98843   193
max accuracy                 0.497393     0.986563  198
max precision                0.99998      0.998045  0
max recall                   1.15716e-05  1         399
max specificity              0.99998      0.999361  0
max absolute_mcc             0.497393     0.973138  198
max min_per_class_accuracy   0.442936     0.985569  208
max mean_per_class_accuracy  0.494767     0.986526  199
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.05 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999996           2.02591     2.02263            1                0.999999     0.998382                    1                   0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.999916           2.01935     2.02154            0.996764         0.999971     0.997843                    0.99999             0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.999356           2.00624     2.01771            0.990291         0.999715     0.995955                    0.999921            0.100361        0.403739                   100.624   101.771
    9        0.299984                    0.989409           2.02591     2.02044            1                0.996222     0.997302                    0.99869             0.202361        0.6061                     102.591   102.044
    10       0.400032                    0.939147           2.00952     2.01771            0.991909         0.970618     0.995953                    0.991669            0.20105         0.80715                    100.952   101.771
    11       0.500081                    0.347593           1.80955     1.97607            0.893204         0.782779     0.975397                    0.949877            0.181043        0.988193                   80.9551   97.6066
    12       0.599968                    0.0436116          0.0919376   1.66238            0.0453809        0.133523     0.820561                    0.813965            0.00918334      0.997376                   -90.8062  66.2383
    13       0.700016                    0.00546897         0.00983452  1.4262             0.00485437       0.0193561    0.703978                    0.700397            0.000983929     0.99836                    -99.0165  42.6196
    14       0.799903                    0.000204572        0.0131339   1.24974            0.00648298       0.00188155   0.616879                    0.613171            0.00131191      0.999672                   -98.6866  24.9742
    15       0.899951                    2.58734e-07        0.00327817  1.11117            0.00161812       3.7783e-05   0.54848                     0.545008            0.000327976     1                          -99.6722  11.1171
    16       1                           1.10599e-45        0           1                  0                2.53563e-08  0.493605                    0.490481            0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:38:47  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:38:52  32 min 10.442 sec  4425 obs/sec      1         1             25000      0.302145         0.394438            0.634829       0.942316        0.682288           2.007            0.117612                         0.28991            0.362326              0.663754         0.949183          0.640953             2.02591            0.107981
    2019-08-03 16:39:03  32 min 21.475 sec  4663 obs/sec      3         3             75000      0.239143         0.220035            0.77124        0.973338        0.742506           2.007            0.0674773                        0.232236           0.204917              0.78423          0.976513          0.731017             2.02591            0.065242
    2019-08-03 16:39:14  32 min 32.010 sec  4809 obs/sec      5         5             125000     0.194046         0.148034            0.849383       0.987413        0.762957           2.007            0.0409648                        0.188143           0.146341              0.858386         0.987936          0.765821             2.02591            0.0375587
    2019-08-03 16:39:24  32 min 42.493 sec  4878 obs/sec      7         7             175000     0.160923         0.111272            0.896414       0.993097        0.714474           2.007            0.0258148                        0.16088            0.113279              0.896454         0.992573          0.713695             2.02591            0.0246074
    2019-08-03 16:39:35  32 min 52.583 sec  4963 obs/sec      9         9             225000     0.13932          0.086549            0.922359       0.995643        0.65974            2.007            0.0184392                        0.139013           0.0903855             0.922689         0.995174          0.657075             2.02591            0.0161891
    2019-08-03 16:39:40  32 min 57.923 sec  4995 obs/sec      10        10            250000     0.122529         0.0689163           0.939946       0.997222        0.669156           2.007            0.013954                         0.125456           0.0762983             0.937033         0.995971          0.660869             2.02591            0.0134369
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.00319443417302945
C36         0.9474123120307922     0.9474123120307922   0.003026446265500003
C31         0.8958074450492859     0.8958074450492859   0.00286159791491964
C22         0.8863621950149536     0.8863621950149536   0.0028314256854371617
C28         0.8828277587890625     0.8828277587890625   0.002820135161574782
---         ---                    ---                  ---
C985        0.21384233236312866    0.21384233236312866  0.0006831052541410997
C534        0.21161049604415894    0.21161049604415894  0.0006759757999351746
C376        0.20845232903957367    0.20845232903957367  0.0006658872433315934
C467        0.20415621995925903    0.20415621995925903  0.0006521636056743741
C662        0.20117773115634918    0.20117773115634918  0.0006426490192583733

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_33

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.022887928142500753   0.06607946753501892    0.0         0.024661913530588338   0.08117306232452393  0.08679609229902667    0.10871866345405579
    3        2        Softmax                      0.0   0.0   0.0002482419457692231  6.116941221989691e-05  0.0         -0.004300511893234216  0.3829522132873535   0.0011357645185058607  0.06901425123214722


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01631827450164317
RMSE: 0.1277430017716946
LogLoss: 0.0757479670240729
Mean Per-Class Error: 0.014607463967615253
AUC: 0.9966396355835062
pr_auc: 0.6302113523309771
Gini: 0.9932792711670124
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5288730503926249: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4864  100   0.0201   (100.0/4964.0)
1      46    5019  0.0091   (46.0/5065.0)
Total  4910  5119  0.0146   (146.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.528873     0.985664  186
max f2                       0.460164     0.989852  201
max f0point5                 0.694039     0.986498  149
max accuracy                 0.540298     0.985442  183
max precision                0.998959     0.998764  3
max recall                   2.30303e-05  1         399
max specificity              0.999978     0.999396  0
max absolute_mcc             0.528873     0.970935  186
max min_per_class_accuracy   0.615881     0.984891  167
max mean_per_class_accuracy  0.540298     0.985393  183
Gains/Lift Table: Avg response rate: 50.50 %, avg score: 51.61 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0103699                   1                  1.98006     1.98006            1                1            1                           1                   0.0205331       0.0205331                  98.0059   98.0059
    2        0.0200419                   1                  1.98006     1.98006            1                1            1                           1                   0.019151        0.0396841                  98.0059   98.0059
    3        0.030013                    1                  1.98006     1.98006            1                1            1                           1                   0.0197433       0.0594274                  98.0059   98.0059
    4        0.0400838                   1                  1.96045     1.97513            0.990099         1            0.997512                    1                   0.0197433       0.0791708                  96.0455   97.5134
    5        0.0500548                   1                  1.98006     1.97611            1                1            0.998008                    1                   0.0197433       0.0989141                  98.0059   97.6115
    6        0.10001                     0.999999           1.98006     1.97809            1                1            0.999003                    1                   0.0989141       0.197828                   98.0059   97.8085
    7        0.150065                    0.999967           1.97611     1.97743            0.998008         0.999989     0.998671                    0.999996            0.0989141       0.296742                   97.6115   97.7428
    8        0.20002                     0.999694           1.97611     1.9771             0.998004         0.99987      0.998504                    0.999965            0.0987167       0.395459                   97.6107   97.7098
    9        0.30003                     0.994743           1.97414     1.97611            0.997009         0.998009     0.998006                    0.999313            0.197433        0.592892                   97.4137   97.6111
    10       0.40004                     0.962433           1.95834     1.97167            0.989033         0.983024     0.995763                    0.995241            0.195854        0.788746                   95.8344   97.1669
    11       0.50005                     0.67262            1.89517     1.95637            0.957129         0.880014     0.988036                    0.972195            0.189536        0.978282                   89.5171   95.637
    12       0.59996                     0.0843954          0.195635    1.66316            0.0988024        0.257276     0.839953                    0.853141            0.0195459       0.997828                   -80.4365  66.3158
    13       0.69997                     0.0121364          0.013819    1.4275             0.00697906       0.0385847    0.72094                     0.736759            0.00138203      0.99921                    -98.6181  42.7504
    14       0.79998                     0.000467708        0.00197414  1.24929            0.000997009      0.0042488    0.630936                    0.645184            0.000197433     0.999408                   -99.8026  24.9291
    15       0.89999                     6.23661e-07        0.00394827  1.1109             0.00199402       9.46464e-05  0.561046                    0.573499            0.000394867     0.999803                   -99.6052  11.0904
    16       1                           8.88401e-39        0.00197414  1                  0.000997009      6.18557e-08  0.505035                    0.516144            0.000197433     1                          -99.8026  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.016417867939621765
RMSE: 0.1281322283409672
LogLoss: 0.07635534594979104
Mean Per-Class Error: 0.013719489178876332
AUC: 0.9964410158376525
pr_auc: 0.6217436047823104
Gini: 0.9928820316753051
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5512361922479827: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3075  53    0.0169   (53.0/3128.0)
1      32    3017  0.0105   (32.0/3049.0)
Total  3107  3070  0.0138   (85.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.551236     0.986109  183
max f2                       0.461219     0.988688  197
max f0point5                 0.661309     0.986552  160
max accuracy                 0.551236     0.986239  183
max precision                0.999403     0.998554  2
max recall                   2.0622e-05   1         399
max specificity              0.99998      0.999361  0
max absolute_mcc             0.551236     0.972499  183
max min_per_class_accuracy   0.608283     0.985294  172
max mean_per_class_accuracy  0.551236     0.986281  183
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.53 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.010361                    1                  2.02591     2.02591            1                1            1                           1                   0.0209905       0.0209905                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0196786       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999999           2.02591     2.02591            1                1            1                           1                   0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.999964           2.01935     2.02372            0.996764         0.999988     0.998921                    0.999996            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.999678           2.01935     2.02263            0.996764         0.999872     0.998382                    0.999965            0.101017        0.404723                   101.935   102.263
    9        0.299984                    0.994099           2.01606     2.02044            0.995138         0.997862     0.997302                    0.999265            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.956767           2.00624     2.01689            0.990291         0.980321     0.995548                    0.994527            0.200722        0.806822                   100.624   101.689
    11       0.500081                    0.476328           1.84233     1.98197            0.909385         0.840246     0.97831                     0.963661            0.184323        0.991145                   84.2333   98.1968
    12       0.599968                    0.0720879          0.0689532   1.66348            0.0340357        0.196946     0.821101                    0.836013            0.0068875       0.998032                   -93.1047  66.3477
    13       0.700016                    0.0103344          0.00983452  1.42713            0.00485437       0.0340167    0.70444                     0.721389            0.000983929     0.999016                   -99.0165  42.7133
    14       0.799903                    0.000323426        0.00328348  1.24933            0.00162075       0.00343115   0.616677                    0.631735            0.000327976     0.999344                   -99.6717  24.9332
    15       0.899951                    5.64542e-07        0.00327817  1.11081            0.00161812       6.47257e-05  0.5483                      0.561512            0.000327976     0.999672                   -99.6722  11.0807
    16       1                           1.06988e-43        0.00327817  1                  0.00161812       5.56859e-08  0.493605                    0.505333            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:43:49  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:43:55  37 min 13.247 sec  4399 obs/sec      1         1             25000      0.310019         0.411701            0.615514       0.940993        0.673971           1.96045          0.122146                         0.30123            0.3882                0.636984         0.946536          0.667869             2.02591            0.113162
    2019-08-03 16:44:06  37 min 24.439 sec  4615 obs/sec      3         3             75000      0.236795         0.208945            0.77569        0.975064        0.7445             1.98006          0.0687008                        0.224137           0.194888              0.799018         0.978237          0.776824             2.02591            0.0607091
    2019-08-03 16:44:17  37 min 35.165 sec  4745 obs/sec      5         5             125000     0.191334         0.143104            0.853551       0.987872        0.755624           1.98006          0.0419783                        0.178045           0.133904              0.873179         0.98956           0.751281             2.02591            0.0323782
    2019-08-03 16:44:27  37 min 45.334 sec  4872 obs/sec      7         7             175000     0.161844         0.10795             0.895216       0.993264        0.716311           1.98006          0.026224                         0.159822           0.110974              0.897811         0.992647          0.709327             2.02591            0.0246074
    2019-08-03 16:44:37  37 min 55.344 sec  4967 obs/sec      9         9             225000     0.144718         0.0924712           0.916218       0.994603        0.694898           1.98006          0.0191445                        0.140073           0.0918087             0.921506         0.994164          0.662409             2.02591            0.016351
    2019-08-03 16:44:43  38 min  0.714 sec  4995 obs/sec      10        10            250000     0.127743         0.075748            0.93472        0.99664         0.630211           1.98006          0.0145578                        0.128132           0.0763553             0.934318         0.996441          0.621744             2.02591            0.0137607
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C34         1.0                    1.0                  0.00309328396139814
C25         0.9676334857940674     0.9676334857940674   0.0029931651421185638
C28         0.9522315859794617     0.9522315859794617   0.002945522692446983
C35         0.9401572942733765     0.9401572942733765   0.002908173479567307
C27         0.9320993423461914     0.9320993423461914   0.002883247946109228
---         ---                    ---                  ---
C986        0.21451343595981598    0.21451343595981598  0.0006635509709589058
C797        0.2113431841135025     0.2113431841135025   0.0006537444817691115
C396        0.20982947945594788    0.20982947945594788  0.0006490621634296041
C429        0.20794111490249634    0.20794111490249634  0.0006432209156431397
C721        0.1988775134086609     0.1988775134086609   0.0006151846225097543

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_78

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms              momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  --------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.030818310382303527    0.09388232231140137   0.0         0.02413450745998475   0.07916709780693054  0.06370574846037302    0.11890682578086853
    3        2        Softmax                      0.0   0.0   0.00027885028038099335  6.16114994045347e-05  0.0         0.041256444289501815  0.3799772262573242   0.0003367193899818377  0.05879126489162445


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.015444043805496764
RMSE: 0.12427406730889902
LogLoss: 0.07250248734274646
Mean Per-Class Error: 0.01335631875558585
AUC: 0.996732222694787
pr_auc: 0.6610610317123213
Gini: 0.993464445389574
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5300728257657527: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4917  69    0.0138   (69.0/4986.0)
1      65    4977  0.0129   (65.0/5042.0)
Total  4982  5046  0.0134   (134.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.530073     0.986717  193
max f2                       0.357285     0.988868  228
max f0point5                 0.566666     0.987539  184
max accuracy                 0.548374     0.986637  187
max precision                0.999752     0.998515  1
max recall                   1.1574e-05   1         399
max specificity              0.999986     0.999398  0
max absolute_mcc             0.548374     0.973277  187
max min_per_class_accuracy   0.53346      0.986161  192
max mean_per_class_accuracy  0.548374     0.986644  187
Gains/Lift Table: Avg response rate: 50.28 %, avg score: 50.63 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0106701                   1                  1.98889     1.98889            1                1            1                           1                   0.0212217       0.0212217                  98.8893   98.8893
    2        0.0200439                   1                  1.98889     1.98889            1                1            1                           1                   0.0186434       0.0398651                  98.8893   98.8893
    3        0.030016                    1                  1.98889     1.98889            1                1            1                           1                   0.0198334       0.0596985                  98.8893   98.8893
    4        0.0400878                   1                  1.98889     1.98889            1                1            1                           1                   0.0200317       0.0797303                  98.8893   98.8893
    5        0.0500598                   1                  1.98889     1.98889            1                1            1                           1                   0.0198334       0.0995637                  98.8893   98.8893
    6        0.10002                     0.999998           1.98492     1.98691            0.998004         1            0.999003                    1                   0.099167        0.198731                   98.4923   98.691
    7        0.15008                     0.999958           1.98493     1.98625            0.998008         0.999985     0.998671                    0.999995            0.0993653       0.298096                   98.4931   98.625
    8        0.20004                     0.999562           1.98492     1.98592            0.998004         0.999819     0.998504                    0.999951            0.099167        0.397263                   98.4923   98.5919
    9        0.30006                     0.99285            1.97898     1.98361            0.995015         0.997327     0.997341                    0.999076            0.197937        0.5952                     97.8979   98.3605
    10       0.39998                     0.950771           1.975       1.98146            0.993014         0.977674     0.99626                     0.99373             0.197342        0.792543                   97.4999   98.1455
    11       0.5                         0.570163           1.90561     1.96628            0.958126         0.84776      0.988632                    0.96453             0.190599        0.983142                   90.561    96.6283
    12       0.60002                     0.0674762          0.148721    1.66331            0.0747757        0.20723      0.836297                    0.838293            0.014875        0.998017                   -85.1279  66.3306
    13       0.69994                     0.00873592         0.0119095   1.42756            0.00598802       0.0299055    0.717766                    0.722891            0.00119         0.999207                   -98.809   42.756
    14       0.79996                     0.000261371        0.00396589  1.24957            0.00199402       0.00288814   0.628272                    0.632868            0.000396668     0.999603                   -99.6034  24.9566
    15       0.89998                     3.40827e-07        0.00198294  1.11092            0.000997009      5.13759e-05  0.55856                     0.56254             0.000198334     0.999802                   -99.8017  11.0915
    16       1                           3.37711e-48        0.00198294  1                  0.000997009      3.2461e-08   0.502792                    0.506274            0.000198334     1                          -99.8017  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.015517222959115545
RMSE: 0.12456814584441539
LogLoss: 0.0785769805363295
Mean Per-Class Error: 0.012621271575351978
AUC: 0.9960320938733843
pr_auc: 0.6437137806918871
Gini: 0.9920641877467686
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5295225898319148: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3087  41    0.0131   (41.0/3128.0)
1      37    3012  0.0121   (37.0/3049.0)
Total  3124  3053  0.0126   (78.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.529523     0.987217  188
max f2                       0.49198      0.988665  194
max f0point5                 0.652595     0.988229  161
max accuracy                 0.533068     0.987373  187
max precision                0.999686     0.996818  1
max recall                   1.28523e-05  1         399
max specificity              0.999982     0.998721  0
max absolute_mcc             0.529523     0.974742  188
max min_per_class_accuracy   0.533068     0.987212  187
max mean_per_class_accuracy  0.529523     0.987379  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.75 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0105229                   1                  2.02591     2.02591            1                1            1                           1                   0.0213185       0.0213185                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0193506       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999998           2.01935     2.01935            0.996764         1            0.996764                    1                   0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.99995            2.0128      2.01717            0.993528         0.999984     0.995685                    0.999994            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.999544           2.02591     2.01935            1                0.999805     0.996764                    0.999947            0.101345        0.404067                   102.591   101.935
    9        0.299984                    0.99208            2.01278     2.01716            0.993517         0.99718      0.995683                    0.999026            0.20105         0.605116                   101.278   101.716
    10       0.400032                    0.945054           2.00296     2.01361            0.988673         0.975248     0.99393                     0.993079            0.200394        0.80551                    100.296   101.361
    11       0.500081                    0.430998           1.84561     1.98               0.911003         0.810709     0.977339                    0.956593            0.184651        0.990161                   84.5611   98.0001
    12       0.599968                    0.0596533          0.0820871   1.66402            0.0405186        0.161585     0.821371                    0.824235            0.00819941      0.99836                    -91.7913  66.4023
    13       0.700016                    0.0082474          0.00655634  1.42713            0.00323625       0.0272794    0.70444                     0.710331            0.000655953     0.999016                   -99.3444  42.7133
    14       0.799903                    0.000270886        0.00656697  1.24974            0.00324149       0.00269913   0.616879                    0.621967            0.000655953     0.999672                   -99.3433  24.9742
    15       0.899951                    4.26585e-07        0           1.11081            0                5.29259e-05  0.5483                      0.552828            0               0.999672                   -100      11.0807
    16       1                           3.80181e-44        0.00327817  1                  0.00161812       3.66353e-08  0.493605                    0.497518            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:34:11  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:34:17  1:27:35.229  4434 obs/sec      1         1             25000      0.30323          0.393711            0.632194       0.944951        0.626979           1.98889          0.115477                         0.299968           0.386721              0.640019         0.946758          0.645939             2.02591            0.114457
    2019-08-03 17:34:28  1:27:46.391  4630 obs/sec      3         3             75000      0.233213         0.20455             0.782439       0.976783        0.775183           1.98889          0.0651177                        0.230179           0.202406              0.788037         0.978228          0.767209             2.02591            0.0649182
    2019-08-03 17:34:39  1:27:57.009  4767 obs/sec      5         5             125000     0.193075         0.145975            0.850883       0.988185        0.751975           1.98889          0.0409852                        0.18944            0.146593              0.856427         0.9881            0.743498             2.02591            0.0362636
    2019-08-03 17:34:49  1:28:07.344  4873 obs/sec      7         7             175000     0.157898         0.103114            0.90027        0.994314        0.738814           1.98889          0.024631                         0.156991           0.10599               0.901399         0.993585          0.701005             2.02591            0.0226647
    2019-08-03 17:34:59  1:28:17.417  4965 obs/sec      9         9             225000     0.131467         0.0766148           0.930864       0.9967          0.70291            1.98889          0.0157559                        0.130451           0.0800416             0.931919         0.996186          0.695308             2.02591            0.0140845
    2019-08-03 17:35:05  1:28:22.666  5009 obs/sec      10        10            250000     0.124274         0.0725025           0.938222       0.996732        0.661061           1.98889          0.0133626                        0.124568           0.078577              0.937921         0.996032          0.643714             2.02591            0.0126275
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0032139095945164474
C35         0.9563474655151367     0.9563474655151367   0.0030736142951105854
C40         0.8733344078063965     0.8733344078063965   0.0028068178324703176
C28         0.8657210469245911     0.8657210469245911   0.002782349178885767
C31         0.8466550707817078     0.8466550707817078   0.0027210728552313325
---         ---                    ---                  ---
C329        0.21993093192577362    0.21993093192577362  0.0007068381322471875
C985        0.2173634171485901     0.2173634171485901   0.0006985863718707346
C589        0.21530012786388397    0.21530012786388397  0.0006919551466423546
C292        0.21293522417545319    0.21293522417545319  0.0006843545599879996
C769        0.21190080046653748    0.21190080046653748  0.00068103001570512

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_220

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.06245446583053303    0.1309773325920105     0.0         0.023834651613958285   0.07022306323051453  0.09932402222619297     0.09648635983467102
    3        2        Softmax                      0.0   0.0   0.0002748338158085062  7.656723028048873e-05  0.0         -0.003458672312717681  0.256473183631897    -3.768040245565041e-06  0.057159557938575745


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01666467807127249
RMSE: 0.1290917428469865
LogLoss: 0.07547903849747324
Mean Per-Class Error: 0.014787025687672761
AUC: 0.9958123373790583
pr_auc: 0.654718108202998
Gini: 0.9916246747581166
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5090667818439214: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4890  91    0.0183   (91.0/4981.0)
1      57    4973  0.0113   (57.0/5030.0)
Total  4947  5064  0.0148   (148.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.509067     0.985338  205
max f2                       0.475782     0.988176  210
max f0point5                 0.576457     0.985391  191
max accuracy                 0.550567     0.985216  196
max precision                0.999986     0.998253  0
max recall                   8.61872e-06  1         399
max specificity              0.999986     0.999398  0
max absolute_mcc             0.509067     0.970453  205
max min_per_class_accuracy   0.563755     0.984742  194
max mean_per_class_accuracy  0.550567     0.985213  196
Gains/Lift Table: Avg response rate: 50.24 %, avg score: 50.33 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101888                   1                  1.99026     1.99026            1                1            1                           1                   0.0202783       0.0202783                  99.0258   99.0258
    2        0.0200779                   1                  1.99026     1.99026            1                1            1                           1                   0.0196819       0.0399602                  99.0258   99.0258
    3        0.0300669                   1                  1.99026     1.99026            1                1            1                           1                   0.0198807       0.059841                   99.0258   99.0258
    4        0.0400559                   1                  1.99026     1.99026            1                1            1                           1                   0.0198807       0.0797217                  99.0258   99.0258
    5        0.050045                    1                  1.99026     1.99026            1                1            1                           1                   0.0198807       0.0996024                  99.0258   99.0258
    6        0.10009                     0.999998           1.98629     1.98827            0.998004         1            0.999002                    1                   0.0994036       0.199006                   98.6286   98.8272
    7        0.150035                    0.999961           1.98628     1.98761            0.998            0.999987     0.998668                    0.999995            0.0992048       0.298211                   98.6278   98.7608
    8        0.20008                     0.999617           1.98231     1.98628            0.996008         0.999839     0.998003                    0.999956            0.0992048       0.397416                   98.2313   98.6284
    9        0.30007                     0.993087           1.97833     1.98363            0.994006         0.997511     0.996671                    0.999141            0.197813        0.595229                   97.8329   98.3633
    10       0.40006                     0.950192           1.95447     1.97634            0.982018         0.977892     0.993009                    0.99383             0.195427        0.790656                   95.447    97.6344
    11       0.50005                     0.59873            1.90874     1.96283            0.959041         0.844239     0.986217                    0.963918            0.190855        0.981511                   90.8739   96.2826
    12       0.60004                     0.0494143          0.157073    1.66192            0.0789211        0.188354     0.835026                    0.834679            0.0157058       0.997217                   -84.2927  66.1917
    13       0.70003                     0.00612915         0.0238592   1.42794            0.011988         0.0223017    0.717466                    0.718642            0.00238569      0.999602                   -97.6141  42.7942
    14       0.80002                     0.000243457        0.00198827  1.24972            0.000999001      0.00200424   0.627919                    0.629073            0.000198807     0.999801                   -99.8012  24.972
    15       0.90001                     3.36263e-07        0.00198827  1.1111             0.000999001      4.64665e-05  0.558269                    0.559189            0.000198807     1                          -99.8012  11.1099
    16       1                           4.3003e-47         0           1                  0                3.18197e-08  0.502447                    0.503276            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.016091294325051082
RMSE: 0.12685146560072172
LogLoss: 0.0794384963792225
Mean Per-Class Error: 0.014182462238677918
AUC: 0.9957027019885771
pr_auc: 0.682217373516761
Gini: 0.9914054039771543
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47854484737252756: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3068  60    0.0192   (60.0/3128.0)
1      28    3021  0.0092   (28.0/3049.0)
Total  3096  3081  0.0142   (88.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.478545     0.985644  212
max f2                       0.418035     0.989607  224
max f0point5                 0.610723     0.984903  183
max accuracy                 0.492063     0.985754  210
max precision                0.999603     0.997712  2
max recall                   1.68979e-05  1         399
max specificity              0.999993     0.999041  0
max absolute_mcc             0.478545     0.971558  212
max min_per_class_accuracy   0.563886     0.984335  195
max mean_per_class_accuracy  0.478545     0.985818  212
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.61 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0106848                   1                  2.02591     2.02591            1                1            1                           1                   0.0216464       0.0216464                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0190226       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999998           2.01935     2.01935            0.996764         1            0.996764                    1                   0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999959           2.01935     2.01935            0.996764         0.999987     0.996764                    0.999995            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.999617           2.02591     2.02099            1                0.999838     0.997573                    0.999956            0.101345        0.404395                   102.591   102.099
    9        0.299984                    0.992851           2.00621     2.01607            0.990276         0.997468     0.995143                    0.999128            0.200394        0.604788                   100.621   101.607
    10       0.400032                    0.9457             1.99641     2.01115            0.985437         0.976146     0.992715                    0.99338             0.199738        0.804526                   99.6407   101.115
    11       0.500081                    0.455869           1.86856     1.98262            0.92233          0.814168     0.978634                    0.957526            0.186947        0.991473                   86.8558   98.2624
    12       0.599968                    0.0444793          0.0623862   1.66293            0.0307942        0.15082      0.820831                    0.82322             0.00623155      0.997704                   -93.7614  66.293
    13       0.700016                    0.00547516         0.0131127   1.42713            0.00647249       0.0199113    0.70444                     0.708409            0.00131191      0.999016                   -98.6887  42.7133
    14       0.799903                    0.000172945        0.00656697  1.24974            0.00324149       0.00168982   0.616879                    0.620158            0.000655953     0.999672                   -99.3433  24.9742
    15       0.899951                    3.46468e-07        0           1.11081            0                3.71579e-05  0.5483                      0.551219            0               0.999672                   -100      11.0807
    16       1                           1.08777e-46        0.00327817  1                  0.00161812       3.47651e-08  0.493605                    0.49607             0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:32:50  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:33:02  4:26:21.001  1998 obs/sec      1         1             25000      0.308764         0.440852            0.61865        0.940756        0.632103           1.97055          0.121366                         0.305252           0.437897              0.627223         0.943217          0.601154             1.99323            0.117371
    2019-08-03 20:33:24  4:26:42.879  2252 obs/sec      3         3             75000      0.239534         0.236578            0.770489       0.971407        0.697356           1.99026          0.0699231                        0.234094           0.230344              0.780764         0.972778          0.712037             2.02591            0.063785
    2019-08-03 20:33:45  4:27:03.266  2378 obs/sec      5         5             125000     0.193107         0.159333            0.850835       0.985468        0.726858           1.99026          0.0388573                        0.189558           0.162046              0.856248         0.985378          0.70807              2.02591            0.0373968
    2019-08-03 20:34:05  4:27:23.115  2457 obs/sec      7         7             175000     0.14277          0.0926303           0.918465       0.994816        0.714799           1.99026          0.017281                         0.143874           0.0941053             0.917187         0.994499          0.746009             2.02591            0.0173223
    2019-08-03 20:34:24  4:27:42.999  2502 obs/sec      9         9             225000     0.129092         0.075479            0.93334        0.995812        0.654718           1.99026          0.0147837                        0.126851           0.0794385             0.935624         0.995703          0.682217             2.02591            0.0142464
    2019-08-03 20:34:35  4:27:53.210  2526 obs/sec      10        10            250000     0.132669         0.0953683           0.929594       0.993625        0.589985           1.99026          0.0161822                        0.131698           0.100867              0.930611         0.993317          0.577073             2.00545            0.0157034
    2019-08-03 20:34:36  4:27:54.364  2525 obs/sec      10        10            250000     0.129092         0.075479            0.93334        0.995812        0.654718           1.99026          0.0147837                        0.126851           0.0794385             0.935624         0.995703          0.682217             2.02591            0.0142464
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0029257796387046845
C31         0.9958457350730896     0.9958457350730896   0.0029136251749677447
C28         0.9700658917427063     0.9700658917427063   0.002838199034262713
C35         0.933737576007843      0.933737576007843    0.0027319103877772146
C38         0.910534143447876      0.910534143447876    0.002664022257245206
---         ---                    ---                  ---
C740        0.24898043274879456    0.24898043274879456  0.0007284618805723041
C562        0.2439802587032318     0.2439802587032318   0.000713832473159817
C478        0.24252314865589142    0.24252314865589142  0.0007095692902519564
C769        0.24104271829128265    0.24104271829128265  0.000705237877234664
C499        0.23681224882602692    0.23681224882602692  0.0006928604558110569

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_70

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.02631199026591252    0.08658811450004578    0.0         0.023509443222395555   0.08059895038604736  0.0802253992707729     0.10575810074806213
    3        2        Softmax                      0.0   0.0   0.0002915010898050241  9.058360592462122e-05  0.0         -0.020848928292252822  0.39703989028930664  3.613102613644198e-05  0.06596723198890686


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01759482168640564
RMSE: 0.1326454736747758
LogLoss: 0.08045811038553587
Mean Per-Class Error: 0.01626136980384918
AUC: 0.9956269618223935
pr_auc: 0.6771352860449356
Gini: 0.991253923644787
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5256488859767792: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4978  74    0.0146   (74.0/5052.0)
1      89    4890  0.0179   (89.0/4979.0)
Total  5067  4964  0.0162   (163.0/10031.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525649     0.983607  202
max f2                       0.415394     0.985289  224
max f0point5                 0.618305     0.9855    181
max accuracy                 0.525649     0.98375   202
max precision                0.999046     0.999528  3
max recall                   8.57056e-06  1         399
max specificity              0.999978     0.999802  0
max absolute_mcc             0.525649     0.967503  202
max min_per_class_accuracy   0.499984     0.983373  207
max mean_per_class_accuracy  0.525649     0.983739  202
Gains/Lift Table: Avg response rate: 49.64 %, avg score: 49.31 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101685                   1                  2.01466     2.01466            1                1            1                           1                   0.020486        0.020486                   101.466   101.466
    2        0.0200379                   1                  2.01466     2.01466            1                1            1                           1                   0.0198835       0.0403696                  101.466   101.466
    3        0.030007                    1                  2.01466     2.01466            1                1            1                           1                   0.0200844       0.0604539                  101.466   101.466
    4        0.0400758                   1                  2.01466     2.01466            1                1            1                           1                   0.0202852       0.0807391                  101.466   101.466
    5        0.0500449                   1                  2.01466     2.01466            1                1            1                           1                   0.0200844       0.100823                   101.466   101.466
    6        0.10009                     0.999994           2.01466     2.01466            1                0.999999     1                           0.999999            0.100823        0.201647                   101.466   101.466
    7        0.150035                    0.999892           2.01064     2.01332            0.998004         0.999961     0.999336                    0.999987            0.100422        0.302069                   101.064   101.332
    8        0.20008                     0.999141           2.01466     2.01366            1                0.999605     0.999502                    0.999891            0.100823        0.402892                   101.466   101.366
    9        0.30007                     0.989132           1.99658     2.00797            0.991027         0.995721     0.996678                    0.998501            0.199638        0.602531                   99.6584   100.797
    10       0.40006                     0.93323            1.99658     2.00512            0.991027         0.968428     0.995265                    0.990985            0.199638        0.802169                   99.6584   100.512
    11       0.50005                     0.435462           1.83991     1.97209            0.91326          0.794842     0.978868                    0.951764            0.183973        0.986142                   83.991    97.2087
    12       0.60004                     0.0424613          0.100432    1.6602             0.0498504        0.151677     0.824057                    0.818438            0.0100422       0.996184                   -89.9568  66.0196
    13       0.70003                     0.00454225         0.0241036   1.4265             0.0119641        0.0183513    0.70806                     0.704156            0.00241012      0.998594                   -97.5896  42.6502
    14       0.80002                     0.000132727        0.0100432   1.24947            0.00498504       0.00146733   0.620187                    0.616331            0.00100422      0.999598                   -98.9957  24.9467
    15       0.90001                     1.92511e-07        0.00200864  1.11088            0.000997009      2.50825e-05  0.551396                    0.54786             0.000200844     0.999799                   -99.7991  11.0876
    16       1                           1.6675e-45         0.00200864  1                  0.000997009      1.82004e-08  0.496361                    0.49308             0.000200844     1                          -99.7991  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.016898206923904226
RMSE: 0.12999310337054126
LogLoss: 0.08032767045404529
Mean Per-Class Error: 0.015375937689519614
AUC: 0.9957745254617882
pr_auc: 0.6527792328765872
Gini: 0.9915490509235765
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46721375586955305: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3079  49    0.0157   (49.0/3128.0)
1      46    3003  0.0151   (46.0/3049.0)
Total  3125  3052  0.0154   (95.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.467214     0.984429  212
max f2                       0.34296      0.986601  237
max f0point5                 0.553489     0.986986  198
max accuracy                 0.553489     0.98462   198
max precision                0.998908     0.998501  3
max recall                   1.18107e-05  1         399
max specificity              0.999978     0.999361  0
max absolute_mcc             0.553489     0.969269  198
max min_per_class_accuracy   0.473387     0.984585  211
max mean_per_class_accuracy  0.467214     0.984624  212
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.89 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999997           2.01935     2.02263            0.996764         0.999999     0.998382                    1                   0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999929           2.01935     2.02154            0.996764         0.999975     0.997843                    0.999991            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.999308           2.02591     2.02263            1                0.999718     0.998382                    0.999923            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.989273           2.01606     2.02044            0.995138         0.99582      0.997302                    0.998557            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.92477            2.00624     2.01689            0.990291         0.966103     0.995548                    0.99044             0.200722        0.806822                   100.624   101.689
    11       0.500081                    0.379441           1.81611     1.97672            0.89644          0.770568     0.97572                     0.946451            0.181699        0.988521                   81.6107   97.6722
    12       0.599968                    0.0413024          0.0820871   1.66129            0.0405186        0.135932     0.820022                    0.811511            0.00819941      0.99672                    -91.7913  66.129
    13       0.700016                    0.00482439         0.0163909   1.4262             0.00809061       0.0189083    0.703978                    0.698229            0.00163988      0.99836                    -98.3609  42.6196
    14       0.799903                    0.000159897        0.00985045  1.24933            0.00486224       0.00151506   0.616677                    0.611228            0.000983929     0.999344                   -99.015   24.9332
    15       0.899951                    1.90555e-07        0.00655634  1.11117            0.00323625       3.18337e-05  0.54848                     0.543281            0.000655953     1                          -99.3444  11.1171
    16       1                           1.6675e-45         0           1                  0                1.68782e-08  0.493605                    0.488926            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:24:33  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:24:39  1:17:56.903  4391 obs/sec      1         1             25000      0.30347          0.409648            0.631604       0.944206        0.641152           2.01466          0.117137                         0.292479           0.383188              0.657768         0.949622          0.634913             2.02591            0.105715
    2019-08-03 17:24:50  1:18:07.771  4698 obs/sec      3         3             75000      0.237766         0.226442            0.773858       0.973065        0.728884           2.01466          0.0690858                        0.225623           0.20638               0.796343         0.977087          0.72196              2.02591            0.0592521
    2019-08-03 17:25:00  1:18:18.391  4809 obs/sec      5         5             125000     0.193713         0.152554            0.849893       0.986678        0.741725           2.01466          0.0421693                        0.189579           0.145328              0.856216         0.988229          0.725982             2.02591            0.0393395
    2019-08-03 17:25:11  1:18:28.714  4900 obs/sec      7         7             175000     0.165683         0.117927            0.89019        0.991964        0.765969           2.01466          0.0280132                        0.164454           0.11882               0.891802         0.991875          0.733245             2.02591            0.0250931
    2019-08-03 17:25:21  1:18:38.923  4968 obs/sec      9         9             225000     0.140901         0.0909255           0.920583       0.994986        0.688009           2.01466          0.0179444                        0.141707           0.0932448             0.919663         0.994726          0.685818             2.02591            0.0165129
    2019-08-03 17:25:26  1:18:44.287  5000 obs/sec      10        10            250000     0.132645         0.0804581           0.929617       0.995627        0.677135           2.01466          0.0162496                        0.129993           0.0803277             0.932396         0.995775          0.652779             2.02591            0.0153796
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C31         1.0                    1.0                  0.003254722731003478
C36         0.9571030139923096     0.9571030139923096   0.0031151049355527096
C40         0.8779810667037964     0.8779810667037964   0.002857584935191527
C34         0.8769757151603699     0.8769757151603699   0.0028543127946704873
C33         0.8546239733695984     0.8546239733695984   0.002781564072586543
---         ---                    ---                  ---
C631        0.21487993001937866    0.21487993001937866  0.0006993745926705084
C274        0.21070030331611633    0.21070030331611633  0.0006857710666322913
C633        0.20975114405155182    0.20975114405155182  0.0006826818163985707
C558        0.20640182495117188    0.20640182495117188  0.00067178071138918
C437        0.20258601009845734    0.20258601009845734  0.0006593612920507493

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_185

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.01963035145222745    0.05551569163799286   0.0         0.024674111559427104  0.0822702944278717   0.06714102369583297    0.1209503710269928
    3        2        Softmax                      0.0   0.0   0.0002533433640223848  6.83042744640261e-05  0.0         -0.01832415917488106  0.39923787117004395  0.0003671827345267456  0.06676816940307617


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01602766490339596
RMSE: 0.12660041430973265
LogLoss: 0.07254129719628159
Mean Per-Class Error: 0.013880338891870903
AUC: 0.9968110295373793
pr_auc: 0.6829213533613175
Gini: 0.9936220590747586
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5086994609791288: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4935  64    0.0128   (64.0/4999.0)
1      75    4939  0.015    (75.0/5014.0)
Total  5010  5003  0.0139   (139.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.508699     0.986124  200
max f2                       0.367947     0.986962  230
max f0point5                 0.610759     0.987963  180
max accuracy                 0.508699     0.986118  200
max precision                0.999403     0.999498  2
max recall                   1.80702e-05  1         399
max specificity              0.999979     0.9998    0
max absolute_mcc             0.508699     0.972238  200
max min_per_class_accuracy   0.483567     0.985397  204
max mean_per_class_accuracy  0.508699     0.98612   200
Gains/Lift Table: Avg response rate: 50.07 %, avg score: 49.68 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   1                  1.99701     1.99701            1                1            1                           1                   0.0201436       0.0201436                  99.7008   99.7008
    2        0.0200739                   1                  1.99701     1.99701            1                1            1                           1                   0.0199442       0.0400878                  99.7008   99.7008
    3        0.0300609                   1                  1.99701     1.99701            1                1            1                           1                   0.0199442       0.0600319                  99.7008   99.7008
    4        0.0400479                   1                  1.99701     1.99701            1                1            1                           1                   0.0199442       0.0799761                  99.7008   99.7008
    5        0.050035                    1                  1.99701     1.99701            1                1            1                           1                   0.0199442       0.0999202                  99.7008   99.7008
    6        0.10007                     0.999993           1.99701     1.99701            1                0.999998     1                           0.999999            0.0999202       0.19984                    99.7008   99.7008
    7        0.150005                    0.99988            1.99301     1.99568            0.998            0.999957     0.999334                    0.999985            0.0995213       0.299362                   99.3014   99.5679
    8        0.20004                     0.999149           1.99701     1.99601            1                0.999622     0.999501                    0.999894            0.0999202       0.399282                   99.7008   99.6011
    9        0.30001                     0.988756           1.98703     1.99302            0.995005         0.995483     0.998003                    0.998424            0.198644        0.597926                   98.7033   99.302
    10       0.39998                     0.930639           1.98903     1.99202            0.996004         0.967341     0.997503                    0.990655            0.198843        0.796769                   98.9028   99.2022
    11       0.50005                     0.496128           1.88341     1.97029            0.943114         0.808497     0.986619                    0.954202            0.188472        0.985241                   88.3406   97.0286
    12       0.60002                     0.0516092          0.119701    1.66196            0.0599401        0.171397     0.832224                    0.823778            0.0119665       0.997208                   -88.0299  66.1958
    13       0.69999                     0.00652427         0.0179551   1.42717            0.00899101       0.0228144    0.714653                    0.709387            0.00179497      0.999003                   -98.2045  42.7167
    14       0.79996                     0.000207591        0.00598504  1.24956            0.002997         0.00217626   0.625718                    0.621008            0.000598325     0.999601                   -99.4015  24.9564
    15       0.89993                     3.33072e-07        0.00399003  1.1112             0.001998         4.11291e-05  0.556431                    0.552027            0.000398883     1                          -99.601   11.1197
    16       1                           1.26879e-46        0           1                  0                2.60257e-08  0.500749                    0.496786            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.017026562979891614
RMSE: 0.13048587272150045
LogLoss: 0.08060539995176194
Mean Per-Class Error: 0.014252870212781987
AUC: 0.995959274308209
pr_auc: 0.6786256100563819
Gini: 0.9919185486164179
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4804856924302767: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3085  43    0.0137   (43.0/3128.0)
1      45    3004  0.0148   (45.0/3049.0)
Total  3130  3047  0.0142   (88.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.480486     0.985564  211
max f2                       0.367571     0.986275  233
max f0point5                 0.581331     0.98779   192
max accuracy                 0.480486     0.985754  211
max precision                0.997122     0.998658  6
max recall                   2.79176e-05  1         399
max specificity              0.999979     0.999361  0
max absolute_mcc             0.480486     0.971503  211
max min_per_class_accuracy   0.473924     0.985294  212
max mean_per_class_accuracy  0.480486     0.985747  211
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.92 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999993           2.01935     2.02263            0.996764         0.999998     0.998382                    0.999999            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999889           2.01935     2.02154            0.996764         0.99996      0.997843                    0.999986            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.999205           2.02591     2.02263            1                0.999648     0.998382                    0.999902            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.986099           2.01934     2.02154            0.996759         0.994489     0.997841                    0.998099            0.201705        0.606428                   101.934   102.154
    10       0.400032                    0.919202           2.0128      2.01935            0.993528         0.962323     0.996762                    0.989151            0.201378        0.807806                   101.28    101.935
    11       0.500081                    0.395139           1.80299     1.97607            0.889968         0.763465     0.975397                    0.944               0.180387        0.988193                   80.2994   97.6066
    12       0.599968                    0.0497223          0.0755202   1.65965            0.0372771        0.146617     0.819212                    0.811246            0.00754346      0.995736                   -92.448   65.965
    13       0.700016                    0.00688132         0.0229472   1.42573            0.0113269        0.0226594    0.703747                    0.698539            0.00229583      0.998032                   -97.7053  42.5727
    14       0.799903                    0.000251783        0.0131339   1.24933            0.00648298       0.00240372   0.616677                    0.61161             0.00131191      0.999344                   -98.6866  24.9332
    15       0.899951                    3.70234e-07        0.00327817  1.11081            0.00161812       4.76745e-05  0.5483                      0.543622            0.000327976     0.999672                   -99.6722  11.0807
    16       1                           1.0619e-42         0.00327817  1                  0.00161812       3.16186e-08  0.493605                    0.489233            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:57:43  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:57:49  3:51:06.576  4457 obs/sec      1         1             25000      0.299009         0.390893            0.642374       0.944594        0.683003           1.99701          0.112254                         0.292716           0.370677              0.657214         0.947707          0.684194             2.02591            0.108629
    2019-08-03 19:57:59  3:51:17.432  4727 obs/sec      3         3             75000      0.241038         0.218582            0.767603       0.973177        0.762848           1.99701          0.0736043                        0.233078           0.211321              0.782663         0.975475          0.742375             2.02591            0.066699
    2019-08-03 19:58:10  3:51:28.100  4822 obs/sec      5         5             125000     0.194383         0.147113            0.848861       0.987822        0.779508           1.99701          0.0405473                        0.189133           0.150041              0.856891         0.987755          0.795639             2.02591            0.0351303
    2019-08-03 19:58:20  3:51:38.419  4920 obs/sec      7         7             175000     0.163399         0.110911            0.893203       0.992736        0.737635           1.99701          0.0266653                        0.159033           0.113194              0.898817         0.992769          0.729559             2.02591            0.023798
    2019-08-03 19:58:30  3:51:48.493  5002 obs/sec      9         9             225000     0.144122         0.0913511           0.916915       0.994966        0.641752           1.99701          0.0193748                        0.138216           0.0887768             0.923572         0.995502          0.659027             2.02591            0.0158653
    2019-08-03 19:58:36  3:51:54.139  5012 obs/sec      10        10            250000     0.1266           0.0725413           0.935889       0.996811        0.682921           1.99701          0.013882                         0.130486           0.0806054             0.931883         0.995959          0.678626             2.02591            0.0142464
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003262774030966659
C31         0.8786113262176514     0.8786113262176514   0.0028667102184961285
C34         0.8710264563560486     0.8710264563560486   0.002841962502083429
C25         0.8521103858947754     0.8521103858947754   0.002780243638614451
C40         0.8214071989059448     0.8214071989059448   0.0026800660774393818
---         ---                    ---                  ---
C588        0.21027147769927979    0.21027147769927979  0.0006860683168901949
C274        0.20740006864070892    0.20740006864070892  0.0006766995579816075
C731        0.20414599776268005    0.20414599776268005  0.00066608226002585
C489        0.20335400104522705    0.20335400104522705  0.0006634981537035336
C388        0.20106996595859528    0.20106996595859528  0.0006560458633370548

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_228

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.011888545514892596    0.039072051644325256    0.0         0.024470451154354343    0.08032053709030151  0.07051750447746523     0.12403446435928345
    3        2        Softmax                      0.0   0.0   0.00021121467761986423  4.5961758587509394e-05  0.0         -0.0066328693628747715  0.3714488744735718   -0.0011380088076004963  0.07452726364135742


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01569322801504809
RMSE: 0.12527261478490856
LogLoss: 0.07593338034067769
Mean Per-Class Error: 0.014193472649909888
AUC: 0.9960048582430988
pr_auc: 0.6866369858378942
Gini: 0.9920097164861976
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47874783957270983: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4987  67    0.0133   (67.0/5054.0)
1      75    4882  0.0151   (75.0/4957.0)
Total  5062  4949  0.0142   (142.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.478748     0.985665  210
max f2                       0.349441     0.986763  238
max f0point5                 0.623171     0.987535  182
max accuracy                 0.50116      0.985816  205
max precision                0.99998      0.999349  0
max recall                   2.27171e-05  1         399
max specificity              0.99998      0.999802  0
max absolute_mcc             0.50116      0.971637  205
max min_per_class_accuracy   0.456515     0.985358  214
max mean_per_class_accuracy  0.478748     0.985807  210
Gains/Lift Table: Avg response rate: 49.52 %, avg score: 48.90 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   1                  2.01957     2.01957            1                1            1                           1                   0.0203752       0.0203752                  101.957   101.957
    2        0.0200779                   1                  2.01957     2.01957            1                1            1                           1                   0.0201735       0.0405487                  101.957   101.957
    3        0.0300669                   1                  2.01957     2.01957            1                1            1                           1                   0.0201735       0.0607222                  101.957   101.957
    4        0.0400559                   1                  2.01957     2.01957            1                1            1                           1                   0.0201735       0.0808957                  101.957   101.957
    5        0.050045                    1                  2.01957     2.01957            1                1            1                           1                   0.0201735       0.101069                   101.957   101.957
    6        0.10009                     0.999994           2.01957     2.01957            1                0.999999     1                           0.999999            0.101069        0.202138                   101.957   101.957
    7        0.150035                    0.999876           2.01553     2.01822            0.998            0.999956     0.999334                    0.999985            0.100666        0.302804                   101.553   101.822
    8        0.20008                     0.999095           2.01554     2.01755            0.998004         0.999579     0.999001                    0.999884            0.100867        0.403672                   101.554   101.755
    9        0.30007                     0.987657           2.00545     2.01352            0.993007         0.994983     0.997004                    0.998251            0.200525        0.604196                   100.545   101.352
    10       0.40006                     0.931302           2.00545     2.0115             0.993007         0.96547      0.996005                    0.990057            0.200525        0.804721                   100.545   101.15
    11       0.50005                     0.374002           1.83597     1.9764             0.909091         0.784388     0.978626                    0.948932            0.183579        0.988299                   83.5971   97.6401
    12       0.60004                     0.0379708          0.0827196   1.66084            0.040959         0.127277     0.822374                    0.812012            0.00827113      0.996571                   -91.728   66.084
    13       0.70003                     0.00409184         0.018158    1.4262             0.00899101       0.0160783    0.706193                    0.698323            0.00181561      0.998386                   -98.1842  42.6205
    14       0.80002                     0.000112229        0.0040351   1.24846            0.001998         0.00123263   0.61818                     0.611198            0.00040347      0.99879                    -99.5965  24.8456
    15       0.90001                     8.91025e-08        0.0100878   1.11087            0.004995         2.17365e-05  0.550055                    0.543297            0.00100867      0.999798                   -98.9912  11.0875
    16       1                           2.15736e-51        0.00201755  1                  0.000999001      8.6001e-09   0.495155                    0.488973            0.000201735     1                          -99.7982  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.014955912224040628
RMSE: 0.12229436709857339
LogLoss: 0.08093552648726834
Mean Per-Class Error: 0.011182652649520675
AUC: 0.9956673669367929
pr_auc: 0.7010282944516855
Gini: 0.9913347338735858
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4847734907400442: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3096  32    0.0102   (32.0/3128.0)
1      37    3012  0.0121   (37.0/3049.0)
Total  3133  3044  0.0112   (69.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.484773     0.988676  211
max f2                       0.419525     0.988593  220
max f0point5                 0.484773     0.989163  211
max accuracy                 0.484773     0.98883   211
max precision                0.999548     0.998318  2
max recall                   2.1638e-05   1         399
max specificity              0.99999      0.999361  0
max absolute_mcc             0.484773     0.977656  211
max min_per_class_accuracy   0.446019     0.988491  216
max mean_per_class_accuracy  0.484773     0.988817  211
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.77 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.95949     2.0128             0.967213         1            0.993528                    1                   0.0193506       0.100689                   95.9487   101.28
    6        0.100049                    0.999995           2.02591     2.01935            1                0.999999     0.996764                    0.999999            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999911           2.02591     2.02154            1                0.999967     0.997843                    0.999989            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.999227           2.02591     2.02263            1                0.999646     0.998382                    0.999903            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.988164           2.01606     2.02044            0.995138         0.99541      0.997302                    0.998407            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.926911           2.01608     2.01935            0.995146         0.965108     0.996762                    0.990079            0.201705        0.807806                   101.608   101.935
    11       0.500081                    0.350468           1.82266     1.98               0.899676         0.774673     0.977339                    0.946984            0.182355        0.990161                   82.2663   98.0001
    12       0.599968                    0.0375092          0.0492523   1.65856            0.0243112        0.124192     0.818672                    0.81                0.00491965      0.99508                    -95.0748  65.8557
    13       0.700016                    0.0042219          0.0295035   1.42573            0.0145631        0.0162049    0.703747                    0.696548            0.00295179      0.998032                   -97.0496  42.5727
    14       0.799903                    0.000109619        0.00656697  1.24851            0.00324149       0.00124893   0.616272                    0.609724            0.000655953     0.998688                   -99.3433  24.8512
    15       0.899951                    1.36302e-07        0.00983452  1.11081            0.00485437       2.25352e-05  0.5483                      0.541943            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           2.15736e-51        0.00327817  1                  0.00161812       1.45628e-08  0.493605                    0.487722            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:46:41  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:46:46  4:40:04.299  4454 obs/sec      1         1             25000      0.311379         0.439359            0.612137       0.941209        0.59952            2.01957          0.11787                          0.302441           0.409309              0.634058         0.947306          0.63202              2.02591            0.113324
    2019-08-03 20:46:58  4:40:15.661  4588 obs/sec      3         3             75000      0.232283         0.212656            0.784159       0.97528         0.748871           2.01957          0.0637299                        0.230846           0.215771              0.786805         0.975578          0.752577             2.02591            0.0628137
    2019-08-03 20:47:08  4:40:26.388  4723 obs/sec      5         5             125000     0.189108         0.143334            0.85694        0.987914        0.773084           2.01957          0.0397563                        0.18752            0.149056              0.859322         0.987585          0.770415             2.02591            0.035616
    2019-08-03 20:47:19  4:40:37.190  4776 obs/sec      7         7             175000     0.158412         0.111037            0.899613       0.992361        0.716015           2.01957          0.0232744                        0.154957           0.110268              0.903938         0.993399          0.698861             2.02591            0.0221791
    2019-08-03 20:47:29  4:40:47.412  4871 obs/sec      9         9             225000     0.133502         0.0843504           0.928703       0.995294        0.622646           2.01957          0.0148836                        0.133767           0.0849611             0.928413         0.995509          0.66854              2.02591            0.0150559
    2019-08-03 20:47:35  4:40:52.978  4898 obs/sec      10        10            250000     0.125273         0.0759334           0.937221       0.996005        0.686637           2.01957          0.0141844                        0.122294           0.0809355             0.940167         0.995667          0.701028             2.02591            0.0111705
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C27         1.0                    1.0                  0.002915710544056161
C36         0.9891068339347839     0.9891068339347839   0.0028839492249016557
C28         0.9614819884300232     0.9614819884300232   0.002803403171585502
C35         0.9314625263214111     0.9314625263214111   0.0027158751093885277
C40         0.8987470865249634     0.8987470865249634   0.0026204863566205907
---         ---                    ---                  ---
C478        0.23538817465305328    0.23538817465305328  0.0006863237827820407
C533        0.23504842817783356    0.23504842817783356  0.0006853331804019365
C307        0.23289069533348083    0.23289069533348083  0.0006790418559964011
C887        0.22851160168647766    0.22851160168647766  0.0006662736864764245
C523        0.22809384763240814    0.22809384763240814  0.0006650556365761518

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_193

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.03114484611862527    0.08868473768234253    0.0         0.022496422561102795   0.07317525148391724  0.10635528697011351    0.09423243999481201
    3        2        Softmax                      0.0   0.0   0.0003209160465758032  7.294811075553298e-05  0.0         -0.015819769413155882  0.24783766269683838  4.813770928949884e-05  0.080282062292099


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01706722646829167
RMSE: 0.13064159547514592
LogLoss: 0.0805894142703341
Mean Per-Class Error: 0.014890826131084611
AUC: 0.9962432709461364
pr_auc: 0.6902825075703914
Gini: 0.9924865418922728
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49283497242393065: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4900  84    0.0169   (84.0/4984.0)
1      65    4961  0.0129   (65.0/5026.0)
Total  4965  5045  0.0149   (149.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.492835     0.985205  209
max f2                       0.3956       0.987591  230
max f0point5                 0.586234     0.986784  191
max accuracy                 0.497722     0.985115  208
max precision                0.996861     0.999162  7
max recall                   1.76027e-05  1         399
max specificity              0.999972     0.999599  0
max absolute_mcc             0.492835     0.970236  209
max min_per_class_accuracy   0.519692     0.98435   204
max mean_per_class_accuracy  0.497722     0.985109  208
Gains/Lift Table: Avg response rate: 50.21 %, avg score: 50.13 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   1                  1.99164     1.99164            1                1            1                           1                   0.0200955       0.0200955                  99.1643   99.1643
    2        0.0200799                   1                  1.99164     1.99164            1                1            1                           1                   0.0198965       0.039992                   99.1643   99.1643
    3        0.0300699                   1                  1.99164     1.99164            1                1            1                           1                   0.0198965       0.0598886                  99.1643   99.1643
    4        0.0400599                   1                  1.99164     1.99164            1                1            1                           1                   0.0198965       0.0797851                  99.1643   99.1643
    5        0.05005                     1                  1.99164     1.99164            1                1            1                           1                   0.0198965       0.0996817                  99.1643   99.1643
    6        0.1                         0.99999            1.98368     1.98766            0.996            0.999998     0.998002                    0.999999            0.0990848       0.198766                   98.3677   98.7664
    7        0.15005                     0.99982            1.99164     1.98899            1                0.999936     0.998668                    0.999978            0.0996817       0.298448                   99.1643   98.8991
    8        0.2                         0.998767           1.99164     1.98965            1                0.999441     0.999001                    0.999844            0.0994827       0.397931                   99.1643   98.9654
    9        0.3                         0.986281           1.98368     1.98766            0.996004         0.994398     0.998002                    0.998028            0.198368        0.596299                   98.3685   98.7664
    10       0.4                         0.926961           1.97175     1.98368            0.99001          0.963718     0.996004                    0.989451            0.197175        0.793474                   97.1747   98.3685
    11       0.5                         0.547161           1.88818     1.96458            0.948052         0.816432     0.986414                    0.954847            0.188818        0.982292                   88.8181   96.4584
    12       0.6                         0.0694037          0.151214    1.66236            0.0759241        0.204183     0.834665                    0.829736            0.0151214       0.997413                   -84.8786  66.2356
    13       0.7                         0.00923528         0.00795862  1.42601            0.003996         0.0314412    0.715998                    0.715694            0.000795862     0.998209                   -99.2041  42.6013
    14       0.8                         0.000376509        0.00596896  1.24851            0.002997         0.00318881   0.626873                    0.626631            0.000596896     0.998806                   -99.4031  24.8508
    15       0.9                         6.39167e-07        0.00994827  1.11089            0.004995         7.35241e-05  0.557776                    0.557013            0.000994827     0.999801                   -99.0052  11.089
    16       1                           5.57416e-45        0.00198965  1                  0.000999001      6.60843e-08  0.502098                    0.501312            0.000198965     1                          -99.801   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.016719861908977167
RMSE: 0.1293053050302932
LogLoss: 0.08164623027973766
Mean Per-Class Error: 0.012490416546786065
AUC: 0.9959529832010663
pr_auc: 0.6736570281087265
Gini: 0.9919059664021326
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5352868696081226: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3095  33    0.0105   (33.0/3128.0)
1      44    3005  0.0144   (44.0/3049.0)
Total  3139  3038  0.0125   (77.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.535287     0.98735   197
max f2                       0.455267     0.987687  214
max f0point5                 0.5884       0.989393  185
max accuracy                 0.535287     0.987534  197
max precision                0.995426     0.99871   9
max recall                   1.67816e-05  1         399
max specificity              0.999972     0.999361  0
max absolute_mcc             0.535287     0.97507   197
max min_per_class_accuracy   0.497562     0.986881  203
max mean_per_class_accuracy  0.535287     0.98751   197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.12 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999993           2.0128      2.01935            0.993528         0.999998     0.996764                    0.999999            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999849           2.02591     2.02154            1                0.999946     0.997843                    0.999981            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.999043           2.02591     2.02263            1                0.99955      0.998382                    0.999873            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.985429           2.01606     2.02044            0.995138         0.994115     0.997302                    0.997956            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.918675           2.0128      2.01853            0.993528         0.960509     0.996358                    0.988591            0.201378        0.807478                   101.28    101.853
    11       0.500081                    0.405817           1.81939     1.97869            0.898058         0.768773     0.976691                    0.944613            0.182027        0.989505                   81.9385   97.8689
    12       0.599968                    0.0599468          0.0656697   1.6602             0.0324149        0.157542     0.819482                    0.813576            0.00655953      0.996064                   -93.433   66.0197
    13       0.700016                    0.00843949         0.019669    1.42573            0.00970874       0.027733     0.703747                    0.701261            0.00196786      0.998032                   -98.0331  42.5727
    14       0.799903                    0.000376399        0.0131339   1.24933            0.00648298       0.00299039   0.616677                    0.614065            0.00131191      0.999344                   -98.6866  24.9332
    15       0.899951                    8.65524e-07        0.00327817  1.11081            0.00161812       7.96515e-05  0.5483                      0.545808            0.000327976     0.999672                   -99.6722  11.0807
    16       1                           9.34955e-43        0.00327817  1                  0.00161812       7.94314e-08  0.493605                    0.491201            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:04:42  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:04:52  3:58:10.593  2566 obs/sec      1         1             25000      0.310115         0.432543            0.615308       0.940332        0.593927           1.97192          0.121479                         0.297275           0.398123              0.646452         0.947555          0.603835             1.99323            0.109924
    2019-08-03 20:05:11  3:58:29.626  2705 obs/sec      3         3             75000      0.243842         0.225633            0.762159       0.972032        0.786946           1.99164          0.071029                         0.232651           0.20803               0.783459         0.976206          0.831689             2.02591            0.0660515
    2019-08-03 20:05:30  3:58:48.137  2773 obs/sec      5         5             125000     0.20717          0.165745            0.82832        0.984694        0.796099           1.99164          0.0492507                        0.196875           0.15374               0.844935         0.986988          0.804441             2.02591            0.0403108
    2019-08-03 20:05:47  3:59:05.428  2854 obs/sec      7         7             175000     0.171783         0.126487            0.881961       0.990995        0.748096           1.99164          0.0303696                        0.167241           0.124365              0.888104         0.991224          0.760487             2.02591            0.0276833
    2019-08-03 20:06:04  3:59:22.384  2918 obs/sec      9         9             225000     0.143406         0.0957031           0.917738       0.994851        0.69728            1.99164          0.0180819                        0.141501           0.093603              0.919897         0.994757          0.67183              2.02591            0.0158653
    2019-08-03 20:06:13  3:59:31.481  2938 obs/sec      10        10            250000     0.130642         0.0805894           0.93173        0.996243        0.690283           1.99164          0.0148851                        0.129305           0.0816462             0.93311          0.995953          0.673657             2.02591            0.0124656
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C34         1.0                    1.0                  0.0028147317658152177
C31         0.9952564239501953     0.9952564239501953   0.002801379871624272
C36         0.9790195822715759     0.9790195822715759   0.0027556775175749497
C27         0.9392337799072266     0.9392337799072266   0.002643691155831569
C28         0.9376344680786133     0.9376344680786133   0.0026391895220241276
---         ---                    ---                  ---
C854        0.25733062624931335    0.25733062624931335  0.0007243166880210656
C562        0.2570839822292328     0.2570839822292328   0.0007236224512628965
C582        0.2560768723487854     0.2560768723487854   0.0007207877070907348
C468        0.2546789050102234     0.2546789050102234   0.0007168528040153121
C476        0.2543545961380005     0.2543545961380005   0.0007159399615307307

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_134

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms          mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  ------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.02596453041194819     0.09281948208808899    0.0         0.024453450288158447   0.0778958797454834  0.06901776591743522      0.11322036385536194
    3        2        Softmax                      0.0   0.0   0.00026007668753891267  7.748504867777228e-05  0.0         -0.012434238309651846  0.3838242292404175  -0.00040725566187264917  0.1037759780883789


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01632812755835714
RMSE: 0.1277815618872971
LogLoss: 0.08208096607012409
Mean Per-Class Error: 0.012576302594288213
AUC: 0.9960711653962318
pr_auc: 0.6653455644516512
Gini: 0.9921423307924635
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47171868354301866: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4959  57    0.0114   (57.0/5016.0)
1      69    4935  0.0138   (69.0/5004.0)
Total  5028  4992  0.0126   (126.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.471719     0.987395  211
max f2                       0.409519     0.987785  225
max f0point5                 0.551672     0.988851  194
max accuracy                 0.471719     0.987425  211
max precision                0.999626     0.998429  1
max recall                   1.38652e-05  1         399
max specificity              0.999978     0.999402  0
max absolute_mcc             0.471719     0.974853  211
max min_per_class_accuracy   0.456818     0.986811  215
max mean_per_class_accuracy  0.471719     0.987424  211
Gains/Lift Table: Avg response rate: 49.94 %, avg score: 49.01 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0103792                   1                  2.0024      2.0024             1                1            1                           1                   0.0207834       0.0207834                  100.24    100.24
    2        0.0200599                   1                  2.0024      2.0024             1                1            1                           1                   0.0193845       0.0401679                  100.24    100.24
    3        0.0300399                   1                  2.0024      2.0024             1                1            1                           1                   0.019984        0.0601519                  100.24    100.24
    4        0.04002                     1                  1.98237     1.9974             0.99             1            0.997506                    1                   0.0197842       0.0799361                  98.2374   99.7405
    5        0.05                        1                  1.98237     1.9944             0.99             1            0.996008                    1                   0.0197842       0.0997202                  98.2374   99.4404
    6        0.1                         0.999997           1.9984      1.9964             0.998004         0.999999     0.997006                    1                   0.0999201       0.19964                    99.8401   99.6403
    7        0.15                        0.999911           2.0024      1.9984             1                0.999973     0.998004                    0.999991            0.10012         0.29976                    100.24    99.8401
    8        0.2                         0.999115           1.9984      1.9984             0.998004         0.99964      0.998004                    0.999903            0.0999201       0.39968                    99.8401   99.8401
    9        0.3                         0.98585            1.98641     1.9944             0.992016         0.994697     0.996008                    0.998168            0.198641        0.598321                   98.6411   99.4404
    10       0.4                         0.91454            1.98641     1.99241            0.992016         0.959431     0.99501                     0.988484            0.198641        0.796962                   98.6411   99.2406
    11       0.5                         0.446033           1.90048     1.97402            0.949102         0.777719     0.985828                    0.946331            0.190048        0.98701                    90.048    97.4021
    12       0.6                         0.0414427          0.107914    1.663              0.0538922        0.150612     0.830506                    0.813711            0.0107914       0.997802                   -89.2086  66.3003
    13       0.7                         0.00461833         0.00999201  1.42686            0.00499002       0.0176572    0.712575                    0.699989            0.000999201     0.998801                   -99.0008  42.6859
    14       0.8                         0.000147431        0.0039968   1.249              0.00199601       0.00149131   0.623752                    0.612677            0.00039968      0.999201                   -99.6003  24.9001
    15       0.9                         1.33309e-07        0.0059952   1.11089            0.00299401       2.77215e-05  0.554779                    0.544605            0.00059952      0.9998                     -99.4005  11.0889
    16       1                           2.66732e-50        0.0019984   1                  0.000998004      1.02656e-08  0.499401                    0.490144            0.00019984      1                          -99.8002  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.01729019157287575
RMSE: 0.13149217304796415
LogLoss: 0.08403741319804647
Mean Per-Class Error: 0.014412716760096589
AUC: 0.9954965109519788
pr_auc: 0.6675396726394216
Gini: 0.9909930219039575
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4698665903522939: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3084  44    0.0141   (44.0/3128.0)
1      45    3004  0.0148   (45.0/3049.0)
Total  3129  3048  0.0144   (89.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.469867     0.985403  214
max f2                       0.306386     0.986937  246
max f0point5                 0.525018     0.986603  203
max accuracy                 0.480856     0.985592  211
max precision                0.99934      0.997654  2
max recall                   1.60014e-05  1         399
max specificity              0.999985     0.999041  0
max absolute_mcc             0.480856     0.97118   211
max min_per_class_accuracy   0.467314     0.985294  215
max mean_per_class_accuracy  0.469867     0.985587  214
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.67 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999998           2.02591     2.01935            1                1            0.996764                    1                   0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999929           2.01935     2.01935            0.996764         0.999977     0.996764                    0.999992            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.999235           2.02591     2.02099            1                0.99969      0.997573                    0.999917            0.101345        0.404395                   102.591   102.099
    9        0.299984                    0.986792           2.01278     2.01826            0.993517         0.995186     0.996222                    0.998341            0.20105         0.605444                   101.278   101.826
    10       0.400032                    0.917368           2.00296     2.01443            0.988673         0.95981      0.994334                    0.988705            0.200394        0.805838                   100.296   101.443
    11       0.500081                    0.355766           1.82922     1.97738            0.902913         0.76133      0.976044                    0.943215            0.183011        0.988849                   82.922    97.7377
    12       0.599968                    0.0410218          0.0886541   1.66293            0.0437601        0.130283     0.820831                    0.807873            0.00885536      0.997704                   -91.1346  66.293
    13       0.700016                    0.00494862         0.00983452  1.42666            0.00485437       0.0185267    0.704209                    0.695057            0.000983929     0.998688                   -99.0165  42.6664
    14       0.799903                    0.000166492        0.00656697  1.24933            0.00324149       0.00161794   0.616677                    0.608465            0.000655953     0.999344                   -99.3433  24.9332
    15       0.899951                    2.26055e-07        0.00655634  1.11117            0.00323625       3.10756e-05  0.54848                     0.540824            0.000655953     1                          -99.3444  11.1171
    16       1                           2.29258e-45        0           1                  0                1.74258e-08  0.493605                    0.486716            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:35:53  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:35:59  2:29:16.961  4476 obs/sec      1         1             25000      0.312467         0.48318             0.609457       0.938779        0.619234           2.0024           0.122854                         0.299336           0.416759              0.641533         0.947048          0.620645             2.02591            0.113647
    2019-08-03 18:36:10  2:29:28.165  4633 obs/sec      3         3             75000      0.235884         0.228565            0.777434       0.973541        0.713025           2.0024           0.0674651                        0.225132           0.202159              0.797229         0.978136          0.720456             2.02591            0.0600615
    2019-08-03 18:36:21  2:29:38.828  4765 obs/sec      5         5             125000     0.190118         0.154224            0.855421       0.987017        0.718727           2.0024           0.039022                         0.184604           0.141947              0.863664         0.988781          0.722064             2.02591            0.0365873
    2019-08-03 18:36:31  2:29:49.102  4875 obs/sec      7         7             175000     0.160581         0.118591            0.896854       0.992086        0.708073           2.0024           0.0245509                        0.157341           0.112836              0.900959         0.993065          0.7041               2.02591            0.0225028
    2019-08-03 18:36:41  2:29:59.257  4958 obs/sec      9         9             225000     0.144653         0.103913            0.916302       0.99343         0.671599           2.0024           0.0186627                        0.144207           0.106436              0.916803         0.992925          0.638189             2.02591            0.0184556
    2019-08-03 18:36:47  2:30:04.622  4992 obs/sec      10        10            250000     0.127782         0.082081            0.934687       0.996071        0.665346           2.0024           0.0125749                        0.131492           0.0840374             0.930828         0.995497          0.66754              2.02591            0.0144083
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.00301168848092469
C35         0.913266122341156      0.913266122341156    0.0027504730606736183
C40         0.9001387357711792     0.9001387357711792   0.0027109374617561737
C34         0.8971083760261536     0.8971083760261536   0.002701810962219022
C28         0.8594432473182678     0.8594432473182678   0.0025883753279569367
---         ---                    ---                  ---
C462        0.23070476949214935    0.23070476949214935  0.000694810896773892
C439        0.22849322855472565    0.22849322855472565  0.0006881504244075597
C430        0.22841274738311768    0.22841274738311768  0.0006879080401900966
C435        0.22463805973529816    0.22463805973529816  0.0006765398568820698
C464        0.2191789746284485     0.2191789746284485   0.0006600987931493832

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_129

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.025161512995451836   0.0609145313501358    0.0         0.02284397562561335   0.07684916257858276  0.09285009755945366     0.09669941663742065
    3        2        Softmax                      0.0   0.0   0.0003108356197003559  7.68153986427933e-05  0.0         0.022427555191598003  0.24755030870437622  -0.0002935532093155564  0.055139750242233276


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.019911232827556104
RMSE: 0.14110716788156477
LogLoss: 0.0930226400521268
Mean Per-Class Error: 0.018171983468755926
AUC: 0.9946763239723442
pr_auc: 0.6957911555813954
Gini: 0.9893526479446884
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5380886324999975: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4890  102   0.0204   (102.0/4992.0)
1      80    4947  0.0159   (80.0/5027.0)
Total  4970  5049  0.0182   (182.0/10019.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.538089     0.981937  194
max f2                       0.401989     0.985031  220
max f0point5                 0.664297     0.983063  165
max accuracy                 0.542039     0.981835  193
max precision                0.999675     0.999428  1
max recall                   1.61406e-05  1         399
max specificity              0.999977     0.9998    0
max absolute_mcc             0.538089     0.963677  194
max min_per_class_accuracy   0.569455     0.981301  187
max mean_per_class_accuracy  0.542039     0.981828  193
Gains/Lift Table: Avg response rate: 50.17 %, avg score: 50.60 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100808                   1                  1.99304     1.99304            1                1            1                           1                   0.0200915       0.0200915                  99.3038   99.3038
    2        0.0200619                   1                  1.99304     1.99304            1                1            1                           1                   0.0198926       0.0399841                  99.3038   99.3038
    3        0.0300429                   1                  1.99304     1.99304            1                1            1                           1                   0.0198926       0.0598767                  99.3038   99.3038
    4        0.040024                    1                  1.99304     1.99304            1                1            1                           1                   0.0198926       0.0797692                  99.3038   99.3038
    5        0.050005                    1                  1.99304     1.99304            1                1            1                           1                   0.0198926       0.0996618                  99.3038   99.3038
    6        0.10001                     0.999989           1.98906     1.99105            0.998004         0.999997     0.999002                    0.999999            0.0994629       0.199125                   98.9059   99.1049
    7        0.150015                    0.999829           1.99304     1.99171            1                0.999937     0.999335                    0.999978            0.0996618       0.298787                   99.3038   99.1712
    8        0.20002                     0.998686           1.98906     1.99105            0.998004         0.999395     0.999002                    0.999832            0.0994629       0.398249                   98.9059   99.1049
    9        0.30003                     0.986897           1.97911     1.98707            0.993014         0.99434      0.997006                    0.998001            0.197931        0.596181                   97.9114   98.707
    10       0.40004                     0.932209           1.96718     1.9821             0.987026         0.96687      0.994511                    0.990219            0.196738        0.792918                   96.718    98.2098
    11       0.50005                     0.58557            1.86574     1.95883            0.936128         0.823683     0.982834                    0.956912            0.186592        0.979511                   86.5738   95.8826
    12       0.59996                     0.0833026          0.159284    1.65915            0.0799201        0.229652     0.832474                    0.835802            0.0159141       0.995425                   -84.0716  65.9152
    13       0.69997                     0.0134204          0.0119344   1.4238             0.00598802       0.0405989    0.714388                    0.722186            0.00119355      0.996618                   -98.8066  42.3801
    14       0.79998                     0.000590579        0.0218797   1.24854            0.010978         0.00490992   0.62645                     0.632515            0.00218818      0.998806                   -97.812   24.8539
    15       0.89999                     1.31892e-06        0.00795624  1.11068            0.00399202       0.000118781  0.557281                    0.562241            0.000795703     0.999602                   -99.2044  11.0681
    16       1                           7.57374e-37        0.00397812  1                  0.00199601       1.29637e-07  0.501747                    0.506011            0.000397852     1                          -99.6022  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.017982550222718535
RMSE: 0.13409903140111987
LogLoss: 0.08431769438184723
Mean Per-Class Error: 0.015035536367212776
AUC: 0.99590181552964
pr_auc: 0.6764979631207206
Gini: 0.9918036310592799
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5511856498037351: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3076  52    0.0166   (52.0/3128.0)
1      41    3008  0.0134   (41.0/3049.0)
Total  3117  3060  0.0151   (93.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.551186     0.984777  186
max f2                       0.373774     0.987739  222
max f0point5                 0.601413     0.984784  175
max accuracy                 0.551186     0.984944  186
max precision                0.996155     0.998696  8
max recall                   1.41076e-05  1         399
max specificity              0.999973     0.999361  0
max absolute_mcc             0.551186     0.969891  186
max min_per_class_accuracy   0.567956     0.984015  183
max mean_per_class_accuracy  0.551186     0.984964  186
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.05 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.99999            2.01935     2.01935            0.996764         0.999998     0.996764                    0.999999            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999856           2.02591     2.02154            1                0.999946     0.997843                    0.999981            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.998874           2.02591     2.02263            1                0.999506     0.998382                    0.999862            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.98686            2.01606     2.02044            0.995138         0.99469      0.997302                    0.99814             0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.930368           2.00952     2.01771            0.991909         0.965596     0.995953                    0.990001            0.20105         0.80715                    100.952   101.771
    11       0.500081                    0.46125            1.81939     1.97803            0.898058         0.803028     0.976368                    0.952594            0.182027        0.989177                   81.9385   97.8033
    12       0.599968                    0.0788654          0.0755202   1.66129            0.0372771        0.197042     0.820022                    0.826805            0.00754346      0.99672                    -92.448   66.129
    13       0.700016                    0.0129682          0.0131127   1.42573            0.00647249       0.0394866    0.703747                    0.714279            0.00131191      0.998032                   -98.6887  42.5727
    14       0.799903                    0.000608649        0.0131339   1.24933            0.00648298       0.00480726   0.616677                    0.625685            0.00131191      0.999344                   -98.6866  24.9332
    15       0.899951                    1.77608e-06        0.00655634  1.11117            0.00323625       0.00013179   0.54848                     0.556141            0.000655953     1                          -99.3444  11.1171
    16       1                           1.91833e-42        0           1                  0                1.73979e-07  0.493605                    0.5005              0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:32:31  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:32:41  2:25:59.069  2589 obs/sec      1         1             25000      0.305445         0.384865            0.626808       0.942428        0.694326           1.9733           0.116579                         0.29238            0.349238              0.657999         0.949851          0.728269             1.99323            0.110895
    2019-08-03 18:32:59  2:26:17.450  2778 obs/sec      3         3             75000      0.244657         0.222846            0.760568       0.971656        0.804127           1.99304          0.0716638                        0.236541           0.209342              0.776156         0.975376          0.824349             1.99323            0.0660515
    2019-08-03 18:33:16  2:26:34.902  2880 obs/sec      5         5             125000     0.21397          0.178448            0.816866       0.981994        0.797635           1.99304          0.0509033                        0.205942           0.164975              0.830323         0.984926          0.80147              2.02591            0.047434
    2019-08-03 18:33:34  2:26:52.117  2940 obs/sec      7         7             175000     0.178505         0.134664            0.872542       0.989535        0.735192           1.99304          0.0323386                        0.172897           0.127167              0.880407         0.990974          0.794091             2.02591            0.0289785
    2019-08-03 18:33:50  2:27:08.762  2994 obs/sec      9         9             225000     0.15488          0.110149            0.904048       0.992546        0.691157           1.99304          0.0223575                        0.148372           0.100501              0.911929         0.994109          0.68258              2.02591            0.0194269
    2019-08-03 18:33:59  2:27:17.377  3025 obs/sec      10        10            250000     0.141107         0.0930226           0.920354       0.994676        0.695791           1.99304          0.0181655                        0.134099           0.0843177             0.928058         0.995902          0.676498             2.02591            0.0150559
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003078020571792137
C31         0.9954037666320801     0.9954037666320801   0.003063873270932922
C28         0.9515182971954346     0.9515182971954346   0.002928792893204172
C24         0.9360852241516113     0.9360852241516113   0.002881289576889313
C34         0.9132697582244873     0.9132697582244873   0.002811063103410603
---         ---                    ---                  ---
C985        0.2298244833946228     0.2298244833946228   0.0007074044877901493
C872        0.22971227765083313    0.22971227765083313  0.0007070591162024915
C631        0.2296736240386963     0.2296736240386963   0.0007069401395891602
C588        0.22609351575374603    0.22609351575374603  0.0006959204926388399
C589        0.21876917779445648    0.21876917779445648  0.0006733760297253887

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_29

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.016204161697911397   0.046749815344810486   0.0         0.024802664188716197  0.08036801218986511  0.08485794964480266      0.11080867052078247
    3        2        Softmax                      0.0   0.0   0.0002326657854609948  6.726745050400496e-05  0.0         0.03207043149859601   0.3760267496109009   -0.00014416694121383022  0.08208060264587402


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.016882884214120184
RMSE: 0.1299341533782407
LogLoss: 0.08036141664675135
Mean Per-Class Error: 0.015254548514942456
AUC: 0.9956045744587618
pr_auc: 0.701539284337532
Gini: 0.9912091489175237
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4663636337079744: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4921  84    0.0168   (84.0/5005.0)
1      69    4958  0.0137   (69.0/5027.0)
Total  4990  5042  0.0153   (153.0/10032.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.466364     0.984805  213
max f2                       0.36847      0.98715   231
max f0point5                 0.649115     0.987159  171
max accuracy                 0.466364     0.984749  213
max precision                0.999783     0.999416  1
max recall                   1.14586e-05  1         399
max specificity              0.999982     0.9998    0
max absolute_mcc             0.466364     0.969502  213
max min_per_class_accuracy   0.500055     0.984216  205
max mean_per_class_accuracy  0.466364     0.984745  213
Gains/Lift Table: Avg response rate: 50.11 %, avg score: 49.69 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101675                   1                  1.99562     1.99562            1                1            1                           1                   0.0202904       0.0202904                  99.5624   99.5624
    2        0.0200359                   1                  1.99562     1.99562            1                1            1                           1                   0.0196937       0.0399841                  99.5624   99.5624
    3        0.030004                    1                  1.99562     1.99562            1                1            1                           1                   0.0198926       0.0598767                  99.5624   99.5624
    4        0.0400718                   1                  1.99562     1.99562            1                1            1                           1                   0.0200915       0.0799682                  99.5624   99.5624
    5        0.0500399                   1                  1.99562     1.99562            1                1            1                           1                   0.0198926       0.0998608                  99.5624   99.5624
    6        0.10008                     0.999993           1.99562     1.99562            1                0.999998     1                           0.999999            0.0998608       0.199722                   99.5624   99.5624
    7        0.15002                     0.99986            1.99164     1.9943             0.998004         0.999949     0.999336                    0.999982            0.0994629       0.299184                   99.164    99.4298
    8        0.20006                     0.998895           1.98767     1.99264            0.996016         0.999508     0.998505                    0.999864            0.0994629       0.398647                   98.7673   99.2641
    9        0.30004                     0.98775            1.98369     1.98966            0.994018         0.994998     0.99701                     0.998242            0.198329        0.596976                   98.3686   98.9657
    10       0.40002                     0.928328           1.97772     1.98667            0.991027         0.966307     0.995515                    0.99026             0.197732        0.794709                   97.7717   98.6672
    11       0.5                         0.514125           1.88619     1.96658            0.945165         0.809686     0.985447                    0.954153            0.188582        0.98329                    88.6193   96.658
    12       0.59998                     0.0533727          0.121369    1.6591             0.0608175        0.173958     0.831367                    0.824142            0.0121345       0.995425                   -87.8631  65.9096
    13       0.69996                     0.0059829          0.0238759   1.42553            0.0119641        0.0222528    0.714326                    0.709603            0.00238711      0.997812                   -97.6124  42.5527
    14       0.79994                     0.000183119        0.0119379   1.24885            0.00598205       0.00195797   0.625794                    0.621158            0.00119355      0.999005                   -98.8062  24.885
    15       0.89992                     1.98379e-07        0.00994827  1.11121            0.00498504       3.41289e-05  0.556823                    0.552152            0.000994629     1                          -99.0052  11.121
    16       1                           2.30815e-48        0           1                  0                1.82441e-08  0.501096                    0.496893            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.01683061482889302
RMSE: 0.12973285948013719
LogLoss: 0.08473939723662756
Mean Per-Class Error: 0.014580846598482244
AUC: 0.9956401054725084
pr_auc: 0.651145713878994
Gini: 0.9912802109450167
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5046077461683574: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3085  43    0.0137   (43.0/3128.0)
1      47    3002  0.0154   (47.0/3049.0)
Total  3132  3045  0.0146   (90.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.504608     0.985231  204
max f2                       0.375033     0.986257  225
max f0point5                 0.580238     0.987038  190
max accuracy                 0.539905     0.98543   197
max precision                0.999594     0.998285  1
max recall                   8.62468e-06  1         399
max specificity              0.999968     0.999361  0
max absolute_mcc             0.539905     0.970861  197
max min_per_class_accuracy   0.466594     0.984974  209
max mean_per_class_accuracy  0.504608     0.985419  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.03 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999994           2.01935     2.01935            0.996764         0.999999     0.996764                    0.999999            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999899           2.02591     2.02154            1                0.999965     0.997843                    0.999988            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.999124           2.01935     2.02099            0.996764         0.999621     0.997573                    0.999896            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.987577           2.01606     2.01935            0.995138         0.994754     0.996762                    0.998184            0.201378        0.605772                   101.606   101.935
    10       0.400032                    0.922631           2.0128      2.01771            0.993528         0.964079     0.995953                    0.989654            0.201378        0.80715                    101.28    101.771
    11       0.500081                    0.358278           1.81283     1.97672            0.894822         0.772855     0.97572                     0.94628             0.181371        0.988521                   81.2829   97.6722
    12       0.599968                    0.0501991          0.0755202   1.6602             0.0372771        0.146233     0.819482                    0.813083            0.00754346      0.996064                   -92.448   66.0197
    13       0.700016                    0.00645092         0.0229472   1.4262             0.0113269        0.0222263    0.703978                    0.700051            0.00229583      0.99836                    -97.7053  42.6196
    14       0.799903                    0.000186344        0.00328348  1.24851            0.00162075       0.00204595   0.616272                    0.612889            0.000327976     0.998688                   -99.6717  24.8512
    15       0.899951                    2.25063e-07        0.00655634  1.11044            0.00323625       3.59025e-05  0.54812                     0.544757            0.000655953     0.999344                   -99.3444  11.0442
    16       1                           1.13159e-48        0.00655634  1                  0.00323625       2.42389e-08  0.493605                    0.490255            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:40:27  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:40:33  33 min 50.913 sec  4450 obs/sec      1         1             25000      0.309974         0.417749            0.615663       0.942993        0.666045           1.99562          0.118122                         0.304871           0.393515              0.628153         0.947274          0.628974             2.02591            0.117695
    2019-08-03 16:40:44  34 min  1.936 sec  4682 obs/sec      3         3             75000      0.232877         0.207032            0.783072       0.976045        0.769997           1.99562          0.0652911                        0.229813           0.204674              0.788709         0.976437          0.746055             2.02591            0.0629756
    2019-08-03 16:40:51  34 min  8.732 sec  4501 obs/sec      4         4             100000     0.211718         0.177975            0.8207         0.981774        0.749492           1.99562          0.0519338                        0.20806            0.17625               0.826817         0.982654          0.722473             2.02591            0.048891
    2019-08-03 16:41:01  34 min 19.194 sec  4675 obs/sec      6         6             150000     0.180016         0.140108            0.870377       0.988808        0.790304           1.99562          0.032496                         0.175556           0.136229              0.876701         0.989882          0.761102             2.02591            0.0309212
    2019-08-03 16:41:11  34 min 29.241 sec  4820 obs/sec      8         8             200000     0.148178         0.0997624           0.912172       0.993814        0.737068           1.99562          0.0196372                        0.148024           0.103835              0.912341         0.99369           0.734487             2.02591            0.0197507
    2019-08-03 16:41:21  34 min 39.253 sec  4916 obs/sec      10        10            250000     0.129934         0.0803614           0.932468       0.995605        0.701539           1.99562          0.0152512                        0.129733           0.0847394             0.932667         0.99564           0.651146             2.02591            0.0145702
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003156287808365317
C31         0.9213305711746216     0.9213305711746216   0.002907984449272712
C38         0.89834064245224       0.89834064245224     0.0028354216175310713
C40         0.8974570631980896     0.8974570631980896   0.002832632787103472
C28         0.8952133059501648     0.8952133059501648   0.0028255508434569154
---         ---                    ---                  ---
C426        0.22045812010765076    0.22045812010765076  0.0006958292767509149
C478        0.2203955352306366     0.2203955352306366   0.000695631740866607
C568        0.21984659135341644    0.21984659135341644  0.0006938991159994602
C446        0.21970340609550476    0.21970340609550476  0.0006934471821155759
C567        0.21501752734184265    0.21501752734184265  0.0006786572001339142

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_1

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.029342757252284312   0.07727748155593872    0.0         0.022171509810863074    0.07541888952255249  0.1033838984993619     0.09587916731834412
    3        2        Softmax                      0.0   0.0   0.0002847261650629207  8.370450814254582e-05  0.0         -0.0024757335406988545  0.249225914478302    0.0002462329702832833  0.09423166513442993


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.019382953858478047
RMSE: 0.1392226772421722
LogLoss: 0.08848201922897557
Mean Per-Class Error: 0.01694232250062222
AUC: 0.9949714047637966
pr_auc: 0.7025436412714146
Gini: 0.9899428095275933
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5150439577491229: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4950  93    0.0184   (93.0/5043.0)
1      77    4909  0.0154   (77.0/4986.0)
Total  5027  5002  0.017    (170.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.515044     0.98298   201
max f2                       0.407552     0.986135  223
max f0point5                 0.5864       0.984152  184
max accuracy                 0.515044     0.983049  201
max precision                0.999976     0.998629  0
max recall                   2.19448e-05  1         399
max specificity              0.999976     0.999603  0
max absolute_mcc             0.515044     0.966103  201
max min_per_class_accuracy   0.540233     0.982351  195
max mean_per_class_accuracy  0.515044     0.983058  201
Gains/Lift Table: Avg response rate: 49.72 %, avg score: 49.72 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   1                  2.01143     2.01143            1                1            1                           1                   0.0202567       0.0202567                  101.143   101.143
    2        0.0200419                   1                  2.01143     2.01143            1                1            1                           1                   0.0200562       0.0403129                  101.143   101.143
    3        0.030013                    1                  2.01143     2.01143            1                1            1                           1                   0.0200562       0.060369                   101.143   101.143
    4        0.0400838                   1                  2.01143     2.01143            1                1            1                           1                   0.0202567       0.0806258                  101.143   101.143
    5        0.0500548                   1                  2.01143     2.01143            1                1            1                           1                   0.0200562       0.100682                   101.143   101.143
    6        0.10001                     0.999989           2.00742     2.00943            0.998004         0.999997     0.999003                    0.999999            0.100281        0.200963                   100.742   100.943
    7        0.150065                    0.999783           2.00342     2.00742            0.996016         0.999925     0.998007                    0.999974            0.100281        0.301243                   100.342   100.742
    8        0.20002                     0.998608           2.00742     2.00742            0.998004         0.999337     0.998006                    0.999815            0.100281        0.401524                   100.742   100.742
    9        0.30003                     0.984887           1.99138     2.00207            0.99003          0.993603     0.995347                    0.997744            0.199158        0.600682                   99.1378   100.207
    10       0.40004                     0.917858           1.99138     1.9994             0.99003          0.958764     0.994018                    0.987999            0.199158        0.79984                    99.1378   99.94
    11       0.50005                     0.49118            1.853       1.97012            0.921236         0.790234     0.979462                    0.948446            0.185319        0.985158                   85.3004   97.012
    12       0.59996                     0.0682658          0.106393    1.65976            0.0528942        0.194057     0.825162                    0.822819            0.0106298       0.995788                   -89.3607  65.9757
    13       0.69997                     0.00997622         0.024065    1.42605            0.0119641        0.0318658    0.708974                    0.70981             0.00240674      0.998195                   -97.5935  42.6054
    14       0.79998                     0.000416484        0.0120325   1.24928            0.00598205       0.00335643   0.621089                    0.621492            0.00120337      0.999398                   -98.7968  24.9279
    15       0.89999                     1.20556e-06        0.00601625  1.11112            0.00299103       8.4198e-05   0.552404                    0.552439            0.000601685     1                          -99.3984  11.1123
    16       1                           2.92791e-43        0           1                  0                1.07197e-07  0.497158                    0.49719             0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.017314608988102637
RMSE: 0.13158498770035523
LogLoss: 0.08663394204477438
Mean Per-Class Error: 0.013613484023523692
AUC: 0.9955618860403687
pr_auc: 0.709518609216714
Gini: 0.9911237720807373
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5205895131875187: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3089  39    0.0125   (39.0/3128.0)
1      45    3004  0.0148   (45.0/3049.0)
Total  3134  3043  0.0136   (84.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.52059      0.986211  195
max f2                       0.455273     0.987424  207
max f0point5                 0.622894     0.987039  176
max accuracy                 0.524044     0.986401  194
max precision                0.995468     0.998063  9
max recall                   1.06948e-05  1         399
max specificity              0.999981     0.999361  0
max absolute_mcc             0.524044     0.9728    194
max min_per_class_accuracy   0.492218     0.985294  199
max mean_per_class_accuracy  0.52059      0.986387  195
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999991           2.02591     2.01935            1                0.999998     0.996764                    0.999999            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999849           2.02591     2.02154            1                0.99994      0.997843                    0.999979            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.998959           2.01935     2.02099            0.996764         0.99951      0.997573                    0.999862            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.985119           2.01934     2.02044            0.996759         0.994283     0.997302                    0.998004            0.201705        0.6061                     101.934   102.044
    10       0.400032                    0.924838           1.99313     2.01361            0.983819         0.961739     0.99393                     0.988934            0.19941         0.80551                    99.3128   101.361
    11       0.500081                    0.407501           1.83578     1.97803            0.906149         0.778668     0.976368                    0.946867            0.183667        0.989177                   83.5776   97.8033
    12       0.599968                    0.0684547          0.0722367   1.66074            0.0356564        0.171061     0.819752                    0.817706            0.00721548      0.996392                   -92.7763  66.0743
    13       0.700016                    0.00930629         0.019669    1.4262             0.00970874       0.0316983    0.703978                    0.705367            0.00196786      0.99836                    -98.0331  42.6196
    14       0.799903                    0.00048139         0.00656697  1.24892            0.00324149       0.00347948   0.616474                    0.61772             0.000655953     0.999016                   -99.3433  24.8922
    15       0.899951                    1.41942e-06        0.00655634  1.11081            0.00323625       9.4418e-05   0.5483                      0.549058            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           3.44506e-43        0.00327817  1                  0.00161812       1.46804e-07  0.493605                    0.494125            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:06:43  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:06:53  12.237 sec        2579 obs/sec      1         1             25000      0.304335         0.382237            0.629508       0.943183        0.670696           2.01143          0.119254                         0.29229            0.352115              0.65821          0.950324          0.70645              1.99323            0.112028
    2019-08-03 16:07:13  31.221 sec        2720 obs/sec      3         3             75000      0.246026         0.222441            0.757876       0.972976        0.831278           2.01143          0.0738857                        0.23476            0.204076              0.779515         0.97721           0.821125             2.02591            0.0641088
    2019-08-03 16:07:30  48.828 sec        2834 obs/sec      5         5             125000     0.214131         0.172571            0.816586       0.982716        0.813203           2.01143          0.0549407                        0.201449           0.158219              0.837647         0.986201          0.779904             2.02591            0.0443581
    2019-08-03 16:07:48  1 min  6.140 sec  2902 obs/sec      7         7             175000     0.179754         0.133836            0.87075        0.989586        0.752281           2.01143          0.0340014                        0.171671           0.12491               0.882097         0.990917          0.755532             2.02591            0.025255
    2019-08-03 16:08:04  1 min 22.781 sec  2964 obs/sec      9         9             225000     0.15354          0.101562            0.905699       0.99373         0.710236           2.01143          0.0212384                        0.142762           0.0960819             0.918463         0.994575          0.719485             2.02591            0.0158653
    2019-08-03 16:08:13  1 min 31.472 sec  2993 obs/sec      10        10            250000     0.139223         0.088482            0.922466       0.994971        0.702544           2.01143          0.0169508                        0.131585           0.0866339             0.93073          0.995562          0.709519             2.02591            0.0135988
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0031660327741877803
C35         0.9736059904098511     0.9736059904098511   0.003082468474783142
C31         0.9699982404708862     0.9699982404708862   0.0030710462202353057
C28         0.9286355376243591     0.9286355376243591   0.0029400905473942105
C25         0.8823287487030029     0.8823287487030029   0.002793481736001801
---         ---                    ---                  ---
C437        0.22698640823364258    0.22698640823364258  0.0007186464077628794
C626        0.223334401845932      0.223334401845932    0.0007070840358478446
C562        0.2215299755334854     0.2215299755334854   0.0007013711630040319
C361        0.21887415647506714    0.21887415647506714  0.0006929627528227671
C631        0.21862930059432983    0.21862930059432983  0.0006921875310794002

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_232

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.03172271678104176    0.08324015140533447    0.0         0.023012138376744137  0.07662093639373779  0.09971332171400664      0.09885707497596741
    3        2        Softmax                      0.0   0.0   0.0003157246378009404  7.810414535924792e-05  0.0         -0.0118958747329998   0.2583731412887573   -0.00022413554973747113  0.09947112202644348


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.019074793637208296
RMSE: 0.13811152608384392
LogLoss: 0.09334532559456357
Mean Per-Class Error: 0.01662138813604308
AUC: 0.9945625646066313
pr_auc: 0.7235806858585575
Gini: 0.9891251292132626
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48837224504551513: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4848  99    0.02     (99.0/4947.0)
1      67    4997  0.0132   (67.0/5064.0)
Total  4915  5096  0.0166   (166.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.488372     0.983661  199
max f2                       0.354743     0.986131  230
max f0point5                 0.618352     0.984275  175
max accuracy                 0.488372     0.983418  199
max precision                0.999985     0.997818  0
max recall                   1.48261e-05  1         399
max specificity              0.999985     0.999394  0
max absolute_mcc             0.488372     0.966849  199
max min_per_class_accuracy   0.540981     0.982818  190
max mean_per_class_accuracy  0.488372     0.983379  199
Gains/Lift Table: Avg response rate: 50.58 %, avg score: 50.47 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   1                  1.9769      1.9769             1                1            1                           1                   0.0199447       0.0199447                  97.6896   97.6896
    2        0.0200779                   1                  1.9769      1.9769             1                1            1                           1                   0.0197472       0.0396919                  97.6896   97.6896
    3        0.0300669                   1                  1.9769      1.9769             1                1            1                           1                   0.0197472       0.0594392                  97.6896   97.6896
    4        0.0400559                   1                  1.95713     1.97197            0.99             1            0.997506                    1                   0.0195498       0.0789889                  95.7127   97.1966
    5        0.050045                    1                  1.9769      1.97295            1                1            0.998004                    1                   0.0197472       0.0987362                  97.6896   97.295
    6        0.10009                     0.999989           1.969       1.97098            0.996008         0.999997     0.997006                    0.999999            0.0985387       0.197275                   96.9004   97.0977
    7        0.150035                    0.999822           1.9769      1.97295            1                0.999932     0.998003                    0.999976            0.0987362       0.296011                   97.6896   97.2947
    8        0.20008                     0.998778           1.96111     1.96999            0.992016         0.999397     0.996505                    0.999831            0.0981438       0.394155                   96.1112   96.9987
    9        0.30007                     0.986959           1.97097     1.97031            0.997003         0.99443      0.996671                    0.998031            0.197077        0.591232                   97.0971   97.0315
    10       0.40006                     0.929153           1.95122     1.96554            0.987013         0.965563     0.994257                    0.989916            0.195103        0.786335                   95.1222   96.5543
    11       0.50005                     0.625451           1.88605     1.94965            0.954046         0.825834     0.986217                    0.957107            0.188586        0.974921                   88.6049   94.9647
    12       0.60004                     0.0702425          0.211317    1.65997            0.106893         0.224119     0.839687                    0.834962            0.0211295       0.996051                   -78.8683  65.9974
    13       0.70003                     0.00981085         0.0138244   1.42484            0.00699301       0.0336225    0.720748                    0.720502            0.00138231      0.997433                   -98.6176  42.4843
    14       0.80002                     0.000382115        0.0157994   1.24873            0.00799201       0.00331464   0.631664                    0.630864            0.00157978      0.999013                   -98.4201  24.8735
    15       0.90001                     5.41438e-07        0.00592476  1.11066            0.002997         7.8867e-05   0.56182                     0.560785            0.000592417     0.999605                   -99.4075  11.066
    16       1                           3.65983e-44        0.00394984  1                  0.001998         5.66216e-08  0.505844                    0.504712            0.000394945     1                          -99.605   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.018374336590463593
RMSE: 0.13555197007223316
LogLoss: 0.0903890046479914
Mean Per-Class Error: 0.01533866287969976
AUC: 0.9949599843645018
pr_auc: 0.715642752345816
Gini: 0.9899199687290037
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48373539187502523: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3070  58    0.0185   (58.0/3128.0)
1      37    3012  0.0121   (37.0/3049.0)
Total  3107  3070  0.0154   (95.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.483735     0.984475  199
max f2                       0.437702     0.987109  208
max f0point5                 0.67145      0.983771  162
max accuracy                 0.483735     0.98462   199
max precision                0.996053     0.998674  9
max recall                   9.30789e-06  1         399
max specificity              0.999988     0.999361  0
max absolute_mcc             0.483735     0.969261  199
max min_per_class_accuracy   0.553794     0.982945  186
max mean_per_class_accuracy  0.483735     0.984661  199
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.44 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.99999            2.0128      2.01935            0.993528         0.999998     0.996764                    0.999999            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999847           2.02591     2.02154            1                0.999944     0.997843                    0.99998             0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.998813           2.02591     2.02263            1                0.999458     0.998382                    0.99985             0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.986265           2.01278     2.01935            0.993517         0.994207     0.996762                    0.997971            0.20105         0.605772                   101.278   101.935
    10       0.400032                    0.92148            2.00296     2.01525            0.988673         0.96124      0.994739                    0.988784            0.200394        0.806166                   100.296   101.525
    11       0.500081                    0.425942           1.8325      1.97869            0.904531         0.785872     0.976691                    0.948189            0.183339        0.989505                   83.2498   97.8689
    12       0.599968                    0.063234           0.0689532   1.66074            0.0340357        0.168291     0.819752                    0.818346            0.0068875       0.996392                   -93.1047  66.0743
    13       0.700016                    0.00960071         0.00655634  1.42432            0.00323625       0.0304833    0.703053                    0.705742            0.000655953     0.997048                   -99.3444  42.4322
    14       0.799903                    0.000379369        0.0131339   1.2481             0.00648298       0.00321264   0.61607                     0.618015            0.00131191      0.99836                    -98.6866  24.8102
    15       0.899951                    6.61521e-07        0.00655634  1.11008            0.00323625       7.58388e-05  0.54794                     0.549318            0.000655953     0.999016                   -99.3444  11.0078
    16       1                           1.47827e-43        0.00983452  1                  0.00485437       5.97165e-08  0.493605                    0.494359            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:49:51  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:50:01  4:43:19.733  2593 obs/sec      1         1             25000      0.305799         0.405511            0.625896       0.941307        0.629062           1.9769           0.120567                         0.298817           0.388357              0.642774         0.945434          0.638416             1.99323            0.113324
    2019-08-03 20:50:20  4:43:38.136  2785 obs/sec      3         3             75000      0.240639         0.217768            0.76834        0.973869        0.805319           1.9769           0.070023                         0.239957           0.213547              0.769646         0.974607          0.791337             2.02591            0.066699
    2019-08-03 20:50:37  4:43:55.782  2883 obs/sec      5         5             125000     0.2088           0.169818            0.825586       0.983982        0.797059           1.9769           0.0498452                        0.204231           0.166219              0.833132         0.984694          0.788228             2.02591            0.0443581
    2019-08-03 20:50:54  4:44:12.822  2956 obs/sec      7         7             175000     0.17662          0.133623            0.875204       0.989968        0.774242           1.9769           0.0309659                        0.178034           0.1312                0.873195         0.990161          0.747245             2.02591            0.0294641
    2019-08-03 20:51:11  4:44:29.761  3003 obs/sec      9         9             225000     0.145384         0.099967            0.915442       0.994277        0.725212           1.9769           0.0186795                        0.143263           0.0931303             0.917889         0.994924          0.711178             2.02591            0.0174842
    2019-08-03 20:51:20  4:44:38.613  3023 obs/sec      10        10            250000     0.138112         0.0933453           0.92369        0.994563        0.723581           1.9769           0.0165818                        0.135552           0.090389              0.926491         0.99496           0.715643             2.02591            0.0153796
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003212718383245848
C31         0.939689040184021      0.939689040184021    0.0030189562539338507
C28         0.9310606122016907     0.9310606122016907   0.002991235544736505
C40         0.9236986637115479     0.9236986637115479   0.002967583677485714
C34         0.9038472175598145     0.9038472175598145   0.0029038065715000254
---         ---                    ---                  ---
C971        0.22479164600372314    0.22479164600372314  0.0007221922535162544
C588        0.2237587422132492     0.2237587422132492   0.0007188738245204744
C582        0.2233010232448578     0.2233010232448578   0.000717403302376363
C599        0.22010089457035065    0.22010089457035065  0.0007071221901550217
C398        0.21956345438957214    0.21956345438957214  0.0007053955462063396

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_142

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.019420701137130666    0.051909953355789185   0.0         0.022595497227225755  0.07301843166351318  0.09110871025724901     0.10784226655960083
    3        2        Softmax                      0.0   0.0   0.00019688085319558013  4.999346856493503e-05  0.0         -0.01632396134323244  0.2470940351486206   -0.0013641448435861223  0.09127116203308105


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01886656725310084
RMSE: 0.13735562330352857
LogLoss: 0.0859642187732228
Mean Per-Class Error: 0.01756209496839789
AUC: 0.9954658293458748
pr_auc: 0.7129016027024718
Gini: 0.9909316586917496
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5116660741990459: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4937  92    0.0183   (92.0/5029.0)
1      84    4907  0.0168   (84.0/4991.0)
Total  5021  4999  0.0176   (176.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.511666     0.982382  199
max f2                       0.351059     0.984655  234
max f0point5                 0.629233     0.986508  173
max accuracy                 0.558382     0.982435  189
max precision                0.997739     0.99908   5
max recall                   1.66652e-05  1         399
max specificity              0.999976     0.999602  0
max absolute_mcc             0.558382     0.964882  189
max min_per_class_accuracy   0.521962     0.981905  197
max mean_per_class_accuracy  0.511666     0.982438  199
Gains/Lift Table: Avg response rate: 49.81 %, avg score: 49.73 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100798                   1                  2.00761     2.00761            1                1            1                           1                   0.0202364       0.0202364                  100.761   100.761
    2        0.0200599                   1                  2.00761     2.00761            1                1            1                           1                   0.0200361       0.0402725                  100.761   100.761
    3        0.0300399                   1                  2.00761     2.00761            1                1            1                           1                   0.0200361       0.0603086                  100.761   100.761
    4        0.04002                     1                  2.00761     2.00761            1                1            1                           1                   0.0200361       0.0803446                  100.761   100.761
    5        0.05                        1                  1.98754     2.00361            0.99             1            0.998004                    1                   0.0198357       0.10018                    98.7538   100.361
    6        0.1                         0.999986           2.00761     2.00561            1                0.999997     0.999002                    0.999998            0.100381        0.200561                   100.761   100.561
    7        0.15                        0.999716           2.00361     2.00494            0.998004         0.9999       0.998669                    0.999965            0.10018         0.300741                   100.361   100.494
    8        0.2                         0.998328           2.00761     2.00561            1                0.999212     0.999002                    0.999777            0.100381        0.401122                   100.761   100.561
    9        0.3                         0.983684           2.0016      2.00427            0.997006         0.99316      0.998337                    0.997572            0.20016         0.601282                   100.16    100.427
    10       0.4                         0.920899           1.97956     1.9981             0.986028         0.959389     0.995259                    0.988026            0.197956        0.799239                   97.9563   99.8097
    11       0.5                         0.485351           1.84532     1.96754            0.919162         0.796239     0.98004                     0.949668            0.184532        0.983771                   84.5322   96.7542
    12       0.6                         0.0629675          0.116209    1.65899            0.0578842        0.192805     0.826347                    0.823525            0.0116209       0.995392                   -88.3791  65.8986
    13       0.7                         0.00837189         0.0200361   1.42485            0.00998004       0.0292664    0.709723                    0.710059            0.00200361      0.997395                   -97.9964  42.485
    14       0.8                         0.000346522        0.0180325   1.249              0.00898204       0.00282225   0.622131                    0.621655            0.00180325      0.999199                   -98.1968  24.8998
    15       0.9                         5.95611e-07        0.00601082  1.11089            0.00299401       6.66641e-05  0.553338                    0.552589            0.000601082     0.9998                     -99.3989  11.0888
    16       1                           2.58561e-45        0.00200361  1                  0.000998004      5.23278e-08  0.498104                    0.49733             0.000200361     1                          -99.7996  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.019295140343425474
RMSE: 0.1389069485066369
LogLoss: 0.0911671814333971
Mean Per-Class Error: 0.017221224266226187
AUC: 0.9948784621011123
pr_auc: 0.7254682908836269
Gini: 0.9897569242022246
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5630262992360859: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3089  39    0.0125   (39.0/3128.0)
1      67    2982  0.022    (67.0/3049.0)
Total  3156  3021  0.0172   (106.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.563026     0.982537  194
max f2                       0.400962     0.983253  223
max f0point5                 0.632746     0.98704   177
max accuracy                 0.573545     0.98284   192
max precision                0.995031     0.998664  10
max recall                   1.13646e-05  1         399
max specificity              0.999985     0.999361  0
max absolute_mcc             0.573545     0.965727  192
max min_per_class_accuracy   0.468416     0.982097  206
max mean_per_class_accuracy  0.563026     0.982779  194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.99 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999984           2.01935     2.01935            0.996764         0.999996     0.996764                    0.999998            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999773           2.02591     2.02154            1                0.999912     0.997843                    0.999969            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.998445           2.02591     2.02263            1                0.999299     0.998382                    0.999802            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.981987           2.01606     2.02044            0.995138         0.992758     0.997302                    0.997456            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.908069           1.99968     2.01525            0.987055         0.952988     0.994739                    0.986335            0.200066        0.806166                   99.9685   101.525
    11       0.500081                    0.401661           1.79316     1.97082            0.885113         0.759534     0.972807                    0.94096             0.179403        0.985569                   79.316    97.0819
    12       0.599968                    0.0584783          0.0985045   1.6591             0.0486224        0.162948     0.818942                    0.811431            0.00983929      0.995408                   -90.1495  65.9103
    13       0.700016                    0.00822038         0.019669    1.42479            0.00970874       0.0274453    0.703284                    0.699381            0.00196786      0.997376                   -98.0331  42.479
    14       0.799903                    0.000355962        0.0164174   1.24892            0.00810373       0.0029236    0.616474                    0.612412            0.00163988      0.999016                   -98.3583  24.8922
    15       0.899951                    8.09234e-07        0.00655634  1.11081            0.00323625       7.30562e-05  0.5483                      0.544338            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           2.58561e-45        0.00327817  1                  0.00161812       7.73554e-08  0.493605                    0.489878            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:41:10  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:41:19  2:34:37.787  2693 obs/sec      1         1             25000      0.297304         0.373947            0.646437       0.947066        0.669145           2.00761          0.113673                         0.29554            0.376231              0.650568         0.947237          0.633525             1.96056            0.11041
    2019-08-03 18:41:38  2:34:56.234  2810 obs/sec      3         3             75000      0.234069         0.209297            0.780843       0.975204        0.790024           2.00761          0.0653693                        0.232576           0.208661              0.783599         0.976167          0.803558             2.02591            0.0618423
    2019-08-03 18:41:56  2:35:14.756  2834 obs/sec      5         5             125000     0.201986         0.158482            0.836804       0.985684        0.810264           2.00761          0.0448104                        0.198115           0.157977              0.842976         0.98609           0.81126              2.02591            0.0409584
    2019-08-03 18:42:13  2:35:31.745  2917 obs/sec      7         7             175000     0.169189         0.118229            0.885498       0.992376        0.766479           2.00761          0.0281437                        0.170017           0.123796              0.884358         0.991896          0.760703             2.02591            0.0263882
    2019-08-03 18:42:30  2:35:48.128  2986 obs/sec      9         9             225000     0.143931         0.0920144           0.917134       0.995212        0.726058           2.00761          0.0181637                        0.147585           0.0983474             0.91286          0.994706          0.70485              2.02591            0.019265
    2019-08-03 18:42:38  2:35:56.950  3010 obs/sec      10        10            250000     0.137356         0.0859642           0.924533       0.995466        0.712902           2.00761          0.0175649                        0.138907           0.0911672             0.922807         0.994878          0.725468             2.02591            0.0171604
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003205248942697688
C28         0.9463687539100647     0.9463687539100647   0.0030333474478723634
C35         0.8801698684692383     0.8801698684692383   0.002821163540305389
C34         0.8775721788406372     0.8775721788406372   0.002812837298369859
C24         0.80852872133255       0.80852872133255     0.00259153582919187
---         ---                    ---                  ---
C446        0.22588977217674255    0.22588977217674255  0.0007240329534357258
C313        0.22330819070339203    0.22330819070339203  0.000715758342147781
C462        0.22202008962631226    0.22202008962631226  0.0007116296575323833
C662        0.21919672191143036    0.21919672191143036  0.0007025800611494113
C464        0.21838276088237762    0.21838276088237762  0.0006999711134216429

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_97

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.022717074377970322   0.055857181549072266   0.0         0.02270026738074521    0.07409587502479553  0.09621815436828314     0.09239381551742554
    3        2        Softmax                      0.0   0.0   0.0003132866662269862  6.081497122067958e-05  0.0         0.0008964236117208202  0.258614182472229    0.00010646192654973491  0.09198132157325745


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.019301797950160914
RMSE: 0.1389309107080239
LogLoss: 0.09145640855202287
Mean Per-Class Error: 0.01653345519762306
AUC: 0.9947109768152632
pr_auc: 0.6551313167753756
Gini: 0.9894219536305264
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5133694326994391: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4929  108   0.0214   (108.0/5037.0)
1      58    4931  0.0116   (58.0/4989.0)
Total  4987  5039  0.0166   (166.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.513369     0.983446  202
max f2                       0.394704     0.987511  226
max f0point5                 0.616361     0.98219   177
max accuracy                 0.519909     0.983443  200
max precision                0.999963     0.997054  0
max recall                   1.47663e-05  1         399
max specificity              0.999963     0.999007  0
max absolute_mcc             0.513369     0.966935  202
max min_per_class_accuracy   0.564481     0.981338  189
max mean_per_class_accuracy  0.513369     0.983467  202
Gains/Lift Table: Avg response rate: 49.76 %, avg score: 50.00 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   1                  2.00962     2.00962            1                1            1                           1                   0.0202445       0.0202445                  100.962   100.962
    2        0.0200479                   1                  2.00962     2.00962            1                1            1                           1                   0.0200441       0.0402886                  100.962   100.962
    3        0.0300219                   1                  2.00962     2.00962            1                1            1                           1                   0.0200441       0.0603327                  100.962   100.962
    4        0.0400958                   1                  2.00962     2.00962            1                1            1                           1                   0.0202445       0.0805773                  100.962   100.962
    5        0.0500698                   1                  2.00962     2.00962            1                1            1                           1                   0.0200441       0.100621                   100.962   100.962
    6        0.10004                     0.999993           2.0016      2.00561            0.996008         0.999998     0.998006                    0.999999            0.10002         0.200641                   100.16    100.561
    7        0.15001                     0.999876           2.0016      2.00428            0.996008         0.999956     0.99734                     0.999985            0.10002         0.300661                   100.16    100.428
    8        0.20008                     0.998903           1.98961     2.0006             0.99004          0.999526     0.995513                    0.99987             0.0996192       0.400281                   98.9605   100.06
    9        0.30002                     0.986652           1.99558     1.99893            0.993014         0.994782     0.994681                    0.998175            0.199439        0.599719                   99.5582   99.8932
    10       0.40006                     0.922192           1.97957     1.99409            0.985045         0.962118     0.992271                    0.989159            0.198036        0.797755                   97.9567   99.4089
    11       0.5                         0.537005           1.87324     1.96993            0.932136         0.804278     0.980251                    0.952204            0.187212        0.984967                   87.324    96.9934
    12       0.60004                     0.0719945          0.116209    1.66088            0.0578265        0.200693     0.826463                    0.826911            0.0116256       0.996593                   -88.3791  66.0877
    13       0.69998                     0.0115651          0.0200561   1.42661            0.00998004       0.0343447    0.709889                    0.713752            0.00200441      0.998597                   -97.9944  42.6608
    14       0.80002                     0.000469039        0.00801444  1.24922            0.00398804       0.0040433    0.621618                    0.625005            0.000801764     0.999399                   -99.1986  24.9217
    15       0.89996                     8.21292e-07        0.00200561  1.11071            0.000998004      9.24084e-05  0.552699                    0.555609            0.000200441     0.999599                   -99.7994  11.0715
    16       1                           6.35971e-44        0.00400722  1                  0.00199402       8.61691e-08  0.497606                    0.500026            0.000400882     1                          -99.5993  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.018819413420401696
RMSE: 0.1371838672016564
LogLoss: 0.09279041872802628
Mean Per-Class Error: 0.014346450431528046
AUC: 0.9946196878939806
pr_auc: 0.6482565723994961
Gini: 0.9892393757879612
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4920351428016262: 
       0     1     Error    Rate
-----  ----  ----  -------  -------------
0      3068  60    0.0192   (60.0/3128.0)
1      29    3020  0.0095   (29.0/3049.0)
Total  3097  3080  0.0144   (89.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.492035     0.985479  205
max f2                       0.492035     0.988479  205
max f0point5                 0.564782     0.984327  190
max accuracy                 0.513692     0.985592  201
max precision                0.999963     0.997164  0
max recall                   2.26702e-05  1         399
max specificity              0.999963     0.999041  0
max absolute_mcc             0.492035     0.971231  205
max min_per_class_accuracy   0.564782     0.984585  190
max mean_per_class_accuracy  0.492035     0.985654  205
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.84 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999994           2.02591     2.02263            1                0.999998     0.998382                    0.999999            0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.999888           2.01935     2.02154            0.996764         0.99996      0.997843                    0.999986            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.999139           2.00624     2.01771            0.990291         0.999601     0.995955                    0.99989             0.100361        0.403739                   100.624   101.771
    9        0.299984                    0.986829           2.00949     2.01498            0.991896         0.995132     0.994603                    0.998306            0.200722        0.60446                    100.949   101.498
    10       0.400032                    0.923063           1.99968     2.01115            0.987055         0.96202      0.992715                    0.98923             0.200066        0.804526                   99.9685   101.115
    11       0.500081                    0.472412           1.85872     1.98066            0.917476         0.795698     0.977663                    0.950511            0.185963        0.990489                   85.8723   98.0657
    12       0.599968                    0.0717906          0.0591027   1.66074            0.0291734        0.19204      0.819752                    0.824236            0.00590357      0.996392                   -94.0897  66.0743
    13       0.700016                    0.0108205          0.019669    1.4262             0.00970874       0.0344547    0.703978                    0.711358            0.00196786      0.99836                    -98.0331  42.6196
    14       0.799903                    0.000533381        0.00328348  1.24851            0.00162075       0.00389901   0.616272                    0.623015            0.000327976     0.998688                   -99.6717  24.8512
    15       0.899951                    9.89089e-07        0.00655634  1.11044            0.00323625       0.000107472  0.54812                     0.553766            0.000655953     0.999344                   -99.3444  11.0442
    16       1                           5.96103e-38        0.00655634  1                  0.00323625       1.09931e-07  0.493605                    0.498362            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:54:07  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:54:17  1:47:35.576  2592 obs/sec      1         1             25000      0.308428         0.438791            0.619481       0.941325        0.639043           2.00962          0.120886                         0.297534           0.40428               0.645837         0.946891          0.613042             2.02591            0.109276
    2019-08-03 17:54:36  1:47:54.154  2761 obs/sec      3         3             75000      0.236074         0.214936            0.777072       0.974681        0.790201           2.00962          0.069619                         0.228923           0.199153              0.790343         0.978037          0.805033             2.02591            0.0658896
    2019-08-03 17:54:53  1:48:11.791  2856 obs/sec      5         5             125000     0.20486          0.165247            0.832125       0.984375        0.763542           2.00962          0.0470776                        0.197542           0.152467              0.843882         0.98698           0.797095             2.02591            0.0435486
    2019-08-03 17:55:10  1:48:28.923  2928 obs/sec      7         7             175000     0.17229          0.126181            0.881262       0.990723        0.733508           2.00962          0.0291243                        0.169117           0.120862              0.885579         0.991667          0.753957             2.02591            0.0276833
    2019-08-03 17:55:27  1:48:45.894  2978 obs/sec      9         9             225000     0.149397         0.101926            0.91072        0.993726        0.693085           2.00962          0.0202474                        0.144513           0.0983795             0.916451         0.994107          0.715307             2.02591            0.0173223
    2019-08-03 17:55:36  1:48:54.852  2997 obs/sec      10        10            250000     0.138931         0.0914564           0.922791       0.994711        0.655131           2.00962          0.016557                         0.137184           0.0927904             0.92471          0.99462           0.648257             2.02591            0.0144083
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003208165805177923
C34         0.9006779789924622     0.9006779789924622   0.0028895242936803765
C31         0.8828264474868774     0.8828264474868774   0.0028322536207341033
C35         0.8796854019165039     0.8796854019165039   0.0028221766257427255
C38         0.8759752511978149     0.8759752511978149   0.002810273847074971
---         ---                    ---                  ---
C476        0.2272840291261673     0.2272840291261673   0.000729164850305633
C446        0.2272600680589676     0.2272600680589676   0.0007290879792291873
C495        0.22203819453716278    0.22203819453716278  0.0007123353431575691
C467        0.22103849053382874    0.22103849053382874  0.0007091281269587733
C721        0.20784856379032135    0.20784856379032135  0.0006668126550074512

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_211

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.02472466849814797     0.06649455428123474     0.0         0.022443562442646076   0.07482662796974182  0.0964604606377797      0.10165074467658997
    3        2        Softmax                      0.0   0.0   0.00019823969114440843  5.7671102695167065e-05  0.0         -0.006745186232024025  0.24925339221954346  0.00019961827686264255  0.073666512966156


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.01863746779243704
RMSE: 0.13651911145490597
LogLoss: 0.08632859731920846
Mean Per-Class Error: 0.016797975025937495
AUC: 0.9955161864724041
pr_auc: 0.6542587065392018
Gini: 0.9910323729448083
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5285417866023129: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4882  110   0.022    (110.0/4992.0)
1      58    4959  0.0116   (58.0/5017.0)
Total  4940  5069  0.0168   (168.0/10009.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.528542     0.983343  184
max f2                       0.490354     0.987522  193
max f0point5                 0.678105     0.984179  150
max accuracy                 0.528542     0.983215  184
max precision                0.999653     0.997449  1
max recall                   1.22905e-05  1         399
max specificity              0.99997      0.998998  0
max absolute_mcc             0.528542     0.966481  184
max min_per_class_accuracy   0.592696     0.982171  170
max mean_per_class_accuracy  0.528542     0.983202  184
Gains/Lift Table: Avg response rate: 50.12 %, avg score: 51.25 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100909                   1                  1.99502     1.99502            1                1            1                           1                   0.0201316       0.0201316                  99.5017   99.5017
    2        0.0200819                   1                  1.99502     1.99502            1                1            1                           1                   0.0199322       0.0400638                  99.5017   99.5017
    3        0.0300729                   1                  1.99502     1.99502            1                1            1                           1                   0.0199322       0.059996                   99.5017   99.5017
    4        0.0400639                   1                  1.97507     1.99004            0.99             1            0.997506                    1                   0.0197329       0.0797289                  97.5067   99.0042
    5        0.050055                    1                  1.99502     1.99103            1                1            0.998004                    1                   0.0199322       0.0996612                  99.5017   99.1035
    6        0.10001                     0.999995           1.98704     1.98904            0.996            0.999999     0.997003                    0.999999            0.0992625       0.198924                   98.7037   98.9038
    7        0.150065                    0.99991            1.99103     1.9897             0.998004         0.999968     0.997337                    0.999989            0.0996612       0.298585                   99.1035   98.9704
    8        0.20002                     0.999437           1.99103     1.99003            0.998            0.999721     0.997502                    0.999922            0.0994618       0.398047                   99.1027   99.0034
    9        0.30003                     0.992509           1.97907     1.98638            0.992008         0.997054     0.995671                    0.998966            0.197927        0.595974                   97.9073   98.6381
    10       0.40004                     0.952041           1.97309     1.98306            0.989011         0.977654     0.994006                    0.993638            0.197329        0.793303                   97.3094   98.3059
    11       0.50005                     0.602686           1.87743     1.96193            0.941059         0.852094     0.983417                    0.965329            0.187762        0.981064                   87.7429   96.1933
    12       0.59996                     0.0919765          0.161596    1.66213            0.081            0.246883     0.833139                    0.845688            0.0161451       0.997209                   -83.8404  66.2127
    13       0.69997                     0.0159678          0.0159442   1.42692            0.00799201       0.0456886    0.715244                    0.731386            0.00159458      0.998804                   -98.4056  42.6924
    14       0.79998                     0.000817181        0.00398605  1.24903            0.001998         0.00582585   0.626077                    0.64068             0.000398645     0.999203                   -99.6014  24.9035
    15       0.89999                     1.77204e-06        0.0079721   1.11112            0.003996         0.000168581  0.556949                    0.569504            0.000797289     1                          -99.2028  11.1123
    16       1                           1.15745e-42        0           1                  0                1.97004e-07  0.501249                    0.512548            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.019712973898365026
RMSE: 0.14040289846853243
LogLoss: 0.09358449911765505
Mean Per-Class Error: 0.017269246384081338
AUC: 0.9951622958850287
pr_auc: 0.6483144938771799
Gini: 0.9903245917700574
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5614625586293398: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3061  67    0.0214   (67.0/3128.0)
1      40    3009  0.0131   (40.0/3049.0)
Total  3101  3076  0.0173   (107.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.561463     0.982531  178
max f2                       0.494972     0.987057  190
max f0point5                 0.673429     0.982291  152
max accuracy                 0.561463     0.982678  178
max precision                0.999006     0.997118  2
max recall                   0.00019961   1         398
max specificity              0.999977     0.998721  0
max absolute_mcc             0.561463     0.96539   178
max min_per_class_accuracy   0.598489     0.980977  168
max mean_per_class_accuracy  0.561463     0.982731  178
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.59 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999996           2.00624     2.0128             0.990291         0.999999     0.993528                    1                   0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.999931           2.02591     2.01717            1                0.999975     0.995685                    0.999991            0.101345        0.302722                   102.591   101.717
    8        0.200097                    0.999474           2.02591     2.01935            1                0.999749     0.996764                    0.999931            0.101345        0.404067                   102.591   101.935
    9        0.299984                    0.991555           2.00621     2.01498            0.990276         0.996771     0.994603                    0.998879            0.200394        0.60446                    100.621   101.498
    10       0.400032                    0.942218           1.99641     2.01033            0.985437         0.973934     0.992311                    0.99264             0.199738        0.804198                   99.6407   101.033
    11       0.500081                    0.531663           1.83905     1.97607            0.907767         0.817566     0.975397                    0.957614            0.183995        0.988193                   83.9054   97.6066
    12       0.599968                    0.089095           0.0952211   1.66293            0.0470016        0.21996      0.820831                    0.834804            0.00951132      0.997704                   -90.4779  66.293
    13       0.700016                    0.0156242          0.00983452  1.42666            0.00485437       0.0446407    0.704209                    0.721871            0.000983929     0.998688                   -99.0165  42.6664
    14       0.799903                    0.000745445        0.00656697  1.24933            0.00324149       0.00551714   0.616677                    0.632418            0.000655953     0.999344                   -99.3433  24.9332
    15       0.899951                    2.29238e-06        0.00655634  1.11117            0.00323625       0.000150502  0.54848                     0.562128            0.000655953     1                          -99.3444  11.1171
    16       1                           2.01114e-39        0           1                  0                2.16484e-07  0.493605                    0.505888            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:25:35  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:25:45  4:19:03.680  2597 obs/sec      1         1             25000      0.294134         0.354482            0.653939       0.950114        0.670391           1.99502          0.112299                         0.291464           0.347053              0.660138         0.951741          0.656671             1.99323            0.106848
    2019-08-03 20:26:04  4:19:22.179  2769 obs/sec      3         3             75000      0.239587         0.213151            0.770392       0.974412        0.806068           1.99502          0.0713358                        0.231866           0.203301              0.784917         0.977197          0.806121             2.02591            0.0654039
    2019-08-03 20:26:21  4:19:39.721  2874 obs/sec      5         5             125000     0.204705         0.165789            0.832383       0.984768        0.797537           1.99502          0.0450594                        0.202012           0.165835              0.836738         0.985466          0.789862             2.02591            0.0409584
    2019-08-03 20:26:38  4:19:56.828  2940 obs/sec      7         7             175000     0.170848         0.122758            0.883244       0.991229        0.75922            1.99502          0.0279748                        0.17143            0.127418              0.882428         0.991423          0.730538             2.02591            0.028169
    2019-08-03 20:26:55  4:20:13.411  3002 obs/sec      9         9             225000     0.14386          0.093269            0.917217       0.994785        0.725593           1.99502          0.018883                         0.149642           0.10257               0.910414         0.993833          0.704684             2.02591            0.0195888
    2019-08-03 20:27:04  4:20:22.105  3029 obs/sec      10        10            250000     0.136519         0.0863286           0.92545        0.995516        0.654259           1.99502          0.0167849                        0.140403           0.0935845             0.921135         0.995162          0.648314             2.02591            0.0173223
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.003010631441128283
C36         0.9789168238639832     0.9789168238639832   0.002947157768174345
C27         0.9772253036499023     0.9772253036499023   0.0029420652242345296
C31         0.9513962268829346     0.9513962268829346   0.0028643033936245803
C34         0.9452193975448608     0.9452193975448608   0.002845707237012892
---         ---                    ---                  ---
C544        0.24280978739261627    0.24280978739261627  0.0007310107801378843
C564        0.24231359362602234    0.24231359362602234  0.0007295169235832848
C561        0.24204295873641968    0.24204295873641968  0.0007287021416755807
C523        0.240157812833786      0.240157812833786    0.0007230266621499977
C721        0.22884777188301086    0.22884777188301086  0.0006889762972631455

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_121

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 256,190 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.09685742407812573    0.17928153276443481     0.0         0.0014544749734049264  0.09894904494285583  -0.00577310781623493    0.1227877140045166
    3        2        Softmax                 0.0   0.0   0.0016931461620970367  2.4525608750991523e-05  0.0         0.020324784368110693   0.2577228546142578   -8.116095781163235e-06  0.34664392471313477


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02614590971283123
RMSE: 0.16169696878059042
LogLoss: 0.09695391419232202
Mean Per-Class Error: 0.03242758090497344
AUC: 0.9940769500475349
pr_auc: 0.9384312972492059
Gini: 0.9881539000950699
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4749298548650443: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4817  181   0.0362   (181.0/4998.0)
1      144   4880  0.0287   (144.0/5024.0)
Total  4961  5061  0.0324   (325.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.47493      0.967774  216
max f2                       0.24765      0.974381  269
max f0point5                 0.769117     0.973455  137
max accuracy                 0.512882     0.967571  205
max precision                0.9924       0.999574  15
max recall                   0.00317614   1         392
max specificity              0.999852     0.9998    0
max absolute_mcc             0.47493      0.935167  216
max min_per_class_accuracy   0.509793     0.967187  206
max mean_per_class_accuracy  0.512882     0.967572  205
Gains/Lift Table: Avg response rate: 50.13 %, avg score: 49.95 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   0.999895           1.99482     1.99482            1                0.99994      1                           0.99994             0.0201035       0.0201035                  99.4825   99.4825
    2        0.0200559                   0.999794           1.97488     1.9849             0.99             0.999842     0.995025                    0.999891            0.0197054       0.0398089                  97.4877   98.49
    3        0.0300339                   0.999679           1.99482     1.9882             1                0.999741     0.996678                    0.999841            0.0199045       0.0597134                  99.4825   98.8198
    4        0.040012                    0.999544           1.99482     1.98985            1                0.999607     0.997506                    0.999783            0.0199045       0.0796178                  99.4825   98.985
    5        0.0500898                   0.999419           1.99482     1.99085            1                0.999479     0.998008                    0.999722            0.0201035       0.0997213                  99.4825   99.0851
    6        0.10008                     0.998475           1.99482     1.99284            1                0.998973     0.999003                    0.999348            0.0997213       0.199443                   99.4825   99.2836
    7        0.15007                     0.996981           1.99482     1.9935             1                0.997809     0.999335                    0.998835            0.0997213       0.299164                   99.4825   99.3498
    8        0.20006                     0.99474            1.99482     1.99383            1                0.995935     0.999501                    0.998111            0.0997213       0.398885                   99.4825   99.383
    9        0.30004                     0.98391            1.98686     1.99151            0.996008         0.990134     0.998337                    0.995453            0.198646        0.597532                   98.6861   99.1508
    10       0.40002                     0.942005           1.96695     1.98537            0.986028         0.968158     0.995261                    0.988631            0.196656        0.794188                   96.6953   98.5371
    11       0.5                         0.515214           1.72009     1.93232            0.862275         0.812379     0.968669                    0.953387            0.171975        0.966162                   72.0088   93.2325
    12       0.59998                     0.0509121          0.292654    1.65909            0.146707         0.194228     0.831698                    0.826882            0.0292596       0.995422                   -70.7346  65.9092
    13       0.69996                     0.0119248          0.0338443   1.42695            0.0169661        0.025271     0.715324                    0.712382            0.00338376      0.998806                   -96.6156  42.6947
    14       0.79994                     0.00313599         0.00796337  1.2496             0.00399202       0.00661285   0.626419                    0.624172            0.000796178     0.999602                   -99.2037  24.9596
    15       0.89992                     0.000719359        0.00398169  1.11121            0.00199601       0.00168203   0.557046                    0.555014            0.000398089     1                          -99.6018  11.121
    16       1                           4.95342e-06        0           1                  0                0.000283765  0.501297                    0.499497            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.025745131498264923
RMSE: 0.16045289495133744
LogLoss: 0.09487170112555726
Mean Per-Class Error: 0.03140782815043963
AUC: 0.9943026685198871
pr_auc: 0.9361549188223949
Gini: 0.9886053370397743
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5128559877146646: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3030  98    0.0313   (98.0/3128.0)
1      96    2953  0.0315   (96.0/3049.0)
Total  3126  3051  0.0314   (194.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.512856     0.968197  202
max f2                       0.223616     0.974409  269
max f0point5                 0.715726     0.973862  151
max accuracy                 0.512856     0.968593  202
max precision                0.999835     1         0
max recall                   0.00451557   1         389
max specificity              0.999835     1         0
max absolute_mcc             0.512856     0.937177  202
max min_per_class_accuracy   0.512856     0.968514  202
max mean_per_class_accuracy  0.512856     0.968592  202
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999878           2.02591     2.02591            1                0.999936     1                           0.999936            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999787           2.02591     2.02591            1                0.999829     1                           0.999882            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999696           2.02591     2.02591            1                0.99974      1                           0.999835            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999563           2.02591     2.02591            1                0.999637     1                           0.999785            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.99942            2.02591     2.02591            1                0.999496     1                           0.999728            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.998473           2.01935     2.02263            0.996764         0.999025     0.998382                    0.999377            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.997048           2.01935     2.02154            0.996764         0.997866     0.997843                    0.998873            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.994765           2.02591     2.02263            1                0.99596      0.998382                    0.998145            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.984381           2.01934     2.02154            0.996759         0.990295     0.997841                    0.995531            0.201705        0.606428                   101.934   102.154
    10       0.400032                    0.939493           2.00624     2.01771            0.990291         0.96861      0.995953                    0.988798            0.200722        0.80715                    100.624   101.771
    11       0.500081                    0.446077           1.64892     1.94393            0.813916         0.780509     0.959534                    0.947127            0.164972        0.972122                   64.892    94.3929
    12       0.599968                    0.0452266          0.242978    1.66074            0.119935         0.161213     0.819752                    0.816283            0.0242703       0.996392                   -75.7022  66.0743
    13       0.700016                    0.01079            0.0327817   1.42807            0.0161812        0.0228035    0.704903                    0.702876            0.00327976      0.999672                   -96.7218  42.807
    14       0.799903                    0.00272764         0.00328348  1.25015            0.00162075       0.00581298   0.617082                    0.615831            0.000327976     1                          -99.6717  25.0152
    15       0.899951                    0.000637583        0           1.11117            0                0.00146073   0.54848                     0.547531            0               1                          -100      11.1171
    16       1                           1.53317e-06        0           1                  0                0.000262728  0.493605                    0.492778            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:21:25  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:21:34  2:14:52.150  1268 obs/sec      0.4462    1             11155      0.336704         0.384851            0.546518       0.925178        0.855268           1.97507          0.154959                         0.323977           0.361507              0.580088         0.932176          0.862142             1.99323            0.141493
    2019-08-03 18:21:45  2:15:03.494  1170 obs/sec      0.89324   2             22331      0.300947         0.298749            0.637722       0.945834        0.917963           1.99482          0.12283                          0.291802           0.283481              0.659351         0.951286          0.925739             2.02591            0.112676
    2019-08-03 18:22:04  2:15:22.221  1213 obs/sec      1.78504   4             44626      0.286905         0.273515            0.670741       0.954318        0.93369            1.99482          0.10926                          0.279676           0.26344               0.687075         0.95754           0.945837             2.02591            0.0990772
    2019-08-03 18:22:23  2:15:41.031  1222 obs/sec      2.66288   6             66572      0.282397         0.266813            0.681005       0.95689         0.931008           1.99482          0.106067                         0.274138           0.256286              0.699344         0.959811          0.938813             2.02591            0.0948681
    2019-08-03 18:22:42  2:16:00.031  1226 obs/sec      3.55244   8             88811      0.281525         0.265631            0.682973       0.958478        0.926237           1.97507          0.107563                         0.270585           0.247701              0.707087         0.963508          0.95003              2.02591            0.0966489
    2019-08-03 18:23:01  2:16:19.576  1223 obs/sec      4.44516   10            111129     0.268616         0.24306             0.71138        0.963827        0.953211           1.99482          0.0956895                        0.2611             0.230277              0.727263         0.967617          0.951339             2.02591            0.08904
    2019-08-03 18:23:21  2:16:39.241  1221 obs/sec      5.34228   12            133557     0.26425          0.235717            0.720686       0.96613         0.950341           1.99482          0.0955897                        0.255317           0.221561              0.73921          0.969961          0.953823             2.02591            0.0858022
    2019-08-03 18:23:40  2:16:58.428  1222 obs/sec      6.23016   14            155754     0.254299         0.219345            0.741326       0.971299        0.94822            1.99482          0.0849132                        0.243111           0.20301               0.763549         0.975066          0.949705             2.02591            0.0768982
    2019-08-03 18:23:59  2:17:17.614  1223 obs/sec      7.12116   16            178029     0.230607         0.184083            0.78728        0.978818        0.964787           1.99482          0.0703452                        0.22449            0.174074              0.798384         0.981157          0.960833             2.02591            0.0665372
    2019-08-03 18:24:18  2:17:36.578  1226 obs/sec      8.01612   18            200403     0.214745         0.160949            0.815537       0.98382         0.940791           1.99482          0.0606665                        0.20675            0.151767              0.82899          0.985377          0.941869             2.02591            0.0553667
    2019-08-03 18:24:37  2:17:55.659  1227 obs/sec      8.8998    20            222495     0.191417         0.133657            0.853437       0.988677        0.943234           1.99482          0.0459988                        0.189395           0.129466              0.856495         0.989544          0.942883             2.02591            0.0453294
    2019-08-03 18:24:56  2:18:14.312  1232 obs/sec      9.8002    22            245005     0.173705         0.110368            0.879305       0.992535        0.943533           1.97507          0.0378168                        0.171689           0.10802               0.882072         0.992758          0.935817             2.02591            0.0365873
    2019-08-03 18:25:06  2:18:24.151  1234 obs/sec      10.2476   23            256190     0.161697         0.0969539           0.895416       0.994077        0.938431           1.99482          0.0324287                        0.160453           0.0948717             0.897003         0.994303          0.936155             2.02591            0.0314068
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0034355396324351594
C438        0.753814160823822      0.753814160823822    0.0025897584250010918
C374        0.7014480829238892     0.7014480829238892   0.0024098526889806855
C88         0.6673075556755066     0.6673075556755066   0.0022925615545466346
C322        0.6647748351097107     0.6647748351097107   0.002283860292664959
---         ---                    ---                  ---
C844        0.20353642106056213    0.20353642106056213  0.0006992574411975714
C810        0.2028508484363556     0.2028508484363556   0.0006969021292761973
C982        0.2011278122663498     0.2011278122663498   0.0006909825702260231
C921        0.19957342743873596    0.19957342743873596  0.0006856424195466999
C873        0.19672206044197083    0.19672206044197083  0.0006758464352226957

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_36

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0048693900742076655  0.00565570592880249     0.0         0.025175460712364334  0.09250208735466003  0.05219211359529764    0.18093550205230713
    3        2        Softmax                      0.0   0.0   0.0002595542322296751  5.8614517911337316e-05  0.0         -0.06543101304669108  0.42679154872894287  6.528499853541286e-05  0.05626097321510315


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.022538316386230488
RMSE: 0.1501276669579278
LogLoss: 0.09753250905435863
Mean Per-Class Error: 0.021347626048736856
AUC: 0.994768201903006
pr_auc: 0.6908402682942087
Gini: 0.9895364038060119
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5203140782349224: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4880  113   0.0226   (113.0/4993.0)
1      101   4933  0.0201   (101.0/5034.0)
Total  4981  5046  0.0213   (214.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.520314     0.97877   198
max f2                       0.385594     0.982203  231
max f0point5                 0.59482      0.981632  178
max accuracy                 0.520314     0.978658  198
max precision                0.992916     0.998862  11
max recall                   1.5981e-05   1         399
max specificity              0.999969     0.999399  0
max absolute_mcc             0.520314     0.957317  198
max min_per_class_accuracy   0.528387     0.97795   196
max mean_per_class_accuracy  0.520314     0.978652  198
Gains/Lift Table: Avg response rate: 50.20 %, avg score: 50.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   1                  1.99186     1.99186            1                1            1                           1                   0.0200636       0.0200636                  99.1855   99.1855
    2        0.0200459                   1                  1.99186     1.99186            1                1            1                           1                   0.0198649       0.0399285                  99.1855   99.1855
    3        0.0300189                   1                  1.99186     1.99186            1                1            1                           1                   0.0198649       0.0597934                  99.1855   99.1855
    4        0.0400918                   1                  1.99186     1.99186            1                1            1                           1                   0.0200636       0.079857                   99.1855   99.1855
    5        0.0500648                   1                  1.97194     1.98789            0.99             1            0.998008                    1                   0.0196663       0.0995232                  97.1937   98.7888
    6        0.10003                     0.999986           1.98788     1.98788            0.998004         0.999997     0.998006                    0.999998            0.0993246       0.198848                   98.788    98.7884
    7        0.149995                    0.999816           1.98788     1.98788            0.998004         0.999928     0.998005                    0.999975            0.0993246       0.298172                   98.788    98.7882
    8        0.20006                     0.998669           1.99186     1.98888            1                0.999389     0.998504                    0.999828            0.0997219       0.397894                   99.1855   98.8877
    9        0.29999                     0.98372            1.9839      1.98722            0.996008         0.993433     0.997673                    0.997698            0.198252        0.596146                   98.3904   98.722
    10       0.40002                     0.91094            1.96008     1.98043            0.984048         0.956765     0.994266                    0.987462            0.196067        0.792213                   96.0081   98.0434
    11       0.50005                     0.537553           1.83696     1.95173            0.922233         0.786487     0.979856                    0.947259            0.18375         0.975963                   83.6955   95.1732
    12       0.59998                     0.0909119          0.198788    1.65977            0.0998004        0.242077     0.833278                    0.829807            0.0198649       0.995828                   -80.1212  65.9769
    13       0.70001                     0.014895           0.0158872   1.42486            0.00797607       0.0435884    0.715344                    0.717458            0.00158919      0.997418                   -98.4113  42.4862
    14       0.79994                     0.000683127        0.015903    1.24885            0.00798403       0.00511867   0.626979                    0.628471            0.00158919      0.999007                   -98.4097  24.8852
    15       0.89997                     2.39911e-06        0.00992949  1.11115            0.00498504       0.000150893  0.557846                    0.558635            0.000993246     1                          -99.0071  11.1148
    16       1                           8.38166e-40        0           1                  0                2.41418e-07  0.502044                    0.502754            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.021545990020005613
RMSE: 0.14678552387754595
LogLoss: 0.09538252030086732
Mean Per-Class Error: 0.018811406448300927
AUC: 0.99489917032879
pr_auc: 0.7326223788040129
Gini: 0.9897983406575801
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5578278269186866: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3077  51    0.0163   (51.0/3128.0)
1      65    2984  0.0213   (65.0/3049.0)
Total  3142  3035  0.0188   (116.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.557828     0.980934  187
max f2                       0.381315     0.9839    229
max f0point5                 0.583742     0.98281   181
max accuracy                 0.564104     0.981221  186
max precision                0.988452     0.998221  18
max recall                   0.000238382  1         398
max specificity              0.999987     0.999041  0
max absolute_mcc             0.564104     0.962446  186
max min_per_class_accuracy   0.529086     0.980321  193
max mean_per_class_accuracy  0.557828     0.981189  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999982           2.01935     2.02263            0.996764         0.999996     0.998382                    0.999998            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999775           2.0128      2.01935            0.993528         0.999909     0.996764                    0.999968            0.100689        0.30305                    101.28    101.935
    8        0.200097                    0.998547           2.02591     2.02099            1                0.999312     0.997573                    0.999804            0.101345        0.404395                   102.591   102.099
    9        0.299984                    0.979277           2.01606     2.01935            0.995138         0.991856     0.996762                    0.997158            0.201378        0.605772                   101.606   101.935
    10       0.400032                    0.899865           1.99641     2.01361            0.985437         0.949297     0.99393                     0.985188            0.199738        0.80551                    99.6407   101.361
    11       0.500081                    0.459531           1.79644     1.97016            0.886731         0.755455     0.972483                    0.939226            0.179731        0.985241                   79.6438   97.0163
    12       0.599968                    0.0790484          0.105072    1.65965            0.0518639        0.20121      0.819212                    0.816356            0.0104952       0.995736                   -89.4928  65.965
    13       0.700016                    0.0135858          0.0229472   1.42573            0.0113269        0.0384042    0.703747                    0.705169            0.00229583      0.998032                   -97.7053  42.5727
    14       0.799903                    0.000577995        0.0131339   1.24933            0.00648298       0.00457398   0.616677                    0.617683            0.00131191      0.999344                   -98.6866  24.9332
    15       0.899951                    2.32531e-06        0.00655634  1.11117            0.00323625       0.000130193  0.54848                     0.549029            0.000655953     1                          -99.3444  11.1171
    16       1                           8.38166e-40        0           1                  0                2.25338e-07  0.493605                    0.4941              0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:46:35  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:46:38  39 min 56.301 sec  8599 obs/sec      1         1             25000      0.308909         0.394665            0.618294       0.940897        0.647839           1.97213          0.122769                         0.300537           0.373084              0.638652         0.944776          0.667165             1.99323            0.112028
    2019-08-03 16:46:44  40 min  2.013 sec  9065 obs/sec      3         3             75000      0.245179         0.222051            0.759544       0.972456        0.789475           1.99186          0.0736013                        0.236642           0.212937              0.775965         0.975199          0.794487             2.02591            0.068318
    2019-08-03 16:46:50  40 min  7.687 sec  9212 obs/sec      5         5             125000     0.218429         0.182075            0.809152       0.981861        0.7307             1.99186          0.0550514                        0.209987           0.173274              0.823593         0.983536          0.722282             2.02591            0.0469484
    2019-08-03 16:46:55  40 min 13.067 sec  9425 obs/sec      7         7             175000     0.184747         0.137258            0.863472       0.989615        0.750341           1.99186          0.034806                         0.179332           0.131828              0.871339         0.990714          0.76729              2.02591            0.0315687
    2019-08-03 16:47:01  40 min 18.397 sec  9580 obs/sec      9         9             225000     0.161035         0.110119            0.896269       0.993371        0.706304           1.99186          0.0263289                        0.157457           0.108406              0.900813         0.993534          0.719176             2.02591            0.0220172
    2019-08-03 16:47:04  40 min 21.267 sec  9613 obs/sec      10        10            250000     0.150128         0.0975325           0.909845       0.994768        0.69084            1.99186          0.0213424                        0.146786           0.0953825             0.913802         0.994899          0.732622             2.02591            0.0187793
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.0031232901278013757
C36         0.9765923619270325     0.9765923619270325   0.0030501812828929286
C25         0.9076336026191711     0.9076336026191711   0.002834803070721254
C38         0.9062009453773499     0.9062009453773499   0.0028303284665013506
C34         0.8984947204589844     0.8984947204589844   0.0028062596902912024
---         ---                    ---                  ---
C534        0.19650255143642426    0.19650255143642426  0.0006137344789891659
C947        0.19425664842128754    0.19425664842128754  0.00060671987227399
C971        0.18915414810180664    0.18915414810180664  0.0005907832833990519
C361        0.1857343465089798     0.1857343465089798   0.0005801022508451365
C562        0.15724360942840576    0.15724360942840576  0.000491117412987595

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_88

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.026907689193765977   0.07573464512825012   0.0         0.020579308558204078   0.07072702050209045  0.11648559491866785   0.09430044889450073
    3        2        Softmax                      0.0   0.0   0.0002466143262438436  8.15519888419658e-05  0.0         -0.015182397753960686  0.23858880996704102  2.00022448045567e-05  0.06845024228096008


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02084666207769132
RMSE: 0.14438373203962876
LogLoss: 0.08983211071255298
Mean Per-Class Error: 0.019247587524352294
AUC: 0.9957983982288408
pr_auc: 0.7366227531025422
Gini: 0.9915967964576815
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5377941891886848: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4915  101   0.0201   (101.0/5016.0)
1      92    4919  0.0184   (92.0/5011.0)
Total  5007  5020  0.0192   (193.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.537794     0.98076   192
max f2                       0.447462     0.983929  212
max f0point5                 0.641436     0.982125  166
max accuracy                 0.537794     0.980752  192
max precision                0.999984     1         0
max recall                   3.03438e-05  1         399
max specificity              0.999984     1         0
max absolute_mcc             0.537794     0.961506  192
max min_per_class_accuracy   0.543585     0.979864  191
max mean_per_class_accuracy  0.537794     0.980752  192
Gains/Lift Table: Avg response rate: 49.98 %, avg score: 50.26 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   1                  2.001       2.001              1                1            1                           1                   0.0201557       0.0201557                  100.1     100.1
    2        0.0200459                   1                  2.001       2.001              1                1            1                           1                   0.0199561       0.0401118                  100.1     100.1
    3        0.0300189                   1                  2.001       2.001              1                1            1                           1                   0.0199561       0.0600679                  100.1     100.1
    4        0.0400918                   1                  2.001       2.001              1                1            1                           1                   0.0201557       0.0802235                  100.1     100.1
    5        0.0500648                   1                  2.001       2.001              1                1            1                           1                   0.0199561       0.10018                    100.1     100.1
    6        0.10003                     0.99998            2.001       2.001              1                0.999995     1                           0.999998            0.09998         0.20016                    100.1     100.1
    7        0.149995                    0.999693           1.997       1.99967            0.998004         0.999894     0.999335                    0.999963            0.0997805       0.29994                    99.7004   99.9667
    8        0.20006                     0.998119           1.99303     1.99801            0.996016         0.999092     0.998504                    0.999745            0.0997805       0.399721                   99.3026   99.8005
    9        0.29999                     0.982429           1.999       1.99834            0.999002         0.992513     0.99867                     0.997336            0.199761        0.599481                   99.9001   99.8337
    10       0.40002                     0.911715           1.97506     1.99252            0.987039         0.955495     0.995762                    0.986873            0.197565        0.797046                   97.5063   99.2517
    11       0.50005                     0.543284           1.83342     1.96069            0.916251         0.795614     0.979856                    0.948614            0.183397        0.980443                   83.3417   96.0691
    12       0.59998                     0.0886218          0.161757    1.66107            0.0808383        0.232395     0.83012                     0.829323            0.0161644       0.996607                   -83.8243  66.1068
    13       0.70001                     0.0158617          0.0219451   1.42684            0.0109671        0.0440411    0.713065                    0.717108            0.00219517      0.998803                   -97.8055  42.6841
    14       0.79994                     0.00091002         0.00599101  1.24935            0.00299401       0.00588605   0.624361                    0.628261            0.000598683     0.999401                   -99.4009  24.9345
    15       0.89997                     2.6089e-06         0.00399003  1.11093            0.00199402       0.000198107  0.555186                    0.558453            0.000399122     0.9998                     -99.601   11.0926
    16       1                           1.8373e-40         0.00199501  1                  0.000997009      2.61528e-07  0.499751                    0.502591            0.000199561     1                          -99.8005  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.020367564294125718
RMSE: 0.14271497571777714
LogLoss: 0.0959054402758432
Mean Per-Class Error: 0.01733551271264988
AUC: 0.995015870366285
pr_auc: 0.7138138103643441
Gini: 0.99003174073257
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5571572418534462: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3077  51    0.0163   (51.0/3128.0)
1      56    2993  0.0184   (56.0/3049.0)
Total  3133  3044  0.0173   (107.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.557157     0.982439  187
max f2                       0.408792     0.985833  217
max f0point5                 0.598963     0.983163  177
max accuracy                 0.557157     0.982678  187
max precision                0.991847     0.998139  12
max recall                   3.58373e-05  1         399
max specificity              0.999978     0.999361  0
max absolute_mcc             0.557157     0.96535   187
max min_per_class_accuracy   0.546349     0.981777  190
max mean_per_class_accuracy  0.557157     0.982664  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.78 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999984           2.02591     2.01935            1                0.999996     0.996764                    0.999998            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999759           2.02591     2.02154            1                0.999907     0.997843                    0.999968            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.998337           2.01935     2.02099            0.996764         0.99921      0.997573                    0.999778            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.980498           2.01606     2.01935            0.995138         0.991961     0.996762                    0.997175            0.201378        0.605772                   101.606   101.935
    10       0.400032                    0.911461           1.99641     2.01361            0.985437         0.954163     0.99393                     0.986418            0.199738        0.80551                    99.6407   101.361
    11       0.500081                    0.471909           1.81611     1.9741             0.89644          0.77973      0.974425                    0.945067            0.181699        0.987209                   81.6107   97.4098
    12       0.599968                    0.0821518          0.0919376   1.66074            0.0453809        0.204711     0.819752                    0.821807            0.00918334      0.996392                   -90.8062  66.0743
    13       0.700016                    0.0150134          0.0163909   1.42573            0.00809061       0.0416259    0.703747                    0.710301            0.00163988      0.998032                   -98.3609  42.5727
    14       0.799903                    0.000860683        0.00985045  1.24892            0.00486224       0.00559459   0.616474                    0.622302            0.000983929     0.999016                   -99.015   24.8922
    15       0.899951                    3.70383e-06        0.00655634  1.11081            0.00323625       0.00019278   0.5483                      0.553142            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           2.50115e-37        0.00327817  1                  0.00161812       3.96354e-07  0.493605                    0.497801            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:44:11  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:44:20  1:37:38.988  2613 obs/sec      1         1             25000      0.301855         0.378054            0.635533       0.946493        0.635937           2.001            0.119477                         0.291384           0.372751              0.660325         0.950052          0.696985             2.02591            0.110086
    2019-08-03 17:44:39  1:37:57.745  2759 obs/sec      3         3             75000      0.237311         0.204316            0.774735       0.975821        0.787241           2.001            0.0698115                        0.229393           0.198933              0.789481         0.977793          0.803152             2.02591            0.0626518
    2019-08-03 17:44:57  1:38:15.377  2861 obs/sec      5         5             125000     0.203845         0.158493            0.833788       0.985965        0.808659           2.001            0.0452778                        0.19889            0.155817              0.841745         0.986492          0.78042              2.02591            0.0425773
    2019-08-03 17:45:14  1:38:32.481  2932 obs/sec      7         7             175000     0.174539         0.126241            0.878145       0.991236        0.721211           2.001            0.0312157                        0.171022           0.12923               0.882987         0.990874          0.732153             2.02591            0.0278452
    2019-08-03 17:45:31  1:38:49.204  2986 obs/sec      9         9             225000     0.144384         0.0898321           0.916613       0.995798        0.736623           2.001            0.019248                         0.142715           0.0959054             0.918516         0.995016          0.713814             2.02591            0.0173223
    2019-08-03 17:45:39  1:38:57.942  3013 obs/sec      10        10            250000     0.142901         0.0926338           0.918317       0.994781        0.681916           2.001            0.0184502                        0.144829           0.100878              0.916084         0.99392           0.642604             2.02591            0.0182937
    2019-08-03 17:45:41  1:38:59.087  3012 obs/sec      10        10            250000     0.144384         0.0898321           0.916613       0.995798        0.736623           2.001            0.019248                         0.142715           0.0959054             0.918516         0.995016          0.713814             2.02591            0.0173223
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003283321368814066
C31         0.9053708910942078     0.9053708910942078   0.002972623593431845
C34         0.8604691028594971     0.8604691028594971   0.002825196592622855
C35         0.8397582173347473     0.8397582173347473   0.0027571960996123825
C40         0.8390685319900513     0.8390685319900513   0.002754931640982384
---         ---                    ---                  ---
C633        0.2252664864063263     0.2252664864063263   0.0007396222684955545
C624        0.22377435863018036    0.22377435863018036  0.0007347231334831335
C926        0.2207154631614685     0.2207154631614685   0.0007246797966257433
C569        0.2187691330909729     0.2187691330909729   0.0007182893695145197
C562        0.21351350843906403    0.21351350843906403  0.0007010334647884413

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_26

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.02528856385130513    0.06784895062446594   0.0         0.022318196066705345  0.07296133041381836  0.09538813159116939   0.10236677527427673
    3        2        Softmax                      0.0   0.0   0.0002748413691335827  8.09376360848546e-05  0.0         -0.00939865478505908  0.2679891586303711   -0.00019912485955733  0.09508541226387024


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02090022569922911
RMSE: 0.1445691035430085
LogLoss: 0.09704813703554994
Mean Per-Class Error: 0.017829394536061027
AUC: 0.9943290298178952
pr_auc: 0.7347987900276586
Gini: 0.9886580596357903
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46707843143843025: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4934  70    0.014    (70.0/5004.0)
1      109   4921  0.0217   (109.0/5030.0)
Total  5043  4991  0.0178   (179.0/10034.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.467078     0.982138  218
max f2                       0.368061     0.980859  240
max f0point5                 0.540087     0.985944  201
max accuracy                 0.467078     0.982161  218
max precision                0.992061     0.998397  13
max recall                   1.70788e-05  1         399
max specificity              0.999975     0.9994    0
max absolute_mcc             0.467078     0.964351  218
max min_per_class_accuracy   0.417128     0.980119  229
max mean_per_class_accuracy  0.467078     0.982171  218
Gains/Lift Table: Avg response rate: 50.13 %, avg score: 48.73 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100658                   1                  1.99483     1.99483            1                1            1                           1                   0.0200795       0.0200795                  99.4831   99.4831
    2        0.0200319                   1                  1.99483     1.99483            1                1            1                           1                   0.0198807       0.0399602                  99.4831   99.4831
    3        0.029998                    1                  1.99483     1.99483            1                1            1                           1                   0.0198807       0.059841                   99.4831   99.4831
    4        0.0400638                   1                  1.99483     1.99483            1                1            1                           1                   0.0200795       0.0799205                  99.4831   99.4831
    5        0.0500299                   1                  1.97488     1.99086            0.99             1            0.998008                    1                   0.0196819       0.0996024                  97.4883   99.0857
    6        0.10006                     0.99997            1.98688     1.98887            0.996016         0.999993     0.997012                    0.999996            0.0994036       0.199006                   98.6883   98.887
    7        0.14999                     0.999571           1.99483     1.99085            1                0.999845     0.998007                    0.999946            0.0996024       0.298608                   99.4831   99.0855
    8        0.20002                     0.997566           1.99086     1.99086            0.998008         0.998815     0.998007                    0.999663            0.0996024       0.398211                   99.0857   99.0855
    9        0.29998                     0.975651           1.99085     1.99085            0.998006         0.989831     0.998007                    0.996387            0.199006        0.597217                   99.0853   99.0855
    10       0.40004                     0.897122           1.97695     1.98738            0.991036         0.944228     0.996263                    0.98334             0.197813        0.79503                    97.6949   98.7376
    11       0.5                         0.424145           1.84567     1.95905            0.925224         0.757087     0.982061                    0.938108            0.184493        0.979523                   84.5666   95.9046
    12       0.59996                     0.0494268          0.133254    1.65485            0.0667996        0.159184     0.829568                    0.80833             0.0133201       0.992843                   -86.6746  65.4848
    13       0.70002                     0.00616976         0.0397377   1.42399            0.0199203        0.0215995    0.713838                    0.695876            0.00397614      0.996819                   -96.0262  42.3987
    14       0.79998                     0.000208204        0.0198886   1.24854            0.00997009       0.00191048   0.625888                    0.609163            0.00198807      0.998807                   -98.0111  24.854
    15       0.89994                     2.63761e-07        0.00994432  1.11096            0.00498504       4.14074e-05  0.556921                    0.541505            0.000994036     0.999801                   -99.0056  11.0964
    16       1                           8.61596e-39        0.00198688  1                  0.000996016      2.28024e-08  0.501296                    0.487322            0.000198807     1                          -99.8013  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.019615870852642846
RMSE: 0.14005667014691892
LogLoss: 0.09732719312622633
Mean Per-Class Error: 0.016741684624282493
AUC: 0.9944260790716675
pr_auc: 0.7533802999098249
Gini: 0.9888521581433349
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47794095343483367: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3092  36    0.0115   (36.0/3128.0)
1      67    2982  0.022    (67.0/3049.0)
Total  3159  3018  0.0167   (103.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.477941     0.983023  220
max f2                       0.389432     0.982301  239
max f0point5                 0.547659     0.987231  208
max accuracy                 0.510036     0.983325  214
max precision                0.977114     0.998908  28
max recall                   2.00578e-05  1         399
max specificity              0.999989     0.999361  0
max absolute_mcc             0.510036     0.966733  214
max min_per_class_accuracy   0.407463     0.981777  235
max mean_per_class_accuracy  0.477941     0.983258  220
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.04 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999974           2.01935     2.01935            0.996764         0.999994     0.996764                    0.999997            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.99962            2.02591     2.02154            1                0.999854     0.997843                    0.999949            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.997842           2.02591     2.02263            1                0.998912     0.998382                    0.99969             0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.975652           2.02263     2.02263            0.998379         0.98968      0.998381                    0.996357            0.202033        0.606756                   102.263   102.263
    10       0.400032                    0.887394           2.00624     2.01853            0.990291         0.940752     0.996358                    0.98245             0.200722        0.807478                   100.624   101.853
    11       0.500081                    0.324588           1.76693     1.9682             0.872168         0.720727     0.971512                    0.930088            0.176779        0.984257                   76.6935   96.8196
    12       0.599968                    0.0443724          0.0985045   1.65692            0.0486224        0.131474     0.817863                    0.79713             0.00983929      0.994096                   -90.1495  65.6917
    13       0.700016                    0.00556889         0.019669    1.42292            0.00970874       0.0201515    0.702359                    0.686081            0.00196786      0.996064                   -98.0331  42.2916
    14       0.799903                    0.000169774        0.0197009   1.24769            0.00972447       0.00169372   0.615867                    0.60062             0.00196786      0.998032                   -98.0299  24.7692
    15       0.899951                    2.67416e-07        0.0131127   1.11044            0.00647249       3.25669e-05  0.54812                     0.533852            0.00131191      0.999344                   -98.6887  11.0442
    16       1                           1.46005e-43        0.00655634  1                  0.00323625       2.54481e-08  0.493605                    0.480441            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:37:17  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:37:27  30 min 45.283 sec  2649 obs/sec      1         1             25000      0.305028         0.402911            0.627828       0.944858        0.701018           1.99483          0.116404                         0.2974             0.375652              0.646155         0.949868          0.687257             2.02591            0.110086
    2019-08-03 16:37:45  31 min  3.798 sec  2790 obs/sec      3         3             75000      0.240836         0.221052            0.767991       0.973437        0.769638           1.99483          0.0725533                        0.237307           0.216096              0.774705         0.974496          0.765504             1.99323            0.0675085
    2019-08-03 16:38:03  31 min 21.429 sec  2877 obs/sec      5         5             125000     0.216154         0.186936            0.813108       0.981097        0.759994           1.99483          0.0519235                        0.209519           0.181868              0.824379         0.982139          0.74579              2.02591            0.0456532
    2019-08-03 16:38:20  31 min 38.510 sec  2944 obs/sec      7         7             175000     0.178543         0.131698            0.872488       0.989832        0.713058           1.99483          0.0319912                        0.1717             0.125282              0.882058         0.991036          0.763366             2.02591            0.0280071
    2019-08-03 16:38:36  31 min 54.872 sec  3010 obs/sec      9         9             225000     0.153014         0.104132            0.906347       0.993698        0.753201           1.99483          0.0228224                        0.149048           0.101414              0.911124         0.993579          0.749608             2.02591            0.0191031
    2019-08-03 16:38:45  32 min  3.684 sec  3032 obs/sec      10        10            250000     0.144569         0.0970481           0.916399       0.994329        0.734799           1.99483          0.0178393                        0.140057           0.0973272             0.921524         0.994426          0.75338              2.02591            0.0166748
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003054153503021952
C35         0.9834960699081421     0.9834960699081421   0.003003747967118275
C34         0.9475830793380737     0.9475830793380737   0.0028940641811647065
C31         0.9351103901863098     0.9351103901863098   0.0028559706738997426
C38         0.9070115089416504     0.9070115089416504   0.0027701523773153683
---         ---                    ---                  ---
C446        0.2313985973596573     0.2313985973596573   0.0007067268367203635
C562        0.23105551302433014    0.23105551302433014  0.0007056790044957922
C468        0.22973772883415222    0.22973772883415222  0.0007016542892951333
C472        0.2295759916305542     0.2295759916305542   0.0007011603190481955
C398        0.2226330041885376     0.2226330041885376   0.000679955369630723

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_178

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 260,452 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.07346054647230466    0.11656692624092102    0.0         -0.003386601951056294   0.10110384225845337  0.007086320543689549    0.13548582792282104
    3        2        Softmax                 0.0   0.0   0.0017095289981625683  2.007486909860745e-05  0.0         -9.254111142809052e-05  0.26379621028900146  -0.0003840225650799389  0.264898419380188


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03207713944654508
RMSE: 0.17910091972557005
LogLoss: 0.11392621056113286
Mean Per-Class Error: 0.04162136953944784
AUC: 0.9916539419927163
pr_auc: 0.8671864229950247
Gini: 0.9833078839854326
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4984089582896635: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4829  220   0.0436   (220.0/5049.0)
1      197   4769  0.0397   (197.0/4966.0)
Total  5026  4989  0.0416   (417.0/10015.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.498409     0.958112  204
max f2                       0.261708     0.967562  267
max f0point5                 0.778246     0.965885  128
max accuracy                 0.598692     0.958362  178
max precision                0.999825     1         0
max recall                   0.000117603  1         399
max specificity              0.999825     1         0
max absolute_mcc             0.598692     0.916807  178
max min_per_class_accuracy   0.515191     0.958011  199
max mean_per_class_accuracy  0.498409     0.958379  204
Gains/Lift Table: Avg response rate: 49.59 %, avg score: 49.85 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100849                   0.999938           2.01671     2.01671            1                0.99997      1                           0.99997             0.0203383       0.0203383                  101.671   101.671
    2        0.0200699                   0.999889           2.01671     2.01671            1                0.999913     1                           0.999942            0.0201369       0.0404752                  101.671   101.671
    3        0.0300549                   0.99984            2.01671     2.01671            1                0.999864     1                           0.999916            0.0201369       0.0606122                  101.671   101.671
    4        0.0400399                   0.999779           2.01671     2.01671            1                0.999808     1                           0.999889            0.0201369       0.0807491                  101.671   101.671
    5        0.050025                    0.999726           2.01671     2.01671            1                0.999755     1                           0.999862            0.0201369       0.100886                   101.671   101.671
    6        0.10005                     0.999281           2.01671     2.01671            1                0.999519     1                           0.999691            0.100886        0.201772                   101.671   101.671
    7        0.150075                    0.998521           2.01269     2.01537            0.998004         0.998934     0.999335                    0.999438            0.100685        0.302457                   101.269   101.537
    8        0.2                         0.997093           2.00865     2.01369            0.996            0.997875     0.998502                    0.999048            0.100282        0.402739                   100.865   101.369
    9        0.30005                     0.989046           2.00464     2.01067            0.994012         0.994025     0.997005                    0.997373            0.200564        0.603302                   100.464   101.067
    10       0.4                         0.9474             1.98246     2.00362            0.983017         0.974665     0.99351                     0.991699            0.198147        0.80145                    98.2464   100.362
    11       0.50005                     0.476089           1.59807     1.92248            0.792415         0.800246     0.953275                    0.953393            0.159887        0.961337                   59.8074   92.2482
    12       0.6                         0.0494366          0.332425    1.65761            0.164835         0.189255     0.821934                    0.8261              0.0332259       0.994563                   -66.7575  65.7605
    13       0.69995                     0.00863529         0.0423087   1.42695            0.020979         0.0230021    0.707561                    0.711421            0.00422876      0.998792                   -95.7691  42.6947
    14       0.8                         0.00190467         0.00603806  1.24924            0.00299401       0.00448999   0.619446                    0.623011            0.000604108     0.999396                   -99.3962  24.9245
    15       0.89995                     0.000375865        0.0040294   1.11095            0.001998         0.000953146  0.550871                    0.553924            0.000402739     0.999799                   -99.5971  11.0949
    16       1                           6.21785e-07        0.00201269  1                  0.000998004      0.000155694  0.495856                    0.498519            0.000201369     1                          -99.7987  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02742963009986735
RMSE: 0.1656189303789496
LogLoss: 0.09965810778531653
Mean Per-Class Error: 0.03363325487623714
AUC: 0.9934869740529577
pr_auc: 0.9353528303661004
Gini: 0.9869739481059154
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.42786464473680924: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3013  115   0.0368   (115.0/3128.0)
1      93    2956  0.0305   (93.0/3049.0)
Total  3106  3071  0.0337   (208.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.427865     0.966013  216
max f2                       0.250161     0.9706    266
max f0point5                 0.669528     0.972794  160
max accuracy                 0.447547     0.966327  211
max precision                0.999919     1         0
max recall                   0.00258086   1         392
max specificity              0.999919     1         0
max absolute_mcc             0.427865     0.932672  216
max min_per_class_accuracy   0.466725     0.965562  207
max mean_per_class_accuracy  0.427865     0.966367  216
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999945           2.02591     2.02591            1                0.999971     1                           0.999971            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999889           2.02591     2.02591            1                0.999916     1                           0.999943            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.99984            2.02591     2.02591            1                0.999864     1                           0.999917            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999767           2.02591     2.02591            1                0.999801     1                           0.999888            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999723           2.02591     2.02591            1                0.999747     1                           0.99986             0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999244           2.02591     2.02591            1                0.999508     1                           0.999684            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.998429           2.02591     2.02591            1                0.998857     1                           0.999408            0.101345        0.304034                   102.591   102.591
    8        0.200097                    0.996935           2.01935     2.02427            0.996764         0.997739     0.999191                    0.998991            0.101017        0.405051                   101.935   102.427
    9        0.299984                    0.988892           2.01606     2.02154            0.995138         0.993793     0.997841                    0.99726             0.201378        0.606428                   101.606   102.154
    10       0.400032                    0.953282           1.98985     2.01361            0.982201         0.975833     0.99393                     0.991901            0.199082        0.80551                    98.985    101.361
    11       0.500081                    0.397771           1.64892     1.94065            0.813916         0.786786     0.957915                    0.950865            0.164972        0.970482                   64.892    94.065
    12       0.599968                    0.0416284          0.256112    1.6602             0.126418         0.148145     0.819482                    0.817223            0.0255822       0.996064                   -74.3888  66.0197
    13       0.700016                    0.007652           0.0295035   1.42713            0.0145631        0.0196778    0.70444                     0.703235            0.00295179      0.999016                   -97.0496  42.7133
    14       0.799903                    0.00178146         0.00985045  1.25015            0.00486224       0.0040506    0.617082                    0.615925            0.000983929     1                          -99.015   25.0152
    15       0.899951                    0.000341831        0           1.11117            0                0.000889237  0.54848                     0.547551            0               1                          -100      11.1171
    16       1                           6.21785e-07        0           1                  0                0.000142952  0.493605                    0.492784            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:45:34  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:45:44  3:39:02.635  1308 obs/sec      0.52248   1             13062      0.323258         0.358401            0.581988       0.932348        0.861665           2.01671          0.142087                         0.314067           0.336436              0.605382         0.938365          0.852235             2.02591            0.132265
    2019-08-03 19:46:06  3:39:24.530  1266 obs/sec      1.56052   3             39013      0.293158         0.282446            0.656211       0.951367        0.931856           2.01671          0.117823                         0.283807           0.26586               0.677761         0.956793          0.94131              2.02591            0.105715
    2019-08-03 19:46:18  3:39:36.008  1262 obs/sec      2.08432   4             52108      0.294548         0.285926            0.652941       0.950011        0.9395             2.01671          0.116925                         0.284983           0.269024              0.675085         0.956174          0.943539             2.02591            0.108305
    2019-08-03 19:46:29  3:39:47.317  1264 obs/sec      2.60264   5             65066      0.290473         0.279223            0.662479       0.9529          0.925473           2.01671          0.116525                         0.277808           0.257551              0.691239         0.959637          0.947334             2.02591            0.105067
    2019-08-03 19:46:41  3:39:59.126  1255 obs/sec      3.1238    6             78095      0.289661         0.276685            0.664362       0.954019        0.94992            2.01671          0.114928                         0.281251           0.265655              0.68354          0.957902          0.956292             2.02591            0.104258
    2019-08-03 19:46:52  3:40:10.759  1253 obs/sec      3.64408   7             91102      0.283238         0.266696            0.679083       0.957067        0.942882           2.01671          0.108737                         0.273157           0.251856              0.701491         0.961372          0.94732              2.02591            0.100858
    2019-08-03 19:47:14  3:40:32.584  1252 obs/sec      4.68016   9             117004     0.282318         0.267506            0.681165       0.95806         0.928574           2.01671          0.10694                          0.272826           0.25089               0.702216         0.962635          0.93996              2.02591            0.099401
    2019-08-03 19:47:26  3:40:44.127  1252 obs/sec      5.2014    10            130035     0.26885          0.242196            0.710859       0.964949        0.941744           2.01671          0.0962556                        0.257837           0.225                 0.734036         0.969223          0.949339             2.02591            0.087583
    2019-08-03 19:47:39  3:40:57.177  1238 obs/sec      5.7298    11            143245     0.26174          0.22947             0.725951       0.968329        0.941734           2.01671          0.0903645                        0.249567           0.211549              0.750825         0.972662          0.96127              2.02591            0.0820787
    2019-08-03 19:48:01  3:41:19.135  1239 obs/sec      6.77048   13            169262     0.252585         0.216074            0.744785       0.971673        0.939012           2.01671          0.084673                         0.242946           0.199453              0.76387          0.975963          0.952525             2.02591            0.0781933
    2019-08-03 19:48:12  3:41:30.677  1241 obs/sec      7.293     14            182325     0.246816         0.208265            0.75631        0.974112        0.936354           2.01671          0.0797803                        0.233783           0.188065              0.781346         0.978623          0.936713             2.02591            0.0707463
    2019-08-03 19:48:24  3:41:42.233  1241 obs/sec      7.81748   15            195437     0.228093         0.180118            0.79188        0.97979         0.938559           2.01671          0.0682976                        0.21792            0.164996              0.810013         0.982973          0.96169              2.02591            0.0610329
    2019-08-03 19:48:35  3:41:53.603  1243 obs/sec      8.33668   16            208417     0.216809         0.163361            0.811962       0.983325        0.934885           2.01671          0.0621068                        0.207172           0.151478              0.82829          0.985405          0.961364             2.02591            0.0569856
    2019-08-03 19:48:47  3:42:04.945  1243 obs/sec      8.85424   17            221356     0.208763         0.151266            0.825661       0.985796        0.958293           1.99675          0.0579131                        0.196146           0.137559              0.846082         0.987943          0.955678             2.02591            0.0487292
    2019-08-03 19:48:58  3:42:16.400  1244 obs/sec      9.37608   18            234402     0.19704          0.137273            0.84469        0.988125        0.95273            2.01671          0.0490265                        0.18455            0.123591              0.863743         0.990151          0.948506             2.02591            0.0412822
    2019-08-03 19:49:09  3:42:27.731  1245 obs/sec      9.89776   19            247444     0.181886         0.121152            0.867661       0.991069        0.94497            2.01671          0.0402396                        0.170722           0.108998              0.883397         0.992856          0.939415             2.02591            0.0357779
    2019-08-03 19:49:21  3:42:39.108  1246 obs/sec      10.4181   20            260452     0.179101         0.113926            0.871683       0.991654        0.867186           2.01671          0.0416375                        0.165619           0.0996581             0.890264         0.993487          0.935353             2.02591            0.0336733
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003267555071495078
C438        0.7631404399871826     0.7631404399871826   0.0024936034149431042
C374        0.7201254367828369     0.7201254367828369   0.0023530495230723674
C322        0.6934977769851685     0.6934977769851685   0.00226604217825845
C88         0.6721716523170471     0.6721716523170471   0.0021963578914437937
---         ---                    ---                  ---
C973        0.21810294687747955    0.21810294687747955  0.0007126633901775299
C849        0.21657930314540863    0.21657930314540863  0.0007076848003736499
C908        0.21025845408439636    0.21025845408439636  0.0006870310779681844
C659        0.20900407433509827    0.20900407433509827  0.0006829323230567847
C899        0.2017807513475418     0.2017807513475418   0.0006593297173957476

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_172

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 257,446 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  ------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.10276480009261038    0.18911027908325195    0.0         -0.001018246432395616  0.09991371631622314  0.001031156196378638    0.1375112533569336
    3        2        Softmax                 0.0   0.0   0.0017113867029365792  2.382422098889947e-05  0.0         0.005928580434101605   0.25958001613616943  -0.0014992922497852612  0.3580892086029053


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.029134726510842025
RMSE: 0.17068897594994828
LogLoss: 0.10497418446648611
Mean Per-Class Error: 0.03631701156783773
AUC: 0.9928725399102092
pr_auc: 0.8964151406936488
Gini: 0.9857450798204184
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6161694767322147: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4781  165   0.0334   (165.0/4946.0)
1      199   4868  0.0393   (199.0/5067.0)
Total  4980  5033  0.0364   (364.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.616169     0.96396   166
max f2                       0.324185     0.971479  243
max f0point5                 0.800601     0.971436  115
max accuracy                 0.616169     0.963647  166
max precision                0.99982      1         0
max recall                   0.000759199  1         397
max specificity              0.99982      1         0
max absolute_mcc             0.616169     0.927311  166
max min_per_class_accuracy   0.581372     0.963     175
max mean_per_class_accuracy  0.616169     0.963683  166
Gains/Lift Table: Avg response rate: 50.60 %, avg score: 51.32 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   0.999927           1.97612     1.97612            1                0.999958     1                           0.999958            0.0199329       0.0199329                  97.612    97.612
    2        0.0200739                   0.999859           1.97612     1.97612            1                0.999892     1                           0.999925            0.0197355       0.0396684                  97.612    97.612
    3        0.0300609                   0.999792           1.97612     1.97612            1                0.999826     1                           0.999892            0.0197355       0.059404                   97.612    97.612
    4        0.0400479                   0.999728           1.97612     1.97612            1                0.999761     1                           0.999859            0.0197355       0.0791395                  97.612    97.612
    5        0.050035                    0.999654           1.97612     1.97612            1                0.999692     1                           0.999826            0.0197355       0.0988751                  97.612    97.612
    6        0.10007                     0.999133           1.97612     1.97612            1                0.999405     1                           0.999616            0.0988751       0.19775                    97.612    97.612
    7        0.150005                    0.998383           1.97217     1.9748             0.998            0.998778     0.999334                    0.999337            0.0984804       0.296231                   97.2168   97.4804
    8        0.20004                     0.997115           1.97612     1.97513            1                0.997819     0.999501                    0.998957            0.0988751       0.395106                   97.612    97.5133
    9        0.30001                     0.990994           1.96822     1.97283            0.996004         0.994628     0.998336                    0.997515            0.196763        0.591869                   96.8223   97.2831
    10       0.39998                     0.963774           1.93466     1.96329            0.979021         0.981403     0.993508                    0.993488            0.193408        0.785277                   93.4663   96.3291
    11       0.50005                     0.637003           1.71974     1.91455            0.870259         0.868789     0.968844                    0.968533            0.172094        0.957371                   71.9737   91.4551
    12       0.60002                     0.0595442          0.382984    1.65938            0.193806         0.253862     0.839714                    0.849461            0.038287        0.995658                   -61.7016  65.9375
    13       0.69999                     0.0110485          0.0315863   1.4269             0.015984         0.0278004    0.722072                    0.732114            0.00315769      0.998816                   -96.8414  42.69
    14       0.79996                     0.00255212         0.00394829  1.24908            0.001998         0.00569916   0.632085                    0.641335            0.000394711     0.999211                   -99.6052  24.9076
    15       0.89993                     0.00051281         0.00789658  1.1112             0.003996         0.00128288   0.562313                    0.570234            0.000789422     1                          -99.2103  11.1197
    16       1                           2.68341e-06        0           1                  0                0.000202556  0.506042                    0.513191            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02740503701184408
RMSE: 0.16554466772398344
LogLoss: 0.10058472447827516
Mean Per-Class Error: 0.03428506600210213
AUC: 0.9931809641163637
pr_auc: 0.9162529425034379
Gini: 0.9863619282327274
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5109463254393601: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3012  116   0.0371   (116.0/3128.0)
1      96    2953  0.0315   (96.0/3049.0)
Total  3108  3069  0.0343   (212.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.510946     0.965348  197
max f2                       0.315334     0.972818  244
max f0point5                 0.808976     0.971965  121
max accuracy                 0.510946     0.965679  197
max precision                0.999882     1         0
max recall                   0.000620281  1         397
max specificity              0.999882     1         0
max absolute_mcc             0.510946     0.931372  197
max min_per_class_accuracy   0.550362     0.964579  189
max mean_per_class_accuracy  0.510946     0.965715  197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.85 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999939           2.02591     2.02591            1                0.999964     1                           0.999964            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999883           2.02591     2.02591            1                0.999909     1                           0.999937            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999822           2.02591     2.02591            1                0.999855     1                           0.999909            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999756           2.02591     2.02591            1                0.999788     1                           0.999879            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999675           2.02591     2.02591            1                0.999718     1                           0.999847            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999127           2.02591     2.02591            1                0.999418     1                           0.999633            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.998328           2.01935     2.02372            0.996764         0.998744     0.998921                    0.999336            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.996995           2.02591     2.02427            1                0.997713     0.999191                    0.99893             0.101345        0.405051                   102.591   102.427
    9        0.299984                    0.989945           2.02263     2.02372            0.998379         0.994003     0.998921                    0.99729             0.202033        0.607084                   102.263   102.372
    10       0.400032                    0.957267           1.96362     2.00869            0.969256         0.979021     0.991501                    0.992721            0.196458        0.803542                   96.3625   100.869
    11       0.500081                    0.466782           1.67842     1.94262            0.828479         0.82229      0.958886                    0.958624            0.167924        0.971466                   67.8424   94.2618
    12       0.599968                    0.0432831          0.256112    1.66184            0.126418         0.164294     0.820291                    0.826378            0.0255822       0.997048                   -74.3888  66.1837
    13       0.700016                    0.00897861         0.0163909   1.42666            0.00809061       0.0207451    0.704209                    0.711234            0.00163988      0.998688                   -98.3609  42.6664
    14       0.799903                    0.00238213         0.00328348  1.24892            0.00162075       0.00503599   0.616474                    0.623049            0.000327976     0.999016                   -99.6717  24.8922
    15       0.899951                    0.000453934        0.00983452  1.11117            0.00485437       0.0011778    0.54848                     0.553915            0.000983929     1                          -99.0165  11.1171
    16       1                           3.30654e-06        0           1                  0                0.000179599  0.493605                    0.498514            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:35:34  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:35:42  3:29:00.207  1194 obs/sec      0.3556    1             8890       0.346616         0.465791            0.519358       0.921501        0.750832           1.95655          0.1536                           0.336017           0.425838              0.548296         0.928839          0.751849             2.02591            0.143597
    2019-08-03 19:35:57  3:29:15.499  1227 obs/sec      1.06216   3             26554      0.299506         0.29685             0.641132       0.946958        0.913306           1.93699          0.12304                          0.296317           0.287123              0.648728         0.949826          0.918329             2.02591            0.12158
    2019-08-03 19:36:13  3:29:31.287  1221 obs/sec      1.771     5             44275      0.289544         0.277978            0.664608       0.952837        0.933495           1.97612          0.112254                         0.280517           0.261774              0.685189         0.9581            0.940587             2.02591            0.106848
    2019-08-03 19:36:28  3:29:47.082  1221 obs/sec      2.48424   7             62106      0.282275         0.266958            0.681237       0.956351        0.937866           1.97612          0.10786                          0.276762           0.255834              0.69356          0.959973          0.942671             2.02591            0.100696
    2019-08-03 19:36:44  3:30:02.611  1224 obs/sec      3.19252   9             79813      0.281668         0.263956            0.682605       0.957416        0.94791            1.97612          0.108159                         0.271914           0.246289              0.704203         0.96296           0.942427             2.02591            0.0998867
    2019-08-03 19:37:00  3:30:18.092  1228 obs/sec      3.90804   11            97701      0.275003         0.255957            0.697449       0.961456        0.909974           1.97612          0.101668                         0.266175           0.235904              0.716557         0.966963          0.939536             2.02591            0.0961632
    2019-08-03 19:37:15  3:30:33.660  1230 obs/sec      4.62356   13            115589     0.26635          0.242278            0.716188       0.964288        0.942693           1.97612          0.093878                         0.25758            0.223864              0.734566         0.969373          0.946834             2.02591            0.0880686
    2019-08-03 19:37:32  3:30:50.501  1216 obs/sec      5.3326    15            133315     0.257382         0.226156            0.734979       0.968488        0.945618           1.97612          0.0860881                        0.250136           0.215813              0.749687         0.971127          0.96168              2.02591            0.0819168
    2019-08-03 19:37:47  3:31:05.976  1219 obs/sec      6.0468    17            151170     0.255436         0.225085            0.738972       0.969744        0.937524           1.97612          0.0846899                        0.250688           0.215303              0.748581         0.972073          0.925119             2.02591            0.0833738
    2019-08-03 19:38:03  3:31:21.262  1222 obs/sec      6.74976   19            168744     0.237054         0.195383            0.775189       0.976272        0.962174           1.97612          0.0741037                        0.230306           0.185667              0.787801         0.978643          0.959821             2.02591            0.0700988
    2019-08-03 19:38:18  3:31:36.832  1223 obs/sec      7.46244   21            186561     0.224972         0.177583            0.797521       0.980262        0.955849           1.97612          0.0653151                        0.216554           0.164663              0.812387         0.983001          0.956931             2.02591            0.0603853
    2019-08-03 19:38:34  3:31:52.221  1226 obs/sec      8.17312   23            204328     0.208442         0.153613            0.826183       0.984955        0.955563           1.97612          0.0566264                        0.201668           0.144684              0.837294         0.986568          0.950593             2.02591            0.0498624
    2019-08-03 19:38:49  3:32:07.555  1228 obs/sec      8.88328   25            222082     0.195897         0.137559            0.846476       0.987874        0.946075           1.97612          0.0494357                        0.19121            0.133196              0.853731         0.988306          0.957615             2.02591            0.0461389
    2019-08-03 19:39:04  3:32:22.834  1230 obs/sec      9.59068   27            239767     0.179937         0.11844             0.870471       0.991276        0.957462           1.97612          0.0403475                        0.174956           0.111207              0.877542         0.992425          0.935056             2.02591            0.0382062
    2019-08-03 19:39:20  3:32:38.169  1231 obs/sec      10.2978   29            257446     0.170689         0.104974            0.883444       0.992873        0.896415           1.97612          0.0363527                        0.165545           0.100585              0.890362         0.993181          0.916253             2.02591            0.0343209
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003232610445969056
C438        0.7217915654182434     0.7217915654182434   0.002333270954183371
C88         0.720127522945404      0.720127522945404    0.002327891753103134
C79         0.6934947967529297     0.6934947967529297   0.002241798524208708
C36         0.6861695051193237     0.6861695051193237   0.0022181187099541435
---         ---                    ---                  ---
C894        0.21750357747077942    0.21750357747077942  0.0007031043365676814
C953        0.21568940579891205    0.21568940579891205  0.0006972398262704218
C936        0.21504493057727814    0.21504493057727814  0.0006951564889367997
C880        0.21304689347743988    0.21304689347743988  0.0006886976133364289
C668        0.20863741636276245    0.20863741636276245  0.0006744434915542611

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_48

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms          mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  ------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.008436426014269477    0.019770920276641846   0.0         0.026024176262932113  0.0949820876121521  0.08483576128860053    0.15567785501480103
    3        2        Softmax                      0.0   0.0   0.00025975234393627034  6.515721906907856e-05  0.0         0.014131296062259935  0.5782601833343506  0.0011302340796312746  0.11710792779922485


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.024278039532589408
RMSE: 0.15581411852778107
LogLoss: 0.10300641658272451
Mean Per-Class Error: 0.023534776162991933
AUC: 0.9936867913207407
pr_auc: 0.7175786239175428
Gini: 0.9873735826414813
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5242257031754786: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4851  116   0.0234   (116.0/4967.0)
1      120   4940  0.0237   (120.0/5060.0)
Total  4971  5056  0.0235   (236.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.524226     0.976671  200
max f2                       0.347734     0.980081  246
max f0point5                 0.576084     0.979573  186
max accuracy                 0.524226     0.976464  200
max precision                0.999974     0.998571  0
max recall                   1.79547e-05  1         399
max specificity              0.999974     0.999597  0
max absolute_mcc             0.524226     0.952924  200
max min_per_class_accuracy   0.524226     0.976285  200
max mean_per_class_accuracy  0.524226     0.976465  200
Gains/Lift Table: Avg response rate: 50.46 %, avg score: 50.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   1                  1.98162     1.98162            1                1            1                           1                   0.0199605       0.0199605                  98.1621   98.1621
    2        0.0200459                   1                  1.98162     1.98162            1                1            1                           1                   0.0197628       0.0397233                  98.1621   98.1621
    3        0.0300189                   1                  1.98162     1.98162            1                1            1                           1                   0.0197628       0.0594862                  98.1621   98.1621
    4        0.0400918                   1                  1.98162     1.98162            1                1            1                           1                   0.0199605       0.0794466                  98.1621   98.1621
    5        0.0500648                   1                  1.98162     1.98162            1                1            1                           1                   0.0197628       0.0992095                  98.1621   98.1621
    6        0.10003                     0.99998            1.98162     1.98162            1                0.999995     1                           0.999997            0.0990119       0.198221                   98.1621   98.1621
    7        0.149995                    0.999679           1.97371     1.97899            0.996008         0.999884     0.99867                     0.99996             0.0986166       0.296838                   97.371    97.8985
    8        0.20006                     0.998245           1.97767     1.97866            0.998008         0.999142     0.998504                    0.999755            0.0990119       0.39585                    97.7673   97.8657
    9        0.29999                     0.982399           1.96778     1.97503            0.993014         0.99234      0.996676                    0.997285            0.19664         0.59249                    96.7777   97.5033
    10       0.40002                     0.912922           1.94408     1.96729            0.981057         0.954949     0.99277                     0.986698            0.194466        0.786957                   94.4082   96.7293
    11       0.50005                     0.559105           1.84135     1.9421             0.929212         0.787073     0.980056                    0.946765            0.18419         0.971146                   84.1346   94.2099
    12       0.59998                     0.088288           0.23732     1.65816            0.11976          0.247801     0.836769                    0.830349            0.0237154       0.994862                   -76.268   65.8158
    13       0.70001                     0.0132088          0.0276597   1.42516            0.0139581        0.0418692    0.719191                    0.717677            0.0027668       0.997628                   -97.234   42.5163
    14       0.79994                     0.000587596        0.00988833  1.24836            0.00499002       0.00441635   0.629971                    0.628575            0.000988142     0.998617                   -99.0112  24.8364
    15       0.89997                     1.27097e-06        0.0118542   1.11093            0.00598205       0.00012581   0.560616                    0.558724            0.00118577      0.999802                   -98.8146  11.0928
    16       1                           1.26568e-36        0.00197569  1                  0.000997009      1.30269e-07  0.504637                    0.502835            0.000197628     1                          -99.8024  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.023256939464299218
RMSE: 0.152502260521932
LogLoss: 0.10110897789327075
Mean Per-Class Error: 0.023517364294527887
AUC: 0.9941745396377496
pr_auc: 0.7410940546509811
Gini: 0.9883490792754992
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5357469454906947: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3065  63    0.0201   (63.0/3128.0)
1      82    2967  0.0269   (82.0/3049.0)
Total  3147  3030  0.0235   (145.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.535747     0.976147  193
max f2                       0.314332     0.980188  250
max f0point5                 0.626184     0.980926  174
max accuracy                 0.543525     0.976526  191
max precision                0.996619     0.998543  6
max recall                   1.43466e-05  1         399
max specificity              0.999983     0.999361  0
max absolute_mcc             0.543525     0.953066  191
max min_per_class_accuracy   0.512145     0.97573   200
max mean_per_class_accuracy  0.535747     0.976483  193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.29 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999972           2.02591     2.02263            1                0.999993     0.998382                    0.999996            0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.999628           2.01935     2.02154            0.996764         0.999859     0.997843                    0.999951            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.998              2.02591     2.02263            1                0.999016     0.998382                    0.999717            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.979523           2.00949     2.01826            0.991896         0.991435     0.996222                    0.996959            0.200722        0.605444                   100.949   101.826
    10       0.400032                    0.902024           1.98657     2.01033            0.980583         0.947916     0.992311                    0.984694            0.198754        0.804198                   98.6572   101.033
    11       0.500081                    0.448478           1.76038     1.96033            0.868932         0.746983     0.967627                    0.937136            0.176123        0.980321                   76.0378   96.0325
    12       0.599968                    0.0825138          0.160891    1.66074            0.0794165        0.200539     0.819752                    0.814502            0.0160708       0.996392                   -83.9109  66.0743
    13       0.700016                    0.012317           0.0131127   1.42526            0.00647249       0.0381512    0.703515                    0.703544            0.00131191      0.997704                   -98.6887  42.5259
    14       0.799903                    0.000592225        0.0131339   1.24892            0.00648298       0.00424444   0.616474                    0.61622             0.00131191      0.999016                   -98.6866  24.8922
    15       0.899951                    1.46921e-06        0.00655634  1.11081            0.00323625       0.000131385  0.5483                      0.547729            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           1.26568e-36        0.00327817  1                  0.00161812       1.59575e-07  0.493605                    0.492929            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:00:33  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:00:36  53 min 53.940 sec  8392 obs/sec      1         1             25000      0.305595         0.375023            0.626416       0.939128        0.68201            1.98162          0.120275                         0.297552           0.354118              0.645793         0.94448           0.694172             2.02591            0.112352
    2019-08-03 17:00:42  54 min  0.018 sec  8656 obs/sec      3         3             75000      0.248244         0.225571            0.753478       0.970929        0.81339            1.98162          0.0767927                        0.240597           0.212426              0.768414         0.97469           0.807895             2.02591            0.0684798
    2019-08-03 17:00:48  54 min  5.529 sec  9068 obs/sec      5         5             125000     0.218132         0.183209            0.809658       0.981088        0.810097           1.98162          0.0549516                        0.209548           0.169431              0.824329         0.984201          0.80015              2.02591            0.0490529
    2019-08-03 17:00:53  54 min 10.896 sec  9324 obs/sec      7         7             175000     0.190645         0.146497            0.854605       0.987988        0.785704           1.98162          0.0383963                        0.183191           0.136805              0.865743         0.98953           0.812348             2.02591            0.0339971
    2019-08-03 17:01:00  54 min 17.605 sec  8978 obs/sec      9         9             225000     0.169664         0.121984            0.884847       0.991268        0.699245           1.98162          0.0282238                        0.166029           0.11919               0.88972          0.991639          0.722469             2.02591            0.0255788
    2019-08-03 17:01:03  54 min 20.585 sec  9050 obs/sec      10        10            250000     0.155814         0.103006            0.902879       0.993687        0.717579           1.98162          0.0235365                        0.152502           0.101109              0.906957         0.994175          0.741094             2.02591            0.0234742
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C36         1.0                    1.0                  0.0033219391868731913
C28         0.9904376268386841     0.9904376268386841   0.003290173564749111
C40         0.8929178714752197     0.8929178714752197   0.002966218867912932
C34         0.8669247031211853     0.8669247031211853   0.002879871143366673
C41         0.8429239392280579     0.8429239392280579   0.0028001420652752017
---         ---                    ---                  ---
C879        0.17727158963680267    0.17727158963680267  0.0005888854403337983
C452        0.17672304809093475    0.17672304809093475  0.0005870632186769516
C389        0.1766587793827057     0.1766587793827057   0.0005868497219365958
C651        0.17249566316604614    0.17249566316604614  0.0005730201030369672
C478        0.1451764553785324     0.1451764553785324   0.00048226735613329406

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_233

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 256,305 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight             weight_rms           mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  ----------------------  -------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.06068631924061715    0.10765796899795532   0.0         0.00019996574698634458  0.10151010751724243  0.004011868503238077     0.12904846668243408
    3        2        Softmax                 0.0   0.0   0.0016962380930181098  1.80785427801311e-05  0.0         0.0009205081126424375   0.27861273288726807  -0.00047857998604072804  0.3587838411331177


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02947940567595608
RMSE: 0.17169567751098477
LogLoss: 0.10911993919330051
Mean Per-Class Error: 0.03749554368909713
AUC: 0.9920577838174899
pr_auc: 0.8983382186619345
Gini: 0.9841155676349798
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4845919321497865: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4911  177   0.0348   (177.0/5088.0)
1      198   4724  0.0402   (198.0/4922.0)
Total  5109  4901  0.0375   (375.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.484592     0.961824  204
max f2                       0.198881     0.970874  279
max f0point5                 0.76916      0.967902  133
max accuracy                 0.546449     0.962637  188
max precision                0.999787     1         0
max recall                   0.00011631   1         399
max specificity              0.999787     1         0
max absolute_mcc             0.546449     0.925337  188
max min_per_class_accuracy   0.460002     0.961804  209
max mean_per_class_accuracy  0.546449     0.962504  188
Gains/Lift Table: Avg response rate: 49.17 %, avg score: 48.54 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   0.999916           2.03373     2.03373            1                0.999954     1                           0.999954            0.0205201       0.0205201                  103.373   103.373
    2        0.0200799                   0.999816           2.03373     2.03373            1                0.99987      1                           0.999912            0.0203169       0.0408371                  103.373   103.373
    3        0.0300699                   0.999717           2.03373     2.03373            1                0.999764     1                           0.999863            0.0203169       0.061154                   103.373   103.373
    4        0.0400599                   0.999631           2.03373     2.03373            1                0.999674     1                           0.999816            0.0203169       0.0814709                  103.373   103.373
    5        0.05005                     0.999495           2.03373     2.03373            1                0.999566     1                           0.999766            0.0203169       0.101788                   103.373   103.373
    6        0.1                         0.998512           2.02966     2.03169            0.998            0.999069     0.999001                    0.999418            0.101382        0.203169                   102.966   103.169
    7        0.15005                     0.997022           2.02967     2.03102            0.998004         0.997808     0.998668                    0.998881            0.101585        0.304754                   102.967   103.102
    8        0.2                         0.994324           2.02559     2.02966            0.996            0.995793     0.998002                    0.99811             0.101178        0.405933                   102.559   102.966
    9        0.3                         0.981592           2.02154     2.02695            0.994006         0.989388     0.99667                     0.995203            0.202154        0.608086                   102.154   102.695
    10       0.4                         0.924813           1.99106     2.01798            0.979021         0.960946     0.992258                    0.986638            0.199106        0.807192                   99.1061   101.798
    11       0.5                         0.38096            1.62129     1.93864            0.797203         0.745848     0.953247                    0.93848             0.162129        0.969321                   62.1292   93.8643
    12       0.6                         0.0389892          0.25193     1.65752            0.123876         0.134466     0.815018                    0.804478            0.025193        0.994514                   -74.807   65.7524
    13       0.7                         0.00959016         0.0386022   1.42625            0.018981         0.0205416    0.701299                    0.692487            0.00386022      0.998375                   -96.1398  42.6249
    14       0.8                         0.0025026          0.0121902   1.24949            0.00599401       0.00514641   0.614386                    0.60657             0.00121902      0.999594                   -98.781   24.9492
    15       0.9                         0.000506159        0.00203169  1.11089            0.000999001      0.00130724   0.546232                    0.539318            0.000203169     0.999797                   -99.7968  11.0885
    16       1                           5.74571e-07        0.00203169  1                  0.000999001      0.000199804  0.491708                    0.485406            0.000203169     1                          -99.7968  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0277521900311568
RMSE: 0.16658988574087202
LogLoss: 0.10145055996328319
Mean Per-Class Error: 0.03414178603692963
AUC: 0.9932830897556449
pr_auc: 0.9372841833776077
Gini: 0.9865661795112899
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4443260667643422: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3017  111   0.0355   (111.0/3128.0)
1      100   2949  0.0328   (100.0/3049.0)
Total  3117  3060  0.0342   (211.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.444326     0.965461  215
max f2                       0.19069      0.97305   280
max f0point5                 0.793747     0.971421  127
max accuracy                 0.444326     0.965841  215
max precision                0.999888     1         0
max recall                   0.00127789   1         395
max specificity              0.999888     1         0
max absolute_mcc             0.444326     0.93168   215
max min_per_class_accuracy   0.458996     0.965473  212
max mean_per_class_accuracy  0.444326     0.965858  215
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.87 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999925           2.02591     2.02591            1                0.999966     1                           0.999966            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999836           2.02591     2.02591            1                0.999886     1                           0.999926            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999747           2.02591     2.02591            1                0.999792     1                           0.999881            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999647           2.02591     2.02591            1                0.999696     1                           0.999835            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999537           2.02591     2.02591            1                0.999598     1                           0.999788            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.998668           2.02591     2.02591            1                0.999134     1                           0.999461            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.997165           2.02591     2.02591            1                0.997933     1                           0.998951            0.101345        0.304034                   102.591   102.591
    8        0.200097                    0.99473            2.02591     2.02591            1                0.996041     1                           0.998224            0.101345        0.405379                   102.591   102.591
    9        0.299984                    0.983325           2.01606     2.02263            0.995138         0.990284     0.998381                    0.99558             0.201378        0.606756                   101.606   102.263
    10       0.400032                    0.937431           1.99313     2.01525            0.983819         0.966206     0.994739                    0.988234            0.19941         0.806166                   99.3128   101.525
    11       0.500081                    0.391406           1.64236     1.94065            0.81068          0.773104     0.957915                    0.945194            0.164316        0.970482                   64.2364   94.065
    12       0.599968                    0.0371146          0.242978    1.65801            0.119935         0.133931     0.818403                    0.810129            0.0242703       0.994752                   -75.7022  65.801
    13       0.700016                    0.00933659         0.0393381   1.42666            0.0194175        0.0201845    0.704209                    0.697228            0.00393572      0.998688                   -96.0662  42.6664
    14       0.799903                    0.0025541          0.00985045  1.24974            0.00486224       0.00526922   0.616879                    0.610821            0.000983929     0.999672                   -99.015   24.9742
    15       0.899951                    0.000498509        0.00327817  1.11117            0.00161812       0.00133463   0.54848                     0.543063            0.000327976     1                          -99.6722  11.1171
    16       1                           1.03256e-06        0           1                  0                0.000191479  0.493605                    0.48875             0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:51:21  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:51:29  4:44:47.369  1222 obs/sec      0.34508   1             8627       0.348107         0.480091            0.515152       0.920459        0.710933           2.03373          0.151748                         0.336105           0.441289              0.54806          0.928567          0.724082             2.02591            0.141169
    2019-08-03 20:51:44  4:45:02.698  1211 obs/sec      1.0306    3             25765      0.304346         0.306667            0.629393       0.944213        0.908351           2.01359          0.124276                         0.295072           0.288742              0.651673         0.950088          0.910985             2.02591            0.122713
    2019-08-03 20:51:59  4:45:17.837  1215 obs/sec      1.71596   5             42899      0.29727          0.289934            0.646424       0.94891         0.921515           2.03373          0.121279                         0.288182           0.273447              0.66775          0.954698          0.945717             2.02591            0.111867
    2019-08-03 20:52:14  4:45:33.002  1213 obs/sec      2.39256   7             59814      0.28614          0.270528            0.672405       0.95529         0.933435           2.03373          0.113786                         0.276602           0.255963              0.693916         0.959853          0.944307             2.02591            0.102153
    2019-08-03 20:52:30  4:45:48.708  1205 obs/sec      3.07572   9             76893      0.284059         0.268445            0.677152       0.956404        0.932316           2.03373          0.111489                         0.274946           0.250999              0.69757          0.96211           0.940887             2.02591            0.100372
    2019-08-03 20:52:45  4:46:04.021  1206 obs/sec      3.76128   11            94032      0.277237         0.258405            0.692474       0.95994         0.927867           2.03373          0.101399                         0.268607           0.244047              0.711353         0.963976          0.93945              2.02591            0.0930873
    2019-08-03 20:53:01  4:46:19.473  1204 obs/sec      4.44336   13            111084     0.276277         0.25935             0.6946         0.961008        0.931057           2.03373          0.0981019                        0.267307           0.243278              0.714142         0.965323          0.92238              2.02591            0.0951918
    2019-08-03 20:53:18  4:46:36.085  1189 obs/sec      5.12356   15            128089     0.263239         0.235453            0.722744       0.966208        0.942046           2.03373          0.0886114                        0.254316           0.220095              0.741251         0.970356          0.948693             2.02591            0.0822406
    2019-08-03 20:53:33  4:46:51.334  1194 obs/sec      5.81212   17            145303     0.258078         0.227623            0.73351        0.96853         0.933975           2.01359          0.0868132                        0.245452           0.208521              0.758974         0.973059          0.923232             2.02591            0.0773838
    2019-08-03 20:53:48  4:47:06.545  1195 obs/sec      6.49168   19            162292     0.244219         0.205697            0.761363       0.973994        0.925412           2.01359          0.0784216                        0.232144           0.189981              0.784402         0.977199          0.931554             2.02591            0.0700988
    2019-08-03 20:54:03  4:47:21.881  1196 obs/sec      7.17184   21            179296     0.234834         0.18986             0.779351       0.977826        0.944684           2.01359          0.0714286                        0.224932           0.176969              0.79759          0.980488          0.924639             2.02591            0.0647564
    2019-08-03 20:54:19  4:47:37.332  1196 obs/sec      7.85408   23            196352     0.222933         0.174808            0.801149       0.980587        0.934465           2.03373          0.0638362                        0.214626           0.162756              0.815712         0.983059          0.935996             2.02591            0.0582807
    2019-08-03 20:54:34  4:47:52.286  1199 obs/sec      8.54116   25            213529     0.208813         0.154936            0.825541       0.984802        0.92527            2.03373          0.0552448                        0.199021           0.141057              0.841536         0.987495          0.954053             2.02591            0.0501862
    2019-08-03 20:54:49  4:48:07.365  1202 obs/sec      9.22736   27            230684     0.192737         0.132966            0.851369       0.988645        0.931516           2.03373          0.0476523                        0.184684           0.121816              0.863546         0.99055           0.89528              2.02591            0.0424154
    2019-08-03 20:55:04  4:48:22.339  1204 obs/sec      9.91032   29            247758     0.176958         0.115418            0.874709       0.990954        0.91337            2.03373          0.0394605                        0.168457           0.104144              0.886471         0.992789          0.914021             2.02591            0.0349684
    2019-08-03 20:55:12  4:48:30.478  1205 obs/sec      10.2522   30            256305     0.171696         0.10912             0.88205        0.992058        0.898338           2.03373          0.0374625                        0.16659            0.101451              0.888973         0.993283          0.937284             2.02591            0.034159
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003364710042307636
C88         0.7308030128479004     0.7308030128479004   0.002458940236278007
C438        0.7103245258331299     0.7103245258331299   0.0023900360653681422
C322        0.6944581270217896     0.6944581270217896   0.0023366502339523675
C79         0.6661276817321777     0.6661276817321777   0.002241326500183363
---         ---                    ---                  ---
C555        0.20918329060077667    0.20918329060077667  0.0007038411185673898
C776        0.20827768743038177    0.20827768743038177  0.0007007940264856165
C994        0.2081877589225769     0.2081877589225769   0.0007004914431323157
C631        0.20810939371585846    0.20810939371585846  0.0007002277669343026
C641        0.2036384642124176     0.2036384642124176   0.0006851843855356257

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_144

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 258,190 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0964693335279537    0.16826707124710083    0.0         0.0007635758452398555   0.10003280639648438  0.006310454322113055    0.13536417484283447
    3        2        Softmax                 0.0   0.0   0.001694516178986305  2.570099604781717e-05  0.0         -0.0005730589579115986  0.26168394088745117  -0.0019086093949208516  0.3261289596557617


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.029275169786697766
RMSE: 0.17109988248592622
LogLoss: 0.10988736773486174
Mean Per-Class Error: 0.03708772812050487
AUC: 0.9920366687638132
pr_auc: 0.9210021960151449
Gini: 0.9840733375276265
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44422335910933636: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4743  221   0.0445   (221.0/4964.0)
1      152   4902  0.0301   (152.0/5054.0)
Total  4895  5123  0.0372   (373.0/10018.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.444223     0.963349  219
max f2                       0.216935     0.972612  278
max f0point5                 0.691693     0.969246  159
max accuracy                 0.577513     0.962867  189
max precision                0.995093     0.999476  10
max recall                   0.000138446  1         399
max specificity              0.999777     0.999799  0
max absolute_mcc             0.577513     0.925789  189
max min_per_class_accuracy   0.534164     0.961926  200
max mean_per_class_accuracy  0.577513     0.962912  189
Gains/Lift Table: Avg response rate: 50.45 %, avg score: 50.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100819                   0.999879           1.96257     1.96257            0.990099         0.999937     0.990099                    0.999937            0.0197863       0.0197863                  96.2567   96.2567
    2        0.0200639                   0.999755           1.98219     1.97233            1                0.999818     0.995025                    0.999877            0.0197863       0.0395726                  98.2192   97.2331
    3        0.0300459                   0.999633           1.98219     1.97561            1                0.999696     0.996678                    0.999817            0.0197863       0.0593589                  98.2192   97.5607
    4        0.0400279                   0.999493           1.98219     1.97725            1                0.999564     0.997506                    0.999754            0.0197863       0.0791452                  98.2192   97.7249
    5        0.05001                     0.999354           1.98219     1.97824            1                0.999425     0.998004                    0.999688            0.0197863       0.0989315                  98.2192   97.8236
    6        0.10002                     0.998317           1.98219     1.98021            1                0.998876     0.999002                    0.999282            0.0991294       0.198061                   98.2192   98.0214
    7        0.15003                     0.996837           1.98219     1.98087            1                0.997648     0.999335                    0.998737            0.0991294       0.29719                    98.2192   98.0873
    8        0.20004                     0.994289           1.98219     1.9812             1                0.995572     0.999501                    0.997946            0.0991294       0.39632                    98.2192   98.1203
    9        0.30006                     0.98385            1.97428     1.9789             0.996008         0.989849     0.998337                    0.995247            0.197467        0.593787                   97.4279   97.8895
    10       0.39998                     0.941572           1.94259     1.96983            0.98002          0.967484     0.993761                    0.988311            0.194104        0.787891                   94.2588   96.9825
    11       0.5                         0.563046           1.70524     1.9169             0.860279         0.827119     0.967059                    0.956066            0.170558        0.958449                   70.5239   91.6898
    12       0.60002                     0.0597379          0.352126    1.65606            0.177645         0.223063     0.835468                    0.833879            0.0352196       0.993668                   -64.7874  65.6059
    13       0.69994                     0.0121452          0.0336636   1.42445            0.016983         0.0289718    0.718625                    0.718974            0.00336367      0.997032                   -96.6336  42.4453
    14       0.79996                     0.00321674         0.0178041   1.24858            0.00898204       0.00674729   0.629898                    0.629924            0.00178077      0.998813                   -98.2196  24.8578
    15       0.89998                     0.000732487        0.00791294  1.1107             0.00399202       0.00170415   0.560337                    0.560106            0.000791452     0.999604                   -99.2087  11.0696
    16       1                           3.1707e-06         0.00395647  1                  0.00199601       0.000298748  0.504492                    0.504114            0.000395726     1                          -99.6044  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.026932727635504403
RMSE: 0.16411193629807797
LogLoss: 0.10168400001548315
Mean Per-Class Error: 0.03407305569139685
AUC: 0.9929363973261955
pr_auc: 0.9472897388319445
Gini: 0.9858727946523911
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5765598930887853: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3040  88    0.0281   (88.0/3128.0)
1      122   2927  0.04     (122.0/3049.0)
Total  3162  3015  0.034    (210.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.57656      0.965369  182
max f2                       0.291344     0.971978  244
max f0point5                 0.793822     0.974451  130
max accuracy                 0.57656      0.966003  182
max precision                0.999837     1         0
max recall                   0.000803573  1         396
max specificity              0.999837     1         0
max absolute_mcc             0.57656      0.932042  182
max min_per_class_accuracy   0.504053     0.965235  196
max mean_per_class_accuracy  0.57656      0.965927  182
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.46 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999882           2.02591     2.02591            1                0.999938     1                           0.999938            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999713           2.02591     2.02591            1                0.999798     1                           0.999868            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999585           2.02591     2.02591            1                0.999653     1                           0.999796            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999452           2.02591     2.02591            1                0.999521     1                           0.999728            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999281           2.02591     2.02591            1                0.999367     1                           0.999657            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.99823            2.02591     2.02591            1                0.998792     1                           0.999224            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.996731           2.02591     2.02591            1                0.997515     1                           0.998654            0.101345        0.304034                   102.591   102.591
    8        0.200097                    0.994026           2.0128      2.02263            0.993528         0.995434     0.998382                    0.997849            0.100689        0.404723                   101.28    102.263
    9        0.299984                    0.983852           2.01606     2.02044            0.995138         0.989669     0.997302                    0.995125            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.941526           2.00624     2.01689            0.990291         0.968321     0.995548                    0.988422            0.200722        0.806822                   100.624   101.689
    11       0.500081                    0.421823           1.63909     1.94131            0.809061         0.795926     0.958239                    0.94991             0.163988        0.97081                    63.9086   94.1306
    12       0.599968                    0.048653           0.239694    1.65801            0.118314         0.164013     0.818403                    0.819069            0.0239423       0.994752                   -76.0306  65.801
    13       0.700016                    0.0106477          0.0262254   1.42479            0.012945         0.0245285    0.703284                    0.70551             0.00262381      0.997376                   -97.3775  42.479
    14       0.799903                    0.00283462         0.0131339   1.24851            0.00648298       0.00583179   0.616272                    0.618139            0.00131191      0.998688                   -98.6866  24.8512
    15       0.899951                    0.00064484         0.00983452  1.11081            0.00485437       0.00156732   0.5483                      0.549594            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           3.1707e-06         0.00327817  1                  0.00161812       0.000260405  0.493605                    0.494634            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:43:09  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:43:16  2:36:34.073  1269 obs/sec      0.3338    1             8345       0.34235          0.455266            0.531149       0.923675        0.760462           1.98219          0.15582                          0.33476            0.431817              0.551669         0.929026          0.74158              1.99323            0.144407
    2019-08-03 18:43:30  2:36:48.373  1254 obs/sec      0.99364   3             24841      0.298887         0.298966            0.642637       0.947027        0.892177           1.98219          0.122679                         0.288713           0.28199               0.666525         0.952638          0.896732             2.02591            0.108791
    2019-08-03 18:43:44  2:37:02.948  1245 obs/sec      1.65628   5             41407      0.29045          0.281329            0.662528       0.951784        0.929062           1.98219          0.114793                         0.284441           0.268262              0.67632          0.956067          0.929091             2.02591            0.109762
    2019-08-03 18:43:59  2:37:17.641  1240 obs/sec      2.3238    7             58095      0.293793         0.28994             0.654715       0.949624        0.919819           1.98219          0.117189                         0.284286           0.270068              0.676674         0.955909          0.930287             2.02591            0.107819
    2019-08-03 18:44:14  2:37:32.632  1231 obs/sec      2.98908   9             74727      0.281396         0.268163            0.68324        0.957474        0.930335           1.98219          0.104013                         0.273177           0.251724              0.701448         0.962003          0.915895             2.02591            0.0977821
    2019-08-03 18:44:29  2:37:47.324  1231 obs/sec      3.65668   11            91417      0.274206         0.252911            0.69922        0.960846        0.944523           1.98219          0.100519                         0.263655           0.234617              0.721899         0.966149          0.937796             2.02591            0.0938967
    2019-08-03 18:44:43  2:38:01.988  1233 obs/sec      4.32988   13            108247     0.279125         0.262812            0.688331       0.959851        0.945513           1.98219          0.106109                         0.269716           0.245205              0.708965         0.964752          0.941229             2.02591            0.0971345
    2019-08-03 18:44:58  2:38:16.460  1236 obs/sec      4.99708   15            124927     0.263686         0.234785            0.721856       0.966719        0.951194           1.98219          0.0946297                        0.253725           0.217713              0.742452         0.97103           0.956192             2.02591            0.0862878
    2019-08-03 18:45:13  2:38:31.131  1235 obs/sec      5.66128   17            141532     0.251999         0.218537            0.745965       0.970581        0.963947           1.98219          0.0835496                        0.240394           0.200719              0.768806         0.975462          0.966281             2.02591            0.0746317
    2019-08-03 18:45:27  2:38:45.862  1234 obs/sec      6.32832   19            158208     0.243231         0.203844            0.763335       0.974189        0.960576           1.98219          0.0797564                        0.230213           0.184557              0.787973         0.978704          0.95867              2.02591            0.0688036
    2019-08-03 18:45:42  2:39:00.229  1236 obs/sec      6.995     21            174875     0.235368         0.193128            0.778389       0.976895        0.926461           1.98219          0.0723697                        0.228088           0.180252              0.791869         0.979724          0.954                2.02591            0.0676704
    2019-08-03 18:45:56  2:39:14.857  1237 obs/sec      7.66892   23            191723     0.216078         0.164286            0.813225       0.982873        0.937563           1.98219          0.06109                          0.212859           0.159434              0.818734         0.983853          0.949301             2.02591            0.0569856
    2019-08-03 18:46:11  2:39:29.119  1239 obs/sec      8.33384   25            208346     0.212928         0.160146            0.818632       0.983708        0.921216           1.98219          0.0591935                        0.205334           0.149126              0.831324         0.985751          0.944149             2.02591            0.0568237
    2019-08-03 18:46:25  2:39:43.617  1239 obs/sec      8.99676   27            224919     0.191305         0.133688            0.853598       0.988188        0.950725           1.98219          0.046117                         0.187152           0.126795              0.859874         0.989452          0.947255             2.02591            0.0438724
    2019-08-03 18:46:39  2:39:58.015  1240 obs/sec      9.66396   29            241599     0.184879         0.125628            0.863269       0.989412        0.94234            1.98219          0.0427231                        0.182758           0.12104               0.866377         0.990284          0.950557             2.02591            0.0411203
    2019-08-03 18:46:54  2:40:13.591  1240 obs/sec      10.3276   31            258190     0.1711           0.109887            0.88289        0.992037        0.921002           1.96257          0.037233                         0.164112           0.101684              0.892251         0.992936          0.94729              2.02591            0.0339971
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0032185529529925884
C438        0.7756046652793884     0.7756046652793884   0.0024963246857898037
C88         0.7349916100502014     0.7349916100502014   0.0023656094169518527
C374        0.7243162393569946     0.7243162393569946   0.0023312501710829416
C26         0.6997888684272766     0.6997888684272766   0.002252307528947953
---         ---                    ---                  ---
C885        0.2206203192472458     0.2206203192472458   0.0007100781800033905
C773        0.21933923661708832    0.21933923661708832  0.0007059549477210697
C994        0.21924050152301788    0.21924050152301788  0.0007056371635924853
C869        0.21845249831676483    0.21845249831676483  0.0007031009335460319
C975        0.21391041576862335    0.21391041576862335  0.000688482000347975

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_73

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.005342423789297105   0.015163041651248932    0.0         0.02421284551295856   0.09127837419509888  0.0778191224612402      0.17163395881652832
    3        2        Softmax                      0.0   0.0   0.0001942975530937474  4.6456989366561174e-05  0.0         -0.10933681608730694  0.5234551429748535   -9.850848364191533e-05  0.09511396288871765


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02509806880632555
RMSE: 0.1584237002671177
LogLoss: 0.10908688374378292
Mean Per-Class Error: 0.024347898933961165
AUC: 0.9926356200918985
pr_auc: 0.675087145609529
Gini: 0.9852712401837971
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48534181512949104: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4948  145   0.0285   (145.0/5093.0)
1      100   4836  0.0203   (100.0/4936.0)
Total  5048  4981  0.0244   (245.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.485342     0.975295  205
max f2                       0.400245     0.978874  225
max f0point5                 0.616414     0.976962  175
max accuracy                 0.543394     0.975671  191
max precision                0.995394     0.999169  8
max recall                   1.2355e-05   1         399
max specificity              0.999956     0.999607  0
max absolute_mcc             0.543394     0.951329  191
max min_per_class_accuracy   0.528103     0.975081  194
max mean_per_class_accuracy  0.543394     0.975652  191
Gains/Lift Table: Avg response rate: 49.22 %, avg score: 49.30 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   1                  2.03181     2.03181            1                1            1                           1                   0.0204619       0.0204619                  103.181   103.181
    2        0.0200419                   1                  2.03181     2.03181            1                1            1                           1                   0.0202593       0.0407212                  103.181   103.181
    3        0.030013                    1                  2.03181     2.03181            1                1            1                           1                   0.0202593       0.0609806                  103.181   103.181
    4        0.0400838                   1                  2.03181     2.03181            1                1            1                           1                   0.0204619       0.0814425                  103.181   103.181
    5        0.0500548                   1                  2.03181     2.03181            1                1            1                           1                   0.0202593       0.101702                   103.181   103.181
    6        0.10001                     0.999983           2.02775     2.02978            0.998004         0.999996     0.999003                    0.999998            0.101297        0.202998                   102.775   102.978
    7        0.150065                    0.999763           2.02776     2.02911            0.998008         0.999908     0.998671                    0.999968            0.101499        0.304498                   102.776   102.911
    8        0.20002                     0.998337           2.03181     2.02978            1                0.999208     0.999003                    0.999778            0.101499        0.405997                   103.181   102.978
    9        0.30003                     0.980875           2.01358     2.02438            0.991027         0.992181     0.996344                    0.997246            0.201378        0.607374                   101.358   102.438
    10       0.40004                     0.899957           1.98724     2.01509            0.978066         0.95038      0.991775                    0.985529            0.198744        0.806118                   98.7241   101.509
    11       0.50005                     0.438364           1.75428     1.96293            0.86341          0.749952     0.966102                    0.938414            0.175446        0.981564                   75.4282   96.2932
    12       0.59996                     0.0753551          0.119637    1.65597            0.0588822        0.198629     0.815024                    0.815219            0.011953        0.993517                   -88.0363  65.5972
    13       0.69997                     0.0117086          0.0283602   1.42342            0.0139581        0.0351342    0.70057                     0.703762            0.0028363       0.996353                   -97.164   42.3423
    14       0.79998                     0.000514203        0.0202573   1.24801            0.00997009       0.00414354   0.614234                    0.616299            0.00202593      0.998379                   -97.9743  24.8005
    15       0.89999                     1.71369e-06        0.0121544   1.11067            0.00598205       0.000116257  0.546643                    0.547827            0.00121556      0.999595                   -98.7846  11.0673
    16       1                           2.25201e-37        0.00405146  1                  0.00199402       1.86645e-07  0.492173                    0.493039            0.000405186     1                          -99.5949  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.023807964528712856
RMSE: 0.1542982972320591
LogLoss: 0.10282413202454314
Mean Per-Class Error: 0.02204147055887673
AUC: 0.9938501282127635
pr_auc: 0.7076818485704629
Gini: 0.9877002564255271
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5197140940157798: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3065  63    0.0201   (63.0/3128.0)
1      73    2976  0.0239   (73.0/3049.0)
Total  3138  3039  0.022    (136.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.519714     0.977661  203
max f2                       0.393394     0.979432  229
max f0point5                 0.636105     0.98059   177
max accuracy                 0.54524      0.977983  198
max precision                0.99594      0.998625  8
max recall                   1.8558e-05   1         399
max specificity              0.999978     0.999361  0
max absolute_mcc             0.54524      0.955988  198
max min_per_class_accuracy   0.500586     0.977302  207
max mean_per_class_accuracy  0.519714     0.977959  203
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.21 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999984           2.01935     2.02263            0.996764         0.999996     0.998382                    0.999998            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999768           2.01935     2.02154            0.996764         0.999912     0.997843                    0.999969            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.998403           2.02591     2.02263            1                0.99925      0.998382                    0.999789            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.980442           2.01934     2.02154            0.996759         0.992389     0.997841                    0.997325            0.201705        0.606428                   101.934   102.154
    10       0.400032                    0.895201           1.99313     2.01443            0.983819         0.947409     0.994334                    0.984841            0.19941         0.805838                   99.3128   101.443
    11       0.500081                    0.424712           1.75054     1.96164            0.864078         0.742051     0.968275                    0.936267            0.175139        0.980977                   75.0544   96.1637
    12       0.599968                    0.0768215          0.137906    1.65801            0.0680713        0.196765     0.818403                    0.81315             0.013775        0.994752                   -86.2094  65.801
    13       0.700016                    0.013204           0.0295035   1.42526            0.0145631        0.0378461    0.703515                    0.702341            0.00295179      0.997704                   -97.0496  42.5259
    14       0.799903                    0.000529411        0.00985045  1.24851            0.00486224       0.0046778    0.616272                    0.615221            0.000983929     0.998688                   -99.015   24.8512
    15       0.899951                    1.46664e-06        0.00983452  1.11081            0.00485437       0.000123743  0.5483                      0.54684             0.000983929     0.999672                   -99.0165  11.0807
    16       1                           5.01556e-39        0.00327817  1                  0.00161812       1.62434e-07  0.493605                    0.49213             0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:27:33  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:27:36  1:20:53.619  8378 obs/sec      1         1             25000      0.304986         0.382925            0.627842       0.94182         0.704036           2.01169          0.118456                         0.297042           0.364547              0.647005         0.945832          0.699114             2.02591            0.112676
    2019-08-03 17:27:42  1:20:59.602  8732 obs/sec      3         3             75000      0.249551         0.234494            0.750835       0.969675        0.770715           2.03181          0.0771762                        0.241508           0.22408               0.766657         0.973437          0.774669             2.02591            0.0738222
    2019-08-03 17:27:47  1:21:05.252  9061 obs/sec      5         5             125000     0.218079         0.182534            0.80972        0.981739        0.775035           2.03181          0.0515505                        0.21198            0.172368              0.820229         0.984008          0.77065              2.02591            0.0490529
    2019-08-03 17:27:53  1:21:10.735  9263 obs/sec      7         7             175000     0.19152          0.147326            0.853244       0.987688        0.72219            2.03181          0.0372919                        0.186718           0.140938              0.860523         0.988993          0.753456             2.02591            0.0322163
    2019-08-03 17:27:58  1:21:15.996  9461 obs/sec      9         9             225000     0.169339         0.121418            0.88527        0.991315        0.739697           2.03181          0.0289161                        0.165622           0.117044              0.890259         0.991974          0.713461             2.02591            0.0257407
    2019-08-03 17:28:01  1:21:18.905  9518 obs/sec      10        10            250000     0.158424         0.109087            0.899583       0.992636        0.675087           2.03181          0.0244292                        0.154298           0.102824              0.904753         0.99385           0.707682             2.02591            0.0220172
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.003603199979903608
C28         0.8712021112442017     0.8712021112442017   0.003139115429727088
C36         0.8306575417518616     0.8306575417518616   0.002993025237747088
C40         0.7879016995429993     0.7879016995429993   0.0028389673879593534
C24         0.7700508236885071     0.7700508236885071   0.0027746471124391854
---         ---                    ---                  ---
C475        0.17310233414173126    0.17310233414173126  0.0006237223269007537
C467        0.1722973883152008     0.1722973883152008   0.0006208219461147756
C589        0.17009791731834412    0.17009791731834412  0.0006128968122631031
C445        0.16964532434940338    0.16964532434940338  0.0006112660292865113
C406        0.16545097529888153    0.16545097529888153  0.0005961529508719623

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_66

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.006507300325116765    0.009276382625102997   0.0         0.025441923394614367  0.0933355987071991   0.07993930188246855     0.12192392349243164
    3        2        Softmax                      0.0   0.0   0.00030796801399901597  7.616539369337261e-05  0.0         -0.05753994874248747  0.48251938819885254  -0.0018693824577404317  0.08523726463317871


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02262116458412207
RMSE: 0.1504033396707735
LogLoss: 0.09716126657354805
Mean Per-Class Error: 0.021049978208523168
AUC: 0.9948590524252318
pr_auc: 0.7116047618645543
Gini: 0.9897181048504635
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5111109248378708: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4873  120   0.024    (120.0/4993.0)
1      91    4946  0.0181   (91.0/5037.0)
Total  4964  5066  0.021    (211.0/10030.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.511111     0.979115  196
max f2                       0.450703     0.981443  210
max f0point5                 0.627624     0.980779  169
max accuracy                 0.511111     0.978963  196
max precision                0.999971     1         0
max recall                   2.23798e-05  1         399
max specificity              0.999971     1         0
max absolute_mcc             0.511111     0.95794   196
max min_per_class_accuracy   0.541012     0.978169  189
max mean_per_class_accuracy  0.511111     0.97895   196
Gains/Lift Table: Avg response rate: 50.22 %, avg score: 50.50 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100698                   1                  1.99126     1.99126            1                1            1                           1                   0.0200516       0.0200516                  99.1265   99.1265
    2        0.0200399                   1                  1.99126     1.99126            1                1            1                           1                   0.0198531       0.0399047                  99.1265   99.1265
    3        0.03001                     1                  1.99126     1.99126            1                1            1                           1                   0.0198531       0.0597578                  99.1265   99.1265
    4        0.0400798                   1                  1.99126     1.99126            1                1            1                           1                   0.0200516       0.0798094                  99.1265   99.1265
    5        0.0500499                   1                  1.99126     1.99126            1                1            1                           1                   0.0198531       0.0996625                  99.1265   99.1265
    6        0.1                         0.999981           1.99126     1.99126            1                0.999995     1                           0.999998            0.099464        0.199126                   99.1265   99.1265
    7        0.15005                     0.999705           1.99126     1.99126            1                0.999891     1                           0.999962            0.0996625       0.298789                   99.1265   99.1265
    8        0.2                         0.99823            1.99126     1.99126            1                0.999142     1                           0.999757            0.099464        0.398253                   99.1265   99.1265
    9        0.3                         0.984022           1.97737     1.98663            0.993021         0.992679     0.997674                    0.997398            0.197737        0.59599                    97.7367   98.6632
    10       0.4                         0.918626           1.96149     1.98035            0.985045         0.958253     0.994516                    0.987611            0.196149        0.792138                   96.1485   98.0345
    11       0.5                         0.564395           1.83045     1.95037            0.919242         0.801046     0.979462                    0.950298            0.183045        0.975184                   83.0455   95.0367
    12       0.6                         0.0912185          0.204487    1.65939            0.102692         0.249952     0.833333                    0.833574            0.0204487       0.995632                   -79.5513  65.9387
    13       0.7                         0.0140478          0.025809    1.42602            0.0129611        0.0431166    0.716137                    0.720651            0.0025809       0.998213                   -97.4191  42.6019
    14       0.8                         0.000605083        0.00794123  1.24876            0.00398804       0.00483813   0.627119                    0.631175            0.000794123     0.999007                   -99.2059  24.8759
    15       0.9                         1.84574e-06        0.00595593  1.11067            0.00299103       0.000123588  0.557771                    0.561058            0.000595593     0.999603                   -99.4044  11.067
    16       1                           7.60989e-33        0.00397062  1                  0.00199402       1.80009e-07  0.502193                    0.504952            0.000397062     1                          -99.6029  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.022967507155070812
RMSE: 0.1515503452819254
LogLoss: 0.10329161649322569
Mean Per-Class Error: 0.019093824733110276
AUC: 0.9938418973475853
pr_auc: 0.7069365538893122
Gini: 0.9876837946951706
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5111109248378708: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3066  62    0.0198   (62.0/3128.0)
1      56    2993  0.0184   (56.0/3049.0)
Total  3122  3055  0.0191   (118.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.511111     0.980668  199
max f2                       0.413361     0.982719  222
max f0point5                 0.615141     0.981626  175
max accuracy                 0.511111     0.980897  199
max precision                0.99166      0.996896  13
max recall                   1.46505e-05  1         399
max specificity              0.999971     0.999041  0
max absolute_mcc             0.511111     0.96179   199
max min_per_class_accuracy   0.520945     0.980499  197
max mean_per_class_accuracy  0.511111     0.980906  199
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.63 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.99998            2.02591     2.02263            1                0.999994     0.998382                    0.999997            0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.999681           2.0128      2.01935            0.993528         0.999889     0.996764                    0.999961            0.100689        0.30305                    101.28    101.935
    8        0.200097                    0.998227           2.01935     2.01935            0.996764         0.999143     0.996764                    0.999757            0.101017        0.404067                   101.935   101.935
    9        0.299984                    0.981959           2.00949     2.01607            0.991896         0.992233     0.995143                    0.997252            0.200722        0.604788                   100.949   101.607
    10       0.400032                    0.904246           2.00296     2.01279            0.988673         0.951256     0.993525                    0.985748            0.200394        0.805182                   100.296   101.279
    11       0.500081                    0.470469           1.78988     1.9682             0.883495         0.758409     0.971512                    0.940266            0.179075        0.984257                   78.9882   96.8196
    12       0.599968                    0.0828431          0.114922    1.65965            0.0567261        0.214445     0.819212                    0.819426            0.0114792       0.995736                   -88.5078  65.965
    13       0.700016                    0.0136915          0.0295035   1.42666            0.0145631        0.0418549    0.704209                    0.708293            0.00295179      0.998688                   -97.0496  42.6664
    14       0.799903                    0.000615878        0           1.24851            0                0.004891     0.616272                    0.620457            0               0.998688                   -100      24.8512
    15       0.899951                    1.84236e-06        0.00983452  1.11081            0.00485437       0.000134866  0.5483                      0.551495            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           5.32727e-37        0.00327817  1                  0.00161812       1.8864e-07   0.493605                    0.496319            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:17:10  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:17:13  1:10:30.676  8275 obs/sec      1         1             25000      0.304281         0.369218            0.629645       0.942674        0.701566           1.99126          0.118046                         0.303823           0.356645              0.630706         0.944673          0.670648             2.02591            0.121418
    2019-08-03 17:17:19  1:10:36.489  8863 obs/sec      3         3             75000      0.239104         0.208738            0.771312       0.975331        0.791966           1.99126          0.0705882                        0.238067           0.205519              0.773259         0.976289          0.792856             2.02591            0.0678323
    2019-08-03 17:17:24  1:10:42.038  9199 obs/sec      5         5             125000     0.210841         0.169291            0.82218        0.984103        0.819791           1.99126          0.0500499                        0.209241           0.167725              0.824844         0.984406          0.801436             2.02591            0.0482435
    2019-08-03 17:17:30  1:10:47.644  9332 obs/sec      7         7             175000     0.182767         0.136228            0.866383       0.989907        0.765302           1.99126          0.0344965                        0.184311           0.141073              0.864096         0.9891            0.794472             2.02591            0.0335114
    2019-08-03 17:17:35  1:10:53.058  9510 obs/sec      9         9             225000     0.160057         0.11028             0.897525       0.993383        0.735215           1.99126          0.0251246                        0.15957            0.112735              0.898133         0.993042          0.718421             2.02591            0.0236361
    2019-08-03 17:17:38  1:10:55.836  9593 obs/sec      10        10            250000     0.150403         0.0971613           0.909514       0.994859        0.711605           1.99126          0.0210369                        0.15155            0.103292              0.908115         0.993842          0.706937             2.02591            0.0191031
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003604006737673129
C35         0.8641160726547241     0.8641160726547241   0.0031142801479792687
C38         0.8632757067680359     0.8632757067680359   0.003111251463661534
C28         0.8548353910446167     0.8548353910446167   0.0030808325089262427
C25         0.842779815196991      0.842779815196991    0.00303738413234487
---         ---                    ---                  ---
C495        0.17642933130264282    0.17642933130264282  0.0006358524987378894
C938        0.17418120801448822    0.17418120801448822  0.0006277502472602604
C318        0.1735897958278656     0.1735897958278656   0.0006256187937549305
C423        0.17204496264457703    0.17204496264457703  0.0006200512045537774
C379        0.16918207705020905    0.16918207705020905  0.0006097333455824879

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_49

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0284264540279936      0.08009397983551025    0.0         0.020844712189410416    0.07241576910018921  0.09214904028337464    0.11108604073524475
    3        2        Softmax                      0.0   0.0   0.00028019230111908655  6.234433385543525e-05  0.0         0.00011920805729914719  0.2581593990325928   0.0014533058744275462  0.10111191868782043


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02395950478943477
RMSE: 0.15478858094005116
LogLoss: 0.10804434002965684
Mean Per-Class Error: 0.02200116859440726
AUC: 0.992987379371349
pr_auc: 0.6977785729716507
Gini: 0.9859747587426979
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5742323049828116: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4931  131   0.0259   (131.0/5062.0)
1      90    4876  0.0181   (90.0/4966.0)
Total  5021  5007  0.022    (221.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.574232     0.97784   181
max f2                       0.4361       0.983669  212
max f0point5                 0.63741      0.976981  167
max accuracy                 0.589758     0.977962  178
max precision                0.999986     0.996592  0
max recall                   1.46356e-05  1         399
max specificity              0.999986     0.999012  0
max absolute_mcc             0.574232     0.955955  181
max min_per_class_accuracy   0.627763     0.976689  170
max mean_per_class_accuracy  0.574232     0.977999  181
Gains/Lift Table: Avg response rate: 49.52 %, avg score: 50.80 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   1                  2.01933     2.01933            1                1            1                           1                   0.0203383       0.0203383                  101.933   101.933
    2        0.0200439                   1                  2.01933     2.01933            1                1            1                           1                   0.0201369       0.0404752                  101.933   101.933
    3        0.030016                    1                  1.99914     2.01262            0.99             1            0.996678                    1                   0.0199356       0.0604108                  99.9138   101.262
    4        0.0400878                   1                  2.01933     2.01431            1                1            0.997512                    1                   0.0203383       0.0807491                  101.933   101.431
    5        0.0500598                   1                  1.99914     2.01129            0.99             1            0.996016                    1                   0.0199356       0.100685                   99.9138   101.129
    6        0.10002                     0.999992           2.0153      2.01329            0.998004         0.999998     0.997009                    0.999999            0.100685        0.201369                   101.53    101.329
    7        0.15008                     0.999872           2.01129     2.01262            0.996016         0.999955     0.996678                    0.999984            0.100685        0.302054                   101.129   101.262
    8        0.20004                     0.998981           2.00724     2.01128            0.994012         0.999528     0.996012                    0.99987             0.100282        0.402336                   100.724   101.128
    9        0.30006                     0.9874             1.9992      2.00725            0.99003          0.994986     0.994018                    0.998242            0.19996         0.602296                   99.9199   100.725
    10       0.39998                     0.929042           1.96895     1.99768            0.97505          0.964899     0.989279                    0.989913            0.196738        0.799033                   96.8949   99.7683
    11       0.5                         0.567307           1.83008     1.96416            0.906281         0.815897     0.972677                    0.955103            0.183045        0.982078                   83.0082   96.4156
    12       0.60002                     0.102092           0.14093     1.66023            0.0697906        0.247178     0.822171                    0.837095            0.0140959       0.996174                   -85.907   66.0235
    13       0.69994                     0.0182673          0.0221683   1.42639            0.010978         0.0504043    0.706368                    0.724791            0.00221506      0.998389                   -97.7832  42.6392
    14       0.79996                     0.00108034         0.00805317  1.24906            0.00398804       0.00701525   0.618549                    0.635047            0.000805477     0.999195                   -99.1947  24.9055
    15       0.89998                     4.62909e-06        0.00603987  1.11091            0.00299103       0.000252937  0.550139                    0.564498            0.000604108     0.999799                   -99.396   11.0912
    16       1                           6.87654e-43        0.00201329  1                  0.000997009      4.92059e-07  0.495213                    0.508037            0.000201369     1                          -99.7987  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02183863362050978
RMSE: 0.14777900263741725
LogLoss: 0.10358981164100921
Mean Per-Class Error: 0.018593576863488837
AUC: 0.9937421832993754
pr_auc: 0.6801279839011296
Gini: 0.9874843665987507
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5809582726775965: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3064  64    0.0205   (64.0/3128.0)
1      51    2998  0.0167   (51.0/3049.0)
Total  3115  3062  0.0186   (115.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.580958     0.981181  176
max f2                       0.403847     0.985658  211
max f0point5                 0.595804     0.98002   172
max accuracy                 0.580958     0.981383  176
max precision                0.998153     0.995804  5
max recall                   2.60983e-05  1         399
max specificity              0.999979     0.998402  0
max absolute_mcc             0.580958     0.96277   176
max min_per_class_accuracy   0.595804     0.980179  172
max mean_per_class_accuracy  0.580958     0.981406  176
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.49 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999994           2.01935     2.01608            0.996764         0.999998     0.995146                    0.999999            0.101017        0.201705                   101.935   101.608
    7        0.150073                    0.999871           2.0128      2.01498            0.993528         0.999957     0.994606                    0.999985            0.100689        0.302394                   101.28    101.498
    8        0.200097                    0.999139           2.01935     2.01608            0.996764         0.999604     0.995146                    0.99989             0.101017        0.403411                   101.935   101.608
    9        0.299984                    0.987587           2.01278     2.01498            0.993517         0.995326     0.994603                    0.99837             0.20105         0.60446                    101.278   101.498
    10       0.400032                    0.922619           1.97674     2.00541            0.975728         0.963802     0.989883                    0.989725            0.19777         0.80223                    97.6738   100.541
    11       0.500081                    0.517975           1.84889     1.9741             0.912621         0.803991     0.974425                    0.952566            0.184979        0.987209                   84.8889   97.4098
    12       0.599968                    0.100839           0.0952211   1.66129            0.0470016        0.226199     0.820022                    0.831635            0.00951132      0.99672                    -90.4779  66.129
    13       0.700016                    0.0184918          0.0163909   1.4262             0.00809061       0.0519815    0.703978                    0.720205            0.00163988      0.99836                    -98.3609  42.6196
    14       0.799903                    0.00124439         0.00985045  1.24933            0.00486224       0.00690478   0.616677                    0.631132            0.000983929     0.999344                   -99.015   24.9332
    15       0.899951                    6.29758e-06        0.00655634  1.11117            0.00323625       0.000283536  0.54848                     0.561               0.000655953     1                          -99.3444  11.1171
    16       1                           4.33564e-38        0           1                  0                6.96715e-07  0.493605                    0.504873            0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:01:03  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:01:13  54 min 31.477 sec  2689 obs/sec      1         1             25000      0.297718         0.360718            0.645424       0.947493        0.724063           2.01933          0.113482                         0.28646            0.334643              0.67171          0.952804          0.711538             2.02591            0.10442
    2019-08-03 17:01:32  54 min 49.929 sec  2801 obs/sec      3         3             75000      0.240353         0.211484            0.768901       0.974663        0.809173           2.01933          0.070702                         0.234409           0.201867              0.780174         0.976714          0.82863              2.02591            0.0654039
    2019-08-03 17:01:49  55 min  7.359 sec  2898 obs/sec      5         5             125000     0.209134         0.16942             0.825035       0.983535        0.790998           2.01933          0.0484643                        0.199987           0.157913              0.839994         0.986169          0.801235             2.02591            0.0435486
    2019-08-03 17:02:06  55 min 24.235 sec  2966 obs/sec      7         7             175000     0.173195         0.128938            0.880003       0.990658        0.747401           2.01933          0.0296171                        0.168682           0.123045              0.886167         0.99135           0.728645             2.02591            0.0265501
    2019-08-03 17:02:22  55 min 40.695 sec  3025 obs/sec      9         9             225000     0.154789         0.108044            0.904153       0.992987        0.697779           2.01933          0.0220383                        0.147779           0.10359               0.912631         0.993742          0.680128             2.02591            0.0186175
    2019-08-03 17:02:31  55 min 49.639 sec  3040 obs/sec      10        10            250000     0.154358         0.11468             0.904685       0.992262        0.62377            2.01933          0.0222377                        0.146841           0.103863              0.913737         0.993772          0.622067             2.02591            0.0186175
    2019-08-03 17:02:32  55 min 50.796 sec  3039 obs/sec      10        10            250000     0.154789         0.108044            0.904153       0.992987        0.697779           2.01933          0.0220383                        0.147779           0.10359               0.912631         0.993742          0.680128             2.02591            0.0186175
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0033841261003643977
C34         0.9285863637924194     0.9285863637924194   0.003142453350152396
C28         0.8888907432556152     0.8888907432556152   0.003008118364623636
C25         0.8621637225151062     0.8621637225151062   0.002917670756150699
C40         0.8396731615066528     0.8396731615066528   0.002841559861630154
---         ---                    ---                  ---
C758        0.2115643471479416     0.2115643471479416   0.0007159604290899032
C523        0.2115468680858612     0.2115468680858612   0.0007159012777397071
C600        0.21101197600364685    0.21101197600364685  0.0007140911354834073
C901        0.20770853757858276    0.20770853757858276  0.0007029118832882012
C909        0.2038557529449463     0.2038557529449463   0.0006898735742504291

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_157

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -----------------------  ------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.01449701093875514    0.0486808717250824     0.0         0.025221760772845426   0.08784684538841248  0.06580703383995913      0.1699618101119995
    3        2        Softmax                      0.0   0.0   0.0003127677499605852  8.117494871839881e-05  0.0         -0.042043486260809004  0.5542647838592529   -5.5711613218399625e-05  0.08763387799263


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.024112597223882027
RMSE: 0.15528231458824288
LogLoss: 0.10454143479591435
Mean Per-Class Error: 0.02184097689109965
AUC: 0.993704820261894
pr_auc: 0.6786033917337254
Gini: 0.987409640523788
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5480078647166586: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4840  100   0.0202   (100.0/4940.0)
1      119   4958  0.0234   (119.0/5077.0)
Total  4959  5058  0.0219   (219.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.548008     0.978392  190
max f2                       0.390781     0.980549  226
max f0point5                 0.619827     0.980659  173
max accuracy                 0.548008     0.978137  190
max precision                0.999203     0.997544  2
max recall                   2.13249e-05  1         399
max specificity              0.999975     0.998988  0
max absolute_mcc             0.548008     0.956275  190
max min_per_class_accuracy   0.542639     0.977152  192
max mean_per_class_accuracy  0.548008     0.978159  190
Gains/Lift Table: Avg response rate: 50.68 %, avg score: 51.20 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   1                  1.97302     1.97302            1                1            1                           1                   0.0198936       0.0198936                  97.3016   97.3016
    2        0.0200659                   1                  1.97302     1.97302            1                1            1                           1                   0.0196967       0.0395903                  97.3016   97.3016
    3        0.0300489                   1                  1.97302     1.97302            1                1            1                           1                   0.0196967       0.059287                   97.3016   97.3016
    4        0.0400319                   1                  1.97302     1.97302            1                1            1                           1                   0.0196967       0.0789837                  97.3016   97.3016
    5        0.050015                    1                  1.97302     1.97302            1                1            1                           1                   0.0196967       0.0986803                  97.3016   97.3016
    6        0.10003                     0.999993           1.96908     1.97105            0.998004         0.999998     0.999002                    0.999999            0.0984834       0.197164                   96.9077   97.1046
    7        0.150045                    0.999875           1.96514     1.96908            0.996008         0.999956     0.998004                    0.999985            0.0982864       0.29545                    96.5139   96.9077
    8        0.20006                     0.999102           1.96514     1.96809            0.996008         0.999575     0.997505                    0.999882            0.0982864       0.393736                   96.5139   96.8093
    9        0.29999                     0.98807            1.95725     1.96448            0.992008         0.995209     0.995674                    0.998326            0.195588        0.589324                   95.7247   96.448
    10       0.40002                     0.929707           1.94348     1.95923            0.98503          0.965907     0.993012                    0.990219            0.194406        0.783731                   94.3479   95.9229
    11       0.50005                     0.588071           1.85881     1.93914            0.942116         0.816053     0.982831                    0.955379            0.185937        0.969667                   85.8809   93.9141
    12       0.59998                     0.113304           0.256236    1.65884            0.12987          0.28332      0.840765                    0.843444            0.0256057       0.995273                   -74.3764  65.8843
    13       0.70001                     0.0168641          0.025598    1.42546            0.0129741        0.0536899    0.722476                    0.730589            0.00256057      0.997833                   -97.4402  42.5456
    14       0.79994                     0.000640325        0.0137973   1.24911            0.00699301       0.005618     0.633096                    0.640025            0.00137877      0.999212                   -98.6203  24.9109
    15       0.89997                     1.51222e-06        0.00590723  1.11093            0.00299401       0.000134923  0.563062                    0.568902            0.0005909       0.999803                   -99.4093  11.0929
    16       1                           1.055e-42          0.00196908  1                  0.000998004      1.43203e-07  0.506838                    0.511995            0.000196967     1                          -99.8031  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.023889210866000536
RMSE: 0.1545613498452978
LogLoss: 0.10401716971738391
Mean Per-Class Error: 0.02118839643034187
AUC: 0.9940405914815055
pr_auc: 0.6788248830569362
Gini: 0.988081182963011
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5389078716808587: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3057  71    0.0227   (71.0/3128.0)
1      60    2989  0.0197   (60.0/3049.0)
Total  3117  3060  0.0212   (131.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.538908     0.978556  187
max f2                       0.459391     0.982096  204
max f0point5                 0.62387      0.980386  166
max accuracy                 0.556762     0.978792  182
max precision                0.999586     0.998274  1
max recall                   1.00493e-05  1         399
max specificity              0.999975     0.999361  0
max absolute_mcc             0.556762     0.957586  182
max min_per_class_accuracy   0.547516     0.978354  185
max mean_per_class_accuracy  0.538908     0.978812  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.94 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999992           2.01935     2.01935            0.996764         0.999998     0.996764                    0.999999            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999837           2.02591     2.02154            1                0.999947     0.997843                    0.999982            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.998915           2.01935     2.02099            0.996764         0.999491     0.997573                    0.999859            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.98452            2.01278     2.01826            0.993517         0.994184     0.996222                    0.997969            0.20105         0.605444                   101.278   101.826
    10       0.400032                    0.908495           1.98002     2.00869            0.977346         0.954746     0.991501                    0.987159            0.198098        0.803542                   98.0016   100.869
    11       0.500081                    0.494873           1.80955     1.96885            0.893204         0.763323     0.971836                    0.942377            0.181043        0.984585                   80.9551   96.8851
    12       0.599968                    0.0886829          0.118205    1.66074            0.0583468        0.231048     0.819752                    0.82395             0.0118071       0.996392                   -88.1795  66.0743
    13       0.700016                    0.0150834          0.0131127   1.42526            0.00647249       0.0456742    0.703515                    0.712717            0.00131191      0.997704                   -98.6887  42.5259
    14       0.799903                    0.000522532        0.0164174   1.24933            0.00810373       0.00490819   0.616677                    0.62433             0.00163988      0.999344                   -98.3583  24.9332
    15       0.899951                    2.26971e-06        0.00655634  1.11117            0.00323625       0.000118756  0.54848                     0.554936            0.000655953     1                          -99.3444  11.1171
    16       1                           2.70515e-43        0           1                  0                2.06191e-07  0.493605                    0.499415            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:09:01  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:09:05  3:02:22.503  8278 obs/sec      1         1             25000      0.304134         0.40078             0.62994        0.942324        0.65391            1.97302          0.119796                         0.297856           0.379399              0.64507          0.946221          0.651218             1.99323            0.114133
    2019-08-03 19:09:11  3:02:28.381  8839 obs/sec      3         3             75000      0.239946         0.222621            0.769661       0.973291        0.727697           1.97302          0.0709793                        0.237199           0.213995              0.774909         0.975362          0.764418             2.02591            0.071232
    2019-08-03 19:09:16  3:02:34.087  9061 obs/sec      5         5             125000     0.21026          0.17592             0.82313        0.982607        0.708643           1.97302          0.0485175                        0.208696           0.171827              0.825755         0.983992          0.744298             2.02591            0.0475959
    2019-08-03 19:09:22  3:02:39.633  9264 obs/sec      7         7             175000     0.19338          0.152995            0.850388       0.987132        0.721754           1.97302          0.0389338                        0.192046           0.157467              0.85245          0.986865          0.680621             2.02591            0.0352922
    2019-08-03 19:09:27  3:02:45.119  9376 obs/sec      9         9             225000     0.163532         0.11256             0.89301        0.992807        0.705873           1.97302          0.025856                         0.164528           0.115947              0.891705         0.992677          0.687699             2.02591            0.0257407
    2019-08-03 19:09:30  3:02:48.029  9443 obs/sec      10        10            250000     0.155282         0.104541            0.903532       0.993705        0.678603           1.97302          0.0218628                        0.154561           0.104017              0.904428         0.994041          0.678825             2.02591            0.0212077
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.003179088684626931
C34         0.9835365414619446     0.9835365414619446   0.0031267498898787742
C36         0.9826751351356506     0.9826751351356506   0.0031240114027739872
C31         0.9545737504959106     0.9545737504959106   0.0030346746088434407
C25         0.9528982639312744     0.9528982639312744   0.0030293480884645615
---         ---                    ---                  ---
C510        0.19744572043418884    0.19744572043418884  0.0006276974556603421
C797        0.19213056564331055    0.19213056564331055  0.0006108001072076204
C310        0.18679741024971008    0.18679741024971008  0.000593845533242468
C637        0.18662534654140472    0.18662534654140472  0.0005932985274543595
C589        0.1665143370628357     0.1665143370628357   0.0005293638447846158

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_13

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 251,234 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.1023974187632733     0.16571247577667236    0.0         0.0025385108884017006  0.09958967566490173  -0.01269368663365769  0.12603121995925903
    3        2        Softmax                 0.0   0.0   0.0017896955901051115  9.338694508187473e-05  0.0         -0.012936908843698802  0.2586069107055664   0.000774909194938167  0.28449320793151855


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.032734043277872285
RMSE: 0.1809255185922436
LogLoss: 0.1181129194973321
Mean Per-Class Error: 0.041061122694102226
AUC: 0.9909336493034124
pr_auc: 0.9003384914412472
Gini: 0.9818672986068249
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49614040708732576: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4762  250   0.0499   (250.0/5012.0)
1      165   4856  0.0329   (165.0/5021.0)
Total  4927  5106  0.0414   (415.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.49614      0.95902   203
max f2                       0.227508     0.967305  273
max f0point5                 0.778221     0.966086  129
max accuracy                 0.635414     0.958936  171
max precision                0.999891     1         0
max recall                   0.00102053   1         395
max specificity              0.999891     1         0
max absolute_mcc             0.635414     0.917898  171
max min_per_class_accuracy   0.601197     0.95718   179
max mean_per_class_accuracy  0.635414     0.958939  171
Gains/Lift Table: Avg response rate: 50.04 %, avg score: 50.77 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   0.999951           1.99821     1.99821            1                0.999973     1                           0.999973            0.0201155       0.0201155                  99.8208   99.8208
    2        0.0200339                   0.99991            1.99821     1.99821            1                0.999931     1                           0.999952            0.0199164       0.0400319                  99.8208   99.8208
    3        0.030001                    0.999869           1.99821     1.99821            1                0.999888     1                           0.999931            0.0199164       0.0599482                  99.8208   99.8208
    4        0.0400678                   0.999818           1.99821     1.99821            1                0.999841     1                           0.999908            0.0201155       0.0800637                  99.8208   99.8208
    5        0.0500349                   0.999758           1.99821     1.99821            1                0.99979      1                           0.999885            0.0199164       0.0999801                  99.8208   99.8208
    6        0.10007                     0.999381           1.99821     1.99821            1                0.999593     1                           0.999739            0.0999801       0.19996                    99.8208   99.8208
    7        0.150005                    0.998659           1.99422     1.99688            0.998004         0.999051     0.999336                    0.99951             0.0995818       0.299542                   99.4219   99.688
    8        0.20004                     0.997294           1.99423     1.99622            0.998008         0.998063     0.999003                    0.999148            0.0997809       0.399323                   99.4227   99.6216
    9        0.30001                     0.990974           1.98426     1.99223            0.993021         0.994677     0.99701                     0.997658            0.198367        0.59769                    98.4262   99.2233
    10       0.39998                     0.962404           1.96235     1.98476            0.982054         0.980801     0.993272                    0.993445            0.196176        0.793866                   96.2347   98.4763
    11       0.50005                     0.597864           1.632       1.91417            0.816733         0.852849     0.957943                    0.965309            0.163314        0.95718                    63.2002   91.4169
    12       0.60002                     0.0526379          0.356609    1.65466            0.178465         0.220321     0.828073                    0.841186            0.0356503       0.99283                    -64.3391  65.4662
    13       0.69999                     0.0092477          0.0478135   1.42518            0.0239282        0.0239835    0.713228                    0.724476            0.00477992      0.99761                    -95.2186  42.5177
    14       0.79996                     0.0018797          0.0159378   1.24907            0.00797607       0.00453495   0.625093                    0.634505            0.00159331      0.999203                   -98.4062  24.9066
    15       0.89993                     0.000360932        0.00796892  1.1112             0.00398804       0.000958354  0.556097                    0.564127            0.000796654     1                          -99.2031  11.1197
    16       1                           2.10582e-06        0           1                  0                0.000139939  0.500449                    0.507689            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02874402241924918
RMSE: 0.16954062173782772
LogLoss: 0.10537680201343842
Mean Per-Class Error: 0.03589349239489026
AUC: 0.9925733480181754
pr_auc: 0.8610963315478019
Gini: 0.9851466960363509
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5515123647010735: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3009  119   0.038    (119.0/3128.0)
1      104   2945  0.0341   (104.0/3049.0)
Total  3113  3064  0.0361   (223.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.551512     0.96352   183
max f2                       0.273279     0.970396  256
max f0point5                 0.7665       0.972119  131
max accuracy                 0.682094     0.964222  154
max precision                0.999841     1         0
max recall                   0.000640337  1         397
max specificity              0.999841     1         0
max absolute_mcc             0.682094     0.928619  154
max min_per_class_accuracy   0.577008     0.963267  178
max mean_per_class_accuracy  0.664041     0.964107  158
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.07 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999949           2.02591     2.02591            1                0.999972     1                           0.999972            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999905           2.02591     2.02591            1                0.999929     1                           0.999951            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999855           2.02591     2.02591            1                0.999884     1                           0.999929            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999806           2.02591     2.02591            1                0.999831     1                           0.999904            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.99976            2.02591     2.02591            1                0.999785     1                           0.999881            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999308           2.02591     2.02591            1                0.999569     1                           0.999725            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.998524           2.02591     2.02591            1                0.998942     1                           0.999464            0.101345        0.304034                   102.591   102.591
    8        0.200097                    0.997242           2.02591     2.02591            1                0.997943     1                           0.999083            0.101345        0.405379                   102.591   102.591
    9        0.299984                    0.990721           2.00949     2.02044            0.991896         0.994658     0.997302                    0.99761             0.200722        0.6061                     100.949   102.044
    10       0.400032                    0.959504           1.98985     2.01279            0.982201         0.979817     0.993525                    0.99316             0.199082        0.805182                   98.985    101.279
    11       0.500081                    0.491856           1.63909     1.93803            0.809061         0.827805     0.95662                     0.960078            0.163988        0.96917                    63.9086   93.8027
    12       0.599968                    0.0457637          0.249545    1.65692            0.123177         0.177722     0.817863                    0.829826            0.0249262       0.994096                   -75.0455  65.6917
    13       0.700016                    0.00909849         0.0393381   1.42573            0.0194175        0.0226288    0.703747                    0.714459            0.00393572      0.998032                   -96.0662  42.5727
    14       0.799903                    0.00201919         0.0164174   1.24974            0.00810373       0.00472209   0.616879                    0.625832            0.00163988      0.999672                   -98.3583  24.9742
    15       0.899951                    0.000373591        0.00327817  1.11117            0.00161812       0.000981725  0.54848                     0.556366            0.000327976     1                          -99.6722  11.1171
    16       1                           1.57717e-06        0           1                  0                0.000137271  0.493605                    0.500717            0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:21:06  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:21:13  14 min 31.281 sec  1240 obs/sec      0.33644   1             8411       0.361009         0.526122            0.478689       0.913888        0.696864           1.97842          0.164358                         0.354831           0.494502              0.496296         0.919391          0.708857             2.02591            0.160272
    2019-08-03 16:21:28  14 min 46.122 sec  1229 obs/sec      1.01032   3             25258      0.302386         0.300938            0.63425        0.945296        0.920822           1.99821          0.122894                         0.291355           0.282684              0.660394         0.951583          0.919445             2.02591            0.1164
    2019-08-03 16:21:42  15 min  0.629 sec  1235 obs/sec      1.68      5             42000      0.291465         0.283579            0.660193       0.951512        0.926935           1.99821          0.112628                         0.281512           0.264365              0.682952         0.957507          0.929532             2.02591            0.105877
    2019-08-03 16:21:57  15 min 14.999 sec  1241 obs/sec      2.34708   7             58677      0.284466         0.270622            0.676315       0.955124        0.930431           1.99821          0.10894                          0.273954           0.252504              0.699748         0.96085           0.940076             2.02591            0.0995629
    2019-08-03 16:22:11  15 min 29.656 sec  1237 obs/sec      3.01096   9             75274      0.293024         0.28694             0.656547       0.952692        0.931549           1.99821          0.114921                         0.282854           0.265496              0.679922         0.958996          0.926498             2.02591            0.108143
    2019-08-03 16:22:26  15 min 44.428 sec  1235 obs/sec      3.68292   11            92073      0.278307         0.262699            0.690181       0.958842        0.91873            1.99821          0.103658                         0.266994           0.242092              0.71481          0.964385          0.940333             2.02591            0.0943824
    2019-08-03 16:22:40  15 min 58.893 sec  1237 obs/sec      4.34964   13            108741     0.274122         0.253118            0.699427       0.960699        0.939639           1.99821          0.0996711                        0.262068           0.232165              0.725236         0.966923          0.951836             2.02591            0.0879068
    2019-08-03 16:22:55  16 min 13.247 sec  1239 obs/sec      5.01272   15            125318     0.266805         0.238181            0.715261       0.965831        0.945357           1.99821          0.0960829                        0.252996           0.216963              0.743931         0.971494          0.939921             2.02591            0.0838595
    2019-08-03 16:23:09  16 min 27.527 sec  1242 obs/sec      5.68104   17            142026     0.255467         0.221829            0.738947       0.969721        0.956517           1.99821          0.0861158                        0.245812           0.206004              0.758266         0.973877          0.957987             2.02591            0.081593
    2019-08-03 16:23:24  16 min 42.115 sec  1242 obs/sec      6.357     19            158925     0.244605         0.20564             0.760673       0.973856        0.948252           1.99821          0.0787402                        0.236467           0.19124               0.776297         0.977284          0.958969             2.02591            0.0743079
    2019-08-03 16:23:38  16 min 56.517 sec  1243 obs/sec      7.02904   21            175726     0.24082          0.200198            0.768023       0.975264        0.948089           1.99821          0.0779428                        0.228662           0.182572              0.79082          0.979326          0.954617             2.02591            0.0665372
    2019-08-03 16:23:53  17 min 11.108 sec  1242 obs/sec      7.69876   23            192469     0.214321         0.163671            0.816266       0.982834        0.942042           1.99821          0.0602013                        0.210244           0.153322              0.823161         0.985413          0.94709              2.02591            0.0576332
    2019-08-03 16:24:07  17 min 25.556 sec  1244 obs/sec      8.37028   25            209257     0.202902         0.146839            0.835323       0.986115        0.923287           1.99821          0.0523273                        0.197498           0.13852               0.843953         0.987759          0.944113             2.02591            0.0498624
    2019-08-03 16:24:22  17 min 39.970 sec  1245 obs/sec      9.04428   27            226107     0.190793         0.13064             0.854393       0.988962        0.943475           1.99821          0.0475431                        0.188258           0.127378              0.858213         0.989613          0.956462             2.02591            0.0451676
    2019-08-03 16:24:36  17 min 54.145 sec  1247 obs/sec      9.7146    29            242865     0.178715         0.117708            0.872243       0.99074         0.924534           1.99821          0.0400678                        0.17128            0.108287              0.882633         0.992352          0.933554             2.02591            0.035616
    2019-08-03 16:24:43  18 min  1.998 sec  1247 obs/sec      10.0494   30            251234     0.180926         0.118113            0.869064       0.990934        0.900338           1.99821          0.0413635                        0.169541           0.105377              0.885005         0.992573          0.861096             2.02591            0.0361017
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003129199104324759
C438        0.76401686668396       0.76401686668396     0.002390760894916456
C88         0.7130371332168579     0.7130371332168579   0.0022312351586124854
C374        0.6950621604919434     0.6950621604919434   0.002174987890061421
C79         0.6869184374809265     0.6869184374809265   0.002149504559309478
---         ---                    ---                  ---
C947        0.22745381295681       0.22745381295681     0.0007117482677797011
C691        0.223744198679924      0.223744198679924    0.000700140146107079
C748        0.2237090766429901     0.2237090766429901   0.0007000302422605634
C899        0.22151853144168854    0.22151853144168854  0.0006931755901786676
C743        0.22067245841026306    0.22067245841026306  0.0006905280592065377

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_32

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0032815422765960353  0.003752961754798889   0.0         0.025810265171358805   0.08405095338821411  0.0036963995368630943   0.2009507417678833
    3        2        Softmax                      0.0   0.0   0.0002205022052521599  4.863401409238577e-05  0.0         -0.047116905683651567  0.5053932666778564   0.00036927413150567023  0.06719455122947693


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02606871970454364
RMSE: 0.16145810510638245
LogLoss: 0.11999325498267131
Mean Per-Class Error: 0.0263299055695978
AUC: 0.9921473041735595
pr_auc: 0.6676955723109672
Gini: 0.9842946083471189
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5342099210098475: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4856  140   0.028    (140.0/4996.0)
1      124   4909  0.0246   (124.0/5033.0)
Total  4980  5049  0.0263   (264.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.53421      0.973815  191
max f2                       0.399528     0.980102  225
max f0point5                 0.589967     0.975394  177
max accuracy                 0.53421      0.973676  191
max precision                0.999495     0.995876  1
max recall                   2.42555e-05  1         399
max specificity              0.999969     0.998599  0
max absolute_mcc             0.53421      0.947356  191
max min_per_class_accuracy   0.537793     0.972382  190
max mean_per_class_accuracy  0.53421      0.97367   191
Gains/Lift Table: Avg response rate: 50.18 %, avg score: 50.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0104696                   1                  1.99265     1.99265            1                1            1                           1                   0.0208623       0.0208623                  99.2649   99.2649
    2        0.0200419                   1                  1.97189     1.98273            0.989583         1            0.995025                    1                   0.0188754       0.0397377                  97.1892   98.2735
    3        0.030013                    1                  1.97272     1.97941            0.99             1            0.993355                    1                   0.0196702       0.0594079                  97.2722   97.9408
    4        0.0400838                   1                  1.99265     1.98273            1                1            0.995025                    1                   0.0200676       0.0794755                  99.2649   98.2735
    5        0.0500548                   1                  1.97272     1.98074            0.99             1            0.994024                    1                   0.0196702       0.0991456                  97.2722   98.074
    6        0.10001                     0.999995           1.98072     1.98073            0.994012         0.999999     0.994018                    0.999999            0.098947        0.198093                   98.0716   98.0728
    7        0.150065                    0.999866           1.98868     1.98338            0.998008         0.999955     0.995349                    0.999985            0.099543        0.297636                   98.8679   98.338
    8        0.20002                     0.998919           1.98072     1.98272            0.994012         0.999514     0.995015                    0.999867            0.098947        0.396583                   98.0716   98.2715
    9        0.30003                     0.98276            1.97278     1.9794             0.99003          0.993299     0.993353                    0.997678            0.197298        0.59388                    97.2782   97.9404
    10       0.40004                     0.905963           1.94695     1.97129            0.977069         0.953402     0.989282                    0.986609            0.194715        0.788595                   94.6955   97.1292
    11       0.50005                     0.545424           1.82378     1.94179            0.915254         0.786322     0.974477                    0.946551            0.182396        0.970991                   82.378    94.1789
    12       0.59996                     0.0988098          0.248584    1.65982            0.12475          0.255032     0.832973                    0.831394            0.0248361       0.995828                   -75.1416  65.9823
    13       0.69997                     0.0153636          0.0178802   1.42523            0.00897308       0.0478068    0.715242                    0.719437            0.0017882       0.997616                   -98.212   42.5226
    14       0.79998                     0.000684269        0.00794675  1.24804            0.00398804       0.0053024    0.626324                    0.630159            0.000794755     0.99841                    -99.2053  24.8044
    15       0.89999                     1.10569e-06        0.0139068   1.1109             0.00697906       0.000144991  0.557501                    0.56015             0.00139082      0.999801                   -98.6093  11.0903
    16       1                           2.04111e-43        0.00198669  1                  0.000997009      1.09259e-07  0.501845                    0.504129            0.000198689     1                          -99.8013  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02283517124029902
RMSE: 0.15111310744041703
LogLoss: 0.1061757307592766
Mean Per-Class Error: 0.020962283554458727
AUC: 0.9941980264377487
pr_auc: 0.6894536690855304
Gini: 0.9883960528754974
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49505377591418925: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3042  86    0.0275   (86.0/3128.0)
1      44    3005  0.0144   (44.0/3049.0)
Total  3086  3091  0.021    (130.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.495054     0.978827  206
max f2                       0.376696     0.984701  232
max f0point5                 0.611668     0.979279  177
max accuracy                 0.495054     0.978954  206
max precision                0.992276     0.995765  13
max recall                   2.38964e-05  1         399
max specificity              0.999987     0.998402  0
max absolute_mcc             0.495054     0.957997  206
max min_per_class_accuracy   0.541847     0.976982  194
max mean_per_class_accuracy  0.495054     0.979038  206
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.71 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.010361                    1                  2.02591     2.02591            1                1            1                           1                   0.0209905       0.0209905                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0196786       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999996           2.00624     2.0128             0.990291         0.999999     0.993528                    1                   0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.9999             2.01935     2.01498            0.996764         0.999966     0.994606                    0.999988            0.101017        0.302394                   101.935   101.498
    8        0.200097                    0.999064           2.01935     2.01608            0.996764         0.999581     0.995146                    0.999886            0.101017        0.403411                   101.935   101.608
    9        0.299984                    0.98382            2.01278     2.01498            0.993517         0.993705     0.994603                    0.997828            0.20105         0.60446                    101.278   101.498
    10       0.400032                    0.901167           1.99313     2.00951            0.983819         0.952488     0.991906                    0.986489            0.19941         0.80387                    99.3128   100.951
    11       0.500081                    0.497541           1.80955     1.96951            0.893204         0.758163     0.972159                    0.940809            0.181043        0.984913                   80.9551   96.9507
    12       0.599968                    0.0896079          0.124772    1.66238            0.0615883        0.219031     0.820561                    0.820642            0.0124631       0.997376                   -87.5228  66.2383
    13       0.700016                    0.0127639          0.0131127   1.42666            0.00647249       0.0427305    0.704209                    0.709461            0.00131191      0.998688                   -98.6887  42.6664
    14       0.799903                    0.000530999        0.00328348  1.24892            0.00162075       0.00447125   0.616474                    0.621426            0.000327976     0.999016                   -99.6717  24.8922
    15       0.899951                    8.72944e-07        0.00655634  1.11081            0.00323625       0.000121864  0.5483                      0.552355            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           1.26536e-38        0.00327817  1                  0.00161812       9.10361e-08  0.493605                    0.497093            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:43:21  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:43:24  36 min 41.974 sec  8858 obs/sec      1         1             25000      0.318105         0.4592              0.595232       0.935159        0.626332           1.99265          0.128428                         0.307726           0.434376              0.621156         0.940636          0.594806             2.02591            0.118504
    2019-08-03 16:43:30  36 min 47.556 sec  9405 obs/sec      3         3             75000      0.250298         0.253701            0.7494         0.968772        0.7263             1.99265          0.0766776                        0.241906           0.233464              0.765887         0.972467          0.684305             2.02591            0.0725271
    2019-08-03 16:43:35  36 min 52.951 sec  9630 obs/sec      5         5             125000     0.210316         0.184568            0.823067       0.982094        0.723801           1.99265          0.0481603                        0.197931           0.162321              0.843268         0.986328          0.732208             2.02591            0.0419297
    2019-08-03 16:43:41  36 min 58.313 sec  9744 obs/sec      7         7             175000     0.186072         0.147725            0.861507       0.987883        0.759687           1.99265          0.0353973                        0.173767           0.128587              0.8792           0.991226          0.723325             2.02591            0.0283309
    2019-08-03 16:43:46  37 min  3.607 sec  9853 obs/sec      9         9             225000     0.17151          0.131307            0.882336       0.99036         0.675884           1.99265          0.0303121                        0.159516           0.11497               0.898202         0.992941          0.685689             2.02591            0.0244455
    2019-08-03 16:43:49  37 min  6.492 sec  9881 obs/sec      10        10            250000     0.161458         0.119993            0.895724       0.992147        0.667696           1.99265          0.0263237                        0.151113           0.106176              0.908644         0.994198          0.689454             2.02591            0.0210458
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003046595099218206
C38         0.9582236409187317     0.9582236409187317   0.0029193194483780344
C28         0.9540600776672363     0.9540600776672363   0.0029066347569807437
C31         0.8845425248146057     0.8845425248146057   0.0026948429211502765
C35         0.8716678619384766     0.8716678619384766   0.0026556190363277747
---         ---                    ---                  ---
C423        0.21172353625297546    0.21172353625297546  0.0006450358879374633
C485        0.2102394849061966     0.2102394849061966   0.0006405145843773786
C336        0.20819737017154694    0.20819737017154694  0.0006342930876347537
C662        0.19661597907543182    0.19661597907543182  0.0005990092782792
C721        0.18307651579380035    0.18307651579380035  0.0005577600157993367

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_95

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  --------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.005628884525921124   0.005897309631109238   0.0         0.02598577526244899    0.093252032995224   0.03781869241283365   0.1802825927734375
    3        2        Softmax                      0.0   0.0   0.0002646200507570029  5.095498636364937e-05  0.0         -0.023164751575677656  0.5846922397613525  0.000327791425761656  0.026353180408477783


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.024808272713526154
RMSE: 0.15750642118188754
LogLoss: 0.10762108288702046
Mean Per-Class Error: 0.024227279298971727
AUC: 0.9934463098853668
pr_auc: 0.7046933492601114
Gini: 0.9868926197707335
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5379190700137076: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4837  115   0.0232   (115.0/4952.0)
1      128   4945  0.0252   (128.0/5073.0)
Total  4965  5060  0.0242   (243.0/10025.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.537919     0.976019  187
max f2                       0.438555     0.980527  211
max f0point5                 0.651754     0.978518  161
max accuracy                 0.537919     0.975761  187
max precision                0.999713     0.998347  1
max recall                   2.96056e-05  1         399
max specificity              0.999984     0.999394  0
max absolute_mcc             0.537919     0.951519  187
max min_per_class_accuracy   0.527906     0.975565  189
max mean_per_class_accuracy  0.537919     0.975773  187
Gains/Lift Table: Avg response rate: 50.60 %, avg score: 51.23 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100748                   1                  1.97615     1.97615            1                1            1                           1                   0.0199093       0.0199093                  97.6148   97.6148
    2        0.0200499                   1                  1.97615     1.97615            1                1            1                           1                   0.0197122       0.0396215                  97.6148   97.6148
    3        0.0300249                   1                  1.97615     1.97615            1                1            1                           1                   0.0197122       0.0593337                  97.6148   97.6148
    4        0.04                        1                  1.97615     1.97615            1                1            1                           1                   0.0197122       0.0790459                  97.6148   97.6148
    5        0.0500748                   1                  1.97615     1.97615            1                1            1                           1                   0.0199093       0.0989553                  97.6148   97.6148
    6        0.10005                     0.999992           1.96826     1.97221            0.996008         0.999998     0.998006                    0.999999            0.0983639       0.197319                   96.8259   97.2208
    7        0.150025                    0.999868           1.9722      1.97221            0.998004         0.99995      0.998005                    0.999983            0.098561        0.29588                    97.2204   97.2206
    8        0.2                         0.99902            1.9722      1.97221            0.998004         0.99954      0.998005                    0.999872            0.098561        0.394441                   97.2204   97.2206
    9        0.30005                     0.986631           1.96433     1.96958            0.994018         0.994693     0.996676                    0.998145            0.196531        0.590972                   96.4327   96.9579
    10       0.4                         0.926473           1.94854     1.96432            0.986028         0.964081     0.994015                    0.989634            0.194757        0.785728                   94.8537   96.4321
    11       0.50005                     0.596782           1.83035     1.93752            0.926221         0.815876     0.980451                    0.954868            0.183126        0.968855                   83.0351   93.7516
    12       0.6                         0.117148           0.254414    1.65714            0.128743         0.282074     0.83857                     0.842792            0.0254287       0.994283                   -74.5586  65.7139
    13       0.69995                     0.0205247          0.0295831   1.42473            0.0149701        0.0579596    0.720963                    0.730721            0.00295683      0.99724                    -97.0417  42.4731
    14       0.8                         0.00121614         0.0157619   1.24852            0.00797607       0.00783857   0.631796                    0.640315            0.00157698      0.998817                   -98.4238  24.8522
    15       0.89995                     3.94318e-06        0.00788882  1.11073            0.00399202       0.000246508  0.56207                     0.569228            0.000788488     0.999606                   -99.2111  11.0735
    16       1                           5.5048e-41         0.00394048  1                  0.00199402       4.3303e-07   0.506035                    0.512277            0.000394244     1                          -99.606   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.025123660714540193
RMSE: 0.1585044501411244
LogLoss: 0.10648876017928367
Mean Per-Class Error: 0.02314797145347225
AUC: 0.9934842479065292
pr_auc: 0.6891252554830736
Gini: 0.9869684958130585
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5484201687584048: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3055  73    0.0233   (73.0/3128.0)
1      70    2979  0.023    (70.0/3049.0)
Total  3125  3052  0.0232   (143.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.54842      0.976561  183
max f2                       0.442848     0.98107   208
max f0point5                 0.632819     0.978369  165
max accuracy                 0.54842      0.97685   183
max precision                0.998849     0.996951  3
max recall                   0.000324897  1         398
max specificity              0.999982     0.999041  0
max absolute_mcc             0.54842      0.953693  183
max min_per_class_accuracy   0.54842      0.976662  183
max mean_per_class_accuracy  0.54842      0.976852  183
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.27 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999991           2.0128      2.01935            0.993528         0.999998     0.996764                    0.999999            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999835           2.01935     2.01935            0.996764         0.999948     0.996764                    0.999982            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.998983           2.01935     2.01935            0.996764         0.999502     0.996764                    0.999862            0.101017        0.404067                   101.935   101.935
    9        0.299984                    0.985458           2.00949     2.01607            0.991896         0.994307     0.995143                    0.998012            0.200722        0.604788                   100.949   101.607
    10       0.400032                    0.915348           1.98002     2.00705            0.977346         0.95858      0.990692                    0.98815             0.198098        0.802886                   98.0016   100.705
    11       0.500081                    0.486286           1.78988     1.9636             0.883495         0.774398     0.969246                    0.945386            0.179075        0.981961                   78.9882   96.3605
    12       0.599968                    0.104728           0.144473    1.66074            0.0713128        0.238332     0.819752                    0.827671            0.014431        0.996392                   -85.5527  66.0743
    13       0.700016                    0.0208749          0.0229472   1.42666            0.0113269        0.0534836    0.704209                    0.717021            0.00229583      0.998688                   -97.7053  42.6664
    14       0.799903                    0.00106469         0.00985045  1.24974            0.00486224       0.007485     0.616879                    0.628419            0.000983929     0.999672                   -99.015   24.9742
    15       0.899951                    4.94826e-06        0.00327817  1.11117            0.00161812       0.000241017  0.54848                     0.558584            0.000327976     1                          -99.6722  11.1171
    16       1                           5.5048e-41         0           1                  0                5.03716e-07  0.493605                    0.502698            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:49:53  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:49:56  1:43:13.994  8500 obs/sec      1         1             25000      0.30494          0.375227            0.627992       0.941543        0.716409           1.97615          0.118803                         0.296497           0.345799              0.648301         0.946973          0.690283             2.02591            0.113809
    2019-08-03 17:50:02  1:43:19.775  8996 obs/sec      3         3             75000      0.245362         0.223848            0.759156       0.972174        0.767163           1.97615          0.0739152                        0.241794           0.213708              0.766104         0.974247          0.775234             2.02591            0.0746317
    2019-08-03 17:50:08  1:43:25.303  9277 obs/sec      5         5             125000     0.208464         0.1686              0.826145       0.984183        0.771291           1.97615          0.0477805                        0.208279           0.165941              0.826451         0.984256          0.76684              2.02591            0.0458151
    2019-08-03 17:50:13  1:43:30.653  9506 obs/sec      7         7             175000     0.184292         0.139625            0.864127       0.989818        0.749496           1.97615          0.034015                         0.185099           0.136982              0.862931         0.990089          0.751344             2.02591            0.0349684
    2019-08-03 17:50:18  1:43:35.941  9650 obs/sec      9         9             225000     0.171401         0.128872            0.88247        0.990726        0.707713           1.97615          0.0297257                        0.166971           0.122437              0.888464         0.991812          0.670639             2.02591            0.0259025
    2019-08-03 17:50:21  1:43:38.643  9753 obs/sec      10        10            250000     0.157506         0.107621            0.900752       0.993446        0.704693           1.97615          0.0242394                        0.158504           0.106489              0.899489         0.993484          0.689125             2.02591            0.0231504
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003237836391003667
C35         0.9742009043693542     0.9742009043693542   0.0031543031403157783
C28         0.9555681943893433     0.9555681943893433   0.0030939734738794815
C38         0.8663547039031982     0.8663547039031982   0.0028051147878149817
C34         0.8490450978279114     0.8490450978279114   0.00274906911535048
---         ---                    ---                  ---
C721        0.19486942887306213    0.19486942887306213  0.0006309553282993013
C604        0.19301006197929382    0.19301006197929382  0.0006249350025064308
C588        0.19231027364730835    0.19231027364730835  0.0006226692023791285
C985        0.19127576053142548    0.19127576053142548  0.0006193196181655523
C887        0.18046827614307404    0.18046827614307404  0.000584326751917744

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_74

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0047463092166072805   0.008559241890907288   0.0         0.025560882433302512  0.08582371473312378  0.04322135630467847     0.17610019445419312
    3        2        Softmax                      0.0   0.0   0.00020165154802498364  6.143530481494963e-05  0.0         -0.08110058152669808  0.4849294424057007   -0.0007129998335767135  0.09702479839324951


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.024389302057867643
RMSE: 0.1561707464855939
LogLoss: 0.10887943217790749
Mean Per-Class Error: 0.02262694319970182
AUC: 0.9933606730407175
pr_auc: 0.6648092299389387
Gini: 0.986721346081435
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5279334958923501: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4909  124   0.0246   (124.0/5033.0)
1      103   4893  0.0206   (103.0/4996.0)
Total  5012  5017  0.0226   (227.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.527933     0.977329  195
max f2                       0.459002     0.979856  211
max f0point5                 0.606226     0.979346  174
max accuracy                 0.527933     0.977366  195
max precision                0.999959     0.999392  0
max recall                   1.97507e-05  1         399
max specificity              0.999959     0.999801  0
max absolute_mcc             0.527933     0.95474   195
max min_per_class_accuracy   0.541293     0.975959  192
max mean_per_class_accuracy  0.527933     0.977373  195
Gains/Lift Table: Avg response rate: 49.82 %, avg score: 49.93 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   1                  2.00741     2.00741            1                1            1                           1                   0.0202162       0.0202162                  100.741   100.741
    2        0.0200419                   1                  2.00741     2.00741            1                1            1                           1                   0.020016        0.0402322                  100.741   100.741
    3        0.030013                    1                  2.00741     2.00741            1                1            1                           1                   0.020016        0.0602482                  100.741   100.741
    4        0.0400838                   1                  2.00741     2.00741            1                1            1                           1                   0.0202162       0.0804644                  100.741   100.741
    5        0.0500548                   1                  2.00741     2.00741            1                1            1                           1                   0.020016        0.10048                    100.741   100.741
    6        0.10001                     0.999992           2.0034      2.0054             0.998004         0.999998     0.999003                    0.999999            0.10008         0.20056                    100.34    100.54
    7        0.150065                    0.999817           2.00741     2.00607            1                0.999938     0.999336                    0.999979            0.10048         0.301041                   100.741   100.607
    8        0.20002                     0.998739           1.99939     2.0044             0.996008         0.999414     0.998504                    0.999838            0.0998799       0.400921                   99.9392   100.44
    9        0.30003                     0.984232           1.9974      2.00207            0.995015         0.99356      0.997341                    0.997745            0.19976         0.600681                   99.7399   100.207
    10       0.40004                     0.910189           1.97138     1.9944             0.982054         0.955556     0.993519                    0.987198            0.197158        0.797838                   97.1381   99.4397
    11       0.50005                     0.528607           1.81327     1.95817            0.90329          0.776257     0.975474                    0.94501             0.181345        0.979183                   81.327    95.8171
    12       0.59996                     0.0805941          0.150255    1.6571             0.0748503        0.227606     0.825494                    0.825542            0.015012        0.994195                   -84.9745  65.7102
    13       0.69997                     0.0103004          0.0280196   1.42434            0.0139581        0.0367926    0.709544                    0.712847            0.00280224      0.996998                   -97.198   42.4343
    14       0.79998                     0.000278778        0.0120084   1.24778            0.00598205       0.00313117   0.621588                    0.624122            0.00120096      0.998199                   -98.7992  24.7779
    15       0.89999                     3.66053e-07        0.0120084   1.11046            0.00598205       5.32444e-05  0.55318                     0.554773            0.00120096      0.9994                     -98.7992  11.0456
    16       1                           1.50497e-46        0.00600421  1                  0.00299103       3.22475e-08  0.498155                    0.49929             0.00060048      1                          -99.3996  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.023253068255362563
RMSE: 0.1524895676935395
LogLoss: 0.10659132470883753
Mean Per-Class Error: 0.020216892209847792
AUC: 0.99386695692437
pr_auc: 0.7147392902574842
Gini: 0.98773391384874
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5350328137151442: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3060  68    0.0217   (68.0/3128.0)
1      57    2992  0.0187   (57.0/3049.0)
Total  3117  3060  0.0202   (125.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.535033     0.979538  198
max f2                       0.47501      0.982014  210
max f0point5                 0.599147     0.981221  180
max accuracy                 0.537745     0.979764  197
max precision                0.998172     0.997796  5
max recall                   1.13242e-05  1         399
max specificity              0.99999      0.999361  0
max absolute_mcc             0.535033     0.959529  198
max min_per_class_accuracy   0.544135     0.97922   195
max mean_per_class_accuracy  0.535033     0.979783  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.65 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999993           2.0128      2.01935            0.993528         0.999998     0.996764                    0.999999            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999841           2.01935     2.01935            0.996764         0.999944     0.996764                    0.999981            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.99884            2.02591     2.02099            1                0.999476     0.997573                    0.999855            0.101345        0.404395                   102.591   102.099
    9        0.299984                    0.98387            2.00621     2.01607            0.990276         0.99398      0.995143                    0.997899            0.200394        0.604788                   100.621   101.607
    10       0.400032                    0.90605            2.00624     2.01361            0.990291         0.953546     0.99393                     0.986806            0.200722        0.80551                    100.624   101.361
    11       0.500081                    0.483202           1.7866      1.9682             0.881877         0.758444     0.971512                    0.941119            0.178747        0.984257                   78.6604   96.8196
    12       0.599968                    0.0828904          0.111638    1.6591             0.0551053        0.215247     0.818942                    0.820271            0.0111512       0.995408                   -88.8362  65.9103
    13       0.700016                    0.0112886          0.0229472   1.42526            0.0113269        0.0404813    0.703515                    0.708821            0.00229583      0.997704                   -97.7053  42.5259
    14       0.799903                    0.00028215         0.00985045  1.24851            0.00486224       0.00355794   0.616272                    0.620752            0.000983929     0.998688                   -99.015   24.8512
    15       0.899951                    4.09284e-07        0.00655634  1.11044            0.00323625       6.18765e-05  0.54812                     0.551749            0.000655953     0.999344                   -99.3444  11.0442
    16       1                           1.1883e-44         0.00655634  1                  0.00323625       3.73783e-08  0.493605                    0.496548            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:28:02  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:28:05  1:21:22.799  8311 obs/sec      1         1             25000      0.307775         0.431086            0.621093       0.941499        0.630182           2.00741          0.12065                          0.299328           0.402365              0.641551         0.945545          0.642104             1.99323            0.114133
    2019-08-03 17:28:11  1:21:28.653  8842 obs/sec      3         3             75000      0.244557         0.23241             0.760763       0.972072        0.697367           2.00741          0.074484                         0.239848           0.22296               0.769854         0.97369           0.734299             2.02591            0.0699369
    2019-08-03 17:28:17  1:21:34.423  9008 obs/sec      5         5             125000     0.208167         0.175223            0.826664       0.983403        0.687965           2.00741          0.0502543                        0.210371           0.176767              0.822946         0.98307           0.717239             2.02591            0.0482435
    2019-08-03 17:28:22  1:21:39.943  9198 obs/sec      7         7             175000     0.182222         0.139517            0.867179       0.989045        0.738615           2.00741          0.0326054                        0.181637           0.138514              0.86801          0.989374          0.702204             2.02591            0.0323782
    2019-08-03 17:28:27  1:21:45.098  9454 obs/sec      9         9             225000     0.166806         0.121139            0.888702       0.991947        0.687575           2.00741          0.0278193                        0.16689            0.120079              0.888572         0.991925          0.698022             2.02591            0.0262263
    2019-08-03 17:28:30  1:21:48.026  9508 obs/sec      10        10            250000     0.156171         0.108879            0.902441       0.993361        0.664809           2.00741          0.0226344                        0.15249            0.106591              0.906973         0.993867          0.714739             2.02591            0.0202364
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003328496086284457
C35         0.8658167123794556     0.8658167123794556   0.002881867538594693
C27         0.859216570854187      0.859216570854187    0.002859898993358913
C28         0.8453885912895203     0.8453885912895203   0.0028138726174966986
C38         0.8370922207832336     0.8370922207832336   0.0027862581807361576
---         ---                    ---                  ---
C423        0.19424818456172943    0.19424818456172943  0.0006465543220815773
C437        0.1928301453590393     0.1928301453590393   0.0006418343841452253
C403        0.18732261657714844    0.18732261657714844  0.0006235025961496025
C443        0.17825181782245636    0.17825181782245636  0.000593310477995136
C264        0.1725481003522873     0.1725481003522873   0.0005743256767184059

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_202

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 255,278 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.08812789019166488   0.1516830325126648      0.0         0.0015669463716117293  0.0998501181602478  -0.010009627255694174  0.14318156242370605
    3        2        Softmax                 0.0   0.0   0.001757273044631802  4.5782464439980686e-05  0.0         0.046511175342402566   0.2576409578323364  0.002377565649121033   0.295005202293396


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.031597605449590276
RMSE: 0.17775715301947845
LogLoss: 0.11501034687383796
Mean Per-Class Error: 0.03829088150750559
AUC: 0.9913306251996168
pr_auc: 0.8943644010669144
Gini: 0.9826612503992336
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.552771136606553: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4754  206   0.0415   (206.0/4960.0)
1      177   4873  0.035    (177.0/5050.0)
Total  4931  5079  0.0383   (383.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.552771     0.962188  189
max f2                       0.254494     0.968806  266
max f0point5                 0.79603      0.967104  123
max accuracy                 0.552771     0.961738  189
max precision                0.999853     1         0
max recall                   9.92558e-05  1         399
max specificity              0.999853     1         0
max absolute_mcc             0.552771     0.923482  189
max min_per_class_accuracy   0.585495     0.96      181
max mean_per_class_accuracy  0.552771     0.961709  189
Gains/Lift Table: Avg response rate: 50.45 %, avg score: 51.21 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   0.99994            1.98218     1.98218            1                0.999965     1                           0.999965            0.02            0.02                       98.2178   98.2178
    2        0.0200799                   0.999886           1.98218     1.98218            1                0.999917     1                           0.999941            0.019802        0.039802                   98.2178   98.2178
    3        0.0300699                   0.999822           1.98218     1.98218            1                0.999852     1                           0.999912            0.019802        0.059604                   98.2178   98.2178
    4        0.0400599                   0.999759           1.98218     1.98218            1                0.999793     1                           0.999882            0.019802        0.0794059                  98.2178   98.2178
    5        0.05005                     0.999678           1.98218     1.98218            1                0.99972      1                           0.99985             0.019802        0.0992079                  98.2178   98.2178
    6        0.1                         0.99915            1.97425     1.97822            0.996            0.999434     0.998002                    0.999642            0.0986139       0.197822                   97.425    97.8218
    7        0.15005                     0.998316           1.98218     1.97954            1                0.998752     0.998668                    0.999345            0.0992079       0.29703                    98.2178   97.9539
    8        0.2                         0.996866           1.97821     1.97921            0.998            0.99766      0.998501                    0.998924            0.0988119       0.395842                   97.8214   97.9208
    9        0.3                         0.990079           1.97624     1.97822            0.997003         0.994174     0.998002                    0.997341            0.197624        0.593465                   97.6238   97.8218
    10       0.4                         0.959673           1.93861     1.96832            0.978022         0.978838     0.993007                    0.992715            0.193861        0.787327                   93.8614   96.8317
    11       0.5                         0.619255           1.68119     1.91089            0.848152         0.867275     0.964036                    0.967627            0.168119        0.955446                   68.1188   91.0891
    12       0.6                         0.0597233          0.382178    1.65611            0.192807         0.249009     0.835498                    0.847857            0.0382178       0.993663                   -61.7822  65.6106
    13       0.7                         0.0102341          0.0376238   1.42489            0.018981         0.0276788    0.718853                    0.730689            0.00376238      0.997426                   -96.2376  42.4894
    14       0.8                         0.00219636         0.0158416   1.24876            0.00799201       0.0051839    0.629995                    0.640001            0.00158416      0.99901                    -98.4158  24.8762
    15       0.9                         0.000401403        0.00594059  1.11067            0.002997         0.00111262   0.560329                    0.569013            0.000594059     0.999604                   -99.4059  11.0671
    16       1                           1.3049e-06         0.0039604   1                  0.001998         0.000152268  0.504496                    0.512127            0.00039604      1                          -99.604   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02967947326335637
RMSE: 0.17227731499926613
LogLoss: 0.1071986638667106
Mean Per-Class Error: 0.03670347243949845
AUC: 0.9925678957253186
pr_auc: 0.8935050329904544
Gini: 0.9851357914506371
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5510036917291061: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3002  126   0.0403   (126.0/3128.0)
1      101   2948  0.0331   (101.0/3049.0)
Total  3103  3074  0.0367   (227.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.551004     0.962927  189
max f2                       0.207949     0.971569  274
max f0point5                 0.825849     0.968209  114
max accuracy                 0.553568     0.963251  188
max precision                0.998347     0.998959  5
max recall                   0.00451548   1         388
max specificity              0.999843     0.99968   0
max absolute_mcc             0.551004     0.926527  189
max min_per_class_accuracy   0.586918     0.962276  179
max mean_per_class_accuracy  0.551004     0.963297  189
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.20 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999935           2.02591     2.02591            1                0.999963     1                           0.999963            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.99988            2.02591     2.02591            1                0.999908     1                           0.999936            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999817           2.02591     2.02591            1                0.999848     1                           0.999906            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999747           2.02591     2.02591            1                0.999779     1                           0.999875            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999666           2.02591     2.02591            1                0.999707     1                           0.999842            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999141           2.01935     2.02263            0.996764         0.999424     0.998382                    0.999633            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.9983             2.02591     2.02372            1                0.99874      0.998921                    0.999335            0.101345        0.303706                   102.591   102.372
    8        0.200097                    0.99668            2.01935     2.02263            0.996764         0.997551     0.998382                    0.998889            0.101017        0.404723                   101.935   102.263
    9        0.299984                    0.989218           2.01606     2.02044            0.995138         0.993711     0.997302                    0.997165            0.201378        0.6061                     101.606   102.044
    10       0.400032                    0.954702           1.97018     2.00787            0.972492         0.976922     0.991097                    0.992102            0.197114        0.803214                   97.0181   100.787
    11       0.500081                    0.51816            1.6522      1.93671            0.815534         0.827498     0.955973                    0.95917             0.1653          0.968514                   65.2199   93.6715
    12       0.599968                    0.0539383          0.272529    1.65965            0.134522         0.19319      0.819212                    0.831645            0.027222        0.995736                   -72.7471  65.965
    13       0.700016                    0.0100028          0.0327817   1.42713            0.0161812        0.0244951    0.70444                     0.716284            0.00327976      0.999016                   -96.7218  42.7133
    14       0.799903                    0.00210548         0.00985045  1.25015            0.00486224       0.00513353   0.617082                    0.62748             0.000983929     1                          -99.015   25.0152
    15       0.899951                    0.000396073        0           1.11117            0                0.00105456   0.54848                     0.55784             0               1                          -100      11.1171
    16       1                           1.3049e-06         0           1                  0                0.000149253  0.493605                    0.502044            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:11:46  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:11:53  4:05:11.964  1275 obs/sec      0.35252   1             8813       0.330256         0.383806            0.563689       0.928038        0.823946           1.96255          0.146454                         0.324829           0.367539              0.577874         0.932201          0.835962             1.99323            0.139874
    2019-08-03 20:12:09  4:05:27.061  1251 obs/sec      1.04892   3             26223      0.307384         0.310056            0.622029       0.942114        0.920161           1.98218          0.129471                         0.305543           0.305216              0.626513         0.943947          0.921927             2.02591            0.129836
    2019-08-03 20:12:24  4:05:42.567  1240 obs/sec      1.7524    5             43810      0.293212         0.290449            0.65608        0.950681        0.923683           1.98218          0.116384                         0.288817           0.27944               0.666285         0.954465          0.938892             2.02591            0.112028
    2019-08-03 20:12:39  4:05:57.647  1243 obs/sec      2.45636   7             61409      0.28379          0.272655            0.677826       0.955032        0.933512           1.96255          0.106793                         0.277434           0.259564              0.692072         0.959026          0.942839             2.02591            0.100372
    2019-08-03 20:12:56  4:06:14.501  1215 obs/sec      3.15948   9             78987      0.290386         0.281181            0.662677       0.952102        0.936242           1.98218          0.115385                         0.285131           0.267932              0.674749         0.956788          0.94555              2.02591            0.112676
    2019-08-03 20:13:11  4:06:30.027  1219 obs/sec      3.86948   11            96737      0.273283         0.252555            0.701242       0.960654        0.940732           1.98218          0.101299                         0.269591           0.243035              0.709236         0.963854          0.942965             2.02591            0.0998867
    2019-08-03 20:13:27  4:06:45.561  1221 obs/sec      4.57784   13            114446     0.269363         0.247144            0.70975        0.963247        0.943968           1.96255          0.0967033                        0.266554           0.239208              0.71575          0.96565           0.943857             2.02591            0.0958394
    2019-08-03 20:13:42  4:07:00.929  1224 obs/sec      5.2828    15            132070     0.266997         0.243765            0.714827       0.964324        0.949526           1.98218          0.0912088                        0.260844           0.230437              0.727797         0.968065          0.956671             2.02591            0.0893638
    2019-08-03 20:13:58  4:07:16.136  1226 obs/sec      5.98352   17            149588     0.256032         0.229102            0.73777        0.969449        0.933393           1.98218          0.0854146                        0.24635            0.209494              0.757207         0.97393           0.91918              2.02591            0.078679
    2019-08-03 20:14:13  4:07:31.356  1229 obs/sec      6.694     19            167350     0.236016         0.194183            0.777167       0.97667         0.946389           1.98218          0.0722278                        0.229433           0.182164              0.789407         0.979432          0.957482             2.02591            0.0679942
    2019-08-03 20:14:28  4:07:46.342  1232 obs/sec      7.3928    21            184820     0.221229         0.171789            0.804215       0.981297        0.95013            1.98218          0.0634366                        0.219331           0.168226              0.807545         0.982164          0.958271             2.02591            0.0628137
    2019-08-03 20:14:43  4:08:01.495  1234 obs/sec      8.0946    23            202365     0.214947         0.164666            0.815177       0.982778        0.958189           1.98218          0.0588412                        0.212368           0.158411              0.819569         0.984205          0.962903             2.02591            0.0590902
    2019-08-03 20:14:58  4:08:16.541  1236 obs/sec      8.79556   25            219889     0.205721         0.149851            0.830701       0.985815        0.959497           1.98218          0.0546454                        0.201055           0.142949              0.838281         0.987205          0.959824             2.02591            0.0521289
    2019-08-03 20:15:13  4:08:31.802  1237 obs/sec      9.50332   27            237583     0.195827         0.137563            0.846595       0.987878        0.922257           1.98218          0.0497502                        0.189687           0.128165              0.856052         0.989507          0.92354              2.02591            0.0453294
    2019-08-03 20:15:28  4:08:46.995  1239 obs/sec      10.2111   29            255278     0.177757         0.11501             0.873599       0.991331        0.894364           1.98218          0.0382617                        0.172277           0.107199              0.881263         0.992568          0.893505             2.02591            0.0367492
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003131568202765699
C438        0.8132169246673584     0.8132169246673584   0.0025466442632392085
C374        0.7221664786338806     0.7221664786338806   0.0022615135815931353
C88         0.716115415096283      0.716115415096283    0.0022425642634258795
C79         0.7129594087600708     0.7129594087600708   0.0022326810143356705
---         ---                    ---                  ---
C849        0.22816629707813263    0.22816629707813263  0.0007145183208726724
C727        0.22772139310836792    0.22772139310836792  0.000713125073747673
C982        0.22726662456989288    0.22726662456989288  0.0007117009350529664
C873        0.2264833003282547     0.2264833003282547   0.0007092479017653967
C539        0.22542224824428558    0.22542224824428558  0.0007059251447977607

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_204

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0048014877896040455  0.004850801080465317   0.0         0.025383109032316966    0.08620911836624146  0.030446331663297202   0.2018834948539734
    3        2        Softmax                      0.0   0.0   0.0003189062368846862  6.224881508387625e-05  0.0         -0.0046156841090123635  0.48860907554626465  5.188209402879479e-05  0.06419059634208679


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02457059436985605
RMSE: 0.15675010165820005
LogLoss: 0.11222085908237704
Mean Per-Class Error: 0.02277794952306622
AUC: 0.9929082879627702
pr_auc: 0.6723471162711105
Gini: 0.9858165759255404
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5330130608596039: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4900  108   0.0216   (108.0/5008.0)
1      120   4882  0.024    (120.0/5002.0)
Total  5020  4990  0.0228   (228.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.533013     0.977182  195
max f2                       0.422984     0.979982  224
max f0point5                 0.583218     0.978622  183
max accuracy                 0.536137     0.977223  194
max precision                0.99925      0.996569  2
max recall                   1.66857e-05  1         399
max specificity              0.999975     0.998602  0
max absolute_mcc             0.536137     0.954453  194
max min_per_class_accuracy   0.51905      0.976837  198
max mean_per_class_accuracy  0.533013     0.977222  195
Gains/Lift Table: Avg response rate: 49.97 %, avg score: 50.08 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   1                  2.0012     2.0012             1                1            1                           1                   0.0201919       0.0201919                  100.12    100.12
    2        0.0200799                   1                  1.98119    1.99124            0.99             1            0.995025                    1                   0.0197921       0.039984                   98.1188   99.1243
    3        0.0300699                   1                  2.0012     1.99455            1                1            0.996678                    1                   0.019992        0.059976                   100.12    99.4551
    4        0.0400599                   1                  2.0012     1.99621            1                1            0.997506                    1                   0.019992        0.079968                   100.12    99.6209
    5        0.05005                     1                  1.98119    1.99321            0.99             1            0.996008                    1                   0.0197921       0.0997601                  98.1188   99.3211
    6        0.1                         0.999994           1.98919    1.9912             0.994            0.999999     0.995005                    0.999999            0.0993603       0.19912                    98.9192   99.1204
    7        0.15005                     0.999879           1.99321    1.99187            0.996008         0.999956     0.99534                     0.999985            0.0997601       0.29888                    99.3211   99.1873
    8        0.2                         0.999023           2.0012     1.9942             1                0.999549     0.996503                    0.999876            0.09996         0.39884                    100.12    99.4202
    9        0.3                         0.985217           1.97721    1.98854            0.988012         0.994277     0.993673                    0.99801             0.197721        0.596561                   97.7209   98.8538
    10       0.4                         0.915549           1.97921    1.98621            0.989011         0.957716     0.992507                    0.987936            0.197921        0.794482                   97.9208   98.6206
    11       0.5                         0.514505           1.82727    1.95442            0.913087         0.781952     0.976623                    0.946739            0.182727        0.977209                   82.7269   95.4418
    12       0.6                         0.0857025          0.17593    1.658              0.0879121        0.230987     0.828505                    0.827447            0.017593        0.994802                   -82.407   65.8003
    13       0.7                         0.0122041          0.029988   1.42543            0.014985         0.0389676    0.712288                    0.714807            0.0029988       0.997801                   -97.0012  42.543
    14       0.8                         0.000436137        0.0159936  1.24925            0.00799201       0.00403974   0.624251                    0.625961            0.00159936      0.9994                     -98.4006  24.925
    15       0.9                         7.31349e-07        0.0019992  1.11067            0.000999001      8.01906e-05  0.555001                    0.556419            0.00019992      0.9996                     -99.8001  11.0667
    16       1                           3.24836e-44        0.0039984  1                  0.001998         5.9736e-08   0.4997                      0.500777            0.00039984      1                          -99.6002  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.023624621676562686
RMSE: 0.15370303079823341
LogLoss: 0.10771692653787363
Mean Per-Class Error: 0.0212215295946262
AUC: 0.9933037979833227
pr_auc: 0.6776296607098459
Gini: 0.9866075959666454
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5331832579993777: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3065  63    0.0201   (63.0/3128.0)
1      68    2981  0.0223   (68.0/3049.0)
Total  3133  3044  0.0212   (131.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.533183     0.9785    189
max f2                       0.434387     0.982032  212
max f0point5                 0.582457     0.98023   177
max accuracy                 0.533183     0.978792  189
max precision                0.99998      0.996885  0
max recall                   1.60479e-05  1         399
max specificity              0.99998      0.999041  0
max absolute_mcc             0.533183     0.957578  189
max min_per_class_accuracy   0.51814      0.978354  192
max mean_per_class_accuracy  0.533183     0.978778  189
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.65 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0101991                   1                  2.02591     2.02591            1                1            1                           1                   0.0206625       0.0206625                  102.591   102.591
    2        0.0200745                   1                  1.9927      2.00957            0.983607         1            0.991935                    1                   0.0196786       0.0403411                  99.2698   100.957
    3        0.0301117                   1                  2.02591     2.01502            1                1            0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999994           2.01935     2.01608            0.996764         0.999999     0.995146                    0.999999            0.101017        0.201705                   101.935   101.608
    7        0.150073                    0.999876           2.02591     2.01935            1                0.999958     0.996764                    0.999985            0.101345        0.30305                    102.591   101.935
    8        0.200097                    0.998977           2.0128      2.01771            0.993528         0.99956      0.995955                    0.999879            0.100689        0.403739                   101.28    101.771
    9        0.299984                    0.983515           2.00949     2.01498            0.991896         0.993709     0.994603                    0.997824            0.200722        0.60446                    100.949   101.498
    10       0.400032                    0.912146           1.9669      2.00295            0.970874         0.955501     0.988669                    0.987239            0.196786        0.801246                   96.6903   100.295
    11       0.500081                    0.460109           1.82594     1.96754            0.901294         0.762379     0.971188                    0.942253            0.182683        0.983929                   82.5942   96.754
    12       0.599968                    0.0820812          0.124772    1.66074            0.0615883        0.210172     0.819752                    0.820371            0.0124631       0.996392                   -87.5228  66.0743
    13       0.700016                    0.0121801          0.019669    1.4262             0.00970874       0.038819     0.703978                    0.708669            0.00196786      0.99836                    -98.0331  42.6196
    14       0.799903                    0.000438976        0.0131339   1.24974            0.00648298       0.00409956   0.616879                    0.620687            0.00131191      0.999672                   -98.6866  24.9742
    15       0.899951                    9.05493e-07        0.00327817  1.11117            0.00161812       9.15984e-05  0.54848                     0.551695            0.000327976     1                          -99.6722  11.1171
    16       1                           1.42933e-40        0           1                  0                9.08362e-08  0.493605                    0.496498            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:16:25  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:16:28  4:09:45.575  8799 obs/sec      1         1             25000      0.322979         0.517701            0.582738       0.927593        0.584304           1.94662          0.132168                         0.315489           0.487422              0.601802         0.932628          0.603647             1.96803            0.123685
    2019-08-03 20:16:34  4:09:51.394  9059 obs/sec      3         3             75000      0.246903         0.259013            0.756155       0.96858         0.663493           1.98139          0.0751249                        0.240275           0.23439               0.769035         0.972428          0.66926              1.99323            0.0709082
    2019-08-03 20:16:39  4:09:56.922  9313 obs/sec      5         5             125000     0.212179         0.189312            0.81992        0.981132        0.761136           2.0012           0.0516484                        0.202888           0.172202              0.835318         0.984153          0.759906             2.02591            0.0450057
    2019-08-03 20:16:45  4:10:02.424  9421 obs/sec      7         7             175000     0.184299         0.144006            0.864135       0.988619        0.742226           2.0012           0.0348651                        0.178317           0.133104              0.872792         0.990428          0.75975              2.02591            0.0323782
    2019-08-03 20:16:50  4:10:07.670  9601 obs/sec      9         9             225000     0.166465         0.124641            0.889157       0.99096         0.637634           2.0012           0.0271728                        0.160474           0.112335              0.896975         0.992846          0.677747             2.02591            0.0242836
    2019-08-03 20:16:53  4:10:10.599  9634 obs/sec      10        10            250000     0.15675          0.112221            0.901718       0.992908        0.672347           2.0012           0.0227772                        0.153703           0.107717              0.905486         0.993304          0.67763              2.02591            0.0212077
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.0032506798976881177
C36         0.9945431351661682     0.9945431351661682   0.0032329413768683794
C28         0.8823716640472412     0.8823716640472412   0.00286830783060798
C34         0.877906322479248      0.877906322479248    0.0028537924345365937
C25         0.8485972285270691     0.8485972285270691   0.002758517952006793
---         ---                    ---                  ---
C539        0.20231100916862488    0.20231100916862488  0.0006576483305854453
C626        0.20152240991592407    0.20152240991592407  0.000655084846847359
C478        0.20097222924232483    0.20097222924232483  0.0006532963855915934
C215        0.20047715306282043    0.20047715306282043  0.0006516870514070543
C850        0.1804760992527008     0.1804760992527008   0.00058667002785392

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_122

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 257,146 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.08510876492709905    0.14459943771362305     0.0         -0.0010060140700829622  0.10016223788261414  0.008366404336647305  0.12593257427215576
    3        2        Softmax                 0.0   0.0   0.0017080131619877648  2.2279360564425588e-05  0.0         0.020884982918790485    0.26350975036621094  -0.00097857341878263  0.34965765476226807


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03176617721687578
RMSE: 0.1782306853964148
LogLoss: 0.11835492958758087
Mean Per-Class Error: 0.03999245337485646
AUC: 0.9904677258706339
pr_auc: 0.910864157452898
Gini: 0.9809354517412678
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4512556406424988: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4716  248   0.05     (248.0/4964.0)
1      152   4906  0.0301   (152.0/5058.0)
Total  4868  5154  0.0399   (400.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.451256     0.96083   209
max f2                       0.284802     0.970881  252
max f0point5                 0.759716     0.966215  132
max accuracy                 0.468816     0.960088  205
max precision                0.999809     1         0
max recall                   0.00011841   1         399
max specificity              0.999809     1         0
max absolute_mcc             0.451256     0.920323  209
max min_per_class_accuracy   0.549196     0.958877  186
max mean_per_class_accuracy  0.468816     0.960008  205
Gains/Lift Table: Avg response rate: 50.47 %, avg score: 50.79 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   0.9999             1.98142     1.98142            1                0.99994      1                           0.99994             0.0199684       0.0199684                  98.1416   98.1416
    2        0.0200559                   0.999818           1.98142     1.98142            1                0.999858     1                           0.999899            0.0197707       0.039739                   98.1416   98.1416
    3        0.0300339                   0.999726           1.98142     1.98142            1                0.999773     1                           0.999857            0.0197707       0.0595097                  98.1416   98.1416
    4        0.040012                    0.999638           1.98142     1.98142            1                0.999682     1                           0.999814            0.0197707       0.0792803                  98.1416   98.1416
    5        0.0500898                   0.999525           1.98142     1.98142            1                0.999582     1                           0.999767            0.0199684       0.0992487                  98.1416   98.1416
    6        0.10008                     0.998713           1.98142     1.98142            1                0.999148     1                           0.999458            0.099051        0.1983                     98.1416   98.1416
    7        0.15007                     0.997588           1.96955     1.97746            0.994012         0.998213     0.998005                    0.999043            0.0984579       0.296758                   96.9551   97.7463
    8        0.20006                     0.995355           1.97746     1.97746            0.998004         0.996567     0.998005                    0.998424            0.0988533       0.395611                   97.7461   97.7463
    9        0.30004                     0.985726           1.96164     1.97219            0.99002          0.991365     0.995344                    0.996072            0.196125        0.591736                   96.1641   97.219
    10       0.40002                     0.945377           1.94384     1.96511            0.981038         0.97098      0.991769                    0.9898              0.194346        0.786081                   94.3844   96.5106
    11       0.5                         0.585924           1.67293     1.90668            0.844311         0.834039     0.962283                    0.958654            0.16726         0.953341                   67.2932   90.6682
    12       0.59998                     0.0712033          0.39747     1.65519            0.200599         0.242288     0.835357                    0.83928             0.039739        0.99308                    -60.253   65.5189
    13       0.69996                     0.0141895          0.0435041   1.42498            0.0219561        0.0342094    0.719173                    0.724286            0.00434955      0.99743                    -95.6496  42.4981
    14       0.79994                     0.00345863         0.0118648   1.24836            0.00598802       0.00747059   0.630036                    0.634695            0.00118624      0.998616                   -98.8135  24.8363
    15       0.89992                     0.00073533         0.00790984  1.11055            0.00399202       0.0017986    0.560483                    0.564381            0.000790826     0.999407                   -99.209   11.0551
    16       1                           2.02028e-06        0.00592647  1                  0.00299103       0.000291472  0.50469                     0.507927            0.00059312      1                          -99.4074  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02815595702052362
RMSE: 0.16779736893206526
LogLoss: 0.10778046816097198
Mean Per-Class Error: 0.03295659387715899
AUC: 0.9918296343021358
pr_auc: 0.9308981719284399
Gini: 0.9836592686042716
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4996913564858462: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3008  120   0.0384   (120.0/3128.0)
1      84    2965  0.0276   (84.0/3049.0)
Total  3092  3085  0.033    (204.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.499691     0.966743  202
max f2                       0.364474     0.973561  231
max f0point5                 0.730785     0.970266  142
max accuracy                 0.499691     0.966974  202
max precision                0.999836     1         0
max recall                   0.000806773  1         396
max specificity              0.999836     1         0
max absolute_mcc             0.499691     0.934011  202
max min_per_class_accuracy   0.553698     0.965473  191
max mean_per_class_accuracy  0.499691     0.967043  202
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.74 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.9999             2.02591     2.02591            1                0.999946     1                           0.999946            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999802           2.02591     2.02591            1                0.999854     1                           0.9999              0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999701           2.02591     2.02591            1                0.999754     1                           0.999851            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999588           2.02591     2.02591            1                0.999643     1                           0.999799            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999443           2.02591     2.02591            1                0.999514     1                           0.999743            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.998601           2.02591     2.02591            1                0.99904      1                           0.999391            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.997284           2.00624     2.01935            0.990291         0.998049     0.996764                    0.998944            0.100361        0.30305                    100.624   101.935
    8        0.200097                    0.995005           2.01935     2.01935            0.996764         0.996319     0.996764                    0.998288            0.101017        0.404067                   101.935   101.935
    9        0.299984                    0.984386           2.01606     2.01826            0.995138         0.990592     0.996222                    0.995725            0.201378        0.605444                   101.606   101.826
    10       0.400032                    0.941239           1.97346     2.00705            0.97411          0.969365     0.990692                    0.989133            0.197442        0.802886                   97.3459   100.705
    11       0.500081                    0.485579           1.69809     1.94524            0.838188         0.802808     0.960181                    0.951856            0.169892        0.972778                   69.8093   94.5241
    12       0.599968                    0.053861           0.223277    1.65856            0.110211         0.179506     0.818672                    0.82327             0.0223024       0.99508                    -77.6723  65.8557
    13       0.700016                    0.0117945          0.0262254   1.42526            0.012945         0.026597     0.703515                    0.709407            0.00262381      0.997704                   -97.3775  42.5259
    14       0.799903                    0.00300879         0.0131339   1.24892            0.00648298       0.00656608   0.616474                    0.62164             0.00131191      0.999016                   -98.6866  24.8922
    15       0.899951                    0.000631998        0.00983452  1.11117            0.00485437       0.00153743   0.54848                     0.552703            0.000983929     1                          -99.0165  11.1171
    16       1                           4.48243e-06        0           1                  0                0.000269548  0.493605                    0.497433            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:25:07  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:25:14  2:18:32.513  1271 obs/sec      0.34216   1             8554       0.339609         0.416362            0.538622       0.922669        0.8131             1.94218          0.153363                         0.327655           0.382821              0.570498         0.9311            0.817868             2.02591            0.142302
    2019-08-03 18:25:29  2:18:47.366  1252 obs/sec      1.0254    3             25635      0.298517         0.297133            0.643519       0.946863        0.921743           1.9618           0.120136                         0.289981           0.278539              0.663588         0.952918          0.921896             2.02591            0.113
    2019-08-03 18:25:44  2:19:02.267  1244 obs/sec      1.70664   5             42666      0.291167         0.281775            0.660857       0.951534        0.929578           1.98142          0.117541                         0.285168           0.269232              0.674664         0.955686          0.929011             2.02591            0.111381
    2019-08-03 18:25:59  2:19:17.428  1235 obs/sec      2.39056   7             59764      0.28689          0.275111            0.670747       0.953591        0.939964           1.98142          0.10916                          0.278351           0.260305              0.690032         0.958377          0.938792             2.02591            0.101344
    2019-08-03 18:26:14  2:19:32.566  1231 obs/sec      3.0746    9             76865      0.287676         0.276326            0.668941       0.954336        0.944004           1.98142          0.112852                         0.280755           0.263492              0.684656         0.958517          0.929356             2.02591            0.104258
    2019-08-03 18:26:29  2:19:47.520  1233 obs/sec      3.76248   11            94062      0.278007         0.259105            0.690822       0.958761        0.946667           1.98142          0.102175                         0.267323           0.241308              0.714106         0.964151          0.951001             2.02591            0.0937348
    2019-08-03 18:26:45  2:20:03.664  1222 obs/sec      4.4482    13            111205     0.273527         0.25271             0.700707       0.960799        0.951965           1.98142          0.100479                         0.2635             0.235424              0.722225         0.966433          0.955915             2.02591            0.0921159
    2019-08-03 18:27:00  2:20:18.631  1225 obs/sec      5.13532   15            128383     0.266131         0.240869            0.716673       0.964423        0.947615           1.9618           0.0960886                        0.259728           0.227466              0.730122         0.968321          0.954734             1.99323            0.0917921
    2019-08-03 18:27:15  2:20:33.742  1225 obs/sec      5.8206    17            145515     0.25687          0.227442            0.736047       0.968564        0.939969           1.98142          0.0882059                        0.248999           0.213258              0.751958         0.972267          0.939619             2.02591            0.0802979
    2019-08-03 18:27:30  2:20:48.696  1227 obs/sec      6.50652   19            162663     0.252325         0.216656            0.745305       0.971412        0.9379             1.98142          0.0838156                        0.241266           0.198839              0.767125         0.975961          0.954108             2.02591            0.0781933
    2019-08-03 18:27:45  2:21:03.745  1227 obs/sec      7.19492   21            179873     0.242949         0.204069            0.763882       0.974128        0.946197           1.98142          0.0776292                        0.235547           0.191756              0.778033         0.977085          0.955405             2.02591            0.0707463
    2019-08-03 18:28:00  2:21:18.637  1229 obs/sec      7.88136   23            197034     0.22932          0.1839              0.789631       0.978888        0.957433           1.9618           0.0679505                        0.220999           0.170594              0.804605         0.981906          0.963827             2.02591            0.0628137
    2019-08-03 18:28:15  2:21:33.515  1230 obs/sec      8.57096   25            214274     0.217479         0.165764            0.810795       0.983305        0.938956           1.98142          0.0591698                        0.209157           0.153013              0.824985         0.985702          0.935962             2.02591            0.0553667
    2019-08-03 18:28:30  2:21:48.742  1230 obs/sec      9.26048   27            231512     0.197479         0.139622            0.843994       0.987399        0.932733           1.98142          0.0501896                        0.190646           0.132959              0.854592         0.988285          0.929592             2.02591            0.0469484
    2019-08-03 18:28:45  2:22:03.614  1231 obs/sec      9.94844   29            248711     0.190068         0.133044            0.855484       0.988324        0.939227           1.98142          0.0459988                        0.182759           0.123066              0.866375         0.989719          0.941212             2.02591            0.0437105
    2019-08-03 18:28:53  2:22:11.539  1231 obs/sec      10.2858   30            257146     0.178231         0.118355            0.872924       0.990468        0.910864           1.98142          0.0399122                        0.167797           0.10778               0.887358         0.99183           0.930898             2.02591            0.0330257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0032409607669763624
C438        0.8262894749641418     0.8262894749641418   0.002677971770524281
C88         0.7460945844650269     0.7460945844650269   0.0024180632767046837
C374        0.6972432136535645     0.6972432136535645   0.0022597379004917198
C79         0.6503309011459351     0.6503309011459351   0.0021076969361663585
---         ---                    ---                  ---
C731        0.21257366240024567    0.21257366240024567  0.0006889428999316745
C691        0.2098948210477829     0.2098948210477829   0.0006802608802073888
C916        0.20984506607055664    0.20984506607055664  0.0006800996262782367
C908        0.2076866328716278     0.2076866328716278   0.000673104228962369
C899        0.19976523518562317    0.19976523518562317  0.0006474312898424107

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_140

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight          weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  -------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.005896038536658051    0.01233716681599617     0.0         0.02473519061797608  0.08967664837837219  0.07254841084407884     0.14629018306732178
    3        2        Softmax                      0.0   0.0   0.00024247709018254682  4.4927874114364386e-05  0.0         0.14647175422084047  0.5194156169891357   -0.0003924270549772041  0.10775023698806763


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02630940233890816
RMSE: 0.16220173346456
LogLoss: 0.1150442127549761
Mean Per-Class Error: 0.02334282878612759
AUC: 0.9923425932918877
pr_auc: 0.6816870685825471
Gini: 0.9846851865837754
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5323836958543574: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4905  127   0.0252   (127.0/5032.0)
1      107   4882  0.0214   (107.0/4989.0)
Total  5012  5009  0.0234   (234.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.532384     0.976595  196
max f2                       0.463066     0.979311  212
max f0point5                 0.610402     0.976675  175
max accuracy                 0.532384     0.976649  196
max precision                0.999974     0.995495  0
max recall                   3.19232e-05  1         399
max specificity              0.999974     0.998609  0
max absolute_mcc             0.532384     0.953306  196
max min_per_class_accuracy   0.551635     0.975747  191
max mean_per_class_accuracy  0.532384     0.976657  196
Gains/Lift Table: Avg response rate: 49.79 %, avg score: 50.30 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   1                  2.00862     2.00862            1                1            1                           1                   0.0202445       0.0202445                  100.862   100.862
    2        0.0200579                   1                  2.00862     2.00862            1                1            1                           1                   0.0200441       0.0402886                  100.862   100.862
    3        0.0300369                   1                  2.00862     2.00862            1                1            1                           1                   0.0200441       0.0603327                  100.862   100.862
    4        0.040016                    1                  1.98853     2.00361            0.99             1            0.997506                    1                   0.0198437       0.0801764                  98.8533   100.361
    5        0.0500948                   1                  2.00862     2.00462            1                1            0.998008                    1                   0.0202445       0.100421                   100.862   100.462
    6        0.10009                     0.999993           1.99659     2.00061            0.994012         0.999998     0.996012                    0.999999            0.0998196       0.200241                   99.6591   100.061
    7        0.150085                    0.999829           1.99659     1.99927            0.994012         0.999942     0.995346                    0.99998             0.0998196       0.30006                    99.6591   99.927
    8        0.20008                     0.998636           1.99659     1.9986             0.994012         0.999382     0.995012                    0.999831            0.0998196       0.39988                    99.6591   99.8601
    9        0.30007                     0.983102           1.99058     1.99593            0.991018         0.993206     0.993681                    0.997623            0.199038        0.598918                   99.0577   99.5927
    10       0.40006                     0.906726           1.9565      1.98607            0.974052         0.954012     0.988775                    0.986723            0.19563         0.794548                   95.6499   98.6073
    11       0.50005                     0.527613           1.84224     1.95731            0.917166         0.776106     0.974456                    0.944608            0.184205        0.978753                   84.2236   95.7311
    12       0.60004                     0.100625           0.164378    1.65854            0.0818363        0.251058     0.825711                    0.829036            0.0164362       0.995189                   -83.5622  65.8539
    13       0.70003                     0.0174139          0.0280645   1.42565            0.0139721        0.049762     0.709765                    0.717727            0.00280617      0.997996                   -97.1935  42.5647
    14       0.80002                     0.000741423        0.0140323   1.24922            0.00698603       0.00600987   0.621928                    0.628773            0.00140309      0.999399                   -98.5968  24.9217
    15       0.90001                     2.37474e-06        0.00601383  1.1111             0.00299401       0.000165062  0.553166                    0.558936            0.000601323     1                          -99.3986  11.1099
    16       1                           1.35518e-28        0           1                  0                2.49505e-07  0.497855                    0.503048            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.025378145293908222
RMSE: 0.15930519543915767
LogLoss: 0.11087386541294271
Mean Per-Class Error: 0.021819499328529224
AUC: 0.9931183676002949
pr_auc: 0.6744429005759033
Gini: 0.9862367352005899
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5258746187458893: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3051  77    0.0246   (77.0/3128.0)
1      58    2991  0.019    (58.0/3049.0)
Total  3109  3068  0.0219   (135.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525875     0.97793   194
max f2                       0.399512     0.98255   223
max f0point5                 0.627867     0.978021  166
max accuracy                 0.525875     0.978145  194
max precision                0.99638      0.997262  7
max recall                   1.06988e-05  1         399
max specificity              0.999971     0.999041  0
max absolute_mcc             0.525875     0.956304  194
max min_per_class_accuracy   0.544369     0.977302  189
max mean_per_class_accuracy  0.525875     0.978181  194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.95 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999992           2.02591     2.01935            1                0.999998     0.996764                    0.999999            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999834           2.01935     2.01935            0.996764         0.999941     0.996764                    0.99998             0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.998808           2.01935     2.01935            0.996764         0.999452     0.996764                    0.999848            0.101017        0.404067                   101.935   101.935
    9        0.299984                    0.982705           2.00949     2.01607            0.991896         0.993112     0.995143                    0.997605            0.200722        0.604788                   100.949   101.607
    10       0.400032                    0.904585           1.97018     2.00459            0.972492         0.951018     0.989478                    0.985953            0.197114        0.801902                   97.0181   100.459
    11       0.500081                    0.499743           1.80627     1.96492            0.891586         0.760517     0.969893                    0.940852            0.180715        0.982617                   80.6273   96.4916
    12       0.599968                    0.0992674          0.131339    1.65965            0.0648298        0.233901     0.819212                    0.823154            0.0131191       0.995736                   -86.8661  65.965
    13       0.700016                    0.0179746          0.0229472   1.42573            0.0113269        0.0501895    0.703747                    0.712679            0.00229583      0.998032                   -97.7053  42.5727
    14       0.799903                    0.000900698        0.0164174   1.24974            0.00810373       0.00643453   0.616879                    0.624488            0.00163988      0.999672                   -98.3583  24.9742
    15       0.899951                    2.94532e-06        0.00327817  1.11117            0.00161812       0.000186042  0.54848                     0.555084            0.000327976     1                          -99.6722  11.1171
    16       1                           2.32877e-39        0           1                  0                3.16256e-07  0.493605                    0.499548            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:40:30  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:40:33  2:33:51.047  8347 obs/sec      1         1             25000      0.301708         0.376583            0.635882       0.943989        0.696588           2.00862          0.117653                         0.294332           0.353995              0.653419         0.948792          0.721336             2.02591            0.110086
    2019-08-03 18:40:39  2:33:57.030  8727 obs/sec      3         3             75000      0.2487           0.237474            0.752588       0.969789        0.714175           2.00862          0.0754416                        0.245175           0.229346              0.759517         0.97181           0.735269             2.02591            0.0725271
    2019-08-03 18:40:45  2:34:02.878  8939 obs/sec      5         5             125000     0.211883         0.173832            0.82042        0.982601        0.78664            2.00862          0.049995                         0.202434           0.16139               0.836055         0.985832          0.771359             2.02591            0.04452
    2019-08-03 18:40:51  2:34:08.398  9176 obs/sec      7         7             175000     0.185462         0.141265            0.862414       0.989046        0.754488           2.00862          0.0350264                        0.176719           0.134391              0.875061         0.990883          0.803782             2.02591            0.029626
    2019-08-03 18:40:56  2:34:14.046  9267 obs/sec      9         9             225000     0.166887         0.1192              0.888592       0.991938        0.685418           2.00862          0.0268436                        0.16183            0.114303              0.895227         0.992963          0.724528             2.02591            0.0247693
    2019-08-03 18:40:59  2:34:17.015  9325 obs/sec      10        10            250000     0.162202         0.115044            0.89476        0.992343        0.681687           2.00862          0.023351                         0.159305           0.110874              0.898471         0.993118          0.674443             2.02591            0.0218553
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.00331153439172673
C40         0.9510648250579834     0.9510648250579834   0.003149483876941078
C24         0.950591504573822      0.950591504573822    0.003147916459879469
C31         0.9143902063369751     0.9143902063369751   0.003028034615742994
C38         0.8791595101356506     0.8791595101356506   0.002911366953627832
---         ---                    ---                  ---
C267        0.19144795835018158    0.19144795835018158  0.0006339864983024929
C524        0.19007453322410583    0.19007453322410583  0.0006294383537630315
C352        0.18845431506633759    0.18845431506633759  0.0006240729456114818
C631        0.18542861938476562    0.18542861938476562  0.0006140532503030572
C767        0.18416757881641388    0.18416757881641388  0.0006098772710915977

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_28

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.019751211489932644   0.07416388392448425    0.0         0.023069312751055737  0.08035913109779358  0.043026192670189777   0.15722638368606567
    3        2        Softmax                      0.0   0.0   0.0002799876835979376  6.102830229792744e-05  0.0         0.014657676514616469  0.389345645904541    0.0004914225675030637  0.1296979784965515


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.028507089960592712
RMSE: 0.16884042750654452
LogLoss: 0.12020584010839695
Mean Per-Class Error: 0.027709661403936714
AUC: 0.9919820438218295
pr_auc: 0.7287341904454633
Gini: 0.9839640876436591
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5474443794101386: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4891  128   0.0255   (128.0/5019.0)
1      150   4864  0.0299   (150.0/5014.0)
Total  5041  4992  0.0277   (278.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.547444     0.972217  194
max f2                       0.355539     0.975909  242
max f0point5                 0.598603     0.976382  180
max accuracy                 0.547444     0.972291  194
max precision                0.998817     0.999451  2
max recall                   1.90578e-05  1         399
max specificity              0.999967     0.999801  0
max absolute_mcc             0.547444     0.944592  194
max min_per_class_accuracy   0.530501     0.971879  199
max mean_per_class_accuracy  0.547444     0.97229   194
Gains/Lift Table: Avg response rate: 49.98 %, avg score: 49.72 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   1                  2.001       2.001              1                1            1                           1                   0.0201436       0.0201436                  100.1     100.1
    2        0.0200339                   1                  2.001       2.001              1                1            1                           1                   0.0199442       0.0400878                  100.1     100.1
    3        0.030001                    1                  2.001       2.001              1                1            1                           1                   0.0199442       0.0600319                  100.1     100.1
    4        0.0400678                   1                  2.001       2.001              1                1            1                           1                   0.0201436       0.0801755                  100.1     100.1
    5        0.0500349                   1                  2.001       2.001              1                1            1                           1                   0.0199442       0.10012                    100.1     100.1
    6        0.10007                     0.999958           1.99701     1.999              0.998008         0.999989     0.999004                    0.999995            0.0999202       0.20004                    99.7011   99.9004
    7        0.150005                    0.999465           2.001       1.99967            1                0.999791     0.999336                    0.999927            0.0999202       0.29996                    100.1     99.9668
    8        0.20004                     0.997247           1.99701     1.999              0.998008         0.998592     0.999003                    0.999593            0.0999202       0.39988                    99.7011   99.9003
    9        0.30001                     0.97319            1.98304     1.99368            0.991027         0.988212     0.996346                    0.9958              0.198245        0.598125                   98.3042   99.3685
    10       0.39998                     0.880751           1.96309     1.98604            0.981057         0.936056     0.992524                    0.980868            0.19625         0.794376                   96.3092   98.6038
    11       0.50005                     0.523759           1.77778     1.94436            0.888446         0.74641      0.971696                    0.933948            0.177902        0.972278                   77.7778   94.4361
    12       0.60002                     0.0987076          0.199501    1.65365            0.0997009        0.249437     0.826412                    0.819901            0.0199442       0.992222                   -80.0499  65.3648
    13       0.69999                     0.0146028          0.0339152   1.42232            0.0169492        0.0465923    0.710807                    0.70946             0.00339051      0.995612                   -96.6085  42.2324
    14       0.79996                     0.000755303        0.0299252   1.24832            0.0149551        0.00542317   0.623847                    0.621477            0.00299162      0.998604                   -97.0075  24.8317
    15       0.89993                     2.07447e-06        0.00997506  1.11075            0.00498504       0.000178244  0.5551                      0.552459            0.000997208     0.999601                   -99.0025  11.0754
    16       1                           2.12009e-41        0.00398605  1                  0.00199203       2.44448e-07  0.499751                    0.497175            0.000398883     1                          -99.6014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.026068603770080027
RMSE: 0.16145774608262073
LogLoss: 0.11140386615423711
Mean Per-Class Error: 0.02345523961149476
AUC: 0.9930303445261915
pr_auc: 0.7573808503784545
Gini: 0.9860606890523831
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5308835618431614: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3050  78    0.0249   (78.0/3128.0)
1      67    2982  0.022    (67.0/3049.0)
Total  3117  3060  0.0235   (145.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.530884     0.976265  195
max f2                       0.360276     0.979422  231
max f0point5                 0.593812     0.978658  178
max accuracy                 0.53504      0.976526  194
max precision                0.998504     0.998247  4
max recall                   1.8098e-05   1         399
max specificity              0.999985     0.999361  0
max absolute_mcc             0.530884     0.953052  195
max min_per_class_accuracy   0.542853     0.976058  192
max mean_per_class_accuracy  0.530884     0.976545  195
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.26 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999957           2.02591     2.02263            1                0.999988     0.998382                    0.999994            0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.999502           2.01935     2.02154            0.996764         0.999806     0.997843                    0.999931            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.997288           2.01935     2.02099            0.996764         0.998623     0.997573                    0.999604            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.972577           2.01606     2.01935            0.995138         0.988141     0.996762                    0.995787            0.201378        0.605772                   101.606   101.935
    10       0.400032                    0.875614           1.97018     2.00705            0.972492         0.933442     0.990692                    0.980195            0.197114        0.802886                   97.0181   100.705
    11       0.500081                    0.47878            1.7866      1.96295            0.881877         0.734072     0.968922                    0.930954            0.178747        0.981633                   78.6604   96.2949
    12       0.599968                    0.092192           0.124772    1.65692            0.0615883        0.218792     0.817863                    0.812389            0.0124631       0.994096                   -87.5228  65.6917
    13       0.700016                    0.0161593          0.0327817   1.42479            0.0161812        0.045749     0.703284                    0.702818            0.00327976      0.997376                   -96.7218  42.479
    14       0.799903                    0.000848966        0.0164174   1.24892            0.00810373       0.00569277   0.616474                    0.615766            0.00163988      0.999016                   -98.3583  24.8922
    15       0.899951                    3.12237e-06        0.00655634  1.11081            0.00323625       0.000188085  0.5483                      0.547331            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           8.85737e-39        0.00327817  1                  0.00161812       3.37682e-07  0.493605                    0.492571            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:39:41  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:39:46  33 min  3.746 sec  5239 obs/sec      1         1             25000      0.308661         0.411358            0.618913       0.939882        0.644704           2.001            0.121499                         0.303271           0.379094              0.632047         0.94499           0.63181              1.99323            0.116238
    2019-08-03 16:39:55  33 min 13.328 sec  5454 obs/sec      3         3             75000      0.24463          0.228852            0.760625       0.971586        0.758372           2.001            0.0723612                        0.241661           0.219692              0.766361         0.972949          0.759568             2.02591            0.0704225
    2019-08-03 16:40:05  33 min 22.552 sec  5573 obs/sec      5         5             125000     0.222586         0.189683            0.801823       0.98023         0.798276           2.001            0.0579089                        0.210664           0.173525              0.822453         0.983493          0.793755             2.02591            0.0490529
    2019-08-03 16:40:13  33 min 31.186 sec  5751 obs/sec      7         7             175000     0.197805         0.15619             0.843492       0.986799        0.767605           2.001            0.0415628                        0.186939           0.141593              0.860192         0.989521          0.791089             2.02591            0.0352922
    2019-08-03 16:40:22  33 min 39.587 sec  5889 obs/sec      9         9             225000     0.176891         0.131028            0.874839       0.990539        0.733154           2.001            0.0315957                        0.16834            0.119373              0.886629         0.992355          0.757282             2.02591            0.0265501
    2019-08-03 16:40:26  33 min 44.180 sec  5924 obs/sec      10        10            250000     0.16884          0.120206            0.885972       0.991982        0.728734           2.001            0.0277086                        0.161458           0.111404              0.895709         0.99303           0.757381             2.02591            0.0234742
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003264023185401571
C35         0.9841843247413635     0.9841843247413635   0.003212400454664599
C25         0.9743979573249817     0.9743979573249817   0.0031804575245166704
C28         0.9729301929473877     0.9729301929473877   0.003175666707557497
C34         0.8836783766746521     0.8836783766746521   0.002884346709904087
---         ---                    ---                  ---
C721        0.20754604041576385    0.20754604041576385  0.0006774350879553447
C633        0.2067928910255432     0.2067928910255432   0.0006749767908835934
C854        0.204672172665596      0.204672172665596    0.000668054716987019
C513        0.20425909757614136    0.20425909757614136  0.0006667064303177272
C495        0.18347157537937164    0.18347157537937164  0.000598855475900421

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_201

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight          weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  -------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.010060385471457284    0.025188028812408447   0.0         0.02333374022158182  0.08384674787521362  0.03898340356675613     0.14926761388778687
    3        2        Softmax                      0.0   0.0   0.00029992853791327434  8.358905324712396e-05  0.0         0.04409052206756314  0.36821460723876953  2.5173327001387635e-06  0.09744483232498169


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.025659761577054598
RMSE: 0.1601866460634425
LogLoss: 0.11476032790314547
Mean Per-Class Error: 0.023282427811633588
AUC: 0.9924227322624326
pr_auc: 0.7465054521613529
Gini: 0.9848454645248652
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5070339646776962: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4939  116   0.0229   (116.0/5055.0)
1      117   4837  0.0236   (117.0/4954.0)
Total  5056  4953  0.0233   (233.0/10009.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.507034     0.976481  201
max f2                       0.405311     0.97962   225
max f0point5                 0.614881     0.978584  176
max accuracy                 0.507034     0.976721  201
max precision                0.997079     0.998978  5
max recall                   2.5946e-05   1         399
max specificity              0.99997      0.999604  0
max absolute_mcc             0.507034     0.953437  201
max min_per_class_accuracy   0.503207     0.976459  202
max mean_per_class_accuracy  0.507034     0.976718  201
Gains/Lift Table: Avg response rate: 49.50 %, avg score: 49.20 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100909                   1                  2.02039    2.02039            1                1            1                           1                   0.0203876       0.0203876                  102.039   102.039
    2        0.0200819                   1                  2.00018    2.01034            0.99             1            0.995025                    1                   0.0199839       0.0403714                  100.018   101.034
    3        0.0300729                   1                  2.02039    2.01368            1                1            0.996678                    1                   0.0201857       0.0605571                  102.039   101.368
    4        0.0400639                   1                  2.02039    2.01535            1                1            0.997506                    1                   0.0201857       0.0807428                  102.039   101.535
    5        0.050055                    1                  2.00018    2.01232            0.99             1            0.996008                    1                   0.0199839       0.100727                   100.018   101.232
    6        0.10001                     0.999935           2.02039    2.01635            1                0.999984     0.998002                    0.999992            0.100929        0.201655                   102.039   101.635
    7        0.150065                    0.999277           2.02039    2.0177             1                0.999706     0.998668                    0.999897            0.10113         0.302786                   102.039   101.77
    8        0.20002                     0.996179           2.01635    2.01736            0.998            0.998115     0.998501                    0.999452            0.100727        0.403512                   101.635   101.736
    9        0.30003                     0.971513           1.99415    2.00962            0.987013         0.98641      0.994672                    0.995105            0.199435        0.602947                   99.4149   100.962
    10       0.40004                     0.881641           1.98809    2.00424            0.984016         0.934363     0.992008                    0.979919            0.198829        0.801776                   98.8094   100.424
    11       0.50005                     0.459023           1.78626    1.96064            0.884116         0.737713     0.97043                     0.931478            0.178644        0.98042                    78.6257   96.0644
    12       0.59996                     0.0849878          0.137386   1.65702            0.068            0.216798     0.82015                     0.812464            0.0137263       0.994146                   -86.2614  65.7021
    13       0.69997                     0.012824           0.0201837  1.42315            0.00999001       0.0407333    0.704396                    0.702201            0.00201857      0.996165                   -97.9816  42.3153
    14       0.79998                     0.000596975        0.016147   1.24726            0.00799201       0.0046636    0.617335                    0.614998            0.00161486      0.99778                    -98.3853  24.7256
    15       0.89999                     2.16443e-06        0.0222021  1.11112            0.010989         0.00013314   0.549956                    0.546672            0.00222043      1                          -97.7798  11.1123
    16       1                           2.95523e-32        0          1                  0                2.42491e-07  0.494955                    0.491999            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.025559867297679086
RMSE: 0.15987453611403876
LogLoss: 0.11141773438606023
Mean Per-Class Error: 0.022672573457064082
AUC: 0.993209745931541
pr_auc: 0.7270353878227395
Gini: 0.986419491863082
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5209613863437456: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3059  69    0.0221   (69.0/3128.0)
1      71    2978  0.0233   (71.0/3049.0)
Total  3130  3047  0.0227   (140.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.520961     0.977034  200
max f2                       0.430516     0.978559  219
max f0point5                 0.592436     0.979213  182
max accuracy                 0.520961     0.977335  200
max precision                0.990577     0.998691  13
max recall                   1.96523e-05  1         399
max specificity              0.999964     0.999361  0
max absolute_mcc             0.520961     0.954663  200
max min_per_class_accuracy   0.520961     0.976714  200
max mean_per_class_accuracy  0.520961     0.977327  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.08 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999999           1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999952           2.01935     2.01935            0.996764         0.999988     0.996764                    0.999994            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999464           2.02591     2.02154            1                0.99978      0.997843                    0.999923            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.997146           2.02591     2.02263            1                0.998566     0.998382                    0.999583            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.971883           2.00949     2.01826            0.991896         0.987484     0.996222                    0.995555            0.200722        0.605444                   100.949   101.826
    10       0.400032                    0.877672           1.98657     2.01033            0.980583         0.933322     0.992311                    0.97999             0.198754        0.804198                   98.6572   101.033
    11       0.500081                    0.443733           1.76038     1.96033            0.868932         0.729222     0.967627                    0.92982             0.176123        0.980321                   76.0378   96.0325
    12       0.599968                    0.0842749          0.134623    1.65637            0.0664506        0.210774     0.817593                    0.810109            0.013447        0.993768                   -86.5377  65.637
    13       0.700016                    0.0133288          0.0327817   1.42432            0.0161812        0.0422304    0.703053                    0.700361            0.00327976      0.997048                   -96.7218  42.4322
    14       0.799903                    0.000755198        0.0197009   1.24892            0.00972447       0.00495416   0.616474                    0.613523            0.00196786      0.999016                   -98.0299  24.8922
    15       0.899951                    2.09805e-06        0.00655634  1.11081            0.00323625       0.000165241  0.5483                      0.545335            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           4.83321e-38        0.00327817  1                  0.00161812       2.48497e-07  0.493605                    0.490775            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:11:00  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:11:04  4:04:22.472  5345 obs/sec      1         1             25000      0.303086         0.377354            0.632519       0.943727        0.710288           2.00038          0.119293                         0.293191           0.352237              0.656101         0.950379          0.709422             1.99323            0.110571
    2019-08-03 20:11:14  4:04:32.119  5487 obs/sec      3         3             75000      0.25007          0.228901            0.749835       0.970774        0.809421           2.00038          0.0802278                        0.24366            0.219608              0.762479         0.973311          0.832931             2.02591            0.072689
    2019-08-03 20:11:23  4:04:41.000  5696 obs/sec      5         5             125000     0.222829         0.189586            0.801368       0.980039        0.768913           2.02039          0.0569487                        0.218718           0.182983              0.808618         0.981738          0.749519             2.02591            0.0535859
    2019-08-03 20:11:32  4:04:49.882  5801 obs/sec      7         7             175000     0.192819         0.149769            0.851269       0.987662        0.791484           2.02039          0.0380657                        0.190015           0.144604              0.855553         0.988705          0.766639             2.02591            0.0351303
    2019-08-03 20:11:41  4:04:58.722  5869 obs/sec      9         9             225000     0.17245          0.126397            0.881032       0.991061        0.736846           2.02039          0.0282746                        0.170214           0.122214              0.88409          0.991869          0.747919             2.02591            0.0254169
    2019-08-03 20:11:45  4:05:03.468  5893 obs/sec      10        10            250000     0.160187         0.11476             0.897351       0.992423        0.746505           2.02039          0.023279                         0.159875           0.111418              0.897744         0.99321           0.727035             2.02591            0.0226647
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0034098180978702273
C34         0.9528209567070007     0.9528209567070007   0.0032489461422095553
C35         0.88286292552948       0.88286292552948     0.0030104019814090758
C28         0.8697617053985596     0.8697617053985596   0.0029657292039024816
C38         0.8449682593345642     0.8449682593345642   0.002881188062804901
---         ---                    ---                  ---
C582        0.19014713168144226    0.19014713168144226  0.000648367130865495
C475        0.18924440443515778    0.18924440443515778  0.0006452889951636737
C604        0.18529793620109558    0.18529793620109558  0.0006318322563564985
C562        0.17825351655483246    0.17825351655483246  0.0006078120667576778
C651        0.16934409737586975    0.16934409737586975  0.0005774325679997387

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_137

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.008222024387756318    0.025624364614486694   0.0         0.022645845420024686  0.07735130190849304  0.03305574623891257   0.16180163621902466
    3        2        Softmax                      0.0   0.0   0.00026460488555812844  6.999698234722018e-05  0.0         -0.01934974057519412  0.37154650688171387  0.000913414885528166  0.10340702533721924


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0255259039572411
RMSE: 0.15976828207513874
LogLoss: 0.1103375283019876
Mean Per-Class Error: 0.0233698513099887
AUC: 0.9931657108791611
pr_auc: 0.6735626562438028
Gini: 0.9863314217583221
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5154400240508986: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4854  131   0.0263   (131.0/4985.0)
1      103   4931  0.0205   (103.0/5034.0)
Total  4957  5062  0.0234   (234.0/10019.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.51544      0.976823  195
max f2                       0.457293     0.980516  208
max f0point5                 0.579544     0.977948  179
max accuracy                 0.51544      0.976644  195
max precision                0.999967     0.998757  0
max recall                   1.26811e-05  1         399
max specificity              0.999967     0.999599  0
max absolute_mcc             0.51544      0.953301  195
max min_per_class_accuracy   0.545824     0.976329  187
max mean_per_class_accuracy  0.51544      0.97663   195
Gains/Lift Table: Avg response rate: 50.24 %, avg score: 50.57 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100808                   1                  1.99027     1.99027            1                1            1                           1                   0.0200636       0.0200636                  99.0266   99.0266
    2        0.0200619                   1                  1.99027     1.99027            1                1            1                           1                   0.0198649       0.0399285                  99.0266   99.0266
    3        0.0300429                   1                  1.97036     1.98365            0.99             1            0.996678                    1                   0.0196663       0.0595948                  97.0364   98.3654
    4        0.040024                    1                  1.99027     1.9853             1                1            0.997506                    1                   0.0198649       0.0794597                  99.0266   98.5303
    5        0.050005                    1                  1.99027     1.98629            1                1            0.998004                    1                   0.0198649       0.0993246                  99.0266   98.6294
    6        0.10001                     0.999995           1.98629     1.98629            0.998004         0.999999     0.998004                    0.999999            0.0993246       0.198649                   98.6294   98.6294
    7        0.150015                    0.999842           1.99027     1.98762            1                0.999944     0.998669                    0.999981            0.0995232       0.298172                   99.0266   98.7618
    8        0.20002                     0.998609           1.9704      1.98331            0.99002          0.999377     0.996507                    0.99983             0.09853         0.396702                   97.0403   98.3314
    9        0.30003                     0.981621           1.97239     1.97967            0.991018         0.992595     0.994677                    0.997418            0.197259        0.593961                   97.239    97.9673
    10       0.40004                     0.906866           1.9565      1.97388            0.983034         0.952205     0.991766                    0.986115            0.195669        0.789631                   95.6499   97.3879
    11       0.50005                     0.56359            1.84129     1.94736            0.92515          0.786624     0.978443                    0.946217            0.184148        0.973778                   84.1294   94.7362
    12       0.59996                     0.108997           0.216722    1.65916            0.108891         0.263686     0.833638                    0.832556            0.0216528       0.995431                   -78.3278  65.9162
    13       0.69997                     0.0194928          0.0278081   1.42608            0.0139721        0.0544718    0.716526                    0.721385            0.00278109      0.998212                   -97.2192  42.6078
    14       0.79998                     0.00105218         0.0119178   1.24929            0.00598802       0.0070908    0.627698                    0.632087            0.0011919       0.999404                   -98.8082  24.9286
    15       0.89999                     2.7193e-06         0.00397259  1.1109             0.00199601       0.000230142  0.558168                    0.561873            0.000397298     0.999801                   -99.6027  11.0903
    16       1                           5.31237e-38        0.00198629  1                  0.000998004      3.07678e-07  0.502445                    0.50568             0.000198649     1                          -99.8014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.025063745570971248
RMSE: 0.15831533586791663
LogLoss: 0.11175669693855815
Mean Per-Class Error: 0.020889411563390414
AUC: 0.9932052897306484
pr_auc: 0.6850448837967148
Gini: 0.9864105794612967
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5534293600454582: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3064  64    0.0205   (64.0/3128.0)
1      65    2984  0.0213   (65.0/3049.0)
Total  3129  3048  0.0209   (129.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.553429     0.978842  191
max f2                       0.468848     0.980918  209
max f0point5                 0.587516     0.979647  184
max accuracy                 0.553429     0.979116  191
max precision                0.999978     0.996812  0
max recall                   9.66727e-06  1         399
max specificity              0.999978     0.999041  0
max absolute_mcc             0.553429     0.958225  191
max min_per_class_accuracy   0.553429     0.978682  191
max mean_per_class_accuracy  0.553429     0.979111  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.82 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  1.96056     2.00413            0.967742         1            0.989247                    1                   0.0196786       0.0603477                  96.0558   100.413
    4        0.0401489                   1                  2.02591     2.00957            1                1            0.991935                    1                   0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   1                  2.02591     2.0128             1                1            0.993528                    1                   0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999993           2.02591     2.01935            1                0.999998     0.996764                    0.999999            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999857           2.01935     2.01935            0.996764         0.999949     0.996764                    0.999982            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.998747           2.00624     2.01608            0.990291         0.999463     0.995146                    0.999852            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.982786           2.01278     2.01498            0.993517         0.993201     0.994603                    0.997638            0.20105         0.60446                    101.278   101.498
    10       0.400032                    0.897941           1.99641     2.01033            0.985437         0.948855     0.992311                    0.985437            0.199738        0.804198                   99.6407   101.033
    11       0.500081                    0.48649            1.7866      1.96557            0.881877         0.7605       0.970217                    0.940435            0.178747        0.982945                   78.6604   96.5572
    12       0.599968                    0.0940768          0.121489    1.65856            0.0599676        0.225559     0.818672                    0.821418            0.0121351       0.99508                    -87.8511  65.8557
    13       0.700016                    0.017507           0.0327817   1.4262             0.0161812        0.0475173    0.703978                    0.710809            0.00327976      0.99836                    -96.7218  42.6196
    14       0.799903                    0.000891063        0.00656697  1.24892            0.00324149       0.00648656   0.616474                    0.622858            0.000655953     0.999016                   -99.3433  24.8922
    15       0.899951                    3.44332e-06        0.00983452  1.11117            0.00485437       0.000195072  0.54848                     0.553636            0.000983929     1                          -99.0165  11.1171
    16       1                           5.31237e-38        0           1                  0                3.65507e-07  0.493605                    0.498245            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:38:56  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:39:01  2:32:19.396  5195 obs/sec      1         1             25000      0.310962         0.439546            0.613203       0.942053        0.646937           1.99027          0.121968                         0.304812           0.426915              0.628299         0.945385          0.609625             2.02591            0.115428
    2019-08-03 18:39:11  2:32:28.776  5527 obs/sec      3         3             75000      0.243369         0.22917             0.76308        0.972008        0.736048           1.99027          0.0727618                        0.238525           0.222341              0.772386         0.9738            0.75361              2.02591            0.0699369
    2019-08-03 18:39:20  2:32:37.743  5699 obs/sec      5         5             125000     0.217661         0.185943            0.81049        0.980827        0.759324           1.99027          0.0526999                        0.212427           0.176245              0.819469         0.98268           0.728836             2.02591            0.045977
    2019-08-03 18:39:29  2:32:46.697  5789 obs/sec      7         7             175000     0.186046         0.139157            0.861545       0.989412        0.753263           1.99027          0.0341351                        0.182412           0.137427              0.866881         0.989906          0.753055             2.02591            0.0320544
    2019-08-03 18:39:37  2:32:55.250  5899 obs/sec      9         9             225000     0.172033         0.126372            0.881616       0.991061        0.726998           1.99027          0.0303423                        0.172521           0.1302                0.880927         0.990355          0.72873              2.02591            0.0278452
    2019-08-03 18:39:42  2:32:59.848  5938 obs/sec      10        10            250000     0.159768         0.110338            0.897894       0.993166        0.673563           1.99027          0.0233556                        0.158315           0.111757              0.899729         0.993205          0.685045             2.02591            0.0208839
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C34         1.0                    1.0                  0.0029885921914294556
C28         0.9955429434776306     0.9955429434776306   0.0029752718671099427
C36         0.9878114461898804     0.9878114461898804   0.002952165574687714
C31         0.9031438231468201     0.9031438231468201   0.0026991285775943316
C25         0.8959724307060242     0.8959724307060242   0.002677696210144093
---         ---                    ---                  ---
C426        0.22235779464244843    0.22235779464244843  0.0006645367687718958
C832        0.2219376415014267     0.2219376415014267   0.0006632811023754337
C721        0.2213914394378662     0.2213914394378662   0.0006616487271533342
C506        0.22017134726047516    0.22017134726047516  0.0006580023691991591
C588        0.20107401907444       0.20107401907444     0.0006009282433052088

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_166

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 252,285 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  ------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.10078452851148935    0.1637188196182251     0.0         0.002910494792827049  0.0980457067489624   -0.011486567819160477   0.1247999370098114
    3        2        Softmax                 0.0   0.0   0.0016905744046198379  4.093228199053556e-05  0.0         0.00848676561162165   0.26469147205352783  -0.0005424891653822428  0.267367959022522


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03204459276675945
RMSE: 0.1790100353800296
LogLoss: 0.11959183885797425
Mean Per-Class Error: 0.03955206171825987
AUC: 0.9902376936259505
pr_auc: 0.9045277043428102
Gini: 0.980475387251901
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5119656571131258: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4836  187   0.0372   (187.0/5023.0)
1      209   4782  0.0419   (209.0/4991.0)
Total  5045  4969  0.0395   (396.0/10014.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.511966     0.960241  201
max f2                       0.243094     0.96764   270
max f0point5                 0.783214     0.966374  126
max accuracy                 0.511966     0.960455  201
max precision                0.999894     1         0
max recall                   0.000127425  1         399
max specificity              0.999894     1         0
max absolute_mcc             0.511966     0.920918  201
max min_per_class_accuracy   0.490648     0.959785  206
max mean_per_class_accuracy  0.511966     0.960448  201
Gains/Lift Table: Avg response rate: 49.84 %, avg score: 49.50 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100859                   0.999954           2.00641     2.00641            1                0.999976     1                           0.999976            0.0202364       0.0202364                  100.641   100.641
    2        0.0200719                   0.999901           2.00641     2.00641            1                0.999926     1                           0.999951            0.0200361       0.0402725                  100.641   100.641
    3        0.0300579                   0.999858           2.00641     2.00641            1                0.99988      1                           0.999927            0.0200361       0.0603086                  100.641   100.641
    4        0.0400439                   0.999805           2.00641     2.00641            1                0.999829     1                           0.999903            0.0200361       0.0803446                  100.641   100.641
    5        0.05003                     0.99974            2.00641     2.00641            1                0.999773     1                           0.999877            0.0200361       0.100381                   100.641   100.641
    6        0.10006                     0.999331           2.00241     2.00441            0.998004         0.999545     0.999002                    0.999711            0.10018         0.200561                   100.241   100.441
    7        0.14999                     0.99849            1.99839     2.0024             0.996            0.998961     0.998003                    0.999461            0.0997796       0.300341                   99.8386   100.24
    8        0.20002                     0.997028           1.9984      2.0014             0.996008         0.997821     0.997504                    0.999051            0.09998         0.400321                   99.8402   100.14
    9        0.29998                     0.98877            1.98837     1.99706            0.991009         0.993835     0.99534                     0.997313            0.198758        0.599078                   98.8372   99.7061
    10       0.40004                     0.947689           1.96036     1.98788            0.977046         0.97479      0.990764                    0.991679            0.196153        0.795231                   96.0356   98.788
    11       0.5                         0.464088           1.66165     1.92266            0.828172         0.798238     0.958258                    0.953006            0.166099        0.96133                    66.1654   92.2661
    12       0.59996                     0.0391008          0.308679    1.65375            0.153846         0.163155     0.824234                    0.821408            0.0308555       0.992186                   -69.1321  65.3753
    13       0.70002                     0.00703988         0.0460554   1.42395            0.0229541        0.0178299    0.7097                      0.706546            0.00460829      0.996794                   -95.3945  42.3951
    14       0.79998                     0.00152858         0.0280617   1.24953            0.013986         0.00361201   0.622769                    0.618712            0.00280505      0.999599                   -97.1938  24.953
    15       0.89994                     0.000279298        0.00400881  1.11119            0.001998         0.000750776  0.553817                    0.550073            0.000400721     1                          -99.5991  11.1185
    16       1                           8.99738e-07        0           1                  0                0.000110771  0.498402                    0.495043            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.030144635805555098
RMSE: 0.17362210632737726
LogLoss: 0.11271416823288856
Mean Per-Class Error: 0.03629434077165883
AUC: 0.9913218895298362
pr_auc: 0.9205424411756342
Gini: 0.9826437790596725
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4819003947339229: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3022  106   0.0339   (106.0/3128.0)
1      118   2931  0.0387   (118.0/3049.0)
Total  3140  3037  0.0363   (224.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.4819       0.963194  201
max f2                       0.216604     0.967595  267
max f0point5                 0.771265     0.968976  132
max accuracy                 0.4819       0.963736  201
max precision                0.999922     1         0
max recall                   0.000388204  1         398
max specificity              0.999922     1         0
max absolute_mcc             0.4819       0.927464  201
max min_per_class_accuracy   0.453582     0.961627  208
max mean_per_class_accuracy  0.4819       0.963706  201
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.88 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999954           2.02591     2.02591            1                0.999976     1                           0.999976            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999914           2.02591     2.02591            1                0.999934     1                           0.999955            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999869           2.02591     2.02591            1                0.999891     1                           0.999934            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999803           2.02591     2.02591            1                0.999833     1                           0.999908            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999734           2.02591     2.02591            1                0.999771     1                           0.999881            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999342           2.02591     2.02591            1                0.999552     1                           0.999716            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.998587           2.01935     2.02372            0.996764         0.999022     0.998921                    0.999485            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.997128           2.02591     2.02427            1                0.997922     0.999191                    0.999094            0.101345        0.405051                   102.591   102.427
    9        0.299984                    0.988701           2.00949     2.01935            0.991896         0.993876     0.996762                    0.997357            0.200722        0.605772                   100.949   101.935
    10       0.400032                    0.947488           1.97346     2.00787            0.97411          0.974864     0.991097                    0.991731            0.197442        0.803214                   97.3459   100.787
    11       0.500081                    0.353671           1.64892     1.93606            0.813916         0.774259     0.955649                    0.948223            0.164972        0.968186                   64.892    93.6059
    12       0.599968                    0.031235           0.252828    1.65582            0.124797         0.127739     0.817323                    0.811623            0.0252542       0.99344                    -74.7172  65.5823
    13       0.700016                    0.00620386         0.0393381   1.42479            0.0194175        0.0147689    0.703284                    0.697734            0.00393572      0.997376                   -96.0662  42.479
    14       0.799903                    0.00132364         0.0229844   1.24974            0.0113452        0.00321744   0.616879                    0.611007            0.00229583      0.999672                   -97.7016  24.9742
    15       0.899951                    0.000276091        0.00327817  1.11117            0.00161812       0.000654815  0.54848                     0.543154            0.000327976     1                          -99.6722  11.1171
    16       1                           1.172e-06          0           1                  0                0.000110345  0.493605                    0.488823            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:19:01  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:19:08  3:12:26.553  1262 obs/sec      0.33984   1             8496       0.348653         0.518315            0.513759       0.921317        0.651873           1.98655          0.150689                         0.334975           0.461947              0.551093         0.930806          0.70788              2.02591            0.143921
    2019-08-03 19:19:23  3:12:41.263  1250 obs/sec      1.0166    3             25415      0.299161         0.303623            0.642007       0.946058        0.889525           2.00641          0.119333                         0.289993           0.284052              0.663562         0.951864          0.912346             2.02591            0.108467
    2019-08-03 19:19:37  3:12:55.814  1254 obs/sec      1.69112   5             42278      0.300237         0.295346            0.639426       0.946945        0.922021           2.00641          0.123927                         0.286799           0.272551              0.670931         0.954968          0.931244             2.02591            0.110248
    2019-08-03 19:19:52  3:13:10.602  1249 obs/sec      2.36528   7             59132      0.294025         0.285752            0.654195       0.950942        0.931186           2.00641          0.117436                         0.280234           0.261753              0.685825         0.958486          0.931372             2.02591            0.10442
    2019-08-03 19:20:07  3:13:25.322  1246 obs/sec      3.03608   9             75902      0.287811         0.279781            0.668656       0.953709        0.918768           2.00641          0.112143                         0.272197           0.250427              0.703587         0.962031          0.929075             2.02591            0.0968107
    2019-08-03 19:20:22  3:13:40.115  1246 obs/sec      3.71336   11            92834      0.286663         0.274064            0.671293       0.953897        0.939867           2.00641          0.109846                         0.271397           0.247908              0.705327         0.962435          0.954467             2.02591            0.0982678
    2019-08-03 19:20:36  3:13:54.992  1244 obs/sec      4.38992   13            109748     0.279015         0.259578            0.6886         0.959251        0.931243           2.00641          0.106052                         0.265322           0.235775              0.71837          0.966216          0.940284             2.02591            0.0968107
    2019-08-03 19:20:51  3:14:09.642  1243 obs/sec      5.05912   15            126478     0.269123         0.244616            0.710289       0.963149        0.952619           2.00641          0.0968644                        0.255034           0.22114               0.739788         0.969976          0.960677             2.02591            0.0867735
    2019-08-03 19:21:06  3:14:24.279  1243 obs/sec      5.73264   17            143316     0.254203         0.223765            0.741521       0.970017        0.941062           1.98655          0.0851807                        0.243606           0.203307              0.762585         0.975023          0.935022             2.02591            0.0770601
    2019-08-03 19:21:21  3:14:39.376  1239 obs/sec      6.40384   19            160096     0.242709         0.20465             0.764366       0.97385         0.957365           1.98655          0.0776912                        0.23065            0.186442              0.787167         0.978423          0.962039             1.99323            0.0675085
    2019-08-03 19:21:35  3:14:53.877  1241 obs/sec      7.07488   21            176872     0.227782         0.180491            0.792459       0.979728        0.965561           2.00641          0.0679049                        0.220801           0.172865              0.804955         0.981053          0.967447             2.02591            0.0613566
    2019-08-03 19:21:50  3:15:08.396  1243 obs/sec      7.74688   23            193672     0.219348         0.168421            0.807543       0.982061        0.955408           2.00641          0.0629119                        0.210891           0.158175              0.82207          0.983816          0.939737             2.02591            0.0579569
    2019-08-03 19:22:04  3:15:22.867  1244 obs/sec      8.41792   25            210448     0.210452         0.159365            0.822838       0.983499        0.930612           2.00641          0.055722                         0.19788            0.143878              0.843348         0.986155          0.9349               2.02591            0.0475959
    2019-08-03 19:22:20  3:15:38.648  1237 obs/sec      9.09016   27            227254     0.194554         0.137272            0.848593       0.98809         0.930866           2.00641          0.0477332                        0.184984           0.129234              0.863102         0.988903          0.957508             2.02591            0.0412822
    2019-08-03 19:22:35  3:15:53.207  1238 obs/sec      9.75872   29            243968     0.186042         0.125034            0.861553       0.989851        0.938494           2.00641          0.0455362                        0.178893           0.119002              0.871969         0.990355          0.93837              2.02591            0.0411203
    2019-08-03 19:22:43  3:16:01.154  1237 obs/sec      10.0914   30            252285     0.17901          0.119592            0.87182        0.990238        0.904528           2.00641          0.0395446                        0.173622           0.112714              0.879402         0.991322          0.920542             2.02591            0.0362636
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0031621157602852315
C374        0.7986021041870117     0.7986021041870117   0.002525272299846698
C438        0.7927222847938538     0.7927222847938538   0.002506679630275963
C88         0.7510184049606323     0.7510184049606323   0.0023748071345902916
C79         0.7052434682846069     0.7052434682846069   0.0022300614859009733
---         ---                    ---                  ---
C972        0.22127194702625275    0.22127194702625275  0.0006996875110007127
C974        0.22087864577770233    0.22087864577770233  0.0006984438469241316
C746        0.21999818086624146    0.21999818086624146  0.000695659714951223
C978        0.21936596930027008    0.21936596930027008  0.0006936605887946303
C968        0.21733984351158142    0.21733984351158142  0.0006872537445058976

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_93

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.008188790802367812    0.015002764761447906   0.0         0.02313262166324897   0.08166134357452393  0.052011766529831895    0.1469082236289978
    3        2        Softmax                      0.0   0.0   0.00024039515477625173  5.119039269629866e-05  0.0         0.024743330817500464  0.3769662380218506   -0.0014175730545462409  0.04891715943813324


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.026429538412590676
RMSE: 0.16257164086208478
LogLoss: 0.1147752291346453
Mean Per-Class Error: 0.02433881405552274
AUC: 0.9925891405410577
pr_auc: 0.7524797120118468
Gini: 0.9851782810821155
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4785042173540608: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4874  139   0.0277   (139.0/5013.0)
1      105   4907  0.0209   (105.0/5012.0)
Total  4979  5046  0.0243   (244.0/10025.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.478504     0.975741  210
max f2                       0.440602     0.978918  219
max f0point5                 0.611748     0.977473  178
max accuracy                 0.481643     0.975661  209
max precision                0.999376     0.99879   2
max recall                   1.61918e-05  1         399
max specificity              0.999983     0.999601  0
max absolute_mcc             0.478504     0.951344  210
max min_per_class_accuracy   0.513445     0.975259  202
max mean_per_class_accuracy  0.478504     0.975661  210
Gains/Lift Table: Avg response rate: 50.00 %, avg score: 50.06 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100748                   1                  2.0002      2.0002             1                1            1                           1                   0.0201516       0.0201516                  100.02    100.02
    2        0.0200499                   1                  2.0002      2.0002             1                1            1                           1                   0.0199521       0.0401038                  100.02    100.02
    3        0.0300249                   1                  2.0002      2.0002             1                1            1                           1                   0.0199521       0.0600559                  100.02    100.02
    4        0.04                        1                  1.9802      1.99521            0.99             1            0.997506                    1                   0.0197526       0.0798085                  98.0198   99.5211
    5        0.0500748                   1                  1.9804      1.99223            0.990099         1            0.996016                    1                   0.0199521       0.0997606                  98.0396   99.2231
    6        0.10005                     0.999967           2.0002      1.99621            1                0.999991     0.998006                    0.999996            0.0999601       0.199721                   100.02    99.6211
    7        0.150025                    0.999529           2.0002      1.99754            1                0.999828     0.99867                     0.99994             0.0999601       0.299681                   100.02    99.754
    8        0.2                         0.997371           1.99221     1.99621            0.996008         0.998677     0.998005                    0.999624            0.0995611       0.399242                   99.2215   99.6209
    9        0.30005                     0.977255           1.98225     1.99156            0.991027         0.989726     0.995678                    0.996324            0.198324        0.597566                   98.2252   99.1555
    10       0.4                         0.896854           1.97625     1.98773            0.988024         0.944604     0.993766                    0.9834              0.197526        0.795092                   97.6245   98.7729
    11       0.50005                     0.509634           1.80078     1.95032            0.900299         0.763135     0.975065                    0.93933             0.180168        0.975259                   80.0778   95.0324
    12       0.6                         0.108984           0.175666    1.6547             0.0878244        0.249252     0.827265                    0.824374            0.0175579       0.992817                   -82.4334  65.4695
    13       0.69995                     0.0180626          0.0359317   1.42354            0.0179641        0.053264     0.7117                      0.714263            0.00359138      0.996409                   -96.4068  42.3542
    14       0.8                         0.000726973        0.0219364   1.24825            0.0109671        0.00633324   0.624065                    0.625727            0.00219473      0.998603                   -97.8064  24.8254
    15       0.89995                     1.99286e-06        0.0119772   1.11095            0.00598802       0.000145647  0.55542                     0.556249            0.00119713      0.9998                     -98.8023  11.0951
    16       1                           1.84572e-32        0.00199422  1                  0.000997009      2.11258e-07  0.49995                     0.500596            0.000199521     1                          -99.8006  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.026198068772015082
RMSE: 0.16185817486928203
LogLoss: 0.11552992543010915
Mean Per-Class Error: 0.023845340680228033
AUC: 0.9925611852110332
pr_auc: 0.7432147091241138
Gini: 0.9851223704220664
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5288748607830235: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3065  63    0.0201   (63.0/3128.0)
1      84    2965  0.0276   (84.0/3049.0)
Total  3149  3028  0.0238   (147.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.528875     0.97581   191
max f2                       0.375888     0.976922  226
max f0point5                 0.556046     0.978124  185
max accuracy                 0.528875     0.976202  191
max precision                0.993886     0.998662  11
max recall                   3.50682e-05  1         399
max specificity              0.999984     0.999361  0
max absolute_mcc             0.528875     0.952414  191
max min_per_class_accuracy   0.488526     0.975402  199
max mean_per_class_accuracy  0.528875     0.976155  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.36 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  1.9927      2.0128             0.983607         1            0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999968           2.02591     2.01935            1                0.999993     0.996764                    0.999996            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999633           2.02591     2.02154            1                0.999854     0.997843                    0.999949            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.997849           2.02591     2.02263            1                0.99896      0.998382                    0.999702            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.978624           2.00293     2.01607            0.988655         0.990908     0.995143                    0.996774            0.200066        0.604788                   100.293   101.607
    10       0.400032                    0.886021           1.99313     2.01033            0.983819         0.943293     0.992311                    0.983398            0.19941         0.804198                   99.3128   101.033
    11       0.500081                    0.441056           1.74727     1.9577             0.86246          0.732552     0.966332                    0.933213            0.174811        0.97901                    74.7266   95.7702
    12       0.599968                    0.0958152          0.14119     1.65528            0.0696921        0.214886     0.817053                    0.813621            0.014103        0.993112                   -85.881   65.5277
    13       0.700016                    0.0156895          0.0262254   1.42245            0.012945         0.0486083    0.702128                    0.704283            0.00262381      0.995736                   -97.3775  42.2448
    14       0.799903                    0.000798691        0.0328348   1.24892            0.0162075        0.00592638   0.616474                    0.617077            0.00327976      0.999016                   -96.7165  24.8922
    15       0.899951                    2.28246e-06        0.00327817  1.11044            0.00161812       0.000167127  0.54812                     0.548494            0.000327976     0.999344                   -99.6722  11.0442
    16       1                           7.10535e-42        0.00655634  1                  0.00323625       2.6098e-07   0.493605                    0.493618            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:48:50  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:48:55  1:42:13.145  5127 obs/sec      1         1             25000      0.304701         0.388299            0.628629       0.945196        0.636453           1.9804           0.118603                         0.295958           0.374771              0.649579         0.948597          0.646124             1.99323            0.113971
    2019-08-03 17:49:05  1:42:22.621  5456 obs/sec      3         3             75000      0.247293         0.226825            0.755384       0.971534        0.773295           2.0002           0.078404                         0.241445           0.216662              0.766779         0.973571          0.7662               2.02591            0.0705844
    2019-08-03 17:49:14  1:42:31.950  5585 obs/sec      5         5             125000     0.217037         0.180607            0.811579       0.981991        0.773149           2.0002           0.0526683                        0.212322           0.174501              0.819647         0.983442          0.772503             2.02591            0.0503481
    2019-08-03 17:49:23  1:42:40.930  5694 obs/sec      7         7             175000     0.189914         0.145332            0.855731       0.988631        0.771966           2.0002           0.035611                         0.190146           0.14938               0.855354         0.98797           0.781241             2.02591            0.034159
    2019-08-03 17:49:32  1:42:49.676  5792 obs/sec      9         9             225000     0.170311         0.123686            0.883977       0.991842        0.743743           2.0002           0.0274314                        0.16767            0.122849              0.887528         0.991808          0.734483             2.02591            0.0239599
    2019-08-03 17:49:36  1:42:54.419  5818 obs/sec      10        10            250000     0.162572         0.114775            0.894282       0.992589        0.75248            2.0002           0.0243392                        0.161858           0.11553               0.895191         0.992561          0.743215             2.02591            0.023798
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003296232012951773
C34         0.9219603538513184     0.9219603538513184   0.00303899523303706
C24         0.8833199739456177     0.8833199739456177   0.002911627575799271
C35         0.8820815682411194     0.8820815682411194   0.0029075455032710816
C25         0.8788548111915588     0.8788548111915588   0.0028969093633863024
---         ---                    ---                  ---
C330        0.20640473067760468    0.20640473067760468  0.0006803578808842095
C780        0.20270608365535736    0.20270608365535736  0.0006681662821648691
C316        0.20157568156719208    0.20157568156719208  0.0006644402146143511
C475        0.19795916974544525    0.19795916974544525  0.0006525193525722908
C420        0.19559529423713684    0.19559529423713684  0.0006447274704471719

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_128

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.009240168542643626    0.020787514746189117   0.0         0.022798110008820066  0.0804436206817627   0.054271015185487076   0.15945494174957275
    3        2        Softmax                      0.0   0.0   0.00023698349474443603  6.092146213632077e-05  0.0         0.04591810368606275   0.35762226581573486  0.0002619989964014052  0.0876322090625763


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0266625336250695
RMSE: 0.16328666089141972
LogLoss: 0.1155680938722685
Mean Per-Class Error: 0.0241483846415691
AUC: 0.992594341592117
pr_auc: 0.7073580849076927
Gini: 0.985188683184234
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5402455337892723: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4881  135   0.0269   (135.0/5016.0)
1      107   4897  0.0214   (107.0/5004.0)
Total  4988  5032  0.0242   (242.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.540246     0.975887  190
max f2                       0.421552     0.980186  217
max f0point5                 0.634126     0.976626  164
max accuracy                 0.540246     0.975848  190
max precision                0.9994       0.997208  2
max recall                   1.85799e-05  1         399
max specificity              0.999969     0.999003  0
max absolute_mcc             0.540246     0.951712  190
max min_per_class_accuracy   0.564719     0.97442   184
max mean_per_class_accuracy  0.540246     0.975852  190
Gains/Lift Table: Avg response rate: 49.94 %, avg score: 50.76 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100798                   1                  2.0024     2.0024             1                1            1                           1                   0.0201839       0.0201839                  100.24    100.24
    2        0.0200599                   1                  2.0024     2.0024             1                1            1                           1                   0.019984        0.0401679                  100.24    100.24
    3        0.0300399                   1                  2.0024     2.0024             1                1            1                           1                   0.019984        0.0601519                  100.24    100.24
    4        0.04002                     1                  2.0024     2.0024             1                1            1                           1                   0.019984        0.0801359                  100.24    100.24
    5        0.05                        1                  2.0024     2.0024             1                1            1                           1                   0.019984        0.10012                    100.24    100.24
    6        0.1                         0.99998            1.99041    1.9964             0.994012         0.999995     0.997006                    0.999997            0.0995204       0.19964                    99.0408   99.6403
    7        0.15                        0.999721           1.9944     1.99574            0.996008         0.999895     0.996673                    0.999963            0.0997202       0.299361                   99.4404   99.5737
    8        0.2                         0.998254           1.9944     1.9954             0.996008         0.99916      0.996507                    0.999762            0.0997202       0.399081                   99.4404   99.5404
    9        0.3                         0.979517           1.97842    1.98974            0.988024         0.991461     0.993679                    0.996995            0.197842        0.596922                   97.8417   98.9742
    10       0.4                         0.908226           1.95843    1.98191            0.978044         0.951084     0.98977                     0.985518            0.195843        0.792766                   95.8433   98.1914
    11       0.5                         0.55692            1.82454    1.95044            0.911178         0.781029     0.974052                    0.94462             0.182454        0.97522                    82.454    95.044
    12       0.6                         0.125393           0.209832   1.66034            0.10479          0.277303     0.829175                    0.833401            0.0209832       0.996203                   -79.0168  66.0338
    13       0.7                         0.025292           0.0119904  1.42486            0.00598802       0.0653216    0.711577                    0.723675            0.00119904      0.997402                   -98.801   42.486
    14       0.8                         0.00143628         0.0139888  1.2485             0.00698603       0.00985767   0.623503                    0.634448            0.00139888      0.998801                   -98.6011  24.8501
    15       0.9                         6.14852e-06        0.0119904  1.11111            0.00598802       0.000349632  0.55489                     0.563992            0.00119904      1                          -98.801   11.1111
    16       1                           3.81259e-37        0          1                  0                7.63151e-07  0.499401                    0.507593            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.026957595730365522
RMSE: 0.1641876844661789
LogLoss: 0.11562058486267858
Mean Per-Class Error: 0.02375422447844633
AUC: 0.9926862209654921
pr_auc: 0.7021378649243314
Gini: 0.9853724419309842
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5400014309719671: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3043  85    0.0272   (85.0/3128.0)
1      62    2987  0.0203   (62.0/3049.0)
Total  3105  3072  0.0238   (147.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.540001     0.975984  188
max f2                       0.42001      0.979996  214
max f0point5                 0.636589     0.974895  164
max accuracy                 0.540001     0.976202  188
max precision                0.999399     0.997326  2
max recall                   2.97367e-05  1         399
max specificity              0.999974     0.999041  0
max absolute_mcc             0.540001     0.952427  188
max min_per_class_accuracy   0.564447     0.973785  182
max mean_per_class_accuracy  0.540001     0.976246  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.30 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999982           2.0128      2.01935            0.993528         0.999996     0.996764                    0.999998            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999753           2.01935     2.01935            0.996764         0.999908     0.996764                    0.999968            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.998488           2.00624     2.01608            0.990291         0.999238     0.995146                    0.999785            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.980761           2.00293     2.0117             0.988655         0.992245     0.992984                    0.997275            0.200066        0.603477                   100.293   101.17
    10       0.400032                    0.898706           1.98002     2.00377            0.977346         0.949544     0.989073                    0.985337            0.198098        0.801574                   98.0016   100.377
    11       0.500081                    0.507444           1.79644     1.96229            0.886731         0.761614     0.968598                    0.940578            0.179731        0.981305                   79.6438   96.2293
    12       0.599968                    0.116344           0.154324    1.66129            0.076175         0.253033     0.820022                    0.826111            0.0154149       0.99672                    -84.5676  66.129
    13       0.700016                    0.0255471          0.0131127   1.42573            0.00647249       0.0631812    0.703747                    0.717071            0.00131191      0.998032                   -98.6887  42.5727
    14       0.799903                    0.00146432         0.0164174   1.24974            0.00810373       0.00993352   0.616879                    0.628768            0.00163988      0.999672                   -98.3583  24.9742
    15       0.899951                    8.43124e-06        0           1.11081            0                0.000348672  0.5483                      0.558906            0               0.999672                   -100      11.0807
    16       1                           3.1225e-33         0.00327817  1                  0.00161812       1.0194e-06   0.493605                    0.502988            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:31:43  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:31:49  2:25:06.934  4253 obs/sec      1         1             25000      0.30146          0.387297            0.636488       0.943714        0.639973           1.98257          0.115569                         0.296949           0.379252              0.647227         0.945841          0.637491             1.99323            0.113486
    2019-08-03 18:31:59  2:25:16.693  4990 obs/sec      3         3             75000      0.239545         0.216459            0.770472       0.973775        0.782943           2.0024           0.0701597                        0.240037           0.217971              0.769491         0.973951          0.76447              2.02591            0.0710701
    2019-08-03 18:32:08  2:25:25.528  5365 obs/sec      5         5             125000     0.211491         0.170555            0.821085       0.983544        0.801841           2.0024           0.0505988                        0.209876           0.171697              0.823779         0.983659          0.771513             2.02591            0.0480816
    2019-08-03 18:32:16  2:25:34.343  5555 obs/sec      7         7             175000     0.188657         0.141218            0.857635       0.989449        0.808973           2.0024           0.0360279                        0.188669           0.142498              0.857593         0.989244          0.799388             2.02591            0.0343209
    2019-08-03 18:32:25  2:25:43.037  5685 obs/sec      9         9             225000     0.171225         0.124513            0.882728       0.991414        0.770765           2.0024           0.0278443                        0.174426           0.128401              0.878283         0.99071           0.725865             2.02591            0.0270358
    2019-08-03 18:32:30  2:25:47.815  5721 obs/sec      10        10            250000     0.163287         0.115568            0.89335        0.992594        0.707358           2.0024           0.0241517                        0.164188           0.115621              0.892152         0.992686          0.702138             2.02591            0.023798
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0033460431639509513
C27         0.8851771950721741     0.8851771950721741   0.0029618411024565257
C36         0.8737503886222839     0.8737503886222839   0.0029236065148490805
C38         0.8542841076850891     0.8542841076850891   0.0028584714985916307
C31         0.8243608474731445     0.8243608474731445   0.002758346978316328
---         ---                    ---                  ---
C377        0.20580331981182098    0.20580331981182098  0.000688626791374755
C721        0.20012331008911133    0.20012331008911133  0.0006696212336709074
C649        0.19968953728675842    0.19968953728675842  0.0006681698111508866
C573        0.19924835860729218    0.19924835860729218  0.0006666936082463777
C583        0.19286642968654633    0.19286642968654633  0.0006453393986082952

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_223

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 253,864 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0901063942176091    0.15264654159545898    0.0         0.002166404787751182  0.09701910614967346  -0.008876203136033513   0.11816015839576721
    3        2        Softmax                 0.0   0.0   0.001762502183282777  6.401154678314924e-05  0.0         0.02104078386605579   0.27309393882751465  -0.0011466643587007552  0.31526756286621094


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0348243292231464
RMSE: 0.18661277883131797
LogLoss: 0.1267754852977435
Mean Per-Class Error: 0.04366767632023172
AUC: 0.9893866853432624
pr_auc: 0.9103478217682206
Gini: 0.9787733706865247
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49554615273916314: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4841  209   0.0414   (209.0/5050.0)
1      228   4734  0.0459   (228.0/4962.0)
Total  5069  4943  0.0436   (437.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.495546     0.955881  204
max f2                       0.20146      0.966557  286
max f0point5                 0.755995     0.96252   135
max accuracy                 0.495546     0.956352  204
max precision                0.999851     1         0
max recall                   0.000143199  1         399
max specificity              0.999851     1         0
max absolute_mcc             0.495546     0.912702  204
max min_per_class_accuracy   0.468437     0.95526   210
max mean_per_class_accuracy  0.495546     0.956332  204
Gains/Lift Table: Avg response rate: 49.56 %, avg score: 49.15 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   0.99993            2.01773     2.01773            1                0.999959     1                           0.999959            0.0203547       0.0203547                  101.773   101.773
    2        0.0200759                   0.999854           2.01773     2.01773            1                0.99989      1                           0.999924            0.0201532       0.0405079                  101.773   101.773
    3        0.0300639                   0.999773           2.01773     2.01773            1                0.999813     1                           0.999887            0.0201532       0.060661                   101.773   101.773
    4        0.0400519                   0.999682           2.01773     2.01773            1                0.99973      1                           0.999848            0.0201532       0.0808142                  101.773   101.773
    5        0.05004                     0.999593           2.01773     2.01773            1                0.999635     1                           0.999805            0.0201532       0.100967                   101.773   101.773
    6        0.10008                     0.998956           2.01371     2.01572            0.998004         0.999291     0.999002                    0.999548            0.100766        0.201733                   101.371   101.572
    7        0.15002                     0.997844           2.00563     2.01236            0.994            0.998483     0.997337                    0.999194            0.100161        0.301894                   100.563   101.236
    8        0.20006                     0.996059           2.01371     2.0127             0.998004         0.997048     0.997504                    0.998657            0.100766        0.40266                    101.371   101.27
    9        0.30004                     0.986598           2.00161     2.009              0.992008         0.992258     0.995672                    0.996525            0.200121        0.602781                   100.161   100.9
    10       0.40002                     0.937825           1.94718     1.99355            0.965035         0.969296     0.988015                    0.989719            0.19468         0.797461                   94.7185   99.3552
    11       0.5                         0.430885           1.62064     1.91898            0.803197         0.771165     0.951059                    0.946017            0.162031        0.959492                   62.0638   91.8984
    12       0.59998                     0.0397259          0.330578    1.65429            0.163836         0.161435     0.819877                    0.815275            0.0330512       0.992543                   -66.9422  65.4294
    13       0.69996                     0.00723659         0.0584559   1.42635            0.028971         0.0184276    0.706906                    0.701456            0.00584442      0.998388                   -94.1544  42.635
    14       0.79994                     0.00177881         0.0100786   1.24934            0.004995         0.00381852   0.619178                    0.614262            0.00100766      0.999395                   -98.9921  24.9338
    15       0.89992                     0.000413408        0.00403144  1.11099            0.001998         0.000946003  0.55061                     0.546123            0.000403063     0.999798                   -99.5969  11.0986
    16       1                           1.7194e-06         0.00201371  1                  0.000998004      0.000168803  0.495605                    0.491484            0.000201532     1                          -99.7986  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.032313586845607374
RMSE: 0.1797598031975096
LogLoss: 0.11607889423382825
Mean Per-Class Error: 0.04179538970892305
AUC: 0.9911090928307381
pr_auc: 0.9324260775959635
Gini: 0.9822181856614762
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4772001942703072: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3004  124   0.0396   (124.0/3128.0)
1      134   2915  0.0439   (134.0/3049.0)
Total  3138  3039  0.0418   (258.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.4772       0.957622  204
max f2                       0.169766     0.967326  293
max f0point5                 0.75448      0.966927  134
max accuracy                 0.533693     0.958232  191
max precision                0.999893     1         0
max recall                   0.00222689   1         391
max specificity              0.999893     1         0
max absolute_mcc             0.621146     0.916564  170
max min_per_class_accuracy   0.460983     0.957363  209
max mean_per_class_accuracy  0.4772       0.958205  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.98 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999932           2.02591     2.02591            1                0.999964     1                           0.999964            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999866           2.02591     2.02591            1                0.999901     1                           0.999932            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999794           2.02591     2.02591            1                0.999832     1                           0.999899            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999723           2.02591     2.02591            1                0.999756     1                           0.999863            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999613           2.02591     2.02591            1                0.999668     1                           0.999824            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.998987           2.01935     2.02263            0.996764         0.999329     0.998382                    0.999577            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.998022           2.02591     2.02372            1                0.99854      0.998921                    0.999231            0.101345        0.303706                   102.591   102.372
    8        0.200097                    0.996327           2.0128      2.02099            0.993528         0.997242     0.997573                    0.998734            0.100689        0.404395                   101.28    102.099
    9        0.299984                    0.987629           1.99636     2.01279            0.985413         0.992767     0.993524                    0.996747            0.19941         0.603805                   99.6359   101.279
    10       0.400032                    0.940359           1.98329     2.00541            0.978964         0.97257      0.989883                    0.9907              0.198426        0.80223                    98.3294   100.541
    11       0.500081                    0.395418           1.6063      1.92557            0.79288          0.762626     0.950469                    0.945071            0.160708        0.962939                   60.6304   92.5566
    12       0.599968                    0.0363234          0.334915    1.66074            0.165316         0.149668     0.819752                    0.812647            0.0334536       0.996392                   -66.5085  66.0743
    13       0.700016                    0.0069407          0.0295035   1.4276             0.0145631        0.0174427    0.704672                    0.698994            0.00295179      0.999344                   -97.0496  42.7601
    14       0.799903                    0.00175852         0.00656697  1.25015            0.00324149       0.00371725   0.617082                    0.612172            0.000655953     1                          -99.3433  25.0152
    15       0.899951                    0.000371497        0           1.11117            0                0.000905901  0.54848                     0.544217            0               1                          -100      11.1171
    16       1                           1.58342e-06        0           1                  0                0.00015501   0.493605                    0.489784            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:37:28  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:37:35  4:30:53.815  1254 obs/sec      0.33936   1             8484       0.3366           0.369022            0.546766       0.921617        0.86757            1.99776          0.159009                         0.329288           0.35284               0.566208         0.927488          0.89507              2.02591            0.15072
    2019-08-03 20:37:50  4:31:08.259  1253 obs/sec      1.00772   3             25193      0.302829         0.300369            0.633151       0.944965        0.929494           2.01773          0.126149                         0.289906           0.279326              0.663764         0.952429          0.934395             2.02591            0.111381
    2019-08-03 20:38:06  4:31:24.240  1203 obs/sec      1.68604   5             42151      0.299418         0.299099            0.641369       0.94775         0.912107           2.01773          0.121055                         0.28919            0.279329              0.665422         0.95383           0.925735             2.02591            0.111381
    2019-08-03 20:38:21  4:31:39.467  1208 obs/sec      2.37252   7             59313      0.294139         0.284781            0.653902       0.950935        0.93754            2.01773          0.117359                         0.279318           0.260233              0.687875         0.958671          0.943015             2.02591            0.106524
    2019-08-03 20:38:36  4:31:54.108  1219 obs/sec      3.05328   9             76332      0.289451         0.276892            0.664846       0.953734        0.935553           2.01773          0.113863                         0.278967           0.259033              0.688658         0.959293          0.947782             2.02591            0.104258
    2019-08-03 20:38:51  4:32:08.958  1221 obs/sec      3.73256   11            93314      0.283576         0.267051            0.678313       0.956749        0.941005           2.01773          0.108769                         0.271627           0.246211              0.704826         0.963189          0.948268             2.02591            0.0974583
    2019-08-03 20:39:05  4:32:23.827  1223 obs/sec      4.40732   13            110183     0.284744         0.270817            0.675659       0.954982        0.935985           2.01773          0.108869                         0.272426           0.252482              0.703087         0.960569          0.94354              2.02591            0.0984297
    2019-08-03 20:39:20  4:32:38.822  1224 obs/sec      5.09264   15            127316     0.28472          0.26978             0.675714       0.957229        0.943967           2.01773          0.107671                         0.270337           0.246384              0.707624         0.96338           0.952618             2.02591            0.096487
    2019-08-03 20:39:35  4:32:53.633  1226 obs/sec      5.77488   17            144372     0.263505         0.233759            0.722239       0.967955        0.937926           2.01773          0.0911906                        0.255105           0.219648              0.739644         0.971669          0.937427             2.02591            0.08305
    2019-08-03 20:39:50  4:33:08.488  1226 obs/sec      6.4476    19            161190     0.253297         0.218665            0.743343       0.970667        0.947891           2.01773          0.0835997                        0.241536           0.201108              0.766602         0.974971          0.953023             2.02591            0.0778695
    2019-08-03 20:40:05  4:33:23.501  1225 obs/sec      7.126     21            178150     0.252313         0.220579            0.745333       0.970689        0.940522           2.01773          0.0848981                        0.235919           0.193635              0.777332         0.976839          0.935088             2.02591            0.0734985
    2019-08-03 20:40:20  4:33:38.226  1226 obs/sec      7.79696   23            194924     0.229866         0.185124            0.788629       0.978546        0.929099           2.01773          0.0685178                        0.219549           0.168538              0.807161         0.982167          0.958045             2.02591            0.062328
    2019-08-03 20:40:35  4:33:53.117  1226 obs/sec      8.47056   25            211764     0.221062         0.173442            0.804512       0.981098        0.939193           2.01773          0.0635238                        0.209709           0.154769              0.82406          0.984854          0.92969              2.02591            0.0584426
    2019-08-03 20:40:49  4:34:07.726  1227 obs/sec      9.14224   27            228556     0.201843         0.14598             0.837026       0.986268        0.939146           1.99776          0.0509389                        0.192947           0.133743              0.851062         0.988585          0.937948             2.02591            0.0471102
    2019-08-03 20:41:04  4:34:22.474  1228 obs/sec      9.81576   29            245394     0.190243         0.129586            0.85522        0.989055        0.913181           2.01773          0.0461446                        0.180212           0.116299              0.870073         0.991349          0.92019              2.02591            0.0429011
    2019-08-03 20:41:12  4:34:30.358  1229 obs/sec      10.1546   30            253864     0.186613         0.126775            0.860692       0.989387        0.910348           2.01773          0.0436476                        0.17976            0.116079              0.870725         0.991109          0.932426             2.02591            0.0417678
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003323512686467032
C438        0.8097978830337524     0.8097978830337524   0.0026913735377368216
C374        0.7162052989006042     0.7162052989006042   0.0023803173970110706
C88         0.6547372341156006     0.6547372341156006   0.0021760275038855336
C79         0.652155339717865      0.652155339717865    0.0021674465450995414
---         ---                    ---                  ---
C884        0.21191272139549255    0.21191272139549255  0.000704294617981673
C688        0.21169553697109222    0.21169553697109222  0.0007035728027918756
C994        0.21070320904254913    0.21070320904254913  0.000700274788332227
C912        0.20768164098262787    0.20768164098262787  0.0006902325685520552
C632        0.20756743848323822    0.20756743848323822  0.0006898530150965074

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_85

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.007972870644875354   0.009608916938304901   0.0         0.02317535112661424   0.0817338228225708  0.06306565535789674    0.15405911207199097
    3        2        Softmax                      0.0   0.0   0.0002845689105015481  6.272247992455959e-05  0.0         0.023357471465715207  0.3716033697128296  0.0019224042516197623  0.06882455945014954


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.027331844256124605
RMSE: 0.16532345343636096
LogLoss: 0.11563621012460129
Mean Per-Class Error: 0.02565112342410414
AUC: 0.9923056637720951
pr_auc: 0.6860881485370166
Gini: 0.9846113275441901
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5168765141960496: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4839  158   0.0316   (158.0/4997.0)
1      99    4930  0.0197   (99.0/5029.0)
Total  4938  5088  0.0256   (257.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.516877     0.974597  198
max f2                       0.441699     0.980101  215
max f0point5                 0.64919      0.975793  163
max accuracy                 0.519867     0.974367  197
max precision                0.999957     0.996757  0
max recall                   0.000789073  1         397
max specificity              0.999957     0.998999  0
max absolute_mcc             0.516877     0.948797  198
max min_per_class_accuracy   0.560073     0.973584  187
max mean_per_class_accuracy  0.519867     0.974349  197
Gains/Lift Table: Avg response rate: 50.16 %, avg score: 50.91 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   1                  1.99364     1.99364            1                1            1                           1                   0.0200835       0.0200835                  99.3637   99.3637
    2        0.0200479                   1                  1.99364     1.99364            1                1            1                           1                   0.0198847       0.0399682                  99.3637   99.3637
    3        0.0300219                   1                  1.99364     1.99364            1                1            1                           1                   0.0198847       0.0598529                  99.3637   99.3637
    4        0.0400958                   1                  1.99364     1.99364            1                1            1                           1                   0.0200835       0.0799364                  99.3637   99.3637
    5        0.0500698                   1                  1.99364     1.99364            1                1            1                           1                   0.0198847       0.099821                   99.3637   99.3637
    6        0.10004                     0.999982           1.98966     1.99165            0.998004         0.999996     0.999003                    0.999998            0.0994233       0.199244                   98.9658   99.1649
    7        0.15001                     0.99973            1.97772     1.98701            0.992016         0.999897     0.996676                    0.999964            0.0988268       0.298071                   97.772    98.7009
    8        0.20008                     0.99829            1.97775     1.98469            0.992032         0.999193     0.995513                    0.999771            0.0990257       0.397097                   97.7751   98.4692
    9        0.30002                     0.979928           1.96578     1.97839            0.986028         0.991762     0.992354                    0.997103            0.196461        0.593557                   96.5782   97.8393
    10       0.40006                     0.905667           1.96183     1.97425            0.984048         0.951382     0.990277                    0.98567             0.196262        0.789819                   96.1834   97.4252
    11       0.5                         0.569246           1.81855     1.94313            0.912176         0.787416     0.974666                    0.946043            0.181746        0.971565                   81.8547   94.313
    12       0.60004                     0.126654           0.228582    1.65728            0.114656         0.285976     0.831283                    0.835995            0.0228674       0.994432                   -77.1418  65.7277
    13       0.69998                     0.0246677          0.0298449   1.42492            0.0149701        0.0645392    0.714734                    0.72585             0.0029827       0.997415                   -97.0155  42.4919
    14       0.80002                     0.001705           0.0198767   1.24922            0.00997009       0.00949662   0.626605                    0.636273            0.00198847      0.999403                   -98.0123  24.9223
    15       0.89996                     8.77664e-06        0.00596897  1.11116            0.00299401       0.000398366  0.557353                    0.565659            0.00059654      1                          -99.4031  11.116
    16       1                           8.9017e-31         0           1                  0                8.3079e-07   0.501596                    0.509071            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02708633975229142
RMSE: 0.1645792810541212
LogLoss: 0.11644565039276662
Mean Per-Class Error: 0.02377907435165949
AUC: 0.9925713558342469
pr_auc: 0.6838470953014073
Gini: 0.9851427116684939
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5428901746326429: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3049  79    0.0253   (79.0/3128.0)
1      68    2981  0.0223   (68.0/3049.0)
Total  3117  3060  0.0238   (147.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.54289      0.975937  189
max f2                       0.428788     0.979913  211
max f0point5                 0.625961     0.97708   169
max accuracy                 0.54289      0.976202  189
max precision                0.999965     0.997875  0
max recall                   1.83174e-05  1         399
max specificity              0.999965     0.999361  0
max absolute_mcc             0.54289      0.952405  189
max min_per_class_accuracy   0.557649     0.975703  186
max mean_per_class_accuracy  0.54289      0.976221  189
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.24 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999985           2.0128      2.01935            0.993528         0.999996     0.996764                    0.999998            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999774           2.02591     2.02154            1                0.999908     0.997843                    0.999968            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.998478           2.0128      2.01935            0.993528         0.999291     0.996764                    0.999799            0.100689        0.404067                   101.28    101.935
    9        0.299984                    0.980588           1.99636     2.0117             0.985413         0.992563     0.992984                    0.99739             0.19941         0.603477                   99.6359   101.17
    10       0.400032                    0.898259           1.98002     2.00377            0.977346         0.948284     0.989073                    0.985108            0.198098        0.801574                   98.0016   100.377
    11       0.500081                    0.499271           1.79316     1.96164            0.885113         0.758641     0.968275                    0.9398              0.179403        0.980977                   79.316    96.1637
    12       0.599968                    0.118205           0.144473    1.6591             0.0713128        0.253856     0.818942                    0.8256              0.014431        0.995408                   -85.5527  65.9103
    13       0.700016                    0.0245395          0.0262254   1.42573            0.012945         0.0614267    0.703747                    0.716381            0.00262381      0.998032                   -97.3775  42.5727
    14       0.799903                    0.00165812         0.0131339   1.24933            0.00648298       0.00906508   0.616677                    0.628056            0.00131191      0.999344                   -98.6866  24.9332
    15       0.899951                    7.0194e-06         0.00327817  1.11081            0.00161812       0.000356885  0.5483                      0.558274            0.000327976     0.999672                   -99.6722  11.0807
    16       1                           7.3372e-35         0.00327817  1                  0.00161812       7.71744e-07  0.493605                    0.50242             0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:41:59  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:42:04  1:35:22.373  5276 obs/sec      1         1             25000      0.306233         0.391857            0.624881       0.943663        0.644166           1.99364          0.12308                          0.293518           0.363495              0.655333         0.951095          0.658481             1.99323            0.112838
    2019-08-03 17:42:14  1:35:32.221  5366 obs/sec      3         3             75000      0.248791         0.235428            0.75241        0.969717        0.7604             1.99364          0.0775982                        0.241841           0.223473              0.766014         0.97227           0.732639             2.02591            0.069775
    2019-08-03 17:42:23  1:35:41.459  5538 obs/sec      5         5             125000     0.215035         0.172361            0.815038       0.983099        0.758561           1.99364          0.0527628                        0.209821           0.167203              0.823871         0.984437          0.797863             2.02591            0.0479197
    2019-08-03 17:42:32  1:35:50.373  5675 obs/sec      7         7             175000     0.192365         0.143331            0.851981       0.98864         0.790738           1.99364          0.0390983                        0.187863           0.14219               0.858807         0.989208          0.765661             2.02591            0.0357779
    2019-08-03 17:42:41  1:35:59.104  5784 obs/sec      9         9             225000     0.170782         0.11911             0.883333       0.992254        0.771931           1.99364          0.0274287                        0.169427           0.123317              0.885159         0.991729          0.76442              2.02591            0.0260644
    2019-08-03 17:42:46  1:36:03.812  5821 obs/sec      10        10            250000     0.165323         0.115636            0.890672       0.992306        0.686088           1.99364          0.0256334                        0.164579           0.116446              0.891637         0.992571          0.683847             2.02591            0.023798
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0034286066786633866
C28         0.912918210029602      0.912918210029602    0.003130037471980918
C34         0.8947567939758301     0.8947567939758301   0.0030677691196049706
C35         0.8747485876083374     0.8747485876083374   0.00299916884962531
C25         0.8364444375038147     0.8364444375038147   0.0028678389847564185
---         ---                    ---                  ---
C573        0.2002517431974411     0.2002517431974411   0.000686584464140732
C624        0.19899900257587433    0.19899900257587433  0.0006822893092789952
C582        0.19844910502433777    0.19844910502433777  0.0006804039268612162
C589        0.19385385513305664    0.19385385513305664  0.0006646486223938426
C721        0.1874561458826065     0.1874561458826065   0.0006427133937296028

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_120

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.008457643050745419   0.014591898769140244  0.0         0.023203216978457522  0.0830325186252594   0.08400386332671954    0.12574326992034912
    3        2        Softmax                      0.0   0.0   0.0002460117948430707  6.54823670629412e-05  0.0         0.05147352540097927   0.40563273429870605  0.0002791610144102438  0.10592195391654968


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03085364567147338
RMSE: 0.1756520585460739
LogLoss: 0.13221149432691467
Mean Per-Class Error: 0.02947968749937757
AUC: 0.9901124530565856
pr_auc: 0.7177792763687121
Gini: 0.9802249061131711
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5364919505840422: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4890  176   0.0347   (176.0/5066.0)
1      120   4835  0.0242   (120.0/4955.0)
Total  5010  5011  0.0295   (296.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.536492     0.970299  190
max f2                       0.433428     0.975292  218
max f0point5                 0.620672     0.970905  170
max accuracy                 0.536492     0.970462  190
max precision                0.999635     0.995692  1
max recall                   3.08705e-05  1         399
max specificity              0.999971     0.998816  0
max absolute_mcc             0.536492     0.940983  190
max min_per_class_accuracy   0.582949     0.969728  180
max mean_per_class_accuracy  0.536492     0.97052   190
Gains/Lift Table: Avg response rate: 49.45 %, avg score: 50.46 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   1                  2.0224      2.0224             1                1            1                           1                   0.0203835       0.0203835                  102.24    102.24
    2        0.0200579                   1                  2.0224      2.0224             1                1            1                           1                   0.0201816       0.0405651                  102.24    102.24
    3        0.0300369                   1                  2.0224      2.0224             1                1            1                           1                   0.0201816       0.0607467                  102.24    102.24
    4        0.040016                    1                  2.0224      2.0224             1                1            1                           1                   0.0201816       0.0809284                  102.24    102.24
    5        0.0500948                   1                  2.00238     2.01837            0.990099         1            0.998008                    1                   0.0201816       0.10111                    100.238   101.837
    6        0.10009                     0.999971           2.01029     2.01434            0.994012         0.999992     0.996012                    0.999996            0.100505        0.201615                   101.029   101.434
    7        0.150085                    0.999623           2.01433     2.01433            0.996008         0.999848     0.996011                    0.999947            0.100706        0.302321                   101.433   101.433
    8        0.20008                     0.997807           2.00625     2.01231            0.992016         0.998907     0.995012                    0.999687            0.100303        0.402624                   100.625   101.231
    9        0.30007                     0.978535           1.98809     2.00424            0.983034         0.990839     0.991021                    0.996739            0.198789        0.601413                   98.8089   100.424
    10       0.40006                     0.900252           1.96387     1.99415            0.971058         0.946621     0.986031                    0.984213            0.196367        0.79778                    96.3869   99.4152
    11       0.50005                     0.535047           1.7802      1.95137            0.88024          0.768975     0.964877                    0.941174            0.178002        0.975782                   78.0198   95.1369
    12       0.60004                     0.118745           0.181653    1.65647            0.0898204        0.271366     0.819059                    0.829558            0.0181635       0.993946                   -81.8347  65.6466
    13       0.70003                     0.0219566          0.0363306   1.42505            0.0179641        0.0596639    0.704633                    0.719589            0.00363269      0.997578                   -96.3669  42.5051
    14       0.80002                     0.00132078         0.0100918   1.2482             0.00499002       0.00843046   0.617188                    0.630705            0.00100908      0.998587                   -98.9908  24.8203
    15       0.90001                     5.30318e-06        0.00807346  1.11043            0.00399202       0.000292348  0.549063                    0.560667            0.000807265     0.999395                   -99.1927  11.0426
    16       1                           1.53708e-32        0.00605509  1                  0.00299401       5.6671e-07   0.494462                    0.504606            0.000605449     1                          -99.3945  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02773428043007951
RMSE: 0.166536123499016
LogLoss: 0.11704243432198728
Mean Per-Class Error: 0.02588192933996214
AUC: 0.9925543174190691
pr_auc: 0.7136745829108277
Gini: 0.9851086348381382
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5349258344841934: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3042  86    0.0275   (86.0/3128.0)
1      74    2975  0.0243   (74.0/3049.0)
Total  3116  3061  0.0259   (160.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.534926     0.973813  193
max f2                       0.44179      0.979203  216
max f0point5                 0.619041     0.975528  172
max accuracy                 0.534926     0.974097  193
max precision                0.998014     0.998441  4
max recall                   2.26859e-05  1         399
max specificity              0.999976     0.999361  0
max absolute_mcc             0.534926     0.948196  193
max min_per_class_accuracy   0.54785      0.973465  189
max mean_per_class_accuracy  0.534926     0.974118  193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.06 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999979           2.0128      2.01935            0.993528         0.999994     0.996764                    0.999997            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999675           2.02591     2.02154            1                0.999882     0.997843                    0.999959            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.998147           2.02591     2.02263            1                0.999063     0.998382                    0.999735            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.979983           1.99636     2.01388            0.985413         0.991519     0.994064                    0.996999            0.19941         0.604133                   99.6359   101.388
    10       0.400032                    0.893704           1.97346     2.00377            0.97411          0.944618     0.989073                    0.983899            0.197442        0.801574                   97.3459   100.377
    11       0.500081                    0.498388           1.77349     1.9577             0.875405         0.75138      0.966332                    0.93738             0.177435        0.97901                    77.3491   95.7702
    12       0.599968                    0.115309           0.15104     1.65692            0.0745543        0.249719     0.817863                    0.822893            0.0150869       0.994096                   -84.896   65.6917
    13       0.700016                    0.0230398          0.0458944   1.42666            0.0226537        0.0599103    0.704209                    0.713845            0.00459167      0.998688                   -95.4106  42.6664
    14       0.799903                    0.00130955         0.00656697  1.24933            0.00324149       0.00891803   0.616677                    0.625819            0.000655953     0.999344                   -99.3433  24.9332
    15       0.899951                    6.34551e-06        0           1.11044            0                0.000303939  0.54812                     0.556279            0               0.999344                   -100      11.0442
    16       1                           6.02297e-36        0.00655634  1                  0.00323625       7.30391e-07  0.493605                    0.500625            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:20:38  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:20:43  2:14:00.989  5335 obs/sec      1         1             25000      0.31003          0.393246            0.615478       0.940259        0.723089           2.0224           0.127033                         0.299747           0.356256              0.640549         0.946449          0.711922             1.99323            0.117371
    2019-08-03 18:20:53  2:14:10.500  5498 obs/sec      3         3             75000      0.251981         0.235062            0.745991       0.969243        0.780252           2.0224           0.0803313                        0.242541           0.215074              0.764657         0.973624          0.80151              2.02591            0.0715558
    2019-08-03 18:21:01  2:14:19.492  5673 obs/sec      5         5             125000     0.224455         0.192194            0.798455       0.979654        0.815859           2.0224           0.0573795                        0.218373           0.180758              0.809222         0.982193          0.811835             2.02591            0.0532621
    2019-08-03 18:21:10  2:14:28.295  5795 obs/sec      7         7             175000     0.201963         0.16454             0.836824       0.984966        0.757253           2.0224           0.0430097                        0.191574           0.146631              0.853174         0.988369          0.769107             2.02591            0.0378825
    2019-08-03 18:21:19  2:14:37.183  5853 obs/sec      9         9             225000     0.179285         0.136224            0.871412       0.990088        0.757587           2.0224           0.0318332                        0.173089           0.127495              0.880141         0.991334          0.739048             2.02591            0.0278452
    2019-08-03 18:21:24  2:14:41.760  5901 obs/sec      10        10            250000     0.175652         0.132211            0.87657        0.990112        0.717779           2.0224           0.029538                         0.166536           0.117042              0.889045         0.992554          0.713675             2.02591            0.0259025
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.00394830902648366
C28         0.8929034471511841     0.8929034471511841   0.003525458740165396
C34         0.8143764138221741     0.8143764138221741   0.0032154097456494825
C31         0.7887666821479797     0.7887666821479797   0.0031142946109144363
C40         0.7516692876815796     0.7516692876815796   0.0029678226334837235
---         ---                    ---                  ---
C583        0.1642097681760788     0.1642097681760788   0.0006483509099264012
C626        0.1641659289598465     0.1641659289598465   0.0006481778191532372
C388        0.16347554326057434    0.16347554326057434  0.0006454519630650457
C745        0.16344432532787323    0.16344432532787323  0.0006453287050195738
C637        0.15662707388401031    0.15662707388401031  0.0006184120896079611

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_227

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.010140519371542705    0.028083160519599915   0.0         0.02143662857366148   0.07366043329238892  0.035369506925789385    0.15979188680648804
    3        2        Softmax                      0.0   0.0   0.00024005830638884618  7.189533789642155e-05  0.0         0.029209408508904744  0.3656485080718994   0.00010780788059552154  0.015454046428203583


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.029968418560433436
RMSE: 0.17311388898766453
LogLoss: 0.12506171885213435
Mean Per-Class Error: 0.02879983450364343
AUC: 0.9913229363006664
pr_auc: 0.713340971961687
Gini: 0.9826458726013327
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47649272687465966: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4806  173   0.0347   (173.0/4979.0)
1      115   4917  0.0229   (115.0/5032.0)
Total  4921  5090  0.0288   (288.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.476493     0.971547  210
max f2                       0.409474     0.976439  226
max f0point5                 0.593896     0.973279  180
max accuracy                 0.476493     0.971232  210
max precision                0.998507     0.998375  3
max recall                   1.98724e-05  1         399
max specificity              0.999955     0.999397  0
max absolute_mcc             0.476493     0.942521  210
max min_per_class_accuracy   0.523455     0.97039   198
max mean_per_class_accuracy  0.476493     0.9712    210
Gains/Lift Table: Avg response rate: 50.26 %, avg score: 50.18 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   1                  1.98947     1.98947            1                1            1                           1                   0.0200715       0.0200715                  98.9467   98.9467
    2        0.0200779                   1                  1.98947     1.98947            1                1            1                           1                   0.0198728       0.0399444                  98.9467   98.9467
    3        0.0300669                   1                  1.98947     1.98947            1                1            1                           1                   0.0198728       0.0598172                  98.9467   98.9467
    4        0.0400559                   1                  1.98947     1.98947            1                1            1                           1                   0.0198728       0.07969                    98.9467   98.9467
    5        0.050045                    0.999999           1.98947     1.98947            1                1            1                           1                   0.0198728       0.0995628                  98.9467   98.9467
    6        0.10009                     0.999961           1.9855      1.98748            0.998004         0.999989     0.999002                    0.999995            0.0993641       0.198927                   98.5496   98.7482
    7        0.150035                    0.99956            1.98151     1.98549            0.996            0.999821     0.998003                    0.999937            0.0989666       0.297893                   98.151    98.5494
    8        0.20008                     0.997176           1.98153     1.9845             0.996008         0.998645     0.997504                    0.999614            0.0991653       0.397059                   98.1525   98.4501
    9        0.30007                     0.973374           1.96562     1.97821            0.988012         0.988292     0.994341                    0.995841            0.196542        0.593601                   96.5618   97.8209
    10       0.40006                     0.880732           1.94773     1.97059            0.979021         0.935415     0.990512                    0.980738            0.194754        0.788355                   94.773    97.0591
    11       0.50005                     0.53885            1.80264     1.93701            0.906094         0.748425     0.973632                    0.934285            0.180246        0.968601                   80.2644   93.7008
    12       0.60004                     0.123666           0.246448    1.6553             0.123876         0.272805     0.832029                    0.824057            0.0246423       0.993243                   -75.3552  65.5295
    13       0.70003                     0.0229994          0.0317997   1.4234             0.015984         0.064489     0.715468                    0.715563            0.00317965      0.996423                   -96.82    42.34
    14       0.80002                     0.00125662         0.0178873   1.24773            0.00899101       0.00873188   0.627169                    0.62722             0.00178855      0.998211                   -98.2113  24.7733
    15       0.90001                     4.96084e-06        0.0139124   1.11066            0.00699301       0.000272597  0.558269                    0.557567            0.0013911       0.999603                   -98.6088  11.0657
    16       1                           7.4727e-36         0.00397496  1                  0.001998         5.30152e-07  0.502647                    0.501816            0.000397456     1                          -99.6025  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02780109623042241
RMSE: 0.1667366073495032
LogLoss: 0.11768299070040118
Mean Per-Class Error: 0.025385823115876338
AUC: 0.9928626340949487
pr_auc: 0.7349751287799114
Gini: 0.9857252681898974
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48211726206811095: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3041  87    0.0278   (87.0/3128.0)
1      70    2979  0.023    (70.0/3049.0)
Total  3111  3066  0.0254   (157.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.482117     0.974325  201
max f2                       0.401076     0.978927  220
max f0point5                 0.566129     0.976633  181
max accuracy                 0.509203     0.974583  194
max precision                0.996996     0.998437  5
max recall                   2.82763e-05  1         399
max specificity              0.999978     0.999361  0
max absolute_mcc             0.482117     0.949176  201
max min_per_class_accuracy   0.497505     0.973785  197
max mean_per_class_accuracy  0.482117     0.974614  201
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999967           2.0128      2.01935            0.993528         0.999992     0.996764                    0.999996            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999526           2.02591     2.02154            1                0.99982      0.997843                    0.999937            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.997109           2.02591     2.02263            1                0.998638     0.998382                    0.999612            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.969973           2.00621     2.01716            0.990276         0.987628     0.995683                    0.995622            0.200394        0.605116                   100.621   101.716
    10       0.400032                    0.862073           1.98985     2.01033            0.982201         0.928825     0.992311                    0.978916            0.199082        0.804198                   98.985    101.033
    11       0.500081                    0.450635           1.75382     1.95901            0.865696         0.711203     0.96698                     0.925356            0.175467        0.979665                   75.3822   95.9014
    12       0.599968                    0.10948            0.144473    1.65692            0.0713128        0.237081     0.817863                    0.810767            0.014431        0.994096                   -85.5527  65.6917
    13       0.700016                    0.0194549          0.0262254   1.42385            0.012945         0.0563245    0.702821                    0.70294             0.00262381      0.99672                    -97.3775  42.3853
    14       0.799903                    0.00118578         0.0229844   1.24892            0.0113452        0.00749767   0.616474                    0.616098            0.00229583      0.999016                   -97.7016  24.8922
    15       0.899951                    4.9439e-06         0.00655634  1.11081            0.00323625       0.00025339   0.5483                      0.547633            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           2.72891e-40        0.00327817  1                  0.00161812       4.62495e-07  0.493605                    0.492844            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:45:53  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:45:58  4:39:16.244  5379 obs/sec      1         1             25000      0.30871          0.439299            0.618782       0.941463        0.671028           1.98947          0.119269                         0.301963           0.415207              0.635214         0.946602          0.653876             2.02591            0.117209
    2019-08-03 20:46:08  4:39:25.885  5493 obs/sec      3         3             75000      0.245159         0.232681            0.759582       0.970756        0.748936           1.98947          0.0744181                        0.236589           0.219162              0.776066         0.973951          0.724884             2.02591            0.0679942
    2019-08-03 20:46:17  4:39:34.919  5660 obs/sec      5         5             125000     0.215344         0.177975            0.814503       0.981703        0.742103           1.98947          0.0520428                        0.206539           0.166536              0.829338         0.984537          0.753736             2.02591            0.0471102
    2019-08-03 20:46:26  4:39:43.735  5774 obs/sec      7         7             175000     0.192176         0.147245            0.852269       0.987848        0.767848           1.98947          0.037259                         0.185084           0.14177               0.862954         0.989201          0.770665             2.02591            0.0328638
    2019-08-03 20:46:34  4:39:52.263  5884 obs/sec      9         9             225000     0.173114         0.125062            0.880123       0.991323        0.713341           1.98947          0.0287684                        0.166737           0.117683              0.888777         0.992863          0.734975             2.02591            0.0254169
    2019-08-03 20:46:39  4:39:56.995  5909 obs/sec      10        10            250000     0.172514         0.129809            0.880952       0.990025        0.691963           1.98947          0.0278693                        0.167666           0.12374               0.887534         0.991388          0.688771             2.02591            0.0244455
    2019-08-03 20:46:40  4:39:57.677  5907 obs/sec      10        10            250000     0.173114         0.125062            0.880123       0.991323        0.713341           1.98947          0.0287684                        0.166737           0.117683              0.888777         0.992863          0.734975             2.02591            0.0254169
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0032666461429516494
C40         0.9556251168251038     0.9556251168251038   0.0031216891019844443
C31         0.9177402257919312     0.9177402257919312   0.002997932568814788
C28         0.9065751433372498     0.9065751433372498   0.0029614601952784657
C35         0.8682902455329895     0.8682902455329895   0.0028363969815328807
---         ---                    ---                  ---
C599        0.2128170132637024     0.2128170132637024   0.0006951978755323635
C726        0.2110314518213272     0.2110314518213272   0.0006893650781336254
C305        0.2060984969139099     0.2060984969139099   0.0006732508600119562
C629        0.20596855878829956    0.20596855878829956  0.0006728263981351088
C734        0.19202105700969696    0.19202105700969696  0.0006272648452462253

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_11

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.010524902690545155    0.026869483292102814   0.0         0.0227232482624882    0.08030888438224792  0.06621491605517398     0.13895177841186523
    3        2        Softmax                      0.0   0.0   0.00028259677293362984  7.829029345884919e-05  0.0         -0.05308737371888128  0.3917280435562134   -0.0004238923137732248  0.10582882165908813


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.027627522904596618
RMSE: 0.1662152908266764
LogLoss: 0.11929689089695045
Mean Per-Class Error: 0.02490729942333947
AUC: 0.9920719310061016
pr_auc: 0.704865185074521
Gini: 0.9841438620122032
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.535496488754356: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4897  139   0.0276   (139.0/5036.0)
1      111   4886  0.0222   (111.0/4997.0)
Total  5008  5025  0.0249   (250.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.535496     0.975055  194
max f2                       0.488401     0.978816  205
max f0point5                 0.613044     0.975733  176
max accuracy                 0.54367      0.975082  192
max precision                0.999968     0.996523  0
max recall                   4.18671e-05  1         399
max specificity              0.999968     0.999007  0
max absolute_mcc             0.535496     0.95018   194
max min_per_class_accuracy   0.552185     0.974186  190
max mean_per_class_accuracy  0.535496     0.975093  194
Gains/Lift Table: Avg response rate: 49.81 %, avg score: 50.61 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   1                  2.0078      2.0078             1                1            1                           1                   0.0202121       0.0202121                  100.78    100.78
    2        0.0200339                   1                  2.0078      2.0078             1                1            1                           1                   0.020012        0.0402241                  100.78    100.78
    3        0.030001                    1                  2.0078      2.0078             1                1            1                           1                   0.020012        0.0602361                  100.78    100.78
    4        0.0400678                   1                  2.0078      2.0078             1                1            1                           1                   0.0202121       0.0804483                  100.78    100.78
    5        0.0500349                   1                  2.0078      2.0078             1                1            1                           1                   0.020012        0.10046                    100.78    100.78
    6        0.10007                     0.999981           1.99581     2.00181            0.994024         0.999996     0.997012                    0.999998            0.0998599       0.20032                    99.5806   100.181
    7        0.150005                    0.999652           1.99979     2.00113            0.996008         0.999881     0.996678                    0.999959            0.0998599       0.30018                    99.9789   100.113
    8        0.20004                     0.997944           1.99581     1.9998             0.994024         0.998964     0.996014                    0.99971             0.0998599       0.40004                    99.5806   99.9801
    9        0.30001                     0.979733           1.98578     1.99513            0.989033         0.991273     0.993688                    0.996899            0.198519        0.598559                   98.5785   99.5131
    10       0.39998                     0.900937           1.96577     1.98779            0.979063         0.949887     0.990032                    0.985149            0.196518        0.795077                   96.5767   98.7792
    11       0.50005                     0.538346           1.81782     1.95378            0.905378         0.776656     0.973091                    0.943425            0.181909        0.976986                   81.7823   95.3778
    12       0.60002                     0.123541           0.172155    1.65694            0.0857428        0.2745       0.825249                    0.831975            0.0172103       0.994197                   -82.7845  65.6939
    13       0.69999                     0.0212156          0.0320288   1.42488            0.0159521        0.0611542    0.709668                    0.721889            0.00320192      0.997398                   -96.7971  42.4875
    14       0.79996                     0.00114701         0.0140126   1.24856            0.00697906       0.00775603   0.621854                    0.632645            0.00140084      0.998799                   -98.5987  24.8561
    15       0.89993                     4.58969e-06        0.0080072   1.11075            0.00398804       0.000245465  0.553217                    0.562394            0.00080048      0.9996                     -99.1993  11.0753
    16       1                           2.69241e-37        0.00399961  1                  0.00199203       4.761e-07    0.498056                    0.506115            0.00040024      1                          -99.6     0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.02752073231303657
RMSE: 0.1658937380163476
LogLoss: 0.11901607960271333
Mean Per-Class Error: 0.023480089484708033
AUC: 0.9919233193726675
pr_auc: 0.6795958967073052
Gini: 0.9838466387453351
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5484798112351842: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3056  72    0.023    (72.0/3128.0)
1      73    2976  0.0239   (73.0/3049.0)
Total  3129  3048  0.0235   (145.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.54848      0.976218  189
max f2                       0.480783     0.977692  201
max f0point5                 0.615648     0.978326  174
max accuracy                 0.54848      0.976526  189
max precision                0.996502     0.997104  6
max recall                   2.79624e-05  1         399
max specificity              0.999956     0.998721  0
max absolute_mcc             0.54848      0.953044  189
max min_per_class_accuracy   0.54848      0.976058  189
max mean_per_class_accuracy  0.54848      0.97652   189
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.19 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999982           2.01935     2.01935            0.996764         0.999995     0.996764                    0.999998            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999759           2.01935     2.01935            0.996764         0.999897     0.996764                    0.999964            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.998171           2.01935     2.01935            0.996764         0.999125     0.996764                    0.999754            0.101017        0.404067                   101.935   101.935
    9        0.299984                    0.979166           2.00621     2.01498            0.990276         0.991635     0.994603                    0.997051            0.200394        0.60446                    100.621   101.498
    10       0.400032                    0.896966           1.96362     2.00213            0.969256         0.947593     0.988264                    0.984681            0.196458        0.800918                   96.3625   100.213
    11       0.500081                    0.480468           1.79316     1.96033            0.885113         0.758166     0.967627                    0.939364            0.179403        0.980321                   79.316    96.0325
    12       0.599968                    0.11915            0.128056    1.65528            0.0632091        0.252217     0.817053                    0.824963            0.0127911       0.993112                   -87.1944  65.5277
    13       0.700016                    0.0216394          0.0524507   1.4262             0.02589          0.061936     0.703978                    0.715909            0.00524762      0.99836                    -94.7549  42.6196
    14       0.799903                    0.00113543         0.00656697  1.24892            0.00324149       0.00757866   0.616474                    0.627457            0.000655953     0.999016                   -99.3433  24.8922
    15       0.899951                    4.38097e-06        0.00655634  1.11081            0.00323625       0.000265278  0.5483                      0.557731            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           2.69241e-37        0.00327817  1                  0.00161812       4.7615e-07   0.493605                    0.501931            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:19:49  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:19:54  13 min 12.041 sec  5149 obs/sec      1         1             25000      0.305983         0.408157            0.625491       0.942985        0.646617           2.0078           0.123991                         0.297343           0.369609              0.64629          0.948566          0.61277              2.02591            0.116076
    2019-08-03 16:20:04  13 min 21.635 sec  5429 obs/sec      3         3             75000      0.25032          0.237366            0.749356       0.969867        0.752422           2.0078           0.0762484                        0.247477           0.231081              0.75498          0.970903          0.748171             2.02591            0.0717177
    2019-08-03 16:20:13  13 min 30.865 sec  5575 obs/sec      5         5             125000     0.217614         0.184301            0.810574       0.981358        0.805733           2.0078           0.0545201                        0.212501           0.178115              0.819343         0.982527          0.803183             2.02591            0.0485673
    2019-08-03 16:20:22  13 min 39.575 sec  5734 obs/sec      7         7             175000     0.193632         0.153694            0.850025       0.987141        0.784853           2.0078           0.038473                         0.189843           0.148543              0.855815         0.987845          0.765776             2.02591            0.034159
    2019-08-03 16:20:30  13 min 48.060 sec  5861 obs/sec      9         9             225000     0.17396          0.128181            0.87895        0.991333        0.749575           2.0078           0.0280076                        0.171803           0.127464              0.881915         0.99175           0.766389             2.02591            0.0254169
    2019-08-03 16:20:35  13 min 52.665 sec  5899 obs/sec      10        10            250000     0.166215         0.119297            0.889488       0.992072        0.704865           2.0078           0.0249178                        0.165894           0.119016              0.889899         0.991923          0.679596             2.02591            0.0234742
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.00341290777580608
C28         0.9708701372146606     0.9708701372146606   0.0033134902405978313
C36         0.9383822679519653     0.9383822679519653   0.0032026121389718072
C27         0.9108120203018188     0.9108120203018188   0.0031085174263857226
C38         0.8634155988693237     0.8634155988693237   0.0029467578111333783
---         ---                    ---                  ---
C938        0.20248037576675415    0.20248037576675415  0.0006910468489024922
C631        0.19864000380039215    0.19864000380039215  0.0006779400135565076
C478        0.19771240651607513    0.19771240651607513  0.0006747742095720455
C534        0.19452844560146332    0.19452844560146332  0.0006639076446087042
C396        0.19357042014598846    0.19357042014598846  0.000660637992082294

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_114

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.007257632296922362    0.012213174253702164    0.0         0.022950513717268906   0.07978662848472595  0.07253817834885563     0.12429949641227722
    3        2        Softmax                      0.0   0.0   0.00021168671830196217  5.5924130720086396e-05  0.0         -0.026800424600878614  0.3835442066192627   -0.0001350092488786661  0.10481148958206177


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.02759282083372921
RMSE: 0.16611086910172138
LogLoss: 0.11629002428859876
Mean Per-Class Error: 0.02527312119387004
AUC: 0.9921858419135573
pr_auc: 0.6969114052829192
Gini: 0.9843716838271146
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4806338528063289: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4833  148   0.0297   (148.0/4981.0)
1      105   4935  0.0208   (105.0/5040.0)
Total  4938  5083  0.0252   (253.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.480634     0.975007  209
max f2                       0.408291     0.978806  228
max f0point5                 0.584782     0.976187  184
max accuracy                 0.480634     0.974753  209
max precision                0.999952     0.997988  0
max recall                   2.68415e-05  1         399
max specificity              0.999952     0.999398  0
max absolute_mcc             0.480634     0.949537  209
max min_per_class_accuracy   0.529826     0.974008  197
max mean_per_class_accuracy  0.480634     0.974727  209
Gains/Lift Table: Avg response rate: 50.29 %, avg score: 50.18 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   1                  1.98829     1.98829            1                1            1                           1                   0.0200397       0.0200397                  98.8294   98.8294
    2        0.0200579                   1                  1.98829     1.98829            1                1            1                           1                   0.0198413       0.039881                   98.8294   98.8294
    3        0.0300369                   1                  1.98829     1.98829            1                1            1                           1                   0.0198413       0.0597222                  98.8294   98.8294
    4        0.040016                    1                  1.98829     1.98829            1                1            1                           1                   0.0198413       0.0795635                  98.8294   98.8294
    5        0.0500948                   1                  1.98829     1.98829            1                1            1                           1                   0.0200397       0.0996032                  98.8294   98.8294
    6        0.10009                     0.999975           1.98036     1.98433            0.996008         0.999993     0.998006                    0.999997            0.0990079       0.198611                   98.0356   98.4329
    7        0.150085                    0.999616           1.98433     1.98433            0.998004         0.999855     0.998005                    0.999949            0.0992063       0.297817                   98.4325   98.4328
    8        0.20008                     0.997654           1.98036     1.98334            0.996008         0.998875     0.997506                    0.999681            0.0990079       0.396825                   98.0356   98.3335
    9        0.30007                     0.977336           1.96845     1.97838            0.99002          0.990358     0.995012                    0.996574            0.196825        0.593651                   96.845    97.8375
    10       0.40006                     0.892489           1.94464     1.96994            0.978044         0.943941     0.990771                    0.983419            0.194444        0.788095                   94.4639   96.9943
    11       0.50005                     0.55032            1.81963     1.93989            0.91517          0.766821     0.975654                    0.940108            0.181944        0.97004                    81.9626   93.9886
    12       0.60004                     0.108239           0.232166    1.65531            0.116766         0.25697      0.83253                     0.826271            0.0232143       0.993254                   -76.7834  65.5313
    13       0.70003                     0.0186076          0.0476238   1.42568            0.0239521        0.0533562    0.717035                    0.71587             0.0047619       0.998016                   -95.2376  42.5676
    14       0.80002                     0.00103034         0.00992163  1.24873            0.00499002       0.00688095   0.62804                     0.627258            0.000992063     0.999008                   -99.0078  24.8729
    15       0.90001                     4.84486e-06        0.00595298  1.11066            0.00299401       0.000244784  0.558599                    0.557597            0.000595238     0.999603                   -99.4047  11.0658
    16       1                           2.95839e-34        0.00396865  1                  0.00199601       5.41748e-07  0.502944                    0.501843            0.000396825     1                          -99.6031  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.027463171532003252
RMSE: 0.16572016030647344
LogLoss: 0.11924797925574918
Mean Per-Class Error: 0.023316101291857905
AUC: 0.9920892997494463
pr_auc: 0.7387157665217938
Gini: 0.9841785994988925
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5293148403417505: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3056  72    0.023    (72.0/3128.0)
1      72    2977  0.0236   (72.0/3049.0)
Total  3128  3049  0.0233   (144.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.529315     0.976386  198
max f2                       0.439977     0.979995  216
max f0point5                 0.58375      0.978499  186
max accuracy                 0.534825     0.976688  197
max precision                0.999979     0.997413  0
max recall                   2.17139e-05  1         399
max specificity              0.999979     0.999361  0
max absolute_mcc             0.529315     0.953368  198
max min_per_class_accuracy   0.529315     0.976386  198
max mean_per_class_accuracy  0.529315     0.976684  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.51 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999968           2.01935     2.01935            0.996764         0.999992     0.996764                    0.999996            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999598           2.01935     2.01935            0.996764         0.999835     0.996764                    0.999942            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.997497           2.0128      2.01771            0.993528         0.998761     0.995955                    0.999647            0.100689        0.403739                   101.28    101.771
    9        0.299984                    0.971957           2.00949     2.01498            0.991896         0.988451     0.994603                    0.995919            0.200722        0.60446                    100.949   101.498
    10       0.400032                    0.881374           1.98002     2.00623            0.977346         0.935728     0.990287                    0.980865            0.198098        0.802558                   98.0016   100.623
    11       0.500081                    0.454578           1.78988     1.96295            0.883495         0.73282      0.968922                    0.93124             0.179075        0.981633                   78.9882   96.2949
    12       0.599968                    0.105762           0.118205    1.65582            0.0583468        0.232164     0.817323                    0.814853            0.0118071       0.99344                    -88.1795  65.5823
    13       0.700016                    0.0195732          0.0458944   1.42573            0.0226537        0.0544075    0.703747                    0.706168            0.00459167      0.998032                   -95.4106  42.5727
    14       0.799903                    0.00114869         0.00985045  1.24892            0.00486224       0.00741063   0.616474                    0.618912            0.000983929     0.999016                   -99.015   24.8922
    15       0.899951                    4.74527e-06        0.00327817  1.11044            0.00161812       0.000259119  0.54812                     0.550135            0.000327976     0.999344                   -99.6722  11.0442
    16       1                           2.95839e-34        0.00655634  1                  0.00323625       5.35144e-07  0.493605                    0.495095            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:16:24  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:16:29  2:09:46.882  5137 obs/sec      1         1             25000      0.299524         0.396357            0.641128       0.943538        0.664329           1.96861          0.111167                         0.299182           0.389828              0.641901         0.944586          0.618864             1.99323            0.111057
    2019-08-03 18:16:39  2:09:57.740  5131 obs/sec      3         3             75000      0.239319         0.217906            0.770897       0.973891        0.778422           1.98829          0.0687556                        0.241545           0.217156              0.766586         0.973438          0.773522             2.02591            0.0722033
    2019-08-03 18:16:53  2:10:11.149  5476 obs/sec      6         6             150000     0.206254         0.166855            0.829832       0.984344        0.761342           1.98829          0.0456042                        0.202622           0.163209              0.83575          0.984929          0.768735             2.02591            0.0427392
    2019-08-03 18:17:02  2:10:20.101  5604 obs/sec      8         8             200000     0.186039         0.141995            0.861553       0.988624        0.746117           1.98829          0.0347271                        0.187191           0.143841              0.859815         0.988358          0.716678             2.02591            0.0333495
    2019-08-03 18:17:11  2:10:28.690  5731 obs/sec      10        10            250000     0.166111         0.11629             0.889625       0.992186        0.696911           1.98829          0.025247                         0.16572            0.119248              0.890129         0.992089          0.738716             2.02591            0.0233123
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0035273657118391377
C28         0.834674060344696      0.834674060344696    0.002944200661021432
C35         0.8073950409889221     0.8073950409889221   0.002847977583493279
C34         0.7928174138069153     0.7928174138069153   0.002796556961211494
C27         0.7905207872390747     0.7905207872390747   0.0027884559194031946
---         ---                    ---                  ---
C544        0.19317446649074554    0.19317446649074554  0.0006813969895022743
C985        0.19045095145702362    0.19045095145702362  0.0006717901559566452
C467        0.18887269496917725    0.18887269496917725  0.0006662230681369282
C604        0.1884675920009613     0.1884675920009613   0.0006647941218170791
C583        0.18815043568611145    0.18815043568611145  0.0006636753955067844

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_89

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 265,208 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.03962041055048099    0.06285825371742249     0.0         0.0033767598154191376  0.11246863007545471  -0.0069438759953083795  0.15531617403030396
    3        2        Softmax                 0.0   0.0   0.0017153202552435687  1.5117693692445755e-05  0.0         -0.016786760272111678  0.37594521045684814  0.0014627074881506108   0.2716033458709717


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.038120883076993003
RMSE: 0.19524569925351237
LogLoss: 0.13719726591957998
Mean Per-Class Error: 0.048874139936229355
AUC: 0.9883914171329781
pr_auc: 0.9568359405977829
Gini: 0.9767828342659561
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4245882762496063: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4659  292   0.059    (292.0/4951.0)
1      197   4879  0.0388   (197.0/5076.0)
Total  4856  5171  0.0488   (489.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.424588     0.952279  221
max f2                       0.297052     0.96309   253
max f0point5                 0.761042     0.960093  135
max accuracy                 0.438668     0.951232  218
max precision                0.999498     1         0
max recall                   0.00364196   1         392
max specificity              0.999498     1         0
max absolute_mcc             0.424588     0.902587  221
max min_per_class_accuracy   0.505228     0.949909  202
max mean_per_class_accuracy  0.438668     0.951126  218
Gains/Lift Table: Avg response rate: 50.62 %, avg score: 50.20 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   0.999403           1.97537     1.97537            1                0.999635    1                           0.999635            0.0198976       0.0198976                  97.5374   97.5374
    2        0.0200459                   0.999068           1.97537     1.97537            1                0.999247    1                           0.999442            0.0197006       0.0395981                  97.5374   97.5374
    3        0.0300189                   0.998729           1.95562     1.96881            0.99             0.998894    0.996678                    0.99926             0.0195035       0.0591017                  95.5621   96.8812
    4        0.0400918                   0.998411           1.97537     1.97046            1                0.998573    0.997512                    0.999087            0.0198976       0.0789992                  97.5374   97.046
    5        0.0500648                   0.997976           1.97537     1.97144            1                0.998185    0.998008                    0.998908            0.0197006       0.0986998                  97.5374   97.1439
    6        0.10003                     0.995698           1.97537     1.9734             1                0.996868    0.999003                    0.997889            0.0986998       0.1974                     97.5374   97.3405
    7        0.149995                    0.992633           1.97143     1.97275            0.998004         0.994299    0.99867                     0.996693            0.0985028       0.295902                   97.1431   97.2747
    8        0.20006                     0.988186           1.97144     1.97242            0.998008         0.990607    0.998504                    0.99517             0.0986998       0.394602                   97.1439   97.242
    9        0.29999                     0.968885           1.96355     1.96946            0.994012         0.980024    0.997008                    0.990125            0.196217        0.59082                    96.3546   96.9464
    10       0.40002                     0.907294           1.92023     1.95715            0.972084         0.944918    0.990775                    0.97882             0.19208         0.7829                     92.0229   95.7152
    11       0.50005                     0.54285            1.60708     1.88712            0.813559         0.779495    0.955325                    0.938947            0.160757        0.943656                   60.7084   88.7125
    12       0.59998                     0.0901459          0.455401    1.64866            0.230539         0.256251    0.834608                    0.82524             0.0455083       0.989165                   -54.4599  64.8663
    13       0.70001                     0.024385           0.0689313   1.42292            0.0348953        0.0488337   0.720331                    0.714293            0.00689519      0.99606                    -93.1069  42.2922
    14       0.79994                     0.00769055         0.0315429   1.24911            0.0159681        0.0144872   0.63234                     0.626872            0.00315209      0.999212                   -96.8457  24.9108
    15       0.89997                     0.00224826         0.00787786  1.11115            0.00398804       0.00449998  0.5625                      0.557697            0.000788022     1                          -99.2122  11.1148
    16       1                           1.05061e-05        0           1                  0                0.00110494  0.506233                    0.502021            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.037556876041752715
RMSE: 0.19379596497799617
LogLoss: 0.13445495444827474
Mean Per-Class Error: 0.047095175643517395
AUC: 0.9888303489719072
pr_auc: 0.97329649357587
Gini: 0.9776606979438145
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4944826300007344: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2977  151   0.0483   (151.0/3128.0)
1      140   2909  0.0459   (140.0/3049.0)
Total  3117  3060  0.0471   (291.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.494483     0.952365  208
max f2                       0.303423     0.963023  252
max f0point5                 0.650698     0.957533  168
max accuracy                 0.494483     0.95289   208
max precision                0.9997       1         0
max recall                   0.00355449   1         391
max specificity              0.9997       1         0
max absolute_mcc             0.494483     0.905774  208
max min_per_class_accuracy   0.511362     0.952366  205
max mean_per_class_accuracy  0.494483     0.952905  208
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.22 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999419           2.02591     2.02591            1                0.999659     1                           0.999659            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999062           2.02591     2.02591            1                0.999251     1                           0.999455            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.99869            2.02591     2.02591            1                0.998891     1                           0.999267            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998323           2.02591     2.02591            1                0.998527     1                           0.999082            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.997893           2.02591     2.02591            1                0.9981       1                           0.998888            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.995507           2.02591     2.02591            1                0.996732     1                           0.99781             0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.99235            2.01935     2.02372            0.996764         0.993986     0.998921                    0.996535            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.987733           2.01935     2.02263            0.996764         0.990302     0.998382                    0.994977            0.101017        0.404723                   101.935   102.263
    9        0.299984                    0.968263           2.00949     2.01826            0.991896         0.979937     0.996222                    0.989969            0.200722        0.605444                   100.949   101.826
    10       0.400032                    0.902251           1.96362     2.00459            0.969256         0.944305     0.989478                    0.978548            0.196458        0.801902                   96.3625   100.459
    11       0.500081                    0.458357           1.55713     1.91507            0.768608         0.744339     0.94529                     0.931691            0.155789        0.957691                   55.7132   91.5072
    12       0.599968                    0.0779232          0.334915    1.652              0.165316         0.202057     0.815434                    0.810217            0.0334536       0.991145                   -66.5085  65.1997
    13       0.700016                    0.0219234          0.0688416   1.42573            0.0339806        0.0425427    0.703747                    0.700498            0.0068875       0.998032                   -93.1158  42.5727
    14       0.799903                    0.00698973         0.0131339   1.24933            0.00648298       0.0130252    0.616677                    0.614651            0.00131191      0.999344                   -98.6866  24.9332
    15       0.899951                    0.00204478         0.00655634  1.11117            0.00323625       0.00405253   0.54848                     0.54677             0.000655953     1                          -99.3444  11.1171
    16       1                           2.0667e-05         0           1                  0                0.000984207  0.493605                    0.492165            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:45:42  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:45:51  1:39:08.731  2383 obs/sec      0.81796   1             20449      0.303934         0.305134            0.630438       0.943722        0.91204            1.97537          0.125062                         0.295178           0.290466              0.651422         0.948687          0.913056             2.02591            0.11559
    2019-08-03 17:46:00  1:39:17.588  2433 obs/sec      1.63344   2             40836      0.289774         0.276422            0.664072       0.953359        0.938404           1.97537          0.11479                          0.28157            0.264068              0.682822         0.957328          0.934946             2.02591            0.103286
    2019-08-03 17:46:08  1:39:26.488  2445 obs/sec      2.44972   3             61243      0.278792         0.257993            0.689051       0.959566        0.950046           1.97537          0.105914                         0.271344           0.246308              0.705441         0.963425          0.957217             2.02591            0.0972964
    2019-08-03 17:46:17  1:39:35.441  2451 obs/sec      3.26844   4             81711      0.280863         0.260435            0.684414       0.958863        0.945116           1.97537          0.106612                         0.274003           0.250286              0.69964          0.962224          0.949309             2.02591            0.101506
    2019-08-03 17:46:28  1:39:45.586  2385 obs/sec      4.08384   5             102096     0.274865         0.251952            0.697749       0.9616          0.952903           1.97537          0.104817                         0.268357           0.243147              0.71189          0.964091          0.960443             2.02591            0.0947062
    2019-08-03 17:46:36  1:39:54.241  2407 obs/sec      4.89504   6             122376     0.270629         0.244453            0.706994       0.96384         0.947332           1.97537          0.0998305                        0.262191           0.231381              0.724979         0.967329          0.950369             2.02591            0.0932492
    2019-08-03 17:46:45  1:40:03.353  2408 obs/sec      5.71308   7             142827     0.261904         0.230539            0.725583       0.96774         0.957996           1.97537          0.094445                         0.254297           0.220027              0.74129          0.970512          0.957653             2.02591            0.0854784
    2019-08-03 17:46:54  1:40:12.086  2421 obs/sec      6.527     8             163175     0.256114         0.220351            0.737582       0.970409        0.951795           1.97537          0.0871647                        0.247474           0.208569              0.754985         0.973302          0.956217             2.02591            0.0817549
    2019-08-03 17:47:03  1:40:21.035  2428 obs/sec      7.34512   9             183628     0.248055         0.208432            0.753837       0.97349         0.9641             1.97537          0.08148                          0.239583           0.196414              0.770362         0.976357          0.962848             2.02591            0.0764125
    2019-08-03 17:47:12  1:40:29.955  2430 obs/sec      8.159     10            203975     0.235132         0.190672            0.778817       0.977542        0.947702           1.97537          0.072604                         0.228139           0.180391              0.791777         0.979729          0.952443             2.02591            0.0679942
    2019-08-03 17:47:21  1:40:38.773  2435 obs/sec      8.97368   11            224342     0.223129         0.173585            0.800823       0.981289        0.960137           1.97537          0.0650244                        0.21757            0.166304              0.810622         0.982718          0.968177             2.02591            0.0603853
    2019-08-03 17:47:30  1:40:47.590  2440 obs/sec      9.78924   12            244731     0.206751         0.151298            0.82899        0.985864        0.966853           1.97537          0.0557495                        0.20185            0.144576              0.837            0.987048          0.961939             2.02591            0.0511575
    2019-08-03 17:47:38  1:40:56.176  2450 obs/sec      10.6083   13            265208     0.195246         0.137197            0.847493       0.988391        0.956836           1.97537          0.0487683                        0.193796           0.134455              0.849748         0.98883           0.973296             2.02591            0.0471102
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004132311511321227
C438        0.7722638249397278     0.7722638249397278   0.0031912346935753983
C374        0.7036615610122681     0.7036615610122681   0.0029077487686452594
C88         0.6722959280014038     0.6722959280014038   0.0027781362022945883
C322        0.6224542856216431     0.6224542856216431   0.0025721750097455467
---         ---                    ---                  ---
C539        0.15236468613147736    0.15236468613147736  0.0006296183464199497
C564        0.1485416740179062     0.1485416740179062   0.000613820469455119
C916        0.14809457957744598    0.14809457957744598  0.0006119729359521576
C733        0.14639542996883392    0.14639542996883392  0.000604951520465033
C780        0.14186687767505646    0.14186687767505646  0.0005862381316918362

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_149

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 263,573 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.04531807911445324    0.09121516346931458     0.0         -0.006910902114339855  0.11331018805503845  0.011721365843407999    0.16054755449295044
    3        2        Softmax                 0.0   0.0   0.0016900427935979678  3.0927942134439945e-05  0.0         0.020038330341321853   0.37338995933532715  -0.0005056749189052967  0.2833747863769531


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04193134929234083
RMSE: 0.20477145624412801
LogLoss: 0.14989755619483305
Mean Per-Class Error: 0.05306443244779291
AUC: 0.9856887346530607
pr_auc: 0.9632996580237281
Gini: 0.9713774693061215
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4613995949589304: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4655  316   0.0636   (316.0/4971.0)
1      216   4830  0.0428   (216.0/5046.0)
Total  4871  5146  0.0531   (532.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.4614       0.947802  216
max f2                       0.306567     0.958408  258
max f0point5                 0.751429     0.955305  135
max accuracy                 0.484219     0.94699   210
max precision                0.999614     1         0
max recall                   0.000900831  1         397
max specificity              0.999614     1         0
max absolute_mcc             0.484219     0.894048  210
max min_per_class_accuracy   0.539954     0.9457    196
max mean_per_class_accuracy  0.484219     0.946936  210
Gains/Lift Table: Avg response rate: 50.37 %, avg score: 50.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   0.999467           1.98514     1.98514            1                0.999659    1                           0.999659            0.0200159       0.0200159                  98.5137   98.5137
    2        0.0200659                   0.999057           1.98514     1.98514            1                0.999237    1                           0.999449            0.0198177       0.0398335                  98.5137   98.5137
    3        0.0300489                   0.99881            1.96529     1.97854            0.99             0.998927    0.996678                    0.999276            0.0196195       0.059453                   96.5285   97.8542
    4        0.0400319                   0.998493           1.98514     1.98019            1                0.998646    0.997506                    0.999119            0.0198177       0.0792707                  98.5137   98.0186
    5        0.050015                    0.998167           1.98514     1.98117            1                0.998323    0.998004                    0.99896             0.0198177       0.0990884                  98.5137   98.1174
    6        0.10003                     0.996279           1.98514     1.98316            1                0.997278    0.999002                    0.998119            0.0992866       0.198375                   98.5137   98.3156
    7        0.150045                    0.993906           1.98117     1.9825             0.998004         0.995167    0.998669                    0.997135            0.0990884       0.297463                   98.1174   98.2495
    8        0.20006                     0.990221           1.98117     1.98216            0.998004         0.992152    0.998503                    0.995889            0.0990884       0.396552                   98.1174   98.2165
    9        0.29999                     0.973956           1.95936     1.97457            0.987013         0.983317    0.994676                    0.991701            0.195799        0.59235                    95.9356   97.4567
    10       0.40002                     0.912578           1.90589     1.95739            0.96008          0.951961    0.986024                    0.981764            0.190646        0.782996                   90.589    95.7393
    11       0.50005                     0.558945           1.59088     1.88408            0.801397         0.78432     0.949092                    0.942267            0.159136        0.942132                   59.0883   88.4077
    12       0.59998                     0.0926636          0.44621     1.64459            0.224775         0.26872     0.828453                    0.830084            0.0445898       0.986722                   -55.379   64.4592
    13       0.70001                     0.0196698          0.0931152   1.42289            0.0469062        0.045881    0.716771                    0.718023            0.00931431      0.996036                   -90.6885  42.2889
    14       0.79994                     0.00534379         0.0297473   1.24885            0.014985         0.0109377   0.629103                    0.629692            0.00297265      0.999009                   -97.0253  24.8855
    15       0.89997                     0.00156066         0.0079247   1.11093            0.00399202       0.00308179  0.559623                    0.560046            0.000792707     0.999802                   -99.2075  11.0928
    16       1                           1.69726e-05        0.00198117  1                  0.000998004      0.00073899  0.503744                    0.504098            0.000198177     1                          -99.8019  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03902679283886623
RMSE: 0.19755200034134363
LogLoss: 0.13837342610320383
Mean Per-Class Error: 0.049021617502363446
AUC: 0.9880108274147996
pr_auc: 0.9581266041082913
Gini: 0.9760216548295992
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48600345144603474: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2967  161   0.0515   (161.0/3128.0)
1      142   2907  0.0466   (142.0/3049.0)
Total  3109  3068  0.0491   (303.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.486003     0.950466  206
max f2                       0.247795     0.960583  269
max f0point5                 0.747947     0.95715   137
max accuracy                 0.495313     0.950947  205
max precision                0.99957      1         0
max recall                   0.00362301   1         392
max specificity              0.99957      1         0
max absolute_mcc             0.486003     0.901903  206
max min_per_class_accuracy   0.507982     0.94982   201
max mean_per_class_accuracy  0.486003     0.950978  206
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.32 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999486           2.02591     2.02591            1                0.999662     1                           0.999662            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.99916            2.02591     2.02591            1                0.999329     1                           0.999496            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.998857           2.02591     2.02591            1                0.999006     1                           0.999332            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998574           2.02591     2.02591            1                0.998706     1                           0.999176            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.998224           2.02591     2.02591            1                0.998414     1                           0.999025            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.996225           2.02591     2.02591            1                0.997284     1                           0.998155            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.993438           2.01935     2.02372            0.996764         0.994877     0.998921                    0.997062            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.989389           2.02591     2.02427            1                0.99152      0.999191                    0.995677            0.101345        0.405051                   102.591   102.427
    9        0.299984                    0.972132           1.99308     2.01388            0.983793         0.982242     0.994064                    0.991203            0.199082        0.604133                   99.3075   101.388
    10       0.400032                    0.904297           1.97674     2.00459            0.975728         0.948923     0.989478                    0.980629            0.19777         0.801902                   97.6738   100.459
    11       0.500081                    0.458984           1.53746     1.91114            0.7589           0.74137      0.943347                    0.932762            0.153821        0.955723                   53.7463   91.1137
    12       0.599968                    0.0753918          0.341482    1.64981            0.168558         0.214165     0.814355                    0.813125            0.0341095       0.989833                   -65.8518  64.981
    13       0.700016                    0.0183924          0.0753979   1.42479            0.0372168        0.0395745    0.703284                    0.702566            0.00754346      0.997376                   -92.4602  42.479
    14       0.799903                    0.00504643         0.0229844   1.24974            0.0113452        0.0104809    0.616879                    0.616143            0.00229583      0.999672                   -97.7016  24.9742
    15       0.899951                    0.0014742          0.00327817  1.11117            0.00161812       0.00292719   0.54848                     0.547971            0.000327976     1                          -99.6722  11.1171
    16       1                           3.03703e-05        0           1                  0                0.000723509  0.493605                    0.49322             0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:53:56  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:54:02  2:47:20.362  2280 obs/sec      0.58396   1             14599      0.314546         0.333709            0.60422        0.936954        0.877973           1.98514          0.133573                         0.305763           0.314847              0.625974         0.942846          0.879406             2.02591            0.129675
    2019-08-03 18:54:15  2:47:33.059  2369 obs/sec      1.7606    3             44015      0.282681         0.267426            0.680348       0.956028        0.934238           1.98514          0.107517                         0.277079           0.257162              0.692859         0.959457          0.938452             2.02591            0.103124
    2019-08-03 18:54:22  2:47:39.849  2361 obs/sec      2.34212   4             58553      0.281442         0.268399            0.683143       0.955806        0.937192           1.98514          0.104023                         0.274227           0.254492              0.699148         0.960116          0.94264              2.02591            0.0992391
    2019-08-03 18:54:28  2:47:46.505  2375 obs/sec      2.928     5             73200      0.278057         0.263408            0.690719       0.957757        0.944106           1.98514          0.103324                         0.270127           0.249251              0.708078         0.961919          0.93039              2.02591            0.0966489
    2019-08-03 18:54:35  2:47:53.006  2399 obs/sec      3.51344   6             87836      0.275001         0.257174            0.697481       0.959147        0.955309           1.98514          0.102326                         0.269491           0.246476              0.70945          0.962583          0.955807             2.02591            0.0961632
    2019-08-03 18:54:48  2:48:05.800  2406 obs/sec      4.69112   8             117278     0.266227         0.242848            0.716478       0.963489        0.93962            1.98514          0.0931417                        0.25662            0.225135              0.736541         0.968601          0.948324             2.02591            0.0877449
    2019-08-03 18:54:54  2:48:12.532  2407 obs/sec      5.27776   9             131944     0.269997         0.24912             0.708389       0.96157         0.945998           1.98514          0.0954378                        0.259773           0.229515              0.730027         0.967453          0.94999              2.02591            0.0882305
    2019-08-03 18:55:01  2:48:19.076  2414 obs/sec      5.8614    10            146535     0.258304         0.228673            0.733101       0.967584        0.953473           1.98514          0.0866527                        0.250657           0.215679              0.748643         0.971273          0.954605             2.02591            0.0822406
    2019-08-03 18:55:08  2:48:25.781  2415 obs/sec      6.4486    11            161215     0.253829         0.220323            0.742269       0.970171        0.962126           1.98514          0.0853549                        0.246623           0.208176              0.756669         0.973575          0.964603             2.02591            0.0791646
    2019-08-03 18:55:20  2:48:38.212  2425 obs/sec      7.61748   13            190437     0.241095         0.201982            0.767479       0.974482        0.949071           1.98514          0.0751722                        0.235507           0.191426              0.778109         0.977234          0.961849             2.02591            0.0734985
    2019-08-03 18:55:27  2:48:44.987  2423 obs/sec      8.20296   14            205074     0.234086         0.190865            0.780803       0.97725         0.965053           1.98514          0.07058                          0.227167           0.17889               0.793547         0.980357          0.968559             2.02591            0.0673466
    2019-08-03 18:55:39  2:48:57.581  2426 obs/sec      9.36844   16            234211     0.215139         0.163565            0.814851       0.983172        0.965004           1.98514          0.0596985                        0.209216           0.153876              0.824887         0.985492          0.968996             2.02591            0.0556905
    2019-08-03 18:55:52  2:49:09.871  2437 obs/sec      10.5429   18            263573     0.204771         0.149898            0.832265       0.985689        0.9633             1.98514          0.0531097                        0.197552           0.138373              0.843867         0.988011          0.958127             2.02591            0.0490529
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003831531402895216
C438        0.8305304050445557     0.8305304050445557   0.0031822033279874985
C374        0.7295567393302917     0.7295567393302917   0.0027953195569378523
C863        0.6813167929649353     0.6813167929649353   0.002610486687565008
C88         0.6627417802810669     0.6627417802810669   0.0025393159431575892
---         ---                    ---                  ---
C982        0.1667400598526001     0.1667400598526001   0.0006388697754458651
C828        0.16605764627456665    0.16605764627456665  0.0006362550863918679
C703        0.16511006653308868    0.16511006653308868  0.0006326244048556477
C964        0.1633819341659546     0.1633819341659546   0.0006260030114226138
C892        0.16241970658302307    0.16241970658302307  0.0006223162062218798

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_94

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.002796660054962428    0.0025284606963396072  0.0         0.026860831110792405  0.09531211853027344  -0.0009197619395779968  0.2535752058029175
    3        2        Softmax                      0.0   0.0   0.00020232652445884014  5.126481119077653e-05  0.0         -0.23290052929587546  0.6117086410522461   0.0006562226963661433   0.060741305351257324


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.034547875681355616
RMSE: 0.1858705885323324
LogLoss: 0.13666961316695264
Mean Per-Class Error: 0.03480089689642596
AUC: 0.9899852839872901
pr_auc: 0.7536792543339155
Gini: 0.9799705679745803
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5087820157034091: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4847  186   0.037    (186.0/5033.0)
1      163   4830  0.0326   (163.0/4993.0)
Total  5010  5016  0.0348   (349.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.508782     0.965131  201
max f2                       0.390884     0.970695  234
max f0point5                 0.574108     0.96846   183
max accuracy                 0.513367     0.965191  199
max precision                0.999196     0.998769  2
max recall                   1.76554e-05  1         399
max specificity              0.999979     0.999603  0
max absolute_mcc             0.508782     0.930391  201
max min_per_class_accuracy   0.51631      0.964751  198
max mean_per_class_accuracy  0.508782     0.965199  201
Gains/Lift Table: Avg response rate: 49.80 %, avg score: 49.69 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   1                  2.00801     2.00801            1                1            1                           1                   0.0202283       0.0202283                  100.801   100.801
    2        0.0200479                   1                  2.00801     2.00801            1                1            1                           1                   0.020028        0.0402564                  100.801   100.801
    3        0.0300219                   1                  2.00801     2.00801            1                1            1                           1                   0.020028        0.0602844                  100.801   100.801
    4        0.0400958                   1                  2.00801     2.00801            1                1            1                           1                   0.0202283       0.0805127                  100.801   100.801
    5        0.0500698                   1                  2.00801     2.00801            1                1            1                           1                   0.020028        0.100541                   100.801   100.801
    6        0.10004                     0.999952           2           2.00401            0.996008         0.999987     0.998006                    0.999994            0.0999399       0.200481                   99.9995   100.401
    7        0.15001                     0.999351           2.00801     2.00534            1                0.999743     0.99867                     0.99991             0.10034         0.300821                   100.801   100.534
    8        0.20008                     0.996731           1.99601     2.00301            0.994024         0.998241     0.997507                    0.999492            0.0999399       0.400761                   99.6011   100.301
    9        0.30002                     0.968231           1.98998     1.99867            0.991018         0.986627     0.995346                    0.995207            0.198878        0.599639                   98.9975   99.8665
    10       0.40006                     0.860862           1.94395     1.98498            0.968096         0.924886     0.988532                    0.977622            0.194472        0.794112                   94.3947   98.4982
    11       0.5                         0.508513           1.73146     1.93431            0.862275         0.711141     0.963295                    0.924358            0.173042        0.967154                   73.1459   93.4308
    12       0.60004                     0.126958           0.242243    1.6522             0.120638         0.274987     0.822806                    0.816093            0.0242339       0.991388                   -75.7757  65.2203
    13       0.69998                     0.0227992          0.0541081   1.42403            0.0269461        0.0636654    0.709176                    0.708665            0.00540757      0.996796                   -94.5892  42.4034
    14       0.80002                     0.00115734         0.016016    1.24797            0.00797607       0.00789677   0.621494                    0.621036            0.00160224      0.998398                   -98.3984  24.7966
    15       0.89996                     3.7942e-06         0.01002     1.11049            0.00499002       0.000253437  0.553031                    0.552099            0.0010014       0.999399                   -98.998   11.0493
    16       1                           1.0349e-36         0.00600602  1                  0.00299103       4.04008e-07  0.498005                    0.496867            0.000600841     1                          -99.3994  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.034760724767254586
RMSE: 0.1864422826701459
LogLoss: 0.14017203665121972
Mean Per-Class Error: 0.03479359716279451
AUC: 0.9895593834379475
pr_auc: 0.7269745322968143
Gini: 0.9791187668758949
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5082755355612906: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3016  112   0.0358   (112.0/3128.0)
1      103   2946  0.0338   (103.0/3049.0)
Total  3119  3058  0.0348   (215.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.508276     0.964794  204
max f2                       0.415346     0.970178  231
max f0point5                 0.589766     0.969039  182
max accuracy                 0.508276     0.965193  204
max precision                0.998462     0.997297  3
max recall                   3.48151e-05  1         399
max specificity              0.999964     0.999041  0
max absolute_mcc             0.508276     0.930382  204
max min_per_class_accuracy   0.511618     0.964194  203
max mean_per_class_accuracy  0.508276     0.965206  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.29 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  1.9927      2.01935            0.983607         1            0.996764                    1                   0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999953           2.01935     2.01935            0.996764         0.999987     0.996764                    0.999994            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.99943            2.01935     2.01935            0.996764         0.999776     0.996764                    0.999921            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.996649           2.00624     2.01608            0.990291         0.998299     0.995146                    0.999516            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.966713           2.00621     2.01279            0.990276         0.985747     0.993524                    0.994931            0.200394        0.603805                   100.621   101.279
    10       0.400032                    0.850401           1.98329     2.00541            0.978964         0.918325     0.989883                    0.975772            0.198426        0.80223                    98.3294   100.541
    11       0.500081                    0.476108           1.67187     1.93868            0.825243         0.691076     0.956944                    0.918814            0.167268        0.969498                   67.1868   93.8683
    12       0.599968                    0.123584           0.21671     1.652              0.106969         0.264595     0.815434                    0.809895            0.0216464       0.991145                   -78.329   65.1997
    13       0.700016                    0.0211496          0.0458944   1.42245            0.0226537        0.0621447    0.702128                    0.703025            0.00459167      0.995736                   -95.4106  42.2448
    14       0.799903                    0.00106481         0.0295514   1.24851            0.0145867        0.00756008   0.616272                    0.616179            0.00295179      0.998688                   -97.0449  24.8512
    15       0.899951                    4.46386e-06        0.00983452  1.11081            0.00485437       0.000241977  0.5483                      0.547705            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           6.26681e-38        0.00327817  1                  0.00161812       4.19068e-07  0.493605                    0.492908            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:49:37  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:49:39  1:42:56.621  16578 obs/sec     1         1             25000      0.309217         0.390033            0.617532       0.941267        0.631555           2.00801          0.123678                         0.306468           0.38828               0.624249         0.942136          0.661135             2.02591            0.119637
    2019-08-03 17:49:45  1:43:02.661  17163 obs/sec     5         5             125000     0.229545         0.194681            0.789234       0.978665        0.764533           2.00801          0.0629364                        0.227581           0.198559              0.792793         0.979073          0.748891             1.99323            0.0587664
    2019-08-03 17:49:51  1:43:08.542  17505 obs/sec     9         9             225000     0.197774         0.149785            0.843539       0.987778        0.754211           2.00801          0.0432875                        0.198828           0.158333              0.841843         0.986542          0.719147             2.02591            0.0420916
    2019-08-03 17:49:52  1:43:10.166  17652 obs/sec     10        10            250000     0.185871         0.13667             0.861806       0.989985        0.753679           2.00801          0.0348095                        0.186442           0.140172              0.860934         0.989559          0.726975             2.02591            0.0348065
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C36         1.0                    1.0                  0.003554170461941562
C41         0.9702562093734741     0.9702562093734741   0.0034484559598705893
C35         0.9148708581924438     0.9148708581924438   0.003251606980678711
C34         0.8904432654380798     0.8904432654380798   0.0031647871520548133
C28         0.8596616983413696     0.8596616983413696   0.0030553842155074135
---         ---                    ---                  ---
C389        0.1544746458530426     0.1544746458530426   0.0005490292234097676
C446        0.1529260277748108     0.1529260277748108   0.0005435251707792874
C688        0.14385674893856049    0.14385674893856049  0.0005112914078283748
C662        0.13346226513385773    0.13346226513385773  0.00047434764052257033
C264        0.11579809337854385    0.11579809337854385  0.00041156616303517134

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_24

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 260,719 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.048274482005321986   0.10073205828666687    0.0         -0.001230815784678709  0.11072498559951782  -0.011277168687015072  0.1367071270942688
    3        2        Softmax                 0.0   0.0   0.0016519122173122014  3.338446549605578e-05  0.0         0.005824199395192409   0.3916417360305786   0.00074430908751838    0.26262569427490234


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04218289016802562
RMSE: 0.20538473694027418
LogLoss: 0.1509302979621847
Mean Per-Class Error: 0.05567299639413714
AUC: 0.9854242053673165
pr_auc: 0.9494036281343126
Gini: 0.9708484107346329
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45119397855363674: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4683  321   0.0641   (321.0/5004.0)
1      248   4782  0.0493   (248.0/5030.0)
Total  4931  5103  0.0567   (569.0/10034.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.451194     0.943847  214
max f2                       0.189687     0.961636  290
max f0point5                 0.759536     0.956027  132
max accuracy                 0.597777     0.944289  178
max precision                0.995994     0.99827   6
max recall                   0.000926709  1         397
max specificity              0.999611     0.9998    0
max absolute_mcc             0.597777     0.888968  178
max min_per_class_accuracy   0.501779     0.94334   201
max mean_per_class_accuracy  0.597777     0.944327  178
Gains/Lift Table: Avg response rate: 50.13 %, avg score: 49.86 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100658                   0.999584           1.97508     1.97508            0.990099         0.999743     0.990099                    0.999743            0.0198807       0.0198807                  97.508    97.508
    2        0.0200319                   0.999291           1.99483     1.98491            1                0.999428     0.995025                    0.999586            0.0198807       0.0397614                  99.4831   98.4906
    3        0.029998                    0.998999           1.99483     1.9882             1                0.999136     0.996678                    0.999437            0.0198807       0.0596421                  99.4831   98.8204
    4        0.0400638                   0.998731           1.99483     1.98987            1                0.998857     0.997512                    0.999291            0.0200795       0.0797217                  99.4831   98.9869
    5        0.0500299                   0.998419           1.99483     1.99086            1                0.998589     0.998008                    0.999151            0.0198807       0.0996024                  99.4831   99.0857
    6        0.10006                     0.996295           1.99086     1.99086            0.998008         0.99745      0.998008                    0.998301            0.0996024       0.199205                   99.0857   99.0857
    7        0.14999                     0.993301           1.9789      1.98688            0.992016         0.994889     0.996013                    0.997165            0.0988072       0.298012                   97.8904   98.6878
    8        0.20002                     0.989119           1.98688     1.98688            0.996016         0.99126      0.996014                    0.995688            0.0994036       0.397416                   98.6883   98.688
    9        0.29998                     0.969867           1.9829      1.98555            0.994018         0.981119     0.995349                    0.990833            0.198211        0.595626                   98.2898   98.5553
    10       0.40004                     0.901601           1.89747     1.96352            0.951195         0.943262     0.984305                    0.978934            0.189861        0.785487                   89.7474   96.3522
    11       0.5                         0.507508           1.56921     1.88469            0.78664          0.759645     0.944788                    0.935094            0.156859        0.942346                   56.9214   88.4692
    12       0.59996                     0.0891684          0.475339    1.64988            0.238285         0.250176     0.827076                    0.820979            0.0475149       0.989861                   -52.4661  64.9878
    13       0.70002                     0.0198578          0.0556327   1.422              0.0278884        0.0450532    0.712842                    0.710069            0.0055666       0.995427                   -94.4367  42.1999
    14       0.79998                     0.00560782         0.029833    1.24804            0.0149551        0.0110765    0.625638                    0.622728            0.00298211      0.99841                    -97.0167  24.8043
    15       0.89994                     0.00155297         0.0119332   1.11074            0.00598205       0.00322284   0.556811                    0.553917            0.00119284      0.999602                   -98.8067  11.0743
    16       1                           1.06306e-05        0.00397377  1                  0.00199203       0.000694886  0.501296                    0.498561            0.000397614     1                          -99.6026  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.039875203656952816
RMSE: 0.19968776541629388
LogLoss: 0.14135915196873494
Mean Per-Class Error: 0.05107230872727553
AUC: 0.9875038166049999
pr_auc: 0.9624184560152835
Gini: 0.9750076332099997
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5546160053229163: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2987  141   0.0451   (141.0/3128.0)
1      174   2875  0.0571   (174.0/3049.0)
Total  3161  3016  0.051    (315.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.554616     0.948063  188
max f2                       0.243433     0.959059  270
max f0point5                 0.790603     0.959918  123
max accuracy                 0.554616     0.949004  188
max precision                0.999724     1         0
max recall                   0.0021039    1         394
max specificity              0.999724     1         0
max absolute_mcc             0.554616     0.898029  188
max min_per_class_accuracy   0.507571     0.94654   198
max mean_per_class_accuracy  0.554616     0.948928  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.35 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999618           2.02591     2.02591            1                0.999761     1                           0.999761            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999297           2.02591     2.02591            1                0.999459     1                           0.99961             0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999016           2.02591     2.02591            1                0.999157     1                           0.999459            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998682           2.02591     2.02591            1                0.998838     1                           0.999304            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.998342           2.02591     2.02591            1                0.99853      1                           0.999151            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.996275           2.02591     2.02591            1                0.997377     1                           0.998264            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.993267           2.02591     2.02591            1                0.994912     1                           0.997147            0.101345        0.304034                   102.591   102.591
    8        0.200097                    0.988902           2.01935     2.02427            0.996764         0.991086     0.999191                    0.995631            0.101017        0.405051                   101.935   102.427
    9        0.299984                    0.969633           1.99964     2.01607            0.987034         0.98105      0.995143                    0.990776            0.199738        0.604788                   99.9642   101.607
    10       0.400032                    0.904586           1.95051     1.99967            0.962783         0.944087     0.98705                     0.979099            0.195146        0.799934                   95.0512   99.9674
    11       0.500081                    0.462365           1.51779     1.90327            0.749191         0.746238     0.939463                    0.932512            0.151853        0.951787                   51.7794   90.3267
    12       0.599968                    0.0806569          0.380884    1.64981            0.188006         0.215762     0.814355                    0.813183            0.0380453       0.989833                   -61.9116  64.981
    13       0.700016                    0.018691           0.0688416   1.42385            0.0339806        0.0423354    0.702821                    0.703011            0.0068875       0.99672                    -93.1158  42.3853
    14       0.799903                    0.00518524         0.0295514   1.24974            0.0145867        0.010579     0.616879                    0.616544            0.00295179      0.999672                   -97.0449  24.9742
    15       0.899951                    0.00139701         0.00327817  1.11117            0.00161812       0.00297293   0.54848                     0.548333            0.000327976     1                          -99.6722  11.1171
    16       1                           1.39572e-05        0           1                  0                0.000641122  0.493605                    0.493537            0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:33:24  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:33:30  26 min 47.995 sec  2404 obs/sec      0.58256   1             14564      0.312913         0.327446            0.608338       0.940274        0.849841           1.99483          0.135041                         0.304966           0.314679              0.627923         0.944174          0.866579             2.02591            0.126761
    2019-08-03 16:33:37  26 min 54.707 sec  2402 obs/sec      1.1634    2             29085      0.28913          0.279338            0.665613       0.952653        0.934727           1.99483          0.115208                         0.281357           0.263706              0.6833           0.957561          0.93208              2.02591            0.106362
    2019-08-03 16:33:49  27 min  6.990 sec  2432 obs/sec      2.3132    4             57830      0.278709         0.259241            0.689283       0.958954        0.947731           1.99483          0.106936                         0.271106           0.246861              0.705959         0.96276           0.942433             2.02591            0.100534
    2019-08-03 16:33:56  27 min 13.753 sec  2421 obs/sec      2.89564   5             72391      0.280034         0.261509            0.686322       0.958445        0.940502           1.99483          0.105641                         0.271318           0.247483              0.705497         0.962649          0.933923             2.02591            0.0958394
    2019-08-03 16:34:02  27 min 20.319 sec  2425 obs/sec      3.47328   6             86832      0.274733         0.254263            0.698086       0.960207        0.94718            1.97508          0.102252                         0.264577           0.238718              0.71995          0.964944          0.953077             2.02591            0.093411
    2019-08-03 16:34:09  27 min 26.864 sec  2428 obs/sec      4.05056   7             101264     0.274492         0.252558            0.698615       0.960867        0.948398           1.99483          0.103847                         0.262945           0.234382              0.723395         0.966568          0.958476             2.02591            0.0908208
    2019-08-03 16:34:15  27 min 33.506 sec  2426 obs/sec      4.63072   8             115768     0.271454         0.247751            0.705249       0.962287        0.955332           1.99483          0.0982659                        0.262269           0.232871              0.724815         0.966926          0.952226             2.02591            0.0921159
    2019-08-03 16:34:22  27 min 40.138 sec  2428 obs/sec      5.21544   9             130386     0.268761         0.242364            0.711069       0.963893        0.951902           1.99483          0.0989635                        0.259939           0.229569              0.729682         0.967637          0.949506             2.02591            0.0916302
    2019-08-03 16:34:34  27 min 52.467 sec  2434 obs/sec      6.36644   11            159161     0.259242         0.228598            0.731173       0.967857        0.934614           1.99483          0.0901933                        0.250062           0.214263              0.749835         0.971695          0.947327             1.99323            0.08305
    2019-08-03 16:34:41  27 min 59.039 sec  2436 obs/sec      6.94792   12            173698     0.249719         0.213236            0.75056        0.971983        0.952046           1.99483          0.0812238                        0.241009           0.197555              0.76762          0.976112          0.96408              2.02591            0.0760887
    2019-08-03 16:34:48  28 min  5.652 sec  2434 obs/sec      7.5228    13            188070     0.242057         0.20166             0.765633       0.974694        0.960767           1.95533          0.0766394                        0.232535           0.186975              0.783675         0.978277          0.958185             2.02591            0.0689655
    2019-08-03 16:35:00  28 min 18.104 sec  2439 obs/sec      8.68588   15            217147     0.224534         0.175156            0.798337       0.980665        0.949275           1.99483          0.066175                         0.218864           0.166897              0.808363         0.98241           0.949573             2.02591            0.0634612
    2019-08-03 16:35:13  28 min 30.587 sec  2440 obs/sec      9.84444   17            246111     0.214761         0.162549            0.815509       0.983284        0.933565           1.97508          0.0615906                        0.207568           0.150348              0.827635         0.985915          0.936362             2.02591            0.0576332
    2019-08-03 16:35:19  28 min 37.004 sec  2443 obs/sec      10.4288   18            260719     0.205385         0.15093             0.831267       0.985424        0.949404           1.97508          0.0567072                        0.199688           0.141359              0.840473         0.987504          0.962418             2.02591            0.0509956
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003606919165471644
C438        0.8529068827629089     0.8529068827629089   0.0030763661818002126
C374        0.7755728960037231     0.7755728960037231   0.002797428742816175
C322        0.7479665279388428     0.7479665279388428   0.0026978548047538937
C79         0.7050842642784119     0.7050842642784119   0.0025431819460982772
---         ---                    ---                  ---
C615        0.17683744430541992    0.17683744430541992  0.0006378383670382435
C994        0.17636828124523163    0.17636828124523163  0.000636146133804719
C879        0.17540940642356873    0.17540940642356873  0.0006326875498331749
C911        0.17455075681209564    0.17455075681209564  0.0006295904700931278
C614        0.17378678917884827    0.17378678917884827  0.0006268349005949679

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_25

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 260,404 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.038682310148257265   0.06302076578140259    0.0         -0.0008607866777908917  0.11140626668930054  0.018447435310028248   0.1407739520072937
    3        2        Softmax                 0.0   0.0   0.0017290059981860395  3.484117041807622e-05  0.0         0.04452315217349678     0.3762357234954834   -0.000306281142310294  0.24198907613754272


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04540358846529319
RMSE: 0.21308117811128505
LogLoss: 0.16236896751894087
Mean Per-Class Error: 0.057602187287266626
AUC: 0.9829838134164391
pr_auc: 0.9502554440228504
Gini: 0.9659676268328783
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48366360634152256: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4698  316   0.063    (316.0/5014.0)
1      262   4759  0.0522   (262.0/5021.0)
Total  4960  5075  0.0576   (578.0/10035.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.483664     0.94275   206
max f2                       0.247703     0.956101  271
max f0point5                 0.706713     0.950712  147
max accuracy                 0.483664     0.942402  206
max precision                0.999642     1         0
max recall                   0.000558233  1         398
max specificity              0.999642     1         0
max absolute_mcc             0.483664     0.884854  206
max min_per_class_accuracy   0.525011     0.941048  195
max mean_per_class_accuracy  0.483664     0.942398  206
Gains/Lift Table: Avg response rate: 50.03 %, avg score: 50.16 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100648                   0.999567           1.99861     1.99861            1                0.999742     1                           0.999742            0.0201155       0.0201155                  99.8606   99.8606
    2        0.0200299                   0.999364           1.99861     1.99861            1                0.999465     1                           0.999604            0.0199164       0.0400319                  99.8606   99.8606
    3        0.0300947                   0.99908            1.99861     1.99861            1                0.999236     1                           0.999481            0.0201155       0.0601474                  99.8606   99.8606
    4        0.0400598                   0.998804           1.99861     1.99861            1                0.998933     1                           0.999345            0.0199164       0.0800637                  99.8606   99.8606
    5        0.0500249                   0.998492           1.99861     1.99861            1                0.998645     1                           0.999205            0.0199164       0.0999801                  99.8606   99.8606
    6        0.10005                     0.996875           1.98666     1.99263            0.994024         0.997725     0.997012                    0.998465            0.0993826       0.199363                   98.6662   99.2634
    7        0.150075                    0.994326           1.99064     1.99197            0.996016         0.995732     0.99668                     0.997554            0.0995818       0.298944                   99.0643   99.197
    8        0.2                         0.990873           1.98664     1.99064            0.994012         0.99266      0.996014                    0.996333            0.0991834       0.398128                   98.6638   99.0639
    9        0.30005                     0.974852           1.96476     1.98201            0.983068         0.984436     0.991697                    0.992366            0.196574        0.594702                   96.4765   98.2012
    10       0.4                         0.907976           1.89897     1.96126            0.95015          0.950056     0.981315                    0.981793            0.189803        0.784505                   89.8974   96.1263
    11       0.50005                     0.525549           1.56265     1.88151            0.781873         0.771932     0.941411                    0.939804            0.156343        0.940848                   56.2655   88.1509
    12       0.6                         0.0972627          0.448341    1.64277            0.224327         0.251924     0.821956                    0.825215            0.0448118       0.98566                    -55.1659  64.2767
    13       0.69995                     0.0213969          0.0976388   1.42213            0.0488534        0.0489585    0.71156                     0.714368            0.00975901      0.995419                   -90.2361  42.2129
    14       0.8                         0.00550218         0.0298596   1.24801            0.0149402        0.0115319    0.624439                    0.62647             0.00298745      0.998407                   -97.014   24.8008
    15       0.89995                     0.00150089         0.0119558   1.11073            0.00598205       0.00316146   0.555752                    0.557244            0.00119498      0.999602                   -98.8044  11.073
    16       1                           4.01466e-05        0.00398129  1                  0.00199203       0.000722981  0.500349                    0.501564            0.000398327     1                          -99.6019  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03944417617255701
RMSE: 0.19860557940943405
LogLoss: 0.14215833767898636
Mean Per-Class Error: 0.04779668651580882
AUC: 0.9869585873193089
pr_auc: 0.962133023811362
Gini: 0.9739171746386177
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5543539195100351: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2988  140   0.0448   (140.0/3128.0)
1      155   2894  0.0508   (155.0/3049.0)
Total  3143  3034  0.0478   (295.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.554354     0.951504  185
max f2                       0.24759      0.959616  266
max f0point5                 0.740031     0.957807  138
max accuracy                 0.582785     0.952242  179
max precision                0.999706     1         0
max recall                   0.00328437   1         391
max specificity              0.999706     1         0
max absolute_mcc             0.582785     0.904497  179
max min_per_class_accuracy   0.531875     0.950767  190
max mean_per_class_accuracy  0.554354     0.952203  185
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.75 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999589           2.02591     2.02591            1                0.999749     1                           0.999749            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999369           2.02591     2.02591            1                0.999479     1                           0.999614            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999115           2.02591     2.02591            1                0.999243     1                           0.99949             0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998803           2.02591     2.02591            1                0.998949     1                           0.999355            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.998596           2.02591     2.02591            1                0.998704     1                           0.999226            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.996931           2.02591     2.02591            1                0.997837     1                           0.998532            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.994415           2.02591     2.02591            1                0.995761     1                           0.997608            0.101345        0.304034                   102.591   102.591
    8        0.200097                    0.991128           2.0128      2.02263            0.993528         0.992807     0.998382                    0.996408            0.100689        0.404723                   101.28    102.263
    9        0.299984                    0.975324           1.99636     2.01388            0.985413         0.984688     0.994064                    0.992505            0.19941         0.604133                   99.6359   101.388
    10       0.400032                    0.910082           1.94723     1.99721            0.961165         0.952278     0.985836                    0.982444            0.194818        0.79895                    94.7234   99.7215
    11       0.500081                    0.491902           1.57352     1.91245            0.776699         0.762125     0.943995                    0.938366            0.157429        0.956379                   57.3522   91.2449
    12       0.599968                    0.0882028          0.325065    1.64817            0.160454         0.223396     0.813546                    0.819333            0.0324697       0.988849                   -67.4935  64.817
    13       0.700016                    0.0198628          0.0819543   1.42432            0.0404531        0.0449322    0.703053                    0.708653            0.00819941      0.997048                   -91.8046  42.4322
    14       0.799903                    0.00539526         0.0262679   1.24974            0.012966         0.0111375    0.616879                    0.621552            0.00262381      0.999672                   -97.3732  24.9742
    15       0.899951                    0.00144029         0.00327817  1.11117            0.00161812       0.00298595   0.54848                     0.552785            0.000327976     1                          -99.6722  11.1171
    16       1                           3.94201e-05        0           1                  0                0.000672428  0.493605                    0.497547            0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:35:20  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:35:26  28 min 43.868 sec  2424 obs/sec      0.57852   1             14463      0.321932         0.354922            0.585438       0.933865        0.86739            1.99861          0.139013                         0.310197           0.332176              0.615049         0.940379          0.846653             2.02591            0.128056
    2019-08-03 16:35:32  28 min 50.416 sec  2441 obs/sec      1.15952   2             28988      0.294652         0.288809            0.652721       0.949374        0.923915           1.99861          0.117688                         0.280572           0.263763              0.685066         0.957704          0.923364             2.02591            0.105391
    2019-08-03 16:35:46  29 min  3.891 sec  2348 obs/sec      2.30852   4             57713      0.288326         0.274571            0.667473       0.954039        0.938287           1.99861          0.111011                         0.275017           0.253553              0.697412         0.961126          0.945635             2.02591            0.0987534
    2019-08-03 16:35:58  29 min 16.229 sec  2387 obs/sec      3.46456   6             86614      0.278825         0.260089            0.689027       0.958415        0.944326           1.99861          0.102143                         0.268038           0.241965              0.712575         0.964161          0.953714             2.02591            0.0960013
    2019-08-03 16:36:05  29 min 22.681 sec  2404 obs/sec      4.0478    7             101195     0.279273         0.262288            0.688027       0.95906         0.931261           1.99861          0.106328                         0.266149           0.238498              0.716613         0.965622          0.950518             2.02591            0.0958394
    2019-08-03 16:36:11  29 min 29.307 sec  2407 obs/sec      4.62816   8             115704     0.276387         0.256415            0.694442       0.959714        0.950627           1.99861          0.103039                         0.261648           0.232992              0.726117         0.966991          0.95523              2.02591            0.0901732
    2019-08-03 16:36:18  29 min 35.850 sec  2412 obs/sec      5.20776   9             130194     0.268853         0.246965            0.710873       0.963279        0.936915           1.99861          0.0969606                        0.255882           0.222977              0.738056         0.969618          0.945863             2.02591            0.0856403
    2019-08-03 16:36:24  29 min 42.419 sec  2414 obs/sec      5.78476   10            144619     0.264193         0.236504            0.720807       0.9658          0.950476           1.99861          0.0920777                        0.251567           0.215372              0.746814         0.971581          0.958822             2.02591            0.084507
    2019-08-03 16:36:31  29 min 49.115 sec  2413 obs/sec      6.36824   11            159206     0.256545         0.223691            0.736738       0.969313        0.954047           1.97882          0.088291                         0.241861           0.201481              0.765975         0.974874          0.965316             2.02591            0.0781933
    2019-08-03 16:36:38  29 min 55.729 sec  2415 obs/sec      6.94908   12            173727     0.251528         0.216709            0.746935       0.97095         0.962901           1.99861          0.0839063                        0.239244           0.197244              0.771012         0.975915          0.967966             2.02591            0.0746317
    2019-08-03 16:36:50  30 min  8.149 sec  2420 obs/sec      8.10084   14            202521     0.236588         0.195079            0.776105       0.976258        0.960554           1.99861          0.0709517                        0.225267           0.179385              0.796985         0.979979          0.956418             2.02591            0.0626518
    2019-08-03 16:36:57  30 min 14.712 sec  2420 obs/sec      8.67492   15            216873     0.229959         0.185185            0.788475       0.978367        0.963207           1.99861          0.0677628                        0.217662           0.166166              0.810462         0.982691          0.962822             2.02591            0.0584426
    2019-08-03 16:37:03  30 min 21.317 sec  2421 obs/sec      9.2556    16            231390     0.221648         0.173092            0.803488       0.980903        0.952098           1.99861          0.0635775                        0.209111           0.15514               0.825062         0.98465           0.968299             2.02591            0.0558524
    2019-08-03 16:37:10  30 min 27.836 sec  2422 obs/sec      9.8332    17            245830     0.220719         0.172129            0.805133       0.981154        0.941256           1.99861          0.0623817                        0.207139           0.152185              0.828345         0.985157          0.934241             2.02591            0.053424
    2019-08-03 16:37:16  30 min 34.282 sec  2427 obs/sec      10.4162   18            260404     0.213081         0.162369            0.818386       0.982984        0.950255           1.99861          0.0575984                        0.198606           0.142158              0.842197         0.986959          0.962133             2.02591            0.0477578
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0037435534250786894
C438        0.8137179017066956     0.8137179017066956   0.0030461964379819447
C88         0.7073072791099548     0.7073072791099548   0.00264784258729516
C374        0.6942209601402283     0.6942209601402283   0.002598853253094368
C322        0.6644688248634338     0.6644688248634338   0.0024874745451755197
---         ---                    ---                  ---
C630        0.1729235202074051     0.1729235202074051   0.0006473484363490953
C884        0.17197421193122864    0.17197421193122864  0.0006437946501003594
C925        0.16891862452030182    0.16891862452030182  0.000632355895382557
C430        0.16671191155910492    0.16671191155910492  0.0006240949475185028
C936        0.15515297651290894    0.15515297651290894  0.0005808234566360537

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_75

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight          weight_rms          mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  -------------------  ------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.001963204064480458    0.001806739717721939    0.0         0.02655551617769666  0.089040607213974   -0.015809352646085226   0.24214136600494385
    3        2        Softmax                      0.0   0.0   0.00023894241348898504  5.2506031352095306e-05  0.0         0.08323067641322268  0.7486081123352051  -0.0007671572860209162  0.029620014131069183


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.036707580810443105
RMSE: 0.19159222533924258
LogLoss: 0.14615959975422865
Mean Per-Class Error: 0.037683052970543196
AUC: 0.9886265113294226
pr_auc: 0.7096542185707895
Gini: 0.9772530226588452
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4949059332726206: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4852  196   0.0388   (196.0/5048.0)
1      182   4799  0.0365   (182.0/4981.0)
Total  5034  4995  0.0377   (378.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.494906     0.962109  205
max f2                       0.335269     0.968419  251
max f0point5                 0.609937     0.965124  171
max accuracy                 0.494906     0.962309  205
max precision                0.999967     0.997124  0
max recall                   2.12341e-05  1         399
max specificity              0.999967     0.999208  0
max absolute_mcc             0.494906     0.92462   205
max min_per_class_accuracy   0.49858      0.962163  204
max mean_per_class_accuracy  0.494906     0.962317  205
Gains/Lift Table: Avg response rate: 49.67 %, avg score: 49.77 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   1                  2.01345     2.01345            1                1            1                           1                   0.0202771       0.0202771                  101.345   101.345
    2        0.0200419                   1                  2.01345     2.01345            1                1            1                           1                   0.0200763       0.0403533                  101.345   101.345
    3        0.030013                    1                  1.99332     2.00676            0.99             1            0.996678                    1                   0.0198755       0.0602289                  99.3317   100.676
    4        0.0400838                   1                  2.01345     2.00844            1                1            0.997512                    1                   0.0202771       0.0805059                  101.345   100.844
    5        0.0500548                   1                  2.01345     2.00944            1                1            0.998008                    1                   0.0200763       0.100582                   101.345   100.944
    6        0.10001                     0.999979           2.00943     2.00944            0.998004         0.999995     0.998006                    0.999997            0.100381        0.200964                   100.943   100.944
    7        0.150065                    0.99965            2.00543     2.0081             0.996016         0.999865     0.997342                    0.999953            0.100381        0.301345                   100.543   100.81
    8        0.20002                     0.997317           1.99336     2.00442            0.99002          0.998803     0.995513                    0.999666            0.0995784       0.400924                   99.3357   100.442
    9        0.30003                     0.972886           1.9733      1.99405            0.98006          0.988987     0.990362                    0.996106            0.19735         0.598273                   97.3303   99.4046
    10       0.40004                     0.855982           1.96327     1.98635            0.975075         0.926936     0.98654                     0.978814            0.196346        0.79462                    96.3265   98.6351
    11       0.504537                    0.48498            1.66379     1.91954            0.826336         0.691138     0.95336                     0.919232            0.173861        0.96848                    66.3787   91.9543
    12       0.59996                     0.137693           0.244055    1.65306            0.121212         0.275013     0.821007                    0.816769            0.0232885       0.991769                   -75.5945  65.3058
    13       0.69997                     0.0233414          0.056208    1.4249             0.0279163        0.068162     0.707692                    0.70981             0.00562136      0.99739                    -94.3792  42.4904
    14       0.79998                     0.0011879          0.014052    1.24853            0.00697906       0.00873512   0.620092                    0.622165            0.00140534      0.998795                   -98.5948  24.8525
    15       0.89999                     4.53842e-06        0.00802972  1.11068            0.00398804       0.000265278  0.551629                    0.553057            0.000803052     0.999598                   -99.197   11.0677
    16       1                           1.60182e-36        0.00401486  1                  0.00199402       4.61969e-07  0.49666                     0.497746            0.000401526     1                          -99.5985  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03581787327150014
RMSE: 0.18925610497814896
LogLoss: 0.14318527153255314
Mean Per-Class Error: 0.03607651118684663
AUC: 0.9893010286379585
pr_auc: 0.7032289788236761
Gini: 0.9786020572759171
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4881942325163724: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3009  119   0.038    (119.0/3128.0)
1      104   2945  0.0341   (104.0/3049.0)
Total  3113  3064  0.0361   (223.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.488194     0.96352   205
max f2                       0.459534     0.970393  213
max f0point5                 0.595301     0.967546  178
max accuracy                 0.509503     0.963898  198
max precision                0.999211     0.99725   2
max recall                   1.97748e-05  1         399
max specificity              0.999973     0.999041  0
max absolute_mcc             0.488194     0.9278    205
max min_per_class_accuracy   0.499851     0.962939  201
max mean_per_class_accuracy  0.488194     0.963923  205
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.73 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999982           2.01935     2.01935            0.996764         0.999996     0.996764                    0.999998            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999697           2.01935     2.01935            0.996764         0.999884     0.996764                    0.99996             0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.997342           2.00624     2.01608            0.990291         0.998867     0.995146                    0.999687            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.971649           1.98979     2.00732            0.982172         0.988763     0.990826                    0.996049            0.198754        0.602165                   98.9792   100.732
    10       0.400032                    0.855576           1.95051     1.99312            0.962783         0.925039     0.983812                    0.97829             0.195146        0.797311                   95.0512   99.3115
    11       0.503481                    0.48498            1.68984     1.9308             0.834116         0.688732     0.953055                    0.918795            0.174811        0.972122                   68.9844   93.0803
    12       0.599968                    0.134049           0.214148    1.65473            0.105705         0.276719     0.816784                    0.815536            0.0206625       0.992785                   -78.5852  65.473
    13       0.700016                    0.0256458          0.0524507   1.42573            0.02589          0.0695484    0.703747                    0.708917            0.00524762      0.998032                   -94.7549  42.5727
    14       0.799903                    0.00126558         0.00656697  1.24851            0.00324149       0.00990384   0.616272                    0.621629            0.000655953     0.998688                   -99.3433  24.8512
    15       0.899951                    5.06439e-06        0.00983452  1.11081            0.00485437       0.000292012  0.5483                      0.552554            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           1.60182e-36        0.00327817  1                  0.00161812       5.24688e-07  0.493605                    0.497272            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:28:31  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:28:33  1:21:50.321  15964 obs/sec     1         1             25000      0.309808         0.417258            0.616059       0.940434        0.652027           2.01345          0.123143                         0.304452           0.389378              0.629174         0.944862          0.630998             2.02591            0.119799
    2019-08-03 17:28:39  1:21:56.252  17365 obs/sec     5         5             125000     0.224172         0.191892            0.798979       0.980271        0.760504           2.01345          0.0584306                        0.221139           0.187008              0.804359         0.98103           0.75424              2.02591            0.0581188
    2019-08-03 17:28:44  1:22:01.836  17925 obs/sec     9         9             225000     0.195249         0.152068            0.847505       0.987679        0.707261           2.01345          0.0398843                        0.191731           0.146672              0.852933         0.988989          0.723652             2.02591            0.0361017
    2019-08-03 17:28:46  1:22:03.417  18067 obs/sec     10        10            250000     0.191592         0.14616             0.853163       0.988627        0.709654           2.01345          0.0376907                        0.189256           0.143185              0.856705         0.989301          0.703229             2.02591            0.0361017
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0031122895457534948
C35         0.9821386337280273     0.9821386337280273   0.0030566998022323604
C28         0.9685720205307007     0.9685720205307007   0.003014476573807039
C22         0.9429463148117065     0.9429463148117065   0.002934721957795258
C79         0.8887742757797241     0.8887742757797241   0.002766122887043869
---         ---                    ---                  ---
C678        0.17306190729141235    0.17306190729141235  0.0005386187648312231
C562        0.17291559278964996    0.17291559278964996  0.000538163391736996
C461        0.1722954511642456     0.1722954511642456   0.0005362333314393634
C375        0.16997022926807404    0.16997022926807404  0.0005289965676403515
C731        0.1633191555738449     0.1633191555738449   0.0005082965005137662

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_31

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0028845970569011336  0.0024693766608834267  0.0         0.02719386165602094   0.09713485836982727  0.05047632859362732     0.21150285005569458
    3        2        Softmax                      0.0   0.0   0.0002665284066551976  5.176721606403589e-05  0.0         -0.11778845434309915  0.7414255142211914   0.00024446732113850983  0.12209242582321167


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03725619560031819
RMSE: 0.19301864055141976
LogLoss: 0.15094308732977665
Mean Per-Class Error: 0.03748715450474016
AUC: 0.9878547017862829
pr_auc: 0.7613495111674693
Gini: 0.9757094035725657
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5205393863806481: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4873  190   0.0375   (190.0/5063.0)
1      186   4781  0.0374   (186.0/4967.0)
Total  5059  4971  0.0375   (376.0/10030.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.520539     0.962165  201
max f2                       0.427691     0.966393  228
max f0point5                 0.582434     0.966362  183
max accuracy                 0.520539     0.962512  201
max precision                0.999973     0.998229  0
max recall                   4.69439e-05  1         399
max specificity              0.999973     0.999605  0
max absolute_mcc             0.520539     0.925019  201
max min_per_class_accuracy   0.520539     0.962473  201
max mean_per_class_accuracy  0.520539     0.962513  201
Gains/Lift Table: Avg response rate: 49.52 %, avg score: 49.08 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100698                   1                  2.01933     2.01933            1                1            1                           1                   0.0203342       0.0203342                  101.933   101.933
    2        0.0200399                   1                  2.01933     2.01933            1                1            1                           1                   0.0201329       0.0404671                  101.933   101.933
    3        0.03001                     1                  2.01933     2.01933            1                1            1                           1                   0.0201329       0.0606                     101.933   101.933
    4        0.0400798                   1                  2.01933     2.01933            1                1            1                           1                   0.0203342       0.0809342                  101.933   101.933
    5        0.0500499                   0.999999           2.01933     2.01933            1                0.999999     1                           1                   0.0201329       0.101067                   101.933   101.933
    6        0.1                         0.999914           2.0153      2.01731            0.998004         0.999974     0.999003                    0.999987            0.100664        0.201731                   101.53    101.731
    7        0.15005                     0.998936           2.01128     2.0153             0.996016         0.999566     0.998007                    0.999847            0.100664        0.302396                   101.128   101.53
    8        0.2                         0.994486           2.00321     2.01228            0.992016         0.99713      0.99651                     0.999168            0.10006         0.402456                   100.321   101.228
    9        0.3                         0.958275           1.99114     2.00523            0.986042         0.98053      0.993021                    0.992955            0.199114        0.60157                    99.1142   100.523
    10       0.4                         0.839718           1.969       1.99617            0.975075         0.90931      0.988534                    0.972044            0.1969          0.79847                    96.8995   99.6175
    11       0.5                         0.495389           1.67506     1.93195            0.829511         0.687618     0.95673                     0.915159            0.167506        0.965975                   67.5055   93.1951
    12       0.6                         0.121772           0.225488    1.64754            0.111665         0.265972     0.815886                    0.806961            0.0225488       0.988524                   -77.4512  64.754
    13       0.7                         0.0198415          0.0543588   1.41994            0.0269192        0.0589396    0.703176                    0.700101            0.00543588      0.99396                    -94.5641  41.9943
    14       0.8                         0.000901781        0.0382525   1.24723            0.0189432        0.00677029   0.617647                    0.613435            0.00382525      0.997785                   -96.1748  24.7232
    15       0.9                         3.57607e-06        0.0161063   1.11044            0.00797607       0.00020211   0.549906                    0.545298            0.00161063      0.999396                   -98.3894  11.044
    16       1                           1.36142e-38        0.00603986  1                  0.00299103       3.74488e-07  0.495214                    0.490768            0.000603986     1                          -99.396   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03518879641009541
RMSE: 0.18758677034933835
LogLoss: 0.14324057975275528
Mean Per-Class Error: 0.0353311198422358
AUC: 0.9893111992611724
pr_auc: 0.7845567271549891
Gini: 0.9786223985223448
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.526632355790697: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3027  101   0.0323   (101.0/3128.0)
1      117   2932  0.0384   (117.0/3049.0)
Total  3144  3033  0.0353   (218.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.526632     0.964157  195
max f2                       0.356933     0.970304  243
max f0point5                 0.582883     0.969797  179
max accuracy                 0.526632     0.964708  195
max precision                0.999773     0.998759  1
max recall                   2.95007e-05  1         399
max specificity              0.999983     0.99968   0
max absolute_mcc             0.526632     0.929412  195
max min_per_class_accuracy   0.511418     0.963875  200
max mean_per_class_accuracy  0.526632     0.964669  195
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.09 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999999           2.02591     2.02591            1                0.999999     1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999902           2.01935     2.02263            0.996764         0.99997      0.998382                    0.999985            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999102           2.01935     2.02154            0.996764         0.999628     0.997843                    0.999866            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.995238           2.0128      2.01935            0.993528         0.99766      0.996764                    0.999315            0.100689        0.404067                   101.28    101.935
    9        0.299984                    0.961233           2.00293     2.01388            0.988655         0.982318     0.994064                    0.993655            0.200066        0.604133                   100.293   101.388
    10       0.400032                    0.846181           1.97674     2.00459            0.975728         0.912233     0.989478                    0.973292            0.19777         0.801902                   97.6738   100.459
    11       0.500081                    0.458634           1.66203     1.93606            0.820388         0.686597     0.955649                    0.915934            0.166284        0.968186                   66.2033   93.6059
    12       0.599968                    0.122755           0.223277    1.6509             0.110211         0.262522     0.814895                    0.80715             0.0223024       0.990489                   -77.6723  65.0904
    13       0.700016                    0.0198045          0.0524507   1.42245            0.02589          0.0595284    0.702128                    0.700297            0.00524762      0.995736                   -94.7549  42.2448
    14       0.799903                    0.00102165         0.0262679   1.2481             0.012966         0.00699606   0.61607                     0.613722            0.00262381      0.99836                    -97.3732  24.8102
    15       0.899951                    4.71438e-06        0.00655634  1.11008            0.00323625       0.000239557  0.54794                     0.545521            0.000655953     0.999016                   -99.3444  11.0078
    16       1                           1.11476e-35        0.00983452  1                  0.00485437       5.4539e-07   0.493605                    0.490942            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:43:05  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:43:07  36 min 24.902 sec  15943 obs/sec     1         1             25000      0.308399         0.379802            0.619526       0.940917        0.73145            2.01933          0.124526                         0.300246           0.352477              0.639351         0.945819          0.737669             2.02591            0.115752
    2019-08-03 16:43:13  36 min 30.981 sec  16949 obs/sec     5         5             125000     0.233283         0.205185            0.782296       0.977057        0.805347           2.01933          0.063011                         0.224883           0.192075              0.797678         0.980088          0.77741              2.02591            0.0569856
    2019-08-03 16:43:19  36 min 36.691 sec  17553 obs/sec     9         9             225000     0.20145          0.161919            0.837656       0.985869        0.735869           2.01933          0.0422732                        0.195928           0.153306              0.846423         0.987641          0.744595             2.02591            0.0386919
    2019-08-03 16:43:21  36 min 38.308 sec  17649 obs/sec     10        10            250000     0.193019         0.150943            0.850962       0.987855        0.76135            2.01933          0.0374875                        0.187587           0.143241              0.859222         0.989311          0.784557             2.02591            0.0352922
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C36         1.0                    1.0                  0.003219991485121689
C28         0.9926892518997192     0.9926892518997192   0.0031964509384889155
C250        0.9219897389411926     0.9219897389411926   0.0029687991087602094
C25         0.9126116037368774     0.9126116037368774   0.0029386015932559946
C35         0.9012733697891235     0.9012733697891235   0.0029020925764879093
---         ---                    ---                  ---
C599        0.16984078288078308    0.16984078288078308  0.0005468858747025231
C467        0.1680470108985901     0.1680470108985901   0.0005411099441936118
C360        0.1639080047607422     0.1639080047607422   0.0005277823796728751
C446        0.16070987284183502    0.16070987284183502  0.0005174844221256981
C497        0.1454988569021225     0.1454988569021225   0.00046850508031977354

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_106

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.002313211881961734   0.0021157823503017426   0.0         0.02790226717703574    0.09366190433502197  -0.10422360539030356    0.36171114444732666
    3        2        Softmax                      0.0   0.0   0.0002160704264042579  4.2353771277703345e-05  0.0         -0.025989254849264398  0.7195711135864258   -0.0001593686871816033  0.10321104526519775


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.038676368440459706
RMSE: 0.19666308357304813
LogLoss: 0.1529373881397539
Mean Per-Class Error: 0.04130506192880545
AUC: 0.9874307240296984
pr_auc: 0.7173078472815881
Gini: 0.9748614480593969
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5257623461184464: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4802  208   0.0415   (208.0/5010.0)
1      206   4807  0.0411   (206.0/5013.0)
Total  5008  5015  0.0413   (414.0/10023.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525762     0.958716  200
max f2                       0.34729      0.965911  247
max f0point5                 0.62177      0.961898  172
max accuracy                 0.525762     0.958695  200
max precision                0.999973     0.997788  0
max recall                   1.45897e-05  1         399
max specificity              0.999973     0.999401  0
max absolute_mcc             0.525762     0.91739   200
max min_per_class_accuracy   0.525762     0.958483  200
max mean_per_class_accuracy  0.525762     0.958695  200
Gains/Lift Table: Avg response rate: 50.01 %, avg score: 49.76 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100768                   1                  1.9994      1.9994             1                1            1                           1                   0.0201476       0.0201476                  99.9402   99.9402
    2        0.0200539                   1                  1.97941     1.98945            0.99             1            0.995025                    1                   0.0197487       0.0398963                  97.9408   98.9454
    3        0.0300309                   1                  1.97941     1.98612            0.99             1            0.993355                    1                   0.0197487       0.0596449                  97.9408   98.6116
    4        0.040008                    1                  1.9994      1.98943            1                1            0.995012                    1                   0.0199481       0.0795931                  99.9402   98.9429
    5        0.0500848                   1                  1.9994      1.99144            1                1            0.996016                    1                   0.0201476       0.0997407                  99.9402   99.1436
    6        0.10007                     0.999978           1.9994      1.99541            1                0.999994     0.998006                    0.999997            0.0999402       0.199681                   99.9402   99.5415
    7        0.150055                    0.999604           1.98743     1.99275            0.994012         0.999847     0.996676                    0.999947            0.0993417       0.299023                   98.7429   99.2755
    8        0.20004                     0.997386           1.99142     1.99242            0.996008         0.998758     0.996509                    0.99965             0.0995412       0.398564                   99.142    99.2421
    9        0.30001                     0.970631           1.97147     1.98544            0.986028         0.987462     0.993016                    0.995589            0.197088        0.595651                   97.1466   98.5438
    10       0.39998                     0.858608           1.91959     1.96898            0.96008          0.925043     0.984784                    0.977957            0.191901        0.787552                   91.9585   96.8979
    11       0.50005                     0.526704           1.70637     1.91643            0.85344          0.709527     0.9585                      0.924239            0.170756        0.958308                   70.6369   91.6426
    12       0.60002                     0.128235           0.319266    1.65032            0.159681         0.285886     0.825407                    0.817882            0.031917        0.990225                   -68.0734  65.0321
    13       0.69999                     0.0196702          0.0618577   1.42346            0.0309381        0.0619672    0.711944                    0.709925            0.00618392      0.996409                   -93.8142  42.3462
    14       0.79996                     0.000677229        0.0219495   1.24832            0.010978         0.00661512   0.624345                    0.622033            0.00219429      0.998604                   -97.805   24.8317
    15       0.89993                     1.2697e-06         0.0119725   1.11098            0.00598802       0.000139759  0.555654                    0.552949            0.00119689      0.999801                   -98.8028  11.0976
    16       1                           1.84362e-38        0.00199342  1                  0.000997009      1.2894e-07   0.50015                     0.497616            0.000199481     1                          -99.8007  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03622697446821036
RMSE: 0.19033385003254247
LogLoss: 0.1458780334607126
Mean Per-Class Error: 0.035945656158280936
AUC: 0.9889313736674386
pr_auc: 0.7391686206477418
Gini: 0.9778627473348771
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5178781319496013: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3017  111   0.0355   (111.0/3128.0)
1      111   2938  0.0364   (111.0/3049.0)
Total  3128  3049  0.0359   (222.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.517878     0.963595  198
max f2                       0.423516     0.966995  222
max f0point5                 0.570828     0.96887   185
max accuracy                 0.517878     0.96406   198
max precision                0.999673     0.997923  1
max recall                   1.90565e-05  1         399
max specificity              0.999984     0.999361  0
max absolute_mcc             0.517878     0.928109  198
max min_per_class_accuracy   0.517878     0.963595  198
max mean_per_class_accuracy  0.517878     0.964054  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.11 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323     2.00957            0.983871         1            0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   1                  2.02591     2.01502            1                1            0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   1                  2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999974           2.02591     2.02263            1                0.999994     0.998382                    0.999997            0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.999517           2.01935     2.02154            0.996764         0.999818     0.997843                    0.999938            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.996985           2.01935     2.02099            0.996764         0.9986       0.997573                    0.999603            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.964835           1.99636     2.01279            0.985413         0.985988     0.993524                    0.99507             0.19941         0.603805                   99.6359   101.279
    10       0.400032                    0.841125           1.95379     1.99803            0.964401         0.914373     0.98624                     0.974887            0.195474        0.799278                   95.379    99.8034
    11       0.500081                    0.472281           1.69154     1.93671            0.834951         0.683706     0.955973                    0.916632            0.169236        0.968514                   69.1537   93.6715
    12       0.599968                    0.123321           0.236411    1.65364            0.116694         0.261195     0.816244                    0.807511            0.0236143       0.992129                   -76.3589  65.3637
    13       0.700016                    0.0190959          0.0426162   1.42338            0.0210356        0.0590065    0.70259                     0.700532            0.00426369      0.996392                   -95.7384  42.3385
    14       0.799903                    0.000773085        0.0229844   1.24851            0.0113452        0.00657579   0.616272                    0.613875            0.00229583      0.998688                   -97.7016  24.8512
    15       0.899951                    1.65287e-06        0.00983452  1.11081            0.00485437       0.000158308  0.5483                      0.545648            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           1.84362e-38        0.00327817  1                  0.00161812       1.58515e-07  0.493605                    0.491056            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:07:45  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:07:46  2:01:04.045  16297 obs/sec     1         1             25000      0.319435         0.447453            0.591845       0.934864        0.666592           1.9994           0.131597                         0.312764           0.437308              0.60865          0.93779           0.676962             2.02591            0.12417
    2019-08-03 18:07:52  2:01:09.864  17675 obs/sec     5         5             125000     0.230987         0.206348            0.786581       0.977459        0.732946           1.9994           0.0652499                        0.225964           0.199293              0.795727         0.978672          0.713807             2.02591            0.0587664
    2019-08-03 18:07:58  2:01:15.514  18065 obs/sec     9         9             225000     0.204776         0.164925            0.832267       0.985604        0.695325           1.9994           0.0463933                        0.197257           0.154638              0.844333         0.98718           0.706827             2.02591            0.0396633
    2019-08-03 18:07:59  2:01:17.167  18121 obs/sec     10        10            250000     0.196663         0.152937            0.845295       0.987431        0.717308           1.9994           0.041305                         0.190334           0.145878              0.855068         0.988931          0.739169             2.02591            0.0359398
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C36         1.0                    1.0                  0.003603715517327331
C35         0.9062314629554749     0.9062314629554749   0.003265800385342893
C25         0.8906978964805603     0.8906978964805603   0.003209821830797808
C28         0.8837956786155701     0.8837956786155701   0.0031849482011737686
C250        0.8633341193199158     0.8633341193199158   0.003111210562431306
---         ---                    ---                  ---
C604        0.1506885141134262     0.1506885141134262   0.0005430385365935525
C662        0.14527203142642975    0.14527203142642975  0.0005235190738850885
C475        0.14453673362731934    0.14453673362731934  0.0005208692697965777
C780        0.1406024694442749     0.1406024694442749   0.0005066913009108754
C651        0.13260337710380554    0.13260337710380554  0.00047786484771899173

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_235

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0120486431113948     0.025547035038471222   0.0         0.017975513024256887   0.06855437159538269  0.13630597217600637    0.11308085918426514
    3        2        Softmax                      0.0   0.0   0.0002818785680887004  8.061091648414731e-05  0.0         0.0004435877779656039  0.24842476844787598  4.060094470219322e-05  0.11167743802070618


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03935270096652342
RMSE: 0.19837515208947773
LogLoss: 0.15858794968556258
Mean Per-Class Error: 0.04125510227295859
AUC: 0.9860325140560711
pr_auc: 0.7780100332794713
Gini: 0.9720650281121421
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5170131984910609: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4806  204   0.0407   (204.0/5010.0)
1      209   4792  0.0418   (209.0/5001.0)
Total  5015  4996  0.0413   (413.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.517013     0.958688  201
max f2                       0.310359     0.966505  258
max f0point5                 0.583506     0.962689  184
max accuracy                 0.517013     0.958745  201
max precision                0.999549     0.995249  1
max recall                   3.42228e-05  1         399
max specificity              0.999949     0.998802  0
max absolute_mcc             0.517013     0.917491  201
max min_per_class_accuracy   0.513932     0.958283  202
max mean_per_class_accuracy  0.517013     0.958745  201
Gains/Lift Table: Avg response rate: 49.96 %, avg score: 49.80 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   1                  2.0018     2.0018             1                1            1                           1                   0.020196        0.020196                   100.18    100.18
    2        0.0200779                   1                  2.0018     2.0018             1                1            1                           1                   0.019996        0.040192                   100.18    100.18
    3        0.0300669                   1                  2.0018     2.0018             1                1            1                           1                   0.019996        0.060188                   100.18    100.18
    4        0.0400559                   0.999998           2.0018     2.0018             1                0.999999     1                           1                   0.019996        0.080184                   100.18    100.18
    5        0.050045                    0.999995           1.98178    1.9978             0.99             0.999997     0.998004                    0.999999            0.019796        0.09998                    98.1782   99.7804
    6        0.10009                     0.999775           1.98182    1.98981            0.99002          0.999927     0.994012                    0.999963            0.0991802       0.19916                    98.1822   98.9813
    7        0.150035                    0.998127           1.99379    1.99114            0.996            0.999174     0.994674                    0.9997              0.0995801       0.29874                    99.3792   99.1138
    8        0.20008                     0.992978           1.98582    1.98981            0.992016         0.996024     0.994009                    0.998781            0.0993801       0.39812                    98.5817   98.9807
    9        0.30007                     0.956884           1.9658     1.98181            0.982018         0.978729     0.990013                    0.992099            0.196561        0.594681                   96.5803   98.1808
    10       0.40006                     0.840341           1.93381    1.96981            0.966034         0.90689      0.98402                     0.970802            0.193361        0.788042                   93.3806   96.9811
    11       0.50005                     0.509136           1.70583    1.91703            0.852148         0.712959     0.957651                    0.919244            0.170566        0.958608                   70.5829   91.7025
    12       0.60004                     0.146622           0.289971   1.64589            0.144855         0.292479     0.822207                    0.8148              0.0289942       0.987602                   -71.0029  64.5895
    13       0.70003                     0.0306831          0.0819918  1.42251            0.040959         0.0784272    0.710616                    0.709619            0.00819836      0.995801                   -91.8008  42.2512
    14       0.80002                     0.00237738         0.0219978  1.24747            0.010989         0.012202     0.623174                    0.622453            0.00219956      0.998                      -97.8002  24.7469
    15       0.90001                     2.37484e-05        0.0159984  1.11065            0.00799201       0.000648537  0.554828                    0.553371            0.00159968      0.9996                     -98.4002  11.0654
    16       1                           3.2405e-31         0.0039996  1                  0.001998         2.84686e-06  0.49955                     0.49804             0.00039992      1                          -99.6     0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03623397591861507
RMSE: 0.19035224169579687
LogLoss: 0.14590657351646116
Mean Per-Class Error: 0.03454017039673396
AUC: 0.9886615900228074
pr_auc: 0.7837316882923191
Gini: 0.9773231800456148
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5466039807722015: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3034  94    0.0301   (94.0/3128.0)
1      119   2930  0.039    (119.0/3049.0)
Total  3153  3024  0.0345   (213.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.546604     0.964927  193
max f2                       0.419027     0.970893  225
max f0point5                 0.563068     0.967817  189
max accuracy                 0.546604     0.965517  193
max precision                0.997349     0.998086  5
max recall                   5.26253e-05  1         399
max specificity              0.999964     0.999361  0
max absolute_mcc             0.546604     0.931047  193
max min_per_class_accuracy   0.512703     0.964907  199
max mean_per_class_accuracy  0.546604     0.96546   193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.45 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591    2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323    2.00957            0.983871         1            0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   1                  2.02591    2.01502            1                1            0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999999           2.02591    2.01774            1                0.999999     0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999995           2.02591    2.01935            1                0.999997     0.996764                    0.999999            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999791           2.01935    2.01935            0.996764         0.999935     0.996764                    0.999967            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998339           2.02591    2.02154            1                0.999274     0.997843                    0.999736            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.993286           2.01935    2.02099            0.996764         0.996195     0.997573                    0.998851            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.953872           1.99308    2.0117             0.983793         0.978888     0.992984                    0.992204            0.199082        0.603477                   99.3075   101.17
    10       0.400032                    0.827889           1.97018    2.00131            0.972492         0.900763     0.987859                    0.969334            0.197114        0.80059                    97.0181   100.131
    11       0.500081                    0.473509           1.70137    1.94131            0.839806         0.698557     0.958239                    0.915161            0.17022         0.97081                    70.1371   94.1306
    12       0.599968                    0.140905           0.183875   1.64872            0.0907618        0.278491     0.813815                    0.809164            0.0183667       0.989177                   -81.6125  64.8717
    13       0.700016                    0.0317385          0.0655634  1.42245            0.0323625        0.0762922    0.702128                    0.70442             0.00655953      0.995736                   -93.4437  42.2448
    14       0.799903                    0.00257005         0.0229844  1.24769            0.0113452        0.0130321    0.615867                    0.618084            0.00229583      0.998032                   -97.7016  24.7692
    15       0.899951                    2.9984e-05         0.019669   1.11117            0.00970874       0.000718244  0.54848                     0.549451            0.00196786      1                          -98.0331  11.1171
    16       1                           3.2405e-31         0          1                  0                3.9871e-06   0.493605                    0.494479            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:55:42  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:55:49  4:49:07.396  3879 obs/sec      1         1             25000      0.300623         0.369104            0.638502       0.945982        0.711995           2.0018           0.115273                         0.291881           0.33649               0.659166         0.951519          0.691357             1.99323            0.108629
    2019-08-03 20:56:03  4:49:21.040  3932 obs/sec      3         3             75000      0.258512         0.244634            0.732686       0.966429        0.790166           2.0018           0.0824093                        0.250683           0.22658               0.748591         0.971044          0.792318             2.02591            0.0775457
    2019-08-03 20:56:15  4:49:33.880  4066 obs/sec      5         5             125000     0.239194         0.21289             0.771144       0.974236        0.81743            2.0018           0.0672261                        0.229931           0.193948              0.788492         0.978832          0.831889             2.02591            0.0610329
    2019-08-03 20:56:28  4:49:46.360  4159 obs/sec      7         7             175000     0.220384         0.185215            0.805723       0.980797        0.83421            2.0018           0.0528419                        0.213447           0.172317              0.817732         0.98375           0.820141             2.02591            0.048891
    2019-08-03 20:56:40  4:49:58.590  4236 obs/sec      9         9             225000     0.207728         0.169726            0.827397       0.984098        0.767739           2.0018           0.0438518                        0.202659           0.15919               0.835691         0.986488          0.771196             2.02591            0.0396633
    2019-08-03 20:56:47  4:50:05.177  4270 obs/sec      10        10            250000     0.198375         0.158588            0.842589       0.986033        0.77801            2.0018           0.0412546                        0.190352           0.145907              0.85504          0.988662          0.783732             2.02591            0.0344828
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.003457506756052167
C34         0.9679316282272339     0.9679316282272339   0.003346630143992236
C36         0.9517493844032288     0.9517493844032288   0.0032906799266426544
C28         0.9168192148208618     0.9168192148208618   0.003169908629321573
C25         0.8499372005462646     0.8499372005462646   0.0029386636131087758
---         ---                    ---                  ---
C713        0.20958377420902252    0.20958377420902252  0.0007246373152866073
C938        0.20446230471134186    0.20446230471134186  0.0007069297998974613
C721        0.203378826379776      0.203378826379776    0.0007031836662460362
C945        0.19973500072956085    0.19973500072956085  0.0006905851144425411
C888        0.19730541110038757    0.19730541110038757  0.0006821847918852403

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_109

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.010136871378521697    0.012114070355892181   0.0         0.018001725062734338    0.06789544224739075  0.10731784651640637    0.13498902320861816
    3        2        Softmax                      0.0   0.0   0.00027735628748359886  7.157193613238633e-05  0.0         -0.0010419494740290247  0.23983585834503174  0.0014858834110337768  0.10158166289329529


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.037980257599319486
RMSE: 0.19488524212807773
LogLoss: 0.15031702979945682
Mean Per-Class Error: 0.03731443677509083
AUC: 0.9878769010324158
pr_auc: 0.8051590123917102
Gini: 0.9757538020648315
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5043751350630721: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4823  197   0.0392   (197.0/5020.0)
1      177   4825  0.0354   (177.0/5002.0)
Total  5000  5022  0.0373   (374.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.504375     0.96269   202
max f2                       0.398358     0.968132  232
max f0point5                 0.605224     0.966595  176
max accuracy                 0.510044     0.962682  201
max precision                0.999972     0.998907  0
max recall                   5.81015e-05  1         399
max specificity              0.999972     0.999801  0
max absolute_mcc             0.504375     0.925372  202
max min_per_class_accuracy   0.515925     0.962415  199
max mean_per_class_accuracy  0.504375     0.962686  202
Gains/Lift Table: Avg response rate: 49.91 %, avg score: 49.87 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   1                  2.0036      2.0036             1                1            1                           1                   0.0201919       0.0201919                  100.36    100.36
    2        0.0200559                   1                  2.0036      2.0036             1                1            1                           1                   0.019992        0.0401839                  100.36    100.36
    3        0.0300339                   1                  2.0036      2.0036             1                1            1                           1                   0.019992        0.0601759                  100.36    100.36
    4        0.040012                    0.999998           2.0036      2.0036             1                0.999999     1                           1                   0.019992        0.0801679                  100.36    100.36
    5        0.0500898                   0.999993           1.98376     1.99961            0.990099         0.999996     0.998008                    0.999999            0.019992        0.10016                    98.3761   99.9607
    6        0.10008                     0.999747           2.0036      2.0016             1                0.999918     0.999003                    0.999958            0.10016         0.20032                    100.36    100.16
    7        0.15007                     0.998193           1.9916      1.99827            0.994012         0.999147     0.99734                     0.999688            0.0995602       0.29988                    99.1601   99.827
    8        0.20006                     0.992853           1.9956      1.9976             0.996008         0.995984     0.997007                    0.998762            0.0997601       0.39964                    99.56     99.7603
    9        0.30004                     0.953268           1.96961     1.98827            0.983034         0.977585     0.992351                    0.991706            0.196921        0.596561                   96.9605   98.8273
    10       0.40002                     0.838489           1.94761     1.97811            0.972056         0.905025     0.987279                    0.970041            0.194722        0.791283                   94.761    97.811
    11       0.5                         0.509339           1.72365     1.92723            0.860279         0.706279     0.961884                    0.917299            0.172331        0.963615                   72.3655   92.7229
    12       0.59998                     0.15847            0.25195     1.64806            0.125749         0.301188     0.822551                    0.814631            0.0251899       0.988804                   -74.805   64.8062
    13       0.69996                     0.0339384          0.0659868   1.42208            0.0329341        0.0847796    0.709765                    0.710381            0.00659736      0.995402                   -93.4013  42.2084
    14       0.79994                     0.0026752          0.0259948   1.24759            0.0129741        0.0135273    0.622677                    0.623285            0.00259896      0.998001                   -97.4005  24.7594
    15       0.89992                     2.4225e-05         0.0179964   1.11099            0.00898204       0.000681188  0.554496                    0.554115            0.00179928      0.9998                     -98.2004  11.0988
    16       1                           7.12075e-32        0.00199761  1                  0.000997009      2.97379e-06  0.499102                    0.498659            0.00019992      1                          -99.8002  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.036592645747006144
RMSE: 0.19129204308336023
LogLoss: 0.14633212673057328
Mean Per-Class Error: 0.034212194011033814
AUC: 0.9887766648576238
pr_auc: 0.7711679636107441
Gini: 0.9775533297152477
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5242991349345826: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3034  94    0.0301   (94.0/3128.0)
1      117   2932  0.0384   (117.0/3049.0)
Total  3151  3026  0.0342   (211.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.524299     0.965267  193
max f2                       0.40519      0.969245  223
max f0point5                 0.55395      0.970199  186
max accuracy                 0.55395      0.965841  186
max precision                0.99397      0.997531  8
max recall                   2.5207e-05   1         399
max specificity              0.99994      0.999361  0
max absolute_mcc             0.55395      0.931793  186
max min_per_class_accuracy   0.503957     0.964907  198
max mean_per_class_accuracy  0.524299     0.965788  193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.27 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999998           1.99323     2.01774            0.983871         0.999999     0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999992           2.02591     2.01935            1                0.999995     0.996764                    0.999999            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999762           2.01935     2.01935            0.996764         0.999917     0.996764                    0.999958            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998196           2.01935     2.01935            0.996764         0.999191     0.996764                    0.999702            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.992958           2.02591     2.02099            1                0.996057     0.997573                    0.998791            0.101345        0.404395                   102.591   102.099
    9        0.299984                    0.949561           1.99636     2.01279            0.985413         0.976831     0.993524                    0.991479            0.19941         0.603805                   99.6359   101.279
    10       0.400032                    0.830076           1.96035     1.99967            0.967638         0.900121     0.98705                     0.96863             0.19613         0.799934                   96.0347   99.9674
    11       0.500081                    0.455485           1.6817      1.93606            0.830097         0.683509     0.955649                    0.911588            0.168252        0.968186                   68.1702   93.6059
    12       0.599968                    0.147764           0.21671     1.64981            0.106969         0.273294     0.814355                    0.80532             0.0216464       0.989833                   -78.329   64.981
    13       0.700016                    0.0339709          0.0524507   1.42151            0.02589          0.0812357    0.701665                    0.701832            0.00524762      0.99508                    -94.7549  42.151
    14       0.799903                    0.00267501         0.0361183   1.24851            0.0178282        0.0132972    0.616272                    0.615852            0.00360774      0.998688                   -96.3882  24.8512
    15       0.899951                    2.83249e-05        0.00983452  1.11081            0.00485437       0.00074438   0.5483                      0.54747             0.000983929     0.999672                   -99.0165  11.0807
    16       1                           7.12075e-32        0.00327817  1                  0.00161812       3.80873e-06  0.493605                    0.492697            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:10:47  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:10:53  2:04:11.654  3924 obs/sec      1         1             25000      0.300744         0.370705            0.638211       0.94733         0.715991           1.98376          0.114947                         0.288278           0.340912              0.66753          0.952917          0.705006             2.02591            0.107172
    2019-08-03 18:11:06  2:04:24.774  4078 obs/sec      3         3             75000      0.258974         0.243692            0.731729       0.967002        0.78496            2.0036           0.0841149                        0.24962            0.22869               0.750718         0.970921          0.784372             2.02591            0.0783552
    2019-08-03 18:11:19  2:04:37.511  4175 obs/sec      5         5             125000     0.238228         0.208796            0.77299        0.975228        0.802893           2.0036           0.0670525                        0.229756           0.193968              0.788813         0.979035          0.813279             2.02591            0.0592521
    2019-08-03 18:11:31  2:04:49.888  4248 obs/sec      7         7             175000     0.223728         0.189294            0.799783       0.980241        0.795394           2.0036           0.0525843                        0.215752           0.17746               0.813775         0.983102          0.783086             2.02591            0.0490529
    2019-08-03 18:11:44  2:05:02.833  4238 obs/sec      9         9             225000     0.204111         0.161341            0.833354       0.98605         0.810056           2.0036           0.0429056                        0.199145           0.155887              0.841339         0.98718           0.807475             2.02591            0.039987
    2019-08-03 18:11:51  2:05:09.525  4259 obs/sec      10        10            250000     0.194885         0.150317            0.848078       0.987877        0.805159           2.0036           0.0373179                        0.191292           0.146332              0.853605         0.988777          0.771168             2.02591            0.034159
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0030473123325415264
C25         0.9924867749214172     0.9924867749214172   0.0030244171891024006
C28         0.9894099235534668     0.9894099235534668   0.0030150410619834483
C40         0.965971827507019      0.965971827507019    0.002943617862849815
C27         0.9507516026496887     0.9507516026496887   0.002897237083938017
---         ---                    ---                  ---
C753        0.23497803509235382    0.23497803509235382  0.0007160514642133054
C629        0.23428718745708466    0.23428718745708466  0.0007139462356944425
C443        0.23153837025165558    0.23153837025165558  0.0007055697311244361
C478        0.23015446960926056    0.23015446960926056  0.0007013525536298536
C752        0.22510884702205658    0.22510884702205658  0.0006859769656945169

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_161

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight          weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  -------------------  -------------------  ---------------------  ------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0028520228289798237   0.0026402082294225693  0.0         0.02721462489806905  0.09620344638824463  0.07556890691306542    0.2680630683898926
    3        2        Softmax                      0.0   0.0   0.00020486335074565432  3.435564576648176e-05  0.0         -0.1176915556716267  0.7830173969268799   0.0006537206939264129  0.1444544792175293


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03898531295174424
RMSE: 0.19744698769984878
LogLoss: 0.15452091465124745
Mean Per-Class Error: 0.04043784522037397
AUC: 0.9867660705163079
pr_auc: 0.7334554818607246
Gini: 0.9735321410326159
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5006759401414975: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4816  226   0.0448   (226.0/5042.0)
1      180   4794  0.0362   (180.0/4974.0)
Total  4996  5020  0.0405   (406.0/10016.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.500676     0.959376  205
max f2                       0.362797     0.965724  244
max f0point5                 0.591707     0.963716  178
max accuracy                 0.527066     0.959565  197
max precision                0.999957     0.998413  0
max recall                   1.6602e-05   1         399
max specificity              0.999957     0.999603  0
max absolute_mcc             0.527066     0.919126  197
max min_per_class_accuracy   0.527066     0.959188  197
max mean_per_class_accuracy  0.527066     0.959562  197
Gains/Lift Table: Avg response rate: 49.66 %, avg score: 49.67 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100839                   1                  2.01367     2.01367            1                1            1                           1                   0.0203056       0.0203056                  101.367   101.367
    2        0.0200679                   1                  2.01367     2.01367            1                1            1                           1                   0.0201045       0.0404101                  101.367   101.367
    3        0.0300519                   1                  2.01367     2.01367            1                1            1                           1                   0.0201045       0.0605147                  101.367   101.367
    4        0.0400359                   1                  1.99353     2.00865            0.99             1            0.997506                    1                   0.0199035       0.0804182                  99.3534   100.865
    5        0.05002                     0.999999           2.01367     2.00965            1                0.999999     0.998004                    1                   0.0201045       0.100523                   101.367   100.965
    6        0.10004                     0.999929           2.00965     2.00965            0.998004         0.999979     0.998004                    0.99999             0.100523        0.201045                   100.965   100.965
    7        0.15006                     0.999122           1.99759     2.00563            0.992016         0.999656     0.996008                    0.999879            0.0999196       0.300965                   99.7594   100.563
    8        0.20008                     0.995815           1.99357     2.00262            0.99002          0.997826     0.994511                    0.999365            0.0997185       0.400684                   99.3575   100.262
    9        0.30002                     0.96306            1.98551     1.99692            0.986014         0.983618     0.991681                    0.99412             0.198432        0.599115                   98.5508   99.6918
    10       0.40006                     0.84797            1.93529     1.98151            0.961078         0.917786     0.984028                    0.975031            0.193607        0.792722                   93.5295   98.1509
    11       0.5                         0.507758           1.69382     1.924              0.841159         0.699936     0.955471                    0.920045            0.16928         0.962002                   69.3817   92.4005
    12       0.60004                     0.134593           0.269293    1.64813            0.133733         0.286443     0.818469                    0.81441             0.0269401       0.988943                   -73.0707  64.8128
    13       0.69998                     0.0284531          0.0683964   1.42258            0.033966         0.0695863    0.706461                    0.708067            0.00683554      0.995778                   -93.1604  42.2581
    14       0.80002                     0.00178261         0.0241158   1.24771            0.011976         0.0104387    0.619618                    0.620831            0.00241255      0.998191                   -97.5884  24.7707
    15       0.89996                     8.82907e-06        0.0160933   1.11094            0.00799201       0.00042539   0.551697                    0.551935            0.00160836      0.999799                   -98.3907  11.0937
    16       1                           1.76956e-27        0.00200965  1                  0.000998004      1.10605e-06  0.496605                    0.49672             0.000201045     1                          -99.799   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03716240614566346
RMSE: 0.1927755330576561
LogLoss: 0.14640045180460173
Mean Per-Class Error: 0.0365353426011128
AUC: 0.9883900238978189
pr_auc: 0.7656087166971917
Gini: 0.9767800477956379
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5148393373368831: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3001  127   0.0406   (127.0/3128.0)
1      99    2950  0.0325   (99.0/3049.0)
Total  3100  3077  0.0366   (226.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.514839     0.963108  201
max f2                       0.456307     0.967731  219
max f0point5                 0.604718     0.965274  173
max accuracy                 0.530803     0.963413  196
max precision                0.999982     0.998527  0
max recall                   2.10602e-05  1         399
max specificity              0.999982     0.99968   0
max absolute_mcc             0.514839     0.92686   201
max min_per_class_accuracy   0.533981     0.962916  195
max mean_per_class_accuracy  0.514839     0.963465  201
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.65 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999999           2.02591     2.02591            1                0.999999     1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.99993            2.01935     2.02263            0.996764         0.999981     0.998382                    0.999991            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999224           2.0128      2.01935            0.993528         0.999702     0.996764                    0.999894            0.100689        0.30305                    101.28    101.935
    8        0.200097                    0.996353           2.00624     2.01608            0.990291         0.998031     0.995146                    0.999428            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.96432            2.00293     2.0117             0.988655         0.984955     0.992984                    0.994609            0.200066        0.603477                   100.293   101.17
    10       0.400032                    0.849871           1.95379     1.99721            0.964401         0.917826     0.985836                    0.975406            0.195474        0.79895                    95.379    99.7215
    11       0.500081                    0.503584           1.69481     1.93671            0.83657          0.698407     0.955973                    0.919988            0.169564        0.968514                   69.4815   93.6715
    12       0.599968                    0.134807           0.21671     1.65036            0.106969         0.283196     0.814625                    0.813971            0.0216464       0.990161                   -78.329   65.0357
    13       0.700016                    0.0281551          0.0622853   1.42338            0.0307443        0.0705401    0.70259                     0.707717            0.00623155      0.996392                   -93.7715  42.3385
    14       0.799903                    0.00188272         0.0262679   1.24892            0.012966         0.010579     0.616474                    0.620663            0.00262381      0.999016                   -97.3732  24.8922
    15       0.899951                    1.0229e-05         0.00655634  1.11081            0.00323625       0.000444435  0.5483                      0.551713            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           3.38686e-35        0.00327817  1                  0.00161812       1.17737e-06  0.493605                    0.496515            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:13:08  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:13:10  3:06:27.259  16118 obs/sec     1         1             25000      0.310015         0.378351            0.615544       0.93889         0.738918           2.01367          0.124501                         0.300555           0.356994              0.638609         0.944767          0.722523             2.02591            0.119314
    2019-08-03 19:13:16  3:06:33.400  16853 obs/sec     5         5             125000     0.235513         0.208344            0.778125       0.976093        0.770569           2.01367          0.0635982                        0.228743           0.196519              0.790672         0.978757          0.764512             2.02591            0.0597377
    2019-08-03 19:13:21  3:06:39.147  17451 obs/sec     9         9             225000     0.201918         0.161958            0.836908       0.985691        0.762996           2.01367          0.0439297                        0.196576           0.153426              0.845406         0.987533          0.769122             2.02591            0.0390157
    2019-08-03 19:13:23  3:06:40.856  17491 obs/sec     10        10            250000     0.197447         0.154521            0.844052       0.986766        0.733455           2.01367          0.0405351                        0.192776           0.1464                0.851326         0.98839           0.765609             2.02591            0.0365873
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0039181124199318285
C36         0.9097923636436462     0.9097923636436462   0.0035646687595513047
C250        0.8807918429374695     0.8807918429374695   0.0034510414591879435
C31         0.7251895666122437     0.7251895666122437   0.002841374247748412
C438        0.7173507809638977     0.7173507809638977   0.0028106610043424443
---         ---                    ---                  ---
C377        0.139510378241539      0.139510378241539    0.0005466173456975611
C383        0.13858267664909363    0.13858267664909363  0.0005429825065662103
C683        0.13775822520256042    0.13775822520256042  0.0005397522131139178
C403        0.1361597776412964     0.1361597776412964   0.0005334893158715194
C626        0.1312118023633957     0.1312118023633957   0.0005141025924816611

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_170

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 258,766 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ----------------------  ------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.05842035661750733    0.1101960837841034     0.0         -0.002315656866404569  0.1107042133808136  0.0032364492382267684   0.1413435935974121
    3        2        Softmax                 0.0   0.0   0.0017325940884802549  1.670970959821716e-05  0.0         -0.00200510247850616   0.3811795711517334  -0.0020707085265404823  0.2622004747390747


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04556169209294554
RMSE: 0.21345184958895425
LogLoss: 0.15900164093361938
Mean Per-Class Error: 0.060118904195276324
AUC: 0.9843578311772657
pr_auc: 0.961895745370485
Gini: 0.9687156623545314
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5843911829976467: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4786  274   0.0542   (274.0/5060.0)
1      328   4626  0.0662   (328.0/4954.0)
Total  5114  4900  0.0601   (602.0/10014.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.584391     0.938908  181
max f2                       0.249618     0.954594  274
max f0point5                 0.806955     0.950859  113
max accuracy                 0.60807      0.939984  174
max precision                0.999502     1         0
max recall                   0.0011054    1         397
max specificity              0.999502     1         0
max absolute_mcc             0.60807      0.880077  174
max min_per_class_accuracy   0.5475       0.938142  190
max mean_per_class_accuracy  0.60807      0.939881  174
Gains/Lift Table: Avg response rate: 49.47 %, avg score: 49.89 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100859                   0.99928            2.0214      2.0214             1                0.999546     1                           0.999546            0.0203876       0.0203876                  102.14    102.14
    2        0.0200719                   0.998902           2.0214      2.0214             1                0.999081     1                           0.999315            0.0201857       0.0405733                  102.14    102.14
    3        0.0300579                   0.998523           2.0214      2.0214             1                0.998713     1                           0.999115            0.0201857       0.060759                   102.14    102.14
    4        0.0400439                   0.998208           2.0214      2.0214             1                0.998379     1                           0.998932            0.0201857       0.0809447                  102.14    102.14
    5        0.05003                     0.997895           2.0214      2.0214             1                0.998056     1                           0.998757            0.0201857       0.10113                    102.14    102.14
    6        0.10006                     0.995885           2.0214      2.0214             1                0.996924     1                           0.997841            0.10113         0.202261                   102.14    102.14
    7        0.14999                     0.992886           2.01735     2.02005            0.998            0.994552     0.999334                    0.996746            0.100727        0.302987                   101.735   102.005
    8        0.20002                     0.988619           2.00929     2.01736            0.994012         0.990898     0.998003                    0.995283            0.100525        0.403512                   100.929   101.736
    9        0.29998                     0.970271           1.99918     2.0113             0.989011         0.981114     0.995007                    0.990562            0.199839        0.603351                   99.9184   101.13
    10       0.40004                     0.899025           1.92658     1.99011            0.953094         0.942897     0.984523                    0.978639            0.192774        0.796124                   92.6581   99.0112
    11       0.5                         0.516456           1.46809     1.88575            0.726274         0.754348     0.932894                    0.933799            0.14675         0.942874                   46.8087   88.5749
    12       0.59996                     0.0926187          0.444263    1.64558            0.21978          0.255106     0.814081                    0.820721            0.0444086       0.987283                   -55.5737  64.5581
    13       0.70002                     0.021551           0.0806945   1.4219             0.0399202        0.0478312    0.703424                    0.710245            0.00807428      0.995357                   -91.9306  42.1898
    14       0.79998                     0.00630139         0.03231     1.24826            0.015984         0.0122557    0.617526                    0.623029            0.00322971      0.998587                   -96.769   24.8265
    15       0.89994                     0.0018688          0.0121163   1.11096            0.00599401       0.00362963   0.549601                    0.55423             0.00121114      0.999798                   -98.7884  11.0961
    16       1                           2.92411e-05        0.00201736  1                  0.000998004      0.000950879  0.494707                    0.498869            0.000201857     1                          -99.7983  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.04174096427528489
RMSE: 0.20430605540532784
LogLoss: 0.14706403431572854
Mean Per-Class Error: 0.052531635880784355
AUC: 0.9865951710300388
pr_auc: 0.9691494059571107
Gini: 0.9731903420600776
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5643066189456694: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2983  145   0.0464   (145.0/3128.0)
1      179   2870  0.0587   (179.0/3049.0)
Total  3162  3015  0.0525   (324.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.564307     0.94657   188
max f2                       0.249982     0.958406  268
max f0point5                 0.820042     0.954124  117
max accuracy                 0.564307     0.947547  188
max precision                0.99961      1         0
max recall                   0.00487456   1         390
max specificity              0.99961      1         0
max absolute_mcc             0.564307     0.895117  188
max min_per_class_accuracy   0.521534     0.945332  198
max mean_per_class_accuracy  0.564307     0.947468  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.56 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999299           2.02591     2.02591            1                0.999574    1                           0.999574            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.998878           2.02591     2.02591            1                0.999069    1                           0.999322            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.998522           2.02591     2.02591            1                0.998706    1                           0.999116            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998129           2.02591     2.02591            1                0.998324    1                           0.998918            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.997793           2.02591     2.02591            1                0.997956    1                           0.998728            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.995613           2.02591     2.02591            1                0.996709    1                           0.997719            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.992476           2.02591     2.02591            1                0.994192    1                           0.996543            0.101345        0.304034                   102.591   102.591
    8        0.200097                    0.988022           1.99968     2.01935            0.987055         0.990388    0.996764                    0.995004            0.100033        0.404067                   99.9685   101.935
    9        0.299984                    0.969535           2.00621     2.01498            0.990276         0.980572    0.994603                    0.990199            0.200394        0.60446                    100.621   101.498
    10       0.400032                    0.897926           1.94068     1.99639            0.957929         0.942311    0.985431                    0.978222            0.194162        0.798622                   94.0678   99.6395
    11       0.500081                    0.484632           1.51779     1.90064            0.749191         0.744343    0.938168                    0.931431            0.151853        0.950476                   51.7794   90.0643
    12       0.599968                    0.0849872          0.394018    1.64981            0.194489         0.23463     0.814355                    0.815423            0.0393572       0.989833                   -60.5982  64.981
    13       0.700016                    0.0212026          0.0786761   1.42526            0.038835         0.046879    0.703515                    0.70558             0.00787143      0.997704                   -92.1324  42.5259
    14       0.799903                    0.00619428         0.0164174   1.24933            0.00810373       0.0121253   0.616677                    0.618986            0.00163988      0.999344                   -98.3583  24.9332
    15       0.899951                    0.00178741         0.00655634  1.11117            0.00323625       0.00361779  0.54848                     0.550575            0.000655953     1                          -99.3444  11.1171
    16       1                           7.48256e-05        0           1                  0                0.00090049  0.493605                    0.495581            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:31:44  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:31:52  3:25:10.397  2363 obs/sec      0.74072   1             18518      0.308158         0.31899             0.620112       0.942783        0.88111            2.0214           0.128021                         0.301486           0.306645              0.636366         0.946132          0.860421             2.02591            0.122713
    2019-08-03 19:32:00  3:25:18.380  2434 obs/sec      1.4792    2             36980      0.289842         0.278163            0.663928       0.952939        0.938388           2.0214           0.11394                          0.282065           0.266461              0.681704         0.956933          0.943072             2.02591            0.106362
    2019-08-03 19:32:08  3:25:26.598  2449 obs/sec      2.22224   3             55556      0.28652          0.273111            0.671588       0.954441        0.937579           2.0214           0.110346                         0.27846            0.259739              0.68979          0.958984          0.949467             2.02591            0.105553
    2019-08-03 19:32:17  3:25:34.760  2454 obs/sec      2.96312   4             74078      0.278494         0.258658            0.689729       0.959252        0.946587           2.0214           0.105752                         0.269112           0.24481               0.710268         0.963663          0.953411             2.02591            0.0966489
    2019-08-03 19:32:26  3:25:44.177  2373 obs/sec      3.70072   5             92518      0.273991         0.252565            0.699682       0.96104         0.953812           2.0214           0.0993609                        0.265441           0.238059              0.718118         0.965799          0.956676             2.02591            0.0930873
    2019-08-03 19:32:34  3:25:52.345  2385 obs/sec      4.43372   6             110843     0.277772         0.259922            0.691336       0.959404        0.952372           2.0214           0.103156                         0.26686            0.240384              0.715097         0.964822          0.958726             2.02591            0.096487
    2019-08-03 19:32:43  3:26:00.710  2387 obs/sec      5.1714    7             129285     0.269815         0.245069            0.708768       0.963634        0.940768           2.0214           0.097863                         0.258991           0.227392              0.731651         0.968421          0.951429             2.02591            0.0888781
    2019-08-03 19:32:51  3:26:08.953  2395 obs/sec      5.91264   8             147816     0.268363         0.242096            0.711893       0.964461        0.94354            2.0214           0.0955662                        0.257078           0.224122              0.735601         0.969566          0.950767             2.02591            0.0867735
    2019-08-03 19:32:59  3:26:17.025  2406 obs/sec      6.65336   9             166334     0.26343          0.234974            0.722387       0.966452        0.941006           2.0214           0.0913721                        0.252657           0.217732              0.744616         0.970993          0.949946             2.02591            0.0827262
    2019-08-03 19:33:07  3:26:25.188  2411 obs/sec      7.39056   10            184764     0.249303         0.212112            0.751363       0.97222         0.955741           2.0214           0.0831835                        0.236861           0.194947              0.77555          0.976501          0.96717              2.02591            0.0707463
    2019-08-03 19:33:15  3:26:33.345  2416 obs/sec      8.12952   11            203238     0.244252         0.203458            0.761338       0.974493        0.957068           2.0214           0.0790893                        0.233764           0.189265              0.781382         0.977756          0.958523             2.02591            0.0713939
    2019-08-03 19:33:24  3:26:41.625  2416 obs/sec      8.86576   12            221644     0.232605         0.186179            0.783554       0.978625        0.956424           2.0214           0.0728979                        0.223033           0.171786              0.800993         0.982005          0.9595               2.02591            0.0632993
    2019-08-03 19:33:32  3:26:49.774  2421 obs/sec      9.60768   13            240192     0.222926         0.17287             0.801194       0.981414        0.960981           2.0214           0.065009                         0.213094           0.1592                0.818335         0.984043          0.958634             2.02591            0.0573094
    2019-08-03 19:33:40  3:26:58.023  2422 obs/sec      10.3506   14            258766     0.213452         0.159002            0.817733       0.984358        0.961896           2.0214           0.0601158                        0.204306           0.147064              0.833009         0.986595          0.969149             2.02591            0.0524526
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004201233666842233
C438        0.7777200937271118     0.7777200937271118   0.003267383841146039
C374        0.6777521371841431     0.6777521371841431   0.0028473950965122972
C322        0.6163811683654785     0.6163811683654785   0.002589561316144599
C79         0.6142858266830444     0.6142858266830444   0.002580758296124819
---         ---                    ---                  ---
C879        0.15058764815330505    0.15058764815330505  0.0006326538972322578
C629        0.14618730545043945    0.14618730545043945  0.0006141670293233353
C941        0.14606446027755737    0.14606446027755737  0.000613650928047214
C671        0.14602507650852203    0.14602507650852203  0.0006134854676308157
C810        0.14227785170078278    0.14227785170078278  0.000597742500611315

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_239

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.01165318482772512     0.013377774506807327   0.0         0.017893292162793808   0.06863337755203247  0.1273038680780062     0.11224755644798279
    3        2        Softmax                      0.0   0.0   0.00033445502953100004  7.475842721760273e-05  0.0         -0.010977778478491018  0.24862068891525269  0.0018205000703069157  0.13938724994659424


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.038824543857275996
RMSE: 0.19703944746490737
LogLoss: 0.15761709603102564
Mean Per-Class Error: 0.03873606567907084
AUC: 0.9863385705354617
pr_auc: 0.8028388069060118
Gini: 0.9726771410709234
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5463845586007722: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4809  186   0.0372   (186.0/4995.0)
1      203   4815  0.0405   (203.0/5018.0)
Total  5012  5001  0.0388   (389.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.546385     0.961174  191
max f2                       0.44935      0.965792  215
max f0point5                 0.610868     0.965405  173
max accuracy                 0.581332     0.96125   182
max precision                0.999965     0.998915  0
max recall                   3.7511e-05   1         399
max specificity              0.999965     0.9998    0
max absolute_mcc             0.581332     0.922569  182
max min_per_class_accuracy   0.537745     0.960741  193
max mean_per_class_accuracy  0.581332     0.961264  182
Gains/Lift Table: Avg response rate: 50.11 %, avg score: 50.21 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   1                  1.99542     1.99542            1                1            1                           1                   0.0201275       0.0201275                  99.5417   99.5417
    2        0.0200739                   1                  1.99542     1.99542            1                1            1                           1                   0.0199283       0.0400558                  99.5417   99.5417
    3        0.0300609                   1                  1.99542     1.99542            1                1            1                           1                   0.0199283       0.0599841                  99.5417   99.5417
    4        0.0400479                   0.999998           1.99542     1.99542            1                0.999999     1                           1                   0.0199283       0.0799123                  99.5417   99.5417
    5        0.050035                    0.999991           1.99542     1.99542            1                0.999995     1                           0.999999            0.0199283       0.0998406                  99.5417   99.5417
    6        0.10007                     0.999742           1.98745     1.99143            0.996008         0.999904     0.998004                    0.999952            0.099442        0.199283                   98.7451   99.1434
    7        0.150005                    0.998246           1.97546     1.98612            0.99             0.999167     0.99534                     0.99969             0.0986449       0.297927                   97.5462   98.6117
    8        0.20004                     0.992943           1.98347     1.98545            0.994012         0.996108     0.995007                    0.998794            0.0992427       0.39717                    98.3468   98.5454
    9        0.30001                     0.956227           1.96552     1.97881            0.985015         0.978606     0.991678                    0.992067            0.196493        0.593663                   96.5515   97.881
    10       0.39998                     0.847237           1.92963     1.96652            0.967033         0.909697     0.985518                    0.97148             0.192906        0.786568                   92.9634   96.6519
    11       0.50005                     0.542095           1.73255     1.9197             0.868263         0.727636     0.962053                    0.922682            0.173376        0.959944                   73.2547   91.9697
    12       0.60002                     0.15698            0.275092    1.64569            0.137862         0.312362     0.824734                    0.820996            0.027501        0.987445                   -72.4908  64.5687
    13       0.69999                     0.0298805          0.065783    1.42005            0.032967         0.0821932    0.711656                    0.715483            0.00657633      0.994022                   -93.4217  42.0051
    14       0.79996                     0.00267056         0.0279079   1.24608            0.013986         0.0123061    0.624469                    0.627607            0.00278996      0.996811                   -97.2092  24.6077
    15       0.89993                     2.88514e-05        0.0239211   1.11031            0.011988         0.000734198  0.556431                    0.55797             0.00239139      0.999203                   -97.6079  11.0312
    16       1                           2.92786e-32        0.00796573  1                  0.00399202       3.58584e-06  0.501149                    0.502135            0.00079713      1                          -99.2034  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03739243419327196
RMSE: 0.19337123414115132
LogLoss: 0.14832236535133214
Mean Per-Class Error: 0.03677388041360263
AUC: 0.9881999800362199
pr_auc: 0.8099371866213955
Gini: 0.9763999600724398
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.535071135498161: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3019  109   0.0348   (109.0/3128.0)
1      118   2931  0.0387   (118.0/3049.0)
Total  3137  3040  0.0367   (227.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.535071     0.96272   193
max f2                       0.403129     0.966504  226
max f0point5                 0.647234     0.967687  163
max accuracy                 0.537436     0.963251  192
max precision                0.99892      0.997717  3
max recall                   1.85591e-05  1         399
max specificity              0.999978     0.999361  0
max absolute_mcc             0.537436     0.926492  192
max min_per_class_accuracy   0.519004     0.962916  197
max mean_per_class_accuracy  0.535071     0.963226  193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.61 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999998           1.99323     2.01774            0.983871         0.999999     0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999991           2.02591     2.01935            1                0.999995     0.996764                    0.999999            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.99974            2.01935     2.01935            0.996764         0.999916     0.996764                    0.999957            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998338           2.02591     2.02154            1                0.99917      0.997843                    0.999695            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.992878           2.01935     2.02099            0.996764         0.996273     0.997573                    0.998839            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.953273           1.98651     2.00951            0.980551         0.977514     0.991905                    0.991739            0.198426        0.602821                   98.6508   100.951
    10       0.400032                    0.838811           1.97346     2.00049            0.97411          0.90479      0.987454                    0.969993            0.197442        0.800262                   97.3459   100.049
    11       0.500081                    0.476907           1.66859     1.93409            0.823625         0.700165     0.954678                    0.91601             0.16694         0.967202                   66.8589   93.4092
    12       0.599968                    0.148614           0.22656     1.64981            0.111831         0.284751     0.814355                    0.810913            0.0226304       0.989833                   -77.344   64.981
    13       0.700016                    0.0325283          0.0655634   1.42338            0.0323625        0.0817524    0.70259                     0.706699            0.00655953      0.996392                   -93.4437  42.3385
    14       0.799903                    0.00245479         0.0197009   1.2481             0.00972447       0.0130582    0.61607                     0.620082            0.00196786      0.99836                    -98.0299  24.8102
    15       0.899951                    2.86542e-05        0.0131127   1.11081            0.00647249       0.000709624  0.5483                      0.551226            0.00131191      0.999672                   -98.6887  11.0807
    16       1                           2.92786e-32        0.00327817  1                  0.00161812       3.69927e-06  0.493605                    0.496077            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:58:26  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:58:33  4:51:51.548  3722 obs/sec      1         1             25000      0.300489         0.364246            0.638824       0.947563        0.749357           1.99542          0.116948                         0.290855           0.332583              0.661558         0.953156          0.73642              2.02591            0.109924
    2019-08-03 20:58:47  4:52:05.133  3901 obs/sec      3         3             75000      0.253416         0.234739            0.743121       0.968731        0.837326           1.99542          0.0831919                        0.248686           0.222059              0.752581         0.971649          0.821063             2.02591            0.0780314
    2019-08-03 20:58:59  4:52:17.865  4058 obs/sec      5         5             125000     0.237171         0.207693            0.774998       0.975699        0.857622           1.99542          0.0664137                        0.23531            0.199812              0.77848          0.977599          0.827136             2.02591            0.0658896
    2019-08-03 20:59:12  4:52:30.179  4166 obs/sec      7         7             175000     0.221111         0.188637            0.804439       0.980522        0.83142            1.99542          0.0543294                        0.219077           0.178066              0.807989         0.98285           0.822805             2.02591            0.0545572
    2019-08-03 20:59:24  4:52:42.412  4233 obs/sec      9         9             225000     0.204531         0.167507            0.832667       0.98455         0.805307           1.99542          0.042345                         0.199906           0.157581              0.840124         0.986823          0.792577             2.02591            0.0388538
    2019-08-03 20:59:31  4:52:49.172  4260 obs/sec      10        10            250000     0.197039         0.157617            0.844701       0.986339        0.802839           1.99542          0.0388495                        0.193371           0.148322              0.850406         0.9882            0.809937             2.02591            0.0367492
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0032930304632771035
C28         0.9354116916656494     0.9354116916656494   0.0030803391963605525
C34         0.9224742650985718     0.9224742650985718   0.003037735856558755
C25         0.9198952913284302     0.9198952913284302   0.0030292432173696865
C35         0.9056956171989441     0.9056956171989441   0.002982483257892681
---         ---                    ---                  ---
C379        0.21781940758228302    0.21781940758228302  0.0007172859446614296
C780        0.2178090661764145     0.2178090661764145   0.0007172518900968714
C854        0.21616163849830627    0.21616163849830627  0.0007118268605668152
C583        0.21544133126735687    0.21544133126735687  0.0007094548669123801
C569        0.21455834805965424    0.21455834805965424  0.0007065471763108531

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_217

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.012715440867347464   0.028760239481925964   0.0         0.0180608085637684     0.07023772597312927  0.12511929070266517    0.1122940182685852
    3        2        Softmax                      0.0   0.0   0.0002790773897913823  7.042725337669253e-05  0.0         -0.015332404845679548  0.2534290552139282   0.0035764323299941475  0.15214884281158447


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.040010818827328785
RMSE: 0.2000270452397095
LogLoss: 0.16182301660781173
Mean Per-Class Error: 0.04125524354971555
AUC: 0.985376521986196
pr_auc: 0.7691926384089443
Gini: 0.9707530439723919
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4953181906806902: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4770  210   0.0422   (210.0/4980.0)
1      203   4829  0.0403   (203.0/5032.0)
Total  4973  5039  0.0413   (413.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.495318     0.958991  206
max f2                       0.376923     0.965379  237
max f0point5                 0.571888     0.962565  186
max accuracy                 0.495318     0.95875   206
max precision                0.999947     0.99449   0
max recall                   4.37223e-05  1         399
max specificity              0.999947     0.998795  0
max absolute_mcc             0.495318     0.917497  206
max min_per_class_accuracy   0.499037     0.957831  205
max mean_per_class_accuracy  0.495318     0.958745  206
Gains/Lift Table: Avg response rate: 50.26 %, avg score: 49.84 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   1                  1.98967     1.98967            1                1            1                           1                   0.0200715       0.0200715                  98.9666   98.9666
    2        0.0200759                   1                  1.98967     1.98967            1                1            1                           1                   0.0198728       0.0399444                  98.9666   98.9666
    3        0.0300639                   1                  1.98967     1.98967            1                1            1                           1                   0.0198728       0.0598172                  98.9666   98.9666
    4        0.0400519                   0.999999           1.98967     1.98967            1                0.999999     1                           1                   0.0198728       0.07969                    98.9666   98.9666
    5        0.05004                     0.999995           1.98967     1.98967            1                0.999997     1                           0.999999            0.0198728       0.0995628                  98.9666   98.9666
    6        0.10008                     0.999799           1.97378     1.98172            0.992016         0.999936     0.996008                    0.999968            0.0987679       0.198331                   97.3781   98.1723
    7        0.15002                     0.998193           1.96579     1.97642            0.988            0.999194     0.993342                    0.99971             0.0981717       0.296502                   96.579    97.6419
    8        0.20006                     0.992728           1.96584     1.97377            0.988024         0.995956     0.992012                    0.998771            0.0983704       0.394873                   96.5838   97.3773
    9        0.30004                     0.951557           1.94991     1.96582            0.98002          0.976721     0.988016                    0.991423            0.194952        0.589825                   94.9913   96.5822
    10       0.40002                     0.842117           1.9201      1.95439            0.965035         0.903458     0.982272                    0.969437            0.191971        0.781797                   92.0097   95.4394
    11       0.5                         0.515222           1.74121     1.91176            0.875125         0.717056     0.960847                    0.918971            0.174086        0.955882                   74.1206   91.1765
    12       0.59998                     0.151396           0.33393     1.64884            0.167832         0.297261     0.8287                      0.81537             0.0333863       0.989269                   -66.607   64.8836
    13       0.69996                     0.032133           0.061618    1.42212            0.030969         0.079152     0.714755                    0.710211            0.00616057      0.995429                   -93.8382  42.2123
    14       0.79994                     0.00233715         0.0298152   1.24811            0.014985         0.012681     0.627294                    0.623031            0.00298092      0.99841                    -97.0185  24.8106
    15       0.89992                     3.06832e-05        0.00993839  1.11055            0.004995         0.000619195  0.558158                    0.553882            0.000993641     0.999404                   -99.0062  11.0547
    16       1                           1.15949e-29        0.00595708  1                  0.00299401       3.78514e-06  0.502597                    0.49845             0.000596184     1                          -99.4043  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03678428612972454
RMSE: 0.1917922994536656
LogLoss: 0.14856228057921195
Mean Per-Class Error: 0.03447390406816542
AUC: 0.9880057421031927
pr_auc: 0.7698083245189736
Gini: 0.9760114842063854
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5072704842931052: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3018  110   0.0352   (110.0/3128.0)
1      103   2946  0.0338   (103.0/3049.0)
Total  3121  3056  0.0345   (213.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.50727      0.965111  200
max f2                       0.402807     0.97046   227
max f0point5                 0.562584     0.967592  188
max accuracy                 0.522719     0.965517  196
max precision                0.999956     0.996992  0
max recall                   3.84667e-05  1         399
max specificity              0.999956     0.999361  0
max absolute_mcc             0.50727      0.931028  200
max min_per_class_accuracy   0.512111     0.965153  199
max mean_per_class_accuracy  0.50727      0.965526  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.30 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999999           1.99323     2.01774            0.983871         0.999999     0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999996           2.02591     2.01935            1                0.999998     0.996764                    0.999999            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999805           2.01935     2.01935            0.996764         0.999944     0.996764                    0.999972            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998451           2.0128      2.01717            0.993528         0.999289     0.995685                    0.999744            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.993276           2.01935     2.01771            0.996764         0.996426     0.995955                    0.998915            0.101017        0.403739                   101.935   101.771
    9        0.299984                    0.952822           1.98651     2.00732            0.980551         0.977425     0.990826                    0.991759            0.198426        0.602165                   98.6508   100.732
    10       0.400032                    0.824394           1.96362     1.99639            0.969256         0.897861     0.985431                    0.968275            0.196458        0.798622                   96.3625   99.6395
    11       0.500081                    0.468376           1.71448     1.93999            0.846278         0.689925     0.957591                    0.912587            0.171532        0.970154                   71.4484   93.9994
    12       0.599968                    0.142161           0.200293    1.65036            0.0988655        0.273623     0.814625                    0.806208            0.0200066       0.990161                   -79.9707  65.0357
    13       0.700016                    0.0337951          0.0557289   1.42245            0.0275081        0.0781674    0.702128                    0.702154            0.0055756       0.995736                   -94.4271  42.2448
    14       0.799903                    0.00278808         0.0328348   1.24892            0.0162075        0.0139157    0.616474                    0.616211            0.00327976      0.999016                   -96.7165  24.8922
    15       0.899951                    3.86578e-05        0.00655634  1.11081            0.00323625       0.000757344  0.5483                      0.547791            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           1.15949e-29        0.00327817  1                  0.00161812       5.09013e-06  0.493605                    0.492986            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:29:55  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:30:02  4:23:20.458  3828 obs/sec      1         1             25000      0.300139         0.362903            0.639657       0.946152        0.682722           1.98967          0.115961                         0.293634           0.342777              0.65506          0.950798          0.662291             2.02591            0.110895
    2019-08-03 20:30:15  4:23:33.639  4034 obs/sec      3         3             75000      0.258063         0.244137            0.733607       0.966608        0.821349           1.98967          0.0828006                        0.251922           0.228122              0.746099         0.970542          0.817644             2.02591            0.0767363
    2019-08-03 20:30:28  4:23:46.552  4115 obs/sec      5         5             125000     0.24118          0.215487            0.767322       0.974349        0.84432            1.98967          0.0704155                        0.233337           0.200529              0.78218          0.978012          0.833161             2.02591            0.0641088
    2019-08-03 20:30:41  4:23:59.164  4184 obs/sec      7         7             175000     0.225343         0.19163             0.796876       0.979716        0.796508           1.98967          0.0559329                        0.217292           0.177558              0.811106         0.983184          0.829305             2.02591            0.0503481
    2019-08-03 20:30:53  4:24:11.396  4258 obs/sec      9         9             225000     0.206872         0.169524            0.828811       0.984267        0.808415           1.98967          0.045845                         0.200491           0.157573              0.839188         0.987108          0.792521             2.02591            0.0403108
    2019-08-03 20:30:59  4:24:17.797  4300 obs/sec      10        10            250000     0.200027         0.161823            0.839952       0.985377        0.769193           1.98967          0.0412505                        0.191792           0.148562              0.852839         0.988006          0.769808             2.02591            0.0344828
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0036938573517830324
C35         0.8913289904594421     0.8913289904594421   0.0032924421442659586
C28         0.8716241717338562     0.8716241717338562   0.003219655354750901
C41         0.8385802507400513     0.8385802507400513   0.003097595824256197
C34         0.8383131623268127     0.8383131623268127   0.00309660923775738
---         ---                    ---                  ---
C797        0.19719566404819489    0.19719566404819489  0.0007284126533841617
C389        0.19484072923660278    0.19484072923660278  0.0007197138601173924
C420        0.19345568120479584    0.19345568120479584  0.0007145976902625297
C845        0.19245357811450958    0.19245357811450958  0.0007108960643952313
C731        0.19212940335273743    0.19212940335273743  0.0007096986090681967

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_199

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.005250173950927853   0.011982183903455734    0.0         0.023938392247374957  0.08612477779388428  -0.013232960436034398  0.2405681610107422
    3        2        Softmax                      0.0   0.0   0.0002192961504761115  6.0339574702084064e-05  0.0         0.01833590621026815   0.5623555183410645   6.611371270867639e-05  0.10467380285263062


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03797569541909402
RMSE: 0.19487353699025944
LogLoss: 0.15361459648055517
Mean Per-Class Error: 0.036555624922920193
AUC: 0.9875720835726933
pr_auc: 0.7567604934748065
Gini: 0.9751441671453867
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.499317263162978: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4840  196   0.0389   (196.0/5036.0)
1      170   4802  0.0342   (170.0/4972.0)
Total  5010  4998  0.0366   (366.0/10008.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.499317     0.96329   204
max f2                       0.401541     0.967446  230
max f0point5                 0.593675     0.968342  179
max accuracy                 0.499317     0.963429  204
max precision                0.999625     0.99843   1
max recall                   3.39974e-05  1         399
max specificity              0.999955     0.999603  0
max absolute_mcc             0.499317     0.92687   204
max min_per_class_accuracy   0.513568     0.962669  201
max mean_per_class_accuracy  0.499317     0.963444  204
Gains/Lift Table: Avg response rate: 49.68 %, avg score: 49.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100919                   1                  2.01287     2.01287            1                1            1                           1                   0.0203138       0.0203138                  101.287   101.287
    2        0.0200839                   1                  2.01287     2.01287            1                1            1                           1                   0.0201126       0.0404264                  101.287   101.287
    3        0.0300759                   1                  2.01287     2.01287            1                1            1                           1                   0.0201126       0.060539                   101.287   101.287
    4        0.0400679                   1                  2.01287     2.01287            1                1            1                           1                   0.0201126       0.0806516                  101.287   101.287
    5        0.05006                     0.999999           2.01287     2.01287            1                0.999999     1                           1                   0.0201126       0.100764                   101.287   101.287
    6        0.10002                     0.999872           2.00482     2.00885            0.996            0.999967     0.998002                    0.999983            0.100161        0.200925                   100.482   100.885
    7        0.15008                     0.998761           2.00885     2.00885            0.998004         0.999465     0.998003                    0.99981             0.100563        0.301488                   100.885   100.885
    8        0.20004                     0.994424           1.99677     2.00583            0.992            0.996997     0.996503                    0.999108            0.0997586       0.401247                   99.6769   100.583
    9        0.30006                     0.954574           1.98874     2.00014            0.988012         0.978975     0.993673                    0.992397            0.198914        0.600161                   98.8742   100.014
    10       0.39998                     0.831021           1.9384      1.98471            0.963            0.9016       0.98601                     0.969715            0.193685        0.793846                   93.8396   98.4713
    11       0.5                         0.494589           1.72331     1.93242            0.856144         0.692021     0.960032                    0.914165            0.172365        0.966211                   72.3308   93.2422
    12       0.60002                     0.1464             0.225216    1.64784            0.111888         0.284452     0.818651                    0.809195            0.0225261       0.988737                   -77.4784  64.784
    13       0.69994                     0.0266502          0.062399    1.42151            0.031            0.0756949    0.70621                     0.704484            0.00623492      0.994972                   -93.7601  42.151
    14       0.79996                     0.0014513          0.0261412   1.24705            0.012987         0.00968566   0.619535                    0.617613            0.00261464      0.997586                   -97.3859  24.7045
    15       0.89998                     6.83666e-06        0.0180978   1.11047            0.00899101       0.000345786  0.551682                    0.549012            0.00181014      0.999397                   -98.1902  11.0465
    16       1                           3.44407e-31        0.00603258  1                  0.002997         7.75329e-07  0.496803                    0.4941              0.000603379     1                          -99.3967  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03688134828828861
RMSE: 0.1920451725201355
LogLoss: 0.1486293370846681
Mean Per-Class Error: 0.03433476574852845
AUC: 0.9881061376880098
pr_auc: 0.7991430868855528
Gini: 0.9762122753760196
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5065515422364895: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3024  104   0.0332   (104.0/3128.0)
1      108   2941  0.0354   (108.0/3049.0)
Total  3132  3045  0.0343   (212.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.506552     0.965212  204
max f2                       0.453194     0.96789   217
max f0point5                 0.604769     0.969867  179
max accuracy                 0.53214      0.965679  198
max precision                0.991658     0.998507  11
max recall                   2.46251e-05  1         399
max specificity              0.999986     0.99968   0
max absolute_mcc             0.53214      0.931382  198
max min_per_class_accuracy   0.50337      0.965153  205
max mean_per_class_accuracy  0.506552     0.965665  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.00 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999998           2.02591     2.02591            1                0.999999     1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999867           2.01935     2.02263            0.996764         0.999961     0.998382                    0.99998             0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.998817           2.01935     2.02154            0.996764         0.999482     0.997843                    0.999814            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.994367           2.02591     2.02263            1                0.997021     0.998382                    0.999116            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.954611           1.98322     2.00951            0.97893          0.979123     0.991905                    0.992459            0.198098        0.602821                   98.3225   100.951
    10       0.400032                    0.829031           1.98002     2.00213            0.977346         0.899292     0.988264                    0.969158            0.198098        0.800918                   98.0016   100.213
    11       0.500081                    0.459204           1.68498     1.93868            0.831715         0.680758     0.956944                    0.911459            0.16858         0.969498                   68.498    93.8683
    12       0.599968                    0.134087           0.180592    1.64598            0.089141         0.263245     0.812466                    0.80354             0.0180387       0.987537                   -81.9408  64.5984
    13       0.700016                    0.0252256          0.0786761   1.42198            0.038835         0.069089     0.701896                    0.69857             0.00787143      0.995408                   -92.1324  42.1979
    14       0.799903                    0.00159963         0.0262679   1.24769            0.012966         0.00929932   0.615867                    0.612498            0.00262381      0.998032                   -97.3732  24.7692
    15       0.899951                    9.82715e-06        0.0163909   1.11081            0.00809061       0.00039021   0.5483                      0.54445             0.00163988      0.999672                   -98.3609  11.0807
    16       1                           3.57768e-37        0.00327817  1                  0.00161812       1.02968e-06  0.493605                    0.489978            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:10:22  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:10:25  4:03:42.421  10024 obs/sec     1         1             25000      0.305445         0.409233            0.626799       0.941949        0.65513            2.01287          0.117306                         0.299031           0.381169              0.642264         0.946329          0.662934             2.02591            0.11219
    2019-08-03 20:10:30  4:03:47.526  10442 obs/sec     3         3             75000      0.25786          0.257608            0.734022       0.965914        0.75354            2.01287          0.0819345                        0.250753           0.240933              0.748451         0.969459          0.75989              2.02591            0.0778695
    2019-08-03 20:10:37  4:03:54.549  10855 obs/sec     6         6             150000     0.228323         0.205915            0.791466       0.977806        0.742295           2.01287          0.0560552                        0.223766           0.193585              0.799682         0.980185          0.767282             2.02591            0.051967
    2019-08-03 20:10:43  4:04:01.206  11181 obs/sec     9         9             225000     0.202            0.162971            0.836778       0.985832        0.764608           2.01287          0.0420663                        0.197918           0.155864              0.843288         0.987311          0.74865              2.02591            0.037073
    2019-08-03 20:10:46  4:04:03.676  11292 obs/sec     10        10            250000     0.194874         0.153615            0.848091       0.987572        0.75676            2.01287          0.0365707                        0.192045           0.148629              0.85245          0.988106          0.799143             2.02591            0.0343209
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003355710205303975
C35         0.9969325661659241     0.9969325661659241   0.0033454167862828716
C34         0.9828921556472778     0.9828921556472778   0.0032983012374187934
C28         0.9242112636566162     0.9242112636566162   0.0031013851693093898
C40         0.9194477200508118     0.9194477200508118   0.003085400097417981
---         ---                    ---                  ---
C624        0.18069571256637573    0.18069571256637573  0.0006063624467136608
C342        0.17679482698440552    0.17679482698440552  0.0005932722051565202
C478        0.1747433841228485     0.1747433841228485   0.0005863881574103953
C462        0.17432352900505066    0.17432352900505066  0.000584979245306852
C606        0.17380023002624512    0.17380023002624512  0.0005832232055832491

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_81

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.011809563347320104    0.016001343727111816   0.0         0.017891341850787983  0.06742122769355774  0.13533830962863458     0.10642582178115845
    3        2        Softmax                      0.0   0.0   0.00035931602715777444  9.241202496923506e-05  0.0         0.004532671504676955  0.26080143451690674  0.00023791662581722217  0.1276150941848755


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03773641128289358
RMSE: 0.19425861958454657
LogLoss: 0.15038113731304406
Mean Per-Class Error: 0.03811644850810292
AUC: 0.9882885066453194
pr_auc: 0.7787451284984377
Gini: 0.9765770132906388
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5079452811772617: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4770  204   0.041    (204.0/4974.0)
1      178   4876  0.0352   (178.0/5054.0)
Total  4948  5080  0.0381   (382.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.507945     0.962305  202
max f2                       0.399661     0.969728  229
max f0point5                 0.620394     0.965793  172
max accuracy                 0.507945     0.961907  202
max precision                0.999525     0.996803  1
max recall                   2.60654e-05  1         399
max specificity              0.999944     0.999196  0
max absolute_mcc             0.507945     0.923818  202
max min_per_class_accuracy   0.522576     0.961198  198
max mean_per_class_accuracy  0.507945     0.961884  202
Gains/Lift Table: Avg response rate: 50.40 %, avg score: 50.11 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   1                  1.98417     1.98417            1                1            1                           1                   0.0199842       0.0199842                  98.4171   98.4171
    2        0.0200439                   1                  1.98417     1.98417            1                1            1                           1                   0.0197863       0.0397705                  98.4171   98.4171
    3        0.030016                    1                  1.98417     1.98417            1                1            1                           1                   0.0197863       0.0595568                  98.4171   98.4171
    4        0.0400878                   0.999998           1.98417     1.98417            1                0.999999     1                           1                   0.0199842       0.079541                   98.4171   98.4171
    5        0.0500598                   0.999994           1.96433     1.98022            0.99             0.999997     0.998008                    0.999999            0.0195884       0.0991294                  96.4329   98.0218
    6        0.10002                     0.999777           1.97229     1.97626            0.994012         0.999923     0.996012                    0.999961            0.0985358       0.197665                   97.229    97.6258
    7        0.15008                     0.998166           1.97627     1.97626            0.996016         0.999157     0.996013                    0.999693            0.0989315       0.296597                   97.6266   97.6261
    8        0.20004                     0.992057           1.96041     1.9723             0.988024         0.995695     0.994018                    0.998694            0.0979422       0.394539                   96.0408   97.2302
    9        0.30006                     0.949953           1.95845     1.96769            0.987039         0.975605     0.991692                    0.990998            0.195884        0.590423                   95.8454   96.7686
    10       0.39998                     0.835819           1.92476     1.95696            0.97006          0.899559     0.986288                    0.968155            0.192323        0.782746                   92.4765   95.6963
    11       0.5                         0.537777           1.74085     1.91373            0.877368         0.716023     0.964499                    0.917719            0.17412         0.956866                   74.0848   91.3732
    12       0.60002                     0.166873           0.350148    1.65309            0.176471         0.321474     0.833139                    0.818328            0.0350218       0.991888                   -64.9852  65.3091
    13       0.69994                     0.0332158          0.037624    1.42247            0.0189621        0.0870786    0.716911                    0.713938            0.0037594       0.995647                   -96.2376  42.2474
    14       0.79996                     0.00254243         0.0296735   1.24833            0.0149551        0.0128838    0.629145                    0.626285            0.00296795      0.998615                   -97.0326  24.8331
    15       0.89998                     2.14893e-05        0.00989118  1.1107             0.00498504       0.000674663  0.559778                    0.556757            0.000989315     0.999604                   -99.0109  11.0696
    16       1                           1.37543e-24        0.00395647  1                  0.00199402       2.8236e-06   0.503989                    0.501071            0.000395726     1                          -99.6044  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.036991699530462024
RMSE: 0.1923322633633318
LogLoss: 0.14872169985195122
Mean Per-Class Error: 0.03526899515920279
AUC: 0.9880163845594421
pr_auc: 0.7950649929880156
Gini: 0.9760327691188841
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48434198017982105: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3012  116   0.0371   (116.0/3128.0)
1      102   2947  0.0335   (102.0/3049.0)
Total  3114  3063  0.0353   (218.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.484342     0.964332  209
max f2                       0.374407     0.968119  240
max f0point5                 0.593723     0.968685  184
max accuracy                 0.484342     0.964708  209
max precision                0.996594     0.998127  6
max recall                   2.86269e-05  1         399
max specificity              0.999965     0.999361  0
max absolute_mcc             0.484342     0.929418  209
max min_per_class_accuracy   0.49462      0.963875  206
max mean_per_class_accuracy  0.484342     0.964731  209
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.18 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999998           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999992           1.9927      2.01935            0.983607         0.999996     0.996764                    0.999999            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999771           2.01935     2.01935            0.996764         0.999918     0.996764                    0.999958            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.997994           2.02591     2.02154            1                0.999068     0.997843                    0.999662            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.992034           2.01935     2.02099            0.996764         0.995613     0.997573                    0.998649            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.948787           1.97994     2.00732            0.97731          0.974936     0.990826                    0.990754            0.19777         0.602165                   97.9941   100.732
    10       0.400032                    0.823398           1.96362     1.99639            0.969256         0.894566     0.985431                    0.966697            0.196458        0.798622                   96.3625   99.6395
    11       0.500081                    0.454703           1.69481     1.93606            0.83657          0.688095     0.955649                    0.910958            0.169564        0.968186                   69.4815   93.6059
    12       0.599968                    0.14112            0.203576    1.64762            0.100486         0.273571     0.813276                    0.804842            0.0203345       0.988521                   -79.6424  64.7624
    13       0.700016                    0.0302176          0.0655634   1.42151            0.0323625        0.0760263    0.701665                    0.700677            0.00655953      0.99508                    -93.4437  42.151
    14       0.799903                    0.00229751         0.0328348   1.2481             0.0162075        0.0122433    0.61607                     0.61471             0.00327976      0.99836                    -96.7165  24.8102
    15       0.899951                    2.9095e-05         0.0131127   1.11081            0.00647249       0.000622417  0.5483                      0.546441            0.00131191      0.999672                   -98.6887  11.0807
    16       1                           7.14866e-30        0.00327817  1                  0.00161812       3.87805e-06  0.493605                    0.491771            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:37:30  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:37:36  1:30:54.947  3809 obs/sec      1         1             25000      0.299829         0.369896            0.640387       0.948195        0.656131           1.98417          0.115975                         0.29277            0.353407              0.657087         0.951331          0.65346              2.02591            0.111219
    2019-08-03 17:37:50  1:31:08.844  3873 obs/sec      3         3             75000      0.259912         0.246345            0.729766       0.965812        0.75376            1.98417          0.0859593                        0.252088           0.233279              0.745764         0.969094          0.796285             2.02591            0.0796503
    2019-08-03 17:38:03  1:31:21.693  4011 obs/sec      5         5             125000     0.236444         0.201992            0.776362       0.977056        0.822824           1.98417          0.0673115                        0.230711           0.197294              0.787055         0.978223          0.826419             2.02591            0.0624899
    2019-08-03 17:38:16  1:31:34.259  4102 obs/sec      7         7             175000     0.221117         0.181664            0.804417       0.982003        0.79401            1.98417          0.0557439                        0.214745           0.174838              0.815508         0.983439          0.808182             2.02591            0.0479197
    2019-08-03 17:38:28  1:31:46.410  4194 obs/sec      9         9             225000     0.202151         0.160169            0.836529       0.986504        0.788725           1.98417          0.0422816                        0.198072           0.155768              0.843044         0.987346          0.79742              2.02591            0.0380444
    2019-08-03 17:38:35  1:31:53.039  4219 obs/sec      10        10            250000     0.194259         0.150381            0.849045       0.988289        0.778745           1.98417          0.0380933                        0.192332           0.148722              0.852009         0.988016          0.795065             2.02591            0.0352922
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003664451432275614
C31         0.8531503081321716     0.8531503081321716   0.003126327868581318
C28         0.8234643340110779     0.8234643340110779   0.003017545058194779
C35         0.8025971055030823     0.8025971055030823   0.0029410781128010317
C41         0.7772701978683472     0.7772701978683472   0.0028482688898438147
---         ---                    ---                  ---
C485        0.19511519372463226    0.19511519372463226  0.0007149901511029626
C534        0.1948966085910797     0.1948966085910797   0.0007141891564972418
C660        0.19322074949741364    0.19322074949741364  0.000708048052241165
C626        0.1925947517156601     0.1925947517156601   0.0007057541137732169
C758        0.18996897339820862    0.18996897339820862  0.0006961320766569936

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_84

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.012068494057035998  0.030840851366519928   0.0         0.017800023325440995   0.06761431694030762  0.13167956197390485      0.11634716391563416
    3        2        Softmax                      0.0   0.0   0.000279411669083629  6.673805182799697e-05  0.0         -0.001978738118424417  0.2543245553970337   -0.00040017174586534643  0.12165996432304382


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03698974183580114
RMSE: 0.1923271739401407
LogLoss: 0.15203754917074197
Mean Per-Class Error: 0.038534049709170404
AUC: 0.9879456346121049
pr_auc: 0.8114596841297624
Gini: 0.9758912692242099
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44309878457710417: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4699  246   0.0497   (246.0/4945.0)
1      142   4939  0.0279   (142.0/5081.0)
Total  4841  5185  0.0387   (388.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.443099     0.962205  219
max f2                       0.408169     0.969029  227
max f0point5                 0.61417      0.968319  175
max accuracy                 0.489146     0.9615    208
max precision                0.999971     0.996663  0
max recall                   1.70168e-05  1         399
max specificity              0.999971     0.999393  0
max absolute_mcc             0.485241     0.922993  209
max min_per_class_accuracy   0.500898     0.961375  204
max mean_per_class_accuracy  0.489146     0.961466  208
Gains/Lift Table: Avg response rate: 50.68 %, avg score: 50.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   1                  1.97323     1.97323            1                1            1                           1                   0.019878        0.019878                   97.3234   97.3234
    2        0.0200479                   1                  1.97323     1.97323            1                1            1                           1                   0.0196812       0.0395591                  97.3234   97.3234
    3        0.0300219                   1                  1.9535      1.96668            0.99             1            0.996678                    1                   0.0194844       0.0590435                  95.3501   96.6678
    4        0.0400958                   0.999998           1.97323     1.96833            1                0.999999     0.997512                    1                   0.019878        0.0789215                  97.3234   96.8325
    5        0.0500698                   0.999993           1.97323     1.9693             1                0.999996     0.998008                    0.999999            0.0196812       0.0986026                  97.3234   96.9303
    6        0.10004                     0.999677           1.96142     1.96536            0.994012         0.999902     0.996012                    0.999951            0.0980122       0.196615                   96.1418   96.5364
    7        0.15001                     0.997861           1.95748     1.96274            0.992016         0.998962     0.994681                    0.999621            0.0978154       0.29443                    95.7479   96.2738
    8        0.20008                     0.992048           1.95751     1.96143            0.992032         0.995367     0.994018                    0.998557            0.0980122       0.392442                   95.7511   96.143
    9        0.30002                     0.952718           1.95551     1.95946            0.991018         0.976232     0.993019                    0.99112             0.195434        0.587876                   95.551    95.9458
    10       0.40006                     0.844515           1.92798     1.95159            0.977069         0.907489     0.98903                     0.970207            0.192875        0.780752                   92.7985   95.1588
    11       0.5                         0.537088           1.74086     1.90947            0.882236         0.729091     0.967684                    0.922013            0.173981        0.954733                   74.0857   90.9467
    12       0.60004                     0.156057           0.334446    1.64688            0.169492         0.313646     0.834608                    0.820585            0.033458        0.988191                   -66.5554  64.6876
    13       0.69998                     0.0372667          0.0768025   1.42271            0.0389222        0.0882044    0.721003                    0.716018            0.00767565      0.995867                   -92.3197  42.2708
    14       0.80002                     0.0028666          0.0196733   1.24726            0.00997009       0.0148966    0.632091                    0.628345            0.00196812      0.997835                   -98.0327  24.7263
    15       0.89996                     2.83706e-05        0.0137851   1.11029            0.00698603       0.000749147  0.562673                    0.558651            0.00137768      0.999213                   -98.6215  11.0286
    16       1                           3.41836e-24        0.00786933  1                  0.00398804       3.56844e-06  0.506782                    0.502764            0.000787247     1                          -99.2131  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03683577491698979
RMSE: 0.19192648310483312
LogLoss: 0.14887533553967852
Mean Per-Class Error: 0.03675317218592489
AUC: 0.9881130054799737
pr_auc: 0.7925444538824759
Gini: 0.9762260109599474
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5090467701119357: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3014  114   0.0364   (114.0/3128.0)
1      113   2936  0.0371   (113.0/3049.0)
Total  3127  3050  0.0367   (227.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.509047     0.962781  200
max f2                       0.414571     0.970485  226
max f0point5                 0.602494     0.967916  175
max accuracy                 0.528299     0.963251  194
max precision                0.999585     0.997315  1
max recall                   1.96324e-05  1         399
max specificity              0.999961     0.999361  0
max absolute_mcc             0.528299     0.926512  194
max min_per_class_accuracy   0.509047     0.962939  200
max mean_per_class_accuracy  0.509047     0.963247  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.29 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999998           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999992           1.95949     2.0128             0.967213         0.999996     0.993528                    0.999999            0.0193506       0.100689                   95.9487   101.28
    6        0.100049                    0.999733           2.02591     2.01935            1                0.999915     0.996764                    0.999957            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.997987           2.01935     2.01935            0.996764         0.999093     0.996764                    0.999669            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.992221           2.0128      2.01771            0.993528         0.995634     0.995955                    0.99866             0.100689        0.403739                   101.28    101.771
    9        0.299984                    0.949729           1.98651     2.00732            0.980551         0.975903     0.990826                    0.991083            0.198426        0.602165                   98.6508   100.732
    10       0.400032                    0.82882            1.9669      1.99721            0.970874         0.898129     0.985836                    0.967835            0.196786        0.79895                    96.6903   99.7215
    11       0.500081                    0.470362           1.68498     1.93475            0.831715         0.69038      0.955002                    0.912326            0.16858         0.96753                    68.498    93.4747
    12       0.599968                    0.144171           0.21671     1.64872            0.106969         0.271919     0.813815                    0.805706            0.0216464       0.989177                   -78.329   64.8717
    13       0.700016                    0.032966           0.0622853   1.42198            0.0307443        0.0807584    0.701896                    0.702095            0.00623155      0.995408                   -93.7715  42.1979
    14       0.799903                    0.00263493         0.0295514   1.2481             0.0145867        0.0138446    0.61607                     0.61615             0.00295179      0.99836                    -97.0449  24.8102
    15       0.899951                    2.96005e-05        0.00655634  1.11008            0.00323625       0.000744594  0.54794                     0.547735            0.000655953     0.999016                   -99.3444  11.0078
    16       1                           3.16928e-29        0.00983452  1                  0.00485437       3.87531e-06  0.493605                    0.492935            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:40:52  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:40:59  1:34:17.604  3764 obs/sec      1         1             25000      0.298551         0.36059             0.643405       0.949361        0.677913           1.97323          0.114403                         0.289692           0.333029              0.66426          0.955133          0.659636             2.02591            0.107657
    2019-08-03 17:41:12  1:34:31.076  3968 obs/sec      3         3             75000      0.249488         0.229591            0.750978       0.970293        0.796763           1.97323          0.0783962                        0.247577           0.225397              0.754783         0.971343          0.808252             2.02591            0.0777076
    2019-08-03 17:41:27  1:34:45.174  3925 obs/sec      5         5             125000     0.231379         0.19876             0.785815       0.977761        0.840918           1.97323          0.0620387                        0.229252           0.194484              0.789739         0.978739          0.821886             2.02591            0.0574713
    2019-08-03 17:41:39  1:34:57.921  4022 obs/sec      7         7             175000     0.215029         0.177934            0.815016       0.982936        0.831859           1.97323          0.0508677                        0.217859           0.179256              0.810118         0.982075          0.821715             2.02591            0.0506718
    2019-08-03 17:41:52  1:35:10.024  4130 obs/sec      9         9             225000     0.203799         0.16346             0.833834       0.985752        0.800807           1.97323          0.045382                         0.202158           0.159684              0.836501         0.986047          0.796809             2.02591            0.0424154
    2019-08-03 17:41:58  1:35:16.547  4173 obs/sec      10        10            250000     0.192327         0.152038            0.852014       0.987946        0.81146            1.97323          0.0386994                        0.191926           0.148875              0.852633         0.988113          0.792544             2.02591            0.0367492
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003340168430566981
C28         0.9478572607040405     0.9478572607040405   0.003166002898887333
C41         0.9173455834388733     0.9173455834388733   0.003064088757722573
C40         0.8996002674102783     0.8996002674102783   0.0030048164133334256
C35         0.8544732332229614     0.8544732332229614   0.002854084518375833
---         ---                    ---                  ---
C740        0.21809019148349762    0.21809019148349762  0.0007284579726094866
C562        0.21781602501869202    0.21781602501869202  0.0007275422104390227
C497        0.2165284901857376     0.2165284901857376   0.0007232416272367332
C773        0.21420690417289734    0.21420690417289734  0.0007154871389277982
C668        0.20693741738796234    0.20693741738796234  0.0006912058286623345

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_210

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight          weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  -------------------  -------------------  ----------------------  ------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0030176208625339405   0.002973390743136406   0.0         0.02788045657316642  0.10003185272216797  0.044012692769255776    0.2138844132423401
    3        2        Softmax                      0.0   0.0   0.00020133249267928477  4.815729334950447e-05  0.0         -0.1648760910911733  0.8145148754119873   -0.0006766130707828721  0.0958361029624939


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03799847279313693
RMSE: 0.19493196965386905
LogLoss: 0.15281413646767694
Mean Per-Class Error: 0.03862487811150095
AUC: 0.987798931294418
pr_auc: 0.772437211225671
Gini: 0.975597862588836
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.50050556059631: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4825  220   0.0436   (220.0/5045.0)
1      167   4797  0.0336   (167.0/4964.0)
Total  4992  5017  0.0387   (387.0/10009.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.500506     0.961226  207
max f2                       0.397862     0.968559  234
max f0point5                 0.604858     0.964773  176
max accuracy                 0.500506     0.961335  207
max precision                0.999971     0.997194  0
max recall                   2.34115e-05  1         399
max specificity              0.999971     0.999405  0
max absolute_mcc             0.500506     0.922723  207
max min_per_class_accuracy   0.528966     0.960113  199
max mean_per_class_accuracy  0.500506     0.961375  207
Gains/Lift Table: Avg response rate: 49.60 %, avg score: 49.42 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100909                   1                  2.01632     2.01632            1                1            1                           1                   0.0203465       0.0203465                  101.632   101.632
    2        0.0200819                   1                  2.01632     2.01632            1                1            1                           1                   0.020145        0.0404915                  101.632   101.632
    3        0.0300729                   1                  2.01632     2.01632            1                1            1                           1                   0.020145        0.0606366                  101.632   101.632
    4        0.0400639                   1                  2.01632     2.01632            1                1            1                           1                   0.020145        0.0807816                  101.632   101.632
    5        0.050055                    0.999998           2.01632     2.01632            1                0.999999     1                           1                   0.020145        0.100927                   101.632   101.632
    6        0.10001                     0.999878           2.00422     2.01027            0.994            0.999966     0.997003                    0.999983            0.100121        0.201048                   100.422   101.027
    7        0.150065                    0.998838           2.00827     2.00961            0.996008         0.999494     0.996671                    0.99982             0.100524        0.301571                   100.827   100.961
    8        0.20002                     0.994729           1.99212     2.00524            0.988            0.997055     0.994505                    0.999129            0.0995165       0.401088                   99.2122   100.524
    9        0.30003                     0.959332           1.9861      1.99886            0.985015         0.980955     0.991342                    0.993071            0.19863         0.599718                   98.6103   99.886
    10       0.40004                     0.831865           1.95387     1.98761            0.969031         0.906048     0.985764                    0.971316            0.195407        0.795125                   95.3874   98.7614
    11       0.50005                     0.503703           1.69201     1.92849            0.839161         0.690573     0.956444                    0.915167            0.169218        0.964343                   69.2015   92.8494
    12       0.59996                     0.139289           0.276235    1.65335            0.137            0.287867     0.819983                    0.810704            0.0275987       0.991942                   -72.3765  65.3347
    13       0.69997                     0.0244239          0.0382718   1.42259            0.018981         0.0692779    0.705538                    0.704771            0.00382756      0.99577                    -96.1728  42.2589
    14       0.79998                     0.00130624         0.0282002   1.24827            0.013986         0.00845871   0.619083                    0.617721            0.00282031      0.99859                    -97.18    24.8268
    15       0.89999                     7.14213e-06        0.00805721  1.11045            0.003996         0.000287835  0.550733                    0.54911             0.000805802     0.999396                   -99.1943  11.0452
    16       1                           5.26403e-36        0.00604291  1                  0.002997         7.80275e-07  0.495954                    0.494193            0.000604351     1                          -99.3957  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.038142725078314677
RMSE: 0.19530162589777555
LogLoss: 0.1488903820444587
Mean Per-Class Error: 0.03833507107692857
AUC: 0.9880075770094424
pr_auc: 0.7681102814931433
Gini: 0.9760151540188848
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5012108872299588: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3000  128   0.0409   (128.0/3128.0)
1      109   2940  0.0357   (109.0/3049.0)
Total  3109  3068  0.0384   (237.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.501211     0.961256  205
max f2                       0.385542     0.967364  233
max f0point5                 0.626935     0.964269  169
max accuracy                 0.501211     0.961632  205
max precision                0.998673     0.997967  3
max recall                   1.91747e-05  1         399
max specificity              0.999961     0.999361  0
max absolute_mcc             0.501211     0.923275  205
max min_per_class_accuracy   0.514652     0.960315  201
max mean_per_class_accuracy  0.501211     0.961665  205
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.97 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999997           2.02591     2.02591            1                0.999998     1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999853           2.01935     2.02263            0.996764         0.999958     0.998382                    0.999979            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.998731           2.01935     2.02154            0.996764         0.999452     0.997843                    0.999803            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.994619           2.0128      2.01935            0.993528         0.997011     0.996764                    0.999105            0.100689        0.404067                   101.28    101.935
    9        0.299984                    0.95502            2.00621     2.01498            0.990276         0.979573     0.994603                    0.992602            0.200394        0.60446                    100.621   101.498
    10       0.400032                    0.824666           1.96362     2.00213            0.969256         0.90123      0.988264                    0.969749            0.196458        0.800918                   96.3625   100.213
    11       0.500081                    0.477117           1.65548     1.93278            0.817152         0.675354     0.95403                     0.910851            0.165628        0.966546                   65.5477   93.278
    12       0.599968                    0.126157           0.22656     1.64872            0.111831         0.268149     0.813815                    0.80385             0.0226304       0.989177                   -77.344   64.8717
    13       0.700016                    0.025194           0.0688416   1.42292            0.0339806        0.0650498    0.702359                    0.698258            0.0068875       0.996064                   -93.1158  42.2916
    14       0.799903                    0.00153072         0.0229844   1.2481             0.0113452        0.00895384   0.61607                     0.612182            0.00229583      0.99836                    -97.7016  24.8102
    15       0.899951                    8.05651e-06        0.0131127   1.11081            0.00647249       0.000361433  0.5483                      0.544166            0.00131191      0.999672                   -98.6887  11.0807
    16       1                           5.62005e-34        0.00327817  1                  0.00161812       9.39352e-07  0.493605                    0.489723            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:25:19  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:25:21  4:18:38.468  15703 obs/sec     1         1             25000      0.311231         0.375444            0.612516       0.93872         0.698899           2.01632          0.127785                         0.301177           0.345197              0.637111         0.944795          0.728679             1.99323            0.119152
    2019-08-03 20:25:27  4:18:44.711  16530 obs/sec     5         5             125000     0.231836         0.202653            0.784994       0.977853        0.809799           2.01632          0.0617444                        0.228829           0.195398              0.790515         0.979318          0.810307             2.02591            0.056338
    2019-08-03 20:25:33  4:18:50.702  17024 obs/sec     9         9             225000     0.204019         0.166299            0.833494       0.985261        0.727092           2.01632          0.0416625                        0.202613           0.157572              0.835764         0.986826          0.769059             2.02591            0.0419297
    2019-08-03 20:25:35  4:18:52.431  17095 obs/sec     10        10            250000     0.194932         0.152814            0.847996       0.987799        0.772437           2.01632          0.0386652                        0.195302           0.14889               0.847404         0.988008          0.76811              2.02591            0.0383681
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C25         1.0                    1.0                  0.0035695666405169474
C250        0.9746648073196411     0.9746648073196411   0.003479130981894069
C36         0.9497243762016296     0.9497243762016296   0.0033901044509751046
C28         0.9119956493377686     0.9119956493377686   0.0032554292461726905
C438        0.8930087685585022     0.8930087685585022   0.003187654309935549
---         ---                    ---                  ---
C1000       0.15070345997810364    0.15070345997810364  0.0005379460433483196
C217        0.14876334369182587    0.14876334369182587  0.0005310206689740989
C542        0.14731644093990326    0.14731644093990326  0.0005258558531787637
C662        0.14165081083774567    0.14165081083774567  0.0005056320089685933
C824        0.13659605383872986    0.13659605383872986  0.00048758871700898697

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_181

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.010763533298311544   0.01923004537820816    0.0         0.017926555985706097  0.06886634230613708  0.12925487856630236  0.1102801263332367
    3        2        Softmax                      0.0   0.0   0.0002450189666518554  7.452775025740266e-05  0.0         0.007081912117580913  0.23728686571121216  0.00719276578900202  0.12158948183059692


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03898759778351719
RMSE: 0.197452773552354
LogLoss: 0.1515676107508681
Mean Per-Class Error: 0.03973616192480445
AUC: 0.9875396099439422
pr_auc: 0.7921320177919741
Gini: 0.9750792198878844
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5360956777086894: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4811  231   0.0458   (231.0/5042.0)
1      168   4803  0.0338   (168.0/4971.0)
Total  4979  5034  0.0398   (399.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.536096     0.96012   194
max f2                       0.466027     0.96762   213
max f0point5                 0.671052     0.962593  156
max accuracy                 0.562096     0.960252  187
max precision                0.999969     0.998969  0
max recall                   3.28524e-05  1         399
max specificity              0.999969     0.999802  0
max absolute_mcc             0.562096     0.920509  187
max min_per_class_accuracy   0.572191     0.959738  185
max mean_per_class_accuracy  0.562096     0.960264  187
Gains/Lift Table: Avg response rate: 49.65 %, avg score: 50.59 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   1                  2.01428     2.01428            1                1            1                           1                   0.0203178       0.0203178                  101.428   101.428
    2        0.0200739                   1                  2.01428     2.01428            1                1            1                           1                   0.0201167       0.0404345                  101.428   101.428
    3        0.0300609                   1                  2.01428     2.01428            1                1            1                           1                   0.0201167       0.0605512                  101.428   101.428
    4        0.0400479                   0.999998           2.01428     2.01428            1                0.999999     1                           1                   0.0201167       0.0806679                  101.428   101.428
    5        0.050035                    0.999994           2.01428     2.01428            1                0.999997     1                           0.999999            0.0201167       0.100785                   101.428   101.428
    6        0.10007                     0.999783           2.01026     2.01227            0.998004         0.999929     0.999002                    0.999964            0.100583        0.201368                   101.026   101.227
    7        0.150005                    0.998397           2.0022      2.00892            0.994            0.999267     0.997337                    0.999732            0.0999799       0.301348                   100.22    100.892
    8        0.20004                     0.993871           1.99418     2.00523            0.99002          0.996507     0.995507                    0.998925            0.0997787       0.401127                   99.418    100.523
    9        0.30001                     0.961474           1.98007     1.99685            0.983017         0.98118      0.991345                    0.993012            0.197948        0.599075                   98.0074   99.6849
    10       0.39998                     0.859666           1.9519      1.98562            0.969031         0.918912     0.985768                    0.974492            0.195132        0.794206                   95.1902   98.5615
    11       0.50005                     0.547699           1.68661     1.92578            0.837325         0.733847     0.956062                    0.926334            0.168779        0.962985                   68.661    92.5778
    12       0.60002                     0.169868           0.267632    1.64951            0.132867         0.32207      0.818908                    0.825657            0.0267552       0.98974                    -73.2368  64.9513
    13       0.69999                     0.0337161          0.0583558   1.42227            0.028971         0.0909031    0.706092                    0.720722            0.00583384      0.995574                   -94.1644  42.2269
    14       0.79996                     0.00229108         0.0321963   1.24855            0.015984         0.0132852    0.61985                     0.632314            0.00321867      0.998793                   -96.7804  24.8554
    15       0.89993                     2.19344e-05        0.00804908  1.11075            0.003996         0.000594125  0.551437                    0.562139            0.000804667     0.999598                   -99.1951  11.075
    16       1                           3.79635e-32        0.00402052  1                  0.00199601       3.00071e-06  0.496455                    0.505886            0.000402334     1                          -99.5979  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.037247856194711056
RMSE: 0.19299703675111454
LogLoss: 0.1493731495884943
Mean Per-Class Error: 0.035580404962760825
AUC: 0.9884230522103176
pr_auc: 0.7772061459797117
Gini: 0.9768461044206351
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5462099006647958: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3008  120   0.0384   (120.0/3128.0)
1      100   2949  0.0328   (100.0/3049.0)
Total  3108  3069  0.0356   (220.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.54621      0.964041  191
max f2                       0.488368     0.970855  207
max f0point5                 0.662998     0.968048  156
max accuracy                 0.548647     0.964384  190
max precision                0.996258     0.998249  5
max recall                   2.85418e-05  1         399
max specificity              0.999953     0.999361  0
max absolute_mcc             0.54621      0.928782  191
max min_per_class_accuracy   0.560931     0.963555  187
max mean_per_class_accuracy  0.54621      0.96442   191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.37 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999998           1.99323     2.01774            0.983871         0.999999     0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999994           1.9927      2.0128             0.983607         0.999996     0.993528                    0.999999            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999783           2.02591     2.01935            1                0.999933     0.996764                    0.999966            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.998439           2.02591     2.02154            1                0.999296     0.997843                    0.999742            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.993884           2.01935     2.02099            0.996764         0.996645     0.997573                    0.998968            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.960297           1.98322     2.00842            0.97893          0.981236     0.991365                    0.993064            0.198098        0.602493                   98.3225   100.842
    10       0.400032                    0.850273           1.9669      1.99803            0.970874         0.915706     0.98624                     0.973717            0.196786        0.799278                   96.6903   99.8034
    11       0.500081                    0.528003           1.70137     1.93868            0.839806         0.723165     0.956944                    0.92359             0.17022         0.969498                   70.1371   93.8683
    12       0.599968                    0.16317            0.200293    1.64926            0.0988655        0.312707     0.814085                    0.821886            0.0200066       0.989505                   -79.9707  64.9264
    13       0.700016                    0.0352213          0.0524507   1.42104            0.02589          0.0899744    0.701434                    0.717279            0.00524762      0.994752                   -94.7549  42.1042
    14       0.799903                    0.00293793         0.0361183   1.2481             0.0178282        0.0148173    0.61607                     0.62956             0.00360774      0.99836                    -96.3882  24.8102
    15       0.899951                    2.84543e-05        0.00983452  1.11044            0.00485437       0.000748441  0.54812                     0.559654            0.000983929     0.999344                   -99.0165  11.0442
    16       1                           3.20451e-30        0.00655634  1                  0.00323625       3.73388e-06  0.493605                    0.503662            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:52:22  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:52:29  3:45:47.719  3785 obs/sec      1         1             25000      0.294559         0.34549             0.652922       0.9509          0.64583            2.01428          0.113552                         0.288786           0.338534              0.666357         0.952679          0.68618              2.02591            0.109438
    2019-08-03 19:52:44  3:46:02.014  3776 obs/sec      3         3             75000      0.253455         0.228883            0.74303        0.969826        0.803145           2.01428          0.0795965                        0.251618           0.227551              0.746712         0.970586          0.801882             2.02591            0.0791646
    2019-08-03 19:52:57  3:46:15.043  3933 obs/sec      5         5             125000     0.236357         0.200841            0.776529       0.976643        0.836434           2.01428          0.0691102                        0.231846           0.197698              0.784954         0.978089          0.837192             2.02591            0.0647564
    2019-08-03 19:53:09  3:46:27.525  4056 obs/sec      7         7             175000     0.220183         0.179824            0.806068       0.981809        0.822701           2.01428          0.0541296                        0.216608           0.176214              0.812293         0.983033          0.822163             2.02591            0.0513194
    2019-08-03 19:53:21  3:46:39.749  4146 obs/sec      9         9             225000     0.206023         0.161221            0.830209       0.985945        0.7663             2.01428          0.0456407                        0.20466            0.163478              0.83243          0.985581          0.780965             2.02591            0.0417678
    2019-08-03 19:53:28  3:46:46.389  4181 obs/sec      10        10            250000     0.197453         0.151568            0.844042       0.98754         0.792132           2.01428          0.0398482                        0.192997           0.149373              0.850984         0.988423          0.777206             2.02591            0.035616
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0036202868702291478
C35         0.9038069844245911     0.9038069844245911   0.003272040558933747
C28         0.9021480083465576     0.9021480083465576   0.003266034589620418
C34         0.8860319256782532     0.8860319256782532   0.003207689747136828
C25         0.8001372814178467     0.8001372814178467   0.002896726494297875
---         ---                    ---                  ---
C585        0.19739258289337158    0.19739258289337158  0.0007146177761294918
C426        0.19546203315258026    0.19546203315258026  0.0007076286322505807
C446        0.19312156736850739    0.19312156736850739  0.0006991554747022811
C342        0.1928129494190216     0.1928129494190216   0.0006980381891918407
C758        0.18852680921554565    0.18852680921554565  0.0006825211320892354

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_180

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 257,602 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.05451083189106881   0.10964897274971008     0.0         0.001041434721711724   0.10839802026748657  -0.010648187199040307  0.13597095012664795
    3        2        Softmax                 0.0   0.0   0.001712328458779666  1.5118839655769989e-05  0.0         -0.026562380529639995  0.3799959421157837   0.0007793967171202121  0.22129333019256592


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.045266300119511715
RMSE: 0.21275878388332575
LogLoss: 0.15857233804692444
Mean Per-Class Error: 0.057521049029040316
AUC: 0.9842397539054585
pr_auc: 0.9521589062719951
Gini: 0.968479507810917
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4765895840423588: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4703  301   0.0602   (301.0/5004.0)
1      275   4735  0.0549   (275.0/5010.0)
Total  4978  5036  0.0575   (576.0/10014.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.47659      0.942664  212
max f2                       0.221788     0.956508  281
max f0point5                 0.740562     0.949927  140
max accuracy                 0.47659      0.942481  212
max precision                0.999441     1         0
max recall                   0.00736811   1         386
max specificity              0.999441     1         0
max absolute_mcc             0.47659      0.884973  212
max min_per_class_accuracy   0.486927     0.941847  209
max mean_per_class_accuracy  0.47659      0.942479  212
Gains/Lift Table: Avg response rate: 50.03 %, avg score: 49.38 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100859                   0.999419           1.9988     1.9988             1                0.999607     1                           0.999607            0.0201597       0.0201597                  99.8802   99.8802
    2        0.0200719                   0.999121           1.97881    1.98886            0.99             0.999261     0.995025                    0.999435            0.0197605       0.0399202                  97.8814   98.8858
    3        0.0300579                   0.998797           1.9988     1.99216            1                0.998961     0.996678                    0.999277            0.0199601       0.0598802                  99.8802   99.2162
    4        0.0400439                   0.998496           1.9988     1.99382            1                0.998653     0.997506                    0.999122            0.0199601       0.0798403                  99.8802   99.3818
    5        0.05003                     0.998207           1.9988     1.99481            1                0.998348     0.998004                    0.998967            0.0199601       0.0998004                  99.8802   99.4813
    6        0.10006                     0.996395           1.9988     1.99681            1                0.997346     0.999002                    0.998157            0.1             0.1998                     99.8802   99.6808
    7        0.14999                     0.993594           1.97881    1.99082            0.99             0.995063     0.996005                    0.997127            0.0988024       0.298603                   97.8814   99.0818
    8        0.20002                     0.988902           1.99082    1.99082            0.996008         0.991521     0.996006                    0.995725            0.0996008       0.398204                   99.0823   99.0819
    9        0.29998                     0.96745            1.97284    1.98483            0.987013         0.980084     0.993009                    0.990513            0.197206        0.595409                   97.2844   98.4829
    10       0.40004                     0.890302           1.89108    1.96138            0.946108         0.937882     0.981278                    0.977349            0.189222        0.784631                   89.1083   96.1381
    11       0.5                         0.48778            1.57149    1.88343            0.786214         0.737392     0.942281                    0.929376            0.157086        0.941717                   57.1486   88.3433
    12       0.59996                     0.0795496          0.455272   1.64549            0.227772         0.236788     0.823236                    0.813983            0.045509        0.987226                   -54.4728  64.5485
    13       0.70002                     0.0178838          0.10373    1.42511            0.0518962        0.0401989    0.712981                    0.70338             0.0103792       0.997605                   -89.627   42.5109
    14       0.79998                     0.00528208         0.0239617  1.25003            0.011988         0.0103305    0.62539                     0.616781            0.00239521      1                          -97.6038  25.0031
    15       0.89994                     0.00177613         0          1.11119            0                0.00322606   0.555925                    0.548631            0               1                          -100      11.1185
    16       1                           2.46788e-05        0          1                  0                0.000928241  0.5003                      0.493828            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.04303347116451283
RMSE: 0.20744510397816776
LogLoss: 0.15003249892285878
Mean Per-Class Error: 0.05406797667089713
AUC: 0.9861570478434505
pr_auc: 0.9593680787515809
Gini: 0.972314095686901
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47438710642753357: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2958  170   0.0543   (170.0/3128.0)
1      164   2885  0.0538   (164.0/3049.0)
Total  3122  3055  0.0541   (334.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.474387     0.945282  212
max f2                       0.180596     0.956681  291
max f0point5                 0.745081     0.953106  141
max accuracy                 0.474387     0.945928  212
max precision                0.999545     1         0
max recall                   0.00660408   1         386
max specificity              0.999545     1         0
max absolute_mcc             0.474387     0.891844  212
max min_per_class_accuracy   0.474387     0.945652  212
max mean_per_class_accuracy  0.474387     0.945932  212
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.64 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999418           2.02591    2.02591            1                0.9996      1                           0.9996              0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999128           2.02591    2.02591            1                0.999284    1                           0.999442            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.998795           2.02591    2.02591            1                0.998959    1                           0.999281            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998549           2.02591    2.02591            1                0.998671    1                           0.999129            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.998174           2.02591    2.02591            1                0.998366    1                           0.998978            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.996213           2.02591    2.02591            1                0.997209    1                           0.998093            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.993371           2.0128     2.02154            0.993528         0.994947    0.997843                    0.997044            0.100689        0.303378                   101.28    102.154
    8        0.200097                    0.989032           2.02591    2.02263            1                0.991422    0.998382                    0.995639            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.96807            1.99964    2.01498            0.987034         0.980451    0.994603                    0.990582            0.199738        0.60446                    99.9642   101.498
    10       0.400032                    0.880711           1.94723    1.99803            0.961165         0.935762    0.98624                     0.976871            0.194818        0.799278                   94.7234   99.8034
    11       0.500081                    0.442562           1.50468    1.89933            0.742718         0.71084     0.93752                     0.923648            0.150541        0.94982                    50.4681   89.9332
    12       0.599968                    0.0692225          0.394018   1.64872            0.194489         0.194867    0.813815                    0.802315            0.0393572       0.989177                   -60.5982  64.8717
    13       0.700016                    0.0172308          0.0852325  1.42526            0.0420712        0.0362565   0.703515                    0.692828            0.00852739      0.997704                   -91.4768  42.5259
    14       0.799903                    0.0051605          0.0229844  1.25015            0.0113452        0.00982024  0.617082                    0.607538            0.00229583      1                          -97.7016  25.0152
    15       0.899951                    0.00182807         0          1.11117            0                0.00329108  0.54848                     0.540363            0               1                          -100      11.1171
    16       1                           4.80165e-05        0          1                  0                0.00094067  0.493605                    0.486395            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:50:27  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:50:35  3:43:52.655  2447 obs/sec      0.73576   1             18394      0.306886         0.315407            0.623285       0.943129        0.885307           1.9988           0.129718                         0.300782           0.300605              0.638062         0.947599          0.890221             2.02591            0.123685
    2019-08-03 19:50:43  3:44:00.737  2457 obs/sec      1.47412   2             36853      0.285433         0.270931            0.674113       0.955623        0.940148           1.9988           0.111344                         0.279394           0.259374              0.687705         0.959628          0.940374             2.02591            0.103286
    2019-08-03 19:50:51  3:44:09.024  2448 obs/sec      2.20888   3             55222      0.279943         0.26341             0.686527       0.957276        0.942922           1.9988           0.105852                         0.274008           0.251713              0.699629         0.961088          0.945859             2.02591            0.104905
    2019-08-03 19:50:59  3:44:17.070  2456 obs/sec      2.9406    4             73515      0.279008         0.262469            0.688618       0.957499        0.943665           1.9988           0.10715                          0.271627           0.248428              0.704827         0.962164          0.953668             2.02591            0.104096
    2019-08-03 19:51:07  3:44:25.224  2447 obs/sec      3.6698    5             91745      0.281121         0.26489             0.683883       0.956698        0.947376           1.9988           0.10745                          0.27186            0.249367              0.704319         0.961998          0.951283             2.02591            0.100534
    2019-08-03 19:51:15  3:44:33.401  2446 obs/sec      4.40412   6             110103     0.280013         0.263083            0.68637        0.957347        0.944487           1.9988           0.104154                         0.270146           0.246847              0.708036         0.962433          0.950204             2.02591            0.0961632
    2019-08-03 19:51:24  3:44:41.672  2444 obs/sec      5.14348   7             128587     0.267484         0.242823            0.71381        0.963705        0.956342           1.9988           0.0966647                        0.259083           0.228894              0.73146          0.968161          0.96268              2.02591            0.087583
    2019-08-03 19:51:32  3:44:49.918  2442 obs/sec      5.88064   8             147016     0.265019         0.239585            0.719059       0.965564        0.96022            1.97901          0.0933693                        0.257588           0.228132              0.734551         0.969289          0.962781             2.02591            0.0895257
    2019-08-03 19:51:40  3:44:58.211  2441 obs/sec      6.62028   9             165507     0.258226         0.228358            0.733277       0.96761         0.955246           1.97901          0.0894747                        0.250645           0.216487              0.748667         0.970779          0.958388             2.02591            0.0827262
    2019-08-03 19:51:48  3:45:06.528  2438 obs/sec      7.3582    10            183955     0.248741         0.211643            0.752511       0.972714        0.965554           1.95922          0.0814859                        0.24302            0.202964              0.763727         0.974982          0.96882              2.02591            0.0768982
    2019-08-03 19:51:57  3:45:14.718  2442 obs/sec      8.09904   11            202476     0.242586         0.202958            0.764607       0.974372        0.963081           1.9988           0.0775914                        0.234911           0.19066               0.779231         0.977375          0.962309             2.02591            0.0733366
    2019-08-03 19:52:05  3:45:23.119  2436 obs/sec      8.83436   12            220859     0.235276         0.189583            0.778581       0.978675        0.958425           1.9988           0.0718993                        0.228009           0.178431              0.792013         0.98083           0.948449             2.02591            0.0663753
    2019-08-03 19:52:13  3:45:31.186  2440 obs/sec      9.56936   13            239234     0.217106         0.165391            0.811459       0.982923        0.968852           1.9988           0.0613142                        0.211566           0.156973              0.82093          0.984844          0.964587             2.02591            0.0571475
    2019-08-03 19:52:21  3:45:39.199  2444 obs/sec      10.3041   14            257602     0.212759         0.158572            0.818935       0.98424         0.952159           1.9988           0.0575195                        0.207445           0.150032              0.827838         0.986157          0.959368             2.02591            0.0540716
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003929795512270011
C438        0.7856383323669434     0.7856383323669434   0.0030873979928029093
C374        0.723901093006134      0.723901093006134    0.0028447832666228614
C88         0.6857194900512695     0.6857194900512695   0.0026947373746795595
C322        0.6622701287269592     0.6622701287269592   0.002602586179781687
---         ---                    ---                  ---
C743        0.1662140041589737     0.1662140041589737   0.0006531870476203638
C908        0.16312925517559052    0.16312925517559052  0.0006410646149089851
C522        0.16291241347789764    0.16291241347789764  0.0006402124713785186
C835        0.15921789407730103    0.15921789407730103  0.0006256937656180596
C853        0.15894357860088348    0.15894357860088348  0.0006246157618898877

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_63

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  --------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0025106164223007927   0.0023583909496665     0.0         0.027238059089400957   0.09196221828460693  -0.02997440709085704   0.3038654327392578
    3        2        Softmax                      0.0   0.0   0.00025418607401661575  7.203270797617733e-05  0.0         -0.057206657860660926  0.6906900405883789   0.0033908519027340753  0.026468470692634583


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03851233357773123
RMSE: 0.19624559505306413
LogLoss: 0.16178569376571336
Mean Per-Class Error: 0.04117108960165905
AUC: 0.9864397348593436
pr_auc: 0.7078315384923192
Gini: 0.9728794697186871
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5267613603595308: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4833  215   0.0426   (215.0/5048.0)
1      198   4783  0.0398   (198.0/4981.0)
Total  5031  4998  0.0412   (413.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.526761     0.958613  193
max f2                       0.3753       0.967486  236
max f0point5                 0.655948     0.960953  154
max accuracy                 0.526761     0.958819  193
max precision                0.999978     0.994257  0
max recall                   2.29276e-05  1         399
max specificity              0.999978     0.998415  0
max absolute_mcc             0.526761     0.917642  193
max min_per_class_accuracy   0.533283     0.957805  191
max mean_per_class_accuracy  0.526761     0.958829  193
Gains/Lift Table: Avg response rate: 49.67 %, avg score: 50.12 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   1                  2.01345     2.01345            1                1            1                           1                   0.0202771       0.0202771                  101.345   101.345
    2        0.0200419                   1                  2.01345     2.01345            1                1            1                           1                   0.0200763       0.0403533                  101.345   101.345
    3        0.030013                    1                  2.01345     2.01345            1                1            1                           1                   0.0200763       0.0604296                  101.345   101.345
    4        0.0400838                   1                  1.97358     2.00343            0.980198         1            0.995025                    1                   0.0198755       0.0803052                  97.3581   100.343
    5        0.0500548                   1                  2.01345     2.00543            1                1            0.996016                    1                   0.0200763       0.100381                   101.345   100.543
    6        0.10001                     0.999987           2.00139     2.00341            0.994012         0.999997     0.995015                    0.999998            0.0999799       0.200361                   100.139   100.341
    7        0.150065                    0.999741           1.9934      2.00007            0.99004          0.999909     0.993355                    0.999969            0.0997792       0.300141                   99.3397   100.007
    8        0.20002                     0.99822            1.99738     1.9994             0.992016         0.999137     0.993021                    0.999761            0.0997792       0.39992                    99.7376   99.9399
    9        0.30003                     0.975157           1.98936     1.99605            0.988036         0.990459     0.991359                    0.99666             0.198956        0.598876                   98.9362   99.6053
    10       0.40004                     0.86849            1.93315     1.98033            0.96012          0.931871     0.983549                    0.980463            0.193335        0.79221                    93.3154   98.0329
    11       0.50005                     0.517203           1.69628     1.92352            0.842473         0.727573     0.955334                    0.929885            0.169645        0.961855                   69.6277   92.3518
    12       0.59996                     0.134901           0.275292    1.64904            0.136727         0.293811     0.819013                    0.823961            0.0275045       0.98936                    -72.4708  64.9042
    13       0.69997                     0.0185475          0.0722674   1.42376            0.0358923        0.0625578    0.707123                    0.715173            0.00722746      0.996587                   -92.7733  42.3757
    14       0.79998                     0.000543818        0.0160594   1.24777            0.00797607       0.00606577   0.619718                    0.626524            0.0016061       0.998193                   -98.3941  24.7773
    15       0.89999                     8.60878e-07        0.0120446   1.11045            0.00598205       0.00010047   0.551518                    0.556913            0.00120458      0.999398                   -98.7955  11.0454
    16       1                           1.06465e-38        0.00602229  1                  0.00299103       8.06971e-08  0.49666                     0.501217            0.000602289     1                          -99.3978  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0372012477644833
RMSE: 0.1928762498714741
LogLoss: 0.15007521842130103
Mean Per-Class Error: 0.040539789575048335
AUC: 0.9882859585005019
pr_auc: 0.694606810703676
Gini: 0.9765719170010039
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49202759601666324: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2978  150   0.048    (150.0/3128.0)
1      101   2948  0.0331   (101.0/3049.0)
Total  3079  3098  0.0406   (251.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.492028     0.959167  200
max f2                       0.431149     0.969063  214
max f0point5                 0.635082     0.9633    160
max accuracy                 0.492028     0.959365  200
max precision                0.999982     0.995546  0
max recall                   2.12433e-05  1         399
max specificity              0.999982     0.998721  0
max absolute_mcc             0.492028     0.91885   200
max min_per_class_accuracy   0.53447      0.958675  189
max mean_per_class_accuracy  0.492028     0.95946   200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.15 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.96056     2.00957            0.967742         1            0.991935                    1                   0.0196786       0.0806822                  96.0558   100.957
    5        0.0500243                   1                  2.02591     2.0128             1                1            0.993528                    1                   0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999992           2.02591     2.01935            1                0.999998     0.996764                    0.999999            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.999832           2.0128      2.01717            0.993528         0.999939     0.995685                    0.999979            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.998485           2.0128      2.01608            0.993528         0.999329     0.995146                    0.999817            0.100689        0.403411                   101.28    101.608
    9        0.299984                    0.977769           2.00621     2.01279            0.990276         0.991543     0.993524                    0.997062            0.200394        0.603805                   100.621   101.279
    10       0.400032                    0.872542           1.94396     1.99557            0.959547         0.936534     0.985026                    0.981924            0.19449         0.798295                   94.3956   99.5575
    11       0.500081                    0.506089           1.66203     1.92884            0.820388         0.715692     0.952088                    0.92866             0.166284        0.964579                   66.2033   92.8845
    12       0.599968                    0.144518           0.269246    1.65254            0.132901         0.292731     0.815704                    0.822786            0.0268941       0.991473                   -73.0754  65.2544
    13       0.700016                    0.0231788          0.0622853   1.42526            0.0307443        0.0699969    0.703515                    0.715195            0.00623155      0.997704                   -93.7715  42.5259
    14       0.799903                    0.000845052        0.00985045  1.24851            0.00486224       0.0080413    0.616272                    0.62689             0.000983929     0.998688                   -99.015   24.8512
    15       0.899951                    1.62442e-06        0.0131127   1.11117            0.00647249       0.000170331  0.54848                     0.557217            0.00131191      1                          -98.6887  11.1171
    16       1                           1.06465e-38        0           1                  0                1.5127e-07   0.493605                    0.501469            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:15:41  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:15:43  1:09:00.708  16578 obs/sec     1         1             25000      0.322773         0.480391            0.583251       0.931358        0.657113           2.01345          0.134011                         0.310742           0.439347              0.613694         0.938632          0.67015              2.02591            0.121742
    2019-08-03 17:15:49  1:09:06.710  17260 obs/sec     5         5             125000     0.236456         0.225455            0.776344       0.974208        0.735882           2.01345          0.0653106                        0.234471           0.220771              0.780057         0.974781          0.706564             2.02591            0.0647564
    2019-08-03 17:15:55  1:09:12.346  17838 obs/sec     9         9             225000     0.199826         0.162962            0.840271       0.986161        0.71599            2.01345          0.0432745                        0.196516           0.157935              0.845501         0.986949          0.701329             2.02591            0.041606
    2019-08-03 17:15:56  1:09:13.943  17940 obs/sec     10        10            250000     0.196246         0.161786            0.845944       0.98644         0.707832           2.01345          0.0411806                        0.192876           0.150075              0.851171         0.988286          0.694607             2.02591            0.0406346
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.004173761127153125
C35         0.8036922812461853     0.8036922812461853   0.0033544196016583447
C28         0.7122704386711121     0.7122704386711121   0.0029728466689457915
C27         0.7040215730667114     0.7040215730667114   0.0029384178743430333
C22         0.6979139447212219     0.6979139447212219   0.0029129260925755307
---         ---                    ---                  ---
C325        0.13487248122692108    0.13487248122692108  0.0005629255192676128
C639        0.13423556089401245    0.13423556089401245  0.0005602671659410253
C453        0.12959672510623932    0.12959672510623932  0.0005409057734547711
C569        0.12249857187271118    0.12249857187271118  0.0005112797774140951
C660        0.11657286435365677    0.11657286435365677  0.0004865472897201868

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_215

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  --------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0027080182260329376   0.0025585154071450233  0.0         0.027395341479207896  0.09586122632026672  -0.011789460288805221  0.2681776285171509
    3        2        Softmax                      0.0   0.0   0.00022242557224672055  4.362789331935346e-05  0.0         0.14931929230806418   0.7596156597137451   0.0004486924589120825  0.004869995638728142


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03929603662600966
RMSE: 0.19823227947539135
LogLoss: 0.15396083382257336
Mean Per-Class Error: 0.04211586758608199
AUC: 0.9870645899853318
pr_auc: 0.7127939100022698
Gini: 0.9741291799706635
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5092381898711352: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4748  195   0.0394   (195.0/4943.0)
1      227   4842  0.0448   (227.0/5069.0)
Total  4975  5037  0.0421   (422.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.509238     0.958243  204
max f2                       0.303994     0.96694   262
max f0point5                 0.602473     0.96328   176
max accuracy                 0.509238     0.957851  204
max precision                0.99995      0.997845  0
max recall                   2.57013e-05  1         399
max specificity              0.99995      0.999393  0
max absolute_mcc             0.509238     0.915713  204
max min_per_class_accuracy   0.50651      0.955613  205
max mean_per_class_accuracy  0.509238     0.957884  204
Gains/Lift Table: Avg response rate: 50.63 %, avg score: 49.98 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   1                  1.97514     1.97514            1                1           1                           1                   0.019925        0.019925                   97.5143   97.5143
    2        0.0200759                   1                  1.97514     1.97514            1                1           1                           1                   0.0197278       0.0396528                  97.5143   97.5143
    3        0.0300639                   1                  1.97514     1.97514            1                1           1                           1                   0.0197278       0.0593805                  97.5143   97.5143
    4        0.0400519                   1                  1.97514     1.97514            1                1           1                           1                   0.0197278       0.0791083                  97.5143   97.5143
    5        0.05004                     1                  1.97514     1.97514            1                1           1                           1                   0.0197278       0.0988361                  97.5143   97.5143
    6        0.10008                     0.999958           1.96726     1.9712             0.996008         0.99999     0.998004                    0.999995            0.0984415       0.197278                   96.7258   97.1201
    7        0.15002                     0.999405           1.96724     1.96988            0.996            0.999768    0.997337                    0.999919            0.0982442       0.295522                   96.7242   96.9883
    8        0.20006                     0.996649           1.95149     1.96528            0.988024         0.998311    0.995007                    0.999517            0.0976524       0.393174                   95.1489   96.5282
    9        0.30004                     0.96715            1.93963     1.95673            0.982018         0.98562     0.990679                    0.994886            0.193924        0.587098                   93.9626   95.6733
    10       0.40002                     0.846611           1.912       1.94555            0.968032         0.919271    0.985019                    0.975987            0.191162        0.77826                    91.2002   94.5553
    11       0.5                         0.527303           1.72652     1.90176            0.874126         0.709744    0.962845                    0.922749            0.172618        0.950878                   72.6524   90.1756
    12       0.59998                     0.138115           0.388714    1.64962            0.196803         0.302936    0.835192                    0.819464            0.0388637       0.989742                   -61.1286  64.9624
    13       0.69996                     0.0260965          0.0611683   1.42273            0.030969         0.0715052   0.72032                     0.712628            0.0061156       0.995857                   -93.8832  42.2734
    14       0.79994                     0.00142925         0.0295975   1.24861            0.014985         0.00940727  0.632164                    0.624736            0.00295916      0.998816                   -97.0402  24.8614
    15       0.89992                     5.74148e-06        0.00986585  1.11099            0.004995         0.00031052  0.562486                    0.555364            0.000986388     0.999803                   -99.0134  11.0991
    16       1                           9.72995e-28        0.0019712   1                  0.000998004      5.5324e-07  0.506292                    0.499783            0.000197278     1                          -99.8029  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03784750609280359
RMSE: 0.19454435507822782
LogLoss: 0.15016524802900003
Mean Per-Class Error: 0.03673660560378278
AUC: 0.9875524678335692
pr_auc: 0.7197138165467236
Gini: 0.9751049356671384
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5024393569327078: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3010  118   0.0377   (118.0/3128.0)
1      109   2940  0.0357   (109.0/3049.0)
Total  3119  3058  0.0367   (227.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.502439     0.96283   204
max f2                       0.380111     0.966736  238
max f0point5                 0.568199     0.967394  185
max accuracy                 0.502439     0.963251  204
max precision                0.99896      0.998053  2
max recall                   2.46472e-05  1         399
max specificity              0.999957     0.999361  0
max absolute_mcc             0.502439     0.926496  204
max min_per_class_accuracy   0.502439     0.962276  204
max mean_per_class_accuracy  0.502439     0.963263  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.83 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   1                  2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999954           2.01935     2.02263            0.996764         0.999986     0.998382                    0.999993            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.999304           2.01935     2.02154            0.996764         0.999735     0.997843                    0.999907            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.996458           2.00624     2.01771            0.990291         0.998119     0.995955                    0.99946             0.100361        0.403739                   100.624   101.771
    9        0.299984                    0.961258           1.97009     2.00186            0.972447         0.983849     0.988127                    0.994262            0.196786        0.600525                   97.0091   100.186
    10       0.400032                    0.824754           1.98329     1.99721            0.978964         0.907242     0.985836                    0.972498            0.198426        0.79895                    98.3294   99.7215
    11       0.500081                    0.471292           1.68498     1.93475            0.831715         0.667229     0.955002                    0.911425            0.16858         0.96753                    68.498    93.4747
    12       0.599968                    0.120707           0.219993    1.64926            0.10859          0.256983     0.814085                    0.802469            0.0219744       0.989505                   -78.0007  64.9264
    13       0.700016                    0.0225542          0.0590071   1.42198            0.0291262        0.0605469    0.701896                    0.696431            0.00590357      0.995408                   -94.0993  42.1979
    14       0.799903                    0.00123436         0.0328348   1.24851            0.0162075        0.0080325    0.616272                    0.610468            0.00327976      0.998688                   -96.7165  24.8512
    15       0.899951                    5.15985e-06        0.00983452  1.11081            0.00485437       0.000278101  0.5483                      0.542633            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           3.76917e-33        0.00327817  1                  0.00161812       5.74123e-07  0.493605                    0.488343            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:29:05  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:29:07  4:22:24.768  16329 obs/sec     1         1             25000      0.310885         0.414167            0.613341       0.937716        0.677335           1.97514          0.123152                         0.301771           0.386688              0.635678         0.94256           0.643856             2.02591            0.11559
    2019-08-03 20:29:13  4:22:30.822  17106 obs/sec     5         5             125000     0.235132         0.213618            0.778818       0.975339        0.725532           1.97514          0.0648222                        0.230116           0.205417              0.788152         0.976976          0.781156             2.02591            0.0607091
    2019-08-03 20:29:19  4:22:36.552  17620 obs/sec     9         9             225000     0.200776         0.159944            0.83873        0.98642         0.724983           1.97514          0.0439473                        0.196052           0.152721              0.846229         0.987418          0.741123             2.02591            0.0382062
    2019-08-03 20:29:21  4:22:38.282  17641 obs/sec     10        10            250000     0.198232         0.153961            0.842791       0.987065        0.712794           1.97514          0.0421494                        0.194544           0.150165              0.848585         0.987552          0.719714             2.02591            0.0367492
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0038291672621664137
C36         0.9183012247085571     0.9183012247085571   0.0035163289864613306
C35         0.8661201000213623     0.8661201000213623   0.0033165187321061
C47         0.8163027167320251     0.8163027167320251   0.0031257596389277745
C40         0.8153557777404785     0.8153557777404785   0.003122133651142075
---         ---                    ---                  ---
C492        0.14569711685180664    0.14569711685180664  0.0005578986300409725
C568        0.1456933170557022     0.1456933170557022   0.0005578840799861265
C631        0.13870705664157867    0.13870705664157867  0.0005311325203233955
C311        0.1340278834104538     0.1340278834104538   0.0005132151833727666
C369        0.1329917013645172     0.1329917013645172   0.0005092474690048217

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_77

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 252,193 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.044351451431774484  0.08149585127830505    0.0         -0.0028818748645803314  0.10955601930618286  0.007310416942696113    0.1368815302848816
    3        2        Softmax                 0.0   0.0   0.001696934606115974  4.240355337969959e-05  0.0         -0.01880069429626019    0.38773107528686523  -0.0001492167798802374  0.24637651443481445


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.048106060793357
RMSE: 0.2193309389788796
LogLoss: 0.16864607155110575
Mean Per-Class Error: 0.061137831271480536
AUC: 0.9820975632571273
pr_auc: 0.9630463857990611
Gini: 0.9641951265142545
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5639520011144799: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4754  299   0.0592   (299.0/5053.0)
1      314   4662  0.0631   (314.0/4976.0)
Total  5068  4961  0.0611   (613.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.563952     0.938311  184
max f2                       0.22764      0.952662  277
max f0point5                 0.794979     0.947609  116
max accuracy                 0.563952     0.938877  184
max precision                0.999558     1         0
max recall                   0.001371     1         397
max specificity              0.999558     1         0
max absolute_mcc             0.563952     0.877748  184
max min_per_class_accuracy   0.554286     0.938103  186
max mean_per_class_accuracy  0.563952     0.938862  184
Gains/Lift Table: Avg response rate: 49.62 %, avg score: 50.25 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   0.999297           2.01547     2.01547            1                0.999554    1                           0.999554            0.0202974       0.0202974                  101.547   101.547
    2        0.0200419                   0.998914           2.01547     2.01547            1                0.999103    1                           0.99933             0.0200965       0.0403939                  101.547   101.547
    3        0.030013                    0.99859            1.99532     2.00878            0.99             0.998764    0.996678                    0.999142            0.0198955       0.0602894                  99.532    100.878
    4        0.0400838                   0.998243           2.01547     2.01046            1                0.998415    0.997512                    0.998959            0.0202974       0.0805868                  101.547   101.046
    5        0.0500548                   0.997915           2.01547     2.01146            1                0.99808     0.998008                    0.998784            0.0200965       0.100683                   101.547   101.146
    6        0.10001                     0.99585            2.01547     2.01346            1                0.996947    0.999003                    0.997867            0.100683        0.201367                   101.547   101.346
    7        0.150065                    0.992762           2.00744     2.01146            0.996016         0.994397    0.998007                    0.996709            0.100482        0.301849                   100.744   101.146
    8        0.20002                     0.988292           1.99938     2.00844            0.992016         0.990731    0.99651                     0.995216            0.0998794       0.401728                   99.9383   100.844
    9        0.30003                     0.970348           1.96926     1.99538            0.977069         0.980648    0.99003                     0.99036             0.196945        0.598674                   96.9257   99.538
    10       0.40004                     0.904494           1.915       1.97529            0.95015          0.945567    0.98006                     0.979162            0.191519        0.790193                   91.5002   97.5285
    11       0.50005                     0.526809           1.50708     1.88165            0.747757         0.763353    0.933599                    0.936               0.150723        0.940916                   50.7084   88.1645
    12       0.59996                     0.108049           0.444531    1.64233            0.220559         0.26667     0.814858                    0.824538            0.0444132       0.98533                    -55.5469  64.2325
    13       0.69997                     0.0274717          0.102482    1.42232            0.0508475        0.0572659   0.705698                    0.714912            0.0102492       0.995579                   -89.7518  42.2316
    14       0.79998                     0.00756626         0.0381795   1.24928            0.0189432        0.0152269   0.619843                    0.62744             0.00381833      0.999397                   -96.1821  24.9278
    15       0.89999                     0.00217447         0.00401889  1.1109             0.00199402       0.00436801  0.551185                    0.558202            0.000401929     0.999799                   -99.5981  11.09
    16       1                           7.37386e-05        0.00200945  1                  0.000997009      0.00108762  0.496161                    0.502485            0.000200965     1                          -99.7991  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.04233058982726773
RMSE: 0.20574399098702184
LogLoss: 0.1502245949304976
Mean Per-Class Error: 0.053464187662887186
AUC: 0.9857708262907883
pr_auc: 0.9543559646187619
Gini: 0.9715416525815765
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47694052762364475: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2931  197   0.063    (197.0/3128.0)
1      134   2915  0.0439   (134.0/3049.0)
Total  3065  3112  0.0536   (331.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.476941     0.946275  208
max f2                       0.319595     0.959126  248
max f0point5                 0.777977     0.952564  129
max accuracy                 0.476941     0.946414  208
max precision                0.999424     1         0
max recall                   0.00789961   1         387
max specificity              0.999424     1         0
max absolute_mcc             0.476941     0.893024  208
max min_per_class_accuracy   0.550001     0.945972  190
max mean_per_class_accuracy  0.476941     0.946536  208
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.01 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999303           2.02591    2.02591            1                0.999545    1                           0.999545            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.998974           2.02591    2.02591            1                0.999142    1                           0.999344            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.998663           2.02591    2.02591            1                0.998812    1                           0.999167            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998276           2.02591    2.02591            1                0.998465    1                           0.998991            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.997919           2.02591    2.02591            1                0.998105    1                           0.998816            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.995926           2.02591    2.02591            1                0.996988    1                           0.997902            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.992829           2.00624    2.01935            0.990291         0.99449     0.996764                    0.996765            0.100361        0.30305                    100.624   101.935
    8        0.200097                    0.98819            2.00624    2.01608            0.990291         0.990817    0.995146                    0.995278            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.970479           1.99964    2.0106             0.987034         0.980525    0.992445                    0.990365            0.199738        0.603149                   99.9642   101.06
    10       0.400032                    0.911844           1.93084    1.99066            0.953074         0.948064    0.982598                    0.979786            0.193178        0.796327                   93.0843   99.0656
    11       0.500081                    0.508775           1.55058    1.90261            0.765372         0.76689     0.939139                    0.937193            0.155133        0.951459                   55.0575   90.2611
    12       0.599968                    0.0945151          0.371034   1.64762            0.183144         0.245839    0.813276                    0.822092            0.0370613       0.988521                   -62.8966  64.7624
    13       0.700016                    0.0251828          0.0917888  1.42526            0.0453074        0.0494908   0.703515                    0.711669            0.00918334      0.997704                   -90.8211  42.5259
    14       0.799903                    0.00728366         0.0229844  1.25015            0.0113452        0.0141232   0.617082                    0.624564            0.00229583      1                          -97.7016  25.0152
    15       0.899951                    0.00212729         0          1.11117            0                0.00425152  0.54848                     0.555603            0               1                          -100      11.1171
    16       1                           9.40292e-05        0          1                  0                0.0010703   0.493605                    0.500123            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:32:19  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:32:25  1:25:43.261  2421 obs/sec      0.62288   1             15572      0.324053         0.353086            0.579933       0.932519        0.859477           2.01547          0.139296                         0.310616           0.322101              0.614008         0.941677          0.882128             2.02591            0.132427
    2019-08-03 17:32:32  1:25:50.438  2416 obs/sec      1.25724   2             31431      0.304446         0.303258            0.629229       0.944062        0.922299           2.01547          0.128727                         0.290229           0.27753               0.663013         0.953003          0.931522             2.02591            0.112028
    2019-08-03 17:32:39  1:25:57.505  2433 obs/sec      1.89136   3             47284      0.290706         0.28009             0.661941       0.952303        0.932219           2.01547          0.113571                         0.278258           0.258573              0.69024          0.959162          0.942169             2.02591            0.104258
    2019-08-03 17:32:47  1:26:04.648  2432 obs/sec      2.52224   4             63056      0.287925         0.276989            0.668377       0.953224        0.938775           2.01547          0.11018                          0.275495           0.254207              0.69636          0.960269          0.944576             2.02591            0.100372
    2019-08-03 17:32:54  1:26:11.805  2429 obs/sec      3.15164   5             78791      0.28506          0.271661            0.674945       0.954586        0.943617           2.01547          0.107089                         0.270625           0.246736              0.707            0.962549          0.944903             2.02591            0.0968107
    2019-08-03 17:33:01  1:26:19.007  2422 obs/sec      3.77764   6             94441      0.286715         0.274251            0.671158       0.953822        0.942092           1.99552          0.111178                         0.273077           0.250924              0.701667         0.961318          0.948818             2.02591            0.100696
    2019-08-03 17:33:08  1:26:26.377  2412 obs/sec      4.40328   7             110082     0.273922         0.252675            0.699848       0.961007        0.941471           1.99552          0.100509                         0.259625           0.229446              0.730336         0.96744           0.955805             2.02591            0.0879068
    2019-08-03 17:33:22  1:26:39.869  2419 obs/sec      5.66692   9             141673     0.275237         0.255643            0.69696        0.960912        0.951319           1.99552          0.101904                         0.257068           0.225315              0.735622         0.969042          0.955913             2.02591            0.0879068
    2019-08-03 17:33:29  1:26:46.714  2430 obs/sec      6.29856   10            157464     0.265289         0.237924            0.718471       0.96524         0.955204           2.01547          0.0936285                        0.250197           0.213629              0.749566         0.972055          0.959021             2.02591            0.0832119
    2019-08-03 17:33:36  1:26:53.781  2431 obs/sec      6.92772   11            173193     0.263147         0.234519            0.722998       0.96635         0.943447           2.01547          0.0930302                        0.246984           0.207531              0.755956         0.973536          0.950983             2.02591            0.0790028
    2019-08-03 17:33:43  1:27:00.677  2436 obs/sec      7.55524   12            188881     0.249965         0.212796            0.750056       0.972388        0.960617           2.01547          0.0812643                        0.233928           0.19026               0.781074         0.978214          0.967101             2.02591            0.0691274
    2019-08-03 17:33:49  1:27:07.502  2445 obs/sec      8.187     13            204675     0.247921         0.209932            0.754127       0.972866        0.959516           2.01547          0.0801675                        0.230205           0.18309               0.787989         0.979283          0.954057             2.02591            0.0686417
    2019-08-03 17:33:57  1:27:14.625  2445 obs/sec      8.82256   14            220564     0.239662         0.197326            0.770236       0.975934        0.948867           1.99552          0.0758799                        0.222348           0.170789              0.802214         0.981912          0.95721              2.02591            0.0668609
    2019-08-03 17:34:04  1:27:21.648  2444 obs/sec      9.45392   15            236348     0.230382         0.182363            0.787684       0.979538        0.961516           1.99552          0.0702961                        0.214132           0.159196              0.81656          0.984329          0.963568             2.02591            0.0598996
    2019-08-03 17:34:11  1:27:28.586  2448 obs/sec      10.0877   16            252193     0.219331         0.168646            0.807564       0.982098        0.963046           2.01547          0.0611227                        0.205744           0.150225              0.83065          0.985771          0.954356             2.02591            0.0535859
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003988365334988653
C438        0.7747848033905029     0.7747848033905029   0.0030901248519186806
C374        0.6947960257530212     0.6947960257530212   0.0027711003840012335
C322        0.6796857118606567     0.6796857118606567   0.0027108349318721294
C88         0.6164168119430542     0.6164168119430542   0.0024584954446578967
---         ---                    ---                  ---
C784        0.15977825224399567    0.15977825224399567  0.0006372540425350253
C757        0.15822073817253113    0.15822073817253113  0.0006310421074036391
C924        0.15741002559661865    0.15741002559661865  0.0006278086894692304
C841        0.15612223744392395    0.15612223744392395  0.0006226725198422138
C921        0.14005674421787262    0.14005674421787262  0.0005585974635699356

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_125

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.012117565842017985    0.01659960299730301    0.0         0.01786417262769335    0.06820186972618103  0.12890259330653364     0.11173444986343384
    3        2        Softmax                      0.0   0.0   0.00033664602773342267  9.541318286210299e-05  0.0         -0.005725418259430626  0.2358161211013794   -0.0003431877091366192  0.1539323329925537


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03748424604987484
RMSE: 0.1936084865130525
LogLoss: 0.15312847324901382
Mean Per-Class Error: 0.03711308673344926
AUC: 0.9876318386065457
pr_auc: 0.7904290731456896
Gini: 0.9752636772130914
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47908179036786225: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4856  191   0.0378   (191.0/5047.0)
1      181   4794  0.0364   (181.0/4975.0)
Total  5037  4985  0.0371   (372.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.479082     0.962651  208
max f2                       0.359545     0.96493   241
max f0point5                 0.59464      0.968598  177
max accuracy                 0.479082     0.962882  208
max precision                0.999961     1         0
max recall                   3.59735e-05  1         399
max specificity              0.999961     1         0
max absolute_mcc             0.479082     0.925762  208
max min_per_class_accuracy   0.482107     0.962412  207
max mean_per_class_accuracy  0.479082     0.962887  208
Gains/Lift Table: Avg response rate: 49.64 %, avg score: 48.94 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   1                  2.01447     2.01447            1                1            1                           1                   0.0203015       0.0203015                  101.447   101.447
    2        0.0200559                   1                  2.01447     2.01447            1                1            1                           1                   0.0201005       0.040402                   101.447   101.447
    3        0.0300339                   1                  2.01447     2.01447            1                1            1                           1                   0.0201005       0.0605025                  101.447   101.447
    4        0.040012                    0.999998           2.01447     2.01447            1                0.999999     1                           1                   0.0201005       0.080603                   101.447   101.447
    5        0.0500898                   0.999994           2.01447     2.01447            1                0.999996     1                           0.999999            0.0203015       0.100905                   101.447   101.447
    6        0.10008                     0.999754           2.01447     2.01447            1                0.99992      1                           0.999959            0.100704        0.201608                   101.447   101.447
    7        0.15007                     0.998255           2.00241     2.01045            0.994012         0.999208     0.998005                    0.999709            0.100101        0.301709                   100.241   101.045
    8        0.20006                     0.992461           1.99839     2.00744            0.992016         0.99583      0.996509                    0.99874             0.0998995       0.401608                   99.8389   100.744
    9        0.30004                     0.951888           1.98633     2.0004             0.986028         0.976416     0.993016                    0.991301            0.198593        0.600201                   98.6326   100.04
    10       0.40002                     0.828994           1.97627     1.99437            0.981038         0.898852     0.990022                    0.968195            0.197588        0.797789                   97.6274   99.4373
    11       0.5                         0.463541           1.66867     1.92925            0.828343         0.682505     0.957693                    0.911068            0.166834        0.964623                   66.8675   92.9246
    12       0.59998                     0.126609           0.225171    1.64528            0.111776         0.26393      0.81673                     0.803229            0.0225126       0.987136                   -77.4829  64.5281
    13       0.69996                     0.0243656          0.0643344   1.41946            0.0319361        0.0656657    0.704633                    0.697878            0.00643216      0.993568                   -93.5666  41.9464
    14       0.79994                     0.00138453         0.040209    1.24708            0.0199601        0.00886824   0.619059                    0.611763            0.0040201       0.997588                   -95.9791  24.7078
    15       0.89992                     1.14066e-05        0.0180941   1.11054            0.00898204       0.000356987  0.551281                    0.543836            0.00180905      0.999397                   -98.1906  11.054
    16       1                           3.94289e-33        0.00602534  1                  0.00299103       1.44101e-06  0.496408                    0.489409            0.000603015     1                          -99.3975  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.036647446586914566
RMSE: 0.1914352281763066
LogLoss: 0.15036141645070472
Mean Per-Class Error: 0.035077693076175254
AUC: 0.9878310590282001
pr_auc: 0.77681631485547
Gini: 0.9756621180564002
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5291807316874155: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3045  83    0.0265   (83.0/3128.0)
1      133   2916  0.0436   (133.0/3049.0)
Total  3178  2999  0.035    (216.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.529181     0.964286  191
max f2                       0.418332     0.967689  220
max f0point5                 0.593348     0.971179  175
max accuracy                 0.529181     0.965032  191
max precision                0.997391     0.998002  4
max recall                   2.02629e-05  1         399
max specificity              0.999943     0.999361  0
max absolute_mcc             0.529181     0.930159  191
max min_per_class_accuracy   0.482765     0.962611  202
max mean_per_class_accuracy  0.529181     0.964922  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.76 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999998           1.99323     2.01774            0.983871         0.999999     0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999993           2.02591     2.01935            1                0.999996     0.996764                    0.999999            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999758           2.01935     2.01935            0.996764         0.999919     0.996764                    0.999959            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998061           2.02591     2.02154            1                0.99915      0.997843                    0.999689            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.992724           2.01935     2.02099            0.996764         0.995697     0.997573                    0.998691            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.950481           1.98651     2.00951            0.980551         0.976262     0.991905                    0.991223            0.198426        0.602821                   98.6508   100.951
    10       0.400032                    0.830026           1.98002     2.00213            0.977346         0.895747     0.988264                    0.967344            0.198098        0.800918                   98.0016   100.213
    11       0.500081                    0.44731            1.66859     1.9354             0.823625         0.676539     0.955325                    0.909164            0.16694         0.967858                   66.8589   93.5403
    12       0.599968                    0.121483           0.197009    1.64598            0.0972447        0.256229     0.812466                    0.800459            0.0196786       0.987537                   -80.2991  64.5984
    13       0.700016                    0.0244373          0.0655634   1.4201             0.0323625        0.0633789    0.700971                    0.695113            0.00655953      0.994096                   -93.4437  42.0105
    14       0.799903                    0.00173719         0.0394018   1.24769            0.0194489        0.0093884    0.615867                    0.609485            0.00393572      0.998032                   -96.0598  24.7692
    15       0.899951                    1.38018e-05        0.0131127   1.11044            0.00647249       0.000478208  0.54812                     0.541781            0.00131191      0.999344                   -98.6887  11.0442
    16       1                           6.43596e-33        0.00655634  1                  0.00323625       1.87862e-06  0.493605                    0.487577            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:29:27  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:29:33  2:22:51.911  3851 obs/sec      1         1             25000      0.297553         0.366835            0.645832       0.947686        0.682762           2.01447          0.115047                         0.28953            0.351762              0.664634         0.950982          0.67931              2.02591            0.107496
    2019-08-03 18:29:47  2:23:05.183  4011 obs/sec      3         3             75000      0.265981         0.260922            0.717002       0.963089        0.737079           2.01447          0.0869088                        0.258113           0.249104              0.733468         0.966479          0.775386             2.02591            0.0814311
    2019-08-03 18:29:59  2:23:17.982  4111 obs/sec      5         5             125000     0.237256         0.205024            0.774826       0.976352        0.843691           2.01447          0.0681501                        0.229405           0.194                 0.789459         0.979437          0.839538             2.02591            0.0629756
    2019-08-03 18:30:12  2:23:30.432  4195 obs/sec      7         7             175000     0.220791         0.183066            0.804995       0.981489        0.803512           2.01447          0.0538815                        0.214036           0.176322              0.816724         0.983597          0.815831             2.02591            0.0493767
    2019-08-03 18:30:24  2:23:42.400  4279 obs/sec      9         9             225000     0.204097         0.165858            0.833369       0.985155        0.763421           2.01447          0.0424067                        0.199405           0.161223              0.840925         0.986117          0.762176             2.02591            0.0396633
    2019-08-03 18:30:30  2:23:48.937  4309 obs/sec      10        10            250000     0.193608         0.153128            0.850055       0.987632        0.790429           2.01447          0.0371183                        0.191435           0.150361              0.853386         0.987831          0.776816             2.02591            0.0349684
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0033979745529922
C35         0.9968819618225098     0.9968819618225098   0.0033873795386098297
C34         0.8943222761154175     0.8943222761154175   0.0030388843364142523
C28         0.8702152967453003     0.8702152967453003   0.0029569694339650864
C38         0.8228095173835754     0.8228095173835754   0.0027958858020291823
---         ---                    ---                  ---
C985        0.21458669006824493    0.21458669006824493  0.0007291601122627204
C947        0.21429823338985443    0.21429823338985443  0.0007281799438099087
C573        0.21425624191761017    0.21425624191761017  0.0007280372578557801
C589        0.21217939257621765    0.21217939257621765  0.0007209801766433297
C423        0.20388087630271912    0.20388087630271912  0.00069278202951839

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_52

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.003935643754929589    0.0035091284662485123  0.0         0.025121820920230253  0.08705800771713257  -0.050751822715720596   0.24762046337127686
    3        2        Softmax                      0.0   0.0   0.00022548772221853142  4.749813524540514e-05  0.0         0.04089559058047598   0.474839448928833    -0.0003387120735741933  0.028081528842449188


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03928322054559215
RMSE: 0.19819995092227483
LogLoss: 0.16301043318438352
Mean Per-Class Error: 0.03758579482548119
AUC: 0.9859949056468793
pr_auc: 0.7425935241499626
Gini: 0.9719898112937586
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5234035240110234: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4786  180   0.0362   (180.0/4966.0)
1      197   4864  0.0389   (197.0/5061.0)
Total  4983  5044  0.0376   (377.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.523404     0.962692  197
max f2                       0.369517     0.968315  240
max f0point5                 0.588164     0.965456  178
max accuracy                 0.523404     0.962402  197
max precision                0.999957     0.995146  0
max recall                   4.65626e-05  1         399
max specificity              0.999957     0.998792  0
max absolute_mcc             0.523404     0.924804  197
max min_per_class_accuracy   0.518879     0.96147   198
max mean_per_class_accuracy  0.523404     0.962414  197
Gains/Lift Table: Avg response rate: 50.47 %, avg score: 50.28 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   1                  1.98123     1.98123            1                1            1                           1                   0.0199565       0.0199565                  98.1229   98.1229
    2        0.0200459                   1                  1.96142     1.97137            0.99             1            0.995025                    1                   0.0195614       0.0395179                  96.1417   97.1372
    3        0.0300189                   1                  1.96142     1.96806            0.99             1            0.993355                    1                   0.0195614       0.0590792                  96.1417   96.8065
    4        0.0400918                   1                  1.98123     1.97137            1                1            0.995025                    1                   0.0199565       0.0790358                  98.1229   97.1372
    5        0.0500648                   0.999999           1.98123     1.97334            1                1            0.996016                    1                   0.0197589       0.0987947                  98.1229   97.3336
    6        0.10003                     0.999928           1.96937     1.97135            0.994012         0.99998      0.995015                    0.99999             0.0983995       0.197194                   96.9365   97.1352
    7        0.149995                    0.999141           1.96541     1.96937            0.992016         0.999644     0.994016                    0.999875            0.0982019       0.295396                   96.5411   96.9373
    8        0.20006                     0.995665           1.95755     1.96641            0.988048         0.997719     0.992522                    0.999335            0.0980043       0.393401                   95.7549   96.6414
    9        0.29999                     0.960412           1.94762     1.96015            0.983034         0.982634     0.989362                    0.993772            0.194626        0.588026                   94.7615   96.0152
    10       0.40002                     0.847664           1.92395     1.9511             0.971087         0.91456      0.984792                    0.973964            0.192452        0.780478                   92.3945   95.1098
    11       0.50005                     0.534756           1.7679      1.91445            0.892323         0.716952     0.966294                    0.922551            0.176843        0.957321                   76.7896   91.445
    12       0.59998                     0.158477           0.312409    1.64762            0.157685         0.319079     0.831616                    0.82204             0.0312191       0.98854                    -68.7591  64.7621
    13       0.70001                     0.0310469          0.065185    1.42149            0.0329013        0.0833691    0.717481                    0.716485            0.00652045      0.99506                    -93.4815  42.1494
    14       0.79994                     0.0021613          0.0316364   1.24787            0.0159681        0.0121757    0.629847                    0.628501            0.00316143      0.998222                   -96.8364  24.787
    15       0.89997                     8.44132e-06        0.0138271   1.11071            0.00697906       0.000512571  0.560616                    0.558702            0.00138313      0.999605                   -98.6173  11.0709
    16       1                           4.04193e-35        0.00395061  1                  0.00199402       8.87317e-07  0.504737                    0.502815            0.000395179     1                          -99.6049  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0372363077039705
RMSE: 0.19296711560255675
LogLoss: 0.151717734175995
Mean Per-Class Error: 0.034801880453865675
AUC: 0.9880106701371211
pr_auc: 0.7491958629895542
Gini: 0.9760213402742421
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5141371924185405: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3018  110   0.0352   (110.0/3128.0)
1      105   2944  0.0344   (105.0/3049.0)
Total  3123  3054  0.0348   (215.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.514137     0.964771  197
max f2                       0.401238     0.970789  229
max f0point5                 0.595506     0.966808  172
max accuracy                 0.514137     0.965193  197
max precision                0.998284     0.998174  4
max recall                   3.05952e-05  1         399
max specificity              0.999977     0.999361  0
max absolute_mcc             0.514137     0.930378  197
max min_per_class_accuracy   0.514137     0.964834  197
max mean_per_class_accuracy  0.514137     0.965198  197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999999           2.02591     2.01935            1                1            0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999941           2.01935     2.01935            0.996764         0.999984     0.996764                    0.999992            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.999251           2.02591     2.02154            1                0.999717     0.997843                    0.9999              0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.995869           2.01935     2.02099            0.996764         0.997892     0.997573                    0.999398            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.959211           1.97666     2.00623            0.975689         0.982644     0.990286                    0.99382             0.197442        0.601837                   97.6658   100.623
    10       0.400032                    0.828066           1.96362     1.99557            0.969256         0.906575     0.985026                    0.972               0.196458        0.798295                   96.3625   99.5575
    11       0.500081                    0.485383           1.72104     1.94065            0.849515         0.685428     0.957915                    0.914667            0.172188        0.970482                   72.104    94.065
    12       0.599968                    0.139752           0.197009    1.65036            0.0972447        0.281714     0.814625                    0.809289            0.0196786       0.990161                   -80.2991  65.0357
    13       0.700016                    0.0285601          0.0524507   1.42198            0.02589          0.0743096    0.701896                    0.704243            0.00524762      0.995408                   -94.7549  42.1979
    14       0.799903                    0.0015909          0.0295514   1.2481             0.0145867        0.0109066    0.61607                     0.617664            0.00295179      0.99836                    -97.0449  24.8102
    15       0.899951                    8.98894e-06        0.00983452  1.11044            0.00485437       0.000396844  0.54812                     0.549041            0.000983929     0.999344                   -99.0165  11.0442
    16       1                           4.04193e-35        0.00655634  1                  0.00323625       9.48342e-07  0.493605                    0.494111            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:07:20  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:07:22  1:00:40.247  10339 obs/sec     1         1             25000      0.316118         0.453838            0.600243       0.935029        0.643271           1.96161          0.130448                         0.305764           0.406381              0.625971         0.94158           0.651616             2.02591            0.117695
    2019-08-03 17:07:30  1:00:47.335  10966 obs/sec     4         4             100000     0.248949         0.252551            0.752075       0.968131        0.739236           1.98123          0.0719059                        0.240965           0.224838              0.767706         0.973101          0.721579             1.99323            0.0662134
    2019-08-03 17:07:36  1:00:54.237  11219 obs/sec     7         7             175000     0.218394         0.188986            0.809199       0.980991        0.764347           1.98123          0.0502643                        0.209658           0.172574              0.824146         0.984078          0.762274             2.02591            0.0448438
    2019-08-03 17:07:43  1:01:00.875  11439 obs/sec     10        10            250000     0.1982           0.16301             0.842853       0.985995        0.742594           1.98123          0.0375985                        0.192967           0.151718              0.85103          0.988011          0.749196             2.02591            0.0348065
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0035144198312321044
C25         0.9255277514457703     0.9255277514457703   0.003252693084036673
C34         0.9247134923934937     0.9247134923934937   0.0032498314358755916
C36         0.8794152736663818     0.8794152736663818   0.0030906344776615406
C438        0.8501176238059998     0.8501176238059998   0.002987670235983719
---         ---                    ---                  ---
C856        0.17713233828544617    0.17713233828544617  0.0006225174024228858
C506        0.17173044383525848    0.17173044383525848  0.0006035328774409235
C662        0.1691783219575882     0.1691783219575882   0.0005945636497023178
C561        0.16896873712539673    0.16896873712539673  0.0005938270806117385
C626        0.16446621716022491    0.16446621716022491  0.0005780033351556203

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_3

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0038995698743844644   0.0032686935737729073  0.0         0.02488647185362523    0.08681726455688477  0.016127498152238837   0.2179451584815979
    3        2        Softmax                      0.0   0.0   0.00021574638361698817  5.254139250610024e-05  0.0         -0.022188295966770966  0.5175585746765137   0.0001900960886062758  0.13377118110656738


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04045188064589047
RMSE: 0.2011265289460604
LogLoss: 0.15857204405834788
Mean Per-Class Error: 0.042753656028237774
AUC: 0.9863384977080132
pr_auc: 0.7994157337116069
Gini: 0.9726769954160264
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5507503472583887: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4786  215   0.043    (215.0/5001.0)
1      216   4814  0.0429   (216.0/5030.0)
Total  5002  5029  0.043    (431.0/10031.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.55075      0.957153  191
max f2                       0.406198     0.967736  229
max f0point5                 0.641232     0.96138   163
max accuracy                 0.57234      0.957233  185
max precision                0.999723     0.998373  1
max recall                   1.94469e-05  1         399
max specificity              0.999977     0.9996    0
max absolute_mcc             0.57234      0.914511  185
max min_per_class_accuracy   0.55075      0.957009  191
max mean_per_class_accuracy  0.57234      0.957246  185
Gains/Lift Table: Avg response rate: 50.14 %, avg score: 50.72 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100688                   1                  1.99423     1.99423            1                1            1                           1                   0.0200795       0.0200795                  99.4235   99.4235
    2        0.0200379                   1                  1.99423     1.99423            1                1            1                           1                   0.0198807       0.0399602                  99.4235   99.4235
    3        0.030007                    1                  1.99423     1.99423            1                1            1                           1                   0.0198807       0.059841                   99.4235   99.4235
    4        0.0400758                   0.999999           1.99423     1.99423            1                0.999999     1                           1                   0.0200795       0.0799205                  99.4235   99.4235
    5        0.0500449                   0.999995           1.99423     1.99423            1                0.999997     1                           0.999999            0.0198807       0.0998012                  99.4235   99.4235
    6        0.10009                     0.999805           1.98629     1.99026            0.996016         0.999942     0.998008                    0.999971            0.0994036       0.199205                   98.6289   99.0262
    7        0.150035                    0.998582           1.98627     1.98893            0.996008         0.999368     0.997342                    0.99977             0.0992048       0.29841                    98.6274   98.8934
    8        0.20008                     0.994081           1.96245     1.98231            0.984064         0.996784     0.994021                    0.999023            0.0982107       0.39662                    96.2454   98.2311
    9        0.30007                     0.959959           1.95845     1.97436            0.982054         0.981428     0.990033                    0.99316             0.195825        0.592445                   95.8446   97.4359
    10       0.40006                     0.855743           1.92862     1.96293            0.967099         0.915581     0.984301                    0.97377             0.192843        0.785288                   92.8622   96.2927
    11       0.50005                     0.553626           1.70594     1.91154            0.855434         0.729122     0.958533                    0.92485             0.170577        0.955865                   70.5935   91.1539
    12       0.60004                     0.173161           0.338006    1.64933            0.169492         0.342012     0.827048                    0.827727            0.0337972       0.989662                   -66.1994  64.9327
    13       0.70003                     0.0346668          0.0576598   1.42198            0.0289133        0.0916777    0.713045                    0.722592            0.00576541      0.995427                   -94.234   42.1978
    14       0.80002                     0.00205492         0.0258475   1.24748            0.0129611        0.0130412    0.625545                    0.633909            0.00258449      0.998012                   -97.4152  24.7484
    15       0.90001                     1.1059e-05         0.0178944   1.11088            0.00897308       0.000477111  0.557045                    0.563536            0.00178926      0.999801                   -98.2106  11.0878
    16       1                           1.22889e-35        0.00198827  1                  0.000997009      1.36293e-06  0.501446                    0.507188            0.000198807     1                          -99.8012  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03900425897602908
RMSE: 0.19749495936866104
LogLoss: 0.1517552670336666
Mean Per-Class Error: 0.03998737794203633
AUC: 0.9879477590656952
pr_auc: 0.760176697056666
Gini: 0.9758955181313904
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5334363482842519: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2988  140   0.0448   (140.0/3128.0)
1      108   2941  0.0354   (108.0/3049.0)
Total  3096  3081  0.0401   (248.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.533436     0.959543  197
max f2                       0.409985     0.968924  226
max f0point5                 0.65305      0.964523  161
max accuracy                 0.568458     0.960013  186
max precision                0.999952     1         0
max recall                   2.54531e-05  1         399
max specificity              0.999952     1         0
max absolute_mcc             0.568458     0.920031  186
max min_per_class_accuracy   0.556773     0.959987  190
max mean_per_class_accuracy  0.556773     0.960013  190
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.98 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999999           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999996           2.02591     2.02591            1                0.999998     1                           0.999999            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999837           2.02591     2.02591            1                0.999949     1                           0.999974            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.998883           2.01935     2.02372            0.996764         0.999479     0.998921                    0.999809            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.994815           2.00624     2.01935            0.990291         0.997199     0.996764                    0.999157            0.100361        0.404067                   100.624   101.935
    9        0.299984                    0.959384           1.99636     2.0117             0.985413         0.981654     0.992984                    0.993329            0.19941         0.603477                   99.6359   101.17
    10       0.400032                    0.834827           1.94396     1.99475            0.959547         0.90796      0.984622                    0.971978            0.19449         0.797967                   94.3956   99.4755
    11       0.500081                    0.523185           1.67515     1.93081            0.826861         0.701896     0.953059                    0.917944            0.167596        0.965562                   67.5146   93.0812
    12       0.599968                    0.162893           0.239694    1.64926            0.118314         0.309057     0.814085                    0.816572            0.0239423       0.989505                   -76.0306  64.9264
    13       0.700016                    0.0321356          0.0557289   1.42151            0.0275081        0.0859855    0.701665                    0.712155            0.0055756       0.99508                    -94.4271  42.151
    14       0.799903                    0.00189049         0.0295514   1.24769            0.0145867        0.0126366    0.615867                    0.624803            0.00295179      0.998032                   -97.0449  24.7692
    15       0.899951                    1.29903e-05        0.0163909   1.11081            0.00809061       0.000455563  0.5483                      0.555394            0.00163988      0.999672                   -98.3609  11.0807
    16       1                           2.69652e-36        0.00327817  1                  0.00161812       1.42905e-06  0.493605                    0.499828            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:11:53  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:11:56  5 min 13.521 sec  10060 obs/sec     1         1             25000      0.302607         0.390543            0.633712       0.943597        0.671467           1.99423          0.119031                         0.30266            0.384839              0.633529         0.944696          0.636829             2.02591            0.118828
    2019-08-03 16:12:03  5 min 20.746 sec  10727 obs/sec     4         4             100000     0.242782         0.219759            0.764225       0.973066        0.76492            1.99423          0.0706809                        0.237703           0.206414              0.773952         0.976213          0.786177             2.02591            0.0662134
    2019-08-03 16:12:10  5 min 27.647 sec  11052 obs/sec     7         7             175000     0.218786         0.1831              0.80853        0.981807        0.804014           1.99423          0.0522381                        0.217121           0.179046              0.811402         0.982605          0.80223              2.02591            0.0480816
    2019-08-03 16:12:17  5 min 34.320 sec  11297 obs/sec     10        10            250000     0.201127         0.158572            0.838191       0.986338        0.799416           1.99423          0.0429668                        0.197495           0.151755              0.843957         0.987948          0.760177             2.02591            0.0401489
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0032958806458079997
C34         0.9511398077011108     0.9511398077011108   0.0031348432836596335
C36         0.9060303568840027     0.9060303568840027   0.0029861679177684993
C35         0.8967632055282593     0.8967632055282593   0.002955624492973331
C43         0.8836854696273804     0.8836854696273804   0.002912521836326636
---         ---                    ---                  ---
C342        0.1808958798646927     0.1808958798646927   0.0005962112293524496
C862        0.17841309309005737    0.17841309309005737  0.0005880282604742611
C478        0.1779664307832718     0.1779664307832718   0.0005865561148221145
C887        0.1778104603290558     0.1778104603290558   0.0005860420548207461
C773        0.17157399654388428    0.17157399654388428  0.0005654874145329168

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_179

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.011736702930936505   0.024169571697711945  0.0         0.01800161903901983   0.06838899850845337  0.14367393430010555    0.11282962560653687
    3        2        Softmax                      0.0   0.0   0.0002981929324903376  7.05392740201205e-05  0.0         0.008529184850658567  0.2488234043121338   0.0006124231900006133  0.16427934169769287


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.040388197399422565
RMSE: 0.20096815021147646
LogLoss: 0.1576912921882369
Mean Per-Class Error: 0.04227652840222629
AUC: 0.9865094400498745
pr_auc: 0.7955086118915167
Gini: 0.973018880099749
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5840006770907255: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4858  180   0.0357   (180.0/5038.0)
1      243   4734  0.0488   (243.0/4977.0)
Total  5101  4914  0.0422   (423.0/10015.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.584001     0.957234  180
max f2                       0.405305     0.962341  227
max f0point5                 0.645419     0.963105  164
max accuracy                 0.584001     0.957763  180
max precision                0.999673     0.997394  1
max recall                   2.4736e-05   1         399
max specificity              0.999969     0.999405  0
max absolute_mcc             0.584001     0.91559   180
max min_per_class_accuracy   0.546458     0.956729  189
max mean_per_class_accuracy  0.584001     0.957723  180
Gains/Lift Table: Avg response rate: 49.70 %, avg score: 50.20 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100849                   1                  2.01226     2.01226            1                1            1                           1                   0.0202933       0.0202933                  101.226   101.226
    2        0.0200699                   1                  2.01226     2.01226            1                1            1                           1                   0.0200924       0.0403858                  101.226   101.226
    3        0.0300549                   1                  2.01226     2.01226            1                1            1                           1                   0.0200924       0.0604782                  101.226   101.226
    4        0.0400399                   0.999998           2.01226     2.01226            1                0.999999     1                           1                   0.0200924       0.0805706                  101.226   101.226
    5        0.050025                    0.999994           2.01226     2.01226            1                0.999996     1                           0.999999            0.0200924       0.100663                   101.226   101.226
    6        0.10005                     0.999755           2.00021     2.00623            0.994012         0.999922     0.997006                    0.999961            0.10006         0.200723                   100.021   100.623
    7        0.150075                    0.99815            2.00021     2.00422            0.994012         0.99915      0.996008                    0.99969             0.10006         0.300784                   100.021   100.422
    8        0.2                         0.993114           2.00823     2.00522            0.998            0.996071     0.996505                    0.998787            0.100261        0.401045                   100.823   100.522
    9        0.30005                     0.956923           1.98213     1.99752            0.98503          0.978985     0.992679                    0.992184            0.198312        0.599357                   98.2133   99.7524
    10       0.4                         0.844847           1.95396     1.98664            0.971029         0.908261     0.987269                    0.971214            0.195298        0.794655                   95.3959   98.6639
    11       0.50005                     0.525356           1.64676     1.91864            0.818363         0.722479     0.953474                    0.921447            0.164758        0.959413                   64.6757   91.8635
    12       0.6                         0.162908           0.269373    1.6439             0.133866         0.311929     0.816941                    0.819911            0.0269238       0.986337                   -73.0627  64.3895
    13       0.69995                     0.0332654          0.0804098   1.42064            0.03996          0.0868853    0.705991                    0.715238            0.00803697      0.994374                   -91.959   42.0636
    14       0.8                         0.00233788         0.0321318   1.24699            0.0159681        0.0129315    0.619695                    0.627406            0.00321479      0.997589                   -96.7868  24.6986
    15       0.89995                     2.62867e-05        0.0180922   1.1105             0.00899101       0.000601282  0.55187                     0.557792            0.00180832      0.999397                   -98.1908  11.0503
    16       1                           6.67808e-25        0.00602472  1                  0.00299401       3.59509e-06  0.496955                    0.501985            0.000602773     1                          -99.3975  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03798879253808278
RMSE: 0.1949071382430176
LogLoss: 0.1518749017671173
Mean Per-Class Error: 0.03687988556895516
AUC: 0.9876517100487434
pr_auc: 0.7969831477542259
Gini: 0.9753034200974868
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5054271984289231: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3005  123   0.0393   (123.0/3128.0)
1      105   2944  0.0344   (105.0/3049.0)
Total  3110  3067  0.0369   (228.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.505427     0.962721  198
max f2                       0.463903     0.966109  210
max f0point5                 0.618892     0.967894  171
max accuracy                 0.521385     0.963089  194
max precision                0.996247     0.998276  6
max recall                   3.07992e-05  1         399
max specificity              0.99997      0.999361  0
max absolute_mcc             0.505427     0.926187  198
max min_per_class_accuracy   0.521385     0.962916  194
max mean_per_class_accuracy  0.505427     0.96312   198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.83 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999998           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999993           1.9927      2.01935            0.983607         0.999995     0.996764                    0.999999            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999784           2.01935     2.01935            0.996764         0.999925     0.996764                    0.999962            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998407           2.02591     2.02154            1                0.999265     0.997843                    0.99973             0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.994142           2.01935     2.02099            0.996764         0.996622     0.997573                    0.998953            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.957923           1.97666     2.00623            0.975689         0.980481     0.990286                    0.992802            0.197442        0.601837                   97.6658   100.623
    10       0.400032                    0.84096            1.97674     1.99885            0.975728         0.908664     0.986645                    0.971759            0.19777         0.799606                   97.6738   99.8854
    11       0.500081                    0.482481           1.67842     1.93475            0.828479         0.70387      0.955002                    0.918164            0.167924        0.96753                    67.8424   93.4747
    12       0.599968                    0.157268           0.210143    1.64762            0.103728         0.291924     0.813276                    0.813903            0.0209905       0.988521                   -78.9857  64.7624
    13       0.700016                    0.0339252          0.0655634   1.42151            0.0323625        0.0858789    0.701665                    0.709852            0.00655953      0.99508                    -93.4437  42.151
    14       0.799903                    0.00276472         0.0262679   1.24728            0.012966         0.0135932    0.615665                    0.622907            0.00262381      0.997704                   -97.3732  24.7282
    15       0.899951                    2.62911e-05        0.0163909   1.11044            0.00809061       0.000719395  0.54812                     0.553738            0.00163988      0.999344                   -98.3609  11.0442
    16       1                           5.31657e-31        0.00655634  1                  0.00323625       3.3877e-06   0.493605                    0.498338            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:49:22  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:49:29  3:42:47.170  3881 obs/sec      1         1             25000      0.303133         0.367633            0.632428       0.945089        0.747321           2.01226          0.117723                         0.292225           0.341079              0.658363         0.950673          0.751794             2.02591            0.109762
    2019-08-03 19:49:42  3:43:00.328  4052 obs/sec      3         3             75000      0.257856         0.240345            0.734031       0.96701         0.813701           2.01226          0.0835746                        0.251398           0.227345              0.747155         0.970339          0.80842              2.02591            0.080136
    2019-08-03 19:49:55  3:43:12.990  4146 obs/sec      5         5             125000     0.239185         0.20756             0.771154       0.975505        0.853257           2.01226          0.0692961                        0.232581           0.197711              0.783589         0.978313          0.864068             2.02591            0.063785
    2019-08-03 19:50:07  3:43:25.308  4236 obs/sec      7         7             175000     0.222987         0.185749            0.801099       0.980773        0.82414            2.01226          0.0554169                        0.216324           0.177241              0.812785         0.983114          0.822663             2.02591            0.0497005
    2019-08-03 19:50:19  3:43:37.551  4292 obs/sec      9         9             225000     0.208042         0.165998            0.826867       0.984916        0.767776           2.01226          0.0451323                        0.202252           0.159603              0.83635          0.986607          0.769876             2.02591            0.0407965
    2019-08-03 19:50:26  3:43:44.033  4328 obs/sec      10        10            250000     0.200968         0.157691            0.838441       0.986509        0.795509           2.01226          0.0422366                        0.194907           0.151875              0.84802          0.987652          0.796983             2.02591            0.0369111
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C31         1.0                    1.0                  0.0032603078378706457
C36         0.9421913623809814     0.9421913623809814   0.0030718338835447356
C28         0.9372185468673706     0.9372185468673706   0.0030556209741494254
C25         0.9113755226135254     0.9113755226135254   0.0029713647596203326
C34         0.8973263502120972     0.8973263502120972   0.0029255601327243604
---         ---                    ---                  ---
C869        0.21874862909317017    0.21874862909317017  0.0007131878699559214
C316        0.21828655898571014    0.21828655898571014  0.0007116813791629237
C783        0.21815401315689087    0.21815401315689087  0.0007112492389583472
C446        0.2119114249944687     0.2119114249944687   0.0006908964798438037
C534        0.20075951516628265    0.20075951516628265  0.000654537820823742

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_5

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0032550376157109433  0.003321690484881401   0.0         0.028505937055801855  0.09821262955665588  0.08900903343528296     0.27910399436950684
    3        2        Softmax                      0.0   0.0   0.0002032007944308134  6.837022374384105e-05  0.0         0.1252972155052703    0.7971374988555908   -0.0009559874236099095  0.10030427575111389


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.041268777726993715
RMSE: 0.20314718242445234
LogLoss: 0.16060321618610082
Mean Per-Class Error: 0.04498402164040993
AUC: 0.9859502597916762
pr_auc: 0.7614323359868411
Gini: 0.9719005195833523
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4764493795376985: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4733  266   0.0532   (266.0/4999.0)
1      185   4848  0.0368   (185.0/5033.0)
Total  4918  5114  0.045    (451.0/10032.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.476449     0.955553  216
max f2                       0.391135     0.964066  240
max f0point5                 0.642652     0.958669  168
max accuracy                 0.476449     0.955044  216
max precision                0.999978     0.99647   0
max recall                   3.58751e-05  1         399
max specificity              0.999978     0.9992    0
max absolute_mcc             0.476449     0.9102    216
max min_per_class_accuracy   0.523368     0.954391  204
max mean_per_class_accuracy  0.476449     0.955016  216
Gains/Lift Table: Avg response rate: 50.17 %, avg score: 49.87 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100678                   1                  1.99324     1.99324            1                1            1                           1                   0.0200676       0.0200676                  99.3245   99.3245
    2        0.0200359                   1                  1.97331     1.98333            0.99             1            0.995025                    1                   0.0196702       0.0397377                  97.3312   98.3328
    3        0.030004                    1                  1.99324     1.98662            1                1            0.996678                    1                   0.0198689       0.0596066                  99.3245   98.6623
    4        0.0400718                   1                  1.99324     1.98829            1                1            0.997512                    1                   0.0200676       0.0796742                  99.3245   98.8286
    5        0.0500399                   0.999999           1.99324     1.98927            1                1            0.998008                    1                   0.0198689       0.099543                   99.3245   98.9274
    6        0.10008                     0.999927           1.9853      1.98729            0.996016         0.99998      0.997012                    0.99999             0.0993443       0.198887                   98.5303   98.7289
    7        0.15002                     0.999247           1.98131     1.9853             0.994012         0.999698     0.996013                    0.999893            0.098947        0.297834                   98.1309   98.5298
    8        0.20006                     0.995718           1.98133     1.98431            0.994024         0.997871     0.995516                    0.999387            0.0991456       0.39698                    98.1333   98.4306
    9        0.30004                     0.962148           1.95946     1.97603            0.983051         0.983123     0.991362                    0.993968            0.195907        0.592887                   95.9461   97.6027
    10       0.40002                     0.844435           1.92766     1.96394            0.967099         0.911748     0.985298                    0.973418            0.192728        0.785615                   92.7664   96.3939
    11       0.5                         0.528546           1.67528     1.90622            0.840479         0.705323     0.95634                     0.91981             0.167495        0.953109                   67.5279   90.6219
    12       0.59998                     0.143304           0.349762    1.64685            0.175474         0.305675     0.826217                    0.817471            0.0349692       0.988079                   -65.0238  64.6853
    13       0.69996                     0.0255563          0.0695549   1.42156            0.0348953        0.0722177    0.713187                    0.711021            0.0069541       0.995033                   -93.0445  42.1556
    14       0.79994                     0.00152499         0.0377584   1.2486             0.0189432        0.00953569   0.626417                    0.623347            0.00377508      0.998808                   -96.2242  24.8603
    15       0.89992                     4.94358e-06        0.00993641  1.11099            0.00498504       0.000359618  0.557377                    0.554133            0.000993443     0.999801                   -99.0064  11.0989
    16       1                           4.26402e-40        0.0019853   1                  0.000996016      5.33139e-07  0.501695                    0.498676            0.000198689     1                          -99.8015  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03841441971059958
RMSE: 0.19599596860802923
LogLoss: 0.1527748778705387
Mean Per-Class Error: 0.04083631042503555
AUC: 0.9879468153996237
pr_auc: 0.7619280573941746
Gini: 0.9758936307992474
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5411926228345183: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3010  118   0.0377   (118.0/3128.0)
1      134   2915  0.0439   (134.0/3049.0)
Total  3144  3033  0.0408   (252.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.541193     0.958566  196
max f2                       0.374692     0.96634   239
max f0point5                 0.630642     0.964406  169
max accuracy                 0.550144     0.959203  193
max precision                0.99911      0.999012  2
max recall                   1.58384e-05  1         399
max specificity              0.999982     0.99968   0
max absolute_mcc             0.550144     0.918464  193
max min_per_class_accuracy   0.523721     0.958347  200
max mean_per_class_accuracy  0.541193     0.959164  196
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.16 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1           1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323     2.00957            0.983871         1           0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   1                  2.02591     2.01502            1                1           0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1           0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999999           2.02591     2.01935            1                1           0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999937           2.02591     2.02263            1                0.999981    0.998382                    0.999991            0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.999246           2.02591     2.02372            1                0.999702    0.998921                    0.999894            0.101345        0.303706                   102.591   102.372
    8        0.200097                    0.99548            2.0128      2.02099            0.993528         0.997762    0.997573                    0.999361            0.100689        0.404395                   101.28    102.099
    9        0.299984                    0.958676           1.99308     2.0117             0.983793         0.982716    0.992984                    0.993819            0.199082        0.603477                   99.3075   101.17
    10       0.400032                    0.827511           1.95379     1.99721            0.964401         0.904665    0.985836                    0.971521            0.195474        0.79895                    95.379    99.7215
    11       0.500081                    0.495494           1.64564     1.92688            0.812298         0.680115    0.951117                    0.913221            0.164644        0.963595                   64.5642   92.6877
    12       0.599968                    0.125682           0.259395    1.64926            0.128039         0.277205    0.814085                    0.807333            0.0259101       0.989505                   -74.0605  64.9264
    13       0.700016                    0.0238848          0.0622853   1.42245            0.0307443        0.0638348   0.702128                    0.70107             0.00623155      0.995736                   -93.7715  42.2448
    14       0.799903                    0.00123355         0.0262679   1.2481             0.012966         0.00804742  0.61607                     0.61453             0.00262381      0.99836                    -97.3732  24.8102
    15       0.899951                    4.65932e-06        0.00983452  1.11044            0.00485437       0.00027577  0.54812                     0.546242            0.000983929     0.999344                   -99.0165  11.0442
    16       1                           2.6676e-37         0.00655634  1                  0.00323625       5.0268e-07  0.493605                    0.491592            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:14:03  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:14:04  7 min 22.002 sec  15384 obs/sec     1         1             25000      0.311972         0.408621            0.61069        0.935781        0.70484            1.97351          0.127791                         0.30162            0.371831              0.636042         0.943164          0.714578             1.99323            0.117047
    2019-08-03 16:14:10  7 min 28.152 sec  16648 obs/sec     5         5             125000     0.244154         0.22351             0.761552       0.972714        0.760514           1.99324          0.069378                         0.235032           0.206499              0.779004         0.977342          0.787585             2.02591            0.062328
    2019-08-03 16:14:16  7 min 34.077 sec  17102 obs/sec     9         9             225000     0.209028         0.170292            0.825228       0.984294        0.779683           1.99324          0.0471491                        0.200582           0.161023              0.839042         0.986489          0.781447             2.02591            0.0406346
    2019-08-03 16:14:18  7 min 35.811 sec  17092 obs/sec     10        10            250000     0.203147         0.160603            0.834923       0.98595         0.761432           1.99324          0.0449561                        0.195996           0.152775              0.846317         0.987947          0.761928             2.02591            0.0407965
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.0034450157963965833
C28         0.9828968644142151     0.9828968644142151   0.0033860952241356415
C36         0.958669900894165      0.958669900894165    0.0033026329521103456
C57         0.8535951972007751     0.8535951972007751   0.0029406489380849267
C40         0.8490160703659058     0.8490160703659058   0.0029248737738050983
---         ---                    ---                  ---
C241        0.15278272330760956    0.15278272330760956  0.0005263388952112033
C651        0.15121345221996307    0.15121345221996307  0.0005209327315254328
C381        0.14952991902828217    0.14952991902828217  0.0005151329330863341
C307        0.1483083963394165     0.1483083963394165   0.000510924768127535
C721        0.14595070481300354    0.14595070481300354  0.000502802483576012

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_44

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0041811355704585735   0.0038112327456474304   0.0         0.02526143387526024    0.09030282497406006  -0.014836726095708972   0.23061734437942505
    3        2        Softmax                      0.0   0.0   0.00024390026612763904  5.2198374760337174e-05  0.0         -0.041277397322119214  0.499605655670166    2.2967726583111858e-07  0.09377872943878174


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.041203664206824905
RMSE: 0.2029868572268286
LogLoss: 0.1616298804746641
Mean Per-Class Error: 0.04263667526727877
AUC: 0.9861207529439169
pr_auc: 0.7605358229889007
Gini: 0.9722415058878338
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5489438369660687: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4808  176   0.0353   (176.0/4984.0)
1      252   4792  0.05     (252.0/5044.0)
Total  5060  4968  0.0427   (428.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.548944     0.957251  190
max f2                       0.35238      0.964291  246
max f0point5                 0.586039     0.963165  178
max accuracy                 0.548944     0.95732   190
max precision                0.999665     0.997063  1
max recall                   3.43854e-05  1         399
max specificity              0.999968     0.999197  0
max absolute_mcc             0.548944     0.914749  190
max min_per_class_accuracy   0.509553     0.956582  200
max mean_per_class_accuracy  0.548944     0.957363  190
Gains/Lift Table: Avg response rate: 50.30 %, avg score: 49.89 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   1                  1.9881      1.9881             1                1            1                           1                   0.0200238       0.0200238                  98.8105   98.8105
    2        0.0200439                   1                  1.9881      1.9881             1                1            1                           1                   0.0198255       0.0398493                  98.8105   98.8105
    3        0.030016                    1                  1.96822     1.9815             0.99             1            0.996678                    1                   0.0196273       0.0594766                  96.8224   98.15
    4        0.0400878                   1                  1.9881      1.98316            1                1            0.997512                    1                   0.0200238       0.0795004                  98.8105   98.3159
    5        0.0500598                   0.999999           1.9881      1.98414            1                1            0.998008                    1                   0.0198255       0.0993259                  98.8105   98.4144
    6        0.10002                     0.999905           1.98414     1.98414            0.998004         0.999975     0.998006                    0.999987            0.0991277       0.198454                   98.4136   98.414
    7        0.15008                     0.999097           1.97622     1.9815             0.994024         0.99961      0.996678                    0.999861            0.0989294       0.297383                   97.6224   98.15
    8        0.20004                     0.994872           1.97223     1.97918            0.992016         0.997378     0.995513                    0.999241            0.0985329       0.395916                   97.2232   97.9185
    9        0.30006                     0.954901           1.95441     1.97093            0.983051         0.979632     0.991359                    0.992705            0.19548         0.591396                   95.4408   97.0926
    10       0.39998                     0.827554           1.92461     1.95936            0.968064         0.901028     0.98554                     0.969803            0.192308        0.783703                   92.4612   95.9356
    11       0.5                         0.519897           1.70664     1.9088             0.858425         0.701145     0.960112                    0.91606             0.170698        0.954401                   70.6638   90.8803
    12       0.60002                     0.15367            0.334985    1.64646            0.168495         0.314183     0.828154                    0.815731            0.0335052       0.987906                   -66.5015  64.6456
    13       0.69994                     0.0316192          0.073413    1.4219             0.0369261        0.0813278    0.715202                    0.710891            0.00733545      0.995242                   -92.6587  42.1896
    14       0.79996                     0.00225888         0.0297324   1.24783            0.0149551        0.0129041    0.627649                    0.623621            0.00297383      0.998216                   -97.0268  24.7832
    15       0.89998                     1.49452e-05        0.0138751   1.1107             0.00697906       0.000538827  0.55867                     0.554374            0.00138779      0.999603                   -98.6125  11.0695
    16       1                           2.12645e-26        0.00396432  1                  0.00199402       1.60065e-06  0.502992                    0.498926            0.000396511     1                          -99.6036  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.038878889614387624
RMSE: 0.19717730501857364
LogLoss: 0.1530864144820684
Mean Per-Class Error: 0.03737185014750555
AUC: 0.9876726804058855
pr_auc: 0.7722258104151769
Gini: 0.975345360811771
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5037993620728543: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3005  123   0.0393   (123.0/3128.0)
1      108   2941  0.0354   (108.0/3049.0)
Total  3113  3064  0.0374   (231.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.503799     0.962212  200
max f2                       0.418942     0.967207  225
max f0point5                 0.637009     0.96578   164
max accuracy                 0.503799     0.962603  200
max precision                0.999977     0.996951  0
max recall                   9.98072e-06  1         399
max specificity              0.999977     0.999361  0
max absolute_mcc             0.503799     0.92521   200
max min_per_class_accuracy   0.510491     0.961955  198
max mean_per_class_accuracy  0.503799     0.962628  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.34 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999999           2.02591     2.02591            1                0.999999     1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.9999             2.0128      2.01935            0.993528         0.999973     0.996764                    0.999986            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.998972           2.01935     2.01935            0.996764         0.999596     0.996764                    0.999856            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.994785           1.99313     2.0128             0.983819         0.997368     0.993528                    0.999234            0.0997048       0.402755                   99.3128   101.28
    9        0.299984                    0.955309           1.99308     2.00623            0.983793         0.980647     0.990286                    0.993045            0.199082        0.601837                   99.3075   100.623
    10       0.400032                    0.816543           1.96362     1.99557            0.969256         0.897675     0.985026                    0.969193            0.196458        0.798295                   96.3625   99.5575
    11       0.500081                    0.480662           1.69154     1.93475            0.834951         0.675827     0.955002                    0.910501            0.169236        0.96753                    69.1537   93.4747
    12       0.599968                    0.142209           0.22656     1.65036            0.111831         0.289417     0.814625                    0.807099            0.0226304       0.990161                   -77.344   65.0357
    13       0.700016                    0.0320383          0.0590071   1.42292            0.0291262        0.0779823    0.702359                    0.702891            0.00590357      0.996064                   -94.0993  42.2916
    14       0.799903                    0.00246782         0.0328348   1.24933            0.0162075        0.0127109    0.616677                    0.616706            0.00327976      0.999344                   -96.7165  24.9332
    15       0.899951                    1.57337e-05        0.00655634  1.11117            0.00323625       0.000541826  0.54848                     0.548206            0.000655953     1                          -99.3444  11.1171
    16       1                           8.33476e-32        0           1                  0                1.91903e-06  0.493605                    0.493359            0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:53:09  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:53:12  46 min 29.407 sec  10421 obs/sec     1         1             25000      0.311707         0.412675            0.611341       0.937984        0.649903           1.9881           0.122357                         0.300581           0.382671              0.638544         0.944059          0.636758             2.02591            0.113162
    2019-08-03 16:53:17  46 min 34.480 sec  10600 obs/sec     3         3             75000      0.260833         0.253144            0.727855       0.965225        0.753236           1.9881           0.0815716                        0.25241            0.237279              0.745115         0.96968           0.754705             2.02591            0.0749555
    2019-08-03 16:53:24  46 min 41.308 sec  11091 obs/sec     6         6             150000     0.234118         0.206228            0.780748       0.97636         0.754348           1.9881           0.0626247                        0.227998           0.196119              0.792033         0.978664          0.764952             2.02591            0.0569856
    2019-08-03 16:53:30  46 min 47.911 sec  11395 obs/sec     9         9             225000     0.206041         0.165726            0.830183       0.985562        0.754532           1.9881           0.0450738                        0.201098           0.160437              0.838211         0.98668           0.781053             2.02591            0.0388538
    2019-08-03 16:53:33  46 min 50.404 sec  11442 obs/sec     10        10            250000     0.202987         0.16163             0.835179       0.986121        0.760536           1.9881           0.0426805                        0.197177           0.153086              0.844459         0.987673          0.772226             2.02591            0.0373968
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.003922345511198727
C36         0.9602453708648682     0.9602453708648682   0.003766414120061173
C35         0.8798682689666748     0.8798682689666748   0.0034511473552276315
C43         0.8164089322090149     0.8164089322090149   0.0032022379105525758
C31         0.7714039087295532     0.7714039087295532   0.003025712658726516
---         ---                    ---                  ---
C324        0.1541333794593811     0.1541333794593811   0.0006045643690483936
C226        0.1537599265575409     0.1537599265575409   0.0006030995577352165
C629        0.15320537984371185    0.15320537984371185  0.0006009244339214791
C475        0.15133482217788696    0.15133482217788696  0.0005935874604574926
C423        0.14325092732906342    0.14325092732906342  0.000561879631784207

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_9

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight             weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ----------------------  -------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.013322190408319199    0.02897554636001587    0.0         0.017845532823936167    0.06862947344779968  0.13352123960319934      0.10844337940216064
    3        2        Softmax                      0.0   0.0   0.00030407807022925226  7.756758714094758e-05  0.0         -0.0016358928205590928  0.2475619912147522   -0.00034627416836530145  0.1214917004108429


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.03899484324381216
RMSE: 0.1974711200247068
LogLoss: 0.15497973832318687
Mean Per-Class Error: 0.03947011099026554
AUC: 0.9872179992505545
pr_auc: 0.7770859794488308
Gini: 0.9744359985011091
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5201172129224491: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4826  192   0.0383   (192.0/5018.0)
1      204   4811  0.0407   (204.0/5015.0)
Total  5030  5003  0.0395   (396.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.520117     0.960471  202
max f2                       0.408221     0.965367  233
max f0point5                 0.606868     0.965949  177
max accuracy                 0.530593     0.96053   199
max precision                0.999463     0.999213  1
max recall                   1.90913e-05  1         399
max specificity              0.999931     0.999801  0
max absolute_mcc             0.530593     0.921075  199
max min_per_class_accuracy   0.516319     0.959521  203
max mean_per_class_accuracy  0.520117     0.96053   202
Gains/Lift Table: Avg response rate: 49.99 %, avg score: 49.68 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   1                  2.0006      2.0006             1                1            1                           1                   0.0201396       0.0201396                  100.06    100.06
    2        0.0200339                   1                  2.0006      2.0006             1                1            1                           1                   0.0199402       0.0400798                  100.06    100.06
    3        0.030001                    0.999999           2.0006      2.0006             1                1            1                           1                   0.0199402       0.0600199                  100.06    100.06
    4        0.0400678                   0.999997           2.0006      2.0006             1                0.999999     1                           1                   0.0201396       0.0801595                  100.06    100.06
    5        0.0500349                   0.999993           2.0006      2.0006             1                0.999995     1                           0.999999            0.0199402       0.1001                     100.06    100.06
    6        0.10007                     0.999716           1.99661     1.99861            0.998008         0.999905     0.999004                    0.999952            0.0999003       0.2                        99.6613   99.8606
    7        0.150005                    0.998025           1.9966      1.99794            0.998004         0.99909      0.998671                    0.999665            0.0997009       0.299701                   99.6605   99.794
    8        0.20004                     0.99213            1.99263     1.99661            0.996016         0.995604     0.998007                    0.998649            0.0997009       0.399402                   99.2628   99.6611
    9        0.30001                     0.951708           1.97068     1.98797            0.985045         0.976866     0.993688                    0.991391            0.197009        0.596411                   97.0679   98.797
    10       0.39998                     0.833237           1.93079     1.97368            0.965105         0.901868     0.986544                    0.969016            0.193021        0.789432                   93.0787   97.3678
    11       0.50005                     0.512456           1.7017      1.91925            0.850598         0.707473     0.959338                    0.916676            0.170289        0.959721                   70.1704   91.925
    12       0.60002                     0.14712            0.271268    1.64468            0.135593         0.296093     0.822093                    0.81328             0.0271186       0.986839                   -72.8732  64.4678
    13       0.69999                     0.0290951          0.0797846   1.42119            0.0398804        0.0760855    0.71038                     0.707996            0.00797607      0.994816                   -92.0215  42.1185
    14       0.79996                     0.00196493         0.0279246   1.24707            0.0139581        0.0111688    0.623349                    0.620914            0.00279163      0.997607                   -97.2075  24.7071
    15       0.89993                     1.98312e-05        0.0179515   1.11053            0.00897308       0.000507654  0.5551                      0.551996            0.00179462      0.999402                   -98.2048  11.0533
    16       1                           1.29199e-29        0.00597788  1                  0.00298805       2.64439e-06  0.49985                     0.496758            0.000598205     1                          -99.4022  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03808716647836711
RMSE: 0.1951593361291412
LogLoss: 0.15326119448604725
Mean Per-Class Error: 0.03725342005554633
AUC: 0.9873455428344708
pr_auc: 0.7885129550773434
Gini: 0.9746910856689417
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5188275518883407: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3016  112   0.0358   (112.0/3128.0)
1      118   2931  0.0387   (118.0/3049.0)
Total  3134  3043  0.0372   (230.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.518828     0.962246  197
max f2                       0.406425     0.967973  224
max f0point5                 0.607949     0.966367  171
max accuracy                 0.518828     0.962765  197
max precision                0.989958     0.998514  13
max recall                   5.38018e-05  1         399
max specificity              0.999953     0.999361  0
max absolute_mcc             0.518828     0.925518  197
max min_per_class_accuracy   0.509288     0.962283  198
max mean_per_class_accuracy  0.518828     0.962747  197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.19 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999997           2.02591     2.02591            1                0.999998     1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999991           1.9927      2.01935            0.983607         0.999994     0.996764                    0.999998            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.999708           2.01935     2.01935            0.996764         0.999909     0.996764                    0.999954            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998066           2.02591     2.02154            1                0.999092     0.997843                    0.999667            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.992619           2.02591     2.02263            1                0.995714     0.998382                    0.998678            0.101345        0.404723                   102.591   102.263
    9        0.299984                    0.948489           1.98322     2.00951            0.97893          0.976271     0.991905                    0.991217            0.198098        0.602821                   98.3225   100.951
    10       0.400032                    0.824774           1.9669      1.99885            0.970874         0.895537     0.986645                    0.967288            0.196786        0.799606                   96.6903   99.8854
    11       0.500081                    0.459643           1.66859     1.93278            0.823625         0.685385     0.95403                     0.910889            0.16694         0.966546                   66.8589   93.278
    12       0.599968                    0.141516           0.223277    1.64817            0.110211         0.279469     0.813546                    0.805766            0.0223024       0.988849                   -77.6723  64.817
    13       0.700016                    0.0277557          0.0458944   1.41917            0.0226537        0.0729308    0.700509                    0.701027            0.00459167      0.99344                    -95.4106  41.9168
    14       0.799903                    0.00228849         0.0426853   1.24728            0.0210697        0.0112563    0.615665                    0.614893            0.00426369      0.997704                   -95.7315  24.7282
    15       0.899951                    2.13983e-05        0.019669    1.11081            0.00970874       0.000593384  0.5483                      0.5466              0.00196786      0.999672                   -98.0331  11.0807
    16       1                           1.35366e-32        0.00327817  1                  0.00161812       2.80734e-06  0.493605                    0.491914            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:17:41  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:17:48  11 min  6.441 sec  3636 obs/sec      1         1             25000      0.297698         0.344157            0.645505       0.949048        0.742861           2.0006           0.115419                         0.287989           0.32379               0.668195         0.952982          0.758208             2.02591            0.10361
    2019-08-03 16:18:02  11 min 20.100 sec  3852 obs/sec      3         3             75000      0.256249         0.236565            0.737347       0.968125        0.832003           2.0006           0.0838234                        0.249468           0.225168              0.751022         0.971168          0.813294             1.99323            0.0768982
    2019-08-03 16:18:14  11 min 32.819 sec  4011 obs/sec      5         5             125000     0.23829          0.204978            0.772871       0.976603        0.828794           2.0006           0.0683744                        0.230651           0.193791              0.787166         0.979112          0.853914             2.02591            0.0616804
    2019-08-03 16:18:27  11 min 45.073 sec  4137 obs/sec      7         7             175000     0.220828         0.184445            0.80494        0.981735        0.832667           2.0006           0.0549188                        0.216737           0.177631              0.81207          0.982719          0.85149              2.02591            0.0522908
    2019-08-03 16:18:39  11 min 57.203 sec  4217 obs/sec      9         9             225000     0.20124          0.159059            0.838011       0.986572        0.806877           2.0006           0.0414632                        0.199409           0.15483               0.840918         0.987398          0.80878              2.02591            0.0398252
    2019-08-03 16:18:45  12 min  3.624 sec  4259 obs/sec      10        10            250000     0.197471         0.15498             0.844021       0.987218        0.777086           2.0006           0.0394697                        0.195159           0.153261              0.847626         0.987346          0.788513             2.02591            0.0372349
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003354545657093079
C28         0.9202039837837219     0.9202039837837219   0.0030868662774414346
C35         0.9017683863639832     0.9017683863639832   0.0030250232241811332
C41         0.897619903087616      0.897619903087616    0.0030111069476228725
C25         0.8973422646522522     0.8973422646522522   0.003010175596815281
---         ---                    ---                  ---
C426        0.2154887169599533     0.2154887169599533   0.000722866739630571
C504        0.21520566940307617    0.21520566940307617  0.000721917243677898
C660        0.21409578621387482    0.21409578621387482  0.0007181940898456821
C888        0.2123907506465912     0.2123907506465912   0.0007124744701882615
C569        0.20066381990909576    0.20066381990909576  0.0006731359456117649

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_115

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 255,050 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  ----------------------  ------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.051265075490254254   0.09439778327941895     0.0         -0.0005475996830007749  0.11004170775413513  -0.0028012092639432325  0.1611199975013733
    3        2        Softmax                 0.0   0.0   0.0017169142674902105  1.7238096916116774e-05  0.0         0.04703711626268614     0.35568881034851074  -0.0007905455533798733  0.2515164613723755


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04769548473538058
RMSE: 0.2183929594455384
LogLoss: 0.1663751022177561
Mean Per-Class Error: 0.06279566443543538
AUC: 0.9825992681217233
pr_auc: 0.9485312336473173
Gini: 0.9651985362434465
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46778483551763417: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4687  362   0.0717   (362.0/5049.0)
1      274   4698  0.0551   (274.0/4972.0)
Total  4961  5060  0.0635   (636.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.467785     0.936603  210
max f2                       0.189956     0.955585  288
max f0point5                 0.767548     0.946468  131
max accuracy                 0.556613     0.937232  187
max precision                0.999487     1         0
max recall                   0.00130778   1         397
max specificity              0.999487     1         0
max absolute_mcc             0.556613     0.874467  187
max min_per_class_accuracy   0.537319     0.936243  192
max mean_per_class_accuracy  0.556613     0.937204  187
Gains/Lift Table: Avg response rate: 49.62 %, avg score: 49.91 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   0.999429           2.01549     2.01549            1                0.999644     1                           0.999644            0.0203138       0.0203138                  101.549   101.549
    2        0.0200579                   0.999091           2.01549     2.01549            1                0.99926      1                           0.999453            0.0201126       0.0404264                  101.549   101.549
    3        0.0300369                   0.998774           2.01549     2.01549            1                0.998921     1                           0.999276            0.0201126       0.060539                   101.549   101.549
    4        0.040016                    0.998436           2.01549     2.01549            1                0.998614     1                           0.999111            0.0201126       0.0806516                  101.549   101.549
    5        0.0500948                   0.998125           2.01549     2.01549            1                0.998288     1                           0.998945            0.0203138       0.100965                   101.549   101.549
    6        0.10009                     0.99607            2.01146     2.01348            0.998004         0.997151     0.999003                    0.998049            0.100563        0.201529                   101.146   101.348
    7        0.150085                    0.993586           2.00744     2.01147            0.996008         0.994874     0.998005                    0.996991            0.100362        0.301891                   100.744   101.147
    8        0.20008                     0.989489           2.01146     2.01147            0.998004         0.991624     0.998005                    0.99565             0.100563        0.402454                   101.146   101.147
    9        0.30007                     0.971205           1.97928     2.00074            0.982036         0.981975     0.992684                    0.991093            0.197908        0.600362                   97.928    100.074
    10       0.40006                     0.905076           1.89882     1.97527            0.942116         0.946206     0.980045                    0.979874            0.189863        0.790225                   89.8822   97.5267
    11       0.50005                     0.50481            1.50055     1.88034            0.744511         0.760626     0.932948                    0.936033            0.15004         0.940265                   50.0552   88.0343
    12       0.60004                     0.0922379          0.472694    1.64577            0.234531         0.247383     0.816564                    0.821277            0.0472647       0.98753                    -52.7306  64.5774
    13       0.70003                     0.0206246          0.0784471   1.4219             0.0389222        0.0470048    0.705488                    0.710683            0.00784393      0.995374                   -92.1553  42.1902
    14       0.80002                     0.00582884         0.0281605   1.24771            0.0139721        0.0115375    0.619059                    0.6233              0.00281577      0.99819                    -97.184   24.7706
    15       0.90001                     0.00191052         0.0140802   1.11065            0.00698603       0.00348502   0.551059                    0.55444             0.00140788      0.999598                   -98.592   11.0652
    16       1                           3.54709e-05        0.00402293  1                  0.00199601       0.000965476  0.496158                    0.499098            0.000402253     1                          -99.5977  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.04391705813161911
RMSE: 0.2095639714541102
LogLoss: 0.15370392100077354
Mean Per-Class Error: 0.05609795966813147
AUC: 0.9851556608640291
pr_auc: 0.9585241563402257
Gini: 0.9703113217280581
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5825763537303087: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2973  155   0.0496   (155.0/3128.0)
1      191   2858  0.0626   (191.0/3049.0)
Total  3164  3013  0.056    (346.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.582576     0.942923  176
max f2                       0.181954     0.955915  289
max f0point5                 0.771533     0.953163  128
max accuracy                 0.582576     0.943986  176
max precision                0.999579     1         0
max recall                   0.0011655    1         397
max specificity              0.999579     1         0
max absolute_mcc             0.582576     0.887997  176
max min_per_class_accuracy   0.519403     0.942455  188
max mean_per_class_accuracy  0.582576     0.943902  176
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.60 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999466           2.02591     2.02591            1                0.999664     1                           0.999664            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999158           2.02591     2.02591            1                0.999317     1                           0.999491            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.998838           2.02591     2.02591            1                0.998994     1                           0.999325            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998604           2.02591     2.02591            1                0.998722     1                           0.999174            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.9983             2.02591     2.02591            1                0.99845      1                           0.999031            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.996395           2.01935     2.02263            0.996764         0.997455     0.998382                    0.998243            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.993575           2.02591     2.02372            1                0.994997     0.998921                    0.997161            0.101345        0.303706                   102.591   102.372
    8        0.200097                    0.989694           2.02591     2.02427            1                0.991716     0.999191                    0.9958              0.101345        0.405051                   102.591   102.427
    9        0.299984                    0.971912           1.99308     2.01388            0.983793         0.982143     0.994064                    0.991252            0.199082        0.604133                   99.3075   101.388
    10       0.400032                    0.908091           1.91445     1.98902            0.944984         0.948581     0.981789                    0.98058             0.191538        0.795671                   91.4452   98.9016
    11       0.500081                    0.466115           1.52763     1.89671            0.754045         0.755135     0.936225                    0.935476            0.152837        0.948508                   52.7628   89.6708
    12       0.599968                    0.0827368          0.390735    1.64598            0.192869         0.224358     0.812466                    0.817085            0.0390292       0.987537                   -60.9265  64.5984
    13       0.700016                    0.0194779          0.101623    1.42526            0.0501618        0.0420468    0.703515                    0.706314            0.0101673       0.997704                   -89.8377  42.5259
    14       0.799903                    0.00564791         0.00985045  1.24851            0.00486224       0.0110657    0.616272                    0.619496            0.000983929     0.998688                   -99.015   24.8512
    15       0.899951                    0.00183433         0.00655634  1.11044            0.00323625       0.00339476   0.54812                     0.551003            0.000655953     0.999344                   -99.3444  11.0442
    16       1                           3.27106e-05        0.00655634  1                  0.00323625       0.000913306  0.493605                    0.495967            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:17:12  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:17:20  2:10:37.864  2435 obs/sec      0.78324   1             19581      0.301406         0.300691            0.636597       0.945103        0.915531           2.01549          0.125636                         0.291639           0.281668              0.659732         0.951956          0.931853             2.02591            0.1164
    2019-08-03 18:17:29  2:10:46.572  2421 obs/sec      1.56836   2             39209      0.287793         0.274878            0.668682       0.953654        0.937643           2.01549          0.112663                         0.279503           0.260539              0.68746          0.958408          0.93881              2.02591            0.107496
    2019-08-03 18:17:37  2:10:55.300  2421 obs/sec      2.35156   3             58789      0.286496         0.272413            0.67166        0.954862        0.944079           2.01549          0.112264                         0.278693           0.261194              0.68927          0.958751          0.945392             2.02591            0.102315
    2019-08-03 18:17:46  2:11:03.964  2428 obs/sec      3.13804   4             78451      0.2826           0.267034            0.680529       0.956803        0.939279           2.01549          0.110069                         0.275086           0.255057              0.697262         0.960297          0.946766             2.02591            0.103448
    2019-08-03 18:17:55  2:11:12.697  2422 obs/sec      3.91552   5             97888      0.283215         0.273088            0.679138       0.956215        0.926552           2.01549          0.108472                         0.275326           0.259341              0.696733         0.959971          0.929041             2.02591            0.101991
    2019-08-03 18:18:03  2:11:21.291  2428 obs/sec      4.7006    6             117515     0.277346         0.260594            0.692299       0.959103        0.93042            2.01549          0.103084                         0.268301           0.245867              0.712012         0.963168          0.941686             2.02591            0.096487
    2019-08-03 18:18:12  2:11:30.007  2431 obs/sec      5.4882    7             137205     0.263578         0.235474            0.72209        0.965908        0.954124           2.01549          0.0926055                        0.25417            0.221037              0.741548         0.970304          0.963408             2.02591            0.0864497
    2019-08-03 18:18:21  2:11:38.714  2433 obs/sec      6.27688   8             156922     0.26274          0.234656            0.723855       0.966077        0.951673           1.99553          0.0921066                        0.253131           0.219944              0.743656         0.970004          0.955229             2.02591            0.0853165
    2019-08-03 18:18:29  2:11:47.432  2432 obs/sec      7.06284   9             176571     0.260653         0.232754            0.728224       0.96688         0.938666           1.99553          0.0910089                        0.248769           0.21396               0.752415         0.9716            0.953542             2.02591            0.0811073
    2019-08-03 18:18:38  2:11:56.032  2435 obs/sec      7.84532   10            196133     0.24742          0.209957            0.755119       0.97274         0.965473           2.01549          0.081429                         0.237742           0.19605               0.773879         0.976161          0.961652             2.02591            0.0744698
    2019-08-03 18:18:46  2:12:04.469  2443 obs/sec      8.63148   11            215787     0.243138         0.203128            0.763523       0.974469        0.952659           2.01549          0.0785351                        0.234391           0.191014              0.780208         0.977097          0.955185             2.02591            0.0725271
    2019-08-03 18:18:55  2:12:13.215  2441 obs/sec      9.41656   12            235414     0.234198         0.190054            0.780593       0.977877        0.931019           2.01549          0.07145                          0.228276           0.181751              0.791527         0.979519          0.952927             2.02591            0.0660515
    2019-08-03 18:19:04  2:12:21.850  2443 obs/sec      10.202    13            255050     0.218393         0.166375            0.809207       0.982599        0.948531           2.01549          0.0634667                        0.209564           0.153704              0.824303         0.985156          0.958524             2.02591            0.0560142
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0038768526648097178
C438        0.8194157481193542     0.8194157481193542   0.0031767541266835672
C374        0.7367422580718994     0.7367422580718994   0.002856241186483972
C322        0.7200751304626465     0.7200751304626465   0.0027916251883973162
C88         0.6981844305992126     0.6981844305992126   0.002706758170297213
---         ---                    ---                  ---
C915        0.16725090146064758    0.16725090146064758  0.0006484071030195391
C743        0.1668681800365448     0.1668681800365448   0.0006469233484466265
C758        0.16666091978549957    0.16666091978549957  0.0006461198309900527
C848        0.1655610054731369     0.1655610054731369   0.0006418556252571071
C838        0.16208481788635254    0.16208481788635254  0.0006283789581479036

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_206

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.005880192157326524   0.013496559113264084   0.0         0.02388063412952717    0.08402252197265625  -0.0045012901367719816  0.2233913540840149
    3        2        Softmax                      0.0   0.0   0.0002937257133908133  6.016311817802489e-05  0.0         -0.039731898424179235  0.48839128017425537  0.0034187471703946287   0.10217881202697754


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.040365182401157614
RMSE: 0.20091088173903776
LogLoss: 0.16307702977393107
Mean Per-Class Error: 0.04127017736149852
AUC: 0.9858014752659656
pr_auc: 0.7496292386421796
Gini: 0.9716029505319312
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5245165582188759: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4761  231   0.0463   (231.0/4992.0)
1      182   4836  0.0363   (182.0/5018.0)
Total  4943  5067  0.0413   (413.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.524517     0.959048  196
max f2                       0.396538     0.966274  232
max f0point5                 0.597774     0.961038  172
max accuracy                 0.52763      0.958741  195
max precision                0.99966      0.994441  1
max recall                   3.66129e-05  1         399
max specificity              0.999974     0.998397  0
max absolute_mcc             0.524517     0.917524  196
max min_per_class_accuracy   0.546282     0.957732  189
max mean_per_class_accuracy  0.52763      0.95873   195
Gains/Lift Table: Avg response rate: 50.13 %, avg score: 50.64 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   1                  1.99482     1.99482            1                1            1                           1                   0.0201275       0.0201275                  99.4819   99.4819
    2        0.0200799                   1                  1.99482     1.99482            1                1            1                           1                   0.0199283       0.0400558                  99.4819   99.4819
    3        0.0300699                   1                  1.99482     1.99482            1                1            1                           1                   0.0199283       0.0599841                  99.4819   99.4819
    4        0.0400599                   1                  1.99482     1.99482            1                1            1                           1                   0.0199283       0.0799123                  99.4819   99.4819
    5        0.05005                     1                  1.99482     1.99482            1                1            1                           1                   0.0199283       0.0998406                  99.4819   99.4819
    6        0.1                         0.999938           1.97088     1.98286            0.988            0.999984     0.994006                    0.999992            0.0984456       0.198286                   97.0881   98.2862
    7        0.15005                     0.999295           1.98287     1.98287            0.994012         0.999707     0.994008                    0.999897            0.0992427       0.297529                   98.2874   98.2866
    8        0.2                         0.996246           1.95492     1.97589            0.98             0.998071     0.990509                    0.999441            0.0976485       0.395177                   95.4922   97.5887
    9        0.3                         0.965433           1.95895     1.97024            0.982018         0.984896     0.987679                    0.994593            0.195895        0.591072                   95.8948   97.024
    10       0.4                         0.85258            1.93902     1.96244            0.972028         0.919015     0.983766                    0.975698            0.193902        0.784974                   93.902    96.2435
    11       0.5                         0.548826           1.71582     1.91311            0.86014          0.725747     0.959041                    0.925708            0.171582        0.956556                   71.5823   91.3113
    12       0.6                         0.171519           0.326823    1.64873            0.163836         0.330863     0.826507                    0.826567            0.0326823       0.989239                   -67.3177  64.8731
    13       0.7                         0.0357777          0.0597848   1.42174            0.02997          0.0902755    0.712716                    0.721383            0.00597848      0.995217                   -94.0215  42.1739
    14       0.8                         0.00240616         0.033878    1.24826            0.016983         0.013905     0.625749                    0.632948            0.0033878       0.998605                   -96.6122  24.8256
    15       0.9                         1.5992e-05         0.00996413  1.11067            0.004995         0.000600255  0.556777                    0.562687            0.000996413     0.999601                   -99.0036  11.0668
    16       1                           1.64274e-31        0.00398565  1                  0.001998         1.74919e-06  0.501299                    0.506419            0.000398565     1                          -99.6014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03862297344800113
RMSE: 0.19652728423300703
LogLoss: 0.1539571377366196
Mean Per-Class Error: 0.036387920990404776
AUC: 0.9874392279050026
pr_auc: 0.7581435382061076
Gini: 0.9748784558100052
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5347773793876798: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3005  123   0.0393   (123.0/3128.0)
1      102   2947  0.0335   (102.0/3049.0)
Total  3107  3070  0.0364   (225.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.534777     0.963229  192
max f2                       0.470266     0.968646  209
max f0point5                 0.61091      0.966335  166
max accuracy                 0.543426     0.963575  189
max precision                0.997684     0.995675  4
max recall                   2.50938e-05  1         399
max specificity              0.999977     0.998402  0
max absolute_mcc             0.534777     0.927165  192
max min_per_class_accuracy   0.545821     0.962916  188
max mean_per_class_accuracy  0.534777     0.963612  192
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.07 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.999931           2.0128      2.01935            0.993528         0.999982     0.996764                    0.999991            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.999189           2.00624     2.01498            0.990291         0.999666     0.994606                    0.999883            0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.995981           2.01935     2.01608            0.996764         0.997894     0.995146                    0.999385            0.101017        0.403411                   101.935   101.608
    9        0.299984                    0.963164           1.97994     2.00404            0.97731          0.983616     0.989207                    0.994135            0.19777         0.601181                   97.9941   100.404
    10       0.400032                    0.842224           1.98657     1.99967            0.980583         0.912635     0.98705                     0.973751            0.198754        0.799934                   98.6572   99.9674
    11       0.500081                    0.513979           1.68826     1.93737            0.833333         0.698384     0.956297                    0.91866             0.168908        0.968842                   68.8258   93.7371
    12       0.599968                    0.165942           0.203576    1.64872            0.100486         0.308265     0.813815                    0.817037            0.0203345       0.989177                   -79.6424  64.8717
    13       0.700016                    0.0370481          0.0458944   1.41964            0.0226537        0.0895772    0.70074                     0.713066            0.00459167      0.993768                   -95.4106  41.9636
    14       0.799903                    0.00253431         0.0525358   1.24892            0.0259319        0.0144785    0.616474                    0.625831            0.00524762      0.999016                   -94.7464  24.8922
    15       0.899951                    1.99185e-05        0.00983452  1.11117            0.00485437       0.000591595  0.54848                     0.556323            0.000983929     1                          -99.0165  11.1171
    16       1                           1.64274e-31        0           1                  0                2.35216e-06  0.493605                    0.500664            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:17:11  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:17:14  4:10:31.686  9854 obs/sec      1         1             25000      0.313419         0.454728            0.607072       0.938072        0.61085            1.99482          0.123776                         0.311156           0.443505              0.612663         0.939049          0.606372             1.99323            0.120447
    2019-08-03 20:17:19  4:10:36.749  10409 obs/sec     3         3             75000      0.255991         0.25785             0.737873       0.966447        0.719798           1.99482          0.0814186                        0.254818           0.25269               0.740228         0.967239          0.686321             2.02591            0.0783552
    2019-08-03 20:17:26  4:10:43.770  10826 obs/sec     6         6             150000     0.225196         0.196479            0.797145       0.979558        0.759151           1.99482          0.0556444                        0.22225            0.189242              0.802387         0.981086          0.740672             2.02591            0.0485673
    2019-08-03 20:17:33  4:10:50.848  10982 obs/sec     9         9             225000     0.208088         0.175809            0.826797       0.983776        0.724684           1.99482          0.0470529                        0.20654            0.168972              0.829336         0.984821          0.7563               2.02591            0.0417678
    2019-08-03 20:17:36  4:10:53.434  11042 obs/sec     10        10            250000     0.200911         0.163077            0.838538       0.985801        0.749629           1.99482          0.0412587                        0.196527           0.153957              0.845483         0.987439          0.758144             2.02591            0.0364254
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0034526667909966047
C25         0.9127142429351807     0.9127142429351807   0.003151298156251906
C28         0.8653331398963928     0.8653331398963928   0.0029877069952690947
C34         0.8570431470870972     0.8570431470870972   0.002959084412398839
C250        0.8476611971855164     0.8476611971855164   0.002926691665538857
---         ---                    ---                  ---
C347        0.17177239060401917    0.17177239060401917  0.0005930728286485942
C696        0.1708308309316635     0.1708308309316635   0.0005898219368361102
C662        0.17079226672649384    0.17079226672649384  0.0005896887874855996
C413        0.16712015867233276    0.16712015867233276  0.0005770102219540466
C901        0.1601831316947937     0.1601831316947937   0.00055305897928045

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_135

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,751 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight             weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ----------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.06164755017651733   0.10858848690986633     0.0         -0.0034062032672992374  0.1082049012184143  0.0040711669618501475  0.13605940341949463
    3        2        Softmax                 0.0   0.0   0.001730867638343625  1.8601611373014748e-05  0.0         -0.02842595939137027    0.3841787576675415  0.006735523508058852   0.23673135042190552


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04881325081983546
RMSE: 0.22093721012956477
LogLoss: 0.16816407072346934
Mean Per-Class Error: 0.06500242872241557
AUC: 0.9825132782907914
pr_auc: 0.9495726424910484
Gini: 0.9650265565815828
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47480878181634856: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4627  361   0.0724   (361.0/4988.0)
1      290   4742  0.0576   (290.0/5032.0)
Total  4917  5103  0.065    (651.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.474809     0.935767  215
max f2                       0.192985     0.952935  294
max f0point5                 0.817757     0.947341  112
max accuracy                 0.474809     0.93503   215
max precision                0.99957      1         0
max recall                   0.000278683  1         399
max specificity              0.99957      1         0
max absolute_mcc             0.474809     0.870137  215
max min_per_class_accuracy   0.528345     0.934643  201
max mean_per_class_accuracy  0.474809     0.934998  215
Gains/Lift Table: Avg response rate: 50.22 %, avg score: 50.23 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100798                   0.999533           1.99126     1.99126            1                0.999721     1                           0.999721            0.0200715       0.0200715                  99.1256   99.1256
    2        0.0200599                   0.999187           1.99126     1.99126            1                0.999348     1                           0.999536            0.0198728       0.0399444                  99.1256   99.1256
    3        0.0300399                   0.998926           1.99126     1.99126            1                0.999073     1                           0.999382            0.0198728       0.0598172                  99.1256   99.1256
    4        0.04002                     0.99855            1.99126     1.99126            1                0.998737     1                           0.999221            0.0198728       0.07969                    99.1256   99.1256
    5        0.05                        0.998228           1.99126     1.99126            1                0.99838      1                           0.999053            0.0198728       0.0995628                  99.1256   99.1256
    6        0.1                         0.996332           1.98728     1.98927            0.998004         0.997357     0.999002                    0.998205            0.0993641       0.198927                   98.7281   98.9269
    7        0.15                        0.993655           1.98331     1.98728            0.996008         0.995126     0.998004                    0.997179            0.0991653       0.298092                   98.3307   98.7281
    8        0.2                         0.989741           1.98728     1.98728            0.998004         0.991883     0.998004                    0.995855            0.0993641       0.397456                   98.7281   98.7281
    9        0.3                         0.97202            1.96542     1.97999            0.987026         0.9827       0.994345                    0.99147             0.196542        0.593998                   96.5421   97.9995
    10       0.4                         0.904418           1.88394     1.95598            0.946108         0.947642     0.982285                    0.980513            0.188394        0.782393                   88.3943   95.5982
    11       0.5                         0.539183           1.50636     1.86606            0.756487         0.772572     0.937126                    0.938925            0.150636        0.933029                   50.6359   86.6057
    12       0.6                         0.0943874          0.528617    1.64315            0.265469         0.26756      0.825183                    0.827031            0.0528617       0.98589                    -47.1383  64.3151
    13       0.7                         0.0196689          0.0993641   1.42261            0.0499002        0.0461398    0.714428                    0.715475            0.00993641      0.995827                   -90.0636  42.261
    14       0.8                         0.00547851         0.0258347   1.24801            0.0129741        0.0108377    0.626747                    0.627395            0.00258347      0.99841                    -97.4165  24.8013
    15       0.9                         0.001548           0.013911    1.11089            0.00698603       0.00313603   0.557884                    0.558033            0.0013911       0.999801                   -98.6089  11.089
    16       1                           1.22371e-05        0.00198728  1                  0.000998004      0.000736451  0.502196                    0.502303            0.000198728     1                          -99.8013  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.043916992954556776
RMSE: 0.20956381594768878
LogLoss: 0.15515663253035164
Mean Per-Class Error: 0.057215207870762175
AUC: 0.9846773270176209
pr_auc: 0.9568082380534544
Gini: 0.9693546540352418
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45451661937724663: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2926  202   0.0646   (202.0/3128.0)
1      152   2897  0.0499   (152.0/3049.0)
Total  3078  3099  0.0573   (354.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.454517     0.94242   213
max f2                       0.212631     0.95558   281
max f0point5                 0.819193     0.951144  115
max accuracy                 0.626028     0.942691  172
max precision                0.999649     1         0
max recall                   0.00133516   1         397
max specificity              0.999649     1         0
max absolute_mcc             0.626028     0.885762  172
max min_per_class_accuracy   0.518618     0.942276  199
max mean_per_class_accuracy  0.454517     0.942785  213
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.27 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999537           2.02591    2.02591            1                0.999737     1                           0.999737            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999259           2.02591    2.02591            1                0.999383     1                           0.99956             0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999001           2.02591    2.02591            1                0.999111     1                           0.99941             0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.998635           2.02591    2.02591            1                0.998826     1                           0.999264            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.998271           2.02591    2.02591            1                0.99846      1                           0.999106            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.996505           2.01935    2.02263            0.996764         0.997458     0.998382                    0.998282            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.993661           2.01935    2.02154            0.996764         0.995214     0.997843                    0.997259            0.101017        0.303378                   101.935   102.154
    8        0.200097                    0.989642           2.01935    2.02099            0.996764         0.991874     0.997573                    0.995913            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.97071            2.00293    2.01498            0.988655         0.98234      0.994603                    0.991394            0.200066        0.60446                    100.293   101.498
    10       0.400032                    0.897366           1.91445    1.98984            0.944984         0.944641     0.982193                    0.979701            0.191538        0.795999                   91.4452   98.9836
    11       0.500081                    0.466958           1.51779    1.8954             0.749191         0.740107     0.935578                    0.931766            0.151853        0.947852                   51.7794   89.5397
    12       0.599968                    0.0775426          0.410436   1.64817            0.202593         0.2164       0.813546                    0.812667            0.040997        0.988849                   -58.9564  64.817
    13       0.700016                    0.0168339          0.0753979  1.42338            0.0372168        0.0385727    0.70259                     0.702031            0.00754346      0.996392                   -92.4602  42.3385
    14       0.799903                    0.00500967         0.0197009  1.2481             0.00972447       0.00937439   0.61607                     0.615537            0.00196786      0.99836                    -98.0299  24.8102
    15       0.899951                    0.00143108         0.0163909  1.11117            0.00809061       0.00292846   0.54848                     0.547432            0.00163988      1                          -98.3609  11.1171
    16       1                           4.15652e-05        0          1                  0                0.000698813  0.493605                    0.492733            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:36:47  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:36:55  2:30:13.490  2016 obs/sec      0.62444   1             15611      0.309734         0.319573            0.616251       0.938814        0.908687           1.99126          0.13523                          0.304902           0.31191               0.628079         0.941825          0.902147             2.02591            0.127732
    2019-08-03 18:37:03  2:30:20.667  2192 obs/sec      1.2548    2             31370      0.295448         0.289046            0.650835       0.948779        0.929754           1.99126          0.116966                         0.287935           0.275056              0.66832          0.953845          0.928211             2.02591            0.113486
    2019-08-03 18:37:10  2:30:27.768  2257 obs/sec      1.87836   3             46959      0.290815         0.281267            0.6617         0.95197         0.929314           1.99126          0.114072                         0.282556           0.266769              0.680597         0.956625          0.944234             2.02591            0.105877
    2019-08-03 18:37:17  2:30:34.916  2286 obs/sec      2.50236   4             62559      0.286089         0.272775            0.672605       0.954821        0.940907           1.99126          0.109182                         0.27578            0.256234              0.695732         0.95974           0.939034             2.02591            0.10021
    2019-08-03 18:37:24  2:30:41.999  2313 obs/sec      3.1302    5             78255      0.284771         0.271654            0.675615       0.955784        0.940882           1.99126          0.109581                         0.274318           0.252935              0.698949         0.961306          0.94609              2.02591            0.102477
    2019-08-03 18:37:31  2:30:49.221  2328 obs/sec      3.76236   6             94059      0.282002         0.266355            0.681894       0.9564          0.9457             1.99126          0.107984                         0.27157            0.24876               0.70495          0.962011          0.950831             2.02591            0.10102
    2019-08-03 18:37:38  2:30:56.370  2343 obs/sec      4.39444   7             109861     0.277075         0.25879             0.692911       0.959392        0.940913           1.99126          0.104391                         0.265848           0.241014              0.717253         0.964357          0.939396             1.99323            0.096487
    2019-08-03 18:37:45  2:31:03.532  2351 obs/sec      5.02132   8             125533     0.274142         0.253987            0.699378       0.960973        0.945088           1.99126          0.0996008                        0.268638           0.244143              0.711288         0.964158          0.948577             2.02591            0.0937348
    2019-08-03 18:37:53  2:31:10.598  2361 obs/sec      5.64916   9             141229     0.271619         0.251873            0.704887       0.962581        0.941001           1.99126          0.0961078                        0.264152           0.238881              0.720849         0.965935          0.949052             2.02591            0.0914684
    2019-08-03 18:37:59  2:31:17.465  2375 obs/sec      6.27456   10            156864     0.261495         0.232771            0.726477       0.966805        0.953891           1.99126          0.0898204                        0.25167            0.219219              0.746608         0.970068          0.956161             2.02591            0.081593
    2019-08-03 18:38:07  2:31:24.678  2378 obs/sec      6.90576   11            172644     0.261091         0.233532            0.72732        0.966799        0.945575           1.99126          0.0887226                        0.252691           0.22063               0.744546         0.969943          0.958304             2.02591            0.0825644
    2019-08-03 18:38:14  2:31:31.647  2385 obs/sec      7.5298    12            188245     0.248105         0.209876            0.753771       0.973142        0.94001            1.97154          0.0809381                        0.236924           0.192732              0.775432         0.977086          0.95853              1.99323            0.072689
    2019-08-03 18:38:21  2:31:38.820  2386 obs/sec      8.15356   13            203839     0.243698         0.202161            0.76244        0.974907        0.956858           1.99126          0.0792415                        0.231271           0.185884              0.78602          0.978406          0.964137             2.02591            0.0691274
    2019-08-03 18:38:28  2:31:45.948  2389 obs/sec      8.78252   14            219563     0.237035         0.192994            0.775254       0.976978        0.959085           1.99126          0.0753493                        0.22533            0.176936              0.796872         0.98063           0.956283             2.02591            0.0671847
    2019-08-03 18:38:35  2:31:52.818  2397 obs/sec      9.4078    15            235195     0.226392         0.1774              0.794983       0.980512        0.959292           1.99126          0.0691617                        0.215621           0.162155              0.814            0.983781          0.953327             2.02591            0.0600615
    2019-08-03 18:38:42  2:31:59.749  2402 obs/sec      10.03     16            250751     0.220937         0.168164            0.804743       0.982513        0.949573           1.99126          0.0649701                        0.209564           0.155157              0.824303         0.984677          0.956808             2.02591            0.0573094
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003931185213486501
C438        0.7356059551239014     0.7356059551239014   0.0028918032537356957
C88         0.6847609877586365     0.6847609877586365   0.0026919222698491624
C374        0.6822109818458557     0.6822109818458557   0.0026818977243105355
C322        0.6291855573654175     0.6291855573654175   0.0024734449596541916
---         ---                    ---                  ---
C936        0.16123634576797485    0.16123634576797485  0.0006338499383596595
C963        0.15955163538455963    0.15955163538455963  0.0006272270298113704
C982        0.1555180698633194     0.1555180698633194   0.0006113703366766418
C572        0.15452952682971954    0.15452952682971954  0.000607484190920059
C973        0.15178510546684265    0.15178510546684265  0.0005966953622387409

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_194

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  --------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.006213874033898849    0.012857221066951752   0.0         0.024380857077238      0.08851107954978943  0.013921888206785502  0.2183050513267517
    3        2        Softmax                      0.0   0.0   0.00023188805619156483  6.173978908918798e-05  0.0         -0.039045723740855465  0.4369826316833496   0.001464903347707892  0.030850060284137726


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.040169926605384744
RMSE: 0.20042436629657767
LogLoss: 0.15460582478682433
Mean Per-Class Error: 0.041264987710907475
AUC: 0.9871651956801668
pr_auc: 0.7695696501080577
Gini: 0.9743303913603336
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5158513049363801: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4774  218   0.0437   (218.0/4992.0)
1      195   4823  0.0389   (195.0/5018.0)
Total  4969  5041  0.0413   (413.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.515851     0.958942  201
max f2                       0.371416     0.96613   241
max f0point5                 0.593328     0.961759  177
max accuracy                 0.515851     0.958741  201
max precision                0.99996      0.999083  0
max recall                   3.89673e-05  1         399
max specificity              0.99996      0.9998    0
max absolute_mcc             0.515851     0.917491  201
max min_per_class_accuracy   0.524192     0.957933  199
max mean_per_class_accuracy  0.515851     0.958735  201
Gains/Lift Table: Avg response rate: 50.13 %, avg score: 50.32 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   1                  1.99482     1.99482            1                1            1                           1                   0.0201275       0.0201275                  99.4819   99.4819
    2        0.0200799                   1                  1.99482     1.99482            1                1            1                           1                   0.0199283       0.0400558                  99.4819   99.4819
    3        0.0300699                   1                  1.99482     1.99482            1                1            1                           1                   0.0199283       0.0599841                  99.4819   99.4819
    4        0.0400599                   1                  1.99482     1.99482            1                1            1                           1                   0.0199283       0.0799123                  99.4819   99.4819
    5        0.05005                     0.999998           1.99482     1.99482            1                0.999999     1                           1                   0.0199283       0.0998406                  99.4819   99.4819
    6        0.1                         0.999859           1.99083     1.99283            0.998            0.999959     0.999001                    0.999979            0.099442        0.199283                   99.0829   99.2826
    7        0.15005                     0.998695           1.98686     1.99083            0.996008         0.999434     0.998003                    0.999797            0.099442        0.298725                   98.6855   99.0834
    8        0.2                         0.993789           1.97088     1.98585            0.988            0.996636     0.995504                    0.999008            0.0984456       0.39717                    97.0881   98.5851
    9        0.3                         0.958168           1.94898     1.97356            0.977023         0.980451     0.989344                    0.992822            0.194898        0.592069                   94.8984   97.3562
    10       0.4                         0.845944           1.94301     1.96592            0.974026         0.912417     0.985514                    0.972721            0.194301        0.786369                   94.3005   96.5923
    11       0.5                         0.527522           1.70187     1.91311            0.853147         0.708683     0.959041                    0.919913            0.170187        0.956556                   70.1873   91.3113
    12       0.6                         0.170449           0.344759    1.65172            0.172827         0.325228     0.828005                    0.820799            0.0344759       0.991032                   -65.5241  65.172
    13       0.7                         0.0350477          0.0478278   1.42259            0.023976         0.092973     0.713144                    0.716824            0.00478278      0.995815                   -95.2172  42.2593
    14       0.8                         0.00231337         0.0278996   1.24826            0.013986         0.0135186    0.625749                    0.628911            0.00278996      0.998605                   -97.21    24.8256
    15       0.9                         1.64429e-05        0.00996413  1.11067            0.004995         0.000600993  0.556777                    0.559099            0.000996413     0.999601                   -99.0036  11.0668
    16       1                           3.57011e-27        0.00398565  1                  0.001998         1.89612e-06  0.501299                    0.503189            0.000398565     1                          -99.6014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.039295611278125094
RMSE: 0.19823120662026222
LogLoss: 0.1579605374688284
Mean Per-Class Error: 0.03834335436799963
AUC: 0.987099875100553
pr_auc: 0.7702995390197294
Gini: 0.9741997502011059
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5286127651962715: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3002  126   0.0403   (126.0/3128.0)
1      111   2938  0.0364   (111.0/3049.0)
Total  3113  3064  0.0384   (237.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.528613     0.96123   197
max f2                       0.428601     0.967291  225
max f0point5                 0.638916     0.964531  167
max accuracy                 0.528613     0.961632  197
max precision                0.999694     0.997487  1
max recall                   3.4514e-05   1         399
max specificity              0.999973     0.999361  0
max absolute_mcc             0.528613     0.923267  197
max min_per_class_accuracy   0.534814     0.960678  195
max mean_per_class_accuracy  0.528613     0.961657  197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.93 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323     2.00957            0.983871         1            0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   1                  2.02591     2.01502            1                1            0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999998           2.02591     2.01935            1                0.999999     0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999887           2.01935     2.01935            0.996764         0.999967     0.996764                    0.999983            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998862           2.01935     2.01935            0.996764         0.999499     0.996764                    0.999822            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.994693           2.0128      2.01771            0.993528         0.997282     0.995955                    0.999187            0.100689        0.403739                   101.28    101.771
    9        0.299984                    0.957691           1.97666     2.00404            0.975689         0.980512     0.989207                    0.992969            0.197442        0.601181                   97.6658   100.404
    10       0.400032                    0.836975           1.97346     1.99639            0.97411          0.906384     0.985431                    0.971314            0.197442        0.798622                   97.3459   99.6395
    11       0.500081                    0.512531           1.6817      1.93344            0.830097         0.698995     0.954354                    0.916832            0.168252        0.966874                   68.1702   93.3436
    12       0.599968                    0.161511           0.213427    1.64708            0.105348         0.305669     0.813006                    0.815082            0.0213185       0.988193                   -78.6573  64.7077
    13       0.700016                    0.0344187          0.0622853   1.42057            0.0307443        0.0892028    0.701203                    0.711337            0.00623155      0.994424                   -93.7715  42.0573
    14       0.799903                    0.00267082         0.0394018   1.2481             0.0194489        0.0132174    0.61607                     0.62416             0.00393572      0.99836                    -96.0598  24.8102
    15       0.899951                    1.60456e-05        0.0131127   1.11081            0.00647249       0.000629413  0.5483                      0.554842            0.00131191      0.999672                   -98.6887  11.0807
    16       1                           1.97075e-31        0.00327817  1                  0.00161812       2.01665e-06  0.493605                    0.499331            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:06:14  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:06:17  3:59:34.887  9735 obs/sec      1         1             25000      0.314583         0.409125            0.604147       0.936379        0.652866           1.99482          0.127073                         0.302808           0.385242              0.633169         0.943184          0.657475             2.02591            0.11818
    2019-08-03 20:06:22  3:59:40.141  10198 obs/sec     3         3             75000      0.263769         0.25497             0.721701       0.963885        0.764974           1.99482          0.0844156                        0.254475           0.242571              0.740928         0.967792          0.774353             2.02591            0.0760887
    2019-08-03 20:06:29  3:59:47.124  10752 obs/sec     6         6             150000     0.229595         0.193399            0.789143       0.97973         0.812065           1.99482          0.058042                         0.225157           0.191344              0.797184         0.98085           0.822085             2.02591            0.0531002
    2019-08-03 20:06:36  3:59:54.012  11036 obs/sec     9         9             225000     0.207972         0.164566            0.826989       0.985586        0.757808           1.99482          0.0435564                        0.203179           0.164367              0.834846         0.986404          0.788521             2.02591            0.0393395
    2019-08-03 20:06:39  3:59:56.466  11165 obs/sec     10        10            250000     0.200424         0.154606            0.839319       0.987165        0.76957            1.99482          0.0412587                        0.198231           0.157961              0.842792         0.9871            0.7703               2.02591            0.0383681
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0038900598526967296
C35         0.8558031916618347     0.8558031916618347   0.003329125637693428
C34         0.8407512903213501     0.8407512903213501   0.0032705728405820565
C40         0.809638500213623      0.809638500213623    0.0031495422248786075
C28         0.7945256233215332     0.7945256233215332   0.003090752229221941
---         ---                    ---                  ---
C649        0.1650177389383316     0.1650177389383316   0.0006419288812267936
C389        0.16003888845443726    0.16003888845443726  0.0006225608548468166
C476        0.15931455790996552    0.15931455790996552  0.000619743165675685
C740        0.1581781953573227     0.1581781953573227   0.0006153226473315412
C446        0.1560581773519516     0.1560581773519516   0.0006070756504018529

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_176

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight          weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  -------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.004460047672829409    0.004119573161005974   0.0         0.02535043069291916  0.09291940927505493  -0.010581409581690786   0.22944390773773193
    3        2        Softmax                      0.0   0.0   0.00023482978326683224  5.758041515946388e-05  0.0         0.13461250366162858  0.5051620006561279   -0.0005436464115671953  0.05676713585853577


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.041803468992910986
RMSE: 0.2044589665260758
LogLoss: 0.16679277341778034
Mean Per-Class Error: 0.04195181925044855
AUC: 0.9858028926256248
pr_auc: 0.7764691024158045
Gini: 0.9716057852512496
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5345263620306524: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4831  200   0.0398   (200.0/5031.0)
1      220   4763  0.0442   (220.0/4983.0)
Total  5051  4963  0.0419   (420.0/10014.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.534526     0.957772  195
max f2                       0.396513     0.963246  236
max f0point5                 0.600042     0.963642  177
max accuracy                 0.534526     0.958059  195
max precision                0.999963     0.996165  0
max recall                   2.89222e-05  1         399
max specificity              0.999963     0.999205  0
max absolute_mcc             0.534526     0.916121  195
max min_per_class_accuracy   0.52506      0.957656  197
max mean_per_class_accuracy  0.534526     0.958048  195
Gains/Lift Table: Avg response rate: 49.76 %, avg score: 49.95 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100859                   1                  2.00963     2.00963            1                1            1                           1                   0.0202689       0.0202689                  100.963   100.963
    2        0.0200719                   1                  2.00963     2.00963            1                1            1                           1                   0.0200682       0.0403371                  100.963   100.963
    3        0.0300579                   1                  1.98954     2.00296            0.99             1            0.996678                    1                   0.0198675       0.0602047                  98.9536   100.296
    4        0.0400439                   0.999999           2.00963     2.00462            1                1            0.997506                    1                   0.0200682       0.0802729                  100.963   100.462
    5        0.05003                     0.999996           1.96944     1.9976             0.98             0.999998     0.994012                    0.999999            0.0196669       0.0999398                  96.944    99.7599
    6        0.10006                     0.999815           2.00562     2.00161            0.998004         0.999944     0.996008                    0.999972            0.100341        0.200281                   100.562   100.161
    7        0.14999                     0.998398           1.99356     1.99893            0.992            0.999292     0.994674                    0.999745            0.0995384       0.299819                   99.3556   99.8929
    8        0.20002                     0.992777           1.99359     1.99759            0.992016         0.99603      0.994009                    0.998816            0.0997391       0.399558                   99.3588   99.7593
    9        0.29998                     0.949801           1.96747     1.98756            0.979021         0.975867     0.989015                    0.991169            0.196669        0.596227                   96.7473   98.7556
    10       0.40004                     0.825994           1.95147     1.97853            0.971058         0.896776     0.984523                    0.967559            0.195264        0.791491                   95.147    97.853
    11       0.5                         0.513046           1.68841     1.92053            0.84016          0.694114     0.955662                    0.912892            0.168774        0.960265                   68.8413   92.053
    12       0.59996                     0.177632           0.27906     1.64704            0.138861         0.32064      0.819574                    0.814216            0.0278948       0.98816                    -72.094   64.7043
    13       0.70002                     0.0368134          0.0701968   1.42165            0.0349301        0.0957459    0.707418                    0.711519            0.00702388      0.995184                   -92.9803  42.165
    14       0.79998                     0.00255754         0.0281068   1.24752            0.013986         0.0137524    0.620771                    0.624331            0.00280955      0.997993                   -97.1893  24.7523
    15       0.89994                     1.50427e-05        0.016061    1.11074            0.00799201       0.000613032  0.552708                    0.555052            0.00160546      0.999599                   -98.3939  11.0739
    16       1                           3.05733e-28        0.00401124  1                  0.00199601       1.86796e-06  0.497603                    0.499514            0.000401365     1                          -99.5989  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.039938869480882926
RMSE: 0.199847115267854
LogLoss: 0.15859705079146227
Mean Per-Class Error: 0.03834749601353504
AUC: 0.9874386512201812
pr_auc: 0.7737486329780261
Gini: 0.9748773024403623
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5203149348861607: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3003  125   0.04     (125.0/3128.0)
1      112   2937  0.0367   (112.0/3049.0)
Total  3115  3062  0.0384   (237.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.520315     0.961217  199
max f2                       0.422378     0.967134  226
max f0point5                 0.633218     0.966482  165
max accuracy                 0.520315     0.961632  199
max precision                0.999119     0.99773   2
max recall                   2.44076e-05  1         399
max specificity              0.999965     0.999361  0
max absolute_mcc             0.520315     0.923263  199
max min_per_class_accuracy   0.525618     0.960997  197
max mean_per_class_accuracy  0.520315     0.961653  199
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.64 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999997           1.95949     2.0128             0.967213         0.999998     0.993528                    1                   0.0193506       0.100689                   95.9487   101.28
    6        0.100049                    0.999843           2.02591     2.01935            1                0.999953     0.996764                    0.999976            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.998547           2.01935     2.01935            0.996764         0.99935      0.996764                    0.999768            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.992944           2.00624     2.01608            0.990291         0.996265     0.995146                    0.998892            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.949815           1.97337     2.00186            0.974068         0.976107     0.988127                    0.991305            0.197114        0.600525                   97.3374   100.186
    10       0.400032                    0.820741           1.98329     1.99721            0.978964         0.89517      0.985836                    0.967262            0.198426        0.79895                    98.3294   99.7215
    11       0.500081                    0.494201           1.66531     1.93081            0.822006         0.6775       0.953059                    0.90929             0.166612        0.965562                   66.5311   93.0812
    12       0.599968                    0.172707           0.22656     1.64708            0.111831         0.307697     0.813006                    0.809133            0.0226304       0.988193                   -77.344   64.7077
    13       0.700016                    0.0379939          0.0753979   1.42245            0.0372168        0.0943925    0.702128                    0.70698             0.00754346      0.995736                   -92.4602  42.2448
    14       0.799903                    0.00271428         0.0262679   1.2481             0.012966         0.0146041    0.61607                     0.620521            0.00262381      0.99836                    -97.3732  24.8102
    15       0.899951                    2.10691e-05        0.00983452  1.11044            0.00485437       0.00065561   0.54812                     0.55161             0.000983929     0.999344                   -99.0165  11.0442
    16       1                           9.97444e-31        0.00655634  1                  0.00323625       2.48085e-06  0.493605                    0.496422            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:43:15  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:43:18  3:36:36.031  9968 obs/sec      1         1             25000      0.305633         0.387212            0.626346       0.941288        0.696956           1.98974          0.119433                         0.299832           0.359563              0.640345         0.945568          0.679382             1.99323            0.112676
    2019-08-03 19:43:23  3:36:41.082  10461 obs/sec     3         3             75000      0.26085          0.255382            0.727823       0.965605        0.771967           2.00963          0.0839824                        0.253737           0.235448              0.742427         0.969895          0.773469             2.02591            0.0775457
    2019-08-03 19:43:30  3:36:48.116  10901 obs/sec     6         6             150000     0.229312         0.200656            0.789659       0.978615        0.8175             2.00963          0.0574196                        0.224031           0.189474              0.799208         0.981179          0.797615             2.02591            0.0526145
    2019-08-03 19:43:37  3:36:55.013  11127 obs/sec     9         9             225000     0.209518         0.174084            0.824405       0.984236        0.766626           2.00963          0.0451368                        0.205705           0.164796              0.830714         0.986011          0.792068             2.02591            0.0417678
    2019-08-03 19:43:40  3:36:57.580  11161 obs/sec     10        10            250000     0.204459         0.166793            0.832782       0.985803        0.776469           2.00963          0.0419413                        0.199847           0.158597              0.840218         0.987439          0.773749             2.02591            0.0383681
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.004067647319646794
C25         0.892700731754303      0.892700731754303    0.0036311917387671223
C40         0.7931610345840454     0.7931610345840454   0.0032262993563740706
C28         0.7432695031166077     0.7432695031166077   0.0030233582021274735
C250        0.7373576760292053     0.7373576760292053   0.0029993109745211862
---         ---                    ---                  ---
C437        0.14967750012874603    0.14967750012874603  0.0006088352822101265
C890        0.1463082879781723     0.1463082879781723   0.0005951305154365238
C353        0.1452101767063141     0.1452101767063141   0.0005906637860648758
C773        0.14513030648231506    0.14513030648231506  0.0005903389021623066
C721        0.13749000430107117    0.13749000430107117  0.0005592608474734783

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_189

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.005568882230470396    0.005760384723544121    0.0         0.024878099990500568   0.08832991123199463  0.0359295382223067     0.19555574655532837
    3        2        Softmax                      0.0   0.0   0.00028093056698708097  4.7234323574230075e-05  0.0         -0.017238250184163917  0.5296096801757812   0.0005427139533170228  0.07357168197631836


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.041115145158670784
RMSE: 0.2027686986659203
LogLoss: 0.16722447637015503
Mean Per-Class Error: 0.04195096855151115
AUC: 0.9852699507562181
pr_auc: 0.7570217561223959
Gini: 0.9705399015124363
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5173136836789812: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4797  218   0.0435   (218.0/5015.0)
1      202   4794  0.0404   (202.0/4996.0)
Total  4999  5012  0.042    (420.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.517314     0.958034  199
max f2                       0.415013     0.966578  227
max f0point5                 0.592588     0.962187  177
max accuracy                 0.523804     0.958046  197
max precision                0.999971     0.996491  0
max recall                   3.07317e-05  1         399
max specificity              0.999971     0.999202  0
max absolute_mcc             0.517314     0.916097  199
max min_per_class_accuracy   0.523804     0.957727  197
max mean_per_class_accuracy  0.517314     0.958049  199
Gains/Lift Table: Avg response rate: 49.91 %, avg score: 50.07 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   1                  2.0038     2.0038             1                1            1                           1                   0.0202162       0.0202162                  100.38    100.38
    2        0.0200779                   1                  1.98377    1.99383            0.99             1            0.995025                    1                   0.0198159       0.040032                   98.3765   99.3834
    3        0.0300669                   1                  2.0038     1.99715            1                1            0.996678                    1                   0.020016        0.060048                   100.38    99.7146
    4        0.0400559                   1                  2.0038     1.99881            1                1            0.997506                    1                   0.020016        0.0800641                  100.38    99.8806
    5        0.050045                    0.999999           1.98377    1.9958             0.99             0.999999     0.996008                    1                   0.0198159       0.0998799                  98.3765   99.5804
    6        0.10009                     0.999925           1.9958     1.9958             0.996008         0.99998      0.996008                    0.99999             0.0998799       0.19976                    99.5804   99.5804
    7        0.150035                    0.999128           1.98777    1.99313            0.992            0.999632     0.994674                    0.999871            0.0992794       0.299039                   98.7773   99.313
    8        0.20008                     0.99534            1.97181    1.9878             0.984032         0.997548     0.992012                    0.99929             0.0986789       0.397718                   97.1806   98.7797
    9        0.30007                     0.961881           1.96577    1.98046            0.981019         0.982659     0.988349                    0.993748            0.196557        0.594275                   96.5769   98.0456
    10       0.40006                     0.833342           1.92974    1.96778            0.963037         0.911032     0.982022                    0.973074            0.192954        0.78723                    92.9736   96.778
    11       0.50005                     0.518897           1.71354    1.91694            0.855145         0.695689     0.956652                    0.917608            0.171337        0.958567                   71.3542   91.6942
    12       0.60004                     0.163828           0.308277   1.64888            0.153846         0.314173     0.822873                    0.817052            0.0308247       0.989392                   -69.1723  64.8876
    13       0.70003                     0.0352044          0.0460414  1.41993            0.022977         0.0891048    0.708619                    0.713075            0.00460368      0.993995                   -95.3959  41.9932
    14       0.80002                     0.00244887         0.0380342  1.24722            0.018981         0.0143877    0.622425                    0.62575             0.00380304      0.997798                   -96.1966  24.7217
    15       0.90001                     1.66684e-05        0.0160144  1.11043            0.00799201       0.000626811  0.554162                    0.556299            0.00160128      0.9994                     -98.3986  11.0432
    16       1                           5.90189e-28        0.0060054  1                  0.002997         2.11582e-06  0.499051                    0.500675            0.00060048      1                          -99.3995  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.04078212870251993
RMSE: 0.20194585586864597
LogLoss: 0.16017317696056668
Mean Per-Class Error: 0.03968257380097784
AUC: 0.9864024010220113
pr_auc: 0.7711063802281786
Gini: 0.9728048020440225
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48607320753025285: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2969  159   0.0508   (159.0/3128.0)
1      87    2962  0.0285   (87.0/3049.0)
Total  3056  3121  0.0398   (246.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.486073     0.96013   206
max f2                       0.440588     0.968697  217
max f0point5                 0.602655     0.961786  172
max accuracy                 0.486073     0.960175  206
max precision                0.999979     0.996942  0
max recall                   2.27377e-05  1         399
max specificity              0.999979     0.999361  0
max absolute_mcc             0.486073     0.920611  206
max min_per_class_accuracy   0.537071     0.959399  192
max mean_per_class_accuracy  0.486073     0.960317  206
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.73 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999999           1.9927      2.0128             0.983607         0.999999     0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999908           2.02591     2.01935            1                0.999975     0.996764                    0.999987            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.998926           2.00624     2.01498            0.990291         0.999563     0.994606                    0.999846            0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.994674           2.00624     2.0128             0.990291         0.9972       0.993528                    0.999184            0.100361        0.402755                   100.624   101.28
    9        0.299984                    0.957291           1.98322     2.00295            0.97893          0.980624     0.988667                    0.993004            0.198098        0.600853                   98.3225   100.295
    10       0.400032                    0.825777           1.94068     1.98738            0.957929         0.903256     0.980979                    0.970558            0.194162        0.795015                   94.0678   98.7376
    11       0.500081                    0.50675            1.70465     1.93081            0.841424         0.683359     0.953059                    0.9131              0.170548        0.965562                   70.4649   93.0812
    12       0.599968                    0.160024           0.239694    1.64926            0.118314         0.303619     0.814085                    0.811629            0.0239423       0.989505                   -76.0306  64.9264
    13       0.700016                    0.0348163          0.0622853   1.42245            0.0307443        0.088996     0.702128                    0.708348            0.00623155      0.995736                   -93.7715  42.2448
    14       0.799903                    0.00235022         0.0328348   1.24892            0.0162075        0.0139524    0.616474                    0.621637            0.00327976      0.999016                   -96.7165  24.8922
    15       0.899951                    2.37613e-05        0.00983452  1.11117            0.00485437       0.000631686  0.54848                     0.552599            0.000983929     1                          -99.0165  11.1171
    16       1                           1.22298e-32        0           1                  0                2.84239e-06  0.493605                    0.497312            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:59:57  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:00:00  3:53:17.394  9671 obs/sec      1         1             25000      0.308535         0.406198            0.619224       0.939841        0.645324           2.0038           0.120368                         0.299971           0.385614              0.64001          0.943927          0.689368             2.02591            0.112838
    2019-08-03 20:00:05  3:53:22.542  10206 obs/sec     3         3             75000      0.257649         0.249863            0.734467       0.966573        0.779536           2.0038           0.0826091                        0.250612           0.235197              0.748734         0.969996          0.780828             2.02591            0.0773838
    2019-08-03 20:00:12  3:53:29.362  10875 obs/sec     6         6             150000     0.228479         0.200062            0.791189       0.978796        0.800586           2.0038           0.0584357                        0.226783           0.192211              0.794244         0.980051          0.787011             2.02591            0.0552048
    2019-08-03 20:00:18  3:53:36.101  11161 obs/sec     9         9             225000     0.205735         0.170001            0.830691       0.984411        0.752535           2.0038           0.042753                         0.202932           0.161688              0.835248         0.986125          0.790903             2.02591            0.0373968
    2019-08-03 20:00:21  3:53:38.519  11264 obs/sec     10        10            250000     0.202769         0.167224            0.835539       0.98527         0.757022           2.0038           0.0419539                        0.201946           0.160173              0.836845         0.986402          0.771106             2.02591            0.0398252
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.00339610120854082
C40         0.9975298643112183     0.9975298643112183   0.0033877123777428884
C36         0.9539526700973511     0.9539526700973511   0.003239719815808356
C35         0.9468833804130554     0.9468833804130554   0.0032157117925679943
C25         0.8985421061515808     0.8985421061515808   0.003051539932626197
---         ---                    ---                  ---
C497        0.17581017315387726    0.17581017315387726  0.0005970691415216533
C462        0.1734158992767334     0.1734158992767334   0.0005889379451139074
C726        0.1733189970254898     0.1733189970254898   0.0005886088552613486
C538        0.17310835421085358    0.17310835421085358  0.0005878934909439921
C631        0.1717529147863388     0.1717529147863388   0.0005832902814762936

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_58

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.004855813772198825   0.004717744886875153    0.0         0.02450487436358584   0.08830055594444275  0.03224806831899445     0.22298604249954224
    3        2        Softmax                      0.0   0.0   0.0002656921708421578  4.3888576328754425e-05  0.0         -0.08544095559136622  0.48848509788513184  -0.0051067729918112745  0.08726394176483154


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.041378660285631426
RMSE: 0.20341745324733426
LogLoss: 0.16606509784896112
Mean Per-Class Error: 0.04136214823497175
AUC: 0.9855537742094639
pr_auc: 0.7782130470846278
Gini: 0.9711075484189278
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5424861406177753: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4864  217   0.0427   (217.0/5081.0)
1      198   4750  0.04     (198.0/4948.0)
Total  5062  4967  0.0414   (415.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.542486     0.958144  193
max f2                       0.404928     0.966492  230
max f0point5                 0.644914     0.961263  162
max accuracy                 0.542486     0.95862   193
max precision                0.99997      0.99707   0
max recall                   2.4499e-05   1         399
max specificity              0.99997      0.99941   0
max absolute_mcc             0.542486     0.917236  193
max min_per_class_accuracy   0.546863     0.957559  192
max mean_per_class_accuracy  0.542486     0.958638  193
Gains/Lift Table: Avg response rate: 49.34 %, avg score: 50.09 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   1                  2.02688     2.02688            1                1            1                           1                   0.0204123       0.0204123                  102.688   102.688
    2        0.0200419                   1                  2.02688     2.02688            1                1            1                           1                   0.0202102       0.0406225                  102.688   102.688
    3        0.030013                    1                  2.02688     2.02688            1                1            1                           1                   0.0202102       0.0608327                  102.688   102.688
    4        0.0400838                   0.999999           2.02688     2.02688            1                1            1                           1                   0.0204123       0.0812449                  102.688   102.688
    5        0.0500548                   0.999998           2.02688     2.02688            1                0.999999     1                           1                   0.0202102       0.101455                   102.688   102.688
    6        0.10001                     0.999827           2.01474     2.02082            0.994012         0.999954     0.997009                    0.999977            0.100647        0.202102                   101.474   102.082
    7        0.150065                    0.998488           2.00669     2.01611            0.99004          0.999371     0.994684                    0.999775            0.100445        0.302546                   100.669   101.611
    8        0.20002                     0.993251           1.99856     2.01172            0.986028         0.996463     0.992522                    0.998948            0.0998383       0.402385                   99.856    101.172
    9        0.30003                     0.954041           1.98242     2.00196            0.978066         0.977981     0.987704                    0.991959            0.198262        0.600647                   98.2422   100.196
    10       0.40004                     0.832345           1.96828     1.99354            0.971087         0.904632     0.983549                    0.970127            0.196847        0.797494                   96.8276   99.3536
    11       0.50005                     0.516883           1.66515     1.92786            0.821535         0.69625      0.951147                    0.915352            0.166532        0.964026                   66.5153   92.786
    12       0.59996                     0.179224           0.246786    1.64791            0.121756         0.316123     0.81303                     0.815563            0.0246564       0.988682                   -75.3214  64.7913
    13       0.69997                     0.0416888          0.0565829   1.42055            0.0279163        0.0983439    0.700855                    0.713089            0.00565885      0.994341                   -94.3417  42.0548
    14       0.79998                     0.00304204         0.0303123   1.24675            0.0149551        0.0166509    0.615107                    0.626023            0.00303153      0.997373                   -96.9688  24.6747
    15       0.89999                     2.50934e-05        0.022229    1.11067            0.0109671        0.00078785   0.547973                    0.556545            0.00222312      0.999596                   -97.7771  11.0674
    16       1                           1.47886e-32        0.00404163  1                  0.00199402       3.40272e-06  0.493369                    0.500885            0.000404204     1                          -99.5958  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.03954308315465431
RMSE: 0.19885442704313702
LogLoss: 0.1603128235444592
Mean Per-Class Error: 0.03709771515376725
AUC: 0.9869583251898447
pr_auc: 0.7771932155585068
Gini: 0.9739166503796894
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5362383950228051: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      3003  125   0.04     (125.0/3128.0)
1      105   2944  0.0344   (105.0/3049.0)
Total  3108  3069  0.0372   (230.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.536238     0.962406  191
max f2                       0.41934      0.9695    223
max f0point5                 0.620848     0.965936  168
max accuracy                 0.551764     0.962927  187
max precision                0.999657     0.994975  1
max recall                   2.21793e-05  1         399
max specificity              0.999969     0.998721  0
max absolute_mcc             0.551764     0.925843  187
max min_per_class_accuracy   0.542814     0.961957  189
max mean_per_class_accuracy  0.551764     0.962902  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.22 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   1                  2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999998           1.9927      2.0128             0.983607         0.999999     0.993528                    1                   0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999859           2.0128      2.0128             0.993528         0.99996      0.993528                    0.99998             0.100689        0.201378                   101.28    101.28
    7        0.150073                    0.998761           2.01935     2.01498            0.996764         0.999438     0.994606                    0.999799            0.101017        0.302394                   101.935   101.498
    8        0.200097                    0.994473           2.00624     2.0128             0.990291         0.997064     0.993528                    0.999115            0.100361        0.402755                   100.624   101.28
    9        0.299984                    0.958397           1.98322     2.00295            0.97893          0.980528     0.988667                    0.992926            0.198098        0.600853                   98.3225   100.295
    10       0.400032                    0.833339           1.96362     1.99312            0.969256         0.907811     0.983812                    0.971639            0.196458        0.797311                   96.3625   99.3115
    11       0.500081                    0.521144           1.71121     1.93671            0.84466          0.699356     0.955973                    0.917165            0.171204        0.968514                   71.1206   93.6715
    12       0.599968                    0.176367           0.20686     1.64872            0.102107         0.320066     0.813815                    0.817756            0.0206625       0.989177                   -79.314   64.8717
    13       0.700016                    0.0431776          0.0557289   1.42104            0.0275081        0.0974473    0.701434                    0.714807            0.0055756       0.994752                   -94.4271  42.1042
    14       0.799903                    0.00318221         0.0328348   1.24769            0.0162075        0.0178065    0.615867                    0.62777             0.00327976      0.998032                   -96.7165  24.7692
    15       0.899951                    3.64517e-05        0.0163909   1.11081            0.00809061       0.000874857  0.5483                      0.558077            0.00163988      0.999672                   -98.3609  11.0807
    16       1                           8.36468e-30        0.00327817  1                  0.00161812       4.46516e-06  0.493605                    0.502243            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:12:19  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:12:22  1:05:40.125  9541 obs/sec      1         1             25000      0.298004         0.363229            0.644712       0.94605         0.705089           2.02688          0.112474                         0.290917           0.340203              0.661413         0.950921          0.678363             2.02591            0.112676
    2019-08-03 17:12:30  1:05:47.374  10555 obs/sec     4         4             100000     0.243949         0.22474             0.761914       0.972058        0.789148           2.02688          0.0702961                        0.238578           0.21085               0.772286         0.975594          0.792651             2.02591            0.0673466
    2019-08-03 17:12:36  1:05:54.110  11052 obs/sec     7         7             175000     0.220257         0.188042            0.805914       0.980783        0.76549            2.02688          0.052747                         0.213775           0.175889              0.817172         0.983844          0.788053             2.02591            0.0480816
    2019-08-03 17:12:43  1:06:00.847  11267 obs/sec     10        10            250000     0.203417         0.166065            0.834456       0.985554        0.778213           2.02688          0.04138                          0.198854           0.160313              0.841802         0.986958          0.777193             2.02591            0.0372349
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003332332868901767
C28         0.9684658646583557     0.9684658646583557   0.0032272506332104087
C25         0.9076058864593506     0.9076058864593506   0.003024444927457219
C35         0.8968695998191833     0.8968695998191833   0.002988668046596239
C40         0.8648809194564819     0.8648809194564819   0.0028820711155908164
---         ---                    ---                  ---
C388        0.1770218014717102     0.1770218014717102   0.0005898955675563831
C443        0.17383769154548645    0.17383769154548645  0.0005792850533910313
C268        0.1736113280057907     0.1736113280057907   0.0005785307347273822
C414        0.1673872321844101     0.1673872321844101   0.0005577899756426015
C444        0.16522766649723053    0.16522766649723053  0.0005505935839206606

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_182

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.00742321907168194    0.00630900077521801    0.0         0.027073363515272574  0.09857243299484253  0.050459418289926554     0.2083759307861328
    3        2        Softmax                      0.0   0.0   0.0002670473144235075  5.262273771222681e-05  0.0         0.01869347608226235   0.5490889549255371   -0.00027832791504056945  0.06076766550540924


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04536003970223233
RMSE: 0.2129789653985396
LogLoss: 0.17681152641281042
Mean Per-Class Error: 0.04524235748277272
AUC: 0.9834149875683422
pr_auc: 0.7533041614744501
Gini: 0.9668299751366844
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5477700069387601: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4759  246   0.0492   (246.0/5005.0)
1      207   4801  0.0413   (207.0/5008.0)
Total  4966  5047  0.0452   (453.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.54777      0.954948  187
max f2                       0.489198     0.96221   205
max f0point5                 0.652065     0.957741  155
max accuracy                 0.54777      0.954759  187
max precision                0.999586     0.997744  1
max recall                   5.33797e-05  1         399
max specificity              0.999954     0.999401  0
max absolute_mcc             0.54777      0.909545  187
max min_per_class_accuracy   0.565599     0.953846  182
max mean_per_class_accuracy  0.54777      0.954758  187
Gains/Lift Table: Avg response rate: 50.01 %, avg score: 51.44 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   1                  1.9994      1.9994             1                1            1                           1                   0.0201677       0.0201677                  99.9401   99.9401
    2        0.0200739                   1                  1.9994      1.9994             1                1            1                           1                   0.0199681       0.0401358                  99.9401   99.9401
    3        0.0300609                   1                  1.9994      1.9994             1                1            1                           1                   0.0199681       0.0601038                  99.9401   99.9401
    4        0.0400479                   0.999999           1.9994      1.9994             1                1            1                           1                   0.0199681       0.0800719                  99.9401   99.9401
    5        0.050035                    0.999998           1.9994      1.9994             1                0.999999     1                           1                   0.0199681       0.10004                    99.9401   99.9401
    6        0.10007                     0.999881           1.98743     1.99341            0.994012         0.999962     0.997006                    0.999981            0.0994409       0.199481                   98.7428   99.3415
    7        0.150005                    0.998922           1.98341     1.99008            0.992            0.999529     0.99534                     0.999831            0.0990415       0.298522                   98.3406   99.0083
    8        0.20004                     0.995072           1.97546     1.98642            0.988024         0.997359     0.99351                     0.999212            0.0988419       0.397364                   97.5456   98.6424
    9        0.30001                     0.962902           1.95546     1.97611            0.978022         0.982977     0.988349                    0.993802            0.195487        0.592851                   95.5458   97.6106
    10       0.39998                     0.856411           1.91551     1.96096            0.958042         0.918666     0.980774                    0.975023            0.191494        0.784345                   91.551    96.0961
    11       0.50005                     0.56502            1.6941      1.90756            0.847305         0.734276     0.954064                    0.926845            0.169529        0.953874                   69.4103   90.7557
    12       0.60002                     0.20521            0.313592    1.64198            0.156843         0.36507      0.821238                    0.833247            0.0313498       0.985224                   -68.6408  64.1985
    13       0.69999                     0.0549682          0.0838909   1.41946            0.041958         0.120932     0.709944                    0.731517            0.00838658      0.99361                    -91.6109  41.9463
    14       0.79996                     0.00445856         0.0419455   1.24732            0.020979         0.0220723    0.623845                    0.642858            0.00419329      0.997804                   -95.8055  24.7317
    15       0.89993                     4.43672e-05        0.0159792   1.11053            0.00799201       0.00118326   0.555432                    0.571577            0.00159744      0.999401                   -98.4021  11.0532
    16       1                           5.88391e-31        0.00598623  1                  0.00299401       6.09445e-06  0.50015                     0.51438             0.000599042     1                          -99.4014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.04229451512426129
RMSE: 0.20565630339053867
LogLoss: 0.1636527981190032
Mean Per-Class Error: 0.04169599021607018
AUC: 0.986678528199678
pr_auc: 0.7684292272857893
Gini: 0.9733570563993561
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5308960367851717: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2980  148   0.0473   (148.0/3128.0)
1      110   2939  0.0361   (110.0/3049.0)
Total  3090  3087  0.0418   (258.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.530896     0.957953  190
max f2                       0.475307     0.967185  205
max f0point5                 0.631255     0.961317  160
max accuracy                 0.539187     0.958232  188
max precision                0.996718     0.998277  6
max recall                   2.19151e-05  1         399
max specificity              0.999969     0.999361  0
max absolute_mcc             0.530896     0.916533  190
max min_per_class_accuracy   0.551905     0.956841  184
max mean_per_class_accuracy  0.530896     0.958304  190
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.66 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999999           2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999997           2.02591     2.01935            1                0.999998     0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999871           2.01935     2.01935            0.996764         0.999959     0.996764                    0.999979            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998903           2.02591     2.02154            1                0.999524     0.997843                    0.999828            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.995134           2.01935     2.02099            0.996764         0.99734      0.997573                    0.999206            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.960716           1.97666     2.00623            0.975689         0.982405     0.990286                    0.993611            0.197442        0.601837                   97.6658   100.623
    10       0.400032                    0.838451           1.9669      1.99639            0.970874         0.90843      0.985431                    0.972308            0.196786        0.798622                   96.6903   99.6395
    11       0.500081                    0.528682           1.65548     1.92819            0.817152         0.699116     0.951764                    0.917652            0.165628        0.964251                   65.5477   92.8189
    12       0.599968                    0.199144           0.246261    1.64817            0.121556         0.342872     0.813546                    0.821958            0.0245982       0.988849                   -75.3739  64.817
    13       0.700016                    0.0496698          0.0557289   1.42057            0.0275081        0.113199     0.701203                    0.72066             0.0055756       0.994424                   -94.4271  42.0573
    14       0.799903                    0.00417533         0.0426853   1.24851            0.0210697        0.0206532    0.616272                    0.633248            0.00426369      0.998688                   -95.7315  24.8512
    15       0.899951                    4.44318e-05        0.00655634  1.11044            0.00323625       0.00111196   0.54812                     0.562973            0.000655953     0.999344                   -99.3444  11.0442
    16       1                           5.88391e-31        0.00655634  1                  0.00323625       5.74225e-06  0.493605                    0.506649            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:53:29  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:53:32  3:46:49.700  10146 obs/sec     1         1             25000      0.302529         0.340431            0.633905       0.943265        0.787598           1.9994           0.120943                         0.291518           0.306621              0.660013         0.950598          0.779816             2.02591            0.111219
    2019-08-03 19:53:37  3:46:54.831  10409 obs/sec     3         3             75000      0.264968         0.251959            0.719168       0.964413        0.844425           1.9994           0.0862878                        0.255275           0.229238              0.739296         0.970476          0.843493             2.02591            0.0765744
    2019-08-03 19:53:42  3:46:59.912  10547 obs/sec     5         5             125000     0.248264         0.224168            0.753461       0.971911        0.83899            1.9994           0.0736043                        0.237592           0.203627              0.774164         0.977893          0.846411             2.02591            0.0657277
    2019-08-03 19:53:49  3:47:06.912  10895 obs/sec     8         8             200000     0.225632         0.19514             0.796361       0.979366        0.792746           1.9994           0.0545291                        0.216065           0.177367              0.813233         0.983926          0.808892             2.02591            0.0461389
    2019-08-03 19:53:54  3:47:11.622  11051 obs/sec     10        10            250000     0.212979         0.176812            0.81856        0.983415        0.753304           1.9994           0.0452412                        0.205656           0.163653              0.830794         0.986679          0.768429             2.02591            0.0417678
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003981376905165452
C40         0.9569547772407532     0.9569547772407532   0.003809997649394085
C28         0.9540305733680725     0.9540305733680725   0.003798355291629399
C25         0.9088441133499146     0.9088441133499146   0.0036184509632869225
C43         0.8382977843284607     0.8382977843284607   0.0033375794381767026
---         ---                    ---                  ---
C843        0.15425467491149902    0.15425467491149902  0.0006141460002064469
C606        0.15418215095996857    0.15418215095996857  0.0006138572550207522
C349        0.15360289812088013    0.15360289812088013  0.000611551031144954
C396        0.14028269052505493    0.14028269052505493  0.0005585182642509261
C869        0.13943442702293396    0.13943442702293396  0.000555141007534087

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_177

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 251,892 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate            rate_rms                momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  -------------------  ----------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.06302391929216912  0.11572447419166565     0.0         -0.0024316111136763125  0.10874292254447937  0.0007868002380282144   0.14431393146514893
    3        2        Softmax                 0.0   0.0   0.00171975408511571  3.0288669222500175e-05  0.0         -0.026636097105495082   0.42124879360198975  -0.0009705156180971897  0.23050129413604736


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.04897597640989442
RMSE: 0.2213051658002913
LogLoss: 0.17129373648291707
Mean Per-Class Error: 0.0627812133508846
AUC: 0.981620833810921
pr_auc: 0.9546390655781402
Gini: 0.963241667621842
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4878013007597767: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4706  335   0.0665   (335.0/5041.0)
1      294   4680  0.0591   (294.0/4974.0)
Total  5000  5015  0.0628   (629.0/10015.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.487801     0.937031  206
max f2                       0.176992     0.951822  296
max f0point5                 0.774459     0.946046  127
max accuracy                 0.496964     0.937194  204
max precision                0.999239     1         0
max recall                   0.00102461   1         398
max specificity              0.999239     1         0
max absolute_mcc             0.487801     0.874419  206
max min_per_class_accuracy   0.515532     0.936124  199
max mean_per_class_accuracy  0.487801     0.937219  206
Gains/Lift Table: Avg response rate: 49.67 %, avg score: 49.58 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100849                   0.999076           2.01347     2.01347            1                0.999356    1                           0.999356            0.0203056       0.0203056                  101.347   101.347
    2        0.0200699                   0.998564           2.01347     2.01347            1                0.998796    1                           0.999077            0.0201045       0.0404101                  101.347   101.347
    3        0.0300549                   0.998062           2.01347     2.01347            1                0.998327    1                           0.998828            0.0201045       0.0605147                  101.347   101.347
    4        0.0400399                   0.99768            2.01347     2.01347            1                0.997878    1                           0.998591            0.0201045       0.0806192                  101.347   101.347
    5        0.050025                    0.997276           2.01347     2.01347            1                0.997488    1                           0.998371            0.0201045       0.100724                   101.347   101.347
    6        0.10005                     0.994715           2.01347     2.01347            1                0.996069    1                           0.99722             0.100724        0.201448                   101.347   101.347
    7        0.150075                    0.990952           2.00945     2.01213            0.998004         0.99298     0.999335                    0.995807            0.100523        0.30197                    100.945   101.213
    8        0.2                         0.986197           2.00542     2.01045            0.996            0.988725    0.998502                    0.994039            0.100121        0.402091                   100.542   101.045
    9        0.30005                     0.964454           1.98132     2.00074            0.984032         0.977339    0.993677                    0.98847             0.198231        0.600322                   98.1319   100.074
    10       0.4                         0.8856             1.8787      1.97025            0.933067         0.933612    0.978532                    0.974763            0.187776        0.788098                   87.8702   97.0245
    11       0.50005                     0.491821           1.51915     1.87999            0.754491         0.737867    0.933706                    0.927365            0.15199         0.940088                   51.9145   87.9989
    12       0.6                         0.0983821          0.466658    1.64455            0.231768         0.247862    0.816775                    0.814171            0.0466425       0.986731                   -53.3342  64.4552
    13       0.69995                     0.0244358          0.0824698   1.42149            0.040959         0.0519286   0.705991                    0.705326            0.00824286      0.994974                   -91.753   42.1493
    14       0.8                         0.00806912         0.0301418   1.24749            0.0149701        0.014657    0.619571                    0.618949            0.00301568      0.99799                    -96.9858  24.7487
    15       0.89995                     0.00278557         0.0140802   1.1105             0.00699301       0.00510124  0.551537                    0.550774            0.00140732      0.999397                   -98.592   11.0503
    16       1                           6.79527e-05        0.00602835  1                  0.00299401       0.00142659  0.496655                    0.495812            0.000603136     1                          -99.3972  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.047086508915195766
RMSE: 0.21699426009734857
LogLoss: 0.16485725624810457
Mean Per-Class Error: 0.05988457705725492
AUC: 0.9830682715141185
pr_auc: 0.9612005390335542
Gini: 0.9661365430282369
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4965812943730814: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2937  191   0.0611   (191.0/3128.0)
1      179   2870  0.0587   (179.0/3049.0)
Total  3116  3061  0.0599   (370.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.496581     0.939444  207
max f2                       0.235895     0.952136  276
max f0point5                 0.757596     0.949033  133
max accuracy                 0.496581     0.9401    207
max precision                0.999332     1         0
max recall                   0.00367908   1         393
max specificity              0.999332     1         0
max absolute_mcc             0.496581     0.880194  207
max min_per_class_accuracy   0.499831     0.939258  206
max mean_per_class_accuracy  0.496581     0.940115  207
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.12 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999106           2.02591     2.02591            1                0.9994      1                           0.9994              0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.998638           2.02591     2.02591            1                0.998884    1                           0.999142            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.998186           2.02591     2.02591            1                0.998416    1                           0.9989              0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.997706           2.02591     2.02591            1                0.997923    1                           0.998656            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.997303           2.02591     2.02591            1                0.997505    1                           0.998429            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.994732           2.02591     2.02591            1                0.996115    1                           0.997272            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.991166           2.01935     2.02372            0.996764         0.993079    0.998921                    0.995874            0.101017        0.303706                   101.935   102.372
    8        0.200097                    0.986169           2.0128      2.02099            0.993528         0.988843    0.997573                    0.994116            0.100689        0.404395                   101.28    102.099
    9        0.299984                    0.963672           1.99636     2.01279            0.985413         0.976548    0.993524                    0.988267            0.19941         0.603805                   99.6359   101.279
    10       0.400032                    0.879163           1.91773     1.98902            0.946602         0.930993    0.981789                    0.973943            0.191866        0.795671                   91.773    98.9016
    11       0.500081                    0.468469           1.48501     1.88818            0.73301          0.71427     0.932017                    0.921991            0.148573        0.944244                   48.5012   88.8182
    12       0.599968                    0.0914526          0.426853    1.64489            0.210697         0.232195    0.811927                    0.807149            0.0426369       0.986881                   -57.3147  64.489
    13       0.700016                    0.0237788          0.0852325   1.42198            0.0420712        0.0486336   0.701896                    0.69874             0.00852739      0.995408                   -91.4768  42.1979
    14       0.799903                    0.00771225         0.0394018   1.24933            0.0194489        0.0141518   0.616677                    0.613253            0.00393572      0.999344                   -96.0598  24.9332
    15       0.899951                    0.00261135         0.00655634  1.11117            0.00323625       0.00479752  0.54848                     0.54561             0.000655953     1                          -99.3444  11.1171
    16       1                           0.000114558        0           1                  0                0.00135727  0.493605                    0.491158            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:43:40  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:43:50  3:37:07.812  2493 obs/sec      0.9138    1             22845      0.30522          0.307309            0.627347       0.943092        0.920443           2.01347          0.127209                         0.301519           0.296869              0.636286         0.947046          0.918055             2.02591            0.123361
    2019-08-03 19:44:00  3:37:18.155  2422 obs/sec      1.82768   2             45692      0.29014          0.27936             0.663261       0.952172        0.941567           2.01347          0.113929                         0.283809           0.26677               0.677758         0.956497          0.941524             2.02591            0.106362
    2019-08-03 19:44:11  3:37:28.580  2395 obs/sec      2.74224   3             68556      0.279732         0.263153            0.686987       0.957868        0.946182           2.01347          0.102446                         0.273968           0.250639              0.699716         0.961855          0.948737             2.02591            0.0998867
    2019-08-03 19:44:21  3:37:39.124  2378 obs/sec      3.65736   4             91434      0.27612          0.257778            0.695017       0.959237        0.949858           2.01347          0.101448                         0.270347           0.245927              0.707601         0.963312          0.958275             2.02591            0.096487
    2019-08-03 19:44:31  3:37:49.434  2377 obs/sec      4.57408   5             114352     0.268842         0.246035            0.710882       0.962495        0.950302           1.99353          0.0964553                        0.266006           0.238847              0.716917         0.96495           0.952124             2.02591            0.0951918
    2019-08-03 19:44:42  3:37:59.780  2376 obs/sec      5.49104   6             137276     0.266637         0.242715            0.715606       0.963551        0.952821           2.01347          0.0917624                        0.260746           0.23174               0.728002         0.966736          0.95368              2.02591            0.0909827
    2019-08-03 19:44:52  3:38:10.183  2373 obs/sec      6.41004   7             160251     0.259679         0.231935            0.730256       0.966642        0.960996           2.01347          0.0880679                        0.254891           0.222197              0.740081         0.970005          0.963388             2.02591            0.0849927
    2019-08-03 19:45:03  3:38:20.648  2371 obs/sec      7.32956   8             183239     0.250559         0.215364            0.748869       0.97145         0.956836           2.01347          0.0815776                        0.244985           0.20473               0.759889         0.974296          0.964217             2.02591            0.0802979
    2019-08-03 19:45:13  3:38:30.706  2377 obs/sec      8.24428   9             206107     0.240749         0.200498            0.76815        0.9752          0.960959           2.01347          0.0757863                        0.236108           0.190707              0.776976         0.977609          0.957377             2.02591            0.0731747
    2019-08-03 19:45:23  3:38:40.861  2380 obs/sec      9.15836   10            228959     0.228019         0.179884            0.79202        0.98005         0.967132           2.01347          0.0670994                        0.222065           0.170367              0.802716         0.982056          0.959883             2.02591            0.0644326
    2019-08-03 19:45:33  3:38:51.025  2383 obs/sec      10.0757   11            251892     0.221305         0.171294            0.804087       0.981621        0.954639           2.01347          0.0628058                        0.216994           0.164857              0.811623         0.983068          0.961201             2.02591            0.0598996
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0038102731550025805
C438        0.7927788496017456     0.7927788496017456   0.0030207039684913596
C374        0.7830434441566467     0.7830434441566467   0.0029836094144708334
C88         0.6905055642127991     0.6905055642127991   0.0026310148146999387
C322        0.6894755363464355     0.6894755363464355   0.0026270901271718294
---         ---                    ---                  ---
C681        0.16937480866909027    0.16937480866909027  0.000645364286605533
C614        0.16485467553138733    0.16485467553138733  0.0006281413446539059
C708        0.16312532126903534    0.16312532126903534  0.0006215520325325768
C615        0.16268794238567352    0.16268794238567352  0.0006198854995147383
C988        0.1625233292579651     0.1625233292579651   0.0006192582785332698

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_133

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  --------------------
    1        980      Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.004583876285170511    0.0038887420669198036  0.0         0.030034026093277367  0.11128941178321838  0.07882424625514418    0.28839313983917236
    3        2        Softmax                      0.0   0.0   0.00020192127033169527  5.644952761940658e-05  0.0         -0.08598445700044977  0.8329970836639404   0.0024383506397591924  0.012086443603038788


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.043686901057726595
RMSE: 0.20901411688622037
LogLoss: 0.1719018835511247
Mean Per-Class Error: 0.0491655477518419
AUC: 0.9845943001331221
pr_auc: 0.7544707845891213
Gini: 0.9691886002662442
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4520551679378295: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4757  319   0.0628   (319.0/5076.0)
1      176   4768  0.0356   (176.0/4944.0)
Total  4933  5087  0.0494   (495.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.452055     0.950653  217
max f2                       0.401669     0.961277  232
max f0point5                 0.629363     0.957005  162
max accuracy                 0.525452     0.950898  195
max precision                0.999956     0.998241  0
max recall                   2.30214e-05  1         399
max specificity              0.999956     0.999606  0
max absolute_mcc             0.525452     0.9018    195
max min_per_class_accuracy   0.510414     0.949434  200
max mean_per_class_accuracy  0.525452     0.950834  195
Gains/Lift Table: Avg response rate: 49.34 %, avg score: 49.45 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100798                   1                  2.0267     2.0267             1                1           1                           1                   0.0204288       0.0204288                  102.67    102.67
    2        0.0200599                   1                  2.0267     2.0267             1                1           1                           1                   0.0202265       0.0406553                  102.67    102.67
    3        0.0300399                   1                  2.0267     2.0267             1                1           1                           1                   0.0202265       0.0608819                  102.67    102.67
    4        0.04002                     0.999999           2.00643    2.02164            0.99             1           0.997506                    1                   0.0200243       0.0809061                  100.643   102.164
    5        0.05                        0.999997           2.0267     2.02265            1                0.999999    0.998004                    1                   0.0202265       0.101133                   102.67    102.265
    6        0.1                         0.999862           2.02265    2.02265            0.998004         0.999959    0.998004                    0.999979            0.101133        0.202265                   102.265   102.265
    7        0.15                        0.998714           2.00243    2.01591            0.988024         0.999455    0.994677                    0.999804            0.100121        0.302387                   100.243   101.591
    8        0.2                         0.994012           2.00243    2.01254            0.988024         0.996866    0.993014                    0.99907             0.100121        0.402508                   100.243   101.254
    9        0.3                         0.952683           1.99434    2.00647            0.984032         0.978777    0.99002                     0.992306            0.199434        0.601942                   99.4337   100.647
    10       0.4                         0.814246           1.95186    1.99282            0.963074         0.895657    0.983283                    0.968143            0.195186        0.797128                   95.1861   99.282
    11       0.5                         0.489091           1.58576    1.91141            0.782435         0.670342    0.943114                    0.908583            0.158576        0.955704                   58.5761   91.1408
    12       0.6                         0.160374           0.329693   1.64779            0.162675         0.298768    0.813041                    0.806947            0.0329693       0.988673                   -67.0307  64.7789
    13       0.7                         0.0346717          0.0667476  1.42193            0.0329341        0.0874839   0.701597                    0.704167            0.00667476      0.995348                   -93.3252  42.1926
    14       0.8                         0.00332667         0.0182039  1.24646            0.00898204       0.0148706   0.61502                     0.618005            0.00182039      0.997168                   -98.1796  24.646
    15       0.9                         3.29748e-05        0.0182039  1.10999            0.00898204       0.00083603  0.547682                    0.54943             0.00182039      0.998989                   -98.1796  10.9987
    16       1                           7.84392e-30        0.0101133  1                  0.00499002       4.4465e-06  0.493413                    0.494488            0.00101133      1                          -98.9887  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.04244417801619217
RMSE: 0.20601984859763434
LogLoss: 0.16501325871528807
Mean Per-Class Error: 0.04563584849000857
AUC: 0.9852194631756335
pr_auc: 0.7661524202064645
Gini: 0.9704389263512669
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4997391057657838: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2981  147   0.047    (147.0/3128.0)
1      135   2914  0.0443   (135.0/3049.0)
Total  3116  3061  0.0457   (282.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.499739     0.953846  196
max f2                       0.361514     0.96292   237
max f0point5                 0.562127     0.95866   179
max accuracy                 0.503265     0.954347  195
max precision                0.999127     0.997691  2
max recall                   2.43217e-05  1         399
max specificity              0.999962     0.999361  0
max absolute_mcc             0.499739     0.90869   196
max min_per_class_accuracy   0.505963     0.954083  194
max mean_per_class_accuracy  0.499739     0.954364  196
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.60 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999999           1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999997           2.02591     2.01935            1                0.999998     0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999847           2.01935     2.01935            0.996764         0.999952     0.996764                    0.999976            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998555           2.01935     2.01935            0.996764         0.999343     0.996764                    0.999765            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.994              2.00624     2.01608            0.990291         0.996688     0.995146                    0.998996            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.953784           1.97666     2.00295            0.975689         0.979401     0.988667                    0.992471            0.197442        0.600853                   97.6658   100.295
    10       0.400032                    0.825393           1.95051     1.98984            0.962783         0.900512     0.982193                    0.969472            0.195146        0.795999                   95.0512   98.9836
    11       0.500081                    0.47939            1.63253     1.91835            0.805825         0.678925     0.946908                    0.911344            0.163332        0.959331                   63.253    91.8351
    12       0.599968                    0.160364           0.28238     1.64598            0.139384         0.292452     0.812466                    0.808306            0.028206        0.987537                   -71.762   64.5984
    13       0.700016                    0.0391234          0.0721198   1.42104            0.0355987        0.0931455    0.701434                    0.706093            0.00721548      0.994752                   -92.788   42.1042
    14       0.799903                    0.00350965         0.0328348   1.24769            0.0162075        0.0164398    0.615867                    0.619974            0.00327976      0.998032                   -96.7165  24.7692
    15       0.899951                    5.38944e-05        0.0131127   1.11044            0.00647249       0.000991376  0.54812                     0.551161            0.00131191      0.999344                   -98.6887  11.0442
    16       1                           7.84392e-30        0.00655634  1                  0.00323625       6.93652e-06  0.493605                    0.496019            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:35:37  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:35:39  2:28:56.848  16181 obs/sec     1         1             25000      0.297108         0.307343            0.646846       0.946992        0.808099           2.0267           0.117066                         0.293585           0.297035              0.655174         0.949761          0.822345             2.02591            0.113162
    2019-08-03 18:35:45  2:29:02.949  16976 obs/sec     5         5             125000     0.248896         0.224739            0.752159       0.972203        0.819507           2.0267           0.0739521                        0.245303           0.216012              0.759267         0.973952          0.841018             2.02591            0.0707463
    2019-08-03 18:35:51  2:29:08.726  17481 obs/sec     9         9             225000     0.21588          0.180504            0.813551       0.983045        0.758739           2.0267           0.0511976                        0.213358           0.176209              0.817884         0.98328           0.78729              2.02591            0.048891
    2019-08-03 18:35:53  2:29:10.340  17579 obs/sec     10        10            250000     0.209014         0.171902            0.825222       0.984594        0.754471           2.0267           0.0494012                        0.20602            0.165013              0.830196         0.985219          0.766152             2.02591            0.0456532
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C36         1.0                    1.0                  0.004643591082848324
C28         0.867988109588623      0.867988109588623    0.004030581845704104
C250        0.7617470026016235     0.7617470026016235   0.003537241588667339
C34         0.7191040515899658     0.7191040515899658   0.003339225161603267
C438        0.7015425562858582     0.7015425562858582   0.00325767675860763
---         ---                    ---                  ---
C814        0.10539975017309189    0.10539975017309189  0.0004894333400382106
C534        0.10525454580783844    0.10525454580783844  0.0004887590703425291
C379        0.10359867662191391    0.10359867662191391  0.0004810698909564066
C767        0.0996902659535408     0.0996902659535408   0.00046292083002864
C938        0.09879749268293381    0.09879749268293381  0.00045877515603024403

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_236

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate            rate_rms                momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  -------------------  ----------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0468241411117152   0.10239812731742859     0.0         0.0004141546341838482  0.123636394739151    0.008420350847524679   0.18149209022521973
    3        2        Softmax                 0.0   0.0   0.00169751561134035  0.00012380816042423248  0.0         -0.04353339005319867   0.49828600883483887  -0.004681276356577599  0.19890213012695312


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05688592536146339
RMSE: 0.2385077050358403
LogLoss: 0.1960402650804428
Mean Per-Class Error: 0.07489912212021765
AUC: 0.9762098561587345
pr_auc: 0.9665849501751886
Gini: 0.9524197123174689
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48074213421764656: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4609  429   0.0852   (429.0/5038.0)
1      325   4649  0.0653   (325.0/4974.0)
Total  4934  5078  0.0753   (754.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.480742     0.92499   205
max f2                       0.188797     0.94375   291
max f0point5                 0.800134     0.936803  117
max accuracy                 0.528098     0.92509   191
max precision                0.997512     1         0
max recall                   0.00418654   1         394
max specificity              0.997512     1         0
max absolute_mcc             0.524845     0.850186  192
max min_per_class_accuracy   0.531725     0.924375  190
max mean_per_class_accuracy  0.524845     0.925101  192
Gains/Lift Table: Avg response rate: 49.68 %, avg score: 49.87 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   0.996484           2.01287    2.01287            1                0.997098    1                           0.997098            0.0203056       0.0203056                  101.287   101.287
    2        0.0200759                   0.995643           2.01287    2.01287            1                0.996081    1                           0.996592            0.0201045       0.0404101                  101.287   101.287
    3        0.0300639                   0.994892           2.01287    2.01287            1                0.995263    1                           0.99615             0.0201045       0.0605147                  101.287   101.287
    4        0.0400519                   0.994071           2.01287    2.01287            1                0.994482    1                           0.995734            0.0201045       0.0806192                  101.287   101.287
    5        0.05004                     0.993379           2.01287    2.01287            1                0.993782    1                           0.995345            0.0201045       0.100724                   101.287   101.287
    6        0.10008                     0.990265           2.00885    2.01086            0.998004         0.991932    0.999002                    0.993638            0.100523        0.201246                   100.885   101.086
    7        0.15002                     0.986439           1.98871    2.00349            0.988            0.988381    0.99534                     0.991888            0.0993164       0.300563                   98.8713   100.349
    8        0.20006                     0.980994           1.9968     2.00181            0.992016         0.983861    0.994508                    0.98988             0.0999196       0.400483                   99.6796   100.181
    9        0.30004                     0.957047           1.96058    1.98807            0.974026         0.971053    0.987683                    0.983607            0.196019        0.596502                   96.0585   98.8075
    10       0.40002                     0.874973           1.85401    1.95457            0.921079         0.926235    0.971036                    0.969267            0.185364        0.781866                   85.4009   95.4567
    11       0.5                         0.516708           1.45586    1.85485            0.723277         0.733365    0.921494                    0.922096            0.145557        0.927423                   45.586    85.4845
    12       0.59998                     0.122623           0.528855   1.63388            0.262737         0.279246    0.81172                     0.814972            0.0528749       0.980298                   -47.1145  63.3884
    13       0.69996                     0.0336253          0.136738   1.42004            0.0679321        0.0651761   0.705479                    0.707874            0.0136711       0.993969                   -86.3262  42.0036
    14       0.79994                     0.0124116          0.0462497  1.24833            0.022977         0.0209983   0.620177                    0.622025            0.00462405      0.998593                   -95.375   24.8334
    15       0.89992                     0.00518406         0.0100543  1.11076            0.004995         0.00825811  0.551831                    0.553836            0.00100523      0.999598                   -98.9946  11.0763
    16       1                           0.000527682        0.0040177  1                  0.00199601       0.00327224  0.496804                    0.498736            0.000402091     1                          -99.5982  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.052411118671141364
RMSE: 0.22893474762722535
LogLoss: 0.1810734586512332
Mean Per-Class Error: 0.06800115378904992
AUC: 0.9800166651428207
pr_auc: 0.9713919276679385
Gini: 0.9600333302856414
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.544262074145074: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2917  211   0.0675   (211.0/3128.0)
1      209   2840  0.0685   (209.0/3049.0)
Total  3126  3051  0.068    (420.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.544262     0.931148  191
max f2                       0.222677     0.948788  279
max f0point5                 0.75184      0.942799  136
max accuracy                 0.551583     0.932006  189
max precision                0.997733     1         0
max recall                   0.00677575   1         390
max specificity              0.997733     1         0
max absolute_mcc             0.544262     0.863991  191
max min_per_class_accuracy   0.541478     0.931781  192
max mean_per_class_accuracy  0.544262     0.931999  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.78 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.996417           2.02591     2.02591            1                0.997144    1                           0.997144            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.995484           2.02591     2.02591            1                0.99596     1                           0.996552            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.994829           2.02591     2.02591            1                0.995167    1                           0.996091            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.994164           2.02591     2.02591            1                0.9945      1                           0.995693            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.993628           2.02591     2.02591            1                0.993901    1                           0.995339            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.990234           2.0128      2.01935            0.993528         0.992007    0.996764                    0.993673            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.986253           2.02591     2.02154            1                0.988315    0.997843                    0.991887            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.980841           2.01935     2.02099            0.996764         0.983708    0.997573                    0.989842            0.101017        0.404395                   101.935   102.099
    9        0.299984                    0.957759           1.98651     2.00951            0.980551         0.97113     0.991905                    0.983612            0.198426        0.602821                   98.6508   100.951
    10       0.400032                    0.876379           1.86856     1.97426            0.92233          0.927706    0.974504                    0.96963             0.186947        0.789767                   86.8558   97.4258
    11       0.500081                    0.511649           1.46534     1.87244            0.723301         0.730771    0.924247                    0.921843            0.146605        0.936373                   46.5343   87.2442
    12       0.599968                    0.121135           0.482672    1.64106            0.23825          0.272861    0.810038                    0.813796            0.0482125       0.984585                   -51.7328  64.1064
    13       0.700016                    0.0324457          0.121292    1.42385            0.0598706        0.0637677   0.702821                    0.706599            0.0121351       0.99672                    -87.8708  42.3853
    14       0.799903                    0.012203           0.0262679   1.24933            0.012966         0.0204246   0.616677                    0.620914            0.00262381      0.999344                   -97.3732  24.9332
    15       0.899951                    0.005051           0.00655634  1.11117            0.00323625       0.00810053  0.54848                     0.552787            0.000655953     1                          -99.3444  11.1171
    16       1                           0.000438483        0           1                  0                0.00320879  0.493605                    0.497803            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:56:48  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:56:54  4:50:11.470  4645 obs/sec      1         1             25000      0.296849         0.290281            0.647507       0.948622        0.931817           2.01287          0.120755                         0.288557           0.276219              0.666885         0.953532          0.934956             2.02591            0.109438
    2019-08-03 20:56:59  4:50:16.948  4776 obs/sec      2         2             50000      0.285986         0.271106            0.672836       0.955414        0.945646           2.01287          0.111666                         0.27879            0.259564              0.689053         0.959708          0.948103             2.02591            0.105553
    2019-08-03 20:57:05  4:50:22.765  4740 obs/sec      3         3             75000      0.280117         0.261211            0.686125       0.958655        0.956627           2.01287          0.10807                          0.270988           0.247604              0.706213         0.963267          0.959004             2.02591            0.0966489
    2019-08-03 20:57:11  4:50:28.673  4702 obs/sec      4         4             100000     0.274443         0.252074            0.698712       0.961672        0.955556           2.01287          0.103875                         0.265844           0.239493              0.717262         0.965814          0.958919             2.02591            0.0947062
    2019-08-03 20:57:17  4:50:34.383  4712 obs/sec      5         5             125000     0.275732         0.254186            0.695875       0.960529        0.956418           2.01287          0.103576                         0.266786           0.240703              0.715254         0.964531          0.959637             2.02591            0.096487
    2019-08-03 20:57:22  4:50:40.153  4710 obs/sec      6         6             150000     0.266958         0.239423            0.714922       0.965347        0.957599           2.01287          0.0984818                        0.258761           0.225975              0.732128         0.969315          0.964176             2.02591            0.0898494
    2019-08-03 20:57:28  4:50:45.988  4702 obs/sec      7         7             175000     0.259595         0.22846             0.730431       0.967999        0.960133           2.01287          0.0915901                        0.251675           0.214906              0.746598         0.971982          0.965007             2.02591            0.0851546
    2019-08-03 20:57:34  4:50:51.788  4705 obs/sec      8         8             200000     0.254055         0.219911            0.741814       0.970366        0.964778           1.99294          0.0853975                        0.245277           0.204854              0.759317         0.974408          0.968807             2.02591            0.0817549
    2019-08-03 20:57:40  4:50:57.427  4717 obs/sec      9         9             225000     0.244871         0.206047            0.760144       0.973822        0.959659           2.01287          0.0793048                        0.235957           0.191554              0.77726          0.977848          0.964123             2.02591            0.0722033
    2019-08-03 20:57:45  4:51:03.059  4728 obs/sec      10        10            250000     0.238508         0.19604             0.772447       0.97621         0.966585           2.01287          0.0753096                        0.228935           0.181073              0.790321         0.980017          0.971392             2.02591            0.0679942
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004835958099090392
C438        0.7828472852706909     0.7828472852706909   0.0037858166695557242
C374        0.7541444301605225     0.7541444301605225   0.003647010864918687
C322        0.6493585109710693     0.6493585109710693   0.00314027055034382
C88         0.6396865844726562     0.6396865844726562   0.003093497519060012
---         ---                    ---                  ---
C978        0.11175254732370377    0.11175254732370377  0.0005404306363240475
C913        0.10915092378854752    0.10915092378854752  0.0005278492939184245
C912        0.10817824304103851    0.10817824304103851  0.0005231454505796791
C815        0.10602250695228577    0.10602250695228577  0.0005127204011817737
C950        0.10195398330688477    0.10195398330688477  0.000493045191307456

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_10

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 272,619 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms          mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  ------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.03509882228476996   0.06128378212451935     0.0         0.001274200132887778  0.1284812092781067  -0.012506750208215718   0.1451982855796814
    3        2        Softmax                 0.0   0.0   0.001864608314463112  0.00042769836727529764  0.0         0.021992917347233742  0.5011148452758789  -0.0011307996368869477  0.17877131700515747


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05877838623148958
RMSE: 0.24244254212388053
LogLoss: 0.20250675780473695
Mean Per-Class Error: 0.07648453282375378
AUC: 0.974717317153951
pr_auc: 0.9656590641140287
Gini: 0.9494346343079021
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47768189563519936: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4544  459   0.0917   (459.0/5003.0)
1      308   4721  0.0612   (308.0/5029.0)
Total  4852  5180  0.0765   (767.0/10032.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.477682     0.92487   210
max f2                       0.211603     0.944059  285
max f0point5                 0.785997     0.933159  120
max accuracy                 0.503711     0.923545  204
max precision                0.99825      1         0
max recall                   0.00168611   1         398
max specificity              0.99825      1         0
max absolute_mcc             0.477682     0.847461  210
max min_per_class_accuracy   0.561213     0.922251  189
max mean_per_class_accuracy  0.503711     0.923515  204
Gains/Lift Table: Avg response rate: 50.13 %, avg score: 50.93 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100678                   0.997187           1.99483     1.99483            1                0.997798    1                           0.997798            0.0200835       0.0200835                  99.483    99.483
    2        0.0200359                   0.996189           1.99483     1.99483            1                0.996681    1                           0.997243            0.0198847       0.0399682                  99.483    99.483
    3        0.030004                    0.995474           1.97488     1.9882             0.99             0.995824    0.996678                    0.996771            0.0196858       0.059654                   97.4882   98.8203
    4        0.0400718                   0.994655           1.99483     1.98987            1                0.99507     0.997512                    0.996344            0.0200835       0.0797375                  99.483    98.9868
    5        0.0500399                   0.993941           1.97488     1.98688            0.99             0.994294    0.996016                    0.995936            0.0196858       0.0994233                  97.4882   98.6882
    6        0.10008                     0.990302           1.97893     1.98291            0.992032         0.992168    0.994024                    0.994052            0.0990257       0.198449                   97.8935   98.2909
    7        0.15002                     0.986097           1.99085     1.98555            0.998004         0.988319    0.995349                    0.992144            0.0994233       0.297872                   99.0848   98.5552
    8        0.20006                     0.980006           1.97496     1.9829             0.99004          0.983318    0.994021                    0.989936            0.0988268       0.396699                   97.4961   98.2903
    9        0.30004                     0.957196           1.93516     1.967              0.97009          0.970478    0.986047                    0.983452            0.193478        0.590177                   93.5164   96.6995
    10       0.40002                     0.884654           1.85362     1.93866            0.929212         0.929243    0.971842                    0.969903            0.185325        0.775502                   85.3621   93.8659
    11       0.5                         0.564554           1.45187     1.84132            0.727817         0.758897    0.923046                    0.927711            0.145158        0.92066                    45.187    84.132
    12       0.59998                     0.157799           0.574782    1.63027            0.288136         0.330377    0.817245                    0.828171            0.0574667       0.978127                   -42.5218  63.0266
    13       0.69996                     0.0410795          0.145187    1.41814            0.0727817        0.086414    0.710909                    0.722221            0.0145158       0.992643                   -85.4813  41.8142
    14       0.79994                     0.0141187          0.043755    1.24636            0.0219342        0.0245539   0.624798                    0.635024            0.00437463      0.997017                   -95.6245  24.6365
    15       0.89992                     0.00564205         0.0238664   1.11055            0.0119641        0.00929333  0.556712                    0.565506            0.00238616      0.999403                   -97.6134  11.0547
    16       1                           0.0005565          0.00596065  1                  0.00298805       0.0034631   0.501296                    0.509257            0.00059654      1                          -99.4039  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.051957881548158995
RMSE: 0.22794271549702788
LogLoss: 0.18132037160450518
Mean Per-Class Error: 0.06502205242757042
AUC: 0.9800222747133561
pr_auc: 0.9727140600197486
Gini: 0.9600445494267122
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6120855221800227: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2950  178   0.0569   (178.0/3128.0)
1      223   2826  0.0731   (223.0/3049.0)
Total  3173  3004  0.0649   (401.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.612086     0.933752  173
max f2                       0.266423     0.949076  265
max f0point5                 0.758693     0.944697  130
max accuracy                 0.612086     0.935082  173
max precision                0.998368     1         0
max recall                   0.00394793   1         395
max specificity              0.998368     1         0
max absolute_mcc             0.612086     0.870211  173
max min_per_class_accuracy   0.572289     0.933824  184
max mean_per_class_accuracy  0.612086     0.934978  173
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.40 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.997083           2.02591     2.02591            1                0.997787   1                           0.997787            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.996144           2.02591     2.02591            1                0.996544   1                           0.997166            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.995461           1.99323     2.01502            0.983871         0.995776   0.994624                    0.996703            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.99457            2.02591     2.01774            1                0.995032   0.995968                    0.996285            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.993849           2.02591     2.01935            1                0.994245   0.996764                    0.995882            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.990208           2.01935     2.01935            0.996764         0.992098   0.996764                    0.99399             0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.985673           2.00624     2.01498            0.990291         0.988096   0.994606                    0.992026            0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.979264           2.0128      2.01444            0.993528         0.982836   0.994337                    0.989728            0.100689        0.403083                   101.28    101.444
    9        0.299984                    0.956137           1.97994     2.00295            0.97731          0.969275   0.988667                    0.982918            0.19777         0.600853                   97.9941   100.295
    10       0.400032                    0.881357           1.91773     1.98164            0.946602         0.927375   0.978146                    0.969026            0.191866        0.792719                   91.773    98.1637
    11       0.500081                    0.53765            1.46534     1.87834            0.723301         0.747528   0.927161                    0.924712            0.146605        0.939324                   46.5343   87.8345
    12       0.599968                    0.139542           0.400585    1.63232            0.197731         0.30279    0.80572                     0.821171            0.0400131       0.979337                   -59.9415  63.2317
    13       0.700016                    0.0371235          0.173743    1.42385            0.0857605        0.0774012  0.702821                    0.714869            0.0173827       0.99672                    -82.6257  42.3853
    14       0.799903                    0.0134257          0.0197009   1.24851            0.00972447       0.0229186  0.616272                    0.628462            0.00196786      0.998688                   -98.0299  24.8512
    15       0.899951                    0.00556774         0.00983452  1.11081            0.00485437       0.0088978  0.5483                      0.559585            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           0.000630211        0.00327817  1                  0.00161812       0.0035152  0.493605                    0.503951            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:18:46  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:18:51  12 min  9.182 sec  4808 obs/sec      0.9104    1             22760      0.296597         0.290088            0.648118       0.94862         0.935149           1.99483          0.117125                         0.286865           0.272589              0.670779         0.955013          0.941042             2.02591            0.108305
    2019-08-03 16:18:57  12 min 14.487 sec  4713 obs/sec      1.81996   2             45499      0.288036         0.275836            0.668139       0.953303        0.936781           1.99483          0.111344                         0.275431           0.254692              0.696502         0.960241          0.949585             2.02591            0.102963
    2019-08-03 16:19:02  12 min 19.700 sec  4700 obs/sec      2.7278    3             68195      0.28324          0.267972            0.679098       0.956196        0.937949           1.99483          0.109649                         0.272161           0.248915              0.703664         0.962225          0.954771             2.02591            0.101991
    2019-08-03 16:19:07  12 min 25.024 sec  4677 obs/sec      3.63908   4             90977      0.279729         0.26233             0.687005       0.957928        0.946681           1.97508          0.105363                         0.267603           0.241828              0.713508         0.964539          0.957153             2.02591            0.0960013
    2019-08-03 16:19:12  12 min 30.171 sec  4693 obs/sec      4.54776   5             113694     0.275831         0.255225            0.695668       0.960375        0.956765           1.99483          0.101774                         0.264874           0.237423              0.71932          0.96549           0.959141             2.02591            0.0938967
    2019-08-03 16:19:18  12 min 35.313 sec  4705 obs/sec      5.45696   6             136424     0.272173         0.249468            0.703686       0.962178        0.951157           1.99483          0.0972887                        0.261344           0.23074               0.726752         0.967684          0.951472             2.02591            0.090497
    2019-08-03 16:19:23  12 min 40.444 sec  4714 obs/sec      6.36384   7             159096     0.266703         0.242383            0.715475       0.964169        0.957018           1.99483          0.0938995                        0.254818           0.221104              0.740229         0.969979          0.958121             2.02591            0.0859641
    2019-08-03 16:19:28  12 min 45.769 sec  4695 obs/sec      7.27384   8             181846     0.266977         0.243084            0.714891       0.963524        0.958342           1.99483          0.0942982                        0.254409           0.222887              0.741063         0.969518          0.958413             2.02591            0.0841833
    2019-08-03 16:19:33  12 min 50.931 sec  4706 obs/sec      8.18224   9             204556     0.262741         0.236819            0.723866       0.965558        0.959547           1.99483          0.0921053                        0.250015           0.214966              0.749928         0.971379          0.964192             2.02591            0.0812692
    2019-08-03 16:19:38  12 min 56.085 sec  4711 obs/sec      9.08968   10            227242     0.249196         0.212384            0.751603       0.972353        0.965784           1.99483          0.0833333                        0.2377             0.194949              0.773958         0.976752          0.970642             2.02591            0.0747936
    2019-08-03 16:19:43  13 min  1.072 sec  4729 obs/sec      9.99836   11            249959     0.248045         0.212264            0.753893       0.972065        0.963794           1.99483          0.0802432                        0.236387           0.193518              0.776449         0.976774          0.961592             2.02591            0.0728509
    2019-08-03 16:19:48  13 min  6.163 sec  4735 obs/sec      10.9048   12            272619     0.242443         0.202507            0.764885       0.974717        0.965659           1.99483          0.0764553                        0.227943           0.18132               0.792134         0.980022          0.972714             2.02591            0.0649182
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004781062076037719
C438        0.8102627992630005     0.8102627992630005   0.0038739167411804944
C374        0.7947483062744141     0.7947483062744141   0.0037997409871238104
C322        0.6929380893707275     0.6929380893707275   0.0033129800201324206
C863        0.6263291835784912     0.6263291835784912   0.0029945187067227904
---         ---                    ---                  ---
C925        0.11212970316410065    0.11212970316410065  0.0005360990713952482
C835        0.11061886698007584    0.11061886698007584  0.0005288756698127016
C621        0.10911509394645691    0.10911509394645691  0.000521686037590698
C731        0.10805387049913406    0.10805387049913406  0.0005166122624125006
C591        0.10510837286710739    0.10510837286710739  0.0005025296553889591

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_38

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.03460904207718715    0.06066453456878662    0.0         -0.003517525451591334  0.12413585186004639  0.015108506729473194  0.1477142572402954
    3        2        Softmax                 0.0   0.0   0.0017198234218085418  3.280497912783176e-05  0.0         -0.0741125717831892    0.45166921615600586  0.001797387362326916  0.16570621728897095


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05795144488385003
RMSE: 0.24073106339616837
LogLoss: 0.19901673611270512
Mean Per-Class Error: 0.07537478060128544
AUC: 0.9755556283391347
pr_auc: 0.9676094999579196
Gini: 0.9511112566782693
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4943449361654002: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4554  410   0.0826   (410.0/4964.0)
1      345   4717  0.0682   (345.0/5062.0)
Total  4899  5127  0.0753   (755.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.494345     0.9259    205
max f2                       0.216155     0.943356  283
max f0point5                 0.79085      0.936868  119
max accuracy                 0.494345     0.924696  205
max precision                0.998884     1         0
max recall                   0.000872988  1         399
max specificity              0.998884     1         0
max absolute_mcc             0.494345     0.84943   205
max min_per_class_accuracy   0.529946     0.923046  194
max mean_per_class_accuracy  0.494345     0.924625  205
Gains/Lift Table: Avg response rate: 50.49 %, avg score: 50.60 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.998021           1.98064     1.98064            1                0.998554    1                           0.998554            0.0199526       0.0199526                  98.064    98.064
    2        0.0200479                   0.997323           1.98064     1.98064            1                0.997635    1                           0.998097            0.019755        0.0397076                  98.064    98.064
    3        0.0300219                   0.996592           1.98064     1.98064            1                0.996944    1                           0.997714            0.019755        0.0594627                  98.064    98.064
    4        0.0400958                   0.995943           1.98064     1.98064            1                0.996305    1                           0.99736             0.0199526       0.0794153                  98.064    98.064
    5        0.0500698                   0.995356           1.98064     1.98064            1                0.995667    1                           0.997022            0.019755        0.0991703                  98.064    98.064
    6        0.10004                     0.991644           1.96878     1.97472            0.994012         0.993588    0.997009                    0.995307            0.0983801       0.19755                    96.878    97.4716
    7        0.15001                     0.986954           1.96087     1.9701             0.99002          0.989347    0.994681                    0.993322            0.097985        0.295535                   96.0873   97.0105
    8        0.20008                     0.98009            1.9688      1.96978            0.994024         0.983642    0.994516                    0.990899            0.0985776       0.394113                   96.8804   96.9779
    9        0.30002                     0.956809           1.93913     1.95957            0.979042         0.969597    0.989362                    0.983803            0.193797        0.58791                    93.913    95.9569
    10       0.40006                     0.874822           1.85623     1.93373            0.937188         0.927057    0.976315                    0.969613            0.185697        0.773607                   85.6233   93.3729
    11       0.5                         0.547614           1.45879     1.8388             0.736527         0.745548    0.928386                    0.924827            0.145792        0.919399                   45.8795   83.8799
    12       0.60004                     0.143194           0.566743    1.62672            0.286142         0.319764    0.82131                     0.82395             0.056697        0.976096                   -43.3257  62.6719
    13       0.69998                     0.0400794          0.169995    1.41873            0.0858283        0.0802443   0.716301                    0.717767            0.0169893       0.993086                   -83.0005  41.8734
    14       0.80002                     0.0139588          0.0513426   1.24775            0.0259222        0.0243939   0.629971                    0.631063            0.00513631      0.998222                   -94.8657  24.7746
    15       0.89996                     0.0049576          0.0158135   1.11094            0.00798403       0.00882252  0.5609                      0.561963            0.0015804       0.999802                   -98.4187  11.0941
    16       1                           0.000329939        0.00197472  1                  0.000997009      0.00269273  0.504887                    0.506014            0.00019755      1                          -99.8025  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05291722139625666
RMSE: 0.23003743477150987
LogLoss: 0.18312597573855022
Mean Per-Class Error: 0.06922608477560455
AUC: 0.9794467432615952
pr_auc: 0.9726888258736225
Gini: 0.9588934865231904
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5120766157231178: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2896  232   0.0742   (232.0/3128.0)
1      196   2853  0.0643   (196.0/3049.0)
Total  3092  3085  0.0693   (428.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.512077     0.930225  200
max f2                       0.273488     0.946267  264
max f0point5                 0.820793     0.943522  111
max accuracy                 0.512077     0.930711  200
max precision                0.998977     1         0
max recall                   0.00383317   1         394
max specificity              0.998977     1         0
max absolute_mcc             0.512077     0.861478  200
max min_per_class_accuracy   0.535967     0.929987  194
max mean_per_class_accuracy  0.512077     0.930774  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.81 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.998007           2.02591     2.02591            1                0.998521    1                           0.998521            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.997141           2.02591     2.02591            1                0.997535    1                           0.998028            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.99657            2.02591     2.02591            1                0.996837    1                           0.997631            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.995944           2.02591     2.02591            1                0.99625     1                           0.997286            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.995198           2.02591     2.02591            1                0.995545    1                           0.996942            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.991719           2.01935     2.02263            0.996764         0.993495    0.998382                    0.995219            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.987108           2.0128      2.01935            0.993528         0.989514    0.996764                    0.993317            0.100689        0.30305                    101.28    101.935
    8        0.200097                    0.979339           1.99968     2.01444            0.987055         0.983456    0.994337                    0.990852            0.100033        0.403083                   99.9685   101.444
    9        0.299984                    0.954152           1.99636     2.00842            0.985413         0.968532    0.991365                    0.98342             0.19941         0.602493                   99.6359   100.842
    10       0.400032                    0.8687             1.9374      1.99066            0.956311         0.921598    0.982598                    0.967958            0.193834        0.796327                   93.7399   99.0656
    11       0.500081                    0.508048           1.39322     1.87113            0.687702         0.724139    0.9236                      0.919179            0.13939         0.935717                   39.3223   87.113
    12       0.599968                    0.129232           0.479389    1.63942            0.236629         0.284683    0.809228                    0.813543            0.0478846       0.983601                   -52.0611  63.9424
    13       0.700016                    0.0358782          0.101623    1.41964            0.0501618        0.0678251   0.70074                     0.706963            0.0101673       0.993768                   -89.8377  41.9636
    14       0.799903                    0.0125852          0.0492523   1.24851            0.0243112        0.022055    0.616272                    0.621436            0.00491965      0.998688                   -95.0748  24.8512
    15       0.899951                    0.0048015          0.00655634  1.11044            0.00323625       0.00789849  0.54812                     0.553229            0.000655953     0.999344                   -99.3444  11.0442
    16       1                           0.000262145        0.00655634  1                  0.00323625       0.0025617   0.493605                    0.498135            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:48:33  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:48:38  41 min 56.287 sec  4750 obs/sec      1         1             25000      0.294939         0.290327            0.652011       0.949019        0.92368            1.98064          0.117195                         0.289552           0.278322              0.664585         0.952838          0.924227             2.02591            0.113486
    2019-08-03 16:48:44  42 min  1.803 sec  4812 obs/sec      2         2             50000      0.282793         0.267921            0.680082       0.956542        0.947523           1.98064          0.107321                         0.274388           0.253403              0.698795         0.961554          0.951721             2.02591            0.0987534
    2019-08-03 16:48:50  42 min  7.467 sec  4787 obs/sec      3         3             75000      0.278031         0.260736            0.690766       0.958405        0.952999           1.98064          0.102633                         0.270855           0.248013              0.706503         0.962599          0.954974             2.02591            0.0971345
    2019-08-03 16:48:55  42 min 13.191 sec  4763 obs/sec      4         4             100000     0.274497         0.255062            0.698576       0.960335        0.949446           1.98064          0.0990425                        0.26743            0.243266              0.713878         0.964072          0.956395             2.02591            0.0922778
    2019-08-03 16:49:01  42 min 18.758 sec  4781 obs/sec      5         5             125000     0.267356         0.241467            0.714055       0.964643        0.954277           1.98064          0.0963495                        0.260064           0.228225              0.729422         0.968973          0.961366             2.02591            0.0914684
    2019-08-03 16:49:07  42 min 24.473 sec  4764 obs/sec      6         6             150000     0.263791         0.236312            0.721631       0.965652        0.963099           1.98064          0.0923599                        0.255996           0.22249               0.737822         0.969717          0.961051             2.02591            0.0864497
    2019-08-03 16:49:12  42 min 30.005 sec  4775 obs/sec      7         7             175000     0.257265         0.225698            0.735234       0.968672        0.955576           1.98064          0.0875723                        0.247793           0.209597              0.754355         0.973252          0.967256             2.02591            0.0798122
    2019-08-03 16:49:18  42 min 35.721 sec  4772 obs/sec      8         8             200000     0.252185         0.217034            0.745586       0.970999        0.958539           1.98064          0.0846798                        0.243974           0.203599              0.761868         0.974625          0.965671             2.02591            0.0814311
    2019-08-03 16:49:23  42 min 41.139 sec  4791 obs/sec      9         9             225000     0.245018         0.206492            0.759842       0.973856        0.961289           1.98064          0.0778975                        0.236394           0.192476              0.776434         0.97777           0.970455             2.02591            0.0717177
    2019-08-03 16:49:29  42 min 46.641 sec  4800 obs/sec      10        10            250000     0.240731         0.199017            0.768172       0.975556        0.967609           1.98064          0.0753042                        0.230037           0.183126              0.788296         0.979447          0.972689             2.02591            0.0692893
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.00479211987840054
C438        0.7953822612762451     0.7953822612762451   0.003811567145189066
C322        0.7804092764854431     0.7804092764854431   0.0037398148071340746
C374        0.6862937808036804     0.6862937808036804   0.0032888020694119796
C88         0.6658216714859009     0.6658216714859009   0.0031906972673974594
---         ---                    ---                  ---
C862        0.1124253123998642     0.1124253123998642   0.0005387555743867799
C375        0.11111298203468323    0.11111298203468323  0.0005324667299567676
C925        0.11062818765640259    0.11062818765640259  0.000530143537179672
C888        0.10443408042192459    0.10443408042192459  0.0005004606327723855
C835        0.10418212413787842    0.10418212413787842  0.0004992532280551199

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_173

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.03140441388657805   0.05221065878868103    0.0         0.0033438759664937623  0.125385582447052   -0.020822910443125776  0.15496814250946045
    3        2        Softmax                 0.0   0.0   0.001755053931447037  0.0001651686616241932  0.0         -0.015380770160390966  0.5219032764434814  0.004197493627518201   0.1987391710281372


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05746931878579594
RMSE: 0.23972759287532158
LogLoss: 0.19786090301388223
Mean Per-Class Error: 0.07580028171569697
AUC: 0.9757406806451038
pr_auc: 0.9681385910288535
Gini: 0.9514813612902076
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38661470432754125: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4459  540   0.108    (540.0/4999.0)
1      242   4772  0.0483   (242.0/5014.0)
Total  4701  5312  0.0781   (782.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.386615     0.924269  231
max f2                       0.223335     0.945636  279
max f0point5                 0.807308     0.935368  115
max accuracy                 0.555081     0.924199  187
max precision                0.998305     1         0
max recall                   0.00357478   1         395
max specificity              0.998305     1         0
max absolute_mcc             0.555081     0.848399  187
max min_per_class_accuracy   0.549356     0.923785  189
max mean_per_class_accuracy  0.555081     0.9242    187
Gains/Lift Table: Avg response rate: 50.07 %, avg score: 50.44 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   0.996917           1.99701     1.99701            1                0.997683    1                           0.997683            0.0201436       0.0201436                  99.7008   99.7008
    2        0.0200739                   0.995955           1.97704     1.98707            0.99             0.996455    0.995025                    0.997072            0.0197447       0.0398883                  97.7038   98.7073
    3        0.0300609                   0.995169           1.99701     1.99037            1                0.995546    0.996678                    0.996565            0.0199442       0.0598325                  99.7008   99.0374
    4        0.0400479                   0.994523           1.99701     1.99203            1                0.994813    0.997506                    0.996128            0.0199442       0.0797766                  99.7008   99.2028
    5        0.050035                    0.993803           1.99701     1.99302            1                0.994155    0.998004                    0.995734            0.0199442       0.0997208                  99.7008   99.3022
    6        0.10007                     0.990093           1.99302     1.99302            0.998004         0.991992    0.998004                    0.993863            0.0997208       0.199442                   99.3022   99.3022
    7        0.150005                    0.985164           1.98103     1.98903            0.992            0.987683    0.996005                    0.991806            0.098923        0.298365                   98.1032   98.9031
    8        0.20004                     0.979525           1.97309     1.98504            0.988024         0.982511    0.994009                    0.989481            0.0987236       0.397088                   97.3092   98.5044
    9        0.30001                     0.956226           1.93915     1.96975            0.971029         0.969832    0.986352                    0.982934            0.193857        0.590945                   93.9153   96.9752
    10       0.39998                     0.883174           1.85137     1.94016            0.927073         0.927563    0.971536                    0.969095            0.185082        0.776027                   85.1372   94.0165
    11       0.50005                     0.552444           1.47284     1.84664            0.737525         0.752787    0.924705                    0.925807            0.147387        0.923414                   47.2844   84.6644
    12       0.60002                     0.1349             0.562594    1.63271            0.281718         0.30703     0.817577                    0.822712            0.0562425       0.979657                   -43.7406  63.2707
    13       0.69999                     0.0366344          0.143641    1.42004            0.0719281        0.0741641   0.711086                    0.715807            0.0143598       0.994017                   -85.6359  42.0044
    14       0.79996                     0.0127804          0.0418953   1.24782            0.020979         0.0222694   0.624844                    0.629137            0.00418827      0.998205                   -95.8105  24.7819
    15       0.89993                     0.00525271         0.00997507  1.11031            0.004995         0.00838967  0.555987                    0.56018             0.000997208     0.999202                   -99.0025  11.0311
    16       1                           0.00036273         0.00797209  1                  0.00399202       0.00319155  0.500749                    0.504442            0.000797766     1                          -99.2028  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05321226183537585
RMSE: 0.23067783126121125
LogLoss: 0.18462198028629784
Mean Per-Class Error: 0.0675630306024616
AUC: 0.9790613080973258
pr_auc: 0.9726317572725288
Gini: 0.9581226161946517
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5478811251257459: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2930  198   0.0633   (198.0/3128.0)
1      219   2830  0.0718   (219.0/3049.0)
Total  3149  3028  0.0675   (417.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.547881     0.931381  193
max f2                       0.207472     0.946256  285
max f0point5                 0.783516     0.942832  129
max accuracy                 0.555794     0.932492  191
max precision                0.998541     1         0
max recall                   0.00351976   1         395
max specificity              0.998541     1         0
max absolute_mcc             0.555794     0.864975  191
max min_per_class_accuracy   0.527393     0.931453  199
max mean_per_class_accuracy  0.547881     0.932437  193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.58 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.997004           2.02591     2.02591            1                0.997855    1                           0.997855            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.996045           2.02591     2.02591            1                0.996493    1                           0.997174            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.995336           2.02591     2.02591            1                0.995728    1                           0.996692            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.994552           2.02591     2.02591            1                0.994874    1                           0.996237            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.993761           2.02591     2.02591            1                0.994161    1                           0.995827            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.990222           2.02591     2.02591            1                0.991999    1                           0.993913            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.985008           2.0128      2.02154            0.993528         0.987697    0.997843                    0.991841            0.100689        0.303378                   101.28    102.154
    8        0.200097                    0.97918            2.0128      2.01935            0.993528         0.982253    0.996764                    0.989444            0.100689        0.404067                   101.28    101.935
    9        0.299984                    0.955553           1.97337     2.00404            0.974068         0.969561    0.989207                    0.982824            0.197114        0.601181                   97.3374   100.404
    10       0.400032                    0.87223            1.89806     1.97754            0.936893         0.92395     0.976123                    0.968099            0.189898        0.791079                   89.8061   97.7538
    11       0.500081                    0.497251           1.4424      1.87047            0.711974         0.719383    0.923276                    0.91834             0.14431         0.935389                   44.2396   87.0474
    12       0.599968                    0.117611           0.466255    1.63669            0.230146         0.267906    0.807879                    0.810051            0.0465726       0.981961                   -53.3745  63.669
    13       0.700016                    0.0342031          0.124571    1.42057            0.0614887        0.0650525   0.701203                    0.703574            0.0124631       0.994424                   -87.5429  42.0573
    14       0.799903                    0.0119421          0.0328348   1.24728            0.0162075        0.0211341   0.615665                    0.618355            0.00327976      0.997704                   -96.7165  24.7282
    15       0.899951                    0.00513004         0.019669    1.11081            0.00970874       0.0080924   0.5483                      0.550511            0.00196786      0.999672                   -98.0331  11.0807
    16       1                           0.000504412        0.00327817  1                  0.00161812       0.00322274  0.493605                    0.495756            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:39:21  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:39:27  3:32:44.438  4599 obs/sec      1         1             25000      0.296719         0.291884            0.647831       0.94839         0.925186           1.99701          0.121742                         0.287522           0.275057              0.66927          0.953873          0.934744             2.02591            0.113486
    2019-08-03 19:39:32  3:32:50.090  4681 obs/sec      2         2             50000      0.282348         0.267222            0.681117       0.956274        0.945125           1.99701          0.108259                         0.275518           0.254671              0.696309         0.961028          0.95294              2.02591            0.102315
    2019-08-03 19:39:38  3:32:55.924  4663 obs/sec      3         3             75000      0.279152         0.261253            0.688296       0.958926        0.948965           1.99701          0.102966                         0.272705           0.250286              0.702479         0.963066          0.952334             2.02591            0.0971345
    2019-08-03 19:39:44  3:33:01.687  4667 obs/sec      4         4             100000     0.2719           0.24949             0.704281       0.961622        0.945228           1.99701          0.10027                          0.264073           0.23648               0.721016         0.966068          0.952488             2.02591            0.0935729
    2019-08-03 19:39:50  3:33:07.503  4663 obs/sec      5         5             125000     0.269299         0.244691            0.709912       0.96348         0.95901            1.99701          0.0955758                        0.262066           0.232777              0.72524          0.96732           0.961944             2.02591            0.0930873
    2019-08-03 19:39:55  3:33:13.123  4685 obs/sec      6         6             150000     0.265122         0.238713            0.71884        0.964782        0.954494           1.97724          0.0941776                        0.256402           0.225301              0.736989         0.968753          0.96152              2.02591            0.0856403
    2019-08-03 19:40:01  3:33:18.736  4704 obs/sec      7         7             175000     0.25893          0.227855            0.731821       0.968039        0.956762           1.99701          0.089983                         0.25069            0.215195              0.748576         0.971883          0.967283             2.02591            0.0825644
    2019-08-03 19:40:07  3:33:24.412  4712 obs/sec      8         8             200000     0.253609         0.220246            0.74273        0.969889        0.965425           1.99701          0.0855887                        0.245089           0.205831              0.759685         0.974329          0.967984             2.02591            0.0790028
    2019-08-03 19:40:12  3:33:29.998  4728 obs/sec      9         9             225000     0.248431         0.211948            0.753127       0.97214         0.966246           1.99701          0.0810946                        0.238683           0.196179              0.772085         0.976362          0.968275             2.02591            0.0762506
    2019-08-03 19:40:18  3:33:35.647  4734 obs/sec      10        10            250000     0.239728         0.197861            0.770122       0.975741        0.968139           1.99701          0.0780985                        0.230678           0.184622              0.787116         0.979061          0.972632             2.02591            0.0675085
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0049613592861885115
C438        0.7433803677558899     0.7433803677558899   0.003688177090735915
C374        0.7396114468574524     0.7396114468574524   0.003669478120037542
C322        0.7342233061790466     0.7342233061790466   0.0036427456182474434
C88         0.699828028678894      0.699828028678894    0.0034720982888210307
---         ---                    ---                  ---
C849        0.10933704674243927    0.10933704674243927  0.0005424603721800284
C955        0.10801982134580612    0.10801982134580612  0.0005359251437264392
C632        0.1031823679804802     0.1031823679804802   0.0005119247995508756
C700        0.10185960680246353    0.10185960680246353  0.0005053621060969129
C712        0.1010526791214943     0.1010526791214943   0.0005013586479536537

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_159

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.03856074362955654    0.06121411919593811   0.0         -0.007981080725861185  0.1208692193031311   0.027064178408377805    0.14506804943084717
    3        2        Softmax                 0.0   0.0   0.0017502853806945495  0.000207127770408988  0.0         -0.07663782706003985   0.47230732440948486  -0.0019299009250145355  0.17479252815246582


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06034195670913407
RMSE: 0.24564599876475512
LogLoss: 0.20579109269061002
Mean Per-Class Error: 0.07837623604465715
AUC: 0.9741864433811803
pr_auc: 0.9710949501870512
Gini: 0.9483728867623606
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5080649545444779: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4591  409   0.0818   (409.0/5000.0)
1      377   4639  0.0752   (377.0/5016.0)
Total  4968  5048  0.0785   (786.0/10016.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.508065     0.9219    204
max f2                       0.197504     0.940985  293
max f0point5                 0.729615     0.931888  142
max accuracy                 0.514522     0.921625  202
max precision                0.997879     1         0
max recall                   0.00605565   1         393
max specificity              0.997879     1         0
max absolute_mcc             0.510965     0.843256  203
max min_per_class_accuracy   0.521651     0.9212    200
max mean_per_class_accuracy  0.514522     0.921624  202
Gains/Lift Table: Avg response rate: 50.08 %, avg score: 50.10 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100839                   0.99565            1.99681     1.99681            1                0.996618    1                           0.996618            0.0201356       0.0201356                  99.681    99.681
    2        0.0200679                   0.994492           1.99681     1.99681            1                0.994996    1                           0.995811            0.0199362       0.0400718                  99.681    99.681
    3        0.0300519                   0.993577           1.99681     1.99681            1                0.99403     1                           0.995219            0.0199362       0.060008                   99.681    99.681
    4        0.0400359                   0.992708           1.99681     1.99681            1                0.993107    1                           0.994693            0.0199362       0.0799442                  99.681    99.681
    5        0.05002                     0.991898           1.99681     1.99681            1                0.992262    1                           0.994207            0.0199362       0.0998804                  99.681    99.681
    6        0.10004                     0.987833           1.98485     1.99083            0.994012         0.989947    0.997006                    0.992077            0.0992823       0.199163                   98.4853   99.0832
    7        0.15006                     0.982585           1.96891     1.98352            0.986028         0.985391    0.993347                    0.989849            0.0984848       0.297648                   96.8911   98.3525
    8        0.20008                     0.9765             1.97688     1.98186            0.99002          0.979722    0.992515                    0.987317            0.0988836       0.396531                   97.6882   98.1864
    9        0.30002                     0.951996           1.95691     1.97355            0.98002          0.966342    0.988353                    0.98033             0.195574        0.592105                   95.6914   97.3553
    10       0.40006                     0.866021           1.84137     1.9405             0.922156         0.918891    0.971799                    0.964966            0.184211        0.776316                   84.137    94.0499
    11       0.5                         0.524925           1.44026     1.84051            0.721279         0.736185    0.921725                    0.919238            0.143939        0.920255                   44.0257   84.051
    12       0.60004                     0.13658            0.555998    1.62635            0.278443         0.299917    0.814476                    0.815983            0.055622        0.975877                   -44.4002  62.6354
    13       0.69998                     0.0375139          0.169559    1.41836            0.0849151        0.074051    0.710312                    0.710053            0.0169458       0.992823                   -83.0441  41.8359
    14       0.80002                     0.0146152          0.0538063   1.24773            0.0269461        0.0235963   0.62486                     0.624214            0.00538278      0.998206                   -94.6194  24.7726
    15       0.89996                     0.00756902         0.0139637   1.11072            0.00699301       0.0108225   0.556246                    0.556097            0.00139553      0.999601                   -98.6036  11.0717
    16       1                           0.000986265        0.00398565  1                  0.00199601       0.00486948  0.500799                    0.500952            0.000398724     1                          -99.6014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05358160877151529
RMSE: 0.23147701564413536
LogLoss: 0.18526620627997029
Mean Per-Class Error: 0.06851796824081346
AUC: 0.9793822594133836
pr_auc: 0.9768667301860365
Gini: 0.9587645188267673
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5376310280792002: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2923  205   0.0655   (205.0/3128.0)
1      218   2831  0.0715   (218.0/3049.0)
Total  3141  3036  0.0685   (423.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.537631     0.930485  191
max f2                       0.282825     0.945616  262
max f0point5                 0.799781     0.940168  116
max accuracy                 0.542084     0.93152   190
max precision                0.997805     1         0
max recall                   0.0100047    1         387
max specificity              0.997805     1         0
max absolute_mcc             0.542084     0.863023  190
max min_per_class_accuracy   0.522869     0.930627  195
max mean_per_class_accuracy  0.537631     0.931482  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.54 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.995581           2.02591     2.02591            1                0.996457    1                           0.996457            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.994386           2.02591     2.02591            1                0.994901    1                           0.995679            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.993379           2.02591     2.02591            1                0.993886    1                           0.995081            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.992502           2.02591     2.02591            1                0.992901    1                           0.994536            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.991483           2.02591     2.02591            1                0.991912    1                           0.994018            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.986974           2.01935     2.02263            0.996764         0.989414    0.998382                    0.991716            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.981826           1.99968     2.01498            0.987055         0.984514    0.994606                    0.989315            0.100033        0.302394                   99.9685   101.498
    8        0.200097                    0.976247           2.0128      2.01444            0.993528         0.979168    0.994337                    0.986779            0.100689        0.403083                   101.28    101.444
    9        0.299984                    0.951081           2.00293     2.0106             0.988655         0.966269    0.992445                    0.979949            0.200066        0.603149                   100.293   101.06
    10       0.400032                    0.862922           1.88167     1.97836            0.928803         0.91732     0.976528                    0.964286            0.188258        0.791407                   88.1671   97.8357
    11       0.500081                    0.493248           1.43912     1.87047            0.710356         0.715147    0.923276                    0.914442            0.143982        0.935389                   43.9117   87.0474
    12       0.599968                    0.122412           0.466255    1.63669            0.230146         0.274502    0.807879                    0.8079              0.0465726       0.981961                   -53.3745  63.669
    13       0.700016                    0.0360481          0.140961    1.42292            0.0695793        0.0688445   0.702359                    0.702272            0.014103        0.996064                   -85.9039  42.2916
    14       0.799903                    0.0143187          0.0328348   1.24933            0.0162075        0.0227489   0.616677                    0.617418            0.00327976      0.999344                   -96.7165  24.9332
    15       0.899951                    0.00727929         0.00655634  1.11117            0.00323625       0.0104788   0.54848                     0.549944            0.000655953     1                          -99.3444  11.1171
    16       1                           0.00113054         0           1                  0                0.00467369  0.493605                    0.49539             0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:11:15  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:11:21  3:04:38.579  4705 obs/sec      1         1             25000      0.297492         0.294649            0.645993       0.947281        0.92303            1.99681          0.116913                         0.286367           0.272853              0.671922         0.954641          0.933974             2.02591            0.107172
    2019-08-03 19:11:27  3:04:44.349  4677 obs/sec      2         2             50000      0.288895         0.277868            0.666157       0.952816        0.94466            1.97704          0.111621                         0.277708           0.258102              0.691462         0.960102          0.953489             2.02591            0.104582
    2019-08-03 19:11:32  3:04:49.946  4698 obs/sec      3         3             75000      0.285695         0.272542            0.673514       0.954488        0.950173           1.97704          0.109125                         0.273418           0.251576              0.700921         0.961772          0.953171             2.02591            0.0985915
    2019-08-03 19:11:38  3:04:55.708  4696 obs/sec      4         4             100000     0.280683         0.264085            0.684867       0.957378        0.95061            1.97704          0.10633                          0.268339           0.242216              0.71193          0.964501          0.955469             2.02591            0.0972964
    2019-08-03 19:11:43  3:05:01.121  4755 obs/sec      5         5             125000     0.275558         0.256145            0.69627        0.959946        0.955302           1.97704          0.0997404                        0.261543           0.233139              0.726336         0.967019          0.960753             2.02591            0.0880686
    2019-08-03 19:11:49  3:05:06.836  4753 obs/sec      6         6             150000     0.27318          0.252059            0.70149        0.961196        0.952              1.97704          0.0988419                        0.259366           0.229342              0.730872         0.967906          0.959538             2.02591            0.0909827
    2019-08-03 19:11:55  3:05:12.512  4756 obs/sec      7         7             175000     0.272868         0.253427            0.702171       0.960573        0.949148           1.97704          0.0958466                        0.260758           0.230914              0.727977         0.967355          0.954403             2.02591            0.0882305
    2019-08-03 19:12:00  3:05:18.288  4744 obs/sec      8         8             200000     0.262342         0.23474             0.724706       0.966217        0.961059           1.97704          0.0896565                        0.247111           0.209909              0.755704         0.972876          0.960408             2.02591            0.0785171
    2019-08-03 19:12:06  3:05:23.778  4767 obs/sec      9         9             225000     0.259253         0.231212            0.731151       0.96669         0.959413           1.97704          0.0867612                        0.245965           0.208522              0.757966         0.972955          0.966907             2.02591            0.0790028
    2019-08-03 19:12:13  3:05:30.510  4674 obs/sec      10        10            250000     0.245646         0.205791            0.758632       0.974186        0.971095           1.99681          0.0784744                        0.231477           0.185266              0.785639         0.979382          0.976867             2.02591            0.0684798
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.0052309589212870735
C438        0.7997722625732422     0.7997722625732422   0.004183575851905449
C374        0.6993192434310913     0.6993192434310913   0.0036581102352535935
C79         0.6441507935523987     0.6441507935523987   0.0033695263401870676
C863        0.63888019323349       0.63888019323349     0.003341956046428334
---         ---                    ---                  ---
C889        0.09964638948440552    0.09964638948440552  0.0005212461700474975
C975        0.09962188452482224    0.09962188452482224  0.0005211179856105495
C456        0.09774057567119598    0.09774057567119598  0.0005112769362789769
C994        0.09587331116199493    0.09587331116199493  0.000501509352336169
C755        0.09298349916934967    0.09298349916934967  0.00048639286451239883

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_230

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 267,805 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.02924874805259086    0.06427696347236633    0.0         0.004216721400288019  0.12582248449325562  -0.003591251744821801  0.13908499479293823
    3        2        Softmax                 0.0   0.0   0.0017346697577522718  0.0003281149547547102  0.0         0.001229580698236532  0.5033128261566162   0.0006753669371898918  0.17860198020935059


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05902857059408354
RMSE: 0.24295796054890553
LogLoss: 0.20411058006877505
Mean Per-Class Error: 0.07520974830203753
AUC: 0.9739810629162704
pr_auc: 0.9629449269215838
Gini: 0.9479621258325408
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5396263751006269: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4641  365   0.0729   (365.0/5006.0)
1      388   4618  0.0775   (388.0/5006.0)
Total  5029  4983  0.0752   (753.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.539626     0.924617  194
max f2                       0.181902     0.941608  294
max f0point5                 0.763105     0.933272  128
max accuracy                 0.539626     0.92479   194
max precision                0.99848      1         0
max recall                   0.00192188   1         398
max specificity              0.99848      1         0
max absolute_mcc             0.539626     0.849589  194
max min_per_class_accuracy   0.524239     0.923891  198
max mean_per_class_accuracy  0.539626     0.92479   194
Gains/Lift Table: Avg response rate: 50.00 %, avg score: 49.92 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   0.997551           2           2                  1                0.998151    1                           0.998151            0.0201758       0.0201758                  100       100
    2        0.0200759                   0.99647            1.98        1.99005            0.99             0.996979    0.995025                    0.997568            0.0197763       0.0399521                  98        99.005
    3        0.0300639                   0.995719           2           1.99336            1                0.996083    0.996678                    0.997075            0.019976        0.0599281                  100       99.3355
    4        0.0400519                   0.994847           2           1.99501            1                0.995262    0.997506                    0.996623            0.019976        0.0799041                  100       99.5012
    5        0.05004                     0.994053           2           1.99601            1                0.994414    0.998004                    0.996182            0.019976        0.0998801                  100       99.6008
    6        0.10008                     0.989718           1.98004     1.98802            0.99002          0.991861    0.994012                    0.994021            0.0990811       0.198961                   98.004    98.8024
    7        0.15002                     0.985029           1.988       1.98802            0.994            0.987464    0.994008                    0.991838            0.0992809       0.298242                   98.8      98.8016
    8        0.20006                     0.978046           1.98004     1.98602            0.99002          0.981862    0.99301                     0.989343            0.0990811       0.397323                   98.004    98.6021
    9        0.30004                     0.95262            1.94805     1.97337            0.974026         0.9672      0.986684                    0.981965            0.194766        0.592089                   94.8052   97.3369
    10       0.40002                     0.86964            1.84815     1.94207            0.924076         0.920267    0.971036                    0.966544            0.184778        0.776868                   84.8152   94.2072
    11       0.5                         0.521151           1.47253     1.84818            0.736264         0.73327     0.924091                    0.919899            0.147223        0.924091                   47.2527   84.8182
    12       0.59998                     0.126887           0.539461    1.6301             0.26973          0.285844    0.815049                    0.81424             0.0539353       0.978026                   -46.0539  63.0098
    13       0.69996                     0.036238           0.135864    1.41667            0.0679321        0.071176    0.708333                    0.708104            0.0135837       0.99161                    -86.4136  41.6667
    14       0.79994                     0.0137804          0.0559441   1.2466             0.027972         0.022729    0.623299                    0.622442            0.00559329      0.997203                   -94.4056  24.6598
    15       0.89992                     0.00570472         0.023976    1.11077            0.011988         0.00917519  0.555383                    0.554309            0.00239712      0.9996                     -97.6024  11.0766
    16       1                           0.000376792        0.00399202  1                  0.00199601       0.00318214  0.5                         0.499152            0.000399521     1                          -99.6008  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.053222834583434485
RMSE: 0.23070074682027902
LogLoss: 0.18599274081870942
Mean Per-Class Error: 0.0678537321783419
AUC: 0.9785131429616352
pr_auc: 0.9687777137272015
Gini: 0.9570262859232703
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5398865351523623: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2921  207   0.0662   (207.0/3128.0)
1      212   2837  0.0695   (212.0/3049.0)
Total  3133  3044  0.0678   (419.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.539887     0.931233  191
max f2                       0.211189     0.947379  281
max f0point5                 0.707332     0.939703  146
max accuracy                 0.539887     0.932168  191
max precision                0.998476     1         0
max recall                   0.00720001   1         389
max specificity              0.998476     1         0
max absolute_mcc             0.539887     0.864312  191
max min_per_class_accuracy   0.530515     0.931266  193
max mean_per_class_accuracy  0.539887     0.932146  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.51 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.997441           2.02591    2.02591            1                0.998074    1                           0.998074            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.996325           2.02591    2.02591            1                0.996891    1                           0.997483            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.995554           2.02591    2.02591            1                0.995907    1                           0.996957            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.994562           2.02591    2.02591            1                0.995032    1                           0.996476            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.993824           2.02591    2.02591            1                0.994209    1                           0.996029            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.989601           2.0128     2.01935            0.993528         0.991786    0.996764                    0.993907            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.984971           2.0128     2.01717            0.993528         0.987386    0.995685                    0.991734            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.977889           1.99313    2.01116            0.983819         0.981592    0.992718                    0.989198            0.0997048       0.402427                   99.3128   101.116
    9        0.299984                    0.951963           1.98322    2.00186            0.97893          0.966793    0.988127                    0.981738            0.198098        0.600525                   98.3225   100.186
    10       0.400032                    0.86737            1.92429    1.98246            0.949838         0.918446    0.978551                    0.965909            0.192522        0.793047                   92.4287   98.2457
    11       0.500081                    0.486195           1.42928    1.87179            0.705502         0.715049    0.923924                    0.915721            0.142998        0.936045                   42.9283   87.1786
    12       0.599968                    0.122662           0.459688   1.63669            0.226904         0.267928    0.807879                    0.807872            0.0459167       0.981961                   -54.0312  63.669
    13       0.700016                    0.0349432          0.121292   1.4201             0.0598706        0.0701999   0.700971                    0.702441            0.0121351       0.994096                   -87.8708  42.0105
    14       0.799903                    0.0131245          0.0459688  1.24851            0.0226904        0.0220628   0.616272                    0.61748             0.00459167      0.998688                   -95.4031  24.8512
    15       0.899951                    0.00545811         0.0131127  1.11117            0.00647249       0.008959    0.54848                     0.54983             0.00131191      1                          -98.6887  11.1171
    16       1                           0.000393236        0          1                  0                0.00310132  0.493605                    0.495131            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:48:35  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:48:41  4:41:58.563  4655 obs/sec      0.97492   1             24373      0.298213         0.291693            0.644276       0.948161        0.927132           2                0.121854                         0.290931           0.277632              0.661382         0.953207          0.928892             2.02591            0.114781
    2019-08-03 20:48:46  4:42:04.074  4706 obs/sec      1.94864   2             48716      0.284427         0.269166            0.676404       0.955677        0.948446           2                0.112465                         0.276617           0.253831              0.693883         0.96087           0.948758             2.02591            0.103934
    2019-08-03 20:48:52  4:42:09.920  4645 obs/sec      2.92304   3             73076      0.279751         0.262432            0.686958       0.958055        0.948773           2                0.107671                         0.272621           0.249395              0.702663         0.962819          0.956071             2.02591            0.10102
    2019-08-03 20:48:58  4:42:15.413  4686 obs/sec      3.8966    4             97415      0.276515         0.257461            0.694158       0.959201        0.9511             1.9604           0.102777                         0.268771           0.242983              0.711001         0.964317          0.95667              2.02591            0.0968107
    2019-08-03 20:49:03  4:42:20.986  4697 obs/sec      4.86808   5             121702     0.2768           0.260301            0.693528       0.958041        0.94739            1.94059          0.10028                          0.268102           0.244258              0.712438         0.963128          0.958029             2.02591            0.093411
    2019-08-03 20:49:09  4:42:26.710  4685 obs/sec      5.84272   6             146068     0.269475         0.248252            0.709533       0.962023        0.950807           1.9604           0.0976828                        0.259798           0.230381              0.729975         0.96722           0.959486             1.99323            0.0883924
    2019-08-03 20:49:14  4:42:32.187  4705 obs/sec      6.81608   7             170402     0.261254         0.232388            0.726986       0.966622        0.956178           1.9802           0.0921894                        0.249882           0.213353              0.750196         0.972292          0.963702             2.02591            0.0811073
    2019-08-03 20:49:20  4:42:37.827  4705 obs/sec      7.79016   8             194754     0.260841         0.233943            0.727849       0.965881        0.949134           1.9604           0.0893927                        0.250465           0.216161              0.749027         0.970911          0.960173             2.02591            0.0819168
    2019-08-03 20:49:26  4:42:43.598  4684 obs/sec      8.76444   9             219111     0.255969         0.225111            0.73792        0.968521        0.956191           1.9802           0.085797                         0.243313           0.203997              0.763156         0.974066          0.963681             2.02591            0.0765744
    2019-08-03 20:49:31  4:42:49.080  4695 obs/sec      9.739     10            243475     0.250608         0.21752             0.748782       0.971184        0.955887           2                0.0836996                        0.237098           0.194377              0.775101         0.976598          0.958123             2.02591            0.072689
    2019-08-03 20:49:37  4:42:54.517  4711 obs/sec      10.7122   11            267805     0.242958         0.204111            0.763886       0.973981        0.962945           2                0.0752097                        0.230701           0.185993              0.787074         0.978513          0.968778             2.02591            0.0678323
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005416270960607401
C438        0.7337601780891418     0.7337601780891418   0.003974243944634334
C374        0.706823468208313      0.706823468208313    0.0038283474251324945
C322        0.6561824083328247     0.6561824083328247   0.0035540617231145065
C88         0.639430046081543      0.639430046081543    0.0034633263899313134
---         ---                    ---                  ---
C780        0.09308312833309174    0.09308312833309174  0.0005041634449130168
C873        0.09303482621908188    0.09303482621908188  0.0005039018275755692
C839        0.09123063087463379    0.09123063087463379  0.000494129816724172
C765        0.09025619924068451    0.09025619924068451  0.0004888520309621153
C829        0.08766647428274155    0.08766647428274155  0.0004748253788764486

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_103

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.006445290702300572    0.0054677389562129974  0.0         0.01962651940079609   0.07549622654914856  0.09841919955103257    0.17975610494613647
    3        2        Softmax                      0.0   0.0   0.00028433844937580943  8.179200813174248e-05  0.0         -0.01578352323076615  0.38526058197021484  0.0056205372028765715  0.14491307735443115


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05232778155258025
RMSE: 0.22875266458028473
LogLoss: 0.1981143611354631
Mean Per-Class Error: 0.05737864612972765
AUC: 0.9794772332298883
pr_auc: 0.8035922950867949
Gini: 0.9589544664597767
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5049904366443471: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4695  340   0.0675   (340.0/5035.0)
1      237   4752  0.0475   (237.0/4989.0)
Total  4932  5092  0.0576   (577.0/10024.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.50499      0.942764  208
max f2                       0.388429     0.953901  242
max f0point5                 0.63195      0.948171  168
max accuracy                 0.5519       0.942638  193
max precision                0.999949     0.996571  0
max recall                   3.96772e-05  1         399
max specificity              0.999949     0.999404  0
max absolute_mcc             0.5519       0.885289  193
max min_per_class_accuracy   0.537975     0.942403  197
max mean_per_class_accuracy  0.5519       0.942621  193
Gains/Lift Table: Avg response rate: 49.77 %, avg score: 50.16 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100758                   1                  2.00922     2.00922            1                1            1                           1                   0.0202445       0.0202445                  100.922   100.922
    2        0.0200519                   1                  1.98913     1.99922            0.99             1            0.995025                    1                   0.0198437       0.0400882                  98.9128   99.9224
    3        0.0300279                   0.999999           2.00922     2.00255            1                0.999999     0.996678                    1                   0.0200441       0.0601323                  100.922   100.255
    4        0.040004                    0.999996           2.00922     2.00421            1                0.999997     0.997506                    0.999999            0.0200441       0.0801764                  100.922   100.421
    5        0.0500798                   0.999985           2.00922     2.00522            1                0.999991     0.998008                    0.999998            0.0202445       0.100421                   100.922   100.522
    6        0.10006                     0.999532           2.0012      2.00321            0.996008         0.999835     0.997009                    0.999916            0.10002         0.200441                   100.12    100.321
    7        0.15004                     0.996941           1.97714     1.99453            0.984032         0.998551     0.992686                    0.999462            0.0988174       0.299258                   97.7137   99.4525
    8        0.20002                     0.989272           1.98917     1.99319            0.99002          0.993676     0.99202                     0.998016            0.0994187       0.398677                   98.9168   99.3187
    9        0.29998                     0.936485           1.95307     1.97982            0.972056         0.96795      0.985367                    0.987997            0.19523         0.593907                   95.3074   97.982
    10       0.40004                     0.796851           1.88702     1.95661            0.939182         0.874602     0.973815                    0.959634            0.188815        0.782722                   88.7024   95.661
    11       0.5                         0.531112           1.6182      1.88896            0.805389         0.675954     0.940144                    0.902921            0.161756        0.944478                   61.8204   88.8956
    12       0.59996                     0.211457           0.391016    1.63938            0.194611         0.361081     0.815929                    0.812644            0.039086        0.983564                   -60.8984  63.9382
    13       0.70002                     0.0504715          0.0981573   1.41908            0.0488534        0.117829     0.706285                    0.713328            0.00982161      0.993385                   -90.1843  41.9082
    14       0.79998                     0.00496981         0.038099    1.24652            0.0189621        0.0209998    0.620402                    0.62682             0.00380838      0.997194                   -96.1901  24.6523
    15       0.89994                     7.19062e-05        0.0200521   1.11029            0.00998004       0.00141251   0.552599                    0.557353            0.00200441      0.999198                   -97.9948  11.0294
    16       1                           7.14374e-23        0.00801284  1                  0.00398804       1.05491e-05  0.497706                    0.501585            0.000801764     1                          -99.1987  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.049601226930575185
RMSE: 0.2227133290366232
LogLoss: 0.1868795703730784
Mean Per-Class Error: 0.05171169491653371
AUC: 0.9817758684034597
pr_auc: 0.7810394423060223
Gini: 0.9635517368069193
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5579472500891288: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2983  145   0.0464   (145.0/3128.0)
1      174   2875  0.0571   (174.0/3049.0)
Total  3157  3020  0.0516   (319.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.557947     0.947438  188
max f2                       0.425864     0.956978  227
max f0point5                 0.651307     0.953111  158
max accuracy                 0.557947     0.948357  188
max precision                0.998072     0.997613  3
max recall                   2.94873e-05  1         399
max specificity              0.999916     0.999361  0
max absolute_mcc             0.557947     0.896724  188
max min_per_class_accuracy   0.529743     0.94654   195
max mean_per_class_accuracy  0.557947     0.948288  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.87 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323     2.00957            0.983871         1            0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999998           2.02591     2.01502            1                0.999999     0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999993           2.02591     2.01774            1                0.999996     0.995968                    0.999999            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999978           2.02591     2.01935            1                0.999987     0.996764                    0.999996            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999493           2.01935     2.01935            0.996764         0.999828     0.996764                    0.999912            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.996607           2.01935     2.01935            0.996764         0.99835      0.996764                    0.999391            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.9891             2.00624     2.01608            0.990291         0.993499     0.995146                    0.997918            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.935858           1.95696     1.99639            0.965964         0.968226     0.985429                    0.988031            0.195474        0.598885                   95.6957   99.6391
    10       0.400032                    0.788618           1.93412     1.98082            0.954693         0.874069     0.977742                    0.959529            0.193506        0.792391                   93.4121   98.0817
    11       0.500081                    0.506994           1.6063      1.90589            0.79288          0.664263     0.940758                    0.900457            0.160708        0.953099                   60.6304   90.589
    12       0.599968                    0.20054            0.318498    1.64161            0.157212         0.342596     0.810308                    0.80758             0.0318137       0.984913                   -68.1502  64.161
    13       0.700016                    0.0544316          0.0753979   1.41776            0.0372168        0.117578     0.699815                    0.708963            0.00754346      0.992457                   -92.4602  41.7762
    14       0.799903                    0.00576963         0.0525358   1.24728            0.0259319        0.0227601    0.615665                    0.623275            0.00524762      0.997704                   -94.7464  24.7282
    15       0.899951                    0.000104542        0.0163909   1.11044            0.00809061       0.00165959   0.54812                     0.554169            0.00163988      0.999344                   -98.3609  11.0442
    16       1                           9.59878e-26        0.00655634  1                  0.00323625       1.49597e-05  0.493605                    0.498727            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:03:11  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:03:15  1:56:33.040  7505 obs/sec      1         1             25000      0.305519         0.378472            0.626624       0.942369        0.706578           1.98933          0.122007                         0.295579           0.34926               0.650475         0.9478            0.718289             1.99323            0.11219
    2019-08-03 18:03:22  1:56:40.318  7534 obs/sec      3         3             75000      0.265859         0.257282            0.717269       0.963881        0.802892           2.00922          0.0905826                        0.261766           0.247167              0.725869         0.965902          0.800073             2.02591            0.0846689
    2019-08-03 18:03:29  1:56:47.011  7811 obs/sec      5         5             125000     0.250509         0.226489            0.748976       0.971316        0.816349           2.00922          0.0770152                        0.246432           0.218049              0.757045         0.973246          0.844326             2.02591            0.0702606
    2019-08-03 18:03:38  1:56:56.362  8113 obs/sec      8         8             200000     0.236506         0.207846            0.776255       0.976866        0.822388           2.00922          0.0640463                        0.230993           0.197138              0.786534         0.978922          0.831179             2.02591            0.0571475
    2019-08-03 18:03:45  1:57:02.851  8206 obs/sec      10        10            250000     0.228753         0.198114            0.790684       0.979477        0.803592           2.00922          0.0575619                        0.222713           0.18688               0.801563         0.981776          0.781039             2.02591            0.0516432
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C35         1.0                    1.0                  0.003292322141278367
C36         0.9976999759674072     0.9976999759674072   0.003284749721230389
C28         0.9682220816612244     0.9682220816612244   0.00318769899712788
C250        0.9137997627258301     0.9137997627258301   0.0030085231915171684
C34         0.9095568656921387     0.9095568656921387   0.002994554207669982
---         ---                    ---                  ---
C637        0.2033633440732956     0.2033633440732956   0.0006695376404169219
C985        0.20310458540916443    0.20310458540916443  0.0006686857235377551
C467        0.20286406576633453    0.20286406576633453  0.0006678938553922539
C765        0.19033347070217133    0.19033347070217133  0.000626639099819116
C564        0.1811813861131668     0.1811813861131668   0.0005965074890878839

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_127

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.028579248770827282   0.04763828217983246     0.0         0.004561847926627307  0.12444114685058594  -0.027818344003457503  0.14657336473464966
    3        2        Softmax                 0.0   0.0   0.0017701685428619385  0.00023706641513854265  0.0         0.062321712750417646  0.4989205598831177   -0.001073708464204709  0.15422523021697998


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0612727304996453
RMSE: 0.2475332916996122
LogLoss: 0.2103625589621459
Mean Per-Class Error: 0.08070823294708529
AUC: 0.9725415129004297
pr_auc: 0.9543653643322517
Gini: 0.9450830258008593
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4407145623014536: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4580  476   0.0941   (476.0/5056.0)
1      334   4631  0.0673   (334.0/4965.0)
Total  4914  5107  0.0808   (810.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.440715     0.919579  220
max f2                       0.165085     0.939554  301
max f0point5                 0.777013     0.92982   124
max accuracy                 0.440715     0.91917   220
max precision                0.998191     1         0
max recall                   0.00203677   1         398
max specificity              0.998191     1         0
max absolute_mcc             0.440715     0.838705  220
max min_per_class_accuracy   0.505699     0.918026  203
max mean_per_class_accuracy  0.440715     0.919292  220
Gains/Lift Table: Avg response rate: 49.55 %, avg score: 49.29 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   0.997393           2.01833    2.01833            1                0.99809     1                           0.99809             0.0203424       0.0203424                  101.833   101.833
    2        0.0200579                   0.99644            1.99815    2.00829            0.99             0.996902    0.995025                    0.997499            0.0199396       0.040282                   99.8145   100.829
    3        0.0300369                   0.995614           2.01833    2.01162            1                0.99599     0.996678                    0.996998            0.020141        0.060423                   101.833   101.162
    4        0.040016                    0.994661           2.01833    2.0133             1                0.995132    0.997506                    0.996533            0.020141        0.0805639                  101.833   101.33
    5        0.0500948                   0.99376            2.01833    2.01431            1                0.994184    0.998008                    0.99606             0.0203424       0.100906                   101.833   101.431
    6        0.10009                     0.988344           2.0143     2.0143             0.998004         0.991197    0.998006                    0.993631            0.100705        0.201611                   101.43    101.43
    7        0.150085                    0.981857           1.98207    2.00357            0.982036         0.985052    0.992686                    0.990773            0.0990937       0.300705                   98.2071   100.357
    8        0.20008                     0.973908           1.99013    2.00021            0.986028         0.977829    0.991022                    0.987539            0.0994965       0.400201                   99.0128   100.021
    9        0.30007                     0.944413           1.96797    1.98947            0.97505          0.961851    0.9857                      0.978979            0.196777        0.596979                   96.7971   98.9466
    10       0.40006                     0.847288           1.83503    1.95087            0.909182         0.906766    0.966575                    0.96093             0.183484        0.780463                   83.5027   95.0866
    11       0.50005                     0.485365           1.42008    1.84473            0.703593         0.699522    0.913989                    0.908659            0.141994        0.922457                   42.0081   84.473
    12       0.60004                     0.13189            0.555947   1.62997            0.275449         0.275425    0.807584                    0.803138            0.0555891       0.978046                   -44.4053  62.9969
    13       0.70003                     0.0391469          0.143015   1.41758            0.0708583        0.0725681   0.702352                    0.698785            0.0143001       0.992346                   -85.6985  41.7577
    14       0.80002                     0.0150605          0.0543861  1.2472             0.0269461        0.0247694   0.617937                    0.614544            0.00543807      0.997784                   -94.5614  24.7199
    15       0.90001                     0.00558268         0.0181287  1.11065            0.00898204       0.00953526  0.550283                    0.547328            0.00181269      0.999597                   -98.1871  11.0651
    16       1                           0.000404427        0.0040286  1                  0.00199601       0.00321935  0.49546                     0.492923            0.00040282      1                          -99.5971  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05347522542881219
RMSE: 0.23124710901719872
LogLoss: 0.1871321052572991
Mean Per-Class Error: 0.06889643076133312
AUC: 0.9784005845696757
pr_auc: 0.9644744659237313
Gini: 0.9568011691393514
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4295120661446294: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2856  272   0.087    (272.0/3128.0)
1      155   2894  0.0508   (155.0/3049.0)
Total  3011  3166  0.0691   (427.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.429512     0.931295  222
max f2                       0.242594     0.947746  276
max f0point5                 0.750334     0.940119  133
max accuracy                 0.438566     0.930873  219
max precision                0.998335     1         0
max recall                   0.00542428   1         392
max specificity              0.998335     1         0
max absolute_mcc             0.429512     0.862408  222
max min_per_class_accuracy   0.525604     0.929348  197
max mean_per_class_accuracy  0.429512     0.931104  222
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.30 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.997436           2.02591    2.02591            1                0.998094    1                           0.998094            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.996528           2.02591    2.02591            1                0.996949    1                           0.997521            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.995872           2.02591    2.02591            1                0.9962      1                           0.997081            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.994902           2.02591    2.02591            1                0.995338    1                           0.996645            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.99394            2.02591    2.02591            1                0.994457    1                           0.996213            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.988954           2.02591    2.02591            1                0.991472    1                           0.993843            0.101345        0.202689                   102.591   102.591
    7        0.150073                    0.982223           2.0128     2.02154            0.993528         0.985858    0.997843                    0.991181            0.100689        0.303378                   101.28    102.154
    8        0.200097                    0.973407           1.99968    2.01608            0.987055         0.977781    0.995146                    0.987831            0.100033        0.403411                   99.9685   101.608
    9        0.299984                    0.946582           1.98651    2.00623            0.980551         0.962357    0.990286                    0.979349            0.198426        0.601837                   98.6508   100.623
    10       0.400032                    0.855311           1.88823    1.97672            0.932039         0.910913    0.975718                    0.962233            0.188914        0.790751                   88.8227   97.6718
    11       0.500081                    0.493899           1.44895    1.87113            0.71521          0.70854     0.9236                      0.911478            0.144966        0.935717                   44.8952   87.113
    12       0.599968                    0.119759           0.456404   1.6356             0.225284         0.270951    0.807339                    0.804839            0.0455887       0.981305                   -54.3596  63.5597
    13       0.700016                    0.0361988          0.118014   1.4187             0.0582524        0.0665778   0.700278                    0.699324            0.0118071       0.993112                   -88.1986  41.8699
    14       0.799903                    0.014057           0.0459688  1.24728            0.0226904        0.0232157   0.615665                    0.614896            0.00459167      0.997704                   -95.4031  24.7282
    15       0.899951                    0.00515429         0.0229472  1.11117            0.0113269        0.00879733  0.54848                     0.547515            0.00229583      1                          -97.7053  11.1171
    16       1                           0.000331858        0          1                  0                0.00304281  0.493605                    0.493042            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:30:46  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:30:52  2:24:09.465  4878 obs/sec      1         1             25000      0.299271         0.296481            0.641717       0.946436        0.917265           2.01833          0.120846                         0.289556           0.277114              0.664574         0.953384          0.924759             2.02591            0.110895
    2019-08-03 18:30:57  2:24:15.259  4743 obs/sec      2         2             50000      0.285398         0.272036            0.674166       0.954598        0.937232           2.01833          0.111167                         0.272338           0.250802              0.70328          0.961827          0.946983             2.02591            0.0953537
    2019-08-03 18:31:03  2:24:20.883  4751 obs/sec      3         3             75000      0.280494         0.264035            0.685266       0.95731         0.945795           2.01833          0.105079                         0.267546           0.242363              0.71363          0.96456           0.943929             2.02591            0.0930873
    2019-08-03 18:31:09  2:24:26.590  4735 obs/sec      4         4             100000     0.276232         0.25663             0.694757       0.959361        0.939723           2.01833          0.103582                         0.262597           0.234927              0.724127         0.966115          0.942092             2.02591            0.0895257
    2019-08-03 18:31:14  2:24:32.218  4743 obs/sec      5         5             125000     0.274181         0.253687            0.699275       0.960312        0.94661            2.01833          0.100689                         0.260283           0.230878              0.728967         0.967266          0.957699             2.02591            0.0903351
    2019-08-03 18:31:20  2:24:37.860  4746 obs/sec      6         6             150000     0.273199         0.252461            0.701424       0.961048        0.944771           2.01833          0.0988923                        0.258503           0.227675              0.732661         0.968201          0.948035             2.02591            0.0882305
    2019-08-03 18:31:26  2:24:43.452  4753 obs/sec      7         7             175000     0.267041         0.242946            0.714733       0.963585        0.948529           2.01833          0.0933041                        0.252563           0.219008              0.744806         0.970368          0.955609             2.02591            0.0811073
    2019-08-03 18:31:31  2:24:48.907  4780 obs/sec      8         8             200000     0.262145         0.233441            0.725098       0.96649         0.958083           2.01833          0.0903103                        0.246915           0.210717              0.756092         0.972645          0.962639             2.02591            0.0780314
    2019-08-03 18:31:37  2:24:54.627  4775 obs/sec      9         9             225000     0.253083         0.218982            0.743775       0.97036         0.95694            2.01833          0.0865183                        0.237657           0.196038              0.774039         0.976136          0.967641             2.02591            0.074146
    2019-08-03 18:31:42  2:24:59.966  4805 obs/sec      10        10            250000     0.247533         0.210363            0.754889       0.972542        0.954365           2.01833          0.0808303                        0.231247           0.187132              0.786064         0.978401          0.964474             2.02591            0.0691274
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0054185941313330595
C438        0.7607470750808716     0.7607470750808716   0.004122179636462001
C374        0.7256251573562622     0.7256251573562622   0.0039318682191982705
C322        0.6480906009674072     0.6480906009674072   0.0035117399269741084
C863        0.585292637348175      0.585292637348175    0.00317146324984727
---         ---                    ---                  ---
C981        0.09920260310173035    0.09920260310173035  0.0005375386429799988
C828        0.09846054017543793    0.09846054017543793  0.0005335177051625109
C839        0.09431616961956024    0.09431616961956024  0.0005110610431903625
C889        0.0931132361292839     0.0931132361292839   0.0005045428348395671
C912        0.08402606844902039    0.08402606844902039  0.0004553031613768518

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_83

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0072125230370537405  0.0063020940870046616  0.0         0.019452870389826557   0.07470837235450745  0.10670810198939946     0.1547512412071228
    3        2        Softmax                      0.0   0.0   0.0003111616452429189  8.119671838358045e-05  0.0         -0.005077380904367601  0.36361217498779297  0.00015612966645223159  0.12837785482406616


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.052231602337432625
RMSE: 0.22854234254823028
LogLoss: 0.20240326838790063
Mean Per-Class Error: 0.05573126508874282
AUC: 0.9781803100536439
pr_auc: 0.8140857136414248
Gini: 0.9563606201072878
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5129685415834102: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4676  269   0.0544   (269.0/4945.0)
1      290   4792  0.0571   (290.0/5082.0)
Total  4966  5061  0.0557   (559.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.512969     0.944888  203
max f2                       0.369149     0.954116  245
max f0point5                 0.580851     0.952603  183
max accuracy                 0.512969     0.944251  203
max precision                0.999958     0.996407  0
max recall                   2.74737e-05  1         399
max specificity              0.999958     0.999393  0
max absolute_mcc             0.512969     0.888494  203
max min_per_class_accuracy   0.510174     0.943377  204
max mean_per_class_accuracy  0.512969     0.944269  203
Gains/Lift Table: Avg response rate: 50.68 %, avg score: 50.27 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   1                  1.97304     1.97304            1                1            1                           1                   0.0198741       0.0198741                  97.3042   97.3042
    2        0.0200459                   1                  1.97304     1.97304            1                1            1                           1                   0.0196773       0.0395514                  97.3042   97.3042
    3        0.0300189                   0.999999           1.95331     1.96649            0.99             0.999999     0.996678                    1                   0.0194805       0.0590319                  95.3312   96.6487
    4        0.0400918                   0.999993           1.95351     1.96323            0.990099         0.999997     0.995025                    0.999999            0.0196773       0.0787092                  95.3507   96.3226
    5        0.0500648                   0.999982           1.97304     1.96518            1                0.999989     0.996016                    0.999997            0.0196773       0.0983865                  97.3042   96.5181
    6        0.10003                     0.999421           1.96123     1.96321            0.994012         0.999804     0.995015                    0.999901            0.0979929       0.196379                   96.1227   96.3206
    7        0.149995                    0.996617           1.95335     1.95992            0.99002          0.998275     0.993351                    0.999359            0.0975994       0.293979                   95.3351   95.9923
    8        0.20006                     0.988898           1.91802     1.94944            0.972112         0.993297     0.988036                    0.997842            0.0960252       0.390004                   91.8017   94.9436
    9        0.29999                     0.937614           1.93366     1.94418            0.98004          0.967487     0.985372                    0.98773             0.193231        0.583235                   93.366    94.4181
    10       0.40002                     0.803819           1.88059     1.92828            0.953141         0.880653     0.977312                    0.960954            0.188115        0.77135                    88.0586   92.8279
    11       0.50005                     0.530208           1.66223     1.87506            0.842473         0.683778     0.950339                    0.905508            0.166273        0.937623                   66.2234   87.5059
    12       0.59998                     0.207261           0.413512    1.63163            0.209581         0.359536     0.826961                    0.814573            0.0413223       0.978945                   -58.6488  63.163
    13       0.70001                     0.0499747          0.112127    1.4145             0.0568295        0.115545     0.716911                    0.714684            0.0112161       0.990161                   -88.7873  41.4496
    14       0.79994                     0.00527951         0.0689186   1.2464             0.0349301        0.0221238    0.631717                    0.628168            0.00688705      0.997048                   -93.1081  24.6404
    15       0.89997                     9.77528e-05        0.0216385   1.11027            0.0109671        0.00156611   0.562722                    0.558522            0.0021645       0.999213                   -97.8361  11.0273
    16       1                           9.66109e-27        0.00786856  1                  0.00398804       1.46824e-05  0.506832                    0.502655            0.000787092     1                          -99.2131  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05050235413244069
RMSE: 0.22472728835733477
LogLoss: 0.1883787474483068
Mean Per-Class Error: 0.05311718067808069
AUC: 0.980781401641895
pr_auc: 0.8132445392503633
Gini: 0.96156280328379
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5147653388395655: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2966  162   0.0518   (162.0/3128.0)
1      166   2883  0.0544   (166.0/3049.0)
Total  3132  3045  0.0531   (328.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.514765     0.946177  198
max f2                       0.370614     0.954011  239
max f0point5                 0.567835     0.949507  183
max accuracy                 0.529037     0.9469    194
max precision                0.995742     0.997914  7
max recall                   5.51327e-05  1         399
max specificity              0.999956     0.999361  0
max absolute_mcc             0.529037     0.893795  194
max min_per_class_accuracy   0.508631     0.946292  200
max mean_per_class_accuracy  0.514765     0.946883  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.08 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999997           1.99323     2.01502            0.983871         0.999999     0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999991           1.99323     2.00957            0.983871         0.999994     0.991935                    0.999998            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999972           2.02591     2.0128             1                0.999984     0.993528                    0.999996            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999386           2.02591     2.01935            1                0.999785     0.996764                    0.99989             0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.996136           2.02591     2.02154            1                0.998143     0.997843                    0.999308            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.987235           1.98657     2.0128             0.980583         0.992191     0.993528                    0.997529            0.0993768       0.402755                   98.6572   101.28
    9        0.299984                    0.927896           1.96024     1.9953             0.967585         0.962987     0.984889                    0.986027            0.195802        0.598557                   96.024    99.5297
    10       0.400032                    0.780064           1.94396     1.98246            0.959547         0.862436     0.978551                    0.955117            0.19449         0.793047                   94.3956   98.2457
    11       0.500081                    0.485548           1.5768      1.9013             0.778317         0.647145     0.938491                    0.893503            0.157757        0.950804                   57.6801   90.1299
    12       0.599968                    0.177891           0.331632    1.63997            0.163695         0.31519      0.809498                    0.797221            0.0331256       0.983929                   -66.8368  63.997
    13       0.700016                    0.0463708          0.095067    1.41917            0.0469256        0.10324      0.700509                    0.698035            0.00951132      0.99344                    -90.4933  41.9168
    14       0.799903                    0.00451511         0.0459688   1.24769            0.0226904        0.0199056    0.615867                    0.613355            0.00459167      0.998032                   -95.4031  24.7692
    15       0.899951                    8.28966e-05        0.0163909   1.11081            0.00809061       0.00126807   0.5483                      0.545308            0.00163988      0.999672                   -98.3609  11.0807
    16       1                           9.66109e-27        0.00327817  1                  0.00161812       1.18099e-05  0.493605                    0.490752            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:40:19  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:40:22  1:33:40.038  7675 obs/sec      1         1             25000      0.299403         0.35546             0.641365       0.946419        0.739898           1.93397          0.116186                         0.297212           0.343327              0.646602         0.948211          0.713892             2.02591            0.110571
    2019-08-03 17:40:29  1:33:47.034  7765 obs/sec      3         3             75000      0.265878         0.260178            0.717183       0.962844        0.812741           1.97304          0.0867657                        0.26238            0.244262              0.724581         0.966042          0.813593             2.02591            0.0835357
    2019-08-03 17:40:36  1:33:53.639  8008 obs/sec      5         5             125000     0.250643         0.231827            0.748664       0.970398        0.844464           1.97304          0.0738007                        0.24627            0.216551              0.757364         0.973847          0.854785             2.02591            0.0699369
    2019-08-03 17:40:45  1:34:02.947  8241 obs/sec      8         8             200000     0.238521         0.213859            0.772389       0.97541         0.815845           1.97304          0.0624314                        0.233028           0.199158              0.782757         0.978742          0.829305             2.02591            0.0571475
    2019-08-03 17:40:51  1:34:09.382  8319 obs/sec      10        10            250000     0.228542         0.202403            0.791035       0.97818         0.814086           1.97304          0.0557495                        0.224727           0.188379              0.797958         0.980781          0.813245             2.02591            0.0531002
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0034477660730429993
C28         0.9581401944160461     0.9581401944160461   0.0033034432555264673
C35         0.9153493046760559     0.9153493046760559   0.0031559102776456053
C47         0.9040094614028931     0.9040094614028931   0.0031168131507347697
C34         0.9004148244857788     0.9004148244857788   0.003104419683527035
---         ---                    ---                  ---
C476        0.19183820486068726    0.19183820486068726  0.0006614132542321501
C649        0.18936626613140106    0.18936626613140106  0.0006528905877466761
C628        0.18627992272377014    0.18627992272377014  0.0006422495976560863
C446        0.18608754873275757    0.18608754873275757  0.0006415863371365373
C342        0.17315055429935455    0.17315055429935455  0.0005969826066419043

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_216

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.006847500566882259   0.006476948037743568   0.0         0.019136518255083505  0.07469326257705688  0.11166575986030218    0.15126186609268188
    3        2        Softmax                      0.0   0.0   0.0003094176840363616  6.945646600797772e-05  0.0         0.019680736544614774  0.35989582538604736  0.0007988204700251633  0.14392006397247314


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.049830259181978205
RMSE: 0.22322692306704003
LogLoss: 0.18811456511482239
Mean Per-Class Error: 0.053419771206117295
AUC: 0.9814850767533807
pr_auc: 0.7919982804076909
Gini: 0.9629701535067614
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5193795878035803: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4765  277   0.0549   (277.0/5042.0)
1      258   4713  0.0519   (258.0/4971.0)
Total  5023  4990  0.0534   (535.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.51938      0.946291  200
max f2                       0.393818     0.955754  237
max f0point5                 0.597591     0.952183  177
max accuracy                 0.51938      0.946569  200
max precision                0.999908     0.995754  0
max recall                   4.45574e-05  1         399
max specificity              0.999908     0.999207  0
max absolute_mcc             0.51938      0.893143  200
max min_per_class_accuracy   0.524635     0.946087  198
max mean_per_class_accuracy  0.51938      0.94658   200
Gains/Lift Table: Avg response rate: 49.65 %, avg score: 49.67 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   1                  2.01428     2.01428            1                1            1                           1                   0.0203178       0.0203178                  101.428   101.428
    2        0.0200739                   0.999999           1.99414     2.00426            0.99             1            0.995025                    1                   0.0199155       0.0402334                  99.414    100.426
    3        0.0300609                   0.999998           2.01428     2.00759            1                0.999999     0.996678                    1                   0.0201167       0.06035                    101.428   100.759
    4        0.0400479                   0.999992           1.99414     2.00424            0.99             0.999995     0.995012                    0.999999            0.0199155       0.0802655                  99.414    100.424
    5        0.050035                    0.999974           2.01428     2.00624            1                0.999984     0.996008                    0.999996            0.0201167       0.100382                   101.428   100.624
    6        0.10007                     0.999329           2.00624     2.00624            0.996008         0.999762     0.996008                    0.999879            0.100382        0.200764                   100.624   100.624
    7        0.150005                    0.99624            2.0022      2.0049             0.994            0.998121     0.99534                     0.999294            0.0999799       0.300744                   100.22    100.49
    8        0.20004                     0.987411           1.98614     2.0002             0.986028         0.992415     0.99301                     0.997573            0.0993764       0.400121                   98.6139   100.02
    9        0.30001                     0.93105            1.97404     1.99148            0.98002          0.964086     0.988682                    0.986414            0.197345        0.597465                   97.4037   99.1485
    10       0.39998                     0.7933             1.90763     1.97053            0.947053         0.869937     0.978277                    0.957302            0.190706        0.788171                   90.7633   97.0527
    11       0.50005                     0.511249           1.60821     1.89802            0.798403         0.667845     0.942281                    0.899376            0.160933        0.949105                   60.821    89.802
    12       0.60002                     0.198071           0.356172    1.64113            0.176823         0.340461     0.814747                    0.806254            0.0356065       0.984711                   -64.3828  64.1131
    13       0.69999                     0.044022           0.0865276   1.41911            0.042957         0.109192     0.704523                    0.706703            0.00865017      0.993361                   -91.3472  41.9108
    14       0.79996                     0.0042582          0.052319    1.2483             0.025974         0.0191305    0.619725                    0.620777            0.00523034      0.998592                   -94.7681  24.8302
    15       0.89993                     5.79164e-05        0.0100614   1.11075            0.004995         0.00113539   0.551437                    0.551944            0.00100583      0.999598                   -98.9939  11.075
    16       1                           7.07338e-27        0.00402052  1                  0.00199601       7.52938e-06  0.496455                    0.496711            0.000402334     1                          -99.5979  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.050247512282717566
RMSE: 0.22415956879579682
LogLoss: 0.18856166159889473
Mean Per-Class Error: 0.052874501220055325
AUC: 0.9816011329025742
pr_auc: 0.8116753878631181
Gini: 0.9632022658051484
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4987675698464473: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2947  181   0.0579   (181.0/3128.0)
1      146   2903  0.0479   (146.0/3049.0)
Total  3093  3084  0.0529   (327.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.498768     0.946682  204
max f2                       0.346306     0.954493  251
max f0point5                 0.597533     0.953498  174
max accuracy                 0.508479     0.947062  201
max precision                0.994826     0.998002  7
max recall                   4.42735e-05  1         399
max specificity              0.999941     0.999361  0
max absolute_mcc             0.498768     0.894179  204
max min_per_class_accuracy   0.516031     0.946611  199
max mean_per_class_accuracy  0.498768     0.947125  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.34 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323     2.00957            0.983871         1            0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999997           2.02591     2.01502            1                0.999998     0.994624                    0.999999            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999989           1.99323     2.00957            0.983871         0.999994     0.991935                    0.999998            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999968           2.02591     2.0128             1                0.99998      0.993528                    0.999994            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999318           2.02591     2.01935            1                0.999752     0.996764                    0.999873            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.996042           2.02591     2.02154            1                0.998131     0.997843                    0.999292            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.986114           1.99313     2.01444            0.983819         0.991907     0.994337                    0.997446            0.0997048       0.403083                   99.3128   101.444
    9        0.299984                    0.926971           1.98979     2.00623            0.982172         0.962389     0.990286                    0.985773            0.198754        0.601837                   98.9792   100.623
    10       0.400032                    0.780151           1.91445     1.98328            0.944984         0.862029     0.978956                    0.954825            0.191538        0.793375                   91.4452   98.3277
    11       0.500081                    0.494586           1.58991     1.90458            0.78479          0.650456     0.94011                     0.893931            0.159069        0.952443                   58.9913   90.4579
    12       0.599968                    0.192854           0.311931    1.63942            0.153971         0.33299      0.809228                    0.800542            0.0311578       0.983601                   -68.8069  63.9424
    13       0.700016                    0.0457739          0.0852325   1.41729            0.0420712        0.10955      0.699584                    0.701783            0.00852739      0.992129                   -91.4768  41.7294
    14       0.799903                    0.00509466         0.0591027   1.24769            0.0291734        0.019996     0.615867                    0.616646            0.00590357      0.998032                   -94.0897  24.7692
    15       0.899951                    6.85673e-05        0.00983452  1.11008            0.00485437       0.00136725   0.54794                     0.548245            0.000983929     0.999016                   -99.0165  11.0078
    16       1                           7.07338e-27        0.00983452  1                  0.00485437       9.91802e-06  0.493605                    0.493395            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:29:21  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:29:25  4:22:42.750  7411 obs/sec      1         1             25000      0.300263         0.356495            0.63935        0.946233        0.73057            2.01428          0.115849                         0.296518           0.344145              0.64825          0.948279          0.729118             2.02591            0.111705
    2019-08-03 20:29:32  4:22:49.707  7716 obs/sec      3         3             75000      0.264068         0.252685            0.721059       0.964229        0.795598           2.01428          0.0890842                        0.260233           0.242537              0.72907          0.966566          0.831719             2.02591            0.0843452
    2019-08-03 20:29:38  4:22:56.365  7959 obs/sec      5         5             125000     0.248337         0.222537            0.753303       0.972492        0.838768           2.01428          0.0724059                        0.245576           0.21649               0.758731         0.974298          0.834749             2.02591            0.0704225
    2019-08-03 20:29:48  4:23:05.911  8138 obs/sec      8         8             200000     0.235058         0.203434            0.77898        0.97786         0.825174           2.01428          0.0608209                        0.233263           0.198729              0.782318         0.979015          0.820667             2.02591            0.0587664
    2019-08-03 20:29:54  4:23:12.249  8270 obs/sec      10        10            250000     0.223227         0.188115            0.800669       0.981485        0.791998           2.01428          0.0534305                        0.22416            0.188562              0.798977         0.981601          0.811675             2.02591            0.0529383
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0032487294125212343
C25         0.9757771492004395     0.9757771492004395   0.0031700359246735884
C35         0.9565935134887695     0.9565935134887695   0.0031077134830979937
C36         0.9368556141853333     0.9368556141853333   0.003043590389089538
C250        0.9094926714897156     0.9094926714897156   0.0029546955923411516
---         ---                    ---                  ---
C573        0.20096483826637268    0.20096483826637268  0.0006528803809585378
C389        0.20036835968494415    0.20036835968494415  0.000650942583447112
C464        0.20008181035518646    0.20008181035518646  0.0006500116622113899
C780        0.19812455773353577    0.19812455773353577  0.000643653078051699
C599        0.18583528697490692    0.18583528697490692  0.0006037285626797044

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_56

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 263,076 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.031908467712875734   0.06128336489200592   0.0         -0.004709662206092459  0.12488159537315369  0.018668116345563698  0.15828227996826172
    3        2        Softmax                 0.0   0.0   0.0019744289866139297  0.000584528548642993  0.0         -0.0294640296488069    0.5473639965057373   0.003409991182223071  0.14404815435409546


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.058925717569389406
RMSE: 0.2427461999072064
LogLoss: 0.20431635722216843
Mean Per-Class Error: 0.07588434687377732
AUC: 0.9742587012241468
pr_auc: 0.9663799874186858
Gini: 0.9485174024482936
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49098589481786525: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4579  455   0.0904   (455.0/5034.0)
1      309   4685  0.0619   (309.0/4994.0)
Total  4888  5140  0.0762   (764.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.490986     0.92461   207
max f2                       0.282384     0.942559  267
max f0point5                 0.753859     0.933993  134
max accuracy                 0.565945     0.924112  188
max precision                0.99817      1         0
max recall                   0.00139581   1         399
max specificity              0.99817      1         0
max absolute_mcc             0.565945     0.848226  188
max min_per_class_accuracy   0.570596     0.923719  187
max mean_per_class_accuracy  0.565945     0.924116  188
Gains/Lift Table: Avg response rate: 49.80 %, avg score: 50.84 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   0.996621           2.00801    2.00801            1                0.997665    1                           0.997665            0.0202243       0.0202243                  100.801   100.801
    2        0.0200439                   0.99535            2.00801    2.00801            1                0.995904    1                           0.996789            0.020024        0.0402483                  100.801   100.801
    3        0.030016                    0.994369           2.00801    2.00801            1                0.994817    1                           0.996134            0.020024        0.0602723                  100.801   100.801
    4        0.0401875                   0.993625           2.00801    2.00801            1                0.994009    1                           0.995596            0.0204245       0.0806968                  100.801   100.801
    5        0.0500598                   0.992784           2.00801    2.00801            1                0.993191    1                           0.995122            0.0198238       0.100521                   100.801   100.801
    6        0.10002                     0.988455           1.99198    2                  0.992016         0.99068     0.996012                    0.992903            0.0995194       0.20004                    99.1978   100
    7        0.15008                     0.983139           1.98801    1.996              0.99004          0.985935    0.99402                     0.990579            0.0995194       0.299559                   98.801    99.6002
    8        0.20004                     0.97679            1.99198    1.995              0.992016         0.980156    0.993519                    0.987976            0.0995194       0.399079                   99.1978   99.4997
    9        0.30006                     0.954978           1.95396    1.98132            0.973081         0.967704    0.986707                    0.981219            0.195435        0.594513                   95.3956   98.1316
    10       0.39998                     0.885978           1.86172    1.95144            0.927146         0.928538    0.971827                    0.968058            0.186023        0.780537                   86.1717   95.1439
    11       0.5                         0.55978            1.45145    1.85142            0.722832         0.756638    0.922018                    0.925766            0.145174        0.925711                   45.1453   85.1422
    12       0.60002                     0.155952           0.512513   1.62823            0.255234         0.329857    0.810869                    0.826431            0.0512615       0.976972                   -48.7487  62.8233
    13       0.69994                     0.0410771          0.16032    1.41868            0.0798403        0.0835268   0.706511                    0.720378            0.0160192       0.992992                   -83.968   41.8681
    14       0.79996                     0.0163816          0.0400401  1.24631            0.0199402        0.026305    0.620668                    0.633597            0.00400481      0.996996                   -95.996   24.6308
    15       0.89998                     0.00720034         0.014014   1.10936            0.00697906       0.011203    0.552465                    0.564427            0.00140168      0.998398                   -98.5986  10.9356
    16       1                           0.000376558        0.016016   1                  0.00797607       0.00440039  0.498006                    0.508413            0.00160192      1                          -98.3984  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05458955426371104
RMSE: 0.23364407602956905
LogLoss: 0.18872364049964793
Mean Per-Class Error: 0.06992177637378916
AUC: 0.9785805626598465
pr_auc: 0.9728867124643953
Gini: 0.957161125319693
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4965441046060202: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2866  262   0.0838   (262.0/3128.0)
1      171   2878  0.0561   (171.0/3049.0)
Total  3037  3140  0.0701   (433.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.496544     0.930037  202
max f2                       0.23228      0.944437  278
max f0point5                 0.777414     0.941767  126
max accuracy                 0.516061     0.929901  197
max precision                0.998706     1         0
max recall                   0.00594518   1         392
max specificity              0.998706     1         0
max absolute_mcc             0.496544     0.860206  202
max min_per_class_accuracy   0.570218     0.927845  184
max mean_per_class_accuracy  0.496544     0.930078  202
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.41 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.996608           2.02591     2.02591            1                0.997736    1                           0.997736            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.995534           2.02591     2.02591            1                0.99606     1                           0.996898            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.994625           2.02591     2.02591            1                0.995118    1                           0.996305            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.993728           2.02591     2.02591            1                0.994175    1                           0.995772            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.992927           2.02591     2.02591            1                0.993338    1                           0.995292            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.98831            2.0128      2.01935            0.993528         0.990614    0.996764                    0.992953            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.982553           2.0128      2.01717            0.993528         0.985702    0.995685                    0.990536            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.976031           2.01935     2.01771            0.996764         0.979405    0.995955                    0.987753            0.101017        0.403739                   101.935   101.771
    9        0.299984                    0.954681           1.98979     2.00842            0.982172         0.966821    0.991365                    0.980783            0.198754        0.602493                   98.9792   100.842
    10       0.400032                    0.883086           1.87184     1.97426            0.923948         0.92653     0.974504                    0.967214            0.187275        0.789767                   87.1836   97.4258
    11       0.500081                    0.539198           1.4424      1.86785            0.711974         0.747582    0.921981                    0.923274            0.14431         0.934077                   44.2396   86.7851
    12       0.599968                    0.13573            0.479389    1.63669            0.236629         0.30542     0.807879                    0.820409            0.0478846       0.981961                   -52.0611  63.669
    13       0.700016                    0.0402936          0.131127    1.42151            0.0647249        0.0777766   0.701665                    0.71427             0.0131191       0.99508                    -86.8873  42.151
    14       0.799903                    0.0158999          0.0361183   1.24851            0.0178282        0.0257208   0.616272                    0.628288            0.00360774      0.998688                   -96.3882  24.8512
    15       0.899951                    0.00712924         0.00655634  1.11044            0.00323625       0.011007    0.54812                     0.559664            0.000655953     0.999344                   -99.3444  11.0442
    16       1                           0.000605766        0.00655634  1                  0.00323625       0.00440854  0.493605                    0.504112            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:10:17  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:10:22  1:03:39.918  4752 obs/sec      0.95748   1             23937      0.297634         0.293465            0.64565        0.947697        0.929383           1.96825          0.119964                         0.287207           0.274988              0.669995         0.954071          0.935191             2.02591            0.106362
    2019-08-03 17:10:28  1:03:45.313  4758 obs/sec      1.91496   2             47874      0.288088         0.274895            0.668016       0.954311        0.945701           2.00801          0.115277                         0.27872            0.257124              0.689209         0.960291          0.950226             2.02591            0.104258
    2019-08-03 17:10:33  1:03:51.001  4675 obs/sec      2.87292   3             71823      0.283934         0.270232            0.677521       0.955711        0.951346           2.00801          0.108696                         0.274531           0.25286               0.698482         0.961357          0.951933             2.02591            0.100534
    2019-08-03 17:10:39  1:03:56.293  4720 obs/sec      3.82904   4             95726      0.276296         0.255366            0.694638       0.960565        0.951636           1.98813          0.106402                         0.268415           0.241382              0.711765         0.964946          0.95587              1.99323            0.0984297
    2019-08-03 17:10:44  1:04:01.836  4709 obs/sec      4.78568   5             119642     0.273033         0.252719            0.701808       0.961337        0.94556            1.98813          0.10012                          0.265523           0.23803               0.717943         0.965566          0.945632             2.02591            0.0958394
    2019-08-03 17:10:49  1:04:07.308  4717 obs/sec      5.74512   6             143628     0.269456         0.247078            0.709569       0.96229         0.955802           1.98813          0.0977264                        0.260126           0.231204              0.729294         0.96691           0.963385             2.02591            0.0893638
    2019-08-03 17:10:55  1:04:13.024  4686 obs/sec      6.70124   7             167531     0.269326         0.249089            0.709849       0.961551        0.950385           1.98813          0.0955325                        0.261633           0.234088              0.726148         0.965876          0.960325             2.02591            0.0892019
    2019-08-03 17:11:01  1:04:18.502  4691 obs/sec      7.65764   8             191441     0.256216         0.223757            0.73741        0.969267        0.961489           2.00801          0.0882529                        0.247919           0.209985              0.754105         0.97295           0.962464             2.02591            0.0796503
    2019-08-03 17:11:07  1:04:24.939  4595 obs/sec      8.61188   9             215297     0.255651         0.223647            0.738567       0.969095        0.956379           2.00801          0.0877543                        0.247085           0.210153              0.755755         0.97304           0.9662               2.02591            0.0824025
    2019-08-03 17:11:13  1:04:30.352  4612 obs/sec      9.5668    10            239170     0.2514           0.220937            0.747188       0.969993        0.955226           2.00801          0.082868                         0.242982           0.203945              0.7638           0.974399          0.964395             2.02591            0.0764125
    2019-08-03 17:11:18  1:04:35.634  4639 obs/sec      10.523    11            263076     0.242746         0.204316            0.764293       0.974259        0.96638            2.00801          0.0761867                        0.233644           0.188724              0.781606         0.978581          0.972887             2.02591            0.0700988
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004845385427026795
C438        0.7950514554977417     0.7950514554977417   0.0038523307362052
C374        0.6999667286872864     0.6999667286872864   0.0033916085865849954
C322        0.6242983937263489     0.6242983937263489   0.003024966339077887
C88         0.6179796457290649     0.6179796457290649   0.0029943495696147923
---         ---                    ---                  ---
C896        0.11925021559000015    0.11925021559000015  0.0005778132567895902
C416        0.11870047450065613    0.11870047450065613  0.0005751495493266448
C668        0.11856415122747421    0.11856415122747421  0.0005744890105254046
C925        0.1128356009721756     0.1128356009721756   0.00054673197660039
C921        0.11134793609380722    0.11134793609380722  0.0005395236668784443

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_131

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.00985871792667778     0.018983617424964905   0.0         0.01920922584244503   0.07502445578575134  0.11451434285002882    0.14134830236434937
    3        2        Softmax                      0.0   0.0   0.00033060431724152295  6.314797792583704e-05  0.0         0.007427814889410911  0.3549840450286865   0.0005516996770409469  0.1080610454082489


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.055017430420454365
RMSE: 0.23455794682861283
LogLoss: 0.2002617230415323
Mean Per-Class Error: 0.05949083189459681
AUC: 0.9778093259779046
pr_auc: 0.8151131265655959
Gini: 0.9556186519558092
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5262751734330232: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4692  305   0.061    (305.0/4997.0)
1      291   4731  0.0579   (291.0/5022.0)
Total  4983  5036  0.0595   (596.0/10019.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.526275     0.940744  196
max f2                       0.40794      0.951231  233
max f0point5                 0.599017     0.94623   174
max accuracy                 0.526275     0.940513  196
max precision                0.999951     0.997546  0
max recall                   5.61714e-05  1         399
max specificity              0.999951     0.9996    0
max absolute_mcc             0.526275     0.881028  196
max min_per_class_accuracy   0.533179     0.939865  194
max mean_per_class_accuracy  0.526275     0.940509  196
Gains/Lift Table: Avg response rate: 50.12 %, avg score: 50.26 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100808                   1                  1.99502     1.99502            1                1            1                           1                   0.0201115       0.0201115                  99.5022   99.5022
    2        0.0200619                   1                  1.99502     1.99502            1                1            1                           1                   0.0199124       0.0400239                  99.5022   99.5022
    3        0.0300429                   0.999998           1.99502     1.99502            1                0.999999     1                           1                   0.0199124       0.0599363                  99.5022   99.5022
    4        0.040024                    0.999992           1.99502     1.99502            1                0.999995     1                           0.999999            0.0199124       0.0798487                  99.5022   99.5022
    5        0.050005                    0.999973           1.97507     1.99104            0.99             0.999984     0.998004                    0.999996            0.0197133       0.0995619                  97.5072   99.104
    6        0.10001                     0.999375           1.98706     1.98905            0.996008         0.999776     0.997006                    0.999886            0.0993628       0.198925                   98.7058   98.9049
    7        0.150015                    0.996215           1.97909     1.98573            0.992016         0.998018     0.995343                    0.999263            0.0989646       0.297889                   97.9094   98.573
    8        0.20002                     0.987257           1.97113     1.98208            0.988024         0.992428     0.993513                    0.997554            0.0985663       0.396456                   97.1129   98.208
    9        0.30003                     0.930572           1.92334     1.9625             0.964072         0.963922     0.983699                    0.986344            0.192354        0.588809                   92.3344   96.2502
    10       0.40004                     0.79185            1.87954     1.94176            0.942116         0.869748     0.973303                    0.957195            0.187973        0.776782                   87.9542   94.1762
    11       0.50005                     0.533286           1.62469     1.87835            0.814371         0.673312     0.941517                    0.900418            0.162485        0.939267                   62.4688   87.8347
    12       0.59996                     0.219745           0.404585    1.63292            0.202797         0.368639     0.818499                    0.811862            0.0404221       0.979689                   -59.5415  63.2924
    13       0.69997                     0.0578201          0.127427    1.41782            0.0638723        0.127226     0.71068                     0.714043            0.0127439       0.992433                   -87.2573  41.7822
    14       0.79998                     0.00660376         0.051767    1.24704            0.0259481        0.0256267    0.625078                    0.62798             0.00517722      0.997611                   -94.8233  24.7044
    15       0.89999                     0.000144297        0.0219014   1.1109             0.010978         0.00208359   0.556837                    0.558428            0.00219036      0.999801                   -97.8099  11.0902
    16       1                           1.62815e-25        0.00199104  1                  0.000998004      2.33551e-05  0.501248                    0.502582            0.000199124     1                          -99.8009  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05069960487717862
RMSE: 0.22516572758121653
LogLoss: 0.18893016601141885
Mean Per-Class Error: 0.050264792699631466
AUC: 0.9813450848418709
pr_auc: 0.7864604576952716
Gini: 0.9626901696837418
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5513378788669271: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2990  138   0.0441   (138.0/3128.0)
1      172   2877  0.0564   (172.0/3049.0)
Total  3162  3015  0.0502   (310.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.551338     0.948879  186
max f2                       0.462663     0.956409  213
max f0point5                 0.576127     0.954244  179
max accuracy                 0.555446     0.949814  185
max precision                0.996326     0.997917  5
max recall                   4.82543e-05  1         399
max specificity              0.999907     0.999361  0
max absolute_mcc             0.555446     0.89967   185
max min_per_class_accuracy   0.526423     0.948529  194
max mean_per_class_accuracy  0.551338     0.949735  186
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.88 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1           1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323     2.00957            0.983871         1           0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999998           2.02591     2.01502            1                0.999999    0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999991           2.02591     2.01774            1                0.999995    0.995968                    0.999998            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999976           2.02591     2.01935            1                0.999984    0.996764                    0.999996            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999412           2.01935     2.01935            0.996764         0.999789    0.996764                    0.999892            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.996379           2.02591     2.02154            1                0.998189    0.997843                    0.999324            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.98829            1.98657     2.0128             0.980583         0.993078    0.993528                    0.997763            0.0993768       0.402755                   98.6572   101.28
    9        0.299984                    0.932473           1.96681     1.99748            0.970827         0.966362    0.985969                    0.987307            0.196458        0.599213                   96.6807   99.7484
    10       0.400032                    0.788911           1.91773     1.97754            0.946602         0.867733    0.976123                    0.957402            0.191866        0.791079                   91.773    97.7538
    11       0.500081                    0.507498           1.62925     1.90786            0.804207         0.66101     0.941729                    0.898104            0.163004        0.954083                   62.9251   90.7858
    12       0.599968                    0.207587           0.298797    1.63997            0.147488         0.349071    0.809498                    0.806697            0.0298459       0.983929                   -70.1203  63.997
    13       0.700016                    0.053245           0.0917888   1.4187             0.0453074        0.12189     0.700278                    0.708823            0.00918334      0.993112                   -90.8211  41.8699
    14       0.799903                    0.00606315         0.0426853   1.24687            0.0210697        0.0238734   0.615462                    0.623291            0.00426369      0.997376                   -95.7315  24.6872
    15       0.899951                    0.000132875        0.0229472   1.11081            0.0113269        0.00190549  0.5483                      0.55421             0.00229583      0.999672                   -97.7053  11.0807
    16       1                           1.62815e-25        0.00327817  1                  0.00161812       1.9919e-05  0.493605                    0.498765            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:34:34  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:34:38  2:27:55.608  7575 obs/sec      1         1             25000      0.305471         0.354266            0.626748       0.941981        0.733861           1.99502          0.119273                         0.296527           0.337723              0.64823          0.947174          0.739937             2.02591            0.110248
    2019-08-03 18:34:45  2:28:02.508  7814 obs/sec      3         3             75000      0.27134          0.257777            0.705496       0.961353        0.826926           1.99502          0.0932229                        0.263116           0.246689              0.723035         0.965324          0.823412             2.02591            0.0869354
    2019-08-03 18:34:51  2:28:09.041  8052 obs/sec      5         5             125000     0.257885         0.231605            0.73398        0.969201        0.858517           1.99502          0.082643                         0.247767           0.218647              0.754406         0.973453          0.847953             2.02591            0.072689
    2019-08-03 18:34:58  2:28:15.568  8175 obs/sec      7         7             175000     0.248698         0.219024            0.752595       0.972611        0.838975           1.99502          0.0728616                        0.238342           0.206065              0.772736         0.976846          0.813729             2.02591            0.060871
    2019-08-03 18:35:07  2:28:24.763  8348 obs/sec      10        10            250000     0.234558         0.200262            0.779929       0.977809        0.815113           1.99502          0.059487                         0.225166           0.18893               0.797168         0.981345          0.78646              2.02591            0.0501862
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0036960085854365232
C36         0.9141775965690613     0.9141775965690613   0.003378808245532977
C35         0.8765674829483032     0.8765674829483032   0.003239800942691412
C34         0.8484176397323608     0.8484176397323608   0.0031357588804865966
C250        0.8118723034858704     0.8118723034858704   0.0030006870039619034
---         ---                    ---                  ---
C632        0.1807616651058197     0.1807616651058197   0.0006680966661489112
C389        0.17787116765975952    0.17787116765975952  0.0006574133627720905
C649        0.1776910275220871     0.1776910275220871   0.0006567475632766715
C802        0.17178311944007874    0.17178311944007874  0.0006349118842835988
C497        0.16464394330978394    0.16464394330978394  0.0006085254280130856

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_20

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.007240988653089349   0.006861355155706406  0.0         0.01921079887119091   0.07297074794769287  0.1039094753336013     0.17896288633346558
    3        2        Softmax                      0.0   0.0   0.0003282812854763506  6.86727580614388e-05  0.0         0.009248651306734246  0.3530735969543457   0.0001392768354032889  0.10003840923309326


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.053612041908590244
RMSE: 0.23154274315683107
LogLoss: 0.2025751423635989
Mean Per-Class Error: 0.05601694131100876
AUC: 0.97798198893143
pr_auc: 0.7825873436031842
Gini: 0.9559639778628599
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5402647605562291: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4764  263   0.0523   (263.0/5027.0)
1      299   4708  0.0597   (299.0/5007.0)
Total  5063  4971  0.056    (562.0/10034.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.540265     0.943676  190
max f2                       0.359127     0.952997  247
max f0point5                 0.58043      0.949155  178
max accuracy                 0.547618     0.94399   188
max precision                0.999279     0.99556   1
max recall                   3.44406e-05  1         399
max specificity              0.999916     0.999005  0
max absolute_mcc             0.547618     0.888029  188
max min_per_class_accuracy   0.527271     0.943479  194
max mean_per_class_accuracy  0.540265     0.943983  190
Gains/Lift Table: Avg response rate: 49.90 %, avg score: 49.97 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100658                   1                  2.00399     2.00399            1                1            1                           1                   0.0201718       0.0201718                  100.399   100.399
    2        0.0200319                   1                  2.00399     2.00399            1                1            1                           1                   0.019972        0.0401438                  100.399   100.399
    3        0.029998                    0.999998           1.98395     1.99734            0.99             0.999999     0.996678                    1                   0.0197723       0.0599161                  98.3954   99.7337
    4        0.0400638                   0.999992           2.00399     1.99901            1                0.999996     0.997512                    0.999999            0.0201718       0.0800879                  100.399   99.9009
    5        0.0500299                   0.999978           2.00399     2                  1                0.999986     0.998008                    0.999996            0.019972        0.10006                    100.399   100
    6        0.10006                     0.999428           1.98803     1.99401            0.992032         0.999815     0.99502                     0.999906            0.0994608       0.199521                   98.8026   99.4014
    7        0.14999                     0.996386           1.99199     1.99334            0.994012         0.998235     0.994684                    0.999349            0.0994608       0.298981                   99.1994   99.3342
    8        0.20002                     0.987053           1.96407     1.98602            0.98008          0.992458     0.991031                    0.997626            0.0982624       0.397244                   96.4074   98.6021
    9        0.29998                     0.927837           1.94405     1.97204            0.97009          0.962        0.984053                    0.985754            0.194328        0.591572                   94.4054   97.2037
    10       0.40004                     0.784367           1.88623     1.95057            0.941235         0.864846     0.973343                    0.955512            0.188736        0.780308                   88.623    95.0575
    11       0.5                         0.52319            1.64435     1.88935            0.820538         0.670516     0.942794                    0.898536            0.16437         0.944677                   64.4354   88.9355
    12       0.59996                     0.211214           0.355644    1.63382            0.177468         0.354098     0.815282                    0.807826            0.0355502       0.980228                   -64.4356  63.3821
    13       0.70002                     0.0576811          0.103793    1.41512            0.0517928        0.122867     0.70615                     0.709919            0.0103855       0.990613                   -89.6207  41.5121
    14       0.79998                     0.0060608          0.061938    1.24604            0.0309073        0.0256346    0.621777                    0.624416            0.00619133      0.996804                   -93.8062  24.6037
    15       0.89994                     0.000105699        0.021978    1.11008            0.0109671        0.0018072    0.553931                    0.55526             0.00219692      0.999001                   -97.8022  11.0075
    16       1                           1.40811e-27        0.00998005  1                  0.00498008       1.49998e-05  0.499003                    0.499702            0.000998602     1                          -99.002   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05096264953106357
RMSE: 0.22574908533826568
LogLoss: 0.18990642786772693
Mean Per-Class Error: 0.05168684504332055
AUC: 0.981205212559734
pr_auc: 0.7787938507477139
Gini: 0.9624104251194681
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5354976359365331: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2977  151   0.0483   (151.0/3128.0)
1      168   2881  0.0551   (168.0/3049.0)
Total  3145  3032  0.0516   (319.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.535498     0.947542  192
max f2                       0.405359     0.956215  231
max f0point5                 0.565813     0.952111  184
max accuracy                 0.535498     0.948357  192
max precision                0.997015     0.997838  4
max recall                   5.05794e-05  1         399
max specificity              0.999905     0.999361  0
max absolute_mcc             0.535498     0.896703  192
max min_per_class_accuracy   0.524734     0.94757   195
max mean_per_class_accuracy  0.535498     0.948313  192
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.81 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1           1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1           1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999998           1.96056     2.00413            0.967742         0.999999    0.989247                    1                   0.0196786       0.0603477                  96.0558   100.413
    4        0.0401489                   0.999992           2.02591     2.00957            1                0.999995    0.991935                    0.999999            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999979           2.02591     2.0128             1                0.999986    0.993528                    0.999996            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.99945            2.02591     2.01935            1                0.999816    0.996764                    0.999906            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.996614           2.02591     2.02154            1                0.998294    0.997843                    0.999369            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.987761           1.99313     2.01444            0.983819         0.992804    0.994337                    0.997728            0.0997048       0.403083                   99.3128   101.444
    9        0.299984                    0.930798           1.97666     2.00186            0.975689         0.964792    0.988127                    0.986761            0.197442        0.600525                   97.6658   100.186
    10       0.400032                    0.784236           1.90462     1.97754            0.940129         0.866451    0.976123                    0.956671            0.190554        0.791079                   90.4618   97.7538
    11       0.500081                    0.502863           1.61286     1.90458            0.796117         0.66162     0.94011                     0.897642            0.161364        0.952443                   61.286    90.4579
    12       0.599968                    0.211521           0.305364    1.63833            0.150729         0.344632    0.808689                    0.805573            0.0305018       0.982945                   -69.4636  63.833
    13       0.700016                    0.054495           0.0917888   1.41729            0.0453074        0.12227     0.699584                    0.707913            0.00918334      0.992129                   -90.8211  41.7294
    14       0.799903                    0.00568863         0.0525358   1.24687            0.0259319        0.0235057   0.615462                    0.622449            0.00524762      0.997376                   -94.7464  24.6872
    15       0.899951                    0.000100125        0.019669    1.11044            0.00970874       0.00166898  0.54812                     0.553436            0.00196786      0.999344                   -98.0331  11.0442
    16       1                           1.90664e-25        0.00655634  1                  0.00323625       1.4305e-05  0.493605                    0.498067            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:30:26  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:30:29  23 min 47.348 sec  7507 obs/sec      1         1             25000      0.307011         0.378435            0.622975       0.941544        0.713571           2.00399          0.122583                         0.296635           0.353294              0.647973         0.947481          0.695701             1.99323            0.112514
    2019-08-03 16:30:36  23 min 54.200 sec  7822 obs/sec      3         3             75000      0.268274         0.264833            0.712115       0.961696        0.784409           2.00399          0.0932828                        0.257724           0.245339              0.734269         0.966924          0.756484             2.02591            0.0824025
    2019-08-03 16:30:44  24 min  2.126 sec  7406 obs/sec      5         5             125000     0.254384         0.234775            0.741153       0.969398        0.805334           2.00399          0.0761411                        0.248031           0.223011              0.753883         0.972441          0.816811             2.02591            0.0679942
    2019-08-03 16:30:50  24 min  8.481 sec  7739 obs/sec      7         7             175000     0.244798         0.219897            0.760294       0.973379        0.81268            2.00399          0.0677696                        0.238473           0.208414              0.772485         0.976556          0.805931             2.02591            0.060871
    2019-08-03 16:30:57  24 min 14.964 sec  7908 obs/sec      9         9             225000     0.234599         0.205835            0.779852       0.976932        0.835303           2.00399          0.059398                         0.226639           0.192207              0.794505         0.980551          0.837924             2.02591            0.0535859
    2019-08-03 16:31:00  24 min 18.489 sec  7988 obs/sec      10        10            250000     0.231543         0.202575            0.785551       0.977982        0.782587           2.00399          0.0560096                        0.225749           0.189906              0.796116         0.981205          0.778794             2.02591            0.0516432
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.00335246606045071
C28         0.9268144965171814     0.9268144965171814   0.0031071141439075636
C250        0.9154062867164612     0.9154062867164612   0.003068868507740148
C25         0.9141213297843933     0.9141213297843933   0.0030645607332362495
C34         0.8933674097061157     0.8933674097061157   0.002994983920552517
---         ---                    ---                  ---
C624        0.20017291605472565    0.20017291605472565  0.0006710729072949168
C662        0.19831153750419617    0.19831153750419617  0.0006648326988786158
C439        0.19813533127307892    0.19813533127307892  0.0006642419734691553
C753        0.197388157248497      0.197388157248497    0.0006617370979104941
C534        0.1819898933172226     0.1819898933172226   0.0006101149406910342

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_214

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.00701078268857832     0.006214966997504234   0.0         0.019347202790302827   0.07291761040687561  0.09744791371923958    0.16301774978637695
    3        2        Softmax                      0.0   0.0   0.00033483108512655235  7.167115109041333e-05  0.0         0.0024931881102929765  0.35079121589660645  0.0007680292598416238  0.1258818507194519


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05224307469098557
RMSE: 0.22856744013744734
LogLoss: 0.19651038044586439
Mean Per-Class Error: 0.05396446439933489
AUC: 0.9791549876537099
pr_auc: 0.7969718460130462
Gini: 0.9583099753074198
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.489178141909279: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4614  337   0.0681   (337.0/4951.0)
1      206   4854  0.0407   (206.0/5060.0)
Total  4820  5191  0.0542   (543.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.489178     0.94703   208
max f2                       0.389666     0.95541   238
max f0point5                 0.595997     0.948199  174
max accuracy                 0.534147     0.946059  194
max precision                0.998903     0.994764  2
max recall                   3.53701e-05  1         399
max specificity              0.999951     0.99899   0
max absolute_mcc             0.534147     0.892107  194
max min_per_class_accuracy   0.541021     0.945264  192
max mean_per_class_accuracy  0.534147     0.946036  194
Gains/Lift Table: Avg response rate: 50.54 %, avg score: 50.86 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   1                  1.97846     1.97846            1                1            1                           1                   0.0199605       0.0199605                  97.8458   97.8458
    2        0.0200779                   1                  1.97846     1.97846            1                1            1                           1                   0.0197628       0.0397233                  97.8458   97.8458
    3        0.0300669                   0.999999           1.95867     1.97189            0.99             1            0.996678                    1                   0.0195652       0.0592885                  95.8674   97.1886
    4        0.0400559                   0.999996           1.95867     1.96859            0.99             0.999998     0.995012                    0.999999            0.0195652       0.0788538                  95.8674   96.8591
    5        0.050045                    0.999988           1.95867     1.96661            0.99             0.999993     0.994012                    0.999998            0.0195652       0.098419                   95.8674   96.6611
    6        0.10009                     0.999622           1.96661     1.96661            0.994012         0.999874     0.994012                    0.999936            0.098419        0.196838                   96.6611   96.6611
    7        0.150035                    0.997496           1.96659     1.9666             0.994            0.998771     0.994008                    0.999548            0.0982213       0.295059                   96.6588   96.6604
    8        0.20008                     0.99018            1.94687     1.96167            0.984032         0.994476     0.991513                    0.99828             0.0974308       0.39249                    94.6866   96.1667
    9        0.30007                     0.939176           1.92509     1.94948            0.973027         0.969612     0.985353                    0.988727            0.19249         0.58498                    92.5093   94.948
    10       0.40006                     0.811981           1.84999     1.92461            0.935065         0.882965     0.972784                    0.962293            0.18498         0.76996                    84.9987   92.4613
    11       0.50005                     0.558449           1.68989     1.87768            0.854146         0.696901     0.949061                    0.909225            0.168972        0.938933                   68.9892   87.7678
    12       0.60004                     0.227937           0.442732    1.63856            0.223776         0.380599     0.8282                      0.821136            0.0442688       0.983202                   -55.7268  63.856
    13       0.70003                     0.060248           0.104754    1.41948            0.0529471        0.131372     0.717466                    0.722612            0.0104743       0.993676                   -89.5246  41.9476
    14       0.80002                     0.00602472         0.0375532   1.24676            0.018981         0.0258522    0.630166                    0.635528            0.00375494      0.997431                   -96.2447  24.6757
    15       0.90001                     0.000116564        0.0197648   1.11044            0.00999001       0.00174038   0.561265                    0.565115            0.00197628      0.999407                   -98.0235  11.044
    16       1                           2.28565e-27        0.00592945  1                  0.002997         1.63746e-05  0.505444                    0.508611            0.000592885     1                          -99.4071  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05096796706792475
RMSE: 0.22576086256905725
LogLoss: 0.1899278462617656
Mean Per-Class Error: 0.05185911652724173
AUC: 0.9808663840142129
pr_auc: 0.8219339507722396
Gini: 0.9617327680284258
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5446505407904381: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2979  149   0.0476   (149.0/3128.0)
1      171   2878  0.0561   (171.0/3049.0)
Total  3150  3027  0.0518   (320.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.544651     0.947334  187
max f2                       0.382106     0.954622  235
max f0point5                 0.596702     0.951559  170
max accuracy                 0.55327      0.948195  184
max precision                0.99846      0.99765   3
max recall                   3.0745e-05   1         399
max specificity              0.999978     0.999361  0
max absolute_mcc             0.55327      0.896418  184
max min_per_class_accuracy   0.528132     0.946611  192
max mean_per_class_accuracy  0.544651     0.948141  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.85 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999999           1.99323     2.01502            0.983871         0.999999     0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999994           2.02591     2.01774            1                0.999997     0.995968                    0.999999            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999986           1.9927      2.0128             0.983607         0.999991     0.993528                    0.999997            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999603           2.02591     2.01935            1                0.999867     0.996764                    0.999932            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.99717            2.01935     2.01935            0.996764         0.998648     0.996764                    0.999504            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.989012           1.97346     2.00788            0.97411          0.993721     0.9911                      0.998058            0.0987209       0.401771                   97.3459   100.788
    9        0.299984                    0.935478           1.97994     1.99858            0.97731          0.967379     0.986508                    0.987843            0.19777         0.599541                   97.9941   99.8577
    10       0.400032                    0.790229           1.9079      1.9759             0.941748         0.870726     0.975314                    0.958552            0.190882        0.790423                   90.7896   97.5898
    11       0.500081                    0.506208           1.61942     1.90458            0.799353         0.663417     0.94011                     0.899506            0.16202         0.952443                   61.9417   90.4579
    12       0.599968                    0.206569           0.334915    1.64325            0.165316         0.342847     0.811117                    0.806829            0.0334536       0.985897                   -66.5085  64.325
    13       0.700016                    0.0550439          0.0753979   1.41917            0.0372168        0.119257     0.700509                    0.708559            0.00754346      0.99344                    -92.4602  41.9168
    14       0.799903                    0.00541575         0.0459688   1.24769            0.0226904        0.0230981    0.615867                    0.622963            0.00459167      0.998032                   -95.4031  24.7692
    15       0.899951                    8.887e-05          0.0131127   1.11044            0.00647249       0.00160209   0.54812                     0.553886            0.00131191      0.999344                   -98.6887  11.0442
    16       1                           2.28565e-27        0.00655634  1                  0.00323625       1.39958e-05  0.493605                    0.498472            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:28:32  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:28:35  4:21:53.311  7215 obs/sec      1         1             25000      0.303923         0.373765            0.630478       0.944214        0.723552           1.95887          0.11797                          0.293929           0.354396              0.654366         0.948937          0.73356              1.99323            0.109438
    2019-08-03 20:28:45  4:22:02.974  7984 obs/sec      4         4             100000     0.257121         0.239267            0.735524       0.96787         0.820019           1.97846          0.0817101                        0.251106           0.230817              0.747742         0.970354          0.812563             2.02591            0.0752793
    2019-08-03 20:28:52  4:22:09.593  8106 obs/sec      6         6             150000     0.245371         0.218215            0.759143       0.973504        0.837599           1.97846          0.0687244                        0.239803           0.210436              0.76994          0.97576           0.830041             2.02591            0.0636231
    2019-08-03 20:29:01  4:22:18.873  8301 obs/sec      9         9             225000     0.231752         0.199989            0.785139       0.978252        0.797538           1.97846          0.0566377                        0.228232           0.193866              0.791606         0.979845          0.823589             2.02591            0.0526145
    2019-08-03 20:29:04  4:22:22.404  8345 obs/sec      10        10            250000     0.228567         0.19651             0.791003       0.979155        0.796972           1.97846          0.0542403                        0.225761           0.189928              0.796095         0.980866          0.821934             2.02591            0.0518051
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0032629529573040116
C34         0.9549738168716431     0.9549738168716431   0.0031160346399092273
C36         0.9336071014404297     0.9336071014404297   0.0030463160526050764
C35         0.9070509076118469     0.9070509076118469   0.002959664441417364
C250        0.8930636644363403     0.8930636644363403   0.002914024724933314
---         ---                    ---                  ---
C430        0.2094481885433197     0.2094481885433197   0.0006834195862093932
C366        0.20753763616085052    0.20753763616085052  0.0006771855436629312
C443        0.20200084149837494    0.20200084149837494  0.0006591192431450214
C887        0.1964346021413803     0.1964346021413803   0.0006409568659740538
C690        0.18851898610591888    0.18851898610591888  0.0006151285832222619

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_198

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.03961978666746903    0.07062318921089172     0.0         -0.0026235459118748774  0.1206311285495758   -0.00458786644466226    0.14101403951644897
    3        2        Softmax                 0.0   0.0   0.0017546281542308861  0.00021392316557466984  0.0         -0.17446997998922598    0.44775474071502686  -0.0020612941727285033  0.15307766199111938


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05863869134752949
RMSE: 0.2421542717928583
LogLoss: 0.2006192025573904
Mean Per-Class Error: 0.07633860571275775
AUC: 0.975728305972634
pr_auc: 0.9703287037219724
Gini: 0.9514566119452681
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5557287518141855: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4619  380   0.076    (380.0/4999.0)
1      384   4625  0.0767   (384.0/5009.0)
Total  5003  5005  0.0763   (764.0/10008.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.555729     0.923707  190
max f2                       0.216506     0.942833  285
max f0point5                 0.718997     0.934115  146
max accuracy                 0.555729     0.923661  190
max precision                0.997427     1         0
max recall                   0.00508735   1         395
max specificity              0.997427     1         0
max absolute_mcc             0.555729     0.847322  190
max min_per_class_accuracy   0.555729     0.923338  190
max mean_per_class_accuracy  0.555729     0.923661  190
Gains/Lift Table: Avg response rate: 50.05 %, avg score: 50.53 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100919                   0.995829           1.998       1.998              1                0.996744    1                           0.996744            0.0201637       0.0201637                  99.8004   99.8004
    2        0.0200839                   0.994818           1.998       1.998              1                0.995342    1                           0.996047            0.0199641       0.0401278                  99.8004   99.8004
    3        0.0300759                   0.993631           1.998       1.998              1                0.994217    1                           0.995439            0.0199641       0.0600918                  99.8004   99.8004
    4        0.0400679                   0.992754           1.97802     1.99302            0.99             0.993192    0.997506                    0.994879            0.0197644       0.0798563                  97.8024   99.3021
    5        0.05006                     0.991675           1.998       1.99402            1                0.992197    0.998004                    0.994343            0.0199641       0.0998203                  99.8004   99.4016
    6        0.10002                     0.986947           1.98602     1.99002            0.994            0.989373    0.996004                    0.99186             0.0992214       0.199042                   98.6016   99.002
    7        0.15008                     0.981492           1.998       1.99268            1                0.984355    0.997337                    0.989357            0.10002         0.299062                   99.8004   99.2683
    8        0.20004                     0.975179           1.97802     1.98902            0.99             0.978425    0.995504                    0.986627            0.0988221       0.397884                   97.8024   98.9022
    9        0.30006                     0.950433           1.95409     1.97738            0.978022         0.964852    0.989677                    0.979368            0.195448        0.593332                   95.4091   97.7378
    10       0.39998                     0.871849           1.83417     1.9416             0.918            0.917945    0.971771                    0.964024            0.18327         0.776602                   83.4167   94.1602
    11       0.5                         0.554925           1.46507     1.84628            0.733267         0.746522    0.924061                    0.920515            0.146536        0.923138                   46.507    84.6277
    12       0.60002                     0.155749           0.548902    1.63001            0.274725         0.324557    0.81582                     0.821172            0.0549012       0.97804                    -45.1098  63.0012
    13       0.69994                     0.0405806          0.163836    1.42071            0.082            0.0830738   0.711064                    0.715805            0.0163705       0.99441                    -83.6164  42.0707
    14       0.79996                     0.016223           0.0479042   1.24906            0.023976         0.0259811   0.625156                    0.629555            0.00479138      0.999201                   -95.2096  24.9064
    15       0.89998                     0.00797597         0.00399202  1.11069            0.001998         0.0115414   0.555901                    0.560872            0.000399281     0.999601                   -99.6008  11.0692
    16       1                           0.000996641        0.00399202  1                  0.001998         0.00508471  0.5005                      0.505282            0.000399281     1                          -99.6008  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.055269060858541
RMSE: 0.2350937278162499
LogLoss: 0.19030913434983554
Mean Per-Class Error: 0.0725514067334978
AUC: 0.9783473198625351
pr_auc: 0.9708331759838232
Gini: 0.9566946397250702
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4661195110763228: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2855  273   0.0873   (273.0/3128.0)
1      178   2871  0.0584   (178.0/3049.0)
Total  3033  3144  0.073    (451.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.46612      0.927176  211
max f2                       0.262509     0.945255  269
max f0point5                 0.7791       0.941032  123
max accuracy                 0.548332     0.927473  191
max precision                0.99743      1         0
max recall                   0.011189     1         386
max specificity              0.99743      1         0
max absolute_mcc             0.548332     0.85492   191
max min_per_class_accuracy   0.531603     0.92679   195
max mean_per_class_accuracy  0.548332     0.927449  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.93 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.995708           2.02591     2.02591            1                0.996623    1                           0.996623            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.994488           2.02591     2.02591            1                0.99517     1                           0.995896            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.993436           2.02591     2.02591            1                0.993956    1                           0.995249            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.992626           1.99323     2.01774            0.983871         0.993025    0.995968                    0.994693            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.99158            1.9927      2.0128             0.983607         0.992137    0.993528                    0.994189            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.98671            2.01935     2.01608            0.996764         0.98913     0.995146                    0.991659            0.101017        0.201705                   101.935   101.608
    7        0.150073                    0.98139            2.02591     2.01935            1                0.984141    0.996764                    0.989153            0.101345        0.30305                    102.591   101.935
    8        0.200097                    0.975361           2.0128      2.01771            0.993528         0.978469    0.995955                    0.986482            0.100689        0.403739                   101.28    101.771
    9        0.299984                    0.950498           1.98651     2.00732            0.980551         0.964893    0.990826                    0.979293            0.198426        0.602165                   98.6508   100.732
    10       0.400032                    0.868045           1.89478     1.97918            0.935275         0.918358    0.976932                    0.964053            0.18957         0.791735                   89.4783   97.9177
    11       0.500081                    0.500379           1.3965      1.8626             0.68932          0.722314    0.919391                    0.91569             0.139718        0.931453                   39.6501   86.2604
    12       0.599968                    0.140726           0.502373    1.63614            0.247974         0.296219    0.807609                    0.812556            0.0501804       0.981633                   -49.7627  63.6144
    13       0.700016                    0.0392284          0.121292    1.41964            0.0598706        0.0763145   0.70074                     0.70733             0.0121351       0.993768                   -87.8708  41.9636
    14       0.799903                    0.0158942          0.0558192   1.24933            0.0275527        0.0251575   0.616677                    0.622145            0.0055756       0.999344                   -94.4181  24.9332
    15       0.899951                    0.00774463         0.00655634  1.11117            0.00323625       0.0111382   0.54848                     0.554219            0.000655953     1                          -99.3444  11.1171
    16       1                           0.000730165        0           1                  0                0.00492486  0.493605                    0.499263            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:09:24  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:09:30  4:02:47.647  4716 obs/sec      1         1             25000      0.299626         0.292446            0.640896       0.947456        0.928759           1.998            0.121603                         0.288649           0.277488              0.666673         0.953377          0.936837             2.02591            0.110571
    2019-08-03 20:09:36  4:02:53.393  4692 obs/sec      2         2             50000      0.284975         0.26926             0.675157       0.95665         0.951336           1.998            0.109612                         0.275276           0.255943              0.696844         0.961318          0.952261             2.02591            0.101182
    2019-08-03 20:09:41  4:02:59.232  4673 obs/sec      3         3             75000      0.283855         0.26706             0.677705       0.956373        0.948756           1.998            0.111811                         0.273069           0.251942              0.701684         0.96127           0.951265             2.02591            0.0982678
    2019-08-03 20:09:47  4:03:04.754  4733 obs/sec      4         4             100000     0.27932          0.26053             0.687921       0.958701        0.950563           1.97822          0.104916                         0.269559           0.246022              0.709303         0.962869          0.954485             2.02591            0.0972964
    2019-08-03 20:09:53  4:03:10.522  4726 obs/sec      5         5             125000     0.268394         0.242218            0.711859       0.964634        0.962674           1.998            0.0982214                        0.261515           0.232045              0.726395         0.967599          0.963445             2.02591            0.0903351
    2019-08-03 20:09:59  4:03:16.323  4713 obs/sec      6         6             150000     0.274062         0.251692            0.699559       0.961287        0.954882           1.95844          0.102618                         0.263227           0.236411              0.722801         0.96582           0.962051             2.02591            0.0924397
    2019-08-03 20:10:04  4:03:22.091  4714 obs/sec      7         7             175000     0.265398         0.237636            0.718255       0.965343        0.954853           1.998            0.0939249                        0.255477           0.223311              0.738884         0.969153          0.962314             2.02591            0.0838595
    2019-08-03 20:10:10  4:03:27.681  4730 obs/sec      8         8             200000     0.258603         0.226491            0.732498       0.968652        0.964747           1.998            0.0890288                        0.250798           0.21494               0.748361         0.971666          0.960973             2.02591            0.0836976
    2019-08-03 20:10:16  4:03:33.398  4733 obs/sec      9         9             225000     0.254247         0.21968             0.741433       0.970527        0.961482           1.998            0.0872302                        0.246026           0.207614              0.757845         0.973594          0.966629             2.02591            0.0802979
    2019-08-03 20:10:21  4:03:39.010  4743 obs/sec      10        10            250000     0.242154         0.200619            0.765445       0.975728        0.970329           1.998            0.0763389                        0.235094           0.190309              0.778888         0.978347          0.970833             2.02591            0.0730128
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.005381344623942895
C438        0.7506754398345947     0.7506754398345947   0.004039643242479865
C374        0.7034995555877686     0.7034995555877686   0.003785773551408454
C322        0.6673429012298584     0.6673429012298584   0.003591202133859753
C88         0.6386576890945435     0.6386576890945435   0.0034368371217487143
---         ---                    ---                  ---
C953        0.09532035142183304    0.09532035142183304  0.0005129516606762288
C691        0.09405312687158585    0.09405312687158585  0.0005061322886554275
C835        0.09322765469551086    0.09322765469551086  0.000501690138398492
C921        0.08863972872495651    0.08863972872495651  0.00047700092764180137
C908        0.07566531002521515    0.07566531002521515  0.000407181109323164

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_139

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.008563875711397207    0.00687468983232975    0.0         0.019775722314597587  0.07677504420280457  0.09800921505540043    0.1629241704940796
    3        2        Softmax                      0.0   0.0   0.00034336386437416877  9.201030479744077e-05  0.0         -0.07391276459793517  0.37964892387390137  0.0011860653963587271  0.05237063765525818


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.050762775398339094
RMSE: 0.22530595952690444
LogLoss: 0.19058977748926398
Mean Per-Class Error: 0.0518845513700984
AUC: 0.9806277222929962
pr_auc: 0.8021059315567493
Gini: 0.9612554445859924
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49549341517472545: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4762  273   0.0542   (273.0/5035.0)
1      247   4738  0.0495   (247.0/4985.0)
Total  5009  5011  0.0519   (520.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.495493     0.947979  205
max f2                       0.352647     0.954784  248
max f0point5                 0.597383     0.952282  175
max accuracy                 0.49808      0.948104  204
max precision                0.999927     0.996625  0
max recall                   2.93012e-05  1         399
max specificity              0.999927     0.999404  0
max absolute_mcc             0.495493     0.89622   205
max min_per_class_accuracy   0.505821     0.947643  202
max mean_per_class_accuracy  0.495493     0.948115  205
Gains/Lift Table: Avg response rate: 49.75 %, avg score: 49.56 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100798                   1                  2.01003     2.01003            1                1            1                           1                   0.0202608       0.0202608                  101.003   101.003
    2        0.0200599                   1                  2.01003     2.01003            1                1            1                           1                   0.0200602       0.040321                   101.003   101.003
    3        0.0300399                   0.999998           2.01003     2.01003            1                0.999999     1                           1                   0.0200602       0.0603811                  101.003   101.003
    4        0.04002                     0.99999            1.96983     2.00001            0.98             0.999995     0.995012                    0.999998            0.019659        0.0800401                  96.9829   100.001
    5        0.05                        0.999971           2.01003     2.00201            1                0.999982     0.996008                    0.999995            0.0200602       0.1001                     101.003   100.201
    6        0.1                         0.999348           2.00602     2.00401            0.998004         0.999762     0.997006                    0.999878            0.100301        0.200401                   100.602   100.401
    7        0.15                        0.996274           1.98997     1.99933            0.99002          0.998202     0.994677                    0.99932             0.0994985       0.2999                     98.997    99.9331
    8        0.2                         0.987699           1.98596     1.99599            0.988024         0.992597     0.993014                    0.997639            0.0992979       0.399198                   98.5958   99.5988
    9        0.3                         0.932086           1.95988     1.98395            0.97505          0.964197     0.987026                    0.986492            0.195988        0.595186                   95.988    98.3952
    10       0.4                         0.787049           1.88766     1.95988            0.939122         0.868295     0.97505                     0.956942            0.188766        0.783952                   88.7663   95.988
    11       0.5                         0.494365           1.66299     1.9005             0.827345         0.659214     0.945509                    0.897397            0.166299        0.950251                   66.2989   90.0502
    12       0.6                         0.201573           0.318957    1.63691            0.158683         0.333604     0.814371                    0.803431            0.0318957       0.982146                   -68.1043  63.6911
    13       0.7                         0.0506877          0.112337    1.41911            0.0558882        0.113442     0.706017                    0.704861            0.0112337       0.99338                    -88.7663  41.9114
    14       0.8                         0.00468801         0.0441324   1.24724            0.0219561        0.0203964    0.620509                    0.619303            0.00441324      0.997793                   -95.5868  24.7242
    15       0.9                         6.46562e-05        0.0160481   1.11044            0.00798403       0.00129833   0.552451                    0.550636            0.00160481      0.999398                   -98.3952  11.0442
    16       1                           3.90465e-27        0.00601805  1                  0.00299401       9.35233e-06  0.497505                    0.495573            0.000601805     1                          -99.3982  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.051184416306106435
RMSE: 0.22623973193518956
LogLoss: 0.1915494349235337
Mean Per-Class Error: 0.05280991252005807
AUC: 0.9804962047847645
pr_auc: 0.8148366107472705
Gini: 0.960992409569529
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5049745661293137: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2955  173   0.0553   (173.0/3128.0)
1      154   2895  0.0505   (154.0/3049.0)
Total  3109  3068  0.0529   (327.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.504975     0.946542  198
max f2                       0.414524     0.954976  226
max f0point5                 0.58667      0.951655  173
max accuracy                 0.525345     0.947224  191
max precision                0.999504     0.996992  1
max recall                   3.14569e-05  1         399
max specificity              0.999955     0.999361  0
max absolute_mcc             0.525345     0.894431  191
max min_per_class_accuracy   0.513872     0.946292  195
max mean_per_class_accuracy  0.525345     0.94719   191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.42 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999997           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999989           1.96056     2.00957            0.967742         0.999994     0.991935                    0.999998            0.0196786       0.0806822                  96.0558   100.957
    5        0.0500243                   0.999974           2.02591     2.0128             1                0.999982     0.993528                    0.999995            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999386           2.02591     2.01935            1                0.999783     0.996764                    0.999889            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.996372           2.0128      2.01717            0.993528         0.998239     0.995685                    0.999339            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.988119           2.00624     2.01444            0.990291         0.992767     0.994337                    0.997696            0.100361        0.403083                   100.624   101.444
    9        0.299984                    0.933705           1.97666     2.00186            0.975689         0.965607     0.988127                    0.987011            0.197442        0.600525                   97.6658   100.186
    10       0.400032                    0.779273           1.9079      1.97836            0.941748         0.866107     0.976528                    0.956773            0.190882        0.791407                   90.7896   97.8357
    11       0.500081                    0.494856           1.6063      1.90392            0.79288          0.649351     0.939786                    0.895269            0.160708        0.952115                   60.6304   90.3923
    12       0.599968                    0.191588           0.298797    1.63669            0.147488         0.326817     0.807879                    0.800629            0.0298459       0.981961                   -70.1203  63.669
    13       0.700016                    0.0524478          0.10818     1.41823            0.0533981        0.115409     0.700046                    0.702695            0.0108232       0.992785                   -89.182   41.8231
    14       0.799903                    0.00462406         0.0459688   1.24687            0.0226904        0.0216827    0.615462                    0.617655            0.00459167      0.997376                   -95.4031  24.6872
    15       0.899951                    8.8607e-05         0.019669    1.11044            0.00970874       0.00139471   0.54812                     0.549144            0.00196786      0.999344                   -98.0331  11.0442
    16       1                           3.90465e-27        0.00655634  1                  0.00323625       1.25501e-05  0.493605                    0.494205            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:39:56  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:40:00  2:33:17.652  7725 obs/sec      1         1             25000      0.302341         0.367647            0.634351       0.944274        0.7231             2.01003          0.120459                         0.296793           0.355939              0.647597         0.947873          0.721949             2.02591            0.115752
    2019-08-03 18:40:06  2:33:24.408  8002 obs/sec      3         3             75000      0.26343          0.250091            0.722412       0.964952        0.818706           2.01003          0.0894212                        0.26202            0.247731              0.725338         0.965803          0.820514             2.02591            0.0864497
    2019-08-03 18:40:13  2:33:30.967  8151 obs/sec      5         5             125000     0.250596         0.225594            0.7488         0.971638        0.83085            2.01003          0.0762475                        0.247395           0.221482              0.755144         0.973026          0.836213             2.02591            0.0688036
    2019-08-03 18:40:19  2:33:37.452  8256 obs/sec      7         7             175000     0.240384         0.209823            0.768856       0.975951        0.850515           2.01003          0.0643713                        0.236812           0.206696              0.775643         0.977038          0.845639             2.02591            0.0590902
    2019-08-03 18:40:26  2:33:43.773  8364 obs/sec      9         9             225000     0.229906         0.197048            0.788568       0.979208        0.790218           2.01003          0.0555888                        0.229152           0.195638              0.789923         0.97982           0.80801              2.02591            0.0552048
    2019-08-03 18:40:29  2:33:47.195  8426 obs/sec      10        10            250000     0.225306         0.19059             0.796944       0.980628        0.802106           2.01003          0.0518962                        0.22624            0.191549              0.795229         0.980496          0.814837             2.02591            0.0529383
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.0035686106795473484
C28         0.9763184785842896     0.9763184785842896   0.0034841005493153145
C35         0.966440737247467      0.966440737247467    0.0034488507360909237
C25         0.9108178615570068     0.9108178615570068   0.0032503543478748127
C250        0.8725872039794922     0.8725872039794922   0.003113924014957576
---         ---                    ---                  ---
C908        0.18427564203739166    0.18427564203739166  0.0006576080241550801
C660        0.1842268407344818     0.1842268407344818   0.0006574338713043402
C534        0.18406791985034943    0.18406791985034943  0.0006568667445400223
C938        0.18235698342323303    0.18235698342323303  0.0006507610785341882
C446        0.17996247112751007    0.17996247112751007  0.0006422159963833637

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_130

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.008220650650901006   0.008360683917999268  0.0         0.019646246038768213   0.07682457566261292  0.11223515512678821    0.16072791814804077
    3        2        Softmax                      0.0   0.0   0.0003069321014095294  6.94937480147928e-05  0.0         -0.024058578133235642  0.33931493759155273  -0.005399990792506061  0.07929158210754395


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0523459673047303
RMSE: 0.22879241094216893
LogLoss: 0.19797126905369433
Mean Per-Class Error: 0.053992014941955935
AUC: 0.979049524161125
pr_auc: 0.8035526836986433
Gini: 0.95809904832225
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.54005493147302: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4674  294   0.0592   (294.0/4968.0)
1      247   4804  0.0489   (247.0/5051.0)
Total  4921  5098  0.054    (541.0/10019.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.540055     0.946694  193
max f2                       0.417261     0.957248  229
max f0point5                 0.59631      0.949546  175
max accuracy                 0.559278     0.946003  187
max precision                0.999432     0.995737  1
max recall                   3.09708e-05  1         399
max specificity              0.999951     0.999195  0
max absolute_mcc             0.540055     0.892029  193
max min_per_class_accuracy   0.559278     0.945357  187
max mean_per_class_accuracy  0.559278     0.946008  187
Gains/Lift Table: Avg response rate: 50.41 %, avg score: 51.34 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100808                   1                  1.98357     1.98357            1                1            1                           1                   0.019996        0.019996                   98.3568   98.3568
    2        0.0200619                   1                  1.96373     1.9737             0.99             1            0.995025                    1                   0.0196001       0.0395961                  96.3732   97.3699
    3        0.0300429                   0.999999           1.98357     1.97698            1                1            0.996678                    1                   0.0197981       0.0593942                  98.3568   97.6978
    4        0.040024                    0.999996           1.96373     1.97367            0.99             0.999998     0.995012                    0.999999            0.0196001       0.0789943                  96.3732   97.3675
    5        0.050005                    0.999986           1.98357     1.97565            1                0.999992     0.996008                    0.999998            0.0197981       0.0987923                  98.3568   97.5649
    6        0.10001                     0.999507           1.97565     1.97565            0.996008         0.999833     0.996008                    0.999916            0.0987923       0.197585                   97.5649   97.5649
    7        0.150015                    0.996972           1.95981     1.97037            0.988024         0.998537     0.993347                    0.999456            0.0980004       0.295585                   95.9812   97.037
    8        0.20002                     0.989463           1.93606     1.96179            0.976048         0.993753     0.989022                    0.99803             0.0968125       0.392398                   93.6057   96.1792
    9        0.30003                     0.943134           1.92814     1.95057            0.972056         0.970185     0.983367                    0.988748            0.192833        0.585231                   92.8139   95.0574
    10       0.40004                     0.821723           1.87667     1.9321             0.946108         0.890775     0.974052                    0.964255            0.187686        0.772916                   87.6669   93.2098
    11       0.50005                     0.568694           1.68267     1.88221            0.848303         0.710322     0.948902                    0.913468            0.168284        0.9412                     68.2667   88.2212
    12       0.59996                     0.24716            0.406225    1.63642            0.204795         0.395064     0.824988                    0.82714             0.040586        0.981786                   -59.3775  63.6419
    13       0.69997                     0.0629587          0.114817    1.41902            0.0578842        0.141998     0.715386                    0.729248            0.0114829       0.993269                   -88.5183  41.9016
    14       0.79998                     0.00659992         0.045531    1.24731            0.0229541        0.0274632    0.628821                    0.641514            0.00455355      0.997822                   -95.4469  24.7309
    15       0.89999                     0.000120149        0.0178165   1.11068            0.00898204       0.00207464   0.559942                    0.570457            0.00178183      0.999604                   -98.2184  11.0683
    16       1                           7.31106e-21        0.00395922  1                  0.00199601       1.76777e-05  0.504142                    0.513408            0.000395961     1                          -99.6041  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05128656428898873
RMSE: 0.22646537105921674
LogLoss: 0.1919285145659748
Mean Per-Class Error: 0.052403244869182686
AUC: 0.9807317018954687
pr_auc: 0.7975062164160728
Gini: 0.9614634037909373
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5389737836343476: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2952  176   0.0563   (176.0/3128.0)
1      148   2901  0.0485   (148.0/3049.0)
Total  3100  3077  0.0525   (324.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.538974     0.947111  187
max f2                       0.464069     0.956369  210
max f0point5                 0.622443     0.950935  163
max accuracy                 0.538974     0.947547  187
max precision                0.998777     0.997602  2
max recall                   4.01255e-05  1         399
max specificity              0.999951     0.999361  0
max absolute_mcc             0.538974     0.895126  187
max min_per_class_accuracy   0.554315     0.946292  183
max mean_per_class_accuracy  0.538974     0.947597  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.46 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323     2.00957            0.983871         1            0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999998           2.02591     2.01502            1                0.999999     0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999993           1.99323     2.00957            0.983871         0.999996     0.991935                    0.999999            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999981           2.02591     2.0128             1                0.999988     0.993528                    0.999997            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.99954            2.02591     2.01935            1                0.999843     0.996764                    0.99992             0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.997281           2.01935     2.01935            0.996764         0.998646     0.996764                    0.999495            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.989579           1.99313     2.0128             0.983819         0.993721     0.993528                    0.998052            0.0997048       0.402755                   99.3128   101.28
    9        0.299984                    0.937329           1.97009     1.99858            0.972447         0.969284     0.986508                    0.988473            0.196786        0.599541                   97.0091   99.8577
    10       0.400032                    0.802192           1.89806     1.97344            0.936893         0.879755     0.9741                      0.961282            0.189898        0.789439                   89.8061   97.3438
    11       0.500081                    0.527079           1.63253     1.90523            0.805825         0.681309     0.940434                    0.90527             0.163332        0.952771                   63.253    90.5234
    12       0.599968                    0.220537           0.318498    1.64106            0.157212         0.363219     0.810038                    0.815025            0.0318137       0.984585                   -68.1502  64.1064
    13       0.700016                    0.0589145          0.0786761   1.41776            0.038835         0.128432     0.699815                    0.716895            0.00787143      0.992457                   -92.1324  41.7762
    14       0.799903                    0.00681213         0.0525358   1.24728            0.0259319        0.0260349    0.615665                    0.630625            0.00524762      0.997704                   -94.7464  24.7282
    15       0.899951                    0.000117942        0.0163909   1.11044            0.00809061       0.0019508    0.54812                     0.560735            0.00163988      0.999344                   -98.3609  11.0442
    16       1                           9.92109e-25        0.00655634  1                  0.00323625       1.85695e-05  0.493605                    0.504636            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:34:00  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:34:04  2:27:21.743  7596 obs/sec      1         1             25000      0.299582         0.354986            0.640977       0.944958        0.745227           1.96393          0.114782                         0.293145           0.329815              0.656208         0.949999          0.715401             1.99323            0.111219
    2019-08-03 18:34:11  2:27:28.864  7653 obs/sec      3         3             75000      0.26599          0.253209            0.716979       0.963584        0.816588           1.98357          0.0885318                        0.259558           0.24047               0.730474         0.96745           0.824399             2.02591            0.0836976
    2019-08-03 18:34:17  2:27:35.486  7909 obs/sec      5         5             125000     0.250696         0.225936            0.748588       0.971531        0.84222            1.98357          0.0734604                        0.247299           0.221607              0.755333         0.972794          0.835711             2.02591            0.0710701
    2019-08-03 18:34:24  2:27:42.188  8019 obs/sec      7         7             175000     0.241653         0.213405            0.766399       0.975296        0.8161             1.98357          0.0663739                        0.239561           0.20931               0.770405         0.976495          0.854613             2.02591            0.0647564
    2019-08-03 18:34:33  2:27:51.262  8244 obs/sec      10        10            250000     0.228792         0.197971            0.790602       0.97905         0.803553           1.98357          0.0539974                        0.226465           0.191929              0.79482          0.980732          0.797506             2.02591            0.0524526
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.0038495931135978214
C36         0.8666355013847351     0.8666355013847351   0.0033361940581300713
C35         0.8222635984420776     0.8222635984420776   0.0031653802861247864
C250        0.8014822006225586     0.8014822006225586   0.003085380360187829
C34         0.7965903878211975     0.7965903878211975   0.0030665488713146997
---         ---                    ---                  ---
C201        0.17065568268299103    0.17065568268299103  0.0006569549408527773
C573        0.1676999181509018     0.1676999181509018   0.0006455764500646298
C383        0.16764366626739502    0.16764366626739502  0.0006453599032012553
C403        0.16536495089530945    0.16536495089530945  0.0006365877761970251
C582        0.1652473509311676     0.1652473509311676   0.0006361350641849053

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_186

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.010051641231463264   0.029237501323223114   0.0         0.019836908456356345   0.07922136783599854  0.10042757360676122    0.16914749145507812
    3        2        Softmax                      0.0   0.0   0.0003199508257694106  8.036362123675644e-05  0.0         -0.004352520025577178  0.3741436004638672   0.0007576575461777091  0.09353676438331604


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0517722392791459
RMSE: 0.22753513855918145
LogLoss: 0.19615450085840963
Mean Per-Class Error: 0.056065059548237595
AUC: 0.9794210162794926
pr_auc: 0.7793390177613615
Gini: 0.9588420325589853
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5338836903199576: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4670  304   0.0611   (304.0/4974.0)
1      257   4781  0.051    (257.0/5038.0)
Total  4927  5085  0.056    (561.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.533884     0.944582  195
max f2                       0.389625     0.956255  239
max f0point5                 0.632245     0.947706  164
max accuracy                 0.533884     0.943967  195
max precision                0.999014     0.994721  2
max recall                   3.39102e-05  1         399
max specificity              0.999931     0.998794  0
max absolute_mcc             0.533884     0.887962  195
max min_per_class_accuracy   0.55054      0.943033  190
max mean_per_class_accuracy  0.533884     0.943935  195
Gains/Lift Table: Avg response rate: 50.32 %, avg score: 50.93 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   1                  1.9873      1.9873             1                1            1                           1                   0.0200476       0.0200476                  98.7297   98.7297
    2        0.0200759                   1                  1.9873      1.9873             1                1            1                           1                   0.0198491       0.0398968                  98.7297   98.7297
    3        0.0300639                   0.999999           1.96742     1.98069            0.99             1            0.996678                    1                   0.0196507       0.0595474                  96.7424   98.0694
    4        0.0400519                   0.999996           1.9873      1.98234            1                0.999998     0.997506                    0.999999            0.0198491       0.0793966                  98.7297   98.2341
    5        0.05004                     0.999987           1.9873      1.98333            1                0.999992     0.998004                    0.999998            0.0198491       0.0992457                  98.7297   98.333
    6        0.10008                     0.999669           1.97143     1.97738            0.992016         0.99988      0.99501                     0.999939            0.0986503       0.197896                   97.143    97.738
    7        0.15002                     0.997336           1.96742     1.97407            0.99             0.998841     0.993342                    0.999573            0.0982533       0.296149                   96.7424   97.4066
    8        0.20006                     0.990978           1.9635      1.97142            0.988024         0.994715     0.992012                    0.998358            0.0982533       0.394403                   96.3497   97.1422
    9        0.30004                     0.944323           1.93171     1.95819            0.972028         0.971896     0.985353                    0.98954             0.193132        0.587535                   93.1708   95.8188
    10       0.40002                     0.81661            1.86222     1.9342             0.937063         0.889149     0.973283                    0.964449            0.186185        0.77372                    86.2222   93.4203
    11       0.5                         0.554982           1.66965     1.8813             0.84016          0.700068     0.946664                    0.911583            0.166931        0.940651                   66.9647   88.1302
    12       0.59998                     0.219437           0.440739    1.64125            0.221778         0.378159     0.82587                     0.822694            0.0440651       0.984716                   -55.9261  64.1248
    13       0.69996                     0.0608305          0.0754418   1.41759            0.037962         0.129351     0.713328                    0.723659            0.00754268      0.992259                   -92.4558  41.7594
    14       0.79994                     0.00637423         0.0456622   1.24612            0.022977         0.026029     0.627045                    0.636466            0.0045653       0.996824                   -95.4338  24.6124
    15       0.89992                     0.000136292        0.025809    1.11055            0.012987         0.00200075   0.558824                    0.565978            0.00258039      0.999405                   -97.4191  11.0548
    16       1                           4.39442e-27        0.00594999  1                  0.00299401       1.96501e-05  0.503196                    0.509337            0.000595474     1                          -99.405   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05169910041640905
RMSE: 0.2273743618273816
LogLoss: 0.19228547016624783
Mean Per-Class Error: 0.052502644362035555
AUC: 0.9805619468544045
pr_auc: 0.7809704460867323
Gini: 0.9611238937088089
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5682727843547764: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2976  152   0.0486   (152.0/3128.0)
1      172   2877  0.0564   (172.0/3049.0)
Total  3148  3029  0.0525   (324.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.568273     0.946693  182
max f2                       0.409295     0.95547   229
max f0point5                 0.589771     0.950777  175
max accuracy                 0.568273     0.947547  182
max precision                0.999389     0.997323  1
max recall                   4.3168e-05   1         399
max specificity              0.999936     0.999361  0
max absolute_mcc             0.568273     0.895088  182
max min_per_class_accuracy   0.550017     0.947196  186
max mean_per_class_accuracy  0.568273     0.947497  182
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.44 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999999           1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999996           2.02591     2.01774            1                0.999997     0.995968                    0.999999            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999987           1.9927      2.0128             0.983607         0.999992     0.993528                    0.999998            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999611           2.02591     2.01935            1                0.999872     0.996764                    0.999935            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.997291           2.01935     2.01935            0.996764         0.998743     0.996764                    0.999538            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.99064            2.00624     2.01608            0.990291         0.99441      0.995146                    0.998256            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.943239           1.95039     1.9942             0.962723         0.971492     0.98435                     0.989344            0.194818        0.598229                   95.039    99.4204
    10       0.400032                    0.802117           1.92429     1.97672            0.949838         0.880286     0.975718                    0.962069            0.192522        0.790751                   92.4287   97.6718
    11       0.500081                    0.527407           1.61286     1.90392            0.796117         0.677055     0.939786                    0.905047            0.161364        0.952115                   61.286    90.3923
    12       0.599968                    0.218089           0.328348    1.64161            0.162075         0.362412     0.810308                    0.814706            0.0327976       0.984913                   -67.1652  64.161
    13       0.700016                    0.0592557          0.0655634   1.41636            0.0323625        0.128963     0.699121                    0.716697            0.00655953      0.991473                   -93.4437  41.6357
    14       0.799903                    0.00621201         0.0591027   1.24687            0.0291734        0.0250611    0.615462                    0.63033             0.00590357      0.997376                   -94.0897  24.6872
    15       0.899951                    0.000127629        0.0229472   1.11081            0.0113269        0.00184893   0.5483                      0.560461            0.00229583      0.999672                   -97.7053  11.0807
    16       1                           6.82799e-26        0.00327817  1                  0.00161812       1.91972e-05  0.493605                    0.50439             0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:58:37  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:58:41  3:51:58.494  7427 obs/sec      1         1             25000      0.300006         0.345246            0.63997        0.944936        0.693292           1.96762          0.11706                          0.300822           0.339343              0.637965         0.946101          0.730482             1.99323            0.117533
    2019-08-03 19:58:47  3:52:05.394  7765 obs/sec      3         3             75000      0.263611         0.249992            0.722026       0.964518        0.832096           1.9873           0.0889932                        0.261257           0.241564              0.726935         0.966726          0.830843             2.02591            0.0874211
    2019-08-03 19:58:54  3:52:12.124  7950 obs/sec      5         5             125000     0.250106         0.225753            0.749777       0.971393        0.845654           1.9873           0.0749101                        0.245525           0.216908              0.758831         0.973974          0.837002             2.02591            0.0681561
    2019-08-03 19:59:03  3:52:21.406  8211 obs/sec      8         8             200000     0.236023         0.205563            0.777163       0.977006        0.840891           1.9873           0.0648222                        0.233327           0.199537              0.782199         0.978697          0.811336             2.02591            0.057795
    2019-08-03 19:59:10  3:52:27.837  8297 obs/sec      10        10            250000     0.227535         0.196155            0.792903       0.979421        0.779339           1.9873           0.0560328                        0.227374           0.192285              0.79317          0.980562          0.78097              2.02591            0.0524526
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C31         1.0                    1.0                  0.0036919635326297753
C35         0.9671233892440796     0.9671233892440796   0.003570584284642453
C28         0.9597414135932922     0.9597414135932922   0.0035433302997409854
C36         0.9328684210777283     0.9328684210777283   0.0034441161913608903
C25         0.8645060062408447     0.8645060062408447   0.0031917246487806073
---         ---                    ---                  ---
C731        0.17816214263439178    0.17816214263439178  0.0006577681335013589
C599        0.17453846335411072    0.17453846335411072  0.0006443896417446151
C616        0.17186114192008972    0.17186114192008972  0.0006345050686450815
C888        0.17116598784923553    0.17116598784923553  0.0006319385851659288
C702        0.16578929126262665    0.16578929126262665  0.0006120880174421538

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_151

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        980      Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.008306162533220194   0.006907021626830101   0.0         0.019489068233082673  0.0751379132270813  0.10532186053430126   0.17919856309890747
    3        2        Softmax                      0.0   0.0   0.0003602620520837263  6.059688166715205e-05  0.0         0.022182497903486365  0.3678591251373291  0.000373455229897221  0.17369157075881958


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05363865961821464
RMSE: 0.23160021506513037
LogLoss: 0.20072198026338195
Mean Per-Class Error: 0.05650946401893231
AUC: 0.9783454187916679
pr_auc: 0.8003615424587205
Gini: 0.9566908375833358
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5561680391434848: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4751  277   0.0551   (277.0/5028.0)
1      289   4700  0.0579   (289.0/4989.0)
Total  5040  4977  0.0565   (566.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.556168     0.943207  190
max f2                       0.427219     0.952786  227
max f0point5                 0.600225     0.946577  177
max accuracy                 0.556168     0.943496  190
max precision                0.99996      0.997735  0
max recall                   5.0525e-05   1         399
max specificity              0.99996      0.999602  0
max absolute_mcc             0.556168     0.886992  190
max min_per_class_accuracy   0.550573     0.943119  192
max mean_per_class_accuracy  0.556168     0.943491  190
Gains/Lift Table: Avg response rate: 49.81 %, avg score: 50.47 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   1                  2.00782    2.00782            1                1            1                           1                   0.0202445       0.0202445                  100.782   100.782
    2        0.0200659                   1                  2.00782    2.00782            1                1            1                           1                   0.0200441       0.0402886                  100.782   100.782
    3        0.0300489                   0.999999           2.00782    2.00782            1                1            1                           1                   0.0200441       0.0603327                  100.782   100.782
    4        0.0400319                   0.999996           2.00782    2.00782            1                0.999998     1                           0.999999            0.0200441       0.0803768                  100.782   100.782
    5        0.050015                    0.999989           2.00782    2.00782            1                0.999993     1                           0.999998            0.0200441       0.100421                   100.782   100.782
    6        0.10003                     0.999581           1.99579    2.00181            0.994012         0.999863     0.997006                    0.999931            0.0998196       0.200241                   99.5794   100.181
    7        0.150045                    0.997051           1.98377    1.99579            0.988024         0.99863      0.994012                    0.999497            0.0992183       0.299459                   98.3771   99.5794
    8        0.20006                     0.988945           1.96373    1.98778            0.978044         0.99363      0.99002                     0.99803             0.0982161       0.397675                   96.3733   98.7779
    9        0.29999                     0.935406           1.95567    1.97708            0.974026         0.967848     0.984692                    0.987976            0.19543         0.593105                   95.5666   97.7082
    10       0.40002                     0.796261           1.87557    1.9517             0.934132         0.874479     0.972049                    0.959595            0.187613        0.780718                   87.5566   95.1697
    11       0.50005                     0.542111           1.6331     1.88797            0.813373         0.685618     0.940307                    0.904789            0.163359        0.944077                   63.3105   88.7965
    12       0.59998                     0.221506           0.38311    1.63732            0.190809         0.366204     0.815474                    0.815084            0.0382842       0.982361                   -61.689   63.7323
    13       0.70001                     0.0574208          0.116221   1.41996            0.0578842        0.129629     0.707216                    0.717134            0.0116256       0.993987                   -88.3779  41.9961
    14       0.79994                     0.0064237          0.032093   1.24659            0.015984         0.0250223    0.620866                    0.630674            0.00320706      0.997194                   -96.7907  24.6586
    15       0.89997                     0.000117643        0.0180343  1.11003            0.00898204       0.00182245   0.552856                    0.560778            0.00180397      0.998998                   -98.1966  11.0034
    16       1                           1.15723e-25        0.010019   1                  0.00499002       1.97627e-05  0.498053                    0.504686            0.0010022       1                          -98.9981  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05168869091242535
RMSE: 0.22735147000278083
LogLoss: 0.19293347409615652
Mean Per-Class Error: 0.05250678600757119
AUC: 0.980422651257089
pr_auc: 0.778237687014917
Gini: 0.9608453025141781
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5559035908629973: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2977  151   0.0483   (151.0/3128.0)
1      173   2876  0.0567   (173.0/3049.0)
Total  3150  3027  0.0525   (324.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.555904     0.946675  190
max f2                       0.388678     0.954469  237
max f0point5                 0.609036     0.949936  175
max accuracy                 0.555904     0.947547  190
max precision                0.999318     0.997195  1
max recall                   2.32889e-05  1         399
max specificity              0.999922     0.999361  0
max absolute_mcc             0.555904     0.895091  190
max min_per_class_accuracy   0.535366     0.946611  196
max mean_per_class_accuracy  0.555904     0.947493  190
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.02 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  1.99323     2.00957            0.983871         1            0.991935                    1                   0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999998           2.02591     2.01502            1                0.999999     0.994624                    1                   0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999995           1.99323     2.00957            0.983871         0.999997     0.991935                    0.999999            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999985           2.02591     2.0128             1                0.999991     0.993528                    0.999997            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999523           2.02591     2.01935            1                0.999846     0.996764                    0.999922            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.996657           2.00624     2.01498            0.990291         0.998432     0.994606                    0.999425            0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.98879            1.99313     2.00952            0.983819         0.99331      0.991909                    0.997896            0.0997048       0.402099                   99.3128   100.952
    9        0.299984                    0.931576           1.96681     1.9953             0.970827         0.965961     0.984889                    0.987263            0.196458        0.598557                   96.6807   99.5297
    10       0.400032                    0.786838           1.91117     1.97426            0.943366         0.868563     0.974504                    0.957576            0.19121         0.789767                   91.1174   97.4258
    11       0.500081                    0.514911           1.60303     1.89999            0.791262         0.667573     0.937844                    0.899556            0.16038         0.950148                   60.3026   89.9988
    12       0.599968                    0.212536           0.344766    1.64106            0.170178         0.350056     0.810038                    0.808072            0.0344375       0.984585                   -65.5234  64.1064
    13       0.700016                    0.0570911          0.0917888   1.41964            0.0453074        0.126961     0.70074                     0.710725            0.00918334      0.993768                   -90.8211  41.9636
    14       0.799903                    0.00654094         0.0426853   1.24769            0.0210697        0.0249623    0.615867                    0.625092            0.00426369      0.998032                   -95.7315  24.7692
    15       0.899951                    0.000121788        0.0163909   1.11081            0.00809061       0.00190288   0.5483                      0.555811            0.00163988      0.999672                   -98.3609  11.0807
    16       1                           1.15723e-25        0.00327817  1                  0.00161812       1.90725e-05  0.493605                    0.500205            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:59:39  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:59:42  2:53:00.500  7259 obs/sec      1         1             25000      0.30165          0.351953            0.636024       0.945026        0.701759           2.00782          0.116702                         0.29278            0.325644              0.657064         0.950474          0.693559             2.02591            0.111057
    2019-08-03 18:59:52  2:53:10.329  7888 obs/sec      4         4             100000     0.259623         0.239343            0.730379       0.967869        0.801432           2.00782          0.0807627                        0.254895           0.230165              0.740072         0.97046           0.836809             2.02591            0.0767363
    2019-08-03 18:59:59  2:53:16.884  8033 obs/sec      6         6             150000     0.247001         0.221061            0.755958       0.972934        0.808647           2.00782          0.0704802                        0.242775           0.212282              0.764202         0.975321          0.831843             2.02591            0.0673466
    2019-08-03 19:00:05  2:53:23.545  8127 obs/sec      8         8             200000     0.237549         0.20929             0.774278       0.976084        0.813548           2.00782          0.0625936                        0.23171            0.199064              0.785207         0.97884           0.810053             2.02591            0.0597377
    2019-08-03 19:00:12  2:53:29.969  8238 obs/sec      10        10            250000     0.2316           0.200722            0.785442       0.978345        0.800362           2.00782          0.0565039                        0.227351           0.192933              0.793211         0.980423          0.778238             2.02591            0.0524526
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0033648522238875927
C36         0.9858929514884949     0.9858929514884949   0.0033173840903311645
C31         0.8876183032989502     0.8876183032989502   0.002986704421818804
C28         0.8858931660652161     0.8858931660652161   0.0029808995899613627
C35         0.8556333780288696     0.8556333780288696   0.002879079874892895
---         ---                    ---                  ---
C468        0.20402787625789642    0.20402787625789642  0.0006865236531614454
C832        0.20192106068134308    0.20192106068134308  0.0006794345300833587
C447        0.19640500843524933    0.19640500843524933  0.0006608738294160101
C383        0.19196933507919312    0.19196933507919312  0.0006459484440594454
C562        0.1847783625125885     0.1847783625125885   0.0006217518840267911

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_100

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight             weight_rms           mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ----------------------  -------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.030909169178832078  0.061635822057724       0.0         -0.0014593800584977279  0.1249890923500061   0.012021202586378564     0.15537530183792114
    3        2        Softmax                 0.0   0.0   0.001765130165949813  0.00016011018306016922  0.0         0.038849884789669886    0.48251938819885254  -0.00011310835150163401  0.19118988513946533


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.058837242477218006
RMSE: 0.2425638935975798
LogLoss: 0.20199748470332618
Mean Per-Class Error: 0.07782400986284488
AUC: 0.9745915817476062
pr_auc: 0.9557202813238225
Gini: 0.9491831634952124
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4977456054429764: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4582  395   0.0794   (395.0/4977.0)
1      385   4662  0.0763   (385.0/5047.0)
Total  4967  5057  0.0778   (780.0/10024.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.497746     0.922803  202
max f2                       0.203899     0.94387   288
max f0point5                 0.764579     0.936122  127
max accuracy                 0.497746     0.922187  202
max precision                0.998625     1         0
max recall                   0.00121855   1         398
max specificity              0.998625     1         0
max absolute_mcc             0.497746     0.844365  202
max min_per_class_accuracy   0.506182     0.921339  200
max mean_per_class_accuracy  0.497746     0.922176  202
Gains/Lift Table: Avg response rate: 50.35 %, avg score: 50.03 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100758                   0.998014           1.98613     1.98613            1                0.998607    1                           0.998607            0.0200119       0.0200119                  98.613    98.613
    2        0.0200519                   0.997259           1.98613     1.98613            1                0.997648    1                           0.99813             0.0198138       0.0398256                  98.613    98.613
    3        0.0300279                   0.996638           1.98613     1.98613            1                0.996969    1                           0.997744            0.0198138       0.0596394                  98.613    98.613
    4        0.040004                    0.996028           1.98613     1.98613            1                0.996352    1                           0.997397            0.0198138       0.0794531                  98.613    98.613
    5        0.0500798                   0.995437           1.98613     1.98613            1                0.99573     1                           0.997062            0.0200119       0.099465                   98.613    98.613
    6        0.10006                     0.991306           1.9782      1.98217            0.996008         0.993459    0.998006                    0.995262            0.0988706       0.198336                   97.8202   98.217
    7        0.15004                     0.986449           1.96234     1.97557            0.988024         0.989005    0.994681                    0.993178            0.0980781       0.296414                   96.2344   97.5566
    8        0.20002                     0.980638           1.96631     1.97325            0.99002          0.983671    0.993516                    0.990802            0.0982762       0.39469                    96.6309   97.3253
    9        0.29998                     0.955219           1.93261     1.95971            0.973054         0.969753    0.986698                    0.983788            0.193184        0.587874                   93.2612   95.971
    10       0.40004                     0.871268           1.84356     1.93066            0.928215         0.923389    0.97207                     0.968681            0.184466        0.77234                    84.3557   93.0657
    11       0.5                         0.516473           1.45689     1.83594            0.733533         0.730504    0.924381                    0.921065            0.145631        0.917971                   45.6892   83.5942
    12       0.59996                     0.130878           0.600596    1.63012            0.302395         0.296686    0.820752                    0.817036            0.0600357       0.978007                   -39.9404  63.012
    13       0.70002                     0.0333098          0.158415    1.41976            0.0797607        0.0701935   0.714835                    0.710283            0.015851        0.993858                   -84.1585  41.9756
    14       0.79998                     0.0119505          0.0297325   1.24607            0.0149701        0.0205716   0.627385                    0.624102            0.00297206      0.99683                    -97.0268  24.6068
    15       0.89994                     0.00465508         0.0218038   1.11008            0.010978         0.00784708  0.558918                    0.555652            0.00217951      0.999009                   -97.8196  11.0084
    16       1                           0.000209615        0.00990095  1                  0.00498504       0.00256417  0.503492                    0.50031             0.000990688     1                          -99.0099  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05576872906637999
RMSE: 0.23615403673530544
LogLoss: 0.1946677302397251
Mean Per-Class Error: 0.07062328724608036
AUC: 0.9761600067608431
pr_auc: 0.9569131063474202
Gini: 0.9523200135216863
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46008153644495325: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2877  251   0.0802   (251.0/3128.0)
1      186   2863  0.061    (186.0/3049.0)
Total  3063  3114  0.0707   (437.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.460082     0.929093  213
max f2                       0.178911     0.944862  292
max f0point5                 0.755673     0.93806   128
max accuracy                 0.480513     0.929254  207
max precision                0.998742     1         0
max recall                   0.00221755   1         396
max specificity              0.998742     1         0
max absolute_mcc             0.460082     0.858712  213
max min_per_class_accuracy   0.509265     0.927749  198
max mean_per_class_accuracy  0.460082     0.929377  213
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.21 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.99816            2.02591     2.02591            1                0.998687    1                           0.998687            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.997507           2.02591     2.02591            1                0.997844    1                           0.998265            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.996664           2.02591     2.02591            1                0.997006    1                           0.997846            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.995999           2.02591     2.02591            1                0.996299    1                           0.997459            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.995292           2.02591     2.02591            1                0.995656    1                           0.997103            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.991318           2.0128      2.01935            0.993528         0.993316    0.996764                    0.995209            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.986053           1.99968     2.0128             0.987055         0.988835    0.993528                    0.993085            0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.979042           2.00624     2.01116            0.990291         0.982848    0.992718                    0.990525            0.100361        0.402427                   100.624   101.116
    9        0.299984                    0.952507           1.97009     1.99748            0.972447         0.9677      0.985969                    0.982925            0.196786        0.599213                   97.0091   99.7484
    10       0.400032                    0.862122           1.87839     1.9677             0.927184         0.917471    0.971267                    0.966555            0.18793         0.787143                   87.8392   96.7699
    11       0.500081                    0.483905           1.4719      1.86851            0.726537         0.704834    0.922305                    0.914194            0.147261        0.934405                   47.1899   86.8507
    12       0.599968                    0.110644           0.449837    1.63232            0.222042         0.260144    0.80572                     0.805303            0.0449328       0.979337                   -55.0163  63.2317
    13       0.700016                    0.0307132          0.14424     1.41964            0.0711974        0.0604241   0.70074                     0.698842            0.014431        0.993768                   -85.576   41.9636
    14       0.799903                    0.0114972          0.0525358   1.24892            0.0259319        0.0192139   0.616474                    0.613975            0.00524762      0.999016                   -94.7464  24.8922
    15       0.899951                    0.00443891         0.00655634  1.11081            0.00323625       0.00744563  0.5483                      0.546546            0.000655953     0.999672                   -99.3444  11.0807
    16       1                           0.000209615        0.00327817  1                  0.00161812       0.00249041  0.493605                    0.492114            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:57:05  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:57:10  1:50:28.021  4848 obs/sec      1         1             25000      0.292005         0.280925            0.658916       0.952178        0.926249           1.98613          0.116421                         0.28952            0.277989              0.664658         0.95305           0.923403             2.02591            0.113324
    2019-08-03 17:57:16  1:50:33.632  4821 obs/sec      2         2             50000      0.279934         0.260963            0.686534       0.958923        0.946658           1.98613          0.106045                         0.275512           0.25475               0.696322         0.961031          0.945602             2.02591            0.100534
    2019-08-03 17:57:21  1:50:39.172  4830 obs/sec      3         3             75000      0.27411          0.251307            0.699441       0.961937        0.956849           1.98613          0.10425                          0.268828           0.245302              0.710878         0.96378           0.95217              2.02591            0.093411
    2019-08-03 17:57:27  1:50:44.870  4808 obs/sec      4         4             100000     0.271087         0.246711            0.706034       0.963288        0.956331           1.98613          0.101955                         0.266733           0.24188               0.715367         0.964784          0.956361             2.02591            0.093411
    2019-08-03 17:57:33  1:50:50.400  4824 obs/sec      5         5             125000     0.267299         0.241121            0.714191       0.964217        0.954546           1.98613          0.0965682                        0.262034           0.234512              0.725307         0.965887          0.958735             2.02591            0.0935729
    2019-08-03 17:57:38  1:50:56.114  4810 obs/sec      6         6             150000     0.25958          0.226741            0.73046        0.968839        0.961618           1.98613          0.0925778                        0.256609           0.222456              0.736564         0.970198          0.960121             2.02591            0.0867735
    2019-08-03 17:57:44  1:51:01.603  4827 obs/sec      7         7             175000     0.261357         0.232648            0.726756       0.966625        0.959475           1.98613          0.0909816                        0.257065           0.225765              0.735626         0.96884           0.95669              2.02591            0.0867735
    2019-08-03 17:57:49  1:51:07.200  4828 obs/sec      8         8             200000     0.254726         0.220215            0.740446       0.970121        0.9588             1.98613          0.0852953                        0.248615           0.212046              0.752722         0.972158          0.961847             2.02591            0.0802979
    2019-08-03 17:57:55  1:51:12.804  4829 obs/sec      9         9             225000     0.2489           0.21212             0.752184       0.972074        0.959913           1.98613          0.082502                         0.243057           0.204893              0.763655         0.973753          0.962939             2.02591            0.0751174
    2019-08-03 17:58:01  1:51:18.643  4809 obs/sec      10        10            250000     0.242564         0.201997            0.76464        0.974592        0.95572            1.98613          0.0778132                        0.236154           0.194668              0.776889         0.97616           0.956913             2.02591            0.0707463
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.005217609498922522
C438        0.7957372069358826     0.7957372069358826   0.004151846009554738
C374        0.7566585540771484     0.7566585540771484   0.00394794885919391
C88         0.716965913772583      0.716965913772583    0.003740848162103495
C322        0.6648444533348083     0.6648444533348083   0.0034688987350256473
---         ---                    ---                  ---
C810        0.10088072717189789    0.10088072717189789  0.0005263562403503058
C548        0.100743867456913      0.100743867456913    0.0005256421598013808
C773        0.09842151403427124    0.09842151403427124  0.00051352502652355
C758        0.08994156867265701    0.08994156867265701  0.00046927998305444754
C555        0.08586917072534561    0.08586917072534561  0.000448031800841163

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_136

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0023615080367270433  0.0019167978316545486  0.0         0.026767542115058277  0.09027445316314697  -0.14556787702190713   0.4084879159927368
    3        2        Softmax                      0.0   0.0   0.0002447906308589154  5.472340853884816e-05  0.0         -0.16965750011149794  0.8120753765106201   0.0007096956045502395  0.07875341176986694


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05617105361922862
RMSE: 0.23700433249041802
LogLoss: 0.2055155658967095
Mean Per-Class Error: 0.06409158487239819
AUC: 0.9776203038684271
pr_auc: 0.7751809392771387
Gini: 0.9552406077368543
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5391573130430622: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4637  325   0.0655   (325.0/4962.0)
1      317   4740  0.0627   (317.0/5057.0)
Total  4954  5065  0.0641   (642.0/10019.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.539157     0.936574  191
max f2                       0.373971     0.950875  244
max f0point5                 0.648089     0.943521  154
max accuracy                 0.539157     0.935922  191
max precision                0.999967     0.998049  0
max recall                   1.51889e-05  1         399
max specificity              0.999967     0.999597  0
max absolute_mcc             0.539157     0.871831  191
max min_per_class_accuracy   0.539157     0.934502  191
max mean_per_class_accuracy  0.539157     0.935908  191
Gains/Lift Table: Avg response rate: 50.47 %, avg score: 50.46 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100808                   1                  1.98121     1.98121            1                1            1                           1                   0.0199723       0.0199723                  98.1214   98.1214
    2        0.0200619                   1                  1.98121     1.98121            1                1            1                           1                   0.0197746       0.0397469                  98.1214   98.1214
    3        0.0300429                   1                  1.98121     1.98121            1                1            1                           1                   0.0197746       0.0595215                  98.1214   98.1214
    4        0.040024                    0.999999           1.9614      1.97627            0.99             1            0.997506                    1                   0.0195768       0.0790983                  96.1402   97.6273
    5        0.050005                    0.999998           1.98121     1.97726            1                0.999999     0.998004                    1                   0.0197746       0.0988728                  98.1214   97.726
    6        0.10001                     0.999812           1.97726     1.97726            0.998004         0.999946     0.998004                    0.999973            0.0988728       0.197746                   97.726    97.726
    7        0.150015                    0.998313           1.96144     1.97199            0.99002          0.999212     0.995343                    0.999719            0.0980819       0.295828                   96.1442   97.1987
    8        0.20002                     0.992              1.94958     1.96638            0.984032         0.995696     0.992515                    0.998713            0.0974886       0.393316                   94.9578   96.6385
    9        0.30003                     0.940771           1.91992     1.9509             0.969062         0.973029     0.984697                    0.990152            0.192011        0.585327                   91.9919   95.0896
    10       0.40004                     0.787165           1.86653     1.92981            0.942116         0.872766     0.974052                    0.960806            0.186672        0.771999                   86.6533   92.9805
    11       0.50514                     0.539176           1.57293     1.85555            0.793922         0.662126     0.936574                    0.898662            0.165315        0.937315                   57.293    85.5553
    12       0.59996                     0.232842           0.444209    1.6325             0.224211         0.380359     0.823989                    0.816747            0.0421198       0.979434                   -55.5791  63.2499
    13       0.69997                     0.0484617          0.124567    1.41705            0.0628743        0.1264       0.715243                    0.718112            0.012458        0.991892                   -87.5433  41.705
    14       0.79998                     0.00331095         0.0573405   1.24706            0.0289421        0.0190697    0.629445                    0.630721            0.00573463      0.997627                   -94.2659  24.7065
    15       0.89999                     1.62299e-05        0.0217499   1.1109             0.010978         0.00082141   0.560719                    0.560724            0.0021752       0.999802                   -97.825   11.0904
    16       1                           2.93723e-32        0.00197726  1                  0.000998004      1.83764e-06  0.504741                    0.504647            0.000197746     1                          -99.8023  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05225334530464434
RMSE: 0.2285899063927459
LogLoss: 0.19514372082083856
Mean Per-Class Error: 0.05603415735652706
AUC: 0.9808335654052857
pr_auc: 0.7578475335302158
Gini: 0.9616671308105713
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5060783075980719: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2918  210   0.0671   (210.0/3128.0)
1      137   2912  0.0449   (137.0/3049.0)
Total  3055  3122  0.0562   (347.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.506078     0.943769  203
max f2                       0.426848     0.954893  228
max f0point5                 0.593409     0.94951   173
max accuracy                 0.506078     0.943824  203
max precision                0.999056     0.997812  2
max recall                   2.87043e-05  1         399
max specificity              0.999963     0.999361  0
max absolute_mcc             0.506078     0.887911  203
max min_per_class_accuracy   0.534151     0.942775  193
max mean_per_class_accuracy  0.506078     0.943966  203
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.70 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999999           2.02591     2.01774            1                1            0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999998           2.02591     2.01935            1                0.999999     0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999861           2.01935     2.01935            0.996764         0.999958     0.996764                    0.999979            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.998622           2.01935     2.01935            0.996764         0.999401     0.996764                    0.999786            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.993246           2.00624     2.01608            0.990291         0.996307     0.995146                    0.998917            0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.936518           1.97009     2.00076            0.972447         0.972034     0.987588                    0.989965            0.196786        0.600197                   97.0091   100.076
    10       0.400032                    0.775817           1.92101     1.98082            0.94822          0.867763     0.977742                    0.959402            0.192194        0.792391                   92.1009   98.0817
    11       0.500081                    0.519174           1.56369     1.89736            0.771845         0.642401     0.936549                    0.895982            0.156445        0.948836                   56.3688   89.7364
    12       0.599968                    0.205244           0.354616    1.64052            0.175041         0.354332     0.809768                    0.805804            0.0354214       0.984257                   -64.5384  64.0517
    13       0.700016                    0.0493542          0.0819543   1.41776            0.0404531        0.115558     0.699815                    0.707152            0.00819941      0.992457                   -91.8046  41.7762
    14       0.799903                    0.00320676         0.0525358   1.24728            0.0259319        0.0186091    0.615665                    0.621171            0.00524762      0.997704                   -94.7464  24.7282
    15       0.899951                    2.02925e-05        0.0163909   1.11044            0.00809061       0.00078263   0.54812                     0.552202            0.00163988      0.999344                   -98.3609  11.0442
    16       1                           2.93723e-32        0.00655634  1                  0.00323625       2.11734e-06  0.493605                    0.496955            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:38:43  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:38:44  2:32:01.817  18615 obs/sec     1         1             25000      0.32132          0.433361            0.586977       0.932733        0.67019            1.98121          0.132648                         0.313345           0.404199              0.607195         0.939878          0.635825             1.99323            0.125951
    2019-08-03 18:38:49  2:32:06.951  20151 obs/sec     5         5             125000     0.257728         0.243886            0.73428        0.96811         0.772115           1.98121          0.0787504                        0.251686           0.233147              0.746575         0.971119          0.764392             2.02591            0.0739841
    2019-08-03 18:38:54  2:32:12.022  20538 obs/sec     9         9             225000     0.242492         0.217053            0.76477        0.975387        0.780749           1.98121          0.0666733                        0.235985           0.208025              0.777209         0.978129          0.77213              2.02591            0.060871
    2019-08-03 18:38:56  2:32:13.474  20667 obs/sec     10        10            250000     0.237004         0.205516            0.775296       0.97762         0.775181           1.98121          0.0640783                        0.22859            0.195144              0.790952         0.980834          0.757848             2.02591            0.0561761
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.003808250518212815
C36         0.8962792158126831     0.8962792158126831   0.0034132557880820263
C28         0.8884477615356445     0.8884477615356445   0.003383431648273134
C35         0.8467828035354614     0.8467828035354614   0.0032247610503776214
C438        0.807241678237915      0.807241678237915    0.0030741785394725225
---         ---                    ---                  ---
C476        0.13479158282279968    0.13479158282279968  0.0005133201151356525
C363        0.12941771745681763    0.12941771745681763  0.0004928550895708455
C226        0.12840089201927185    0.12840089201927185  0.0004889827635713797
C361        0.12718021869659424    0.12718021869659424  0.0004843341337577242
C651        0.11191307008266449    0.11191307008266449  0.00042619300713709414

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_200

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight          weight_rms          mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  -------------------  ------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0027299757801209088   0.002089615911245346   0.0         0.02660446092419499  0.0928652286529541  -0.06027017938672576    0.36912357807159424
    3        2        Softmax                      0.0   0.0   0.00024118848205034737  5.188708018977195e-05  0.0         0.03445323171035852  0.7430047988891602  -0.0007577639625851174  0.11757683753967285


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0537328942081445
RMSE: 0.23180356815231404
LogLoss: 0.20066034541019676
Mean Per-Class Error: 0.056653035538231644
AUC: 0.9791210388214597
pr_auc: 0.8026424937709816
Gini: 0.9582420776429195
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5387159777562507: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4724  275   0.055    (275.0/4999.0)
1      292   4717  0.0583   (292.0/5009.0)
Total  5016  4992  0.0567   (567.0/10008.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.538716     0.943306  196
max f2                       0.425457     0.951085  229
max f0point5                 0.606402     0.948662  173
max accuracy                 0.538716     0.943345  196
max precision                0.999959     0.99548   0
max recall                   3.0116e-05   1         399
max specificity              0.999959     0.9992    0
max absolute_mcc             0.538716     0.886696  196
max min_per_class_accuracy   0.534079     0.942703  197
max mean_per_class_accuracy  0.538716     0.943347  196
Gains/Lift Table: Avg response rate: 50.05 %, avg score: 49.82 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100919                   1                  1.998       1.998              1                1            1                           1                   0.0201637       0.0201637                  99.8004   99.8004
    2        0.0200839                   1                  1.97802     1.98806            0.99             1            0.995025                    1                   0.0197644       0.0399281                  97.8024   98.8063
    3        0.0300759                   0.999999           1.998       1.99137            1                1            0.996678                    1                   0.0199641       0.0598922                  99.8004   99.1366
    4        0.0400679                   0.999997           1.998       1.99302            1                0.999998     0.997506                    1                   0.0199641       0.0798563                  99.8004   99.3021
    5        0.05006                     0.999989           1.998       1.99402            1                0.999994     0.998004                    0.999998            0.0199641       0.0998203                  99.8004   99.4016
    6        0.10002                     0.999522           1.97802     1.98603            0.99             0.999845     0.994006                    0.999922            0.0988221       0.198642                   97.8024   98.6028
    7        0.15008                     0.996434           1.97806     1.98337            0.99002          0.998324     0.992676                    0.999389            0.0990218       0.297664                   97.8063   98.3371
    8        0.20004                     0.986497           1.97003     1.98004            0.986            0.99228      0.991009                    0.997613            0.0984228       0.396087                   97.0032   98.004
    9        0.30006                     0.926638           1.96008     1.97339            0.981019         0.961231     0.987679                    0.985486            0.196047        0.592134                   96.0079   97.3386
    10       0.39998                     0.786577           1.89611     1.95408            0.949            0.864354     0.978016                    0.955225            0.189459        0.781593                   89.6105   95.408
    11       0.5                         0.533294           1.61078     1.88541            0.806194         0.663076     0.943645                    0.896784            0.16111         0.942703                   61.0778   88.5406
    12       0.60002                     0.2171             0.381237    1.63467            0.190809         0.365149     0.818152                    0.808163            0.0381314       0.980834                   -61.8763  63.467
    13       0.69994                     0.0434039          0.113886    1.41757            0.057            0.11539      0.709493                    0.709266            0.0113795       0.992214                   -88.6114  41.757
    14       0.79996                     0.00327876         0.0578842   1.24757            0.028971         0.0163862    0.624407                    0.622635            0.00578958      0.998004                   -94.2116  24.7567
    15       0.89998                     2.67561e-05        0.0179641   1.11091            0.00899101       0.000788224  0.556012                    0.553525            0.00179677      0.9998                     -98.2036  11.0914
    16       1                           3.22706e-27        0.00199601  1                  0.000999001      3.27031e-06  0.5005                      0.498162            0.000199641     1                          -99.8004  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.052845264775650484
RMSE: 0.2298809795865036
LogLoss: 0.19793068718410586
Mean Per-Class Error: 0.05314617219682938
AUC: 0.9797293188240831
pr_auc: 0.7967045212213815
Gini: 0.9594586376481662
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5433559008238934: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2973  155   0.0496   (155.0/3128.0)
1      173   2876  0.0567   (173.0/3049.0)
Total  3146  3031  0.0531   (328.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.543356     0.946053  193
max f2                       0.425052     0.954448  229
max f0point5                 0.592539     0.950933  178
max accuracy                 0.543356     0.9469    193
max precision                0.998996     0.997429  2
max recall                   3.27255e-05  1         399
max specificity              0.99996      0.999361  0
max absolute_mcc             0.543356     0.893789  193
max min_per_class_accuracy   0.532092     0.945228  197
max mean_per_class_accuracy  0.543356     0.946854  193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.18 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999999           1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999997           2.02591     2.01774            1                0.999998     0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.99999            2.02591     2.01935            1                0.999994     0.996764                    0.999998            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999591           2.01935     2.01935            0.996764         0.99987      0.996764                    0.999934            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.996773           2.01935     2.01935            0.996764         0.998607     0.996764                    0.999492            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.987181           1.98657     2.01116            0.980583         0.992877     0.992718                    0.997838            0.0993768       0.402427                   98.6572   101.116
    9        0.299984                    0.921034           1.97337     1.99858            0.974068         0.9619       0.986508                    0.985872            0.197114        0.599541                   97.3374   99.8577
    10       0.400032                    0.763075           1.92429     1.98               0.949838         0.850268     0.977337                    0.951957            0.192522        0.792063                   92.4287   97.9997
    11       0.500081                    0.508771           1.58008     1.89999            0.779935         0.644532     0.937844                    0.890452            0.158085        0.950148                   58.0079   89.9988
    12       0.599968                    0.192989           0.302081    1.63396            0.149109         0.341003     0.80653                     0.798976            0.0301738       0.980321                   -69.7919  63.3957
    13       0.700016                    0.0459139          0.111458    1.41636            0.0550162        0.106859     0.699121                    0.700056            0.0111512       0.991473                   -88.8542  41.6357
    14       0.799903                    0.0029381          0.0623862   1.24728            0.0307942        0.0171049    0.615665                    0.614774            0.00623155      0.997704                   -93.7614  24.7282
    15       0.899951                    3.24899e-05        0.019669    1.11081            0.00970874       0.000812208  0.5483                      0.546519            0.00196786      0.999672                   -98.0331  11.0807
    16       1                           1.36949e-29        0.00327817  1                  0.00161812       3.81591e-06  0.493605                    0.491841            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:10:47  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:10:48  4:04:05.748  19083 obs/sec     1         1             25000      0.307769         0.381281            0.621114       0.940745        0.715449           1.97822          0.121203                         0.301523           0.363586              0.636275         0.944223          0.709995             1.99323            0.116076
    2019-08-03 20:10:53  4:04:10.762  20671 obs/sec     5         5             125000     0.254796         0.240985            0.740316       0.969647        0.792564           1.998            0.0738409                        0.251581           0.232283              0.746787         0.971762          0.809587             2.02591            0.0705844
    2019-08-03 20:10:59  4:04:16.790  21206 obs/sec     10        10            250000     0.231804         0.20066             0.785068       0.979121        0.802642           1.998            0.0566547                        0.229881           0.197931              0.788584         0.979729          0.796705             2.02591            0.0531002
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0036775695688251175
C36         0.9728134870529175     0.9728134870529175   0.003577589276128457
C28         0.9522784352302551     0.9522784352302551   0.003502070194451187
C438        0.8794646859169006     0.8794646859169006   0.0032342925657843336
C34         0.7844846844673157     0.7844846844673157   0.0028849970028063743
---         ---                    ---                  ---
C423        0.13953429460525513    0.13953429460525513  0.000513147075647765
C662        0.13649116456508636    0.13649116456508636  0.0005019557532180628
C418        0.13607943058013916    0.13607943058013916  0.0005004415728445699
C435        0.1312723308801651     0.1312723308801651   0.0004827631292736369
C497        0.11036019772291183    0.11036019772291183  0.0004058573047553036

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_105

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight          weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  -------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.003597798406777582   0.005033416673541069   0.0         0.02765821114762672  0.09929132461547852  -0.057091357464225445  0.3761483430862427
    3        2        Softmax                      0.0   0.0   0.0002517125437861978  4.502947558648884e-05  0.0         0.04653974388202187  0.7571055889129639   -0.007670715544096828  0.04405246675014496


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.058287001203982905
RMSE: 0.24142701009618395
LogLoss: 0.2112272297475284
Mean Per-Class Error: 0.06354028132340717
AUC: 0.9761097753960489
pr_auc: 0.7833645722345756
Gini: 0.9522195507920979
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48361257185089057: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4652  364   0.0726   (364.0/5016.0)
1      273   4735  0.0545   (273.0/5008.0)
Total  4925  5099  0.0635   (637.0/10024.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.483613     0.936974  211
max f2                       0.386831     0.947056  242
max f0point5                 0.584759     0.943865  177
max accuracy                 0.486821     0.936453  210
max precision                0.999913     0.997923  0
max recall                   2.37519e-05  1         399
max specificity              0.999913     0.999601  0
max absolute_mcc             0.483613     0.873051  211
max min_per_class_accuracy   0.513908     0.935503  202
max mean_per_class_accuracy  0.483613     0.93646   211
Gains/Lift Table: Avg response rate: 49.96 %, avg score: 49.37 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100758                   1                  2.0016      2.0016             1                1           1                           1                   0.0201677       0.0201677                  100.16    100.16
    2        0.0200519                   1                  2.0016      2.0016             1                1           1                           1                   0.0199681       0.0401358                  100.16    100.16
    3        0.0300279                   0.999998           2.0016      2.0016             1                0.999999    1                           1                   0.0199681       0.0601038                  100.16    100.16
    4        0.040004                    0.999994           2.0016      2.0016             1                0.999996    1                           0.999999            0.0199681       0.0800719                  100.16    100.16
    5        0.0500798                   0.999984           2.0016      2.0016             1                0.99999     1                           0.999997            0.0201677       0.10024                    100.16    100.16
    6        0.10006                     0.999364           1.99361     1.99761            0.996008         0.999792    0.998006                    0.999895            0.0996406       0.19988                    99.3607   99.7606
    7        0.15004                     0.995653           1.98162     1.99228            0.99002          0.997926    0.995346                    0.999239            0.0990415       0.298922                   98.1621   99.2281
    8        0.20002                     0.984919           1.96165     1.98463            0.98004          0.991058    0.991521                    0.997195            0.0980431       0.396965                   96.1645   98.4626
    9        0.29998                     0.91885            1.9197      1.96299            0.959082         0.958333    0.980712                    0.984245            0.191893        0.588858                   91.9696   96.299
    10       0.40004                     0.758903           1.87787     1.9417             0.938185         0.84592     0.970075                    0.949646            0.187899        0.776757                   87.787    94.1699
    11       0.5                         0.50964            1.59009     1.87141            0.794411         0.633626    0.934956                    0.886468            0.158946        0.935703                   59.0091   87.1406
    12       0.59996                     0.224094           0.427487    1.63083            0.213573         0.358093    0.814766                    0.798434            0.0427316       0.978435                   -57.2513  63.0833
    13       0.70002                     0.0505119          0.133706    1.41684            0.0667996        0.123844    0.707852                    0.702009            0.0133786       0.991813                   -86.6294  41.6835
    14       0.79998                     0.00481269         0.0559329   1.24679            0.0279441        0.0212059   0.622896                    0.616941            0.00559105      0.997404                   -94.4067  24.6786
    15       0.89994                     5.93285e-05        0.0179784   1.1103             0.00898204       0.00134344  0.554706                    0.548564            0.00179712      0.999201                   -98.2022  11.0297
    16       1                           5.94188e-28        0.00798244  1                  0.00398804       7.182e-06   0.499601                    0.493675            0.000798722     1                          -99.2018  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05388046369726116
RMSE: 0.23212165710519378
LogLoss: 0.19836663644513539
Mean Per-Class Error: 0.05776101384127452
AUC: 0.9803331078320929
pr_auc: 0.8158221148609361
Gini: 0.9606662156641859
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.505239935384698: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2939  189   0.0604   (189.0/3128.0)
1      168   2881  0.0551   (168.0/3049.0)
Total  3107  3070  0.0578   (357.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.50524      0.941657  203
max f2                       0.354335     0.951861  250
max f0point5                 0.613144     0.949416  168
max accuracy                 0.50524      0.942205  203
max precision                0.999022     0.997241  2
max recall                   3.79244e-05  1         399
max specificity              0.999959     0.999361  0
max absolute_mcc             0.50524      0.884421  203
max min_per_class_accuracy   0.515574     0.940964  200
max mean_per_class_accuracy  0.50524      0.942239  203
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.05 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999998           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999993           1.99323     2.01774            0.983871         0.999996     0.995968                    0.999999            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999981           2.02591     2.01935            1                0.999988     0.996764                    0.999997            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.99939            2.01935     2.01935            0.996764         0.999794     0.996764                    0.999895            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.995884           2.01935     2.01935            0.996764         0.998061     0.996764                    0.999284            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.985177           1.99968     2.01444            0.987055         0.991402     0.994337                    0.997314            0.100033        0.403083                   99.9685   101.444
    9        0.299984                    0.916873           1.97666     2.00186            0.975689         0.958079     0.988127                    0.98425             0.197442        0.600525                   97.6658   100.186
    10       0.400032                    0.743161           1.93084     1.9841             0.953074         0.840073     0.979361                    0.948191            0.193178        0.793703                   93.0843   98.4097
    11       0.500081                    0.490718           1.53418     1.89408            0.757282         0.620348     0.93493                     0.882601            0.153493        0.947196                   53.4184   89.4085
    12       0.599968                    0.216092           0.351333    1.63724            0.17342          0.344326     0.808149                    0.792985            0.0350935       0.982289                   -64.8667  63.7237
    13       0.700016                    0.0550168          0.0819543   1.41495            0.0404531        0.123162     0.698427                    0.697252            0.00819941      0.990489                   -91.8046  41.4951
    14       0.799903                    0.00499474         0.0788036   1.2481             0.0388979        0.0231703    0.61607                     0.613077            0.00787143      0.99836                    -92.1196  24.8102
    15       0.899951                    7.46024e-05        0.00983452  1.11044            0.00485437       0.0014214    0.54812                     0.545079            0.000983929     0.999344                   -99.0165  11.0442
    16       1                           5.94188e-28        0.00655634  1                  0.00323625       9.15613e-06  0.493605                    0.490545            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:07:31  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:07:32  2:00:50.184  18853 obs/sec     1         1             25000      0.314722         0.389667            0.6038         0.935555        0.709034           2.0016           0.12909                          0.307287           0.362757              0.622237         0.941436          0.729198             1.99323            0.124818
    2019-08-03 18:07:38  2:00:55.338  20154 obs/sec     5         5             125000     0.260829         0.245681            0.727874       0.967075        0.795442           2.0016           0.0799082                        0.252558           0.227748              0.744817         0.972239          0.803237             2.02591            0.0757649
    2019-08-03 18:07:43  2:01:00.470  20404 obs/sec     9         9             225000     0.245061         0.219635            0.759781       0.974015        0.8051             2.0016           0.0666401                        0.236304           0.205728              0.776605         0.978373          0.774365             2.02591            0.0602234
    2019-08-03 18:07:44  2:01:01.787  20678 obs/sec     10        10            250000     0.241427         0.211227            0.766852       0.97611         0.783365           2.0016           0.0635475                        0.232122           0.198367              0.784443         0.980333          0.815822             2.02591            0.057795
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.0039077802361817855
C36         0.9763731956481934     0.9763731956481934   0.003815451877091662
C40         0.9406338334083557     0.9406338334083557   0.003675790303677083
C28         0.9237440824508667     0.9237440824508667   0.003609788868691375
C39         0.8890187740325928     0.8890187740325928   0.003474089994759127
---         ---                    ---                  ---
C659        0.12603451311588287    0.12603451311588287  0.0004925151794310411
C446        0.12487491220235825    0.12487491220235825  0.00048798371389931124
C330        0.12300462275743484    0.12300462275743484  0.0004806750337705002
C690        0.12289747595787048    0.12289747595787048  0.00048025632762479245
C567        0.11719997972249985    0.11719997972249985  0.00045799176444049093

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_40

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight          weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  -------------------  -------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0023784165178173623  0.001793422270566225  0.0         0.02686073949862717  0.08957695960998535  -0.07457300625801844     0.40166354179382324
    3        2        Softmax                      0.0   0.0   0.0002575175583388045  3.57854733010754e-05  0.0         0.13188433926552534  0.743980884552002    -0.00021839700091057235  0.09633216261863708


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.052811506861007544
RMSE: 0.22980754308988108
LogLoss: 0.19873676202888496
Mean Per-Class Error: 0.05665392763743271
AUC: 0.9799510109780614
pr_auc: 0.7459332335395288
Gini: 0.9599020219561227
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5398900539591013: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4740  280   0.0558   (280.0/5020.0)
1      288   4718  0.0575   (288.0/5006.0)
Total  5028  4998  0.0567   (568.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.53989      0.943223  187
max f2                       0.368315     0.952586  243
max f0point5                 0.59927      0.948498  168
max accuracy                 0.53989      0.943347  187
max precision                0.999956     0.994881  0
max recall                   3.50886e-05  1         399
max specificity              0.999956     0.998805  0
max absolute_mcc             0.53989      0.886695  187
max min_per_class_accuracy   0.53989      0.942469  187
max mean_per_class_accuracy  0.53989      0.943346  187
Gains/Lift Table: Avg response rate: 49.93 %, avg score: 50.54 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   1                  2.0028      2.0028             1                1            1                           1                   0.0201758       0.0201758                  100.28    100.28
    2        0.0200479                   1                  2.0028      2.0028             1                1            1                           1                   0.019976        0.0401518                  100.28    100.28
    3        0.0300219                   1                  1.98277     1.99614            0.99             1            0.996678                    1                   0.0197763       0.0599281                  98.2769   99.6143
    4        0.0400958                   1                  2.0028      1.99781            1                1            0.997512                    1                   0.0201758       0.0801039                  100.28    99.7815
    5        0.0500698                   0.999998           1.98277     1.99482            0.99             0.999999     0.996016                    1                   0.0197763       0.0998801                  98.2769   99.4817
    6        0.10004                     0.999886           2.0028      1.9988             1                0.999969     0.998006                    0.999984            0.10008         0.19996                    100.28    99.8803
    7        0.15001                     0.998608           1.96682     1.98815            0.982036         0.999446     0.992686                    0.999805            0.0982821       0.298242                   96.6818   98.8149
    8        0.20008                     0.992464           1.96689     1.98283            0.982072         0.996201     0.99003                     0.998903            0.0984818       0.396724                   96.689    98.2829
    9        0.30002                     0.947273           1.96082     1.9755             0.979042         0.974253     0.98637                     0.990692            0.195965        0.592689                   96.0822   97.5498
    10       0.40006                     0.801869           1.89896     1.95636            0.948156         0.88478      0.976814                    0.964207            0.189972        0.782661                   89.8963   95.6359
    11       0.5                         0.536035           1.61103     1.88734            0.804391         0.671089     0.94235                     0.905619            0.161007        0.943668                   61.1032   88.7335
    12       0.60004                     0.229539           0.397364    1.63892            0.198405         0.373329     0.818318                    0.816874            0.0397523       0.98342                    -60.2636  63.8924
    13       0.69998                     0.0542628          0.109934    1.42062            0.0548902        0.13011      0.709319                    0.718821            0.0109868       0.994407                   -89.0066  42.0622
    14       0.80002                     0.0038517          0.0399361   1.24797            0.0199402        0.0210065    0.623114                    0.631562            0.00399521      0.998402                   -96.0064  24.7971
    15       0.89996                     2.71423e-05        0.0079952   1.11027            0.00399202       0.000940846  0.554361                    0.561531            0.000799041     0.999201                   -99.2005  11.0273
    16       1                           1.62797e-27        0.00798722  1                  0.00398804       3.25512e-06  0.499302                    0.505356            0.000799041     1                          -99.2013  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05319036915448079
RMSE: 0.23063037344305018
LogLoss: 0.19870907298000046
Mean Per-Class Error: 0.055654017207436235
AUC: 0.9798087440517582
pr_auc: 0.7698665292916373
Gini: 0.9596174881035164
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5259339155557731: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2945  183   0.0585   (183.0/3128.0)
1      161   2888  0.0528   (161.0/3049.0)
Total  3106  3071  0.0557   (344.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525934     0.943791  193
max f2                       0.436945     0.953538  221
max f0point5                 0.602303     0.950345  169
max accuracy                 0.525934     0.94431   193
max precision                0.999656     0.994994  1
max recall                   5.13016e-05  1         399
max specificity              0.999975     0.998721  0
max absolute_mcc             0.525934     0.888634  193
max min_per_class_accuracy   0.539297     0.943588  189
max mean_per_class_accuracy  0.525934     0.944346  193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.19 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   1                  1.99323     2.01774            0.983871         1            0.995968                    1                   0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999998           2.02591     2.01935            1                0.999999     0.996764                    1                   0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999866           2.01935     2.01935            0.996764         0.999966     0.996764                    0.999983            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.99864            1.99968     2.0128             0.987055         0.999427     0.993528                    0.999798            0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.992406           1.98002     2.0046             0.977346         0.996168     0.989482                    0.99889             0.0990489       0.401115                   98.0016   100.46
    9        0.299984                    0.9466             1.99636     2.00186            0.985413         0.974576     0.988127                    0.990794            0.19941         0.600525                   99.6359   100.186
    10       0.400032                    0.789339           1.88823     1.97344            0.932039         0.876407     0.9741                      0.962186            0.188914        0.789439                   88.8227   97.3438
    11       0.500081                    0.513948           1.59975     1.89868            0.789644         0.653675     0.937197                    0.900464            0.160052        0.949492                   59.9748   89.8676
    12       0.599968                    0.226345           0.344766    1.63997            0.170178         0.361336     0.809498                    0.810706            0.0344375       0.983929                   -65.5234  63.997
    13       0.700016                    0.0565236          0.0753979   1.41636            0.0372168        0.131045     0.699121                    0.713567            0.00754346      0.991473                   -92.4602  41.6357
    14       0.799903                    0.00413725         0.0656697   1.24769            0.0324149        0.0226362    0.615867                    0.627288            0.00655953      0.998032                   -93.433   24.7692
    15       0.899951                    3.31387e-05        0.0163909   1.11081            0.00809061       0.00104942   0.5483                      0.557668            0.00163988      0.999672                   -98.3609  11.0807
    16       1                           4.36981e-32        0.00327817  1                  0.00161812       4.10575e-06  0.493605                    0.501875            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:49:59  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:50:01  43 min 18.313 sec  19260 obs/sec     1         1             25000      0.310447         0.41195             0.614491       0.9404          0.676434           1.98297          0.124676                         0.308208           0.397289              0.61997          0.942604          0.641411             2.02591            0.120285
    2019-08-03 16:50:06  43 min 23.499 sec  20148 obs/sec     5         5             125000     0.251201         0.236147            0.747592       0.970828        0.740548           2.0028           0.0745063                        0.248              0.231983              0.753944         0.971826          0.720851             2.02591            0.0704225
    2019-08-03 16:50:12  43 min 29.542 sec  20880 obs/sec     10        10            250000     0.229808         0.198737            0.788754       0.979951        0.745933           2.0028           0.0566527                        0.23063            0.198709              0.787204         0.979809          0.769867             2.02591            0.0556905
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.00374412939271252
C28         0.9466229677200317     0.9466229677200317   0.003544278877257326
C36         0.9141142964363098     0.9141142964363098   0.0034225622055859134
C438        0.8748968839645386     0.8748968839645386   0.003275727138844224
C79         0.8086272478103638     0.8086272478103638   0.003027605046275014
---         ---                    ---                  ---
C631        0.1391337364912033     0.1391337364912033   0.0005209347123146329
C583        0.13645723462104797    0.13645723462104797  0.0005109135429929342
C662        0.132279634475708      0.132279634475708    0.0004952720674977668
C246        0.1281777322292328     0.1281777322292328   0.0004799140147307054
C478        0.12667229771614075    0.12667229771614075  0.0004742774731214336

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_231

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.003037196429503248    0.0037164120003581047  0.0         0.027296949179138982  0.09628447890281677  -0.018435272597271554  0.3249821662902832
    3        2        Softmax                      0.0   0.0   0.00018765946879284456  4.273526428733021e-05  0.0         -0.09067366878662142  0.6638026237487793   0.011078593422486953   0.12206476926803589


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05528087205775283
RMSE: 0.2351188466664313
LogLoss: 0.20026173971729502
Mean Per-Class Error: 0.06009965570414544
AUC: 0.9791614941004109
pr_auc: 0.8208297427124444
Gini: 0.9583229882008217
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5277065653124852: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4637  306   0.0619   (306.0/4943.0)
1      298   4771  0.0588   (298.0/5069.0)
Total  4935  5077  0.0603   (604.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.527707     0.940469  197
max f2                       0.364669     0.953155  246
max f0point5                 0.620744     0.947714  168
max accuracy                 0.537001     0.939872  194
max precision                0.999516     0.999019  1
max recall                   2.74122e-05  1         399
max specificity              0.999945     0.999798  0
max absolute_mcc             0.537001     0.87975   194
max min_per_class_accuracy   0.530181     0.939308  196
max mean_per_class_accuracy  0.537001     0.9399    194
Gains/Lift Table: Avg response rate: 50.63 %, avg score: 50.18 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   1                  1.97514    1.97514            1                1            1                           1                   0.019925        0.019925                   97.5143   97.5143
    2        0.0200759                   1                  1.97514    1.97514            1                1            1                           1                   0.0197278       0.0396528                  97.5143   97.5143
    3        0.0300639                   0.999997           1.97514    1.97514            1                0.999999     1                           0.999999            0.0197278       0.0593805                  97.5143   97.5143
    4        0.0400519                   0.999989           1.97514    1.97514            1                0.999994     1                           0.999998            0.0197278       0.0791083                  97.5143   97.5143
    5        0.05004                     0.999965           1.97514    1.97514            1                0.999979     1                           0.999994            0.0197278       0.0988361                  97.5143   97.5143
    6        0.10008                     0.999294           1.96726    1.9712             0.996008         0.999747     0.998004                    0.999871            0.0984415       0.197278                   96.7258   97.1201
    7        0.15002                     0.995525           1.96329    1.96857            0.994            0.997841     0.996671                    0.999195            0.098047        0.295325                   96.3292   96.8568
    8        0.20006                     0.984988           1.95937    1.96627            0.992016         0.990853     0.995507                    0.997109            0.098047        0.393371                   95.9373   96.6268
    9        0.30004                     0.918079           1.91595    1.9495             0.97003          0.957146     0.987017                    0.983792            0.191557        0.584928                   91.5948   94.95
    10       0.40002                     0.775496           1.85478    1.92583            0.939061         0.85565      0.975031                    0.951765            0.185441        0.770369                   85.478    92.5826
    11       0.5                         0.54464            1.63378    1.86743            0.827173         0.660588     0.945465                    0.893541            0.163346        0.933715                   63.3785   86.7429
    12       0.59998                     0.241943           0.473561   1.63516            0.23976          0.388049     0.827867                    0.809306            0.0473466       0.981061                   -52.6439  63.5157
    13       0.69996                     0.0585205          0.110498   1.41738            0.0559441        0.13676      0.717608                    0.713242            0.0110475       0.992109                   -88.9502  41.7379
    14       0.79994                     0.0051667          0.0552488  1.24713            0.027972         0.0243768    0.631415                    0.627145            0.00552377      0.997633                   -94.4751  24.7134
    15       0.89992                     4.85349e-05        0.023678   1.11121            0.011988         0.00136202   0.562597                    0.557621            0.00236733      1                          -97.6322  11.121
    16       1                           1.11599e-28        0          1                  0                6.44667e-06  0.506292                    0.501815            0               1                          -100      0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05444857244106876
RMSE: 0.23334217887272066
LogLoss: 0.19925524401057915
Mean Per-Class Error: 0.05608553473152489
AUC: 0.9799242907196104
pr_auc: 0.8151208767895552
Gini: 0.9598485814392208
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5423734087835491: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2970  158   0.0505   (158.0/3128.0)
1      188   2861  0.0617   (188.0/3049.0)
Total  3158  3019  0.056    (346.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.542373     0.94298   193
max f2                       0.409814     0.951473  233
max f0point5                 0.62794      0.950018  166
max accuracy                 0.542373     0.943986  193
max precision                0.992104     0.998113  10
max recall                   5.78094e-05  1         399
max specificity              0.999938     0.999361  0
max absolute_mcc             0.542373     0.887981  193
max min_per_class_accuracy   0.52282      0.94162   199
max mean_per_class_accuracy  0.542373     0.943914  193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.20 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591    2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591    2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999997           2.02591    2.02591            1                0.999999     1                           0.999999            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999988           1.99323    2.01774            0.983871         0.999994     0.995968                    0.999998            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999964           2.02591    2.01935            1                0.999977     0.996764                    0.999994            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999255           2.01935    2.01935            0.996764         0.999732     0.996764                    0.999863            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.995388           2.02591    2.02154            1                0.997666     0.997843                    0.999131            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.983261           1.99313    2.01444            0.983819         0.990374     0.994337                    0.996942            0.0997048       0.403083                   99.3128   101.444
    9        0.299984                    0.913079           1.97009    1.99967            0.972447         0.954611     0.987048                    0.982847            0.196786        0.599869                   97.0091   99.9671
    10       0.400032                    0.748515           1.92429    1.98082            0.949838         0.840381     0.977742                    0.947216            0.192522        0.792391                   92.4287   98.0817
    11       0.500081                    0.503484           1.5473     1.89408            0.763754         0.630225     0.93493                     0.883797            0.154805        0.947196                   54.7297   89.4085
    12       0.599968                    0.214408           0.344766   1.63614            0.170178         0.354937     0.807609                    0.795749            0.0344375       0.981633                   -65.5234  63.6144
    13       0.700016                    0.0508878          0.095067   1.41589            0.0469256        0.122752     0.69889                     0.699562            0.00951132      0.991145                   -90.4933  41.5888
    14       0.799903                    0.00500907         0.0689532  1.24769            0.0340357        0.0220612    0.615867                    0.61496             0.0068875       0.998032                   -93.1047  24.7692
    15       0.899951                    6.08183e-05        0.019669   1.11117            0.00970874       0.00129606   0.54848                     0.546738            0.00196786      1                          -98.0331  11.1171
    16       1                           6.87422e-28        0          1                  0                8.08803e-06  0.493605                    0.492039            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:49:37  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:49:39  4:42:56.707  17934 obs/sec     1         1             25000      0.308694         0.369877            0.618772       0.941001        0.737188           1.97514          0.126548                         0.304319           0.362792              0.629499         0.943492          0.735756             2.02591            0.122875
    2019-08-03 20:49:44  4:43:01.963  19604 obs/sec     5         5             125000     0.256023         0.231684            0.737768       0.970307        0.80242            1.97514          0.0789053                        0.254932           0.231297              0.739995         0.970919          0.783236             2.02591            0.078679
    2019-08-03 20:49:49  4:43:07.022  20168 obs/sec     9         9             225000     0.239125         0.205254            0.771241       0.977769        0.814994           1.97514          0.0631243                        0.238466           0.206197              0.772498         0.977909          0.795575             2.02591            0.0595758
    2019-08-03 20:49:51  4:43:08.444  20409 obs/sec     10        10            250000     0.235119         0.200262            0.778841       0.979161        0.82083            1.97514          0.0603276                        0.233342           0.199255              0.78217          0.979924          0.815121             2.02591            0.0560142
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.003760975984047826
C41         0.9631305932998657     0.9631305932998657   0.0036223110309025293
C36         0.9520634412765503     0.9520634412765503   0.0035806877379310335
C40         0.9350878000259399     0.9350878000259399   0.003516842758873676
C250        0.8666961789131165     0.8666961789131165   0.003259623514358249
---         ---                    ---                  ---
C247        0.13784848153591156    0.13784848153591156  0.0005184448284940236
C497        0.13495878875255585    0.13495878875255585  0.0005075767633345464
C361        0.13360771536827087    0.13360771536827087  0.0005024954087835644
C631        0.13146337866783142    0.13146337866783142  0.0004944306099514993
C226        0.12479808926582336    0.12479808926582336  0.0004693626165838185

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_91

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0025026013179100044  0.0020273374393582344   0.0         0.027961304716581634  0.09268611669540405  -0.050366569974843005  0.3837515115737915
    3        2        Softmax                      0.0   0.0   0.000193304729123156   4.7223904402926564e-05  0.0         -0.16212736839952413  0.7486810684204102   0.02805507223539183    0.12442910671234131


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05361583763987337
RMSE: 0.2315509396220913
LogLoss: 0.20022736397494187
Mean Per-Class Error: 0.05847247455889071
AUC: 0.9799218455174128
pr_auc: 0.7933595379049614
Gini: 0.9598436910348256
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5135825540814702: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4573  343   0.0698   (343.0/4916.0)
1      242   4868  0.0474   (242.0/5110.0)
Total  4815  5211  0.0583   (585.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.513583     0.943319  205
max f2                       0.41237      0.954068  238
max f0point5                 0.603832     0.949341  173
max accuracy                 0.529504     0.941652  200
max precision                0.999171     0.997802  2
max recall                   2.17566e-05  1         399
max specificity              0.999972     0.99939   0
max absolute_mcc             0.513583     0.883394  205
max min_per_class_accuracy   0.551116     0.939178  193
max mean_per_class_accuracy  0.529504     0.941528  200
Gains/Lift Table: Avg response rate: 50.97 %, avg score: 51.09 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   1                  1.96204     1.96204            1                1            1                           1                   0.0197652       0.0197652                  96.2035   96.2035
    2        0.0200479                   1                  1.96204     1.96204            1                1            1                           1                   0.0195695       0.0393346                  96.2035   96.2035
    3        0.0300219                   1                  1.96204     1.96204            1                1            1                           1                   0.0195695       0.0589041                  96.2035   96.2035
    4        0.0400958                   0.999999           1.94261     1.95715            0.990099         0.999999     0.997512                    1                   0.0195695       0.0784736                  94.2609   95.7155
    5        0.0500698                   0.999997           1.96204     1.95813            1                0.999998     0.998008                    0.999999            0.0195695       0.0980431                  96.2035   95.8127
    6        0.10004                     0.999763           1.9542      1.95617            0.996008         0.999932     0.997009                    0.999966            0.0976517       0.195695                   95.4203   95.6167
    7        0.15001                     0.998055           1.94637     1.9529             0.992016         0.999129     0.995346                    0.999687            0.0972603       0.292955                   94.637    95.2903
    8        0.20008                     0.99169            1.94249     1.9503             0.99004          0.995593     0.994018                    0.998662            0.0972603       0.390215                   94.2493   95.0298
    9        0.30002                     0.941104           1.91896     1.93986            0.978044         0.971647     0.988697                    0.989663            0.191781        0.581996                   91.8957   93.9858
    10       0.40006                     0.802381           1.86031     1.91997            0.948156         0.880706     0.978559                    0.962417            0.186106        0.768102                   86.0315   91.9967
    11       0.503491                    0.563386           1.61012     1.85632            0.820636         0.67925      0.946117                    0.904247            0.166536        0.934638                   61.0118   85.6315
    12       0.60004                     0.252192           0.496589    1.63753            0.253099         0.406896     0.834608                    0.824221            0.0479452       0.982583                   -50.3411  63.753
    13       0.69998                     0.0559079          0.0939897   1.41715            0.0479042        0.139377     0.722286                    0.726442            0.00939335      0.991977                   -90.601   41.715
    14       0.80002                     0.00439153         0.0489042   1.24606            0.0249252        0.0226035    0.635083                    0.638429            0.00489237      0.996869                   -95.1096  24.6055
    15       0.89996                     3.8429e-05         0.0215393   1.11007            0.010978         0.00110472   0.565776                    0.567654            0.00215264      0.999022                   -97.8461  11.0073
    16       1                           1.55786e-30        0.00978083  1                  0.00498504       4.82809e-06  0.509675                    0.510867            0.000978474     1                          -99.0219  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0534377901468989
RMSE: 0.23116615268438176
LogLoss: 0.20080462930785337
Mean Per-Class Error: 0.054169840180714135
AUC: 0.9793909096857046
pr_auc: 0.764945427710299
Gini: 0.9587818193714093
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5321759959312838: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2943  185   0.0591   (185.0/3128.0)
1      150   2899  0.0492   (150.0/3049.0)
Total  3093  3084  0.0542   (335.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.532176     0.945377  191
max f2                       0.422303     0.955132  227
max f0point5                 0.603875     0.949976  171
max accuracy                 0.538423     0.945767  189
max precision                0.998902     0.997701  2
max recall                   3.71515e-05  1         399
max specificity              0.999952     0.999361  0
max absolute_mcc             0.532176     0.891588  191
max min_per_class_accuracy   0.550785     0.944693  186
max mean_per_class_accuracy  0.532176     0.94583   191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.97 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1           1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1           1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  1.99323     2.01502            0.983871         1           0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999998           2.02591     2.01774            1                0.999999    0.995968                    1                   0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999994           1.9927      2.0128             0.983607         0.999996    0.993528                    0.999999            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.999787           2.02591     2.01935            1                0.999934    0.996764                    0.999967            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.997979           2.00624     2.01498            0.990291         0.999075    0.994606                    0.999669            0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.991              2.0128      2.01444            0.993528         0.995256    0.994337                    0.998566            0.100689        0.403083                   101.28    101.444
    9        0.299984                    0.93603            1.95367     1.9942             0.964344         0.969999    0.98435                     0.989054            0.195146        0.598229                   95.3673   99.4204
    10       0.400032                    0.780206           1.90462     1.9718             0.940129         0.867687    0.97329                     0.9587              0.190554        0.788783                   90.4618   97.1798
    11       0.500081                    0.525794           1.61942     1.9013             0.799353         0.656228    0.938491                    0.898186            0.16202         0.950804                   61.9417   90.1299
    12       0.599968                    0.210722           0.311931    1.63669            0.153971         0.362498    0.807879                    0.809001            0.0311578       0.981961                   -68.8069  63.669
    13       0.700016                    0.0517696          0.0917888   1.41589            0.0453074        0.121462    0.69889                     0.710736            0.00918334      0.991145                   -90.8211  41.5888
    14       0.799903                    0.00416434         0.0591027   1.24646            0.0291734        0.0206291   0.61526                     0.62456             0.00590357      0.997048                   -94.0897  24.6462
    15       0.899951                    3.50851e-05        0.0229472   1.11044            0.0113269        0.00100933  0.54812                     0.555239            0.00229583      0.999344                   -97.7053  11.0442
    16       1                           1.52708e-29        0.00655634  1                  0.00323625       4.2331e-06  0.493605                    0.499688            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:48:09  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:48:10  1:41:28.094  18726 obs/sec     1         1             25000      0.308346         0.394146            0.619547       0.941023        0.688813           1.94261          0.122881                         0.304721           0.379439              0.628519         0.943489          0.648939             2.02591            0.118828
    2019-08-03 17:48:16  1:41:33.259  20077 obs/sec     5         5             125000     0.252557         0.238483            0.744764       0.970691        0.75934            1.96204          0.0762019                        0.250758           0.232685              0.74844          0.971355          0.790018             2.02591            0.0722033
    2019-08-03 17:48:21  1:41:38.395  20367 obs/sec     9         9             225000     0.23407          0.205103            0.780763       0.978765        0.803686           1.96204          0.0606423                        0.233044           0.204605              0.782726         0.978497          0.789358             2.02591            0.0576332
    2019-08-03 17:48:22  1:41:39.755  20635 obs/sec     10        10            250000     0.231551         0.200227            0.785456       0.979922        0.79336            1.96204          0.0583483                        0.231166           0.200805              0.786214         0.979391          0.764945             2.02591            0.0542334
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003442719145824347
C35         0.9399546980857849     0.9399546980857849   0.0032360000353074754
C34         0.9233821034431458     0.9233821034431458   0.0031789452464352757
C22         0.8513813614845276     0.8513813614845276   0.0029310669135807826
C36         0.8496177792549133     0.8496177792549133   0.0029249953952736538
---         ---                    ---                  ---
C348        0.14957107603549957    0.14957107603549957  0.0005149312071289636
C342        0.14848174154758453    0.14848174154758453  0.0005111809344312117
C758        0.14380080997943878    0.14380080997943878  0.0004950658017012627
C606        0.1429339051246643     0.1429339051246643   0.0004920812917601226
C797        0.1415640413761139     0.1415640413761139   0.0004873652356058173

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_138

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  --------------------  -------------------  ---------------------  --------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0032637558787975687   0.004392003640532494    0.0         0.026618705814688146  0.09413638710975647  -0.021542205469803247  0.3841513395309448
    3        2        Softmax                      0.0   0.0   0.00024921261660892924  4.3262087274342775e-05  0.0         0.2520336731686257    0.7317662239074707   0.0005126908888503888  0.055166855454444885


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.059731558393403945
RMSE: 0.24440040587814896
LogLoss: 0.21755060621015773
Mean Per-Class Error: 0.06518154149542099
AUC: 0.97438680497504
pr_auc: 0.788412321632889
Gini: 0.9487736099500801
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5205976315057661: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4653  349   0.0698   (349.0/5002.0)
1      304   4713  0.0606   (304.0/5017.0)
Total  4957  5062  0.0652   (653.0/10019.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.520598     0.935212  193
max f2                       0.382452     0.946142  240
max f0point5                 0.60431      0.940437  166
max accuracy                 0.523309     0.934824  192
max precision                0.999154     0.997746  2
max recall                   3.20229e-05  1         399
max specificity              0.99997      0.9994    0
max absolute_mcc             0.520598     0.869681  193
max min_per_class_accuracy   0.527903     0.933427  190
max mean_per_class_accuracy  0.523309     0.934818  192
Gains/Lift Table: Avg response rate: 50.07 %, avg score: 50.44 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100808                   1                  1.99701     1.99701            1                1            1                           1                   0.0201316       0.0201316                  99.701    99.701
    2        0.0200619                   1                  1.99701     1.99701            1                1            1                           1                   0.0199322       0.0400638                  99.701    99.701
    3        0.0300429                   1                  1.99701     1.99701            1                1            1                           1                   0.0199322       0.059996                   99.701    99.701
    4        0.040024                    0.999998           1.97704     1.99203            0.99             0.999999     0.997506                    1                   0.0197329       0.0797289                  97.704    99.203
    5        0.050005                    0.999994           1.99701     1.99302            1                0.999997     0.998004                    0.999999            0.0199322       0.0996612                  99.701    99.3024
    6        0.10001                     0.999757           1.98904     1.99103            0.996008         0.999921     0.997006                    0.99996             0.0994618       0.199123                   98.9038   99.1031
    7        0.150015                    0.99782            1.98904     1.99037            0.996008         0.999067     0.996673                    0.999662            0.0994618       0.298585                   98.9038   99.0367
    8        0.20002                     0.990713           1.93722     1.97708            0.97006          0.995043     0.99002                     0.998507            0.0968706       0.395455                   93.7219   97.708
    9        0.30003                     0.936494           1.92925     1.96114            0.966068         0.969501     0.982036                    0.988839            0.192944        0.588399                   92.9247   96.1136
    10       0.40004                     0.788404           1.85152     1.93373            0.927146         0.871617     0.968313                    0.959533            0.18517         0.77357                    85.1519   93.3732
    11       0.501148                    0.527823           1.59091     1.86457            0.796644         0.659807     0.933679                    0.899063            0.160853        0.934423                   59.0905   86.4566
    12       0.59996                     0.238548           0.423608    1.62724            0.212121         0.379995     0.814839                    0.813573            0.0418577       0.976281                   -57.6392  62.7243
    13       0.69997                     0.0593474          0.13154     1.41354            0.0658683        0.137325     0.707828                    0.716952            0.0131553       0.989436                   -86.846   41.354
    14       0.79998                     0.00470984         0.0777279   1.24654            0.0389222        0.0240347    0.624205                    0.630327            0.00777357      0.997209                   -92.2272  24.6543
    15       0.89999                     6.56344e-05        0.0239163   1.11068            0.011976         0.00133915   0.556172                    0.560432            0.00239187      0.999601                   -97.6084  11.068
    16       1                           2.3326e-22         0.00398605  1                  0.00199601       8.38635e-06  0.500749                    0.504384            0.000398645     1                          -99.6014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05497635105385696
RMSE: 0.23447036284753978
LogLoss: 0.2023737617245743
Mean Per-Class Error: 0.0565923882636461
AUC: 0.978592306059846
pr_auc: 0.7679242498597334
Gini: 0.9571846121196921
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5241377852085538: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2934  194   0.062    (194.0/3128.0)
1      156   2893  0.0512   (156.0/3049.0)
Total  3090  3087  0.0567   (350.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.524138     0.94296   195
max f2                       0.382807     0.952795  239
max f0point5                 0.600491     0.945751  168
max accuracy                 0.524138     0.943338  195
max precision                0.999504     0.997433  1
max recall                   2.9056e-05   1         399
max specificity              0.999952     0.999361  0
max absolute_mcc             0.524138     0.886743  195
max min_per_class_accuracy   0.527604     0.938939  194
max mean_per_class_accuracy  0.524138     0.943408  195
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.01 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999998           1.96056     2.00957            0.967742         0.999999     0.991935                    1                   0.0196786       0.0806822                  96.0558   100.957
    5        0.0500243                   0.999994           2.02591     2.0128             1                0.999997     0.993528                    0.999999            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999758           2.02591     2.01935            1                0.999923     0.996764                    0.999961            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.997734           2.01935     2.01935            0.996764         0.999078     0.996764                    0.999667            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.99093            1.99968     2.01444            0.987055         0.995075     0.994337                    0.998519            0.100033        0.403083                   99.9685   101.444
    9        0.299984                    0.936136           1.94711     1.99202            0.961102         0.970268     0.98327                     0.989112            0.19449         0.597573                   94.7106   99.2017
    10       0.400032                    0.782673           1.88823     1.96606            0.932039         0.867706     0.970457                    0.958748            0.188914        0.786487                   88.8227   96.6059
    11       0.500081                    0.519785           1.6227      1.89736            0.800971         0.647401     0.936549                    0.896459            0.162348        0.948836                   62.2695   89.7364
    12       0.599968                    0.226705           0.334915    1.63724            0.165316         0.359039     0.808149                    0.806985            0.0334536       0.982289                   -66.5085  63.7237
    13       0.700016                    0.0588072          0.0885106   1.41589            0.0436893        0.132516     0.69889                     0.710588            0.00885536      0.991145                   -91.1489  41.5888
    14       0.799903                    0.00501746         0.0755202   1.24851            0.0372771        0.0250314    0.616272                    0.62498             0.00754346      0.998688                   -92.448   24.8512
    15       0.899951                    7.56436e-05        0.00983452  1.11081            0.00485437       0.00138718   0.5483                      0.555655            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           6.82379e-28        0.00327817  1                  0.00161812       9.84616e-06  0.493605                    0.500063            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:39:43  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:39:44  2:33:01.951  18968 obs/sec     1         1             25000      0.316802         0.400856            0.598546       0.934829        0.727413           1.97724          0.129055                         0.30729            0.366706              0.62223          0.941931          0.671264             1.96056            0.123685
    2019-08-03 18:39:50  2:33:07.283  19592 obs/sec     5         5             125000     0.263143         0.250721            0.723022       0.966131        0.794362           1.99701          0.0820441                        0.250584           0.228064              0.74879          0.972803          0.7983               2.02591            0.0699369
    2019-08-03 18:39:56  2:33:13.307  20615 obs/sec     10        10            250000     0.2444           0.217551            0.761073       0.974387        0.788412           1.99701          0.0651762                        0.23447            0.202374              0.780059         0.978592          0.767924             2.02591            0.0566618
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C28         1.0                    1.0                  0.003927877877403692
C25         0.9190388321876526     0.9190388321876526   0.0036098722974248045
C36         0.9018399119377136     0.9018399119377136   0.003542317039059839
C35         0.8781971335411072     0.8781971335411072   0.0034494510928354503
C47         0.821186363697052      0.821186363697052    0.0032255197511912325
---         ---                    ---                  ---
C467        0.1287025660276413     0.1287025660276413   0.0005055279618650601
C310        0.12685467302799225    0.12685467302799225  0.0004982696638319295
C556        0.12357614189386368    0.12357614189386368  0.00048539199391980665
C362        0.1233534961938858     0.1233534961938858   0.00048451746880036453
C869        0.12158042937517166    0.12158042937517166  0.0004775530788679787

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_54

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0033534541179580293   0.002918833866715431   0.0         0.027163281228631566  0.09437143802642822  -0.0027766459478093496  0.377236008644104
    3        2        Softmax                      0.0   0.0   0.00024657130325067556  5.598273128271103e-05  0.0         -0.06174542255757842  0.7657909393310547   -0.0011454617600588357  0.04900944232940674


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.057356047711504196
RMSE: 0.23949122679443646
LogLoss: 0.20791392364666103
Mean Per-Class Error: 0.06469296989028583
AUC: 0.9763614988165897
pr_auc: 0.7751124265422537
Gini: 0.9527229976331795
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5047246544565379: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4739  341   0.0671   (341.0/5080.0)
1      308   4639  0.0623   (308.0/4947.0)
Total  5047  4980  0.0647   (649.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.504725     0.934623  205
max f2                       0.386046     0.95      241
max f0point5                 0.620154     0.939358  166
max accuracy                 0.508763     0.935275  204
max precision                0.999944     1         0
max recall                   2.19832e-05  1         399
max specificity              0.999944     1         0
max absolute_mcc             0.504725     0.870557  205
max min_per_class_accuracy   0.513324     0.934843  202
max mean_per_class_accuracy  0.504725     0.935307  205
Gains/Lift Table: Avg response rate: 49.34 %, avg score: 49.80 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   1                  2.02688     2.02688            1                1            1                           1                   0.0204164       0.0204164                  102.688   102.688
    2        0.0200459                   1                  2.02688     2.02688            1                1            1                           1                   0.0202143       0.0406307                  102.688   102.688
    3        0.0300189                   1                  2.02688     2.02688            1                1            1                           1                   0.0202143       0.060845                   102.688   102.688
    4        0.0400918                   0.999997           2.02688     2.02688            1                0.999999     1                           1                   0.0204164       0.0812614                  102.688   102.688
    5        0.0500648                   0.99999            2.02688     2.02688            1                0.999994     1                           0.999998            0.0202143       0.101476                   102.688   102.688
    6        0.10003                     0.999637           2.02688     2.02688            1                0.999894     1                           0.999946            0.101273        0.202749                   102.688   102.688
    7        0.149995                    0.997576           2.00666     2.02015            0.99002          0.998893     0.996676                    0.999595            0.100263        0.303012                   100.666   102.015
    8        0.20006                     0.989789           1.99055     2.01274            0.982072         0.99447      0.993021                    0.998313            0.0996564       0.402668                   99.0546   101.274
    9        0.29999                     0.934521           1.94597     1.9905             0.96008          0.968196     0.982048                    0.988281            0.194461        0.59713                    94.5971   99.0498
    10       0.40002                     0.774721           1.89351     1.96625            0.934197         0.870206     0.970082                    0.958755            0.189408        0.786537                   89.3511   96.6245
    11       0.50005                     0.493501           1.53785     1.88055            0.758724         0.642789     0.927802                    0.895549            0.153831        0.940368                   53.7846   88.0548
    12       0.59998                     0.216204           0.398499    1.6337             0.196607         0.352404     0.806017                    0.805085            0.0398221       0.98019                    -60.1501  63.3704
    13       0.70001                     0.0553666          0.121249    1.41758            0.0598205        0.12551      0.699387                    0.707975            0.0121286       0.992319                   -87.8751  41.7578
    14       0.79994                     0.00474011         0.0485481   1.24656            0.0239521        0.0227165    0.615011                    0.622371            0.00485143      0.99717                    -95.1452  24.6556
    15       0.89997                     6.04923e-05        0.022229    1.11047            0.0109671        0.00128997   0.547872                    0.553339            0.00222357      0.999394                   -97.7771  11.0474
    16       1                           1.34791e-27        0.00606247  1                  0.00299103       8.06372e-06  0.493368                    0.497989            0.000606428     1                          -99.3938  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05480501572531391
RMSE: 0.23410471102759534
LogLoss: 0.2033176801538765
Mean Per-Class Error: 0.05954663975191221
AUC: 0.9784189860580677
pr_auc: 0.7711758216776983
Gini: 0.9568379721161353
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46760946046613855: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2885  243   0.0777   (243.0/3128.0)
1      127   2922  0.0417   (127.0/3049.0)
Total  3012  3165  0.0599   (370.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.467609     0.940457  212
max f2                       0.387639     0.954408  236
max f0point5                 0.569123     0.942942  177
max accuracy                 0.475817     0.940262  209
max precision                0.999948     0.996825  0
max recall                   3.63931e-05  1         399
max specificity              0.999948     0.999361  0
max absolute_mcc             0.475817     0.880987  209
max min_per_class_accuracy   0.506103     0.939324  199
max mean_per_class_accuracy  0.475817     0.940453  209
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.87 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999999           1.99323     2.01502            0.983871         1            0.994624                    1                   0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999997           1.99323     2.00957            0.983871         0.999999     0.991935                    1                   0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999991           2.02591     2.0128             1                0.999995     0.993528                    0.999999            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.99972            2.02591     2.01935            1                0.999913     0.996764                    0.999956            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.997949           2.00624     2.01498            0.990291         0.99907      0.994606                    0.99966             0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.991504           1.99313     2.00952            0.983819         0.995305     0.991909                    0.998571            0.0997048       0.402099                   99.3128   100.952
    9        0.299984                    0.938902           1.95039     1.98983            0.962723         0.97177      0.982191                    0.989647            0.194818        0.596917                   95.039    98.9831
    10       0.400032                    0.781435           1.91117     1.97016            0.943366         0.87012      0.972481                    0.959753            0.19121         0.788127                   91.1174   97.0159
    11       0.500081                    0.487332           1.56697     1.88949            0.773463         0.639857     0.932664                    0.895753            0.156773        0.9449                     56.6966   88.9494
    12       0.599968                    0.217947           0.380884    1.63833            0.188006         0.34924      0.808689                    0.804766            0.0380453       0.982945                   -61.9116  63.833
    13       0.700016                    0.0615261          0.0917888   1.41729            0.0453074        0.131329     0.699584                    0.708516            0.00918334      0.992129                   -90.8211  41.7294
    14       0.799903                    0.0052798          0.0558192   1.24728            0.0275527        0.0262136    0.615665                    0.623315            0.0055756       0.997704                   -94.4181  24.7282
    15       0.899951                    7.98342e-05        0.0131127   1.11008            0.00647249       0.00154879   0.54794                     0.554192            0.00131191      0.999016                   -98.6887  11.0078
    16       1                           1.34791e-27        0.00983452  1                  0.00485437       1.05111e-05  0.493605                    0.498747            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:08:12  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:08:14  1:01:31.251  18670 obs/sec     1         1             25000      0.314162         0.394321            0.60514        0.93711         0.695556           2.02688          0.127356                         0.307288           0.372441              0.622234         0.942096          0.704373             1.99323            0.125142
    2019-08-03 17:08:19  1:01:36.417  20048 obs/sec     5         5             125000     0.255908         0.237666            0.737998       0.968793        0.786139           2.02688          0.074798                         0.250731           0.229233              0.748494         0.971891          0.793209             2.02591            0.0738222
    2019-08-03 17:08:24  1:01:41.465  20422 obs/sec     9         9             225000     0.244087         0.217304            0.761645       0.974434        0.787763           2.02688          0.064825                         0.23934            0.211949              0.770827         0.976813          0.785304             2.02591            0.060871
    2019-08-03 17:08:25  1:01:42.841  20562 obs/sec     10        10            250000     0.239491         0.207914            0.770535       0.976361        0.775112           2.02688          0.0647252                        0.234105           0.203318              0.780744         0.978419          0.771176             2.02591            0.0598996
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C36         1.0                    1.0                  0.003936499989662465
C250        0.9328690767288208     0.9328690767288208   0.0036722391108994367
C28         0.9097610712051392     0.9097610712051392   0.0035812744473943435
C34         0.8820965886116028     0.8820965886116028   0.00347237321195087
C35         0.8508937358856201     0.8508937358856201   0.0033495431825176
---         ---                    ---                  ---
C417        0.13789993524551392    0.13789993524551392  0.0005428430936684201
C971        0.13526678085327148    0.13526678085327148  0.0005324776814305781
C491        0.13459721207618713    0.13459721207618713  0.0005298419239465073
C649        0.13040995597839355    0.13040995597839355  0.0005133587903608288
C758        0.12253997474908829    0.12253997474908829  0.0004823786093330248

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_126

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.004883206219120457    0.0037892917171120644  0.0         0.028125480610718786  0.10541731119155884  0.11190632784317464     0.33710169792175293
    3        2        Softmax                      0.0   0.0   0.00028568901984726836  6.474251858890057e-05  0.0         -0.04374100497807376  0.8187189102172852   -0.0005610852321269177  0.2212846279144287


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.05856281275748968
RMSE: 0.2419975470071746
LogLoss: 0.21450738520152302
Mean Per-Class Error: 0.06693848843979366
AUC: 0.9755104665032698
pr_auc: 0.8176989193938872
Gini: 0.9510209330065396
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5357353946604655: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4654  319   0.0641   (319.0/4973.0)
1      352   4696  0.0697   (352.0/5048.0)
Total  5006  5015  0.067    (671.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.535735     0.93332   200
max f2                       0.317298     0.946009  265
max f0point5                 0.634064     0.943605  166
max accuracy                 0.535735     0.933041  200
max precision                0.996282     0.997026  5
max recall                   2.93209e-05  1         399
max specificity              0.999893     0.999397  0
max absolute_mcc             0.535735     0.866099  200
max min_per_class_accuracy   0.528065     0.93225   203
max mean_per_class_accuracy  0.535735     0.933062  200
Gains/Lift Table: Avg response rate: 50.37 %, avg score: 49.51 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   1                  1.98514     1.98514            1                1            1                           1                   0.0200079       0.0200079                  98.5143   98.5143
    2        0.0200579                   0.999999           1.98514     1.98514            1                0.999999     1                           1                   0.0198098       0.0398177                  98.5143   98.5143
    3        0.0300369                   0.999993           1.98514     1.98514            1                0.999996     1                           0.999999            0.0198098       0.0596276                  98.5143   98.5143
    4        0.040016                    0.999966           1.98514     1.98514            1                0.999983     1                           0.999995            0.0198098       0.0794374                  98.5143   98.5143
    5        0.0500948                   0.999917           1.96549     1.98119            0.990099         0.999942     0.998008                    0.999984            0.0198098       0.0992472                  96.5488   98.1188
    6        0.10009                     0.998651           1.97326     1.97723            0.994012         0.999497     0.996012                    0.999741            0.0986529       0.1979                     97.3256   97.7226
    7        0.150085                    0.993555           1.97722     1.97722            0.996008         0.996545     0.996011                    0.998676            0.098851        0.296751                   97.7218   97.7223
    8        0.20008                     0.980944           1.95344     1.97128            0.984032         0.988066     0.993017                    0.996025            0.0976624       0.394414                   95.3444   97.1281
    9        0.30007                     0.912843           1.91184     1.95147            0.963074         0.952909     0.98304                     0.981658            0.191165        0.585578                   91.1839   95.1474
    10       0.40006                     0.764575           1.88608     1.93513            0.9501           0.844199     0.974807                    0.947302            0.18859         0.774168                   88.6084   93.513
    11       0.50005                     0.535661           1.55523     1.85916            0.783433         0.658006     0.93654                     0.889454            0.155507        0.929675                   55.5227   85.9165
    12       0.60004                     0.219124           0.467559    1.62727            0.235529         0.363216     0.819724                    0.801762            0.0467512       0.976426                   -53.2441  62.7269
    13       0.70003                     0.0473368          0.142645    1.41521            0.0718563        0.120375     0.712901                    0.704435            0.0142631       0.990689                   -85.7355  41.521
    14       0.80002                     0.00406284         0.0673601   1.24675            0.0339321        0.0187743    0.62804                     0.618738            0.00673534      0.997425                   -93.264   24.675
    15       0.90001                     5.9696e-05         0.021793    1.11066            0.010978         0.00112778   0.559486                    0.550122            0.00217908      0.999604                   -97.8207  11.0659
    16       1                           9.44586e-27        0.00396236  1                  0.00199601       8.25233e-06  0.503742                    0.495116            0.000396197     1                          -99.6038  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.055774207608254966
RMSE: 0.2361656359597115
LogLoss: 0.20481574082337842
Mean Per-Class Error: 0.06157415873218253
AUC: 0.9779998934705857
pr_auc: 0.847043396990615
Gini: 0.9559997869411714
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5157465965642875: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2924  204   0.0652   (204.0/3128.0)
1      178   2871  0.0584   (178.0/3049.0)
Total  3102  3075  0.0618   (382.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.515747     0.937622  204
max f2                       0.403212     0.94812   240
max f0point5                 0.644588     0.947053  165
max accuracy                 0.542421     0.938481  197
max precision                0.996887     0.997534  5
max recall                   6.65532e-05  1         399
max specificity              0.999949     0.999361  0
max absolute_mcc             0.542421     0.876954  197
max min_per_class_accuracy   0.528392     0.93702   201
max mean_per_class_accuracy  0.542421     0.938426  197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.89 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999998           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.99999            2.02591     2.02591            1                0.999995     1                           0.999998            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999965           2.02591     2.02591            1                0.999979     1                           0.999993            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999918           1.9927      2.01935            0.983607         0.99994      0.996764                    0.999983            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.998669           2.01935     2.01935            0.996764         0.999496     0.996764                    0.999739            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.993643           2.01935     2.01935            0.996764         0.996701     0.996764                    0.998727            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.980877           2.00624     2.01608            0.990291         0.988099     0.995146                    0.99607             0.100361        0.403411                   100.624   101.608
    9        0.299984                    0.90807            1.95367     1.9953             0.964344         0.95112      0.984889                    0.981103            0.195146        0.598557                   95.3673   99.5297
    10       0.400032                    0.746791           1.92429     1.97754            0.949838         0.835145     0.976123                    0.944599            0.192522        0.791079                   92.4287   97.7538
    11       0.500081                    0.50484            1.52107     1.88621            0.750809         0.637461     0.931046                    0.883151            0.152181        0.94326                    52.1072   88.6215
    12       0.599968                    0.201469           0.387451    1.63669            0.191248         0.342701     0.807879                    0.793173            0.0387012       0.981961                   -61.2549  63.669
    13       0.700016                    0.0440792          0.0819543   1.41448            0.0404531        0.111437     0.698196                    0.695737            0.00819941      0.990161                   -91.8046  41.4483
    14       0.799903                    0.00381004         0.0656697   1.24605            0.0324149        0.0174652    0.615058                    0.611039            0.00655953      0.99672                    -93.433   24.6052
    15       0.899951                    5.75338e-05        0.0295035   1.11081            0.0145631        0.00106101   0.5483                      0.543227            0.00295179      0.999672                   -97.0496  11.0807
    16       1                           9.44586e-27        0.00327817  1                  0.00161812       7.94166e-06  0.493605                    0.488879            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:30:32  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:30:33  2:23:51.115  18050 obs/sec     1         1             25000      0.302611         0.32463             0.633687       0.943745        0.8222             1.96549          0.125337                         0.296487           0.30915               0.648325         0.948004          0.851396             1.99323            0.114133
    2019-08-03 18:30:39  2:23:56.560  19060 obs/sec     5         5             125000     0.262235         0.242029            0.724915       0.9674          0.873534           1.98514          0.0836244                        0.2569             0.232466              0.735967         0.970136          0.855462             2.02591            0.0768982
    2019-08-03 18:30:44  2:24:01.917  19411 obs/sec     9         9             225000     0.247396         0.2221              0.755167       0.973529        0.802717           1.98514          0.0691548                        0.243279           0.214295              0.763223         0.97559           0.805079             2.02591            0.0610329
    2019-08-03 18:30:46  2:24:03.453  19506 obs/sec     10        10            250000     0.241998         0.214507            0.765736       0.97551         0.817699           1.98514          0.0669594                        0.236166           0.204816              0.776867         0.978             0.847043             2.02591            0.0618423
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.00414274243597291
C28         0.8329421281814575     0.8329421281814575   0.0034506647011269117
C36         0.7743594646453857     0.7743594646453857   0.0032079718148837044
C438        0.7529698014259338     0.7529698014259338   0.0031193599493733117
C40         0.7409273386001587     0.7409273386001587   0.003069471127591347
---         ---                    ---                  ---
C475        0.12692426145076752    0.12692426145076752  0.0005258145240666152
C468        0.11746303737163544    0.11746303737163544  0.000486619109577746
C731        0.11574123799800873    0.11574123799800873  0.00047948613824639106
C232        0.11435233801603317    0.11435233801603317  0.0004737322833517389
C310        0.10756399482488632    0.10756399482488632  0.0004456099259438271

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_123

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.004660207363704845    0.004106529057025909   0.0         0.028027980886855368  0.10347974300384521  0.09273416398422883    0.3263314962387085
    3        2        Softmax                      0.0   0.0   0.00023869206631843554  6.135622970759869e-05  0.0         -0.11321201972896233  0.8498942852020264   -0.011929479314576746  0.10815674066543579


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.058996357776291995
RMSE: 0.24289165851525654
LogLoss: 0.21803647069060295
Mean Per-Class Error: 0.06549535870356338
AUC: 0.9748157669663954
pr_auc: 0.8153259066806515
Gini: 0.9496315339327908
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5102263586425602: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4674  373   0.0739   (373.0/5047.0)
1      284   4691  0.0571   (284.0/4975.0)
Total  4958  5064  0.0656   (657.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.510226     0.934555  202
max f2                       0.375926     0.947389  244
max f0point5                 0.625911     0.940852  162
max accuracy                 0.51429      0.934444  201
max precision                0.999966     0.994937  0
max recall                   5.68188e-05  1         399
max specificity              0.999966     0.999207  0
max absolute_mcc             0.510226     0.869035  202
max min_per_class_accuracy   0.532861     0.933822  195
max mean_per_class_accuracy  0.510226     0.934505  202
Gains/Lift Table: Avg response rate: 49.64 %, avg score: 49.89 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   1                  2.01447     2.01447            1                1            1                           1                   0.0203015       0.0203015                  101.447   101.447
    2        0.0200559                   1                  2.01447     2.01447            1                1            1                           1                   0.0201005       0.040402                   101.447   101.447
    3        0.0300339                   0.999998           1.99433     2.00778            0.99             0.999999     0.996678                    1                   0.0198995       0.0603015                  99.4328   100.778
    4        0.040012                    0.999992           2.01447     2.00945            1                0.999996     0.997506                    0.999999            0.0201005       0.080402                   101.447   100.945
    5        0.0500898                   0.99998            1.99453     2.00645            0.990099         0.999987     0.996016                    0.999996            0.0201005       0.100503                   99.4527   100.645
    6        0.10008                     0.999419           1.99839     2.00242            0.992016         0.999794     0.994018                    0.999895            0.0998995       0.200402                   99.8389   100.242
    7        0.15007                     0.99579            1.99839     2.00108            0.992016         0.997983     0.993351                    0.999258            0.0998995       0.300302                   99.8389   100.108
    8        0.20006                     0.985807           1.97426     1.99438            0.98004          0.991429     0.990025                    0.997302            0.0986935       0.398995                   97.4263   99.4378
    9        0.30004                     0.922341           1.94009     1.97629            0.963074         0.960329     0.981044                    0.984982            0.19397         0.592965                   94.0086   97.6286
    10       0.40002                     0.771462           1.8858      1.95367            0.936128         0.85532      0.969818                    0.952574            0.188543        0.781508                   88.5803   95.3671
    11       0.5                         0.524929           1.5581      1.87457            0.773453         0.649621     0.930553                    0.891996            0.155779        0.937286                   55.81     87.4573
    12       0.59998                     0.229727           0.404101    1.62953            0.200599         0.367288     0.808914                    0.804559            0.040402        0.977688                   -59.5899  62.9535
    13       0.69996                     0.0606362          0.140732    1.41688            0.0698603        0.134178     0.70335                     0.708804            0.0140704       0.991759                   -85.9268  41.6879
    14       0.79994                     0.00632473         0.0442299   1.24532            0.0219561        0.0261022    0.618186                    0.623477            0.00442211      0.996181                   -95.577   24.5319
    15       0.89992                     0.000143464        0.0321672   1.11054            0.0159681        0.00195165   0.551281                    0.554426            0.00321608      0.999397                   -96.7833  11.054
    16       1                           3.8989e-25         0.00602534  1                  0.00299103       2.06008e-05  0.496408                    0.498941            0.000603015     1                          -99.3975  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.056733307113929037
RMSE: 0.23818754609326037
LogLoss: 0.20578565948499544
Mean Per-Class Error: 0.061167491081307146
AUC: 0.977854568895592
pr_auc: 0.8192124495646869
Gini: 0.9557091377911839
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5114171858750197: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2930  198   0.0633   (198.0/3128.0)
1      180   2869  0.059    (180.0/3049.0)
Total  3110  3067  0.0612   (378.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.511417     0.938195  196
max f2                       0.446936     0.946692  217
max f0point5                 0.604395     0.943918  167
max accuracy                 0.511417     0.938805  196
max precision                0.993287     0.998077  9
max recall                   3.27247e-05  1         399
max specificity              0.999961     0.999361  0
max absolute_mcc             0.511417     0.877615  196
max min_per_class_accuracy   0.519612     0.938012  193
max mean_per_class_accuracy  0.511417     0.938833  196
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.63 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999997           1.99323     2.01502            0.983871         0.999999     0.994624                    0.999999            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.99999            2.02591     2.01774            1                0.999994     0.995968                    0.999998            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999971           2.02591     2.01935            1                0.999981     0.996764                    0.999995            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.999371           2.01935     2.01935            0.996764         0.999778     0.996764                    0.999887            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.996048           2.02591     2.02154            1                0.998113     0.997843                    0.999295            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.986731           1.99313     2.01444            0.983819         0.991788     0.994337                    0.997419            0.0997048       0.403083                   99.3128   101.444
    9        0.299984                    0.925825           1.94711     1.99202            0.961102         0.962783     0.98327                     0.985886            0.19449         0.597573                   94.7106   99.2017
    10       0.400032                    0.759695           1.92756     1.9759             0.951456         0.852095     0.975314                    0.952425            0.19285         0.790423                   92.7565   97.5898
    11       0.500081                    0.498109           1.53746     1.88818            0.7589           0.633529     0.932017                    0.888625            0.153821        0.944244                   53.7463   88.8182
    12       0.599968                    0.228328           0.36775     1.63505            0.181524         0.356308     0.80707                     0.800001            0.0367334       0.980977                   -63.225   63.5051
    13       0.700016                    0.061234           0.111458    1.41729            0.0550162        0.135193     0.699584                    0.704985            0.0111512       0.992129                   -88.8542  41.7294
    14       0.799903                    0.00643051         0.0558192   1.24728            0.0275527        0.0262754    0.615665                    0.620232            0.0055756       0.997704                   -94.4181  24.7282
    15       0.899951                    0.000145912        0.0163909   1.11044            0.00809061       0.00193566   0.54812                     0.551495            0.00163988      0.999344                   -98.3609  11.0442
    16       1                           1.14476e-23        0.00655634  1                  0.00323625       2.11982e-05  0.493605                    0.496321            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:28:54  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:28:56  2:22:13.630  18395 obs/sec     1         1             25000      0.307135         0.34134             0.622653       0.939707        0.78843            1.99453          0.126422                         0.30393            0.325872              0.630445         0.942677          0.785068             1.99323            0.119961
    2019-08-03 18:29:01  2:22:18.869  19728 obs/sec     5         5             125000     0.263576         0.24794             0.722096       0.966151        0.825744           2.01447          0.0825185                        0.25792            0.234085              0.733866         0.970058          0.841226             2.02591            0.077222
    2019-08-03 18:29:06  2:22:24.152  19888 obs/sec     9         9             225000     0.245821         0.221407            0.758275       0.973711        0.817054           2.01447          0.0677509                        0.240249           0.210154              0.769084         0.976819          0.827616             2.02591            0.0620042
    2019-08-03 18:29:08  2:22:25.645  19979 obs/sec     10        10            250000     0.242892         0.218036            0.764002       0.974816        0.815326           2.01447          0.0655558                        0.238188           0.205786              0.77303          0.977855          0.819212             2.02591            0.0611948
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C35         1.0                    1.0                  0.0040993949337808635
C250        0.9826547503471375     0.9826547503471375   0.004028289905228754
C28         0.9239683747291565     0.9239683747291565   0.003787711274338442
C36         0.8990684747695923     0.8990684747695923   0.003685636750592554
C39         0.8778514266014099     0.8778514266014099   0.003598659690822123
---         ---                    ---                  ---
C294        0.12405258417129517    0.12405258417129517  0.0005085405350742315
C470        0.12132129818201065    0.12132129818201065  0.0004973439151270519
C475        0.11590226739645004    0.11590226739645004  0.0004751291677787222
C218        0.10222695767879486    0.10222695767879486  0.00041906867240428235
C352        0.09964552521705627    0.09964552521705627  0.00040848636124873373

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_39

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.018824139979733444   0.023733437061309814   0.0         0.005366184048121198  0.15028762817382812  -0.05385863657697043    0.1873563528060913
    3        2        Softmax                 0.0   0.0   0.0017825827344495337  0.0004049954004585743  0.0         0.015816186132724397  0.673269510269165    -0.0014165507991006493  0.10651159286499023


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06487473835475639
RMSE: 0.2547051989158376
LogLoss: 0.22055228360387286
Mean Per-Class Error: 0.08622285270590302
AUC: 0.9701760795644653
pr_auc: 0.9550211666374201
Gini: 0.9403521591289306
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4731244333218241: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4462  520   0.1044   (520.0/4982.0)
1      362   4682  0.0718   (362.0/5044.0)
Total  4824  5202  0.088    (882.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.473124     0.913918  212
max f2                       0.201671     0.938712  291
max f0point5                 0.819378     0.926418  107
max accuracy                 0.590607     0.913724  179
max precision                0.996595     1         0
max recall                   0.00487336   1         396
max specificity              0.996595     1         0
max absolute_mcc             0.590607     0.827598  179
max min_per_class_accuracy   0.547447     0.912371  191
max mean_per_class_accuracy  0.590607     0.913777  179
Gains/Lift Table: Avg response rate: 50.31 %, avg score: 50.64 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.995773           1.98771     1.98771            1                0.996459    1                           0.996459            0.0200238       0.0200238                  98.7708   98.7708
    2        0.0200479                   0.994676           1.98771     1.98771            1                0.995199    1                           0.995832            0.0198255       0.0398493                  98.7708   98.7708
    3        0.0300219                   0.993409           1.98771     1.98771            1                0.994076    1                           0.995248            0.0198255       0.0596749                  98.7708   98.7708
    4        0.0400958                   0.991985           1.98771     1.98771            1                0.992589    1                           0.99458             0.0200238       0.0796987                  98.7708   98.7708
    5        0.0500698                   0.991113           1.98771     1.98771            1                0.991488    1                           0.993964            0.0198255       0.0995242                  98.7708   98.7708
    6        0.10004                     0.988501           1.98771     1.98771            1                0.990454    1                           0.992211            0.0993259       0.19885                    98.7708   98.7708
    7        0.15001                     0.981263           1.95597     1.97714            0.984032         0.985084    0.994681                    0.989837            0.0977399       0.29659                    95.5968   97.7135
    8        0.20008                     0.974518           1.96395     1.97384            0.988048         0.976744    0.993021                    0.98656             0.0983347       0.394925                   96.3951   97.3836
    9        0.30002                     0.946962           1.91431     1.95401            0.963074         0.962314    0.983045                    0.978484            0.191316        0.586241                   91.431    95.4007
    10       0.40006                     0.867515           1.84304     1.92626            0.927218         0.917099    0.969085                    0.963134            0.184377        0.770619                   84.3039   92.6258
    11       0.5                         0.555354           1.39457     1.81998            0.701597         0.745729    0.915619                    0.919679            0.139374        0.909992                   39.457    81.9984
    12       0.60004                     0.157719           0.628219    1.62129            0.316052         0.335756    0.815658                    0.822326            0.0628469       0.972839                   -37.1781  62.1291
    13       0.69998                     0.0424587          0.176553    1.41502            0.0888224        0.0853801   0.711884                    0.717108            0.0176447       0.990484                   -82.3447  41.5017
    14       0.80002                     0.0172633          0.0554894   1.24501            0.0279163        0.0276287   0.626356                    0.630891            0.00555115      0.996035                   -94.4511  24.5013
    15       0.89996                     0.00658106         0.0317399   1.11028            0.0159681        0.0117249   0.558573                    0.562133            0.00317209      0.999207                   -96.826   11.0279
    16       1                           0.001988           0.00792705  1                  0.00398804       0.00522515  0.503092                    0.50642             0.000793021     1                          -99.2073  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.05990406597837794
RMSE: 0.24475307143808828
LogLoss: 0.20593057565920084
Mean Per-Class Error: 0.07930391415910121
AUC: 0.9740161547243279
pr_auc: 0.9577117409597791
Gini: 0.9480323094486558
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5242607764649131: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2873  255   0.0815   (255.0/3128.0)
1      239   2810  0.0784   (239.0/3049.0)
Total  3112  3065  0.08     (494.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.524261     0.919202  198
max f2                       0.261434     0.940879  274
max f0point5                 0.725817     0.932791  143
max accuracy                 0.597193     0.920835  180
max precision                0.996613     1         0
max recall                   0.00525373   1         396
max specificity              0.996613     1         0
max absolute_mcc             0.597193     0.841769  180
max min_per_class_accuracy   0.533419     0.919437  196
max mean_per_class_accuracy  0.597193     0.920696  180
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.77 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.995748           2.02591     2.02591            1                0.996461    1                           0.996461            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.994582           2.02591     2.02591            1                0.995164    1                           0.995813            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.993135           2.02591     2.02591            1                0.993912    1                           0.995179            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.991834           2.02591     2.02591            1                0.992417    1                           0.994489            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.991109           2.02591     2.02591            1                0.991399    1                           0.993879            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.988412           2.01935     2.02263            0.996764         0.990405    0.998382                    0.992142            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.981266           1.99968     2.01498            0.987055         0.985066    0.994606                    0.989783            0.100033        0.302394                   99.9685   101.498
    8        0.200097                    0.974267           1.99313     2.00952            0.983819         0.976784    0.991909                    0.986533            0.0997048       0.402099                   99.3128   100.952
    9        0.299984                    0.943326           1.97666     1.99858            0.975689         0.960853    0.986508                    0.977983            0.197442        0.599541                   97.6658   99.8577
    10       0.400032                    0.859089           1.86528     1.96524            0.920712         0.912622    0.970053                    0.961636            0.186619        0.786159                   86.528    96.5239
    11       0.500081                    0.500838           1.38667     1.84949            0.684466         0.717489    0.912917                    0.91279             0.138734        0.924893                   38.6667   84.9487
    12       0.599968                    0.135988           0.518791    1.62794            0.256078         0.292954    0.803562                    0.809596            0.0518203       0.976714                   -48.1209  62.7944
    13       0.700016                    0.0398941          0.147518    1.41636            0.0728155        0.0754871   0.699121                    0.704675            0.0147589       0.991473                   -85.2482  41.6357
    14       0.799903                    0.0174411          0.0623862   1.24728            0.0307942        0.026846    0.615665                    0.620032            0.00623155      0.997704                   -93.7614  24.7282
    15       0.899951                    0.00650826         0.019669    1.11081            0.00970874       0.011633    0.5483                      0.552396            0.00196786      0.999672                   -98.0331  11.0807
    16       1                           0.00198949         0.00327817  1                  0.00161812       0.00522926  0.493605                    0.497652            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:49:29  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:49:32  42 min 50.133 sec  9025 obs/sec      1         1             25000      0.300786         0.298757            0.638098       0.945447        0.929594           1.98771          0.120088                         0.288959           0.278628              0.665955         0.952808          0.934295             2.02591            0.107657
    2019-08-03 16:49:38  42 min 55.892 sec  9092 obs/sec      3         3             75000      0.278793         0.260115            0.689086       0.958671        0.940493           1.98771          0.104728                         0.268045           0.242636              0.712561         0.964354          0.942571             2.02591            0.0985915
    2019-08-03 16:49:44  43 min  1.820 sec  8987 obs/sec      5         5             125000     0.271155         0.24735             0.705889       0.962871        0.919478           1.98771          0.100239                         0.261171           0.231769              0.727114         0.967746          0.917699             2.02591            0.0911446
    2019-08-03 16:49:50  43 min  7.644 sec  8991 obs/sec      7         7             175000     0.263521         0.234609            0.722217       0.96662         0.962597           1.98771          0.0926591                        0.25312            0.21911               0.743679         0.970997          0.963492             2.02591            0.084507
    2019-08-03 16:49:56  43 min 13.299 sec  9070 obs/sec      9         9             225000     0.257932         0.225276            0.733875       0.969232        0.959281           1.98771          0.0892679                        0.246626           0.208933              0.756662         0.973747          0.964833             2.02591            0.0798122
    2019-08-03 16:49:59  43 min 16.323 sec  9073 obs/sec      10        10            250000     0.254705         0.220552            0.740491       0.970176        0.955021           1.98771          0.0879713                        0.244753           0.205931              0.760345         0.974016          0.957712             2.02591            0.0799741
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006755032129831535
C438        0.7889809012413025     0.7889809012413025    0.005329591337708439
C88         0.7104235887527466     0.7104235887527466    0.004798934167815028
C374        0.702857494354248      0.702857494354248     0.0047478249570558325
C322        0.6830761432647705     0.6830761432647705    0.0046142012948749336
---         ---                    ---                   ---
C899        0.05631842836737633    0.05631842836737633   0.00038043279312324286
C961        0.05577939748764038    0.05577939748764038   0.00037679162221165516
C382        0.05466248840093613    0.05466248840093613   0.00036924686544486713
C802        0.05363532528281212    0.05363532528281212   0.0003623083455793615
C755        0.053263720124959946   0.053263720124959946  0.000359798140798459

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_132

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.025141177368192186  0.04945091903209686     0.0         0.013687381522472232  0.14422529935836792  -0.05519128089052806    0.16129153966903687
    3        2        Softmax                 0.0   0.0   0.001873729032013216  0.00045934366062283516  0.0         0.34233906722511165   0.5887699127197266   -0.0020587735507424793  0.1358349323272705


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06407670900459375
RMSE: 0.25313377689394545
LogLoss: 0.2193084159737117
Mean Per-Class Error: 0.08405582249470078
AUC: 0.9702960892452152
pr_auc: 0.9477642186564016
Gini: 0.9405921784904303
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5256097878386043: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4638  416   0.0823   (416.0/5054.0)
1      426   4539  0.0858   (426.0/4965.0)
Total  5064  4955  0.084    (842.0/10019.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.52561      0.915121  198
max f2                       0.202387     0.938269  288
max f0point5                 0.719921     0.927041  141
max accuracy                 0.52561      0.91596   198
max precision                0.993073     1         0
max recall                   0.00412355   1         399
max specificity              0.993073     1         0
max absolute_mcc             0.52561      0.831905  198
max min_per_class_accuracy   0.515249     0.915117  201
max mean_per_class_accuracy  0.52561      0.915944  198
Gains/Lift Table: Avg response rate: 49.56 %, avg score: 49.40 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100808                   0.992726           2.01793    2.01793            1                0.993084    1                           0.993084            0.0203424       0.0203424                  101.793   101.793
    2        0.0200619                   0.991431           2.01793    2.01793            1                0.992171    1                           0.99263             0.020141        0.0404834                  101.793   101.793
    3        0.0300429                   0.989972           2.01793    2.01793            1                0.990682    1                           0.991983            0.020141        0.0606244                  101.793   101.793
    4        0.040024                    0.98868            2.01793    2.01793            1                0.989222    1                           0.991294            0.020141        0.0807654                  101.793   101.793
    5        0.050005                    0.988167           1.97757    2.00987            0.98             0.988351    0.996008                    0.990707            0.0197382       0.100504                   97.7567   100.987
    6        0.10001                     0.98223            1.99779    2.00383            0.99002          0.985733    0.993014                    0.98822             0.0998993       0.200403                   99.7787   100.383
    7        0.150015                    0.977633           1.99376    2.00047            0.988024         0.979584    0.991351                    0.985341            0.0996979       0.300101                   99.3759   100.047
    8        0.20002                     0.969964           1.99779    1.9998             0.99002          0.974233    0.991018                    0.982564            0.0998993       0.4                        99.7787   99.98
    9        0.30003                     0.943948           1.93938    1.97966            0.961078         0.959592    0.981038                    0.974907            0.193958        0.593958                   93.9383   97.9661
    10       0.40004                     0.846269           1.83265    1.94291            0.908184         0.906072    0.962824                    0.957698            0.183283        0.777241                   83.2647   94.2908
    11       0.50005                     0.497025           1.40369    1.83506            0.695609         0.697684    0.909381                    0.905695            0.140383        0.917623                   40.3687   83.5064
    12       0.59996                     0.135531           0.584614   1.62683            0.28971          0.291358    0.806189                    0.803391            0.0584089       0.976032                   -41.5386  62.6829
    13       0.69997                     0.0390527          0.16514    1.41799            0.0818363        0.0756689   0.702695                    0.699416            0.0165156       0.992548                   -83.486   41.7986
    14       0.79998                     0.0166278          0.0483335  1.24676            0.0239521        0.0253915   0.617842                    0.615152            0.00483384      0.997382                   -95.1666  24.6758
    15       0.89999                     0.00909706         0.0161112  1.11               0.00798403       0.0125068   0.550072                    0.548184            0.00161128      0.998993                   -98.3889  11.0004
    16       1                           0.00314573         0.0100695  1                  0.00499002       0.00654278  0.495558                    0.494015            0.00100705      1                          -98.9931  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06021571388245538
RMSE: 0.2453889033400968
LogLoss: 0.2068975147411082
Mean Per-Class Error: 0.07965506278944345
AUC: 0.9739108835314753
pr_auc: 0.9508505617921453
Gini: 0.9478217670629505
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4572038238959141: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2842  286   0.0914   (286.0/3128.0)
1      210   2839  0.0689   (210.0/3049.0)
Total  3052  3125  0.0803   (496.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.457204     0.919663  215
max f2                       0.242982     0.942214  276
max f0point5                 0.729563     0.932738  138
max accuracy                 0.527907     0.92035   197
max precision                0.993045     1         0
max recall                   0.00687747   1         395
max specificity              0.993045     1         0
max absolute_mcc             0.525395     0.840677  198
max min_per_class_accuracy   0.525395     0.919974  198
max mean_per_class_accuracy  0.525395     0.920345  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.31 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.992766           2.02591     2.02591            1                0.993071    1                           0.993071            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.991533           2.02591     2.02591            1                0.992252    1                           0.992662            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.990226           2.02591     2.02591            1                0.990885    1                           0.99207             0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.98909            1.99323     2.01774            0.983871         0.98965     0.995968                    0.991465            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.988225           2.02591     2.01935            1                0.988587    0.996764                    0.990897            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.982869           2.0128      2.01608            0.993528         0.986127    0.995146                    0.988512            0.100689        0.201705                   101.28    101.608
    7        0.150073                    0.978275           2.01935     2.01717            0.996764         0.980225    0.995685                    0.985749            0.101017        0.302722                   101.935   101.717
    8        0.200097                    0.970321           1.99968     2.0128             0.987055         0.974543    0.993528                    0.982948            0.100033        0.402755                   99.9685   101.28
    9        0.299984                    0.943352           1.95367     1.99311            0.964344         0.959609    0.98381                     0.975177            0.195146        0.597901                   95.3673   99.3111
    10       0.400032                    0.848991           1.84889     1.95704            0.912621         0.906009    0.966006                    0.957878            0.184979        0.78288                    84.8889   95.7041
    11       0.500081                    0.48707            1.41945     1.84949            0.700647         0.700091    0.912917                    0.906304            0.142014        0.924893                   41.9448   84.9487
    12       0.599968                    0.130254           0.541775    1.63177            0.267423         0.281937    0.805451                    0.802355            0.0541161       0.97901                    -45.8225  63.1771
    13       0.700016                    0.0391521          0.147518    1.41964            0.0728155        0.0731474   0.70074                     0.698134            0.0147589       0.993768                   -85.2482  41.9636
    14       0.799903                    0.0163254          0.0459688   1.2481             0.0226904        0.0257716   0.61607                     0.614174            0.00459167      0.99836                    -95.4031  24.8102
    15       0.899951                    0.00837061         0.00983452  1.11044            0.00485437       0.0122279   0.54812                     0.547255            0.000983929     0.999344                   -99.0165  11.0442
    16       1                           0.00333953         0.00655634  1                  0.00323625       0.00636333  0.493605                    0.493139            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:35:08  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:35:10  2:28:28.121  9451 obs/sec      1         1             25000      0.294357         0.288458            0.65339        0.949517        0.918731           1.99795          0.118774                         0.288531           0.27688               0.666944         0.953545          0.919599             2.02591            0.113324
    2019-08-03 18:35:16  2:28:33.888  9270 obs/sec      3         3             75000      0.276475         0.257954            0.694222       0.959842        0.940755           2.01793          0.103204                         0.269332           0.2468                0.709793         0.963888          0.942086             2.02591            0.0958394
    2019-08-03 18:35:22  2:28:39.781  9156 obs/sec      5         5             125000     0.269202         0.245631            0.710098       0.963352        0.916414           2.01793          0.0964168                        0.261671           0.2337                0.726068         0.967432          0.925281             2.02591            0.0908208
    2019-08-03 18:35:28  2:28:45.789  9053 obs/sec      7         7             175000     0.262892         0.234731            0.72353        0.96632         0.960449           2.01793          0.0922248                        0.255198           0.222461              0.739454         0.970241          0.965985             2.02591            0.0879068
    2019-08-03 18:35:34  2:28:51.557  9081 obs/sec      9         9             225000     0.257145         0.225707            0.735484       0.968862        0.951476           2.01793          0.0891307                        0.249205           0.213309              0.751547         0.972679          0.958511             2.02591            0.0828881
    2019-08-03 18:35:37  2:28:54.582  9095 obs/sec      10        10            250000     0.253134         0.219308            0.743673       0.970296        0.947764           2.01793          0.0840403                        0.245389           0.206898              0.759098         0.973911          0.950851             2.02591            0.0802979
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006613723446131736
C438        0.8186386823654175     0.8186386823654175    0.005414249847470552
C374        0.7312808632850647     0.7312808632850647    0.004836489391215889
C88         0.6555776596069336     0.6555776596069336    0.004335809338102547
C322        0.6477136611938477     0.6477136611938477    0.004283799027417577
---         ---                    ---                   ---
C857        0.0643620565533638     0.0643620565533638    0.0004256728424682389
C888        0.06412792205810547    0.06412792205810547   0.00042412434166740065
C592        0.06369049847126007    0.06369049847126007   0.0004212313430351902
C982        0.061585549265146255   0.061585549265146255  0.0004073097911177989
C525        0.05085940286517143    0.05085940286517143   0.0003363700251856439

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_196

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.01949940179183799    0.03153088688850403    0.0         0.006977161531826971  0.15034586191177368  -0.04221810397681985  0.1748267412185669
    3        2        Softmax                 0.0   0.0   0.0017701989399938611  0.0003892299719154835  0.0         -0.2704539147380274   0.6459250450134277   0.006621935055688574  0.13368761539459229


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06546066016505724
RMSE: 0.2558528095703802
LogLoss: 0.2230604252687045
Mean Per-Class Error: 0.08743017170240219
AUC: 0.9695488965593633
pr_auc: 0.956652200101709
Gini: 0.9390977931187265
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4664477591516778: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4551  496   0.0983   (496.0/5047.0)
1      384   4578  0.0774   (384.0/4962.0)
Total  4935  5074  0.0879   (880.0/10009.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.466448     0.912316  211
max f2                       0.184791     0.939291  295
max f0point5                 0.788018     0.924825  119
max accuracy                 0.528612     0.912579  196
max precision                0.981353     0.995868  14
max recall                   0.00296603   1         399
max specificity              0.994911     0.999802  0
max absolute_mcc             0.528612     0.825144  196
max min_per_class_accuracy   0.525199     0.912225  197
max mean_per_class_accuracy  0.528612     0.91257   196
Gains/Lift Table: Avg response rate: 49.58 %, avg score: 49.39 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100909                   0.993168           1.99716     1.99716            0.990099         0.994397    0.990099                    0.994397            0.0201532       0.0201532                  99.7159   99.7159
    2        0.0200819                   0.991704           2.01713     2.00709            1                0.992429    0.995025                    0.993418            0.0201532       0.0403063                  101.713   100.709
    3        0.0300729                   0.991182           1.99696     2.00373            0.99             0.991412    0.993355                    0.992751            0.0199516       0.060258                   99.6959   100.373
    4        0.0400639                   0.989789           1.99696     2.00204            0.99             0.990422    0.992519                    0.992171            0.0199516       0.0802096                  99.6959   100.204
    5        0.050055                    0.98847            2.01713     2.00505            1                0.98913     0.994012                    0.991564            0.0201532       0.100363                   101.713   100.505
    6        0.10001                     0.980566           2.00906     2.00705            0.996            0.984537    0.995005                    0.988054            0.100363        0.200726                   100.906   100.705
    7        0.150065                    0.974975           1.98492     1.99967            0.984032         0.977623    0.991345                    0.984574            0.0993551       0.300081                   98.4921   99.9672
    8        0.20002                     0.967412           2.00099     2                  0.992            0.971409    0.991508                    0.981286            0.0999597       0.40004                    100.099   100
    9        0.30003                     0.941973           1.95466     1.98489            0.969031         0.957203    0.984016                    0.973258            0.195486        0.595526                   95.4662   98.4888
    10       0.40004                     0.844223           1.7995      1.93854            0.892108         0.903348    0.961039                    0.955781            0.179968        0.775494                   79.9498   93.8541
    11       0.50005                     0.504235           1.4005      1.83093            0.694306         0.702399    0.907692                    0.905104            0.140064        0.915558                   40.0505   83.0934
    12       0.59996                     0.13422            0.617242    1.62882            0.306            0.290022    0.807494                    0.802676            0.0616687       0.977227                   -38.2758  62.882
    13       0.69997                     0.041091           0.145088    1.41683            0.0719281        0.0752463   0.702398                    0.698743            0.0145103       0.991737                   -85.4912  41.6828
    14       0.79998                     0.0194148          0.0644837   1.24776            0.031968         0.0277728   0.618584                    0.614861            0.00644901      0.998186                   -93.5516  24.7764
    15       0.89999                     0.00976386         0.00806046  1.11               0.003996         0.0144888   0.550289                    0.548146            0.000806127     0.998992                   -99.194   11.0004
    16       1                           0.00209501         0.0100756   1                  0.004995         0.00603226  0.495754                    0.493929            0.00100766      1                          -98.9924  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.060641523420088154
RMSE: 0.2462549967413619
LogLoss: 0.20927233381231897
Mean Per-Class Error: 0.07910511517339547
AUC: 0.9731009034868671
pr_auc: 0.961202640066342
Gini: 0.9462018069737341
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5027600794976369: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2866  262   0.0838   (262.0/3128.0)
1      227   2822  0.0745   (227.0/3049.0)
Total  3093  3084  0.0792   (489.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.50276      0.920267  202
max f2                       0.173978     0.94202   293
max f0point5                 0.758799     0.930132  128
max accuracy                 0.50276      0.920835  202
max precision                0.994747     1         0
max recall                   0.00677535   1         393
max specificity              0.994747     1         0
max absolute_mcc             0.50276      0.841722  202
max min_per_class_accuracy   0.526263     0.920302  196
max mean_per_class_accuracy  0.50276      0.920895  202
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.32 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.993194           2.02591     2.02591            1                0.99417     1                           0.99417             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.991588           2.02591     2.02591            1                0.992351    1                           0.993261            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.990799           2.02591     2.02591            1                0.991269    1                           0.992597            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.989616           2.02591     2.02591            1                0.990092    1                           0.991971            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.988673           2.02591     2.02591            1                0.989187    1                           0.991421            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.980704           2.0128      2.01935            0.993528         0.98468     0.996764                    0.988051            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.974744           1.99968     2.0128             0.987055         0.977693    0.993528                    0.984598            0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.967264           2.00624     2.01116            0.990291         0.970994    0.992718                    0.981197            0.100361        0.402427                   100.624   101.116
    9        0.299984                    0.943926           1.95367     1.99202            0.964344         0.957786    0.98327                     0.973402            0.195146        0.597573                   95.3673   99.2017
    10       0.400032                    0.848776           1.86528     1.96032            0.920712         0.906304    0.967624                    0.956621            0.186619        0.784192                   86.528    96.032
    11       0.500081                    0.498393           1.41945     1.85211            0.700647         0.703493    0.914212                    0.905979            0.142014        0.926205                   41.9448   85.2111
    12       0.599968                    0.129757           0.518791    1.63013            0.256078         0.281862    0.804641                    0.802072            0.0518203       0.978026                   -48.1209  63.0131
    13       0.700016                    0.0392395          0.150796    1.4187             0.0744337        0.0729335   0.700278                    0.697861            0.0150869       0.993112                   -84.9204  41.8699
    14       0.799903                    0.0189695          0.0459688   1.24728            0.0226904        0.0265813   0.615665                    0.614036            0.00459167      0.997704                   -95.4031  24.7282
    15       0.899951                    0.00915452         0.0131127   1.11008            0.00647249       0.0140591   0.54794                     0.547336            0.00131191      0.999016                   -98.6887  11.0078
    16       1                           0.00225058         0.00983452  1                  0.00485437       0.00577436  0.493605                    0.493153            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:07:10  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:07:13  4:00:30.346  8827 obs/sec      1         1             25000      0.301722         0.301231            0.63583        0.945456        0.921533           2.01713          0.123988                         0.293139           0.285052              0.656222         0.950699          0.923658             2.02591            0.116238
    2019-08-03 20:07:18  4:00:36.013  9118 obs/sec      3         3             75000      0.279981         0.262462            0.686419       0.958052        0.945826           2.01713          0.106804                         0.270737           0.248711              0.706758         0.962717          0.944891             2.02591            0.0960013
    2019-08-03 20:07:24  4:00:41.688  9177 obs/sec      5         5             125000     0.272153         0.249221            0.703709       0.962055        0.939998           2.01713          0.10001                          0.263022           0.236291              0.723232         0.965938          0.943794             2.02591            0.0909827
    2019-08-03 20:07:30  4:00:47.205  9276 obs/sec      7         7             175000     0.264922         0.238469            0.719245       0.965421        0.959062           2.01713          0.0943151                        0.255616           0.224872              0.738599         0.969477          0.962719             2.02591            0.0854784
    2019-08-03 20:07:35  4:00:52.864  9284 obs/sec      9         9             225000     0.258457         0.227186            0.732781       0.968365        0.955275           1.99716          0.08892                          0.247954           0.212164              0.754036         0.97233           0.961487             2.02591            0.0799741
    2019-08-03 20:07:38  4:00:55.909  9328 obs/sec      10        10            250000     0.255853         0.22306             0.738138       0.969549        0.956652           1.99716          0.0879209                        0.246255           0.209272              0.757394         0.973101          0.961203             2.02591            0.0791646
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006475923309087993
C438        0.7919381856918335     0.7919381856918335    0.0051285309560786
C374        0.7652162909507751     0.7652162909507751    0.004955482015061984
C863        0.6617358326911926     0.6617358326911926    0.004285350503383647
C322        0.6519461274147034     0.6519461274147034    0.004221953122794528
---         ---                    ---                   ---
C925        0.062246568500995636   0.062246568500995636  0.0004031040038663401
C850        0.062115833163261414   0.062115833163261414  0.00040225737184538553
C969        0.05928001552820206    0.05928001552820206   0.00038389283432218186
C674        0.057509299367666245   0.057509299367666245  0.00037242581226438917
C961        0.051899153739213943   0.051899153739213943  0.00033609493942171685

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_53

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.01776789361683397   0.016292549669742584    0.0         -0.010863445926852327  0.15193301439285278  0.03747138316397258     0.19727587699890137
    3        2        Softmax                 0.0   0.0   0.001681873518464272  2.5132219889201224e-05  0.0         -0.12465203791362      0.708942174911499    -0.0019674198189787995  0.11940079927444458


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06872897386577598
RMSE: 0.26216211371168024
LogLoss: 0.23131150671407075
Mean Per-Class Error: 0.09363256706494194
AUC: 0.9676490754011899
pr_auc: 0.9621797685368018
Gini: 0.9352981508023799
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4608485735506869: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4454  567   0.1129   (567.0/5021.0)
1      382   4625  0.0763   (382.0/5007.0)
Total  4836  5192  0.0946   (949.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.460849     0.906952  214
max f2                       0.184263     0.934994  298
max f0point5                 0.79916      0.922963  118
max accuracy                 0.574983     0.906362  186
max precision                0.9959       1         0
max recall                   0.00319874   1         399
max specificity              0.9959       1         0
max absolute_mcc             0.574983     0.81277   186
max min_per_class_accuracy   0.551382     0.905732  193
max mean_per_class_accuracy  0.529729     0.906367  198
Gains/Lift Table: Avg response rate: 49.93 %, avg score: 50.28 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   0.994787           1.98297    1.98297            0.990099         0.995054    0.990099                    0.995054            0.019972        0.019972                   98.2966   98.2966
    2        0.0200439                   0.994646           2.0028     1.99283            1                0.994745    0.995025                    0.9949              0.019972        0.0399441                  100.28    99.2832
    3        0.030016                    0.993658           2.0028     1.99614            1                0.994263    0.996678                    0.994689            0.019972        0.0599161                  100.28    99.6142
    4        0.0400878                   0.992031           1.98297    1.99283            0.990099         0.992859    0.995025                    0.994229            0.019972        0.0798882                  98.2966   99.2832
    5        0.0500598                   0.990427           2.0028     1.99482            1                0.991177    0.996016                    0.993621            0.019972        0.0998602                  100.28    99.4817
    6        0.10002                     0.98092            1.97881    1.98682            0.988024         0.985207    0.992024                    0.989418            0.0988616       0.198722                   97.8811   98.6822
    7        0.15008                     0.975452           1.99482    1.98949            0.996016         0.978098    0.993355                    0.985642            0.0998602       0.298582                   99.4817   98.9488
    8        0.20004                     0.969795           1.96282    1.98283            0.98004          0.972665    0.99003                     0.982401            0.0980627       0.396645                   96.282    98.2828
    9        0.30006                     0.944994           1.93091    1.96552            0.964108         0.959709    0.981389                    0.974837            0.19313         0.589774                   93.0911   96.5522
    10       0.39998                     0.862709           1.8249     1.93039            0.911178         0.912714    0.963849                    0.959318            0.182345        0.772119                   82.4903   93.0394
    11       0.5                         0.545235           1.34385    1.81306            0.670987         0.733328    0.905265                    0.914111            0.134412        0.906531                   34.385    81.3062
    12       0.60002                     0.159411           0.658946   1.62068            0.329013         0.324699    0.809207                    0.815859            0.0659077       0.972439                   -34.1054  62.0677
    13       0.69994                     0.0423439          0.189886   1.41642            0.0948104        0.0860699   0.707223                    0.711678            0.0189734       0.991412                   -81.0114  41.6424
    14       0.79996                     0.0183462          0.0539138  1.24607            0.0269192        0.0277218   0.622164                    0.626162            0.00539245      0.996804                   -94.6086  24.6068
    15       0.89998                     0.00904053         0.0199681  1.1098             0.00997009       0.0138412   0.554127                    0.558111            0.0019972       0.998802                   -98.0032  10.9804
    16       1                           0.00204572         0.0119808  1                  0.00598205       0.00479206  0.499302                    0.502768            0.00119832      1                          -98.8019  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06108567033641137
RMSE: 0.2471551543796151
LogLoss: 0.20929114896506734
Mean Per-Class Error: 0.08052056185458478
AUC: 0.9735022761225642
pr_auc: 0.9682545843479122
Gini: 0.9470045522451285
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5589215046263232: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2891  237   0.0758   (237.0/3128.0)
1      260   2789  0.0853   (260.0/3049.0)
Total  3151  3026  0.0805   (497.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.558922     0.918189  190
max f2                       0.23942      0.940733  276
max f0point5                 0.78643      0.930838  125
max accuracy                 0.57686      0.91954   186
max precision                0.99585      1         0
max recall                   0.00868319   1         392
max specificity              0.99585      1         0
max absolute_mcc             0.57686      0.839095  186
max min_per_class_accuracy   0.536096     0.918662  196
max mean_per_class_accuracy  0.558922     0.919479  190
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.75 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.994787           2.02591     2.02591            1                0.995082    1                           0.995082            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.994719           2.02591     2.02591            1                0.994769    1                           0.994926            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.993933           2.02591     2.02591            1                0.994408    1                           0.994753            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.992078           2.02591     2.02591            1                0.992961    1                           0.994305            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.99052            2.02591     2.02591            1                0.991297    1                           0.993711            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.981084           2.01935     2.02263            0.996764         0.985657    0.998382                    0.989684            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.976183           2.0128      2.01935            0.993528         0.978472    0.996764                    0.985947            0.100689        0.30305                    101.28    101.935
    8        0.200097                    0.969763           1.99313     2.0128             0.983819         0.972885    0.993528                    0.982681            0.0997048       0.402755                   99.3128   101.28
    9        0.299984                    0.947065           1.96024     1.9953             0.967585         0.959752    0.984889                    0.975046            0.195802        0.598557                   96.024    99.5297
    10       0.400032                    0.864135           1.85545     1.96032            0.915858         0.915506    0.967624                    0.960155            0.185635        0.784192                   85.5445   96.032
    11       0.500081                    0.505994           1.38994     1.84621            0.686084         0.719363    0.911298                    0.911981            0.139062        0.923254                   38.9945   84.6208
    12       0.599968                    0.138195           0.558192    1.63177            0.275527         0.291588    0.805451                    0.808694            0.055756        0.97901                    -44.1808  63.1771
    13       0.700016                    0.0405012          0.124571    1.41636            0.0614887        0.0771791   0.699121                    0.704143            0.0124631       0.991473                   -87.5429  41.6357
    14       0.799903                    0.0184357          0.0755202   1.24892            0.0372771        0.0269748   0.616474                    0.619583            0.00754346      0.999016                   -92.448   24.8922
    15       0.899951                    0.00878298         0.00655634  1.11081            0.00323625       0.0139114   0.5483                      0.55225             0.000655953     0.999672                   -99.3444  11.0807
    16       1                           0.0020353          0.00327817  1                  0.00161812       0.00473576  0.493605                    0.497472            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:07:44  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:07:47  1:01:04.275  9214 obs/sec      1         1             25000      0.308019         0.31804             0.620497       0.940423        0.888308           1.98297          0.126845                         0.298078           0.298816              0.64454          0.946738          0.909391             2.02591            0.119475
    2019-08-03 17:07:52  1:01:10.001  9179 obs/sec      3         3             75000      0.282707         0.266206            0.680306       0.957057        0.941777           2.0028           0.11069                          0.269893           0.246584              0.708583         0.963654          0.955317             2.02591            0.0971345
    2019-08-03 17:07:58  1:01:15.624  9213 obs/sec      5         5             125000     0.276445         0.255421            0.694312       0.960252        0.935912           2.0028           0.10361                          0.263164           0.234811              0.722933         0.966602          0.94132              2.02591            0.0908208
    2019-08-03 17:08:03  1:01:21.138  9311 obs/sec      7         7             175000     0.269898         0.24409             0.70862        0.964088        0.929708           2.0028           0.0988233                        0.256413           0.223383              0.736966         0.970241          0.936002             2.02591            0.0888781
    2019-08-03 17:08:09  1:01:26.448  9436 obs/sec      9         9             225000     0.264855         0.235731            0.719407       0.966266        0.91708            2.0028           0.0960311                        0.249733           0.213068              0.750493         0.97239           0.922851             2.02591            0.08305
    2019-08-03 17:08:12  1:01:29.252  9478 obs/sec      10        10            250000     0.262162         0.231312            0.725084       0.967649        0.96218            1.98297          0.094635                         0.247155           0.209291              0.755617         0.973502          0.968255             2.02591            0.0804598
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006708540859148998
C374        0.7459933757781982     0.7459933757781982    0.005004527042062536
C438        0.7344671487808228     0.7344671487808228    0.0049272028772988155
C322        0.6400972604751587     0.6400972604751587    0.004294118625726941
C863        0.6038420796394348     0.6038420796394348    0.0040508992637346515
---         ---                    ---                   ---
C298        0.06048223003745079    0.06048223003745079   0.00040574751145868744
C708        0.059071216732263565   0.059071216732263565  0.0003962816710480361
C764        0.05866805091500282    0.05866805091500282   0.0003935770166899302
C722        0.054415058344602585   0.054415058344602585  0.00036504564225774307
C925        0.04792224243283272    0.04792224243283272   0.0003214883214227022

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_195

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.016901285053807776   0.01659514755010605   0.0         0.006234330158478136   0.1395309567451477  -0.019489483318497463  0.14199519157409668
    3        2        Softmax                 0.0   0.0   0.0019487552581267664  0.000557394465431571  0.0         -0.011022224643966183  0.6807687282562256  -0.039181981422081194  0.14687645435333252


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06799010225098776
RMSE: 0.2607491174500649
LogLoss: 0.23096914154954562
Mean Per-Class Error: 0.08842341397295783
AUC: 0.9677292024736155
pr_auc: 0.9620680232691096
Gini: 0.935458404947231
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5492704242143855: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4606  445   0.0881   (445.0/5051.0)
1      440   4518  0.0887   (440.0/4958.0)
Total  5046  4963  0.0884   (885.0/10009.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.54927      0.910795  194
max f2                       0.176866     0.934156  299
max f0point5                 0.756795     0.922448  132
max accuracy                 0.54927      0.91158   194
max precision                0.992624     1         0
max recall                   0.00990541   1         393
max specificity              0.992624     1         0
max absolute_mcc             0.54927      0.823146  194
max min_per_class_accuracy   0.54927      0.911255  194
max mean_per_class_accuracy  0.54927      0.911577  194
Gains/Lift Table: Avg response rate: 49.54 %, avg score: 49.67 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100909                   0.988189           1.97878     1.97878            0.980198         0.990088    0.980198                    0.990088            0.0199677       0.0199677                  97.8782   97.8782
    2        0.0200819                   0.98607            2.01876     1.99867            1                0.987085    0.99005                     0.988594            0.0201694       0.0401372                  101.876   99.867
    3        0.0300729                   0.984387           1.99857     1.99864            0.99             0.98532     0.990033                    0.987506            0.0199677       0.0601049                  99.857    99.8637
    4        0.0400639                   0.983059           2.01876     2.00365            1                0.983636    0.992519                    0.986541            0.0201694       0.0802743                  101.876   100.365
    5        0.050055                    0.982985           2.01876     2.00667            1                0.98304     0.994012                    0.985842            0.0201694       0.100444                   101.876   100.667
    6        0.10001                     0.978511           2.00665     2.00666            0.994            0.981114    0.994006                    0.98348             0.100242        0.200686                   100.665   100.666
    7        0.150065                    0.973623           2.0107      2.00801            0.996008         0.975799    0.994674                    0.980918            0.100645        0.301331                   101.07    100.801
    8        0.20002                     0.96708            1.97838     2.00061            0.98             0.970771    0.991009                    0.978384            0.0988302       0.400161                   97.8382   100.061
    9        0.30003                     0.94167            1.94212     1.98111            0.962038         0.956039    0.981352                    0.970936            0.194232        0.594393                   94.2121   98.1112
    10       0.40004                     0.849671           1.80095     1.93607            0.892108         0.904934    0.959041                    0.954435            0.180113        0.774506                   80.095    93.6071
    11       0.50005                     0.52181            1.3976      1.82838            0.692308         0.712931    0.905694                    0.906135            0.139774        0.91428                    39.7601   82.8377
    12       0.59996                     0.143101           0.58544     1.62139            0.29             0.303451    0.803164                    0.805771            0.0584913       0.972771                   -41.456   62.1393
    13       0.69997                     0.0402196          0.19159     1.41711            0.0949051        0.0797777   0.70197                     0.702043            0.019161        0.991932                   -80.841   41.7107
    14       0.79998                     0.0195624          0.0524353   1.2465             0.025974         0.0276281   0.61746                     0.61773             0.00524405      0.997176                   -94.7565  24.6501
    15       0.89999                     0.0127021          0.0242009   1.11068            0.011988         0.015631    0.550178                    0.550823            0.00242033      0.999597                   -97.5799  11.0675
    16       1                           0.00352712         0.00403348  1                  0.001998         0.00983196  0.495354                    0.496719            0.000403388     1                          -99.5967  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06107303833108452
RMSE: 0.2471295982497534
LogLoss: 0.2119579670178106
Mean Per-Class Error: 0.08049985362690715
AUC: 0.9724011750949327
pr_auc: 0.9667964607000911
Gini: 0.9448023501898655
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5314075902718869: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2886  242   0.0774   (242.0/3128.0)
1      255   2794  0.0836   (255.0/3049.0)
Total  3141  3036  0.0805   (497.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.531408     0.918324  191
max f2                       0.242613     0.940537  273
max f0point5                 0.757762     0.931686  129
max accuracy                 0.533745     0.91954   190
max precision                0.992394     1         0
max recall                   0.0124538    1         389
max specificity              0.992394     1         0
max absolute_mcc             0.533745     0.839054  190
max min_per_class_accuracy   0.512863     0.918478  196
max mean_per_class_accuracy  0.531408     0.9195    191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.29 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.988404           2.02591     2.02591            1                0.990137    1                           0.990137            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.985925           1.99323     2.00957            0.983871         0.987091    0.991935                    0.988614            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.984326           2.02591     2.01502            1                0.985169    0.994624                    0.987466            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.983056           2.02591     2.01774            1                0.983533    0.995968                    0.986482            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.982917           2.02591     2.01935            1                0.983016    0.996764                    0.985798            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.978001           2.0128      2.01608            0.993528         0.980781    0.995146                    0.98329             0.100689        0.201705                   101.28    101.608
    7        0.150073                    0.973496           2.00624     2.0128             0.990291         0.975595    0.993528                    0.980725            0.100361        0.302066                   100.624   101.28
    8        0.200097                    0.966693           1.98657     2.00624            0.980583         0.970423    0.990291                    0.978149            0.0993768       0.401443                   98.6572   100.624
    9        0.299984                    0.942618           1.96024     1.99092            0.967585         0.956267    0.982731                    0.970863            0.195802        0.597245                   96.024    99.0924
    10       0.400032                    0.856323           1.87839     1.96278            0.927184         0.9075      0.968839                    0.955016            0.18793         0.785175                   87.8392   96.278
    11       0.500081                    0.490466           1.38667     1.84752            0.684466         0.703719    0.911946                    0.90474             0.138734        0.923909                   38.6667   84.752
    12       0.599968                    0.127128           0.545058    1.63068            0.269044         0.27967     0.804911                    0.800674            0.0544441       0.978354                   -45.4942  63.0677
    13       0.700016                    0.0389087          0.134405    1.41683            0.066343         0.0725925   0.699352                    0.696614            0.013447        0.991801                   -86.5595  41.6825
    14       0.799903                    0.019406           0.0591027   1.24728            0.0291734        0.0268693   0.615665                    0.612981            0.00590357      0.997704                   -94.0897  24.7282
    15       0.899951                    0.0127778          0.0163909   1.11044            0.00809061       0.015669    0.54812                     0.546577            0.00163988      0.999344                   -98.3609  11.0442
    16       1                           0.00370765         0.00655634  1                  0.00323625       0.00993215  0.493605                    0.492887            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:06:39  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:06:42  4:00:00.109  8771 obs/sec      1         1             25000      0.297791         0.291075            0.645251       0.948428        0.937992           2.01876          0.121191                         0.285709           0.271186              0.673427         0.9558            0.945752             2.02591            0.110733
    2019-08-03 20:06:48  4:00:06.032  8825 obs/sec      3         3             75000      0.284154         0.267962            0.676997       0.956524        0.945951           1.99877          0.110001                         0.270399           0.246832              0.707489         0.963018          0.951532             1.99323            0.0976202
    2019-08-03 20:06:54  4:00:11.780  8949 obs/sec      5         5             125000     0.276482         0.256343            0.694205       0.960368        0.945599           2.01876          0.105705                         0.263902           0.237844              0.721376         0.965729          0.951015             2.02591            0.0926016
    2019-08-03 20:07:00  4:00:17.770  8914 obs/sec      7         7             175000     0.271514         0.248151            0.705096       0.96266         0.93889            1.99877          0.10041                          0.258605           0.229619              0.732449         0.967607          0.945405             1.99323            0.0896876
    2019-08-03 20:07:06  4:00:23.755  8904 obs/sec      9         9             225000     0.264023         0.235184            0.721144       0.967137        0.959916           2.01876          0.0936157                        0.252113           0.218577              0.745714         0.971204          0.965901             1.99323            0.0858022
    2019-08-03 20:07:09  4:00:26.770  8941 obs/sec      10        10            250000     0.260749         0.230969            0.728016       0.967729        0.962068           1.97878          0.0884204                        0.24713            0.211958              0.755668         0.972401          0.966796             2.02591            0.0804598
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006325384759230681
C438        0.8112564086914062     0.8112564086914062    0.005131508923364838
C374        0.7346681356430054     0.7346681356430054    0.004647058628288685
C322        0.6478074193000793     0.6478074193000793    0.004097631176957281
C863        0.6477466225624084     0.6477466225624084    0.004097246614199407
---         ---                    ---                   ---
C835        0.06410042196512222    0.06410042196512222   0.0004054598321584397
C896        0.06042589992284775    0.06042589992284775   0.0003822170664347795
C774        0.05919402465224266    0.05919402465224266   0.00037442498137282094
C801        0.058444712311029434   0.058444712311029434  0.00036968529250980736
C921        0.0548660047352314     0.0548660047352314    0.0003470485901521111

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_163

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.016731946950012015  0.0171356201171875     0.0         -0.02470280376991607  0.14949572086334229  0.04500731037549246  0.12687593698501587
    3        2        Softmax                 0.0   0.0   0.002102010308590252  0.0006557777523994446  0.0         -0.08778142201481387  0.7716512680053711   -0.0344673596670636  0.09819889068603516


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06696590059510855
RMSE: 0.25877770498075864
LogLoss: 0.22935783989877284
Mean Per-Class Error: 0.08855168213160114
AUC: 0.9675397660060437
pr_auc: 0.9589612567833704
Gini: 0.9350795320120875
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45995477173236154: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4510  508   0.1012   (508.0/5018.0)
1      383   4615  0.0766   (383.0/4998.0)
Total  4893  5123  0.089    (891.0/10016.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.459955     0.911965  217
max f2                       0.210563     0.935122  291
max f0point5                 0.8008       0.92373   116
max accuracy                 0.506279     0.911442  205
max precision                0.994285     1         0
max recall                   0.0053848    1         397
max specificity              0.994285     1         0
max absolute_mcc             0.506279     0.822905  205
max min_per_class_accuracy   0.520918     0.910522  201
max mean_per_class_accuracy  0.506279     0.911448  205
Gains/Lift Table: Avg response rate: 49.90 %, avg score: 49.77 %

    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100839                   0.99306            1.98416   1.98416            0.990099         0.993601    0.990099                    0.993601            0.020008        0.020008                   98.416    98.416
    2        0.0200679                   0.992478           1.98396   1.98406            0.99             0.992756    0.99005                     0.993181            0.0198079       0.0398159                  98.3962   98.4061
    3        0.0300519                   0.992074           1.98396   1.98403            0.99             0.992219    0.990033                    0.992861            0.0198079       0.0596238                  98.3962   98.4028
    4        0.0400359                   0.991874           2.004     1.98901            1                0.992015    0.992519                    0.99265             0.020008        0.0796319                  100.4     98.9009
    5        0.05002                     0.990944           1.96392   1.984              0.98             0.991452    0.99002                     0.992411            0.0196078       0.0992397                  96.3922   98.4002
    6        0.10004                     0.983064           1.984     1.984              0.99002          0.987075    0.99002                     0.989743            0.0992397       0.198479                   98.4002   98.4002
    7        0.15006                     0.97635            2         1.98933            0.998004         0.97979     0.992681                    0.986425            0.10004         0.298519                   100       98.9335
    8        0.20008                     0.96745            1.968     1.984              0.982036         0.97222     0.99002                     0.982874            0.0984394       0.396959                   96.8002   98.4002
    9        0.30002                     0.936363           1.94795   1.97199            0.972028         0.954304    0.984027                    0.973357            0.194678        0.591637                   94.7946   97.1991
    10       0.40006                     0.848315           1.802     1.92948            0.899202         0.902471    0.962815                    0.955631            0.180272        0.771909                   80.2001   92.9483
    11       0.5                         0.51789            1.4014    1.82393            0.699301         0.710517    0.910144                    0.906638            0.140056        0.911965                   40.14     82.393
    12       0.60004                     0.155239           0.588     1.61787            0.293413         0.306318    0.807321                    0.806551            0.0588235       0.970788                   -41.2     61.7873
    13       0.69998                     0.0458714          0.19019   1.41403            0.0949051        0.0857913   0.705605                    0.703644            0.0190076       0.989796                   -80.981   41.4035
    14       0.80002                     0.0208705          0.056     1.24422            0.0279441        0.0310663   0.620866                    0.61954             0.00560224      0.995398                   -94.4     24.4217
    15       0.89996                     0.00953821         0.032032  1.1096             0.015984         0.0145699   0.553694                    0.552359            0.00320128      0.998599                   -96.7968  10.9604
    16       1                           0.00310703         0.014     1                  0.00698603       0.00613267  0.499002                    0.497714            0.00140056      1                          -98.6     0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.061081450308233795
RMSE: 0.2471466170276943
LogLoss: 0.21207360758800545
Mean Per-Class Error: 0.07936682523052707
AUC: 0.9720251765913774
pr_auc: 0.9601844770378972
Gini: 0.9440503531827549
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46026338358707264: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2850  278   0.0889   (278.0/3128.0)
1      213   2836  0.0699   (213.0/3049.0)
Total  3063  3114  0.0795   (491.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.460263     0.920331  216
max f2                       0.24874      0.940179  276
max f0point5                 0.708772     0.929646  148
max accuracy                 0.460263     0.920512  216
max precision                0.994188     1         0
max recall                   0.00589778   1         396
max specificity              0.994188     1         0
max absolute_mcc             0.460263     0.841226  216
max min_per_class_accuracy   0.512241     0.91899   203
max mean_per_class_accuracy  0.460263     0.920633  216
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.27 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.993054           2.02591     2.02591            1                0.993717    1                           0.993717            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.992413           2.02591     2.02591            1                0.992718    1                           0.993217            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.992046           2.02591     2.02591            1                0.99215     1                           0.992861            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.991814           2.02591     2.02591            1                0.991982    1                           0.992642            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.99045            2.02591     2.02591            1                0.991187    1                           0.992354            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.98365            2.00624     2.01608            0.990291         0.987029    0.995146                    0.989692            0.100361        0.201705                   100.624   101.608
    7        0.150073                    0.976491           2.0128      2.01498            0.993528         0.980207    0.994606                    0.98653             0.100689        0.302394                   101.28    101.498
    8        0.200097                    0.967899           1.98657     2.00788            0.980583         0.972596    0.9911                      0.983047            0.0993768       0.401771                   98.6572   100.788
    9        0.299984                    0.938384           1.96352     1.99311            0.969206         0.954867    0.98381                     0.973663            0.19613         0.597901                   96.3524   99.3111
    10       0.400032                    0.847204           1.84233     1.9554             0.909385         0.901623    0.965196                    0.955646            0.184323        0.782224                   84.2333   95.5401
    11       0.500081                    0.478693           1.42928     1.85014            0.705502         0.702326    0.913241                    0.904966            0.142998        0.925221                   42.9283   85.0143
    12       0.599968                    0.131571           0.525358    1.62958            0.259319         0.279839    0.804371                    0.80089             0.0524762       0.977698                   -47.4642  62.9584
    13       0.700016                    0.0411822          0.140961    1.41683            0.0695793        0.0743364   0.699352                    0.697049            0.014103        0.991801                   -85.9039  41.6825
    14       0.799903                    0.018668           0.0525358   1.24646            0.0259319        0.0279638   0.61526                     0.613498            0.00524762      0.997048                   -94.7464  24.6462
    15       0.899951                    0.008794           0.0262254   1.11081            0.012945         0.0135868   0.5483                      0.546805            0.00262381      0.999672                   -97.3775  11.0807
    16       1                           0.00298309         0.00327817  1                  0.00161812       0.00585918  0.493605                    0.492684            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:14:21  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:14:24  3:07:41.304  8912 obs/sec      1         1             25000      0.301671         0.300187            0.635976       0.945492        0.922386           2.004            0.1252                           0.289816           0.278588              0.663972         0.95356           0.936407             2.02591            0.112676
    2019-08-03 19:14:29  3:07:47.066  9077 obs/sec      3         3             75000      0.281641         0.265681            0.682712       0.956991        0.943307           2.004            0.10613                          0.26932            0.246276              0.70982          0.963259          0.948597             2.02591            0.0974583
    2019-08-03 19:14:35  3:07:52.794  9149 obs/sec      5         5             125000     0.274385         0.253125            0.698851       0.960783        0.917177           2.004            0.102536                         0.261968           0.233074              0.725446         0.966821          0.930119             2.02591            0.0937348
    2019-08-03 19:14:41  3:07:58.543  9179 obs/sec      7         7             175000     0.267694         0.243126            0.71336        0.963805        0.946297           1.96432          0.0960463                        0.255641           0.224103              0.738548         0.969299          0.954829             2.02591            0.0872592
    2019-08-03 19:14:47  3:08:04.252  9202 obs/sec      9         9             225000     0.263304         0.23644             0.722683       0.965585        0.947972           1.98416          0.0930511                        0.251662           0.218737              0.746623         0.970519          0.954898             2.02591            0.0819168
    2019-08-03 19:14:49  3:08:07.150  9250 obs/sec      10        10            250000     0.258778         0.229358            0.732135       0.96754         0.958961           1.98416          0.0889577                        0.247147           0.212074              0.755634         0.972025          0.960184             2.02591            0.0794884
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006573877300113787
C438        0.7999587655067444     0.7999587655067444    0.005258830769591835
C374        0.7411682605743408     0.7411682605743408    0.004872349203754479
C88         0.662548840045929      0.662548840045929     0.004355514779794653
C322        0.6526046991348267     0.6526046991348267    0.004290143217590025
---         ---                    ---                   ---
C829        0.06457722187042236    0.06457722187042236   0.00042452273295838115
C880        0.061306554824113846   0.061306554824113846  0.0004030217691064234
C981        0.06034334376454353    0.06034334376454353   0.0003966897377866956
C547        0.05517067015171051    0.05517067015171051   0.000362685216142395
C828        0.05178813636302948    0.05178813636302948   0.0003404488540521169

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_152

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.021387593343800346  0.02656971663236618    0.0         -0.005577800353450403  0.15391790866851807  -0.015228871467593854  0.16092252731323242
    3        2        Softmax                 0.0   0.0   0.001921755880175624  0.0005516598466783762  0.0         -0.08760379267550888   0.7001307010650635   0.0004388405758822961  0.13841503858566284


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06360591525569982
RMSE: 0.25220213174297285
LogLoss: 0.21794370161355922
Mean Per-Class Error: 0.0828117307827555
AUC: 0.9707172375948059
pr_auc: 0.9207939769696044
Gini: 0.9414344751896118
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5549898317650744: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4551  405   0.0817   (405.0/4956.0)
1      427   4634  0.0844   (427.0/5061.0)
Total  4978  5039  0.0831   (832.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.55499      0.917624  187
max f2                       0.280099     0.939892  267
max f0point5                 0.781843     0.926365  119
max accuracy                 0.569697     0.917141  183
max precision                0.992754     1         0
max recall                   0.00422193   1         399
max specificity              0.992754     1         0
max absolute_mcc             0.569697     0.834331  183
max min_per_class_accuracy   0.552425     0.916222  188
max mean_per_class_accuracy  0.569697     0.917188  183
Gains/Lift Table: Avg response rate: 50.52 %, avg score: 50.67 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   0.992815           1.97925     1.97925            1                0.992821    1                           0.992821            0.0199565       0.0199565                  97.9253   97.9253
    2        0.0200659                   0.992705           1.97925     1.97925            1                0.992772    1                           0.992797            0.0197589       0.0397155                  97.9253   97.9253
    3        0.0300489                   0.992216           1.97925     1.97925            1                0.992491    1                           0.992695            0.0197589       0.0594744                  97.9253   97.9253
    4        0.0400319                   0.9913             1.97925     1.97925            1                0.991797    1                           0.992471            0.0197589       0.0792334                  97.9253   97.9253
    5        0.050015                    0.990247           1.97925     1.97925            1                0.9908      1                           0.992138            0.0197589       0.0989923                  97.9253   97.9253
    6        0.10003                     0.985684           1.96345     1.97135            0.992016         0.987933    0.996008                    0.990035            0.0982019       0.197194                   96.3451   97.1352
    7        0.150045                    0.979333           1.95555     1.96608            0.988024         0.982604    0.993347                    0.987558            0.0978068       0.295001                   95.5549   96.6084
    8        0.20006                     0.97327            1.94765     1.96148            0.984032         0.976984    0.991018                    0.984915            0.0974116       0.392413                   94.7648   96.1475
    9        0.29999                     0.947024           1.91993     1.94764            0.97003          0.962228    0.984027                    0.977357            0.191859        0.584272                   91.9935   94.7638
    10       0.40002                     0.864436           1.81728     1.91504            0.918164         0.915214    0.967557                    0.961818            0.181782        0.766054                   81.7278   91.504
    11       0.50005                     0.567123           1.46567     1.82515            0.740519         0.742955    0.92214                     0.918037            0.146611        0.912665                   46.5674   82.5149
    12       0.59998                     0.162327           0.607024    1.62226            0.306693         0.343789    0.819634                    0.822392            0.0606599       0.973325                   -39.2976  62.2263
    13       0.70001                     0.0449177          0.173827    1.41528            0.0878244        0.0902573   0.71506                     0.717772            0.0173879       0.990713                   -82.6173  41.5285
    14       0.79994                     0.0152963          0.0652501   1.24664            0.032967         0.0264937   0.629851                    0.631416            0.00652045      0.997234                   -93.475   24.6636
    15       0.89997                     0.00708321         0.0217283   1.11049            0.010978         0.0108764   0.561065                    0.562444            0.00217348      0.999407                   -97.8272  11.0489
    16       1                           0.00409543         0.00592591  1                  0.00299401       0.00524192  0.505241                    0.506707            0.000592768     1                          -99.4074  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06255399770248078
RMSE: 0.2501079720890175
LogLoss: 0.21516155184851649
Mean Per-Class Error: 0.08121378943580515
AUC: 0.9713499310914064
pr_auc: 0.9209748587552167
Gini: 0.9426998621828129
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5835669098717259: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2900  228   0.0729   (228.0/3128.0)
1      273   2776  0.0895   (273.0/3049.0)
Total  3173  3004  0.0811   (501.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.583567     0.917231  181
max f2                       0.20996      0.93909   289
max f0point5                 0.789053     0.928346  118
max accuracy                 0.594528     0.918893  178
max precision                0.992739     1         0
max recall                   0.00419532   1         399
max specificity              0.992739     1         0
max absolute_mcc             0.594528     0.837863  178
max min_per_class_accuracy   0.546703     0.916694  192
max mean_per_class_accuracy  0.583567     0.918786  181
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.77 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.992801           2.02591     2.02591            1                0.992818    1                           0.992818            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.992648           2.02591     2.02591            1                0.992735    1                           0.992777            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.991941           2.02591     2.02591            1                0.992371    1                           0.992641            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.991081           2.02591     2.02591            1                0.991458    1                           0.992345            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.98996            1.9927      2.01935            0.983607         0.990481    0.996764                    0.991977            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.985803           1.99313     2.00624            0.983819         0.987839    0.990291                    0.989908            0.0997048       0.200722                   99.3128   100.624
    7        0.150073                    0.978983           2.01935     2.01061            0.996764         0.982456    0.992449                    0.987424            0.101017        0.301738                   101.935   101.061
    8        0.200097                    0.972755           1.98002     2.00296            0.977346         0.976402    0.988673                    0.984669            0.0990489       0.400787                   98.0016   100.296
    9        0.299984                    0.943407           1.96024     1.98874            0.967585         0.960373    0.981651                    0.976579            0.195802        0.596589                   96.024    98.8737
    10       0.400032                    0.854362           1.87839     1.96114            0.927184         0.908804    0.968029                    0.959628            0.18793         0.78452                    87.8392   96.114
    11       0.500081                    0.520862           1.37028     1.84293            0.676375         0.712662    0.90968                     0.910219            0.137094        0.921614                   37.0276   84.2929
    12       0.599968                    0.138602           0.538492    1.62576            0.265802         0.305628    0.802482                    0.809563            0.0537881       0.975402                   -46.1508  62.5757
    13       0.700016                    0.0418394          0.154074    1.41542            0.0760518        0.0789717   0.698659                    0.705144            0.0154149       0.990817                   -84.5926  41.542
    14       0.799903                    0.0145536          0.0656697   1.24687            0.0324149        0.025238    0.615462                    0.620242            0.00655953      0.997376                   -93.433   24.6872
    15       0.899951                    0.0070255          0.019669    1.11044            0.00970874       0.0105339   0.54812                     0.55246             0.00196786      0.999344                   -98.0331  11.0442
    16       1                           0.00409543         0.00655634  1                  0.00323625       0.00517948  0.493605                    0.497705            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:00:13  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:00:16  2:53:33.378  9541 obs/sec      1         1             25000      0.290006         0.280517            0.66355        0.952089        0.936155           1.95966          0.114106                         0.288814           0.277283              0.666292         0.953218          0.939125             2.02591            0.112676
    2019-08-03 19:00:22  2:53:39.302  9066 obs/sec      3         3             75000      0.273849         0.253277            0.699995       0.961049        0.941749           1.97925          0.101927                         0.270147           0.247363              0.708034         0.963232          0.944586             2.02591            0.0998867
    2019-08-03 19:00:28  2:53:45.239  9002 obs/sec      5         5             125000     0.264681         0.23864             0.719746       0.965492        0.94326            1.97925          0.0933413                        0.261478           0.234113              0.726473         0.966982          0.9426               2.02591            0.0914684
    2019-08-03 19:00:33  2:53:51.159  8999 obs/sec      7         7             175000     0.259494         0.229027            0.730621       0.968071        0.936372           1.97925          0.0891484                        0.25733            0.225824              0.735082         0.968967          0.941753             2.02591            0.0877449
    2019-08-03 19:00:39  2:53:56.788  9088 obs/sec      9         9             225000     0.252824         0.218816            0.744291       0.970371        0.92776            1.97925          0.0837576                        0.250531           0.215775              0.748897         0.971133          0.913609             2.02591            0.0824025
    2019-08-03 19:00:42  2:53:59.871  9081 obs/sec      10        10            250000     0.252202         0.217944            0.745548       0.970717        0.920794           1.97925          0.0830588                        0.250108           0.215162              0.749743         0.97135           0.920975             2.02591            0.0811073
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007124850011930028
C438        0.754494309425354      0.754494309425354     0.005375658789510372
C374        0.7233860492706299     0.7233860492706299    0.005154017101775863
C322        0.7046955823898315     0.7046955823898315    0.00502085032859723
C88         0.6664991974830627     0.6664991974830627    0.004748706815138554
---         ---                    ---                   ---
C681        0.049676645547151566   0.049676645547151566  0.0003539386486192666
C540        0.04738128185272217    0.04738128185272217   0.00033758452657362757
C972        0.046741094440221786   0.046741094440221786  0.0003330232872800368
C712        0.046722348779439926   0.046722348779439926  0.0003328897272585915
C969        0.040460094809532166   0.040460094809532166  0.00028827210698638536

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_18

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.015506988124193134   0.015196103602647781   0.0         -0.019315622714519143  0.13496917486190796  0.03238810430747081  0.16259169578552246
    3        2        Softmax                 0.0   0.0   0.0021789550155517645  0.0006986036896705627  0.0         0.10694988409522921    0.7009942531585693   0.00799636182713371  0.12576311826705933


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06793855194031674
RMSE: 0.26065024830281047
LogLoss: 0.23096683970041004
Mean Per-Class Error: 0.09007977976132253
AUC: 0.9673017729281904
pr_auc: 0.9548535151197909
Gini: 0.9346035458563808
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5048042636524298: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4448  531   0.1066   (531.0/4979.0)
1      384   4669  0.076    (384.0/5053.0)
Total  4832  5200  0.0912   (915.0/10032.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.504804     0.910758  204
max f2                       0.205991     0.937847  287
max f0point5                 0.797889     0.921372  115
max accuracy                 0.591847     0.909888  178
max precision                0.994632     1         0
max recall                   0.00475251   1         397
max specificity              0.994632     1         0
max absolute_mcc             0.591847     0.819821  178
max min_per_class_accuracy   0.571565     0.90962   183
max mean_per_class_accuracy  0.591847     0.90992   178
Gains/Lift Table: Avg response rate: 50.37 %, avg score: 51.04 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100678                   0.993366           1.98536     1.98536            1                0.994159   1                           0.994159            0.0199881       0.0199881                  98.5355   98.5355
    2        0.0200359                   0.99255            1.98536     1.98536            1                0.99305    1                           0.993607            0.0197902       0.0397783                  98.5355   98.5355
    3        0.030004                    0.991273           1.98536     1.98536            1                0.991934   1                           0.993051            0.0197902       0.0595686                  98.5355   98.5355
    4        0.0400718                   0.989837           1.98536     1.98536            1                0.990582   1                           0.992431            0.0199881       0.0795567                  98.5355   98.5355
    5        0.0500399                   0.988767           1.94565     1.97745            0.98             0.989349   0.996016                    0.991817            0.0193944       0.0989511                  94.5648   97.7445
    6        0.10008                     0.983063           1.96954     1.97349            0.992032         0.985943   0.994024                    0.98888             0.0985553       0.197506                   96.9536   97.3491
    7        0.15002                     0.977595           1.9695      1.97216            0.992016         0.980024   0.993355                    0.985932            0.0983574       0.295864                   96.9504   97.2164
    8        0.20006                     0.971983           1.95767     1.96854            0.986056         0.974475   0.99153                     0.983066            0.0979616       0.393825                   95.7671   96.8539
    9        0.30004                     0.94701            1.91014     1.94908            0.962114         0.961161   0.981728                    0.975767            0.190976        0.584801                   91.0137   94.9078
    10       0.40002                     0.868328           1.78543     1.90818            0.899302         0.915704   0.961126                    0.960755            0.178508        0.763309                   78.5434   90.8177
    11       0.5                         0.584247           1.4331      1.81318            0.721834         0.754203   0.913278                    0.919453            0.143281        0.90659                    43.3098   81.318
    12       0.59998                     0.17228            0.659146    1.62087            0.332004         0.36077    0.816415                    0.826355            0.0659014       0.972492                   -34.0854  62.0873
    13       0.69996                     0.0491909          0.178148    1.4148             0.0897308        0.0940375  0.712617                    0.721753            0.0178112       0.990303                   -82.1852  41.4799
    14       0.79994                     0.0200872          0.0673002   1.24638            0.0338983        0.0315729  0.627788                    0.635491            0.00672868      0.997031                   -93.27    24.6383
    15       0.89992                     0.00998323         0.0197942   1.11011            0.00997009       0.0147132  0.559149                    0.566523            0.00197902      0.99901                    -98.0206  11.011
    16       1                           0.00281156         0.00988723  1                  0.00498008       0.006015   0.503688                    0.510428            0.000989511     1                          -99.0113  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06314490308556758
RMSE: 0.2512864960270798
LogLoss: 0.21599984297270003
Mean Per-Class Error: 0.0836454071982009
AUC: 0.9716972526315701
pr_auc: 0.9614525630864774
Gini: 0.9433945052631403
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47887161344507606: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2814  314   0.1004   (314.0/3128.0)
1      204   2845  0.0669   (204.0/3049.0)
Total  3018  3159  0.0839   (518.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.478872     0.916559  209
max f2                       0.224971     0.93994   282
max f0point5                 0.798212     0.929242  118
max accuracy                 0.478872     0.916141  209
max precision                0.990549     0.995575  4
max recall                   0.00472724   1         397
max specificity              0.99464      0.99968   0
max absolute_mcc             0.478872     0.832858  209
max min_per_class_accuracy   0.561482     0.914962  187
max mean_per_class_accuracy  0.478872     0.916355  209
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.18 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.993312           1.99323     1.99323            0.983871         0.993927    0.983871                    0.993927            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.992346           2.02591     2.00957            1                0.992884    0.991935                    0.993406            0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.990951           2.02591     2.01502            1                0.991626    0.994624                    0.992812            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.989768           2.02591     2.01774            1                0.990342    0.995968                    0.992195            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.988613           1.9927      2.0128             0.983607         0.989182    0.993528                    0.9916              0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.982193           2.0128      2.0128             0.993528         0.985568    0.993528                    0.988584            0.100689        0.201378                   101.28    101.28
    7        0.150073                    0.976438           2.01935     2.01498            0.996764         0.979239    0.994606                    0.985469            0.101017        0.302394                   101.935   101.498
    8        0.200097                    0.97054            1.99968     2.01116            0.987055         0.973481    0.992718                    0.982472            0.100033        0.402427                   99.9685   101.116
    9        0.299984                    0.940502           1.96024     1.9942             0.967585         0.957764    0.98435                     0.974245            0.195802        0.598229                   96.024    99.4204
    10       0.400032                    0.854567           1.83905     1.9554             0.907767         0.907488    0.965196                    0.957549            0.183995        0.782224                   83.9054   95.5401
    11       0.500081                    0.53334            1.38667     1.84162            0.684466         0.72991     0.909032                    0.912006            0.138734        0.920958                   38.6667   84.1617
    12       0.599968                    0.153352           0.564759    1.62904            0.278768         0.319679    0.804101                    0.813392            0.0564119       0.97737                    -43.5241  62.9037
    13       0.700016                    0.0466033          0.163909    1.41964            0.0809061        0.0873731   0.70074                     0.709627            0.0163988       0.993768                   -83.6091  41.9636
    14       0.799903                    0.0197256          0.0328348   1.24646            0.0162075        0.0304187   0.61526                     0.624812            0.00327976      0.997048                   -96.7165  24.6462
    15       0.899951                    0.00953529         0.0262254   1.11081            0.012945         0.0141774   0.5483                      0.556927            0.00262381      0.999672                   -97.3775  11.0807
    16       1                           0.00289            0.00327817  1                  0.00161812       0.00574816  0.493605                    0.501782            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:29:30  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:29:32  22 min 50.165 sec  9124 obs/sec      1         1             25000      0.294374         0.287175            0.653358       0.949487        0.937179           1.98536          0.117026                         0.289435           0.277788              0.664855         0.95306           0.938855             2.02591            0.111219
    2019-08-03 16:29:38  22 min 55.934 sec  9089 obs/sec      3         3             75000      0.277555         0.258972            0.691835       0.959379        0.947233           1.98536          0.102771                         0.27035            0.247728              0.707595         0.963484          0.949407             2.02591            0.0971345
    2019-08-03 16:29:44  23 min  1.548 sec  9192 obs/sec      5         5             125000     0.271087         0.24815             0.706032       0.962544        0.934912           1.98536          0.0966906                        0.262208           0.23308               0.724942         0.966966          0.943307             2.02591            0.0893638
    2019-08-03 16:29:49  23 min  7.151 sec  9238 obs/sec      7         7             175000     0.270666         0.246533            0.706944       0.962598        0.935012           1.98536          0.0990829                        0.260728           0.231101              0.72804          0.967121          0.943861             2.02591            0.0913065
    2019-08-03 16:29:55  23 min 12.710 sec  9288 obs/sec      9         9             225000     0.26065          0.230967            0.728231       0.967302        0.954854           1.98536          0.0912081                        0.251286           0.216                 0.747379         0.971697          0.961453             1.99323            0.0838595
    2019-08-03 16:29:58  23 min 15.588 sec  9326 obs/sec      10        10            250000     0.258208         0.227987            0.733299       0.967996        0.963604           1.98536          0.0888158                        0.2497             0.216206              0.750559         0.971353          0.965451             1.99323            0.0806217
    2019-08-03 16:29:58  23 min 15.895 sec  9323 obs/sec      10        10            250000     0.26065          0.230967            0.728231       0.967302        0.954854           1.98536          0.0912081                        0.251286           0.216                 0.747379         0.971697          0.961453             1.99323            0.0838595
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006677173426653954
C438        0.8192046880722046     0.8192046880722046    0.0054699717741860665
C374        0.7698999643325806     0.7698999643325806    0.005140755583023335
C322        0.6538562774658203     0.6538562774658203    0.004365911760745651
C88         0.6380268931388855     0.6380268931388855    0.004260216216357549
---         ---                    ---                   ---
C639        0.060290753841400146   0.060290753841400146  0.0004025718194227319
C784        0.06016434356570244    0.06016434356570244   0.00040172775608898715
C892        0.05674092844128609    0.05674092844128609   0.0003788690195918291
C774        0.054447632282972336   0.054447632282972336  0.00036355628342408885
C941        0.05339377000927925    0.05339377000927925   0.0003565194622548323

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_12

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.02526998171352549    0.05155159533023834     0.0         -0.002245930797809512  0.1482669711112976  0.00513566106946863   0.19409000873565674
    3        2        Softmax                 0.0   0.0   0.0017233818889508257  0.00030574004631489515  0.0         -0.09923138374870177   0.847114086151123   0.002641695792920992  0.14547312259674072


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06669590535875776
RMSE: 0.25825550402413067
LogLoss: 0.2285774030806383
Mean Per-Class Error: 0.08914280469897218
AUC: 0.9682294547107322
pr_auc: 0.962282203169657
Gini: 0.9364589094214644
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4070403388584775: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4454  586   0.1163   (586.0/5040.0)
1      320   4674  0.0641   (320.0/4994.0)
Total  4774  5260  0.0903   (906.0/10034.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.40704      0.911644  227
max f2                       0.208423     0.934939  289
max f0point5                 0.777057     0.924409  119
max accuracy                 0.595632     0.910903  175
max precision                0.992093     1         0
max recall                   0.00571092   1         398
max specificity              0.992093     1         0
max absolute_mcc             0.62836      0.822075  165
max min_per_class_accuracy   0.550927     0.910092  187
max mean_per_class_accuracy  0.595632     0.910857  175
Gains/Lift Table: Avg response rate: 49.77 %, avg score: 49.93 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100658                   0.98984            1.98932    1.98932            0.990099         0.99063     0.990099                    0.99063             0.020024        0.020024                   98.9318   98.9318
    2        0.0200319                   0.989464           2.00921    1.99921            1                0.989712    0.995025                    0.990173            0.020024        0.0400481                  100.921   99.9215
    3        0.029998                    0.988033           2.00921    2.00254            1                0.988916    0.996678                    0.989755            0.020024        0.0600721                  100.921   100.254
    4        0.0400638                   0.985474           1.96942    1.99422            0.980198         0.986758    0.992537                    0.989002            0.0198238       0.0798959                  96.9425   99.4217
    5        0.0500299                   0.983328           1.98912    1.9932             0.99             0.984363    0.992032                    0.988078            0.0198238       0.0997197                  98.9119   99.3201
    6        0.10006                     0.976359           1.9972     1.9952             0.994024         0.979604    0.993028                    0.983841            0.0999199       0.19964                    99.7204   99.5203
    7        0.14999                     0.972193           1.98916    1.99319            0.99002          0.97397     0.992027                    0.980555            0.0993192       0.298959                   98.9159   99.3191
    8        0.20002                     0.965945           1.9852     1.99119            0.988048         0.969155    0.991031                    0.977704            0.0993192       0.398278                   98.5197   99.1191
    9        0.29998                     0.944823           1.94711    1.9765             0.969093         0.957263    0.983721                    0.970892            0.194634        0.592911                   94.7112   97.6503
    10       0.40004                     0.860667           1.79308    1.93062            0.89243          0.912081    0.960887                    0.956182            0.179415        0.772327                   79.3081   93.0625
    11       0.5                         0.535543           1.39823    1.82419            0.695912         0.727232    0.907913                    0.910411            0.139768        0.912095                   39.8235   82.4189
    12       0.59996                     0.14414            0.586938   1.61805            0.292124         0.309844    0.805316                    0.810349            0.0586704       0.970765                   -41.3062  61.8049
    13       0.70002                     0.0411063          0.192116   1.41423            0.0956175        0.0792748   0.703872                    0.705851            0.0192231       0.989988                   -80.7884  41.4228
    14       0.79998                     0.0196668          0.0681088  1.24603            0.0338983        0.0281234   0.620157                    0.621166            0.00680817      0.996796                   -93.1891  24.6026
    15       0.89994                     0.0121434          0.0220352  1.11007            0.0109671        0.0159028   0.552492                    0.553937            0.00220264      0.998999                   -97.7965  11.0072
    16       1                           0.00387642         0.010006   1                  0.00498008       0.00804351  0.497708                    0.499315            0.0010012       1                          -98.9994  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0625182333288946
RMSE: 0.2500364639985428
LogLoss: 0.21605913659523862
Mean Per-Class Error: 0.08172232059649764
AUC: 0.9715462136342552
pr_auc: 0.9647258785993383
Gini: 0.9430924272685104
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5956837583325172: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2904  224   0.0716   (224.0/3128.0)
1      280   2769  0.0918   (280.0/3049.0)
Total  3184  2993  0.0816   (504.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.595684     0.916584  177
max f2                       0.201335     0.938612  289
max f0point5                 0.743627     0.929847  136
max accuracy                 0.595684     0.918407  177
max precision                0.992229     1         0
max recall                   0.00797891   1         395
max specificity              0.992229     1         0
max absolute_mcc             0.595684     0.836887  177
max min_per_class_accuracy   0.55595      0.916038  189
max mean_per_class_accuracy  0.595684     0.918278  177
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.73 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.989838           1.99323     1.99323            0.983871         0.990773    0.983871                    0.990773            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.989538           2.02591     2.00957            1                0.989731    0.991935                    0.990252            0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.98851            2.02591     2.01502            1                0.989069    0.994624                    0.989858            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.986583           2.02591     2.01774            1                0.987516    0.995968                    0.989272            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.984406           2.02591     2.01935            1                0.985469    0.996764                    0.988521            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.977264           2.0128      2.01608            0.993528         0.980739    0.995146                    0.98463             0.100689        0.201705                   101.28    101.608
    7        0.150073                    0.972969           2.0128      2.01498            0.993528         0.974683    0.994606                    0.981314            0.100689        0.302394                   101.28    101.498
    8        0.200097                    0.966262           1.97346     2.0046             0.97411          0.969761    0.989482                    0.978426            0.0987209       0.401115                   97.3459   100.46
    9        0.299984                    0.944199           1.96681     1.99202            0.970827         0.957076    0.98327                     0.971317            0.196458        0.597573                   96.6807   99.2017
    10       0.400032                    0.860607           1.8325      1.95212            0.904531         0.912246    0.963577                    0.956543            0.183339        0.780912                   83.2498   95.2121
    11       0.500081                    0.521497           1.40961     1.84358            0.695793         0.723473    0.910003                    0.909914            0.14103         0.921942                   40.9614   84.3585
    12       0.599968                    0.132268           0.541775    1.62685            0.267423         0.297059    0.803022                    0.807882            0.0541161       0.976058                   -45.8225  62.6851
    13       0.700016                    0.0396636          0.154074    1.41636            0.0760518        0.0744169   0.699121                    0.703053            0.0154149       0.991473                   -84.5926  41.6357
    14       0.799903                    0.0196727          0.0558192   1.24646            0.0275527        0.0277832   0.61526                     0.618729            0.0055756       0.997048                   -94.4181  24.6462
    15       0.899951                    0.0120891          0.0229472   1.11044            0.0113269        0.0158395   0.54812                     0.551705            0.00229583      0.999344                   -97.7053  11.0442
    16       1                           0.00379384         0.00655634  1                  0.00323625       0.00783537  0.493605                    0.497292            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:20:35  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:20:40  13 min 57.304 sec  6248 obs/sec      1         1             25000      0.295747         0.289034            0.650128       0.949385        0.936688           1.98932          0.116006                         0.287361           0.272933              0.66964          0.955524          0.945471             2.02591            0.110571
    2019-08-03 16:20:46  14 min  3.226 sec  7761 obs/sec      3         3             75000      0.280733         0.263928            0.684749       0.957396        0.94483            2.00921          0.104943                         0.272199           0.249813              0.703582         0.962125          0.945299             2.02591            0.0985915
    2019-08-03 16:20:51  14 min  8.994 sec  8251 obs/sec      5         5             125000     0.274501         0.254827            0.69859        0.96014         0.93301            2.00921          0.101455                         0.266037           0.240733              0.71685          0.964625          0.931024             2.02591            0.0951918
    2019-08-03 16:20:57  14 min 14.577 sec  8554 obs/sec      7         7             175000     0.268637         0.246086            0.71133        0.962993        0.948991           1.98932          0.0951764                        0.260462           0.232699              0.728593         0.967186          0.95218              2.02591            0.091954
    2019-08-03 16:21:02  14 min 20.129 sec  8729 obs/sec      9         9             225000     0.263946         0.237096            0.721324       0.965817        0.960875           1.98932          0.0945784                        0.254408           0.222424              0.741064         0.969699          0.961271             1.99323            0.0872592
    2019-08-03 16:21:05  14 min 22.995 sec  8810 obs/sec      10        10            250000     0.258256         0.228577            0.733211       0.968229        0.962282           1.98932          0.090293                         0.250036           0.216059              0.749886         0.971546          0.964726             1.99323            0.081593
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.006130506861599171
C438        0.8570179343223572     0.8570179343223572   0.005253954326876759
C374        0.7194089293479919     0.7194089293479919   0.004410341377663578
C322        0.7017029523849487     0.7017029523849487   0.0043017947644003246
C88         0.6401245594024658     0.6401245594024658   0.003924288003694963
---         ---                    ---                  ---
C968        0.06669140607118607    0.06669140607118607  0.0004088521225291028
C892        0.06563229858875275    0.06563229858875275  0.00040235925684087433
C634        0.06500405073165894    0.06500405073165894  0.00039850777904217575
C925        0.06119149550795555    0.06119149550795555  0.0003751348830830364
C912        0.04254791513085365    0.04254791513085365  0.00026084028565643755

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_90

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.015503657215440956   0.01489231362938881    0.0         0.008601687027300199  0.14388930797576904  -0.05410671552682969    0.15657120943069458
    3        2        Softmax                 0.0   0.0   0.0018779689653456444  0.0005176020786166191  0.0         0.13596384215634316   0.7519903182983398   -0.0011437836884119895  0.14046823978424072


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07000379260749869
RMSE: 0.26458229836385255
LogLoss: 0.23802174053018305
Mean Per-Class Error: 0.09333478733894762
AUC: 0.9652617914298702
pr_auc: 0.9627649745120319
Gini: 0.9305235828597405
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4450579249685642: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4465  553   0.1102   (553.0/5018.0)
1      384   4625  0.0767   (384.0/5009.0)
Total  4849  5178  0.0934   (937.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.445058     0.90802   218
max f2                       0.164079     0.933215  301
max f0point5                 0.709569     0.919375  143
max accuracy                 0.456367     0.906652  215
max precision                0.993556     1         0
max recall                   0.00513603   1         398
max specificity              0.993556     1         0
max absolute_mcc             0.456367     0.813663  215
max min_per_class_accuracy   0.525168     0.905969  195
max mean_per_class_accuracy  0.456367     0.906665  215
Gains/Lift Table: Avg response rate: 49.96 %, avg score: 49.80 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   0.990877           2.0018     2.0018             1                0.991895    1                           0.991895            0.0201637       0.0201637                  100.18    100.18
    2        0.0200459                   0.98975            2.0018     2.0018             1                0.990326    1                           0.991115            0.0199641       0.0401278                  100.18    100.18
    3        0.0300189                   0.988884           2.0018     2.0018             1                0.989295    1                           0.99051             0.0199641       0.0600918                  100.18    100.18
    4        0.0400918                   0.988571           2.0018     2.0018             1                0.98866     1                           0.990045            0.0201637       0.0802555                  100.18    100.18
    5        0.0500648                   0.988311           2.0018     2.0018             1                0.988486    1                           0.989735            0.0199641       0.10022                    100.18    100.18
    6        0.10003                     0.983754           1.97782    1.98982            0.988024         0.986071    0.994018                    0.987905            0.0988221       0.199042                   97.7823   98.9822
    7        0.149995                    0.9788             2.0018     1.99381            1                0.981242    0.996011                    0.985685            0.10002         0.299062                   100.18    99.3811
    8        0.20006                     0.972015           1.96591    1.98683            0.982072         0.975734    0.992522                    0.983195            0.0984228       0.397485                   96.5908   98.6828
    9        0.29999                     0.943269           1.9119     1.96187            0.95509          0.959681    0.980053                    0.975362            0.191056        0.588541                   91.1896   96.1867
    10       0.40002                     0.84517            1.78425    1.91745            0.891326         0.90431     0.957866                    0.957595            0.178479        0.767019                   78.4254   91.7453
    11       0.50005                     0.521884           1.39707    1.81335            0.697906         0.710298    0.905864                    0.908125            0.139748        0.906768                   39.7067   81.3355
    12       0.59998                     0.145838           0.637299   1.61748            0.318363         0.309016    0.808012                    0.80834             0.0636854       0.970453                   -36.2701  61.7476
    13       0.70001                     0.0441832          0.18561    1.41287            0.0927218        0.0844517   0.705799                    0.704898            0.0185666       0.98902                    -81.439   41.2865
    14       0.79994                     0.0162071          0.0619318  1.2441             0.0309381        0.0273018   0.621494                    0.620251            0.00618886      0.995209                   -93.8068  24.4104
    15       0.89997                     0.00841153         0.0319329  1.10937            0.0159521        0.0116689   0.554189                    0.552609            0.00319425      0.998403                   -96.8067  10.9373
    16       1                           0.00266512         0.0159665  1                  0.00797607       0.00656119  0.499551                    0.497988            0.00159713      1                          -98.4034  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06323868777579561
RMSE: 0.2514730358821709
LogLoss: 0.2166027770120485
Mean Per-Class Error: 0.08360981001695245
AUC: 0.9713237705708718
pr_auc: 0.967390677875174
Gini: 0.9426475411417437
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.40435222160144974: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2780  348   0.1113   (348.0/3128.0)
1      178   2871  0.0584   (178.0/3049.0)
Total  2958  3219  0.0852   (526.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.404352     0.916082  226
max f2                       0.257963     0.93786   269
max f0point5                 0.799368     0.929741  114
max accuracy                 0.494131     0.916302  202
max precision                0.993365     1         0
max recall                   0.00747184   1         394
max specificity              0.993365     1         0
max absolute_mcc             0.494131     0.832716  202
max min_per_class_accuracy   0.531523     0.914003  194
max mean_per_class_accuracy  0.494131     0.91639   202
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.56 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.990967           2.02591     2.02591            1                0.992057    1                           0.992057            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.989956           2.02591     2.02591            1                0.990486    1                           0.991272            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.988816           2.02591     2.02591            1                0.989351    1                           0.990632            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.98857            2.02591     2.02591            1                0.988649    1                           0.990136            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.988284           2.02591     2.02591            1                0.988473    1                           0.989808            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.98399            2.00624     2.01608            0.990291         0.98617     0.995146                    0.987989            0.100361        0.201705                   100.624   101.608
    7        0.150073                    0.978944           2.01935     2.01717            0.996764         0.981421    0.995685                    0.9858              0.101017        0.302722                   101.935   101.717
    8        0.200097                    0.972393           1.99968     2.0128             0.987055         0.975883    0.993528                    0.98332             0.100033        0.402755                   99.9685   101.28
    9        0.299984                    0.944467           1.95696     1.9942             0.965964         0.960824    0.98435                     0.97583             0.195474        0.598229                   95.6957   99.4204
    10       0.400032                    0.84893            1.85217     1.95868            0.914239         0.905728    0.966815                    0.958297            0.185307        0.783536                   85.2167   95.868
    11       0.500081                    0.502643           1.37683     1.84227            0.679612         0.708166    0.909356                    0.908255            0.13775         0.921286                   37.6832   84.2273
    12       0.599968                    0.137668           0.551625    1.6274             0.272285         0.292332    0.803292                    0.805712            0.0551          0.976386                   -44.8375  62.7397
    13       0.700016                    0.0423056          0.14424     1.41542            0.0711974        0.077766    0.698659                    0.701671            0.014431        0.990817                   -85.576   41.542
    14       0.799903                    0.0157821          0.0591027   1.24605            0.0291734        0.0262103   0.615058                    0.617324            0.00590357      0.99672                    -94.0897  24.6052
    15       0.899951                    0.00822691         0.0295035   1.11081            0.0145631        0.0113698   0.5483                      0.54996             0.00295179      0.999672                   -97.0496  11.0807
    16       1                           0.00340031         0.00327817  1                  0.00161812       0.00645557  0.493605                    0.495583            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:47:39  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:47:42  1:40:59.615  9416 obs/sec      1         1             25000      0.298838         0.294573            0.642783       0.947018        0.929218           2.0018           0.123666                         0.286306           0.272025              0.672061         0.955434          0.938895             2.02591            0.110733
    2019-08-03 17:47:48  1:41:05.454  9116 obs/sec      3         3             75000      0.283148         0.268052            0.679308       0.956256        0.948377           2.0018           0.107609                         0.269831           0.246969              0.708716         0.963322          0.957854             2.02591            0.0958394
    2019-08-03 17:47:54  1:41:11.426  9007 obs/sec      5         5             125000     0.275566         0.255322            0.696254       0.96015         0.928524           2.0018           0.103321                         0.261702           0.232902              0.726004         0.967264          0.92735              2.02591            0.0914684
    2019-08-03 17:48:00  1:41:17.293  9005 obs/sec      7         7             175000     0.269703         0.246516            0.70904        0.962859        0.961305           2.0018           0.098534                         0.257552           0.226836              0.734624         0.9692            0.966667             2.02591            0.0909827
    2019-08-03 17:48:05  1:41:22.982  9067 obs/sec      9         9             225000     0.268075         0.243678            0.712543       0.963775        0.950443           2.0018           0.0948439                        0.253774           0.219874              0.742352         0.97041           0.956335             2.02591            0.0851546
    2019-08-03 17:48:08  1:41:25.999  9071 obs/sec      10        10            250000     0.264582         0.238022            0.719985       0.965262        0.962765           2.0018           0.0934477                        0.251473           0.216603              0.747004         0.971324          0.967391             2.02591            0.0851546
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.006368779786272896
C438        0.7954588532447815     0.7954588532447815   0.005066102265357183
C374        0.726370632648468      0.726370632648468    0.004626094602553819
C322        0.6563262343406677     0.6563262343406677   0.004179997254469453
C863        0.6458585262298584     0.6458585262298584   0.004113330726644725
---         ---                    ---                  ---
C663        0.07019643485546112    0.07019643485546112  0.000447065635375883
C540        0.06880814582109451    0.06880814582109451  0.0004382239282363046
C889        0.06798698008060455    0.06798698008060455  0.00043299410446709233
C880        0.06796959787607193    0.06796959787607193  0.0004328834010342241
C841        0.0677860751748085     0.0677860751748085   0.0004317145853640954

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_64

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.004228044700171175    0.0038780085742473602  0.0         0.020411820582499577  0.07720756530761719  0.0570761957608499     0.22473561763763428
    3        2        Softmax                      0.0   0.0   0.00028278524121105875  6.58770150039345e-05   0.0         0.09127017170771978   0.4613351821899414   0.0033898071004176203  0.12103083729743958


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06319452722934307
RMSE: 0.2513852168074787
LogLoss: 0.22905381868952066
Mean Per-Class Error: 0.06790048091943546
AUC: 0.972363934891984
pr_auc: 0.8274943451640209
Gini: 0.944727869783968
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5381364727320154: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4670  351   0.0699   (351.0/5021.0)
1      330   4678  0.0659   (330.0/5008.0)
Total  5000  5029  0.0679   (681.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.538136     0.932151  197
max f2                       0.431961     0.943088  228
max f0point5                 0.59131      0.937758  179
max accuracy                 0.538136     0.932097  197
max precision                0.999938     0.997226  0
max recall                   3.36881e-05  1         399
max specificity              0.999938     0.999602  0
max absolute_mcc             0.538136     0.864202  197
max min_per_class_accuracy   0.54211      0.931089  196
max mean_per_class_accuracy  0.538136     0.9321    197
Gains/Lift Table: Avg response rate: 49.94 %, avg score: 50.56 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   1                  2.0026      2.0026             1                1            1                           1                   0.0201677       0.0201677                  100.26    100.26
    2        0.0200419                   0.999998           2.0026      2.0026             1                1            1                           1                   0.0199681       0.0401358                  100.26    100.26
    3        0.030013                    0.999993           2.0026      2.0026             1                0.999996     1                           0.999999            0.0199681       0.0601038                  100.26    100.26
    4        0.0400838                   0.999972           2.0026      2.0026             1                0.999983     1                           0.999995            0.0201677       0.0802716                  100.26    100.26
    5        0.0500548                   0.999928           1.96254     1.99462            0.98             0.999953     0.996016                    0.999986            0.0195687       0.0998403                  96.2544   99.4617
    6        0.10001                     0.998897           1.9986      1.99661            0.998004         0.999563     0.997009                    0.999775            0.0998403       0.199681                   99.8599   99.6606
    7        0.150065                    0.994471           1.95074     1.98131            0.974104         0.9971       0.989369                    0.998883            0.0976438       0.297324                   95.0736   98.1306
    8        0.20002                     0.982855           1.95463     1.97464            0.976048         0.989271     0.986042                    0.996482            0.0976438       0.394968                   95.4629   97.4643
    9        0.30003                     0.914329           1.93671     1.962              0.967099         0.954265     0.979727                    0.98241             0.19369         0.588658                   93.6708   96.1998
    10       0.40004                     0.765565           1.86084     1.93671            0.929212         0.847801     0.967099                    0.948757            0.186102        0.77476                    86.0837   93.6708
    11       0.50005                     0.540373           1.57532     1.86443            0.78664          0.655434     0.931007                    0.890093            0.157548        0.932308                   57.5322   86.4431
    12       0.59996                     0.267597           0.423703    1.62451            0.211577         0.402636     0.811202                    0.808917            0.0423323       0.974641                   -57.6297  62.4509
    13       0.69997                     0.0773256          0.149745    1.4138             0.0747757        0.166439     0.705983                    0.717122            0.014976        0.989617                   -85.0255  41.3798
    14       0.79998                     0.00799909         0.0638914   1.24504            0.0319043        0.0334336    0.621713                    0.63165             0.00638978      0.996006                   -93.6109  24.5039
    15       0.89999                     0.000198309        0.0319457   1.11024            0.0159521        0.00254807   0.554398                    0.561742            0.00319489      0.999201                   -96.8054  11.0236
    16       1                           4.18599e-24        0.00798642  1                  0.00398804       3.17594e-05  0.499352                    0.505566            0.000798722     1                          -99.2014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06053785013551077
RMSE: 0.24604440683647083
LogLoss: 0.21943589033129862
Mean Per-Class Error: 0.06379958545798003
AUC: 0.9749481822475022
pr_auc: 0.8314928565133451
Gini: 0.9498963644950045
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5415035196246117: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2932  196   0.0627   (196.0/3128.0)
1      198   2851  0.0649   (198.0/3049.0)
Total  3130  3047  0.0638   (394.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.541504     0.935367  191
max f2                       0.411106     0.945102  232
max f0point5                 0.63117      0.941963  162
max accuracy                 0.560988     0.936215  184
max precision                0.998164     0.997372  3
max recall                   2.92647e-05  1         399
max specificity              0.999951     0.999361  0
max absolute_mcc             0.560988     0.872482  184
max min_per_class_accuracy   0.538534     0.936045  192
max mean_per_class_accuracy  0.541504     0.9362    191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.08 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999993           2.02591     2.02591            1                0.999997     1                           0.999999            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999974           1.99323     2.01774            0.983871         0.999984     0.995968                    0.999995            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.999926           1.9927      2.0128             0.983607         0.999957     0.993528                    0.999987            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.998974           2.02591     2.01935            1                0.999625     0.996764                    0.999806            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.994104           1.99968     2.0128             0.987055         0.997108     0.993528                    0.998907            0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.982401           1.99313     2.00788            0.983819         0.989274     0.9911                      0.996499            0.0997048       0.401771                   99.3128   100.788
    9        0.299984                    0.915408           1.94711     1.98764            0.961102         0.954822     0.981112                    0.982621            0.19449         0.596261                   94.7106   98.7644
    10       0.400032                    0.758257           1.90134     1.96606            0.938511         0.842288     0.970457                    0.947524            0.190226        0.786487                   90.134    96.6059
    11       0.500081                    0.52359            1.53091     1.879              0.755663         0.64397      0.927485                    0.886793            0.153165        0.939652                   53.0906   87.9
    12       0.599968                    0.249695           0.390735    1.63122            0.192869         0.38328      0.805181                    0.802965            0.0390292       0.978682                   -60.9265  63.1224
    13       0.700016                    0.0721097          0.104901    1.41308            0.0517799        0.154718     0.697502                    0.710316            0.0104952       0.989177                   -89.5099  41.3077
    14       0.799903                    0.00851279         0.0755202   1.24605            0.0372771        0.0330074    0.615058                    0.625738            0.00754346      0.99672                    -92.448   24.6052
    15       0.899951                    0.000205923        0.0262254   1.11044            0.012945         0.00267858   0.54812                     0.556472            0.00262381      0.999344                   -97.3775  11.0442
    16       1                           4.18599e-24        0.00655634  1                  0.00323625       3.36132e-05  0.493605                    0.500801            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:15:57  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:15:59  1:09:16.503  13827 obs/sec     1         1             25000      0.311997         0.38364             0.61063        0.938857        0.725028           2.0026           0.129026                         0.301102           0.356517              0.637291         0.945029          0.716236             1.99323            0.115266
    2019-08-03 17:16:04  1:09:21.843  14841 obs/sec     4         4             100000     0.270632         0.262103            0.707033       0.962106        0.824339           2.0026           0.0905374                        0.266121           0.249646              0.716671         0.964921          0.834983             2.02591            0.0903351
    2019-08-03 17:16:10  1:09:28.019  13969 obs/sec     7         7             175000     0.260758         0.24312             0.728021       0.968202        0.82388            2.0026           0.0771762                        0.25491            0.232922              0.740042         0.971071          0.805221             2.02591            0.0713939
    2019-08-03 17:16:15  1:09:32.862  14713 obs/sec     10        10            250000     0.251385         0.229054            0.747221       0.972364        0.827494           2.0026           0.0679031                        0.246044           0.219436              0.757809         0.974948          0.831493             2.02591            0.063785
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004032362932130122
C36         0.8960714340209961     0.8960714340209961   0.0036132852350869464
C438        0.8295623660087585     0.8295623660087585   0.0033450965345838786
C28         0.8275899291038513     0.8275899291038513   0.0033371429531225652
C35         0.8193944096565247     0.8193944096565247   0.0033040956442936136
---         ---                    ---                  ---
C949        0.14929798245429993    0.14929798245429993  0.0006020236502905323
C342        0.14886091649532318    0.14886091649532318  0.0006002612417186585
C446        0.1478305608034134     0.1478305608034134   0.0005961064736196922
C534        0.14277584850788116    0.14277584850788116  0.0005757240391266057
C468        0.12888966500759125    0.12888966500759125  0.0005197299075112797

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_190

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight          weight_rms          mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  -------------------  ------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.004538147010612657    0.003641652874648571   0.0         0.02034579514865266  0.077117919921875   0.03656737793068177     0.24325400590896606
    3        2        Softmax                      0.0   0.0   0.00033065663774323184  6.100859900470823e-05  0.0         0.06227655267866794  0.5003459453582764  -0.0009593844399233484  0.05464787781238556


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06399288586783888
RMSE: 0.2529681518844593
LogLoss: 0.23118505952022766
Mean Per-Class Error: 0.0718588581005073
AUC: 0.9715391917209741
pr_auc: 0.8351923503762917
Gini: 0.9430783834419483
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.480262937424948: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4624  441   0.0871   (441.0/5065.0)
1      287   4658  0.058    (287.0/4945.0)
Total  4911  5099  0.0727   (728.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.480263     0.927519  211
max f2                       0.355675     0.941883  251
max f0point5                 0.569628     0.93285   180
max accuracy                 0.52491      0.928172  196
max precision                0.999951     0.997001  0
max recall                   2.47842e-05  1         399
max specificity              0.999951     0.999605  0
max absolute_mcc             0.52491      0.856325  196
max min_per_class_accuracy   0.520461     0.926997  198
max mean_per_class_accuracy  0.523083     0.928141  197
Gains/Lift Table: Avg response rate: 49.40 %, avg score: 49.32 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   1                  2.02427    2.02427            1                1            1                           1                   0.0204247       0.0204247                  102.427   102.427
    2        0.0200799                   0.999999           2.02427    2.02427            1                0.999999     1                           1                   0.0202224       0.0406471                  102.427   102.427
    3        0.0300699                   0.999992           2.02427    2.02427            1                0.999996     1                           0.999998            0.0202224       0.0608696                  102.427   102.427
    4        0.0400599                   0.999972           2.02427    2.02427            1                0.999984     1                           0.999995            0.0202224       0.081092                   102.427   102.427
    5        0.05005                     0.999923           1.98378    2.01619            0.98             0.999949     0.996008                    0.999986            0.019818        0.10091                    98.3782   101.619
    6        0.1                         0.998755           2.01212    2.01416            0.994            0.999525     0.995005                    0.999756            0.100506        0.201416                   101.212   101.416
    7        0.15005                     0.99305            1.99598    2.00809            0.986028         0.996517     0.992011                    0.998675            0.0998989       0.301314                   99.5984   100.809
    8        0.2                         0.979571           1.96759    1.99798            0.972            0.987333     0.987013                    0.995842            0.0982811       0.399596                   96.7587   99.7978
    9        0.3                         0.901053           1.94338    1.97978            0.96004          0.946668     0.978022                    0.979451            0.194338        0.593933                   94.3377   97.9778
    10       0.4                         0.739337           1.86855    1.95197            0.923077         0.827082     0.964286                    0.941359            0.186855        0.780789                   86.8554   95.1972
    11       0.5                         0.505038           1.51871    1.86532            0.75025          0.622581     0.921479                    0.877603            0.151871        0.932659                   51.8706   86.5319
    12       0.6                         0.242447           0.426694   1.62555            0.210789         0.366792     0.80303                     0.792468            0.0426694       0.975329                   -57.3306  62.5548
    13       0.7                         0.0666852          0.143579   1.41384            0.0709291        0.145765     0.698444                    0.700082            0.0143579       0.989687                   -85.6421  41.3838
    14       0.8                         0.00754097         0.0768453  1.24671            0.037962         0.0294332    0.615884                    0.616251            0.00768453      0.997371                   -92.3155  24.6714
    15       0.9                         0.000196331        0.0141557  1.10976            0.00699301       0.00237833   0.54823                     0.548043            0.00141557      0.998787                   -98.5844  10.9763
    16       1                           4.66512e-24        0.0121335  1                  0.00599401       3.02038e-05  0.494006                    0.493241            0.00121335      1                          -98.7867  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.061511582119121826
RMSE: 0.24801528605939155
LogLoss: 0.22067273183515707
Mean Per-Class Error: 0.06710666320515979
AUC: 0.9746062081484098
pr_auc: 0.8327447638481205
Gini: 0.9492124162968196
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48402512012450133: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2888  240   0.0767   (240.0/3128.0)
1      176   2873  0.0577   (176.0/3049.0)
Total  3064  3113  0.0673   (416.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.484025     0.932489  207
max f2                       0.418395     0.944818  226
max f0point5                 0.558668     0.937014  184
max accuracy                 0.491423     0.932815  205
max precision                0.99659      0.997573  5
max recall                   2.84907e-05  1         399
max specificity              0.999943     0.999361  0
max absolute_mcc             0.491423     0.865716  205
max min_per_class_accuracy   0.506494     0.930946  200
max mean_per_class_accuracy  0.491423     0.932893  205
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.39 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999998           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999991           1.99323     2.01502            0.983871         0.999996     0.994624                    0.999998            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999965           2.02591     2.01774            1                0.999978     0.995968                    0.999993            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999925           1.9927      2.0128             0.983607         0.999945     0.993528                    0.999984            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.998854           2.02591     2.01935            1                0.99955      0.996764                    0.999767            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.994036           2.0128      2.01717            0.993528         0.996824     0.995685                    0.998786            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.98005            1.98657     2.00952            0.980583         0.987898     0.991909                    0.996064            0.0993768       0.402099                   98.6572   100.952
    9        0.299984                    0.9054             1.95039     1.98983            0.962723         0.949473     0.982191                    0.98055             0.194818        0.596917                   95.039    98.9831
    10       0.400032                    0.74058            1.88823     1.96442            0.932039         0.827943     0.969648                    0.942383            0.188914        0.785831                   88.8227   96.442
    11       0.500081                    0.491345           1.52763     1.87703            0.754045         0.616296     0.926513                    0.877145            0.152837        0.938668                   52.7628   87.7033
    12       0.599968                    0.246744           0.400585    1.63122            0.197731         0.366038     0.805181                    0.792052            0.0400131       0.978682                   -59.9415  63.1224
    13       0.700016                    0.0747759          0.118014    1.41495            0.0582524        0.151389     0.698427                    0.700486            0.0118071       0.990489                   -88.1986  41.4951
    14       0.799903                    0.00859002         0.0689532   1.24687            0.0340357        0.0326882    0.615462                    0.617096            0.0068875       0.997376                   -93.1047  24.6872
    15       0.899951                    0.000219039        0.019669    1.11044            0.00970874       0.00276783   0.54812                     0.548801            0.00196786      0.999344                   -98.0331  11.0442
    16       1                           1.57821e-23        0.00655634  1                  0.00323625       3.53875e-05  0.493605                    0.493897            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:00:21  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:00:23  3:53:40.960  15470 obs/sec     1         1             25000      0.309984         0.381609            0.615584       0.939685        0.729035           2.02427          0.124775                         0.304069           0.360349              0.630109         0.94386           0.715673             1.99323            0.120932
    2019-08-03 20:00:29  3:53:46.423  14949 obs/sec     4         4             100000     0.271473         0.266856            0.705168       0.961095        0.814113           2.02427          0.0935065                        0.265888           0.252314              0.717168         0.964943          0.820439             2.02591            0.0883924
    2019-08-03 20:00:34  3:53:51.627  15261 obs/sec     7         7             175000     0.260897         0.244141            0.727691       0.967316        0.815852           2.02427          0.0825175                        0.255388           0.233101              0.739066         0.97063           0.826765             2.02591            0.0747936
    2019-08-03 20:00:39  3:53:56.798  15446 obs/sec     10        10            250000     0.252968         0.231185            0.743992       0.971539        0.835192           2.02427          0.0727273                        0.248015           0.220673              0.753913         0.974606          0.832745             2.02591            0.0673466
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.003928004943980164
C28         0.9335429668426514     0.9335429668426514   0.003666961389175845
C25         0.8835654258728027     0.8835654258728027   0.0034706493611583083
C36         0.8694370985031128     0.8694370985031128   0.0034151532213999958
C34         0.8542155027389526     0.8542155027389526   0.003355362717983107
---         ---                    ---                  ---
C721        0.1472216248512268     0.1472216248512268   0.0005782872702764118
C314        0.14611585438251495    0.14611585438251495  0.0005739437984084044
C558        0.14379297196865082    0.14379297196865082  0.0005648195048024616
C467        0.1349823921918869     0.1349823921918869   0.0005302115038800013
C912        0.12368253618478775    0.12368253618478775  0.00048582561361785185

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_209

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 251,972 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.07190896927645693    0.11061564087867737     0.0         0.001641196609099328  0.10838648676872253  -0.002851658845678358  0.14121359586715698
    3        2        Softmax                 0.0   0.0   0.0018501863216897618  0.00044730526860803366  0.0         0.007369255257472673  0.23639631271362305  -0.0656880712328424    0.2185826301574707


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06980245307961729
RMSE: 0.264201538753311
LogLoss: 0.23669829526152894
Mean Per-Class Error: 0.09233509374714555
AUC: 0.9655867165088617
pr_auc: 0.9585829115475198
Gini: 0.9311734330177235
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49915300972375626: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4527  515   0.1021   (515.0/5042.0)
1      410   4558  0.0825   (410.0/4968.0)
Total  4937  5073  0.0924   (925.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.499153     0.907878  204
max f2                       0.128233     0.933829  316
max f0point5                 0.791691     0.919543  114
max accuracy                 0.562728     0.907592  187
max precision                0.995924     1         0
max recall                   0.00407938   1         397
max specificity              0.995924     1         0
max absolute_mcc             0.499153     0.815383  204
max min_per_class_accuracy   0.545254     0.906386  192
max mean_per_class_accuracy  0.499153     0.907665  204
Gains/Lift Table: Avg response rate: 49.63 %, avg score: 49.87 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   0.993585           2.0149     2.0149             1                0.994654    1                           0.994654            0.0203301       0.0203301                  101.49    101.49
    2        0.0200799                   0.992145           2.0149     2.0149             1                0.992851    1                           0.993757            0.0201288       0.0404589                  101.49    101.49
    3        0.0300699                   0.990925           2.0149     2.0149             1                0.991536    1                           0.993019            0.0201288       0.0605878                  101.49    101.49
    4        0.0400599                   0.990018           2.0149     2.0149             1                0.990483    1                           0.992386            0.0201288       0.0807166                  101.49    101.49
    5        0.05005                     0.989121           1.99475    2.01087            0.99             0.989535    0.998004                    0.991817            0.0199275       0.100644                   99.4746   101.087
    6        0.1                         0.984296           1.98669    1.99879            0.986            0.986654    0.992008                    0.989238            0.0992351       0.199879                   98.6687   99.8792
    7        0.15005                     0.979424           1.99881    1.9988             0.992016         0.982085    0.992011                    0.986852            0.10004         0.299919                   99.8808   99.8798
    8        0.2                         0.972693           1.98669    1.99577            0.986            0.976412    0.990509                    0.984245            0.0992351       0.399155                   98.6687   99.5773
    9        0.3                         0.946145           1.92432    1.97195            0.955045         0.961832    0.978688                    0.976774            0.192432        0.591586                   92.4316   97.1954
    10       0.4                         0.852656           1.80958    1.93136            0.898102         0.910133    0.958541                    0.960114            0.180958        0.772544                   80.9581   93.1361
    11       0.5                         0.52815            1.36876    1.81884            0.679321         0.71581     0.902697                    0.911253            0.136876        0.90942                    36.876    81.8841
    12       0.6                         0.142688           0.632045   1.62104            0.313686         0.30977     0.804529                    0.811006            0.0632045       0.972625                   -36.7955  62.1041
    13       0.7                         0.0386498          0.167069   1.41333            0.0829171        0.0781215   0.701441                    0.706308            0.0167069       0.989332                   -83.2931  41.3331
    14       0.8                         0.0157697          0.0623994  1.24446            0.030969         0.0247968   0.617632                    0.621119            0.00623994      0.995572                   -93.7601  24.4465
    15       0.9                         0.00885264         0.034219   1.10999            0.016983         0.0119785   0.550894                    0.553437            0.0034219       0.998994                   -96.5781  10.9993
    16       1                           0.0011549          0.0100644  1                  0.004995         0.00600099  0.496304                    0.498693            0.00100644      1                          -98.9936  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06470559859137356
RMSE: 0.25437295176840946
LogLoss: 0.22103683865057394
Mean Per-Class Error: 0.08413076611425163
AUC: 0.9701376871709226
pr_auc: 0.9632162202764635
Gini: 0.9402753743418453
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4953267172768528: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2843  285   0.0911   (285.0/3128.0)
1      236   2813  0.0774   (236.0/3049.0)
Total  3079  3098  0.0843   (521.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.495327     0.915243  204
max f2                       0.193781     0.936706  291
max f0point5                 0.768346     0.925926  127
max accuracy                 0.52813      0.915817  196
max precision                0.996081     1         0
max recall                   0.00654718   1         393
max specificity              0.996081     1         0
max absolute_mcc             0.517042     0.831673  199
max min_per_class_accuracy   0.535561     0.914962  194
max mean_per_class_accuracy  0.517042     0.915869  199
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.52 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.993638           2.02591     2.02591            1                0.994878    1                           0.994878            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.992128           2.02591     2.02591            1                0.992883    1                           0.993881            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.991102           2.02591     2.02591            1                0.9917      1                           0.993154            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.990111           2.02591     2.02591            1                0.990585    1                           0.992512            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.989022           1.9927      2.01935            0.983607         0.989497    0.996764                    0.991917            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.984371           2.02591     2.02263            1                0.986789    0.998382                    0.989353            0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.978924           1.99968     2.01498            0.987055         0.981597    0.994606                    0.986768            0.100033        0.302394                   99.9685   101.498
    8        0.200097                    0.972496           2.00624     2.0128             0.990291         0.975923    0.993528                    0.984056            0.100361        0.402755                   100.624   101.28
    9        0.299984                    0.946403           1.93397     1.98655            0.954619         0.961411    0.980572                    0.976516            0.193178        0.595933                   93.3973   98.6551
    10       0.400032                    0.854083           1.84889     1.95212            0.912621         0.911925    0.963577                    0.960362            0.184979        0.780912                   84.8889   95.2121
    11       0.500081                    0.505277           1.39978     1.84162            0.690939         0.713182    0.909032                    0.91091             0.140046        0.920958                   39.9779   84.1617
    12       0.599968                    0.131748           0.535208    1.62412            0.264182         0.282489    0.801673                    0.806286            0.0534602       0.974418                   -46.4792  62.4117
    13       0.700016                    0.0364467          0.177021    1.41729            0.0873786        0.0726936   0.699584                    0.701439            0.0177107       0.992129                   -82.2979  41.7294
    14       0.799903                    0.0158013          0.0656697   1.24851            0.0324149        0.0242223   0.616272                    0.616872            0.00655953      0.998688                   -93.433   24.8512
    15       0.899951                    0.00869899         0.00983452  1.11081            0.00485437       0.0118762   0.5483                      0.549614            0.000983929     0.999672                   -99.0165  11.0807
    16       1                           0.00153495         0.00327817  1                  0.00161812       0.00605597  0.493605                    0.495232            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:21:34  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:21:44  4:15:02.114  1290 obs/sec      0.47228   1             11807      0.334975         0.385775            0.551144       0.927028        0.85289            2.0149           0.15025                          0.320848           0.348618              0.588158         0.936279          0.850675             2.02591            0.138255
    2019-08-03 20:22:05  4:15:23.341  1229 obs/sec      1.44068   3             36017      0.297567         0.290022            0.645795       0.948605        0.931632           2.0149           0.122378                         0.286804           0.272866              0.67092          0.954874          0.94609              2.02591            0.111705
    2019-08-03 20:22:16  4:15:34.381  1222 obs/sec      1.92056   4             48014      0.293836         0.283634            0.654622       0.950804        0.938357           2.0149           0.115485                         0.284672           0.269294              0.675795         0.955562          0.940559             2.02591            0.107981
    2019-08-03 20:22:27  4:15:45.517  1220 obs/sec      2.40444   5             60111      0.289689         0.277217            0.664304       0.953233        0.943081           2.0149           0.112288                         0.282625           0.265683              0.68044          0.95685           0.932791             2.02591            0.109276
    2019-08-03 20:22:50  4:16:08.137  1190 obs/sec      3.364     7             84100      0.289112         0.276176            0.665638       0.953862        0.946192           2.0149           0.112587                         0.281356           0.262772              0.683304         0.958465          0.949542             2.02591            0.105877
    2019-08-03 20:23:11  4:16:29.218  1190 obs/sec      4.31868   9             107967     0.287493         0.27542             0.669373       0.954793        0.934341           2.0149           0.112787                         0.276487           0.255643              0.694169         0.960363          0.947212             2.02591            0.102153
    2019-08-03 20:23:22  4:16:40.068  1192 obs/sec      4.79216   10            119804     0.291163         0.280157            0.660878       0.952275        0.944632           2.0149           0.116184                         0.28435            0.26958               0.676528         0.955782          0.949817             2.02591            0.107819
    2019-08-03 20:23:42  4:17:00.967  1196 obs/sec      5.75216   12            143804     0.282802         0.264683            0.680074       0.957713        0.950334           2.0149           0.109491                         0.270771           0.247235              0.706684         0.96297           0.956447             2.02591            0.0976202
    2019-08-03 20:24:03  4:17:21.467  1201 obs/sec      6.7082    14            167705     0.281199         0.264429            0.68369        0.959893        0.946919           1.99495          0.104995                         0.271318           0.247735              0.705498         0.964417          0.941548             2.02591            0.0966489
    2019-08-03 20:24:14  4:17:32.386  1202 obs/sec      7.18916   15            179729     0.279526         0.262569            0.687445       0.959868        0.945325           1.99495          0.103397                         0.267543           0.243316              0.713637         0.964915          0.947353             2.02591            0.0938967
    2019-08-03 20:24:25  4:17:43.434  1204 obs/sec      7.67352   16            191838     0.277435         0.257492            0.692102       0.960216        0.952305           1.975            0.101598                         0.264575           0.239273              0.719955         0.964885          0.956521             2.02591            0.091954
    2019-08-03 20:24:46  4:18:04.398  1204 obs/sec      8.634     18            215850     0.282197         0.269434            0.681442       0.956446        0.949466           1.99495          0.105395                         0.270298           0.248122              0.707709         0.962347          0.954751             2.02591            0.0971345
    2019-08-03 20:25:07  4:18:25.254  1205 obs/sec      9.59348   20            239837     0.277252         0.25977             0.692508       0.958554        0.952529           1.975            0.102997                         0.26511            0.239743              0.718821         0.964191          0.957769             2.02591            0.0929254
    2019-08-03 20:25:18  4:18:36.130  1207 obs/sec      10.0789   21            251972     0.264202         0.236698            0.720775       0.965587        0.958583           2.0149           0.0924076                        0.254373           0.221037              0.741135         0.970138          0.963216             2.02591            0.0843452
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004422803966947105
C438        0.8164795637130737     0.8164795637130737   0.003611129053321424
C374        0.7219709753990173     0.7219709753990173   0.003193136094015445
C322        0.6903297901153564     0.6903297901153564   0.003053193334223961
C863        0.6605995893478394     0.6605995893478394   0.0029217024843312526
---         ---                    ---                  ---
C952        0.1427401453256607     0.1427401453256607   0.0006313116809889385
C991        0.14180590212345123    0.14180590212345123  0.0006271797064481131
C906        0.14017356932163239    0.14017356932163239  0.0006199602184568507
C936        0.14004161953926086    0.14004161953926086  0.0006193766304359401
C953        0.13433608412742615    0.13433608412742615  0.0005941421657829204

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_192

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.004279517046599759    0.0030489740893244743  0.0         0.020589905293179268  0.07691964507102966  0.07829594477261229    0.24699252843856812
    3        2        Softmax                      0.0   0.0   0.00029179035368542827  6.337647209875286e-05  0.0         -0.03869018788827816  0.4201599359512329   0.0010858889287089363  0.18749511241912842


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06504598289503094
RMSE: 0.255041139612869
LogLoss: 0.23068694706044754
Mean Per-Class Error: 0.07357907940174524
AUC: 0.9715290220523182
pr_auc: 0.8513149467918331
Gini: 0.9430580441046363
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5520079601556248: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4639  348   0.0698   (348.0/4987.0)
1      392   4630  0.0781   (392.0/5022.0)
Total  5031  4978  0.0739   (740.0/10009.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.552008     0.926     196
max f2                       0.393696     0.940108  248
max f0point5                 0.613971     0.937474  173
max accuracy                 0.5766       0.926366  187
max precision                0.999937     1         0
max recall                   8.5196e-05   1         399
max specificity              0.999937     1         0
max absolute_mcc             0.5766       0.853178  187
max min_per_class_accuracy   0.544259     0.924731  199
max mean_per_class_accuracy  0.5766       0.926421  187
Gains/Lift Table: Avg response rate: 50.17 %, avg score: 50.24 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100909                   1                  1.99303     1.99303            1                1            1                           1                   0.0201115       0.0201115                  99.3031   99.3031
    2        0.0200819                   0.999997           1.99303     1.99303            1                0.999998     1                           0.999999            0.0199124       0.0400239                  99.3031   99.3031
    3        0.0300729                   0.999985           1.99303     1.99303            1                0.999991     1                           0.999997            0.0199124       0.0599363                  99.3031   99.3031
    4        0.0400639                   0.999949           1.99303     1.99303            1                0.999968     1                           0.999989            0.0199124       0.0798487                  99.3031   99.3031
    5        0.050055                    0.999856           1.99303     1.99303            1                0.99991      1                           0.999974            0.0199124       0.0997611                  99.3031   99.3031
    6        0.10001                     0.998165           1.96513     1.97909            0.986            0.999265     0.993007                    0.99962             0.0981681       0.197929                   96.5128   97.9093
    7        0.150065                    0.992012           1.97712     1.97843            0.992016         0.995617     0.992676                    0.998285            0.0989646       0.296894                   97.7118   97.8435
    8        0.20002                     0.978701           1.94121     1.96914            0.974            0.986143     0.988012                    0.995252            0.0969733       0.393867                   94.1212   96.9138
    9        0.30003                     0.900786           1.92733     1.9552             0.967033         0.945983     0.981019                    0.978829            0.192752        0.586619                   92.7326   95.5201
    10       0.40004                     0.752014           1.83574     1.92534            0.921079         0.833283     0.966034                    0.942443            0.183592        0.770211                   83.5739   92.5335
    11       0.50005                     0.545399           1.53907     1.84808            0.772228         0.651278     0.927273                    0.88421             0.153923        0.924134                   53.9074   84.8083
    12       0.59996                     0.271465           0.496265    1.62297            0.249            0.406533     0.814321                    0.804663            0.0495818       0.973716                   -50.3735  62.2968
    13       0.69997                     0.0738524          0.161274    1.41412            0.0809191        0.161201     0.709535                    0.712727            0.016129        0.989845                   -83.8726  41.4124
    14       0.79998                     0.00769145         0.0696864   1.24605            0.034965         0.0329569    0.625203                    0.627745            0.00696933      0.996814                   -93.0314  24.6049
    15       0.89999                     0.000156293        0.0238925   1.11024            0.011988         0.00229457   0.55706                     0.558243            0.00238949      0.999204                   -97.6108  11.0238
    16       1                           1.3441e-23         0.00796416  1                  0.003996         2.40243e-05  0.501748                    0.502415            0.000796495     1                          -99.2036  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0619839085831309
RMSE: 0.24896567752027768
LogLoss: 0.22209221759109074
Mean Per-Class Error: 0.06698991074177185
AUC: 0.9743788370510981
pr_auc: 0.8495898353812621
Gini: 0.9487576741021961
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5695371591494884: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2950  178   0.0569   (178.0/3128.0)
1      235   2814  0.0771   (235.0/3049.0)
Total  3185  2992  0.0669   (413.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.569537     0.931634  189
max f2                       0.394442     0.944002  243
max f0point5                 0.598688     0.940506  177
max accuracy                 0.569537     0.933139  189
max precision                0.99681      0.997375  5
max recall                   4.74179e-05  1         399
max specificity              0.999935     0.999361  0
max absolute_mcc             0.569537     0.866372  189
max min_per_class_accuracy   0.54462      0.930946  196
max mean_per_class_accuracy  0.569537     0.93301   189
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.68 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999996           2.02591     2.02591            1                0.999998     1                           0.999999            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999979           2.02591     2.02591            1                0.999989     1                           0.999996            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.999936           2.02591     2.02591            1                0.999961     1                           0.999987            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.999852           1.95949     2.0128             0.967213         0.9999       0.993528                    0.99997             0.0193506       0.100689                   95.9487   101.28
    6        0.100049                    0.998293           2.02591     2.01935            1                0.999297     0.996764                    0.999634            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.992617           2.01935     2.01935            0.996764         0.996        0.996764                    0.998422            0.101017        0.30305                    101.935   101.935
    8        0.200097                    0.977409           1.97346     2.00788            0.97411          0.986111     0.9911                      0.995345            0.0987209       0.401771                   97.3459   100.788
    9        0.299984                    0.901426           1.97337     1.99639            0.974068         0.945556     0.985429                    0.978766            0.197114        0.598885                   97.3374   99.6391
    10       0.400032                    0.740397           1.86856     1.96442            0.92233          0.826141     0.969648                    0.940594            0.186947        0.785831                   86.8558   96.442
    11       0.500081                    0.524124           1.49485     1.87047            0.737864         0.638691     0.923276                    0.880194            0.149557        0.935389                   49.4846   87.0474
    12       0.599968                    0.253349           0.42357     1.62958            0.209076         0.38597      0.804371                    0.797913            0.042309        0.977698                   -57.643   62.9584
    13       0.700016                    0.0669606          0.114736    1.41308            0.0566343        0.148447     0.697502                    0.705089            0.0114792       0.989177                   -88.5264  41.3077
    14       0.799903                    0.00736513         0.0755202   1.24605            0.0372771        0.0295758    0.615058                    0.620735            0.00754346      0.99672                    -92.448   24.6052
    15       0.899951                    0.000188619        0.0262254   1.11044            0.012945         0.00231516   0.54812                     0.551985            0.00262381      0.999344                   -97.3775  11.0442
    16       1                           1.3441e-23         0.00655634  1                  0.00323625       2.81696e-05  0.493605                    0.496762            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:04:24  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:04:26  3:57:43.611  14013 obs/sec     1         1             25000      0.30644          0.353582            0.624373       0.94329         0.760058           1.99303          0.126286                         0.299041           0.337903              0.64224          0.947357          0.766767             2.02591            0.117209
    2019-08-03 20:04:31  3:57:48.925  14940 obs/sec     4         4             100000     0.27068          0.25847             0.706927       0.96264         0.847396           1.99303          0.0905185                        0.265655           0.249724              0.717663         0.965533          0.848819             2.02591            0.0853165
    2019-08-03 20:04:36  3:57:54.265  15117 obs/sec     7         7             175000     0.262815         0.242711            0.72371        0.967852        0.830285           1.99303          0.0825257                        0.256105           0.231547              0.737597         0.971244          0.847107             2.02591            0.0722033
    2019-08-03 20:04:41  3:57:59.187  15506 obs/sec     10        10            250000     0.255041         0.230687            0.739813       0.971529        0.851315           1.99303          0.0739335                        0.248966           0.222092              0.752024         0.974379          0.84959              2.02591            0.0668609
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003914819133551531
C438        0.8474537134170532     0.8474537134170532   0.0033176280120843756
C35         0.8045573830604553     0.8045573830604553   0.003149696637245219
C88         0.7575917840003967     0.7575917840003967   0.0029658348114261915
C25         0.7554222941398621     0.7554222941398621   0.0029573416510101243
---         ---                    ---                  ---
C382        0.15222854912281036    0.15222854912281036  0.0005959472367787672
C571        0.14933070540428162    0.14933070540428162  0.0005846027027434287
C334        0.14634159207344055    0.14634159207344055  0.0005729008646834981
C540        0.14581045508384705    0.14581045508384705  0.0005708215594341005
C887        0.13572905957698822    0.13572905957698822  0.0005313547194109492

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_118

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.004247733518704712    0.006246818229556084   0.0         0.020936349785430797  0.08071047067642212  0.02020466422606305   0.29731428623199463
    3        2        Softmax                      0.0   0.0   0.00029063353019864735  5.931330088060349e-05  0.0         -0.12454843854357023  0.45228731632232666  0.000982577458159696  0.0979049801826477


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06266134400577936
RMSE: 0.2503224800248259
LogLoss: 0.2227150051120094
Mean Per-Class Error: 0.06905807157014254
AUC: 0.9731469756916709
pr_auc: 0.8357310748142207
Gini: 0.9462939513833417
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5154567618693107: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4631  346   0.0695   (346.0/4977.0)
1      346   4698  0.0686   (346.0/5044.0)
Total  4977  5044  0.0691   (692.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.515457     0.931404  202
max f2                       0.351354     0.943235  255
max f0point5                 0.578228     0.938788  183
max accuracy                 0.515457     0.930945  202
max precision                0.99995      0.997101  0
max recall                   4.72202e-05  1         399
max specificity              0.99995      0.999598  0
max absolute_mcc             0.515457     0.861884  202
max min_per_class_accuracy   0.515457     0.93048   202
max mean_per_class_accuracy  0.515457     0.930942  202
Gains/Lift Table: Avg response rate: 50.33 %, avg score: 50.05 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   1                  1.98672     1.98672            1                1            1                           1                   0.0200238       0.0200238                  98.6717   98.6717
    2        0.0200579                   0.999999           1.98672     1.98672            1                1            1                           1                   0.0198255       0.0398493                  98.6717   98.6717
    3        0.0300369                   0.999994           1.96685     1.98012            0.99             0.999997     0.996678                    0.999999            0.0196273       0.0594766                  96.685    98.0117
    4        0.040016                    0.999979           1.98672     1.98176            1                0.999987     0.997506                    0.999996            0.0198255       0.0793021                  98.6717   98.1762
    5        0.0500948                   0.999945           1.98672     1.98276            1                0.999963     0.998008                    0.999989            0.0200238       0.0993259                  98.6717   98.2759
    6        0.10009                     0.99884            1.97482     1.97879            0.994012         0.999554     0.996012                    0.999772            0.0987312       0.198057                   97.482    97.8794
    7        0.150085                    0.99424            1.96292     1.97351            0.988024         0.996931     0.993351                    0.998826            0.0981364       0.296193                   96.2924   97.3507
    8        0.20008                     0.981492           1.9431      1.96591            0.978044         0.988874     0.989526                    0.996339            0.0971451       0.393339                   94.3096   96.5908
    9        0.30007                     0.911587           1.90344     1.94509            0.958084         0.95226      0.979049                    0.981651            0.190325        0.583664                   90.3441   94.5093
    10       0.40006                     0.757356           1.8618      1.92428            0.937126         0.843122     0.968571                    0.947027            0.186162        0.769826                   86.1804   92.4276
    11       0.50005                     0.522122           1.57629     1.85469            0.793413         0.642475     0.933546                    0.886129            0.157613        0.927439                   57.6287   85.4692
    12       0.60004                     0.251022           0.47586     1.62492            0.239521         0.386718     0.817895                    0.802908            0.0475813       0.97502                    -52.414   62.4925
    13       0.70003                     0.0716352          0.164568    1.41633            0.0828343        0.152862     0.712901                    0.710057            0.0164552       0.991475                   -83.5432  41.6332
    14       0.80002                     0.00802873         0.0654308   1.24749            0.0329341        0.0315878    0.627916                    0.625259            0.00654243      0.998017                   -93.4569  24.7491
    15       0.90001                     0.000172542        0.0118965   1.11022            0.00598802       0.00242917   0.55882                     0.556064            0.00118953      0.999207                   -98.8103  11.0218
    16       1                           9.46405e-26        0.00793101  1                  0.00399202       2.51098e-05  0.503343                    0.500465            0.000793021     1                          -99.2069  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06170871060935082
RMSE: 0.24841238014509426
LogLoss: 0.22243578391882163
Mean Per-Class Error: 0.06527547919363108
AUC: 0.9739602687225446
pr_auc: 0.8251512468522241
Gini: 0.9479205374450892
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5221473235497959: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2932  196   0.0627   (196.0/3128.0)
1      207   2842  0.0679   (207.0/3049.0)
Total  3139  3038  0.0652   (403.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.522147     0.933793  194
max f2                       0.325697     0.942417  262
max f0point5                 0.581257     0.938372  176
max accuracy                 0.522147     0.934758  194
max precision                0.996583     0.997616  5
max recall                   7.00655e-05  1         399
max specificity              0.999943     0.999361  0
max absolute_mcc             0.522147     0.869494  194
max min_per_class_accuracy   0.516599     0.933421  196
max mean_per_class_accuracy  0.522147     0.934725  194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.52 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999993           1.96056     2.00413            0.967742         0.999996     0.989247                    0.999999            0.0196786       0.0603477                  96.0558   100.413
    4        0.0401489                   0.999976           2.02591     2.00957            1                0.999986     0.991935                    0.999995            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999948           2.02591     2.0128             1                0.999962     0.993528                    0.999989            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.998945           2.02591     2.01935            1                0.999605     0.996764                    0.999797            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.994302           2.0128      2.01717            0.993528         0.997054     0.995685                    0.998883            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.982187           1.97346     2.00624            0.97411          0.98882      0.990291                    0.996367            0.0987209       0.401443                   97.3459   100.624
    9        0.299984                    0.906625           1.96352     1.99202            0.969206         0.951491     0.98327                     0.981424            0.19613         0.597573                   96.3524   99.2017
    10       0.400032                    0.742676           1.87511     1.96278            0.925566         0.832157     0.968839                    0.944092            0.187602        0.785175                   87.5114   96.278
    11       0.500081                    0.504092           1.53746     1.87769            0.7589           0.630306     0.926837                    0.881315            0.153821        0.938996                   53.7463   87.7689
    12       0.599968                    0.237652           0.36775     1.6263             0.181524         0.370085     0.802752                    0.796202            0.0367334       0.97573                    -63.225   62.6304
    13       0.700016                    0.0668434          0.124571    1.41167            0.0614887        0.142871     0.696809                    0.702826            0.0124631       0.988193                   -87.5429  41.1671
    14       0.799903                    0.00768753         0.0886541   1.24646            0.0437601        0.0300942    0.61526                     0.618819            0.00885536      0.997048                   -91.1346  24.6462
    15       0.899951                    0.00016725         0.0229472   1.11044            0.0113269        0.00229015   0.54812                     0.550279            0.00229583      0.999344                   -97.7053  11.0442
    16       1                           6.98506e-24        0.00655634  1                  0.00323625       2.42918e-05  0.493605                    0.495227            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:20:10  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:20:12  2:13:30.079  15051 obs/sec     1         1             25000      0.304116         0.357162            0.630038       0.943812        0.731505           1.98672          0.120347                         0.298741           0.351164              0.642957         0.946192          0.752618             2.02591            0.117047
    2019-08-03 18:20:17  2:13:35.201  15542 obs/sec     4         4             100000     0.266007         0.250824            0.716947       0.964848        0.807413           1.98672          0.08572                          0.264431           0.248639              0.720259         0.965803          0.815506             2.02591            0.0862878
    2019-08-03 18:20:24  2:13:41.645  16017 obs/sec     8         8             200000     0.255061         0.229803            0.739764       0.97098         0.839605           1.98672          0.0755414                        0.250763           0.227135              0.748431         0.972408          0.825539             2.02591            0.0691274
    2019-08-03 18:20:27  2:13:45.046  16113 obs/sec     10        10            250000     0.250322         0.222715            0.749343       0.973147        0.835731           1.98672          0.069055                         0.248412           0.222436              0.753125         0.97396           0.825151             2.02591            0.065242
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004031367263302714
C34         0.9979990124702454     0.9979990124702454   0.0040233005476809835
C28         0.8474293351173401     0.8474293351173401   0.0034162988795544296
C43         0.8019110560417175     0.8019110560417175   0.003232797979407088
C35         0.7880734801292419     0.7880734801292419   0.003177013628870068
---         ---                    ---                  ---
C938        0.14515797793865204    0.14515797793865204  0.0005851851202690994
C338        0.14288318157196045    0.14288318157196045  0.0005760145806657389
C435        0.14205694198608398    0.14205694198608398  0.0005726837054475918
C504        0.13662117719650269    0.13662117719650269  0.0005507701412238602
C721        0.11991585791110992    0.11991585791110992  0.0004834248639337083

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_124

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.00491738024964304     0.006816817447543144   0.0         0.020778880529426415  0.0810634195804596   0.07571139726908858     0.25883936882019043
    3        2        Softmax                      0.0   0.0   0.00031678286040914827  7.396659930236638e-05  0.0         -0.06521166029460801  0.49248290061950684  -0.0005486428295935764  0.1932803988456726


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06484862027389308
RMSE: 0.2546539225574448
LogLoss: 0.23529377840418428
Mean Per-Class Error: 0.07383066376501823
AUC: 0.970275985155635
pr_auc: 0.8381451116866551
Gini: 0.9405519703112699
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5194698589255432: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4590  405   0.0811   (405.0/4995.0)
1      339   4688  0.0674   (339.0/5027.0)
Total  4929  5093  0.0742   (744.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.51947      0.926482  198
max f2                       0.390639     0.940148  238
max f0point5                 0.60838      0.935402  169
max accuracy                 0.545767     0.926162  190
max precision                0.999948     0.99697   0
max recall                   5.4488e-05   1         399
max specificity              0.999948     0.9996    0
max absolute_mcc             0.545767     0.852335  190
max min_per_class_accuracy   0.538925     0.925726  192
max mean_per_class_accuracy  0.545767     0.926169  190
Gains/Lift Table: Avg response rate: 50.16 %, avg score: 50.01 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   1                  1.99363     1.99363            1                1           1                           1                   0.0200915       0.0200915                  99.3634   99.3634
    2        0.0200559                   0.999998           1.99363     1.99363            1                0.999999    1                           1                   0.0198926       0.0399841                  99.3634   99.3634
    3        0.0300339                   0.99999            1.9737      1.98701            0.99             0.999995    0.996678                    0.999998            0.0196937       0.0596777                  97.3698   98.7011
    4        0.040012                    0.999969           1.9737      1.98369            0.99             0.99998     0.995012                    0.999994            0.0196937       0.0793714                  97.3698   98.3691
    5        0.0500898                   0.999913           1.99363     1.98569            1                0.999944    0.996016                    0.999984            0.0200915       0.0994629                  99.3634   98.5692
    6        0.10008                     0.998648           1.97772     1.98171            0.992016         0.999477    0.994018                    0.99973             0.0988661       0.198329                   97.7717   98.1708
    7        0.15007                     0.993156           1.95384     1.97243            0.98004          0.996387    0.989362                    0.998617            0.0976726       0.296002                   95.3841   97.2425
    8        0.20006                     0.979629           1.95782     1.96878            0.982036         0.986969    0.987531                    0.995706            0.0978715       0.393873                   95.7821   96.8776
    9        0.30004                     0.904777           1.91007     1.94921            0.958084         0.949595    0.977719                    0.980341            0.190969        0.584842                   91.0069   94.9214
    10       0.40002                     0.752982           1.83844     1.92153            0.922156         0.834602    0.963831                    0.943915            0.183807        0.768649                   83.8441   92.1527
    11       0.5                         0.541105           1.56188     1.84961            0.783433         0.653831    0.927759                    0.88591             0.156157        0.924806                   56.1879   84.9612
    12       0.59998                     0.249433           0.487465    1.62263            0.244511         0.392442    0.813903                    0.803679            0.0487368       0.973543                   -51.2535  62.2625
    13       0.69996                     0.0662195          0.155193    1.41302            0.0778443        0.147206    0.708767                    0.709911            0.0155162       0.989059                   -84.4807  41.3022
    14       0.79994                     0.00738866         0.0696379   1.24512            0.0349301        0.0296488   0.624548                    0.624888            0.0069624       0.996021                   -93.0362  24.512
    15       0.89992                     0.000149251        0.0318345   1.11033            0.0159681        0.00227162  0.556935                    0.555716            0.00318281      0.999204                   -96.8166  11.0325
    16       1                           2.28047e-23        0.00795069  1                  0.00398804       2.1547e-05  0.501596                    0.500103            0.000795703     1                          -99.2049  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.062475410914789524
RMSE: 0.24995081699164243
LogLoss: 0.22266262330708494
Mean Per-Class Error: 0.0725348401513557
AUC: 0.9734711875681012
pr_auc: 0.8282421350474707
Gini: 0.9469423751362025
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5180823937241663: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2867  261   0.0834   (261.0/3128.0)
1      190   2859  0.0623   (190.0/3049.0)
Total  3057  3120  0.073    (451.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.518082     0.926893  205
max f2                       0.422219     0.943901  234
max f0point5                 0.647289     0.937346  159
max accuracy                 0.5639       0.927473  187
max precision                0.995513     0.997669  6
max recall                   2.43861e-05  1         399
max specificity              0.999912     0.999361  0
max absolute_mcc             0.5639       0.854982  187
max min_per_class_accuracy   0.542925     0.926861  195
max mean_per_class_accuracy  0.542925     0.927465  195
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.90 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999997           1.99323     2.00957            0.983871         0.999999     0.991935                    0.999999            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999986           1.99323     2.00413            0.983871         0.999993     0.989247                    0.999997            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.999955           2.02591     2.00957            1                0.999971     0.991935                    0.999991            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999896           2.02591     2.0128             1                0.999928     0.993528                    0.999978            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.998569           2.02591     2.01935            1                0.999435     0.996764                    0.999707            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.992847           2.0128      2.01717            0.993528         0.996314     0.995685                    0.998576            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.978983           1.99313     2.01116            0.983819         0.986647     0.992718                    0.995594            0.0997048       0.402427                   99.3128   101.116
    9        0.299984                    0.908729           1.95039     1.99092            0.962723         0.950566     0.982731                    0.980601            0.194818        0.597245                   95.039    99.0924
    10       0.400032                    0.754092           1.84561     1.95458            0.911003         0.836539     0.964792                    0.944571            0.184651        0.781896                   84.5611   95.4581
    11       0.500081                    0.526668           1.49812     1.86326            0.739482         0.649217     0.919715                    0.885481            0.149885        0.931781                   49.8124   86.326
    12       0.599968                    0.240262           0.453121    1.62849            0.223663         0.384597     0.803832                    0.80209             0.0452607       0.977042                   -54.6879  62.8491
    13       0.700016                    0.0652052          0.124571    1.41355            0.0614887        0.146679     0.697734                    0.708417            0.0124631       0.989505                   -87.5429  41.3546
    14       0.799903                    0.00747365         0.0788036   1.24687            0.0388979        0.0290094    0.615462                    0.623577            0.00787143      0.997376                   -92.1196  24.6872
    15       0.899951                    0.000169776        0.0229472   1.11081            0.0113269        0.00215605   0.5483                      0.554493            0.00229583      0.999672                   -97.7053  11.0807
    16       1                           2.28047e-23        0.00327817  1                  0.00161812       2.57006e-05  0.493605                    0.499019            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:29:08  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:29:10  2:22:28.314  13812 obs/sec     1         1             25000      0.313425         0.393319            0.607056       0.93756         0.732979           1.9739           0.128118                         0.305403           0.372639              0.626855         0.941505          0.742506             2.02591            0.11818
    2019-08-03 18:29:16  2:22:33.732  14703 obs/sec     4         4             100000     0.273692         0.268005            0.700367       0.960766        0.826657           1.9739           0.0915985                        0.267527           0.253921              0.713671         0.964284          0.82663              1.99323            0.0854784
    2019-08-03 18:29:21  2:22:38.942  15179 obs/sec     7         7             175000     0.263182         0.248066            0.722937       0.966858        0.845056           1.99363          0.0790261                        0.258905           0.237026              0.731828         0.969888          0.825325             2.02591            0.0760887
    2019-08-03 18:29:26  2:22:43.794  15642 obs/sec     10        10            250000     0.254654         0.235294            0.740603       0.970276        0.838145           1.99363          0.0742367                        0.249951           0.222663              0.750057         0.973471          0.828242             2.02591            0.0730128
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C28         1.0                    1.0                  0.004067269748591209
C250        0.9093068242073059     0.9093068242073059   0.0036983961382859197
C36         0.7798614501953125     0.7798614501953125   0.003171906884471864
C40         0.7622554898262024     0.7622554898262024   0.003100298694467687
C35         0.7498043775558472     0.7498043775558472   0.0030496566621941584
---         ---                    ---                  ---
C854        0.14305031299591064    0.14305031299591064  0.0005818242105747713
C394        0.1420377492904663     0.1420377492904663   0.0005777058408470961
C534        0.14180909097194672    0.14180909097194672  0.0005767758257854177
C432        0.13791027665138245    0.13791027665138245  0.0005609182962440124
C353        0.13503660261631012    0.13503660261631012  0.0005492302887738507

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_188

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  ------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.004441939984340303   0.003125821240246296   0.0         0.02080352812455649   0.07700610160827637  0.04674580903378079     0.2806124687194824
    3        2        Softmax                      0.0   0.0   0.0003224167387543275  5.804571264889091e-05  0.0         -0.02721732426351764  0.4838451147079468   -0.0009350573416062116  0.1221906840801239


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06533383194471568
RMSE: 0.2556048355268649
LogLoss: 0.2339312794386202
Mean Per-Class Error: 0.07591476586381274
AUC: 0.970518516602628
pr_auc: 0.8274956836965234
Gini: 0.941037033205256
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5414055275504115: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4592  376   0.0757   (376.0/4968.0)
1      384   4659  0.0761   (384.0/5043.0)
Total  4976  5035  0.0759   (760.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.541406     0.924588  192
max f2                       0.377374     0.941959  243
max f0point5                 0.601687     0.931358  170
max accuracy                 0.541406     0.924084  192
max precision                0.999955     0.993046  0
max recall                   5.49179e-05  1         399
max specificity              0.999955     0.998994  0
max absolute_mcc             0.541406     0.848161  192
max min_per_class_accuracy   0.541406     0.923855  192
max mean_per_class_accuracy  0.541406     0.924085  192
Gains/Lift Table: Avg response rate: 50.37 %, avg score: 50.79 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   1                  1.98513    1.98513            1                1            1                           1                   0.0200278       0.0200278                  98.5128   98.5128
    2        0.0200779                   0.999999           1.98513    1.98513            1                1            1                           1                   0.0198295       0.0398572                  98.5128   98.5128
    3        0.0300669                   0.999996           1.98513    1.98513            1                0.999998     1                           0.999999            0.0198295       0.0596867                  98.5128   98.5128
    4        0.0400559                   0.999983           1.98513    1.98513            1                0.99999      1                           0.999997            0.0198295       0.0795162                  98.5128   98.5128
    5        0.050045                    0.999951           1.96528    1.98117            0.99             0.99997      0.998004                    0.999991            0.0196312       0.0991473                  96.5277   98.1166
    6        0.10009                     0.99906            1.95739    1.96928            0.986028         0.99964      0.992016                    0.999816            0.0979576       0.197105                   95.7392   96.9279
    7        0.150035                    0.994666           1.96925    1.96927            0.992            0.997303     0.992011                    0.998979            0.0983542       0.295459                   96.9247   96.9268
    8        0.20008                     0.983129           1.93758    1.96134            0.976048         0.989541     0.988018                    0.996618            0.0969661       0.392425                   93.758    96.1342
    9        0.30007                     0.917197           1.89787    1.94019            0.956044         0.95704      0.977364                    0.98343             0.189768        0.582193                   89.787    94.0192
    10       0.40006                     0.767259           1.85226    1.91821            0.933067         0.849006     0.966292                    0.949832            0.185207        0.7674                     85.2257   91.8213
    11       0.50005                     0.546615           1.53297    1.84118            0.772228         0.657755     0.927487                    0.891428            0.153282        0.920682                   53.2971   84.118
    12       0.60004                     0.275066           0.539415   1.62426            0.271728         0.408934     0.818212                    0.811026            0.0539361       0.974618                   -46.0585  62.4256
    13       0.70003                     0.0859188          0.160635   1.4152             0.0809191        0.170928     0.7129                      0.719596            0.0160619       0.99068                    -83.9365  41.5197
    14       0.80002                     0.0103775          0.0634606  1.24625            0.031968         0.038796     0.627794                    0.634507            0.00634543      0.997026                   -93.6539  24.6251
    15       0.90001                     0.000261638        0.0178483  1.10978            0.00899101       0.00322086   0.559046                    0.564372            0.00178465      0.99881                    -98.2152  10.9777
    16       1                           3.65912e-23        0.0118989  1                  0.00599401       4.27588e-05  0.503746                    0.507945            0.00118977      1                          -98.8101  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06245095856227799
RMSE: 0.24990189787650272
LogLoss: 0.22296108260581543
Mean Per-Class Error: 0.07033012165323593
AUC: 0.9734026145002471
pr_auc: 0.817067464233828
Gini: 0.9468052290004942
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49991609674618065: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2858  270   0.0863   (270.0/3128.0)
1      167   2882  0.0548   (167.0/3049.0)
Total  3025  3152  0.0707   (437.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.499916     0.929527  201
max f2                       0.408242     0.946711  231
max f0point5                 0.574423     0.934325  175
max accuracy                 0.550026     0.929739  183
max precision                0.999439     0.996732  1
max recall                   4.65568e-05  1         399
max specificity              0.999943     0.999361  0
max absolute_mcc             0.550026     0.859475  183
max min_per_class_accuracy   0.537746     0.928389  187
max mean_per_class_accuracy  0.550026     0.92967   183
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.09 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999996           1.99323     2.01502            0.983871         0.999998     0.994624                    0.999999            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999982           1.99323     2.00957            0.983871         0.999989     0.991935                    0.999997            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999957           2.02591     2.0128             1                0.99997      0.993528                    0.999992            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999049           2.02591     2.01935            1                0.999656     0.996764                    0.999824            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.994653           2.0128      2.01717            0.993528         0.997328     0.995685                    0.998992            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.982635           1.98002     2.00788            0.977346         0.989203     0.9911                      0.996545            0.0990489       0.401771                   98.0016   100.788
    9        0.299984                    0.906132           1.94054     1.98546            0.957861         0.954349     0.980032                    0.982495            0.193834        0.595605                   94.054    98.5458
    10       0.400032                    0.761162           1.86528     1.9554             0.920712         0.839302     0.965196                    0.946682            0.186619        0.782224                   86.528    95.5401
    11       0.500081                    0.520528           1.51779     1.86785            0.749191         0.643749     0.921981                    0.886076            0.151853        0.934077                   51.7794   86.7851
    12       0.599968                    0.253121           0.439987    1.63013            0.21718          0.383289     0.804641                    0.802368            0.0439488       0.978026                   -56.0013  63.0131
    13       0.700016                    0.0762268          0.124571    1.41495            0.0614887        0.156807     0.698427                    0.710103            0.0124631       0.990489                   -87.5429  41.4951
    14       0.799903                    0.00989389         0.0689532   1.24687            0.0340357        0.0349879    0.615462                    0.625799            0.0068875       0.997376                   -93.1047  24.6872
    15       0.899951                    0.000259584        0.019669    1.11044            0.00970874       0.00306546   0.54812                     0.556569            0.00196786      0.999344                   -98.0331  11.0442
    16       1                           1.22103e-22        0.00655634  1                  0.00323625       4.30778e-05  0.493605                    0.500889            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:59:39  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:59:41  3:52:58.858  14384 obs/sec     1         1             25000      0.316199         0.384628            0.600051       0.935193        0.729496           1.98513          0.132954                         0.304044           0.353522              0.630168         0.942719          0.726077             2.02591            0.125465
    2019-08-03 19:59:46  3:53:03.999  15482 obs/sec     4         4             100000     0.273488         0.264884            0.7008         0.960906        0.803978           1.98513          0.0940965                        0.263614           0.245115              0.721985         0.966554          0.80739              2.02591            0.0840214
    2019-08-03 19:59:51  3:53:09.019  15850 obs/sec     7         7             175000     0.262566         0.244194            0.724222       0.967439        0.840945           1.98513          0.0832085                        0.255075           0.23108               0.739704         0.971345          0.860275             2.02591            0.0734985
    2019-08-03 19:59:56  3:53:13.924  16126 obs/sec     10        10            250000     0.255605         0.233931            0.73865        0.970519        0.827496           1.98513          0.0759165                        0.249902           0.222961              0.750155         0.973403          0.817067             2.02591            0.0707463
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004156692893592141
C438        0.8230286836624146     0.8230286836624146   0.0034210774806020527
C36         0.7940236926078796     0.7940236926078796   0.003300512640406964
C88         0.750742495059967      0.750742495059967    0.0031206059941333983
C35         0.7101753354072571     0.7101753354072571   0.002951980769891761
---         ---                    ---                  ---
C475        0.14415057003498077    0.14415057003498077  0.0005991896500716609
C721        0.14180988073349       0.14180988073349     0.0005894601234860469
C462        0.13979598879814148    0.13979598879814148  0.0005810889931899213
C190        0.13780899345874786    0.13780899345874786  0.0005728296637830631
C626        0.13061510026454926    0.13061510026454926  0.0005429268590654768

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_150

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 258,044 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  ---------------------  ------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.07351966014364883    0.10695546865463257     0.0         -0.0012175110341501687  0.10702979564666748  0.008111150880742811   0.1325240135192871
    3        2        Softmax                 0.0   0.0   0.0018493771906378242  0.00040082167834043503  0.0         0.002900878950299557    0.24692583084106445  0.0016238452914411755  0.2184962034225464


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0707230762746297
RMSE: 0.2659381060973205
LogLoss: 0.23945703909312055
Mean Per-Class Error: 0.0936093037647121
AUC: 0.9657104300124324
pr_auc: 0.957872175734484
Gini: 0.9314208600248648
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4044913757529454: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4390  600   0.1202   (600.0/4990.0)
1      340   4686  0.0676   (340.0/5026.0)
Total  4730  5286  0.0938   (940.0/10016.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.404491     0.908844  233
max f2                       0.153855     0.931946  304
max f0point5                 0.798774     0.918044  116
max accuracy                 0.454097     0.90645   219
max precision                0.996752     1         0
max recall                   0.00205825   1         399
max specificity              0.996752     1         0
max absolute_mcc             0.404491     0.81336   233
max min_per_class_accuracy   0.52986      0.903808  196
max mean_per_class_accuracy  0.454097     0.906391  219
Gains/Lift Table: Avg response rate: 50.18 %, avg score: 50.12 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100839                   0.994987           1.99284     1.99284            1                0.996035    1                           0.996035            0.0200955       0.0200955                  99.2837   99.2837
    2        0.0200679                   0.993902           1.99284     1.99284            1                0.994444    1                           0.995244            0.0198965       0.039992                   99.2837   99.2837
    3        0.0300519                   0.993098           1.93305     1.97298            0.97             0.993485    0.990033                    0.994659            0.0192996       0.0592917                  93.3052   97.2975
    4        0.0400359                   0.992316           1.97291     1.97296            0.99             0.992698    0.990025                    0.99417             0.0196976       0.0789893                  97.2909   97.2959
    5        0.05002                     0.991522           1.99284     1.97693            1                0.991905    0.992016                    0.993718            0.0198965       0.0988858                  99.2837   97.6926
    6        0.10004                     0.988136           1.98488     1.9809             0.996008         0.989813    0.994012                    0.991766            0.0992837       0.19817                    98.4882   98.0904
    7        0.15006                     0.984599           1.97295     1.97825            0.99002          0.986439    0.992681                    0.98999             0.0986868       0.296856                   97.2949   97.8252
    8        0.20008                     0.979173           1.97693     1.97792            0.992016         0.982071    0.992515                    0.98801             0.0988858       0.395742                   97.6926   97.7921
    9        0.30002                     0.955165           1.92316     1.95968            0.965035         0.969175    0.983361                    0.981736            0.192201        0.587943                   92.3158   95.9679
    10       0.40006                     0.869731           1.77804     1.91426            0.892216         0.923247    0.960569                    0.96711             0.177875        0.765818                   77.804    91.4258
    11       0.5                         0.538619           1.36771     1.80501            0.686314         0.73254     0.905751                    0.920224            0.136689        0.902507                   36.7711   80.5014
    12       0.60004                     0.140124           0.656324    1.6135             0.329341         0.306221    0.809651                    0.817856            0.0656586       0.968166                   -34.3676  61.3502
    13       0.69998                     0.032324           0.209039    1.41298            0.104895         0.0720316   0.709029                    0.711371            0.0208914       0.989057                   -79.0961  41.2979
    14       0.80002                     0.0120327          0.0835321   1.24674            0.0419162        0.0201032   0.625608                    0.62493             0.00835655      0.997413                   -91.6468  24.6736
    15       0.89996                     0.00593586         0.0179176   1.11028            0.00899101       0.00849927  0.557133                    0.556476            0.00179069      0.999204                   -98.2082  11.0276
    16       1                           0.000883852        0.00795544  1                  0.00399202       0.00417122  0.501797                    0.501223            0.000795862     1                          -99.2045  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0651380745556375
RMSE: 0.25522161851151537
LogLoss: 0.22296780916497086
Mean Per-Class Error: 0.08628578486594485
AUC: 0.9695529287620192
pr_auc: 0.9622846814798989
Gini: 0.9391058575240383
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4476986924041195: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2818  310   0.0991   (310.0/3128.0)
1      224   2825  0.0735   (224.0/3049.0)
Total  3042  3135  0.0864   (534.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.447699     0.913648  216
max f2                       0.218372     0.938019  284
max f0point5                 0.804708     0.926416  113
max accuracy                 0.447699     0.91355   216
max precision                0.996781     1         0
max recall                   0.00405657   1         396
max specificity              0.996781     1         0
max absolute_mcc             0.447699     0.827455  216
max min_per_class_accuracy   0.518147     0.913043  196
max mean_per_class_accuracy  0.447699     0.913714  216
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.59 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.994647           2.02591     2.02591            1                0.995656    1                           0.995656            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.993672           2.02591     2.02591            1                0.99418     1                           0.994918            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.992757           2.02591     2.02591            1                0.993193    1                           0.994343            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.992024           1.99323     2.01774            0.983871         0.992363    0.995968                    0.993848            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.991316           2.02591     2.01935            1                0.991644    0.996764                    0.993413            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.988151           2.01935     2.01935            0.996764         0.989751    0.996764                    0.991582            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.984465           1.99968     2.0128             0.987055         0.98646     0.993528                    0.989875            0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.97881            2.01935     2.01444            0.996764         0.9818      0.994337                    0.987856            0.101017        0.403083                   101.935   101.444
    9        0.299984                    0.955535           1.92412     1.98436            0.949757         0.968982    0.979493                    0.981571            0.192194        0.595277                   92.4122   98.4364
    10       0.400032                    0.863726           1.86528     1.95458            0.920712         0.921715    0.964792                    0.966601            0.186619        0.781896                   86.528    95.4581
    11       0.500081                    0.490942           1.36372     1.83637            0.673139         0.71803     0.906442                    0.916871            0.136438        0.918334                   36.3719   83.637
    12       0.599968                    0.129293           0.545058    1.62138            0.269044         0.27573     0.800324                    0.810129            0.0544441       0.972778                   -45.4942  62.1384
    13       0.700016                    0.03091            0.183578    1.41589            0.0906149        0.0669589   0.69889                     0.703913            0.0183667       0.991145                   -81.6422  41.5888
    14       0.799903                    0.011832           0.0623862   1.24687            0.0307942        0.0187804   0.615462                    0.618358            0.00623155      0.997376                   -93.7614  24.6872
    15       0.899951                    0.00596655         0.0163909   1.11008            0.00809061       0.00844197  0.54794                     0.550553            0.00163988      0.999016                   -98.3609  11.0078
    16       1                           0.000883852        0.00983452  1                  0.00485437       0.00420149  0.493605                    0.495891            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:55:53  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:56:00  2:49:18.257  1236 obs/sec      0.33468   1             8367       0.341432         0.456401            0.533691       0.925674        0.721711           1.99284          0.151058                         0.329284           0.420762              0.566216         0.933553          0.737057             2.02591            0.13615
    2019-08-03 18:56:14  2:49:32.503  1251 obs/sec      0.99792   3             24948      0.305584         0.306836            0.626468       0.943024        0.919435           1.99284          0.127097                         0.294805           0.285738              0.652304         0.950114          0.91264              2.02591            0.119799
    2019-08-03 18:56:28  2:49:46.732  1252 obs/sec      1.65736   5             41434      0.297656         0.292533            0.645599       0.948088        0.931205           1.99284          0.118011                         0.286907           0.273872              0.670684         0.95405           0.936529             2.02591            0.107172
    2019-08-03 18:56:43  2:50:01.005  1252 obs/sec      2.31812   7             57953      0.300059         0.297711            0.639854       0.946617        0.931186           1.97311          0.123602                         0.288639           0.276161              0.666695         0.953692          0.944585             2.02591            0.11219
    2019-08-03 18:56:57  2:50:15.249  1251 obs/sec      2.978     9             74450      0.29263          0.285167            0.657466       0.950363        0.937623           1.99284          0.118411                         0.281497           0.262883              0.682986         0.957756          0.940408             2.02591            0.108305
    2019-08-03 18:57:12  2:50:30.837  1231 obs/sec      3.64052   11            91013      0.289286         0.278955            0.665251       0.95264         0.949639           1.99284          0.113718                         0.276211           0.254475              0.694779         0.960509          0.951319             2.02591            0.101182
    2019-08-03 18:57:27  2:50:45.235  1235 obs/sec      4.30648   13            107662     0.287344         0.278373            0.669729       0.953863        0.946118           1.99284          0.110423                         0.27306            0.250858              0.701705         0.961826          0.945462             2.02591            0.100049
    2019-08-03 18:57:41  2:50:59.688  1237 obs/sec      4.9738    15            124345     0.285197         0.272061            0.674647       0.955474        0.947378           1.99284          0.109724                         0.272513           0.248427              0.702898         0.962967          0.958143             2.02591            0.0977821
    2019-08-03 18:57:56  2:51:14.170  1238 obs/sec      5.63712   17            140928     0.282028         0.266503            0.681837       0.956585        0.952921           1.99284          0.108027                         0.269412           0.244974              0.709621         0.963403          0.951576             2.02591            0.0981059
    2019-08-03 18:58:10  2:51:28.547  1242 obs/sec      6.3076    19            157690     0.280176         0.264949            0.686001       0.957319        0.953396           1.99284          0.103834                         0.266769           0.242921              0.71529          0.964951          0.959585             2.02591            0.0937348
    2019-08-03 18:58:24  2:51:43.032  1242 obs/sec      6.96964   21            174241     0.276472         0.25905             0.69425        0.959381        0.956097           1.97311          0.101038                         0.265211           0.238905              0.718607         0.965042          0.956884             2.02591            0.093411
    2019-08-03 18:58:39  2:51:57.294  1245 obs/sec      7.63992   23            190998     0.273036         0.252625            0.701801       0.961142        0.957704           1.97311          0.101038                         0.262436           0.235467              0.724464         0.965867          0.961845             1.99323            0.0926016
    2019-08-03 18:58:53  2:52:11.921  1245 obs/sec      8.30948   25            207737     0.27117          0.24945             0.705864       0.962554        0.957656           1.95338          0.098742                         0.260391           0.232381              0.728741         0.966853          0.959716             2.02591            0.08904
    2019-08-03 18:59:08  2:52:26.366  1245 obs/sec      8.9802    27            224505     0.269678         0.247151            0.709092       0.96257         0.959018           1.95338          0.0976438                        0.258859           0.23009               0.731923         0.967131          0.962335             2.02591            0.0887162
    2019-08-03 18:59:22  2:52:40.592  1247 obs/sec      9.6462    29            241155     0.265938         0.239457            0.717104       0.96571         0.957872           1.99284          0.0938498                        0.255222           0.222968              0.739405         0.969553          0.962285             2.02591            0.0864497
    2019-08-03 18:59:36  2:52:54.845  1249 obs/sec      10.3218   31            258044     0.266249         0.240998            0.716443       0.964568        0.960211           1.97311          0.0947484                        0.256175           0.227867              0.737454         0.967345          0.962119             1.99323            0.086126
    2019-08-03 18:59:37  2:52:55.871  1249 obs/sec      10.3218   31            258044     0.265938         0.239457            0.717104       0.96571         0.957872           1.99284          0.0938498                        0.255222           0.222968              0.739405         0.969553          0.962285             2.02591            0.0864497
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004695875802244895
C438        0.8344711661338806     0.8344711661338806   0.0039185729567191695
C374        0.7487850785255432     0.7487850785255432   0.003516201731330142
C88         0.6577089428901672     0.6577089428901672   0.0030885195098380057
C322        0.644475519657135      0.644475519657135    0.0030263769978971446
---         ---                    ---                  ---
C908        0.13154789805412292    0.13154789805412292  0.0006177325913085341
C945        0.13151399791240692    0.13151399791240692  0.0006175734004533573
C973        0.13114185631275177    0.13114185631275177  0.000615825869720528
C949        0.13007645308971405    0.13007645308971405  0.0006108228685058314
C764        0.12792859971523285    0.12792859971523285  0.0006007368158178351

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_43

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight          weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  -------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.00455048331490783    0.004026424139738083   0.0         0.02070712445785277  0.07848170399665833  0.05175112326140627     0.3027611970901489
    3        2        Softmax                      0.0   0.0   0.0002834620861449366  6.150981062091887e-05  0.0         0.01613040593929327  0.44744420051574707  -4.613777203491161e-05  0.024585135281085968


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06627016045081614
RMSE: 0.25742991366742163
LogLoss: 0.23751770826552604
Mean Per-Class Error: 0.075139558449836
AUC: 0.969657997750514
pr_auc: 0.8174403799774501
Gini: 0.939315995501028
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5058017425759697: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4570  420   0.0842   (420.0/4990.0)
1      333   4704  0.0661   (333.0/5037.0)
Total  4903  5124  0.0751   (753.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.505802     0.925893  205
max f2                       0.324469     0.942895  266
max f0point5                 0.571029     0.930931  182
max accuracy                 0.505802     0.924903  205
max precision                0.998344     0.993355  3
max recall                   6.55389e-05  1         399
max specificity              0.999938     0.998597  0
max absolute_mcc             0.505802     0.849918  205
max min_per_class_accuracy   0.520473     0.924048  199
max mean_per_class_accuracy  0.505802     0.92486   205
Gains/Lift Table: Avg response rate: 50.23 %, avg score: 50.34 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   1                  1.99067     1.99067            1                1            1                           1                   0.0200516       0.0200516                  99.0669   99.0669
    2        0.0200459                   0.999999           1.99067     1.99067            1                1            1                           1                   0.0198531       0.0399047                  99.0669   99.0669
    3        0.0300189                   0.999995           1.95086     1.97744            0.98             0.999997     0.993355                    0.999999            0.019456        0.0593607                  95.0856   97.7442
    4        0.0400918                   0.999982           1.97096     1.97581            0.990099         0.99999      0.992537                    0.999997            0.0198531       0.0792138                  97.0959   97.5813
    5        0.0500648                   0.999938           1.97076     1.97481            0.99             0.999963     0.992032                    0.99999             0.0196546       0.0988684                  97.0762   97.4807
    6        0.10003                     0.999057           1.97875     1.97678            0.994012         0.999639     0.993021                    0.999815            0.0988684       0.197737                   97.8749   97.6776
    7        0.149995                    0.994969           1.95491     1.96949            0.982036         0.99738      0.989362                    0.999004            0.0976772       0.295414                   95.4909   96.9492
    8        0.20006                     0.981928           1.92722     1.95891            0.968127         0.989489     0.984048                    0.996623            0.096486        0.3919                     92.7221   95.8914
    9        0.29999                     0.910724           1.90325     1.94037            0.956088         0.953541     0.974734                    0.982272            0.190193        0.582093                   90.3254   94.0373
    10       0.40002                     0.754646           1.82991     1.91275            0.919242         0.839519     0.960858                    0.946575            0.183045        0.765138                   82.9907   91.275
    11       0.50005                     0.522974           1.56792     1.84377            0.787637         0.641826     0.926207                    0.885613            0.156839        0.921977                   56.7925   84.3771
    12       0.59998                     0.268118           0.552301    1.62867            0.277445         0.401138     0.818152                    0.804921            0.0551916       0.977169                   -44.7699  62.8669
    13       0.70001                     0.0792409          0.132976    1.41494            0.0667996        0.165958     0.710785                    0.713614            0.0133016       0.990471                   -86.7024  41.4938
    14       0.79994                     0.00965313         0.0695343   1.24687            0.0349301        0.035836     0.626356                    0.628945            0.00694858      0.997419                   -93.0466  24.6867
    15       0.89997                     0.000257524        0.0198471   1.11049            0.00997009       0.00298665   0.557846                    0.559371            0.00198531      0.999404                   -98.0153  11.0486
    16       1                           4.47887e-23        0.00595414  1                  0.00299103       4.02877e-05  0.502344                    0.503421            0.000595593     1                          -99.4046  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06209016553072442
RMSE: 0.2491789829233686
LogLoss: 0.22316756377840397
Mean Per-Class Error: 0.06548748950433625
AUC: 0.9737553359073747
pr_auc: 0.8057049258167536
Gini: 0.9475106718147495
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5070802874094288: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2904  224   0.0716   (224.0/3128.0)
1      181   2868  0.0594   (181.0/3049.0)
Total  3085  3092  0.0656   (405.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.50708      0.93405   200
max f2                       0.354527     0.945799  247
max f0point5                 0.561025     0.936682  182
max accuracy                 0.512333     0.934434  198
max precision                0.997724     0.997475  3
max recall                   5.90613e-05  1         399
max specificity              0.999916     0.999361  0
max absolute_mcc             0.50708      0.868955  200
max min_per_class_accuracy   0.517996     0.931781  196
max mean_per_class_accuracy  0.50708      0.934513  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.68 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999994           1.96056     2.00413            0.967742         0.999997     0.989247                    0.999999            0.0196786       0.0603477                  96.0558   100.413
    4        0.0401489                   0.999979           2.02591     2.00957            1                0.999988     0.991935                    0.999996            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.99994            2.02591     2.0128             1                0.999962     0.993528                    0.999989            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.999032           2.02591     2.01935            1                0.999653     0.996764                    0.999821            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.994886           2.00624     2.01498            0.990291         0.997412     0.994606                    0.999018            0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.983417           1.98657     2.00788            0.980583         0.989494     0.9911                      0.996637            0.0993768       0.401771                   98.6572   100.788
    9        0.299984                    0.910458           1.95367     1.98983            0.964344         0.954557     0.982191                    0.982625            0.195146        0.596917                   95.3673   98.9831
    10       0.400032                    0.744088           1.85545     1.95622            0.915858         0.833276     0.965601                    0.945273            0.185635        0.782552                   85.5445   95.6221
    11       0.500081                    0.50655            1.57352     1.87966            0.776699         0.625953     0.927808                    0.881388            0.157429        0.93998                    57.3522   87.9656
    12       0.599968                    0.251447           0.384168    1.63068            0.189627         0.371952     0.804911                    0.796574            0.0383732       0.978354                   -61.5832  63.0677
    13       0.700016                    0.0693963          0.114736    1.41401            0.0566343        0.153147     0.697965                    0.704613            0.0114792       0.989833                   -88.5264  41.4014
    14       0.799903                    0.0096906          0.0656697   1.24564            0.0324149        0.0331134    0.614855                    0.620761            0.00655953      0.996392                   -93.433   24.5642
    15       0.899951                    0.000279136        0.0295035   1.11044            0.0145631        0.00295481   0.54812                     0.552078            0.00295179      0.999344                   -97.0496  11.0442
    16       1                           1.04544e-22        0.00655634  1                  0.00323625       4.49911e-05  0.493605                    0.496848            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:52:51  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:52:53  46 min 11.137 sec  14568 obs/sec     1         1             25000      0.313437         0.370705            0.60702        0.938425        0.759934           1.99067          0.12945                          0.302546           0.340369              0.633805         0.945658          0.734312             2.02591            0.123847
    2019-08-03 16:52:59  46 min 16.374 sec  15197 obs/sec     4         4             100000     0.275117         0.270108            0.697235       0.959866        0.765673           1.99067          0.0937469                        0.266565           0.250669              0.715727         0.965055          0.800839             2.02591            0.0827262
    2019-08-03 16:53:04  46 min 21.384 sec  15608 obs/sec     7         7             175000     0.263759         0.246753            0.721718       0.966503        0.812865           1.99067          0.0831754                        0.253496           0.227488              0.742918         0.971904          0.829                2.02591            0.0760887
    2019-08-03 16:53:08  46 min 26.252 sec  15944 obs/sec     10        10            250000     0.25743          0.237518            0.734914       0.969658        0.81744            1.99067          0.0750972                        0.249179           0.223168              0.751599         0.973755          0.805705             2.02591            0.0655658
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003929392680001744
C28         0.8915229439735413     0.8915229439735413   0.0035031437301032376
C36         0.8717260956764221     0.8717260956764221   0.003425354139317433
C88         0.7781201004981995     0.7781201004981995   0.003057539427059846
C438        0.7653051018714905     0.7653051018714905   0.0030071842652618233
---         ---                    ---                  ---
C514        0.15411734580993652    0.15411734580993652  0.000605587570486862
C311        0.15170042216777802    0.15170042216777802  0.0005960905284192412
C229        0.14671002328395844    0.14671002328395844  0.0005764812915748717
C660        0.14399413764476776    0.14399413764476776  0.000565809510424514
C396        0.12802079319953918    0.12802079319953918  0.0005030439676862862

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_240

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.005306719159364324    0.005092369392514229   0.0         0.02091292845971177   0.07967135310173035  0.09664064120819024    0.24204421043395996
    3        2        Softmax                      0.0   0.0   0.00031322880556672317  6.023432069923729e-05  0.0         0.059188318046835775  0.5236697196960449   0.0006428258206664164  0.01928069442510605


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06403288760882186
RMSE: 0.25304720430943684
LogLoss: 0.22906330785160556
Mean Per-Class Error: 0.0710644280167193
AUC: 0.9721674941707643
pr_auc: 0.8470375749159494
Gini: 0.9443349883415286
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.514982336487012: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4638  327   0.0659   (327.0/4965.0)
1      385   4663  0.0763   (385.0/5048.0)
Total  5023  4990  0.0711   (712.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.514982     0.92907   203
max f2                       0.36977      0.942846  250
max f0point5                 0.572835     0.934886  182
max accuracy                 0.514982     0.928892  203
max precision                0.998821     0.997107  2
max recall                   3.61583e-05  1         399
max specificity              0.999943     0.999396  0
max absolute_mcc             0.514982     0.857846  203
max min_per_class_accuracy   0.501133     0.927492  207
max mean_per_class_accuracy  0.514982     0.928936  203
Gains/Lift Table: Avg response rate: 50.41 %, avg score: 49.34 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   1                  1.98356    1.98356            1                1            1                           1                   0.0200079       0.0200079                  98.3558   98.3558
    2        0.0200739                   0.999998           1.98356    1.98356            1                0.999999     1                           1                   0.0198098       0.0398177                  98.3558   98.3558
    3        0.0300609                   0.999987           1.96372    1.97697            0.99             0.999994     0.996678                    0.999998            0.0196117       0.0594295                  96.3722   97.6968
    4        0.0400479                   0.999953           1.98356    1.97861            1                0.999971     0.997506                    0.999991            0.0198098       0.0792393                  98.3558   97.8611
    5        0.050035                    0.999886           1.98356    1.9796             1                0.999924     0.998004                    0.999978            0.0198098       0.0990491                  98.3558   97.9599
    6        0.10007                     0.998638           1.97564    1.97762            0.996008         0.999435     0.997006                    0.999706            0.098851        0.1979                     97.5639   97.7619
    7        0.150005                    0.992933           1.95976    1.97167            0.988            0.996314     0.994008                    0.998577            0.0978605       0.295761                   95.9755   97.1672
    8        0.20004                     0.978988           1.94397    1.96474            0.98004          0.986573     0.990514                    0.995574            0.0972662       0.393027                   94.3966   96.4742
    9        0.30001                     0.901235           1.91222    1.94724            0.964036         0.944992     0.981691                    0.978719            0.191165        0.584192                   91.2221   94.7241
    10       0.39998                     0.737375           1.84485    1.92165            0.93007          0.827841     0.968789                    0.941009            0.184429        0.768621                   84.4848   92.1649
    11       0.50005                     0.509428           1.56388    1.85005            0.788423         0.623158     0.932694                    0.877401            0.156498        0.925119                   56.3883   85.0053
    12       0.60002                     0.240624           0.487468   1.62303            0.245754         0.374646     0.818242                    0.793636            0.0487322       0.973851                   -51.2532  62.3031
    13       0.69999                     0.0640495          0.152581   1.41303            0.0769231        0.142273     0.71237                     0.700611            0.0152536       0.989105                   -84.7419  41.3027
    14       0.79996                     0.00710982         0.0772815  1.2461             0.038961         0.0280596    0.628215                    0.616563            0.00772583      0.99683                    -92.2719  24.61
    15       0.89993                     0.000152302        0.0277421  1.11076            0.013986         0.00218833   0.559982                    0.548314            0.00277338      0.999604                   -97.2258  11.0757
    16       1                           5.99235e-24        0.0039592  1                  0.00199601       2.18713e-05  0.504145                    0.493447            0.000396197     1                          -99.6041  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06175228336841362
RMSE: 0.24850006713965617
LogLoss: 0.22317683494855173
Mean Per-Class Error: 0.06598527335699345
AUC: 0.9740238089046847
pr_auc: 0.8514344783749965
Gini: 0.9480476178093693
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49956075138241085: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2924  204   0.0652   (204.0/3128.0)
1      204   2845  0.0669   (204.0/3049.0)
Total  3128  3049  0.0661   (408.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.499561     0.933093  203
max f2                       0.357        0.946024  251
max f0point5                 0.569855     0.939597  180
max accuracy                 0.516425     0.93411   197
max precision                0.997239     0.997409  4
max recall                   2.46572e-05  1         399
max specificity              0.999947     0.999361  0
max absolute_mcc             0.516425     0.868282  197
max min_per_class_accuracy   0.499561     0.933093  203
max mean_per_class_accuracy  0.513858     0.934015  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.67 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1           1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999998           2.02591     2.02591            1                0.999999    1                           0.999999            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999985           1.99323     2.01502            0.983871         0.999992    0.994624                    0.999997            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999952           1.99323     2.00957            0.983871         0.99997     0.991935                    0.99999             0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999886           2.02591     2.0128             1                0.999922    0.993528                    0.999977            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.998563           2.02591     2.01935            1                0.999421    0.996764                    0.999699            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.99291            2.0128      2.01717            0.993528         0.996354    0.995685                    0.998584            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.978185           1.97346     2.00624            0.97411          0.986107    0.990291                    0.995464            0.0987209       0.401443                   97.3459   100.624
    9        0.299984                    0.900265           1.96681     1.99311            0.970827         0.946278    0.98381                     0.979087            0.196458        0.597901                   96.6807   99.3111
    10       0.400032                    0.721112           1.862       1.96032            0.919094         0.81623     0.967624                    0.938356            0.186291        0.784192                   86.2002   96.032
    11       0.500081                    0.480827           1.53091     1.87441            0.755663         0.601475    0.925219                    0.870958            0.153165        0.937357                   53.0906   87.441
    12       0.599968                    0.223699           0.394018    1.62794            0.194489         0.348309    0.803562                    0.783944            0.0393572       0.976714                   -60.5982  62.7944
    13       0.700016                    0.0598613          0.134405    1.41448            0.066343         0.134284    0.698196                    0.691092            0.013447        0.990161                   -86.5595  41.4483
    14       0.799903                    0.00703943         0.0722367   1.24687            0.0356564        0.0270075   0.615462                    0.608166            0.00721548      0.997376                   -92.7763  24.6872
    15       0.899951                    0.000183812        0.0163909   1.11008            0.00809061       0.00224672  0.54794                     0.540805            0.00163988      0.999016                   -98.3609  11.0078
    16       1                           2.38508e-23        0.00983452  1                  0.00485437       2.877e-05   0.493605                    0.486701            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:59:32  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:59:34  4:52:51.809  13758 obs/sec     1         1             25000      0.31051          0.365715            0.614308       0.940345        0.754608           1.98356          0.123939                         0.304226           0.356241              0.629726         0.943751          0.742398             2.02591            0.118342
    2019-08-03 20:59:39  4:52:57.258  14575 obs/sec     4         4             100000     0.268857         0.254599            0.710844       0.963571        0.818392           1.98356          0.090782                         0.265627           0.248134              0.717724         0.965442          0.814152             2.02591            0.086126
    2019-08-03 20:59:44  4:53:02.344  15265 obs/sec     7         7             175000     0.258497         0.236735            0.732698       0.969012        0.837544           1.98356          0.0779986                        0.254147           0.230554              0.741596         0.971125          0.833299             2.02591            0.0715558
    2019-08-03 20:59:50  4:53:07.590  15390 obs/sec     10        10            250000     0.253047         0.229063            0.743851       0.972167        0.847038           1.98356          0.0711076                        0.2485             0.223177              0.75295          0.974024          0.851434             2.02591            0.0660515
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.003861290622750073
C28         0.8814699649810791     0.8814699649810791   0.0034036117100172763
C36         0.8435494899749756     0.8435494899749756   0.0032571897354659804
C25         0.8081050515174866     0.8081050515174866   0.003120328457621436
C438        0.7926677465438843     0.7926677465438843   0.0030607205366863324
---         ---                    ---                  ---
C947        0.1548924744129181     0.1548924744129181   0.0005980848589851563
C599        0.1525842398405075     0.1525842398405075   0.0005891720944755998
C482        0.15160004794597626    0.15160004794597626  0.0005853718435422596
C361        0.15080076456069946    0.15080076456069946  0.0005822855781017704
C323        0.14490047097206116    0.14490047097206116  0.0005595028297964889

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_205

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.00486240625631655     0.006188869476318359   0.0         0.020632404184902402  0.08020934462547302  0.06956531808291819     0.267200231552124
    3        2        Softmax                      0.0   0.0   0.00033986224093496276  6.957902223803103e-05  0.0         0.0567002732277615    0.49544525146484375  -0.0015428567774733865  0.17016911506652832


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06371560171547848
RMSE: 0.25241949551387366
LogLoss: 0.2319334850053483
Mean Per-Class Error: 0.06964475123667957
AUC: 0.9714533220428071
pr_auc: 0.8321140952232161
Gini: 0.9429066440856142
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5254820529697231: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4672  369   0.0732   (369.0/5041.0)
1      330   4639  0.0664   (330.0/4969.0)
Total  5002  5008  0.0698   (699.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525482     0.929939  198
max f2                       0.374529     0.941607  245
max f0point5                 0.60734      0.935096  171
max accuracy                 0.542103     0.93037   192
max precision                0.999426     0.996599  1
max recall                   5.3874e-05   1         399
max specificity              0.999934     0.999405  0
max absolute_mcc             0.542103     0.860733  192
max min_per_class_accuracy   0.53471      0.929974  195
max mean_per_class_accuracy  0.542103     0.930355  192
Gains/Lift Table: Avg response rate: 49.64 %, avg score: 49.69 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   1                  2.01449    2.01449            1                1           1                           1                   0.020326        0.020326                   101.449   101.449
    2        0.0200799                   0.999998           1.99434    2.00447            0.99             0.999999    0.995025                    1                   0.0199235       0.0402495                  99.4345   100.447
    3        0.0300699                   0.999989           2.01449    2.0078             1                0.999995    0.996678                    0.999998            0.0201248       0.0603743                  101.449   100.78
    4        0.0400599                   0.999964           2.01449    2.00947            1                0.999979    0.997506                    0.999993            0.0201248       0.0804991                  101.449   100.947
    5        0.05005                     0.999903           2.01449    2.01047            1                0.999937    0.998004                    0.999982            0.0201248       0.100624                   101.449   101.047
    6        0.1                         0.998428           1.99837    2.00443            0.992            0.999418    0.995005                    0.9997              0.0998189       0.200443                   99.8374   100.443
    7        0.15005                     0.992609           1.98232    1.99705            0.984032         0.996122    0.991345                    0.998507            0.0992151       0.299658                   98.2322   99.7054
    8        0.2                         0.976948           1.96614    1.98933            0.976            0.986078    0.987512                    0.995403            0.0982089       0.397867                   96.6142   98.9334
    9        0.3                         0.899976           1.94204    1.97357            0.964036         0.943746    0.979687                    0.978184            0.194204        0.592071                   94.2041   97.3569
    10       0.4                         0.750043           1.84544    1.94154            0.916084         0.831844    0.963786                    0.941599            0.184544        0.776615                   84.5442   94.1538
    11       0.5                         0.524893           1.56772    1.86677            0.778222         0.647747    0.926673                    0.882829            0.156772        0.933387                   56.772    86.6774
    12       0.6                         0.243323           0.41457    1.62474            0.205794         0.382738    0.806527                    0.79948             0.041457        0.974844                   -58.543   62.474
    13       0.7                         0.0619075          0.144898   1.41333            0.0719281        0.142976    0.701584                    0.705694            0.0144898       0.989334                   -85.5102  41.3334
    14       0.8                         0.00659484         0.0684242  1.24522            0.033966         0.026744    0.618132                    0.620825            0.00684242      0.996176                   -93.1576  24.522
    15       0.9                         0.000154262        0.0281747  1.10999            0.013986         0.00201077  0.551005                    0.552068            0.00281747      0.998994                   -97.1825  10.9993
    16       1                           1.9257e-20         0.0100624  1                  0.004995         2.3536e-05  0.496404                    0.496863            0.00100624      1                          -98.9938  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06199976837526262
RMSE: 0.24899752684567497
LogLoss: 0.2234399058287731
Mean Per-Class Error: 0.06832252451225052
AUC: 0.9733976864663187
pr_auc: 0.833620108071112
Gini: 0.9467953729326375
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5256374155489373: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2916  212   0.0678   (212.0/3128.0)
1      210   2839  0.0689   (210.0/3049.0)
Total  3126  3051  0.0683   (422.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525637     0.93082   199
max f2                       0.360881     0.942145  252
max f0point5                 0.59669      0.940092  173
max accuracy                 0.563816     0.931844  186
max precision                0.994211     0.997788  8
max recall                   4.96928e-05  1         399
max specificity              0.999924     0.999361  0
max absolute_mcc             0.563816     0.863878  186
max min_per_class_accuracy   0.525637     0.931125  199
max mean_per_class_accuracy  0.563816     0.931677  186
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.40 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999998           2.02591     2.02591            1                0.999999     1                           1                   0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999989           1.99323     2.01502            0.983871         0.999995     0.994624                    0.999998            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999962           2.02591     2.01774            1                0.999976     0.995968                    0.999992            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999917           2.02591     2.01935            1                0.99994      0.996764                    0.999982            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.998562           2.01935     2.01935            0.996764         0.999445     0.996764                    0.999713            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.992945           2.02591     2.02154            1                0.996291     0.997843                    0.998572            0.101345        0.303378                   102.591   102.154
    8        0.200097                    0.978993           1.98657     2.0128             0.980583         0.986759     0.993528                    0.995619            0.0993768       0.402755                   98.6572   101.28
    9        0.299984                    0.902392           1.95696     1.9942             0.965964         0.946331     0.98435                     0.979207            0.195474        0.598229                   95.6957   99.4204
    10       0.400032                    0.746465           1.86528     1.96196            0.920712         0.831253     0.968434                    0.942204            0.186619        0.784847                   86.528    96.196
    11       0.500081                    0.509734           1.51124     1.87179            0.745955         0.635324     0.923924                    0.880808            0.151197        0.936045                   51.1237   87.1786
    12       0.599968                    0.234505           0.394018    1.62576            0.194489         0.366711     0.802482                    0.795218            0.0393572       0.975402                   -60.5982  62.5757
    13       0.700016                    0.0603092          0.137683    1.41308            0.0679612        0.139706     0.697502                    0.70153             0.013775        0.989177                   -86.2317  41.3077
    14       0.799903                    0.00684372         0.0656697   1.24482            0.0324149        0.02699      0.614451                    0.617298            0.00655953      0.995736                   -93.433   24.4822
    15       0.899951                    0.000159799        0.0327817   1.11008            0.0161812        0.00209046   0.54794                     0.548904            0.00327976      0.999016                   -96.7218  11.0078
    16       1                           1.22655e-24        0.00983452  1                  0.00485437       2.17632e-05  0.493605                    0.493989            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:16:53  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:16:55  4:10:13.255  14196 obs/sec     1         1             25000      0.314711         0.387113            0.603809       0.936778        0.681183           2.01449          0.128172                         0.308667           0.372593              0.618837         0.941008          0.693069             2.02591            0.123037
    2019-08-03 20:17:01  4:10:18.582  14929 obs/sec     4         4             100000     0.270419         0.262401            0.707479       0.962066        0.811533           2.01449          0.0891109                        0.264789           0.248972              0.719502         0.965332          0.806559             2.02591            0.0832119
    2019-08-03 20:17:06  4:10:23.599  15466 obs/sec     7         7             175000     0.258784         0.242042            0.73211        0.96822         0.833849           2.01449          0.0769231                        0.253551           0.230557              0.742806         0.971281          0.843842             2.02591            0.0744698
    2019-08-03 20:17:10  4:10:28.283  16015 obs/sec     10        10            250000     0.252419         0.231933            0.745124       0.971453        0.832114           2.01449          0.0698302                        0.248998           0.22344               0.75196          0.973398          0.83362              2.02591            0.068318
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0041469093583468425
C438        0.8806940913200378     0.8806940913200378   0.0036521585691358335
C36         0.8423514366149902     0.8423514366149902   0.00349315505551561
C28         0.8281362056732178     0.8281362056732178   0.0034342057812921122
C25         0.7993854880332947     0.7993854880332947   0.0033149791612519276
---         ---                    ---                  ---
C506        0.14239366352558136    0.14239366352558136  0.0005904936158435248
C396        0.141520693898201      0.141520693898201    0.0005868734899261886
C274        0.1366003453731537     0.1366003453731537   0.0005664692505813418
C361        0.1322687864303589     0.1322687864303589   0.0005485066682652351
C583        0.12620463967323303    0.12620463967323303  0.0005233592013277212

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_104

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 256,611 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0870977247363336     0.12351953983306885     0.0         -0.0008966843124265452  0.10947439074516296  0.004752722327795545    0.15889286994934082
    3        2        Softmax                 0.0   0.0   0.0017438584281990188  0.00032986525911837816  0.0         0.02861745733002863     0.24856936931610107  -0.0016722969968831214  0.26587677001953125


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06909393302890872
RMSE: 0.26285724838571356
LogLoss: 0.23752414970925168
Mean Per-Class Error: 0.09239318769732019
AUC: 0.9652066401372325
pr_auc: 0.958953301432248
Gini: 0.9304132802744649
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4859514376238665: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4481  520   0.104    (520.0/5001.0)
1      408   4615  0.0812   (408.0/5023.0)
Total  4889  5135  0.0926   (928.0/10024.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.485951     0.908643  209
max f2                       0.226268     0.933171  281
max f0point5                 0.746992     0.923343  134
max accuracy                 0.506653     0.907622  202
max precision                0.996433     1         0
max recall                   0.0018792    1         399
max specificity              0.996433     1         0
max absolute_mcc             0.506653     0.815308  202
max min_per_class_accuracy   0.538288     0.906829  193
max mean_per_class_accuracy  0.506653     0.907607  202
Gains/Lift Table: Avg response rate: 50.11 %, avg score: 50.15 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100758                   0.993683           1.99562    1.99562            1                0.99503     1                           0.99503             0.0201075       0.0201075                  99.562    99.562
    2        0.0200519                   0.992221           1.95571    1.97576            0.98             0.992932    0.99005                     0.993986            0.0195103       0.0396178                  95.5708   97.5763
    3        0.0300279                   0.990888           1.97566    1.97573            0.99             0.991535    0.990033                    0.993172            0.0197093       0.0593271                  97.5664   97.573
    4        0.040004                    0.989754           1.99562    1.98069            1                0.99025     0.992519                    0.992443            0.0199084       0.0792355                  99.562    98.069
    5        0.0500798                   0.988888           1.9561     1.97574            0.980198         0.989317    0.99004                     0.991814            0.0197093       0.0989449                  95.6103   97.5743
    6        0.10006                     0.9842             1.9757     1.97572            0.99002          0.986488    0.99003                     0.989154            0.0987458       0.197691                   97.5704   97.5724
    7        0.15004                     0.979374           1.97969    1.97704            0.992016         0.981818    0.990691                    0.98671             0.0989449       0.296635                   97.9687   97.7044
    8        0.20002                     0.972282           1.95977    1.97273            0.982036         0.97602     0.988529                    0.984039            0.0979494       0.394585                   95.9771   97.2728
    9        0.29998                     0.946313           1.9299     1.95846            0.967066         0.961574    0.981377                    0.976553            0.192913        0.587498                   92.9896   95.8455
    10       0.40004                     0.861756           1.80063    1.91898            0.902293         0.913392    0.961596                    0.960755            0.180171        0.767669                   80.0634   91.898
    11       0.5                         0.539442           1.38419    1.81206            0.693613         0.732739    0.908021                    0.91517             0.138364        0.906032                   38.4188   81.2065
    12       0.59996                     0.157892           0.623382   1.61402            0.312375         0.322704    0.80878                     0.816458            0.0623134       0.968346                   -37.6618  61.4017
    13       0.70002                     0.0362771          0.194986   1.41118            0.0977069        0.0791452   0.70714                     0.711068            0.0195103       0.987856                   -80.5014  41.1182
    14       0.79998                     0.0136634          0.0677157  1.24331            0.0339321        0.022543    0.62302                     0.625034            0.00676886      0.994625                   -93.2284  24.3312
    15       0.89994                     0.00685826         0.0338578  1.10897            0.0169661        0.00980906  0.555703                    0.556699            0.00338443      0.998009                   -96.6142  10.8973
    16       1                           0.00122944         0.0198965  1                  0.00997009       0.00454672  0.501097                    0.501451            0.00199084      1                          -98.0103  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06605730471313044
RMSE: 0.25701615652159
LogLoss: 0.22523156612860376
Mean Per-Class Error: 0.08761425699088798
AUC: 0.9690266252236488
pr_auc: 0.9648705754419366
Gini: 0.9380532504472976
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4839492136755119: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2822  306   0.0978   (306.0/3128.0)
1      236   2813  0.0774   (236.0/3049.0)
Total  3058  3119  0.0877   (542.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.483949     0.912127  211
max f2                       0.223509     0.934824  280
max f0point5                 0.764943     0.925286  132
max accuracy                 0.491217     0.912255  208
max precision                0.99646      1         0
max recall                   0.00573983   1         394
max specificity              0.99646      1         0
max absolute_mcc             0.483949     0.824744  211
max min_per_class_accuracy   0.527628     0.910462  198
max mean_per_class_accuracy  0.483949     0.912386  211
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.39 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.993569           2.02591     2.02591            1                0.994664    1                           0.994664            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.991832           2.02591     2.02591            1                0.992595    1                           0.993629            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.990556           2.02591     2.02591            1                0.991176    1                           0.992812            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.989579           1.96056     2.00957            0.967742         0.990014    0.991935                    0.992112            0.0196786       0.0806822                  96.0558   100.957
    5        0.0500243                   0.988615           2.02591     2.0128             1                0.989123    0.993528                    0.991522            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.983793           2.0128      2.0128             0.993528         0.986141    0.993528                    0.988832            0.100689        0.201378                   101.28    101.28
    7        0.150073                    0.978715           2.0128      2.0128             0.993528         0.981442    0.993528                    0.986368            0.100689        0.302066                   101.28    101.28
    8        0.200097                    0.971922           1.99313     2.00788            0.983819         0.97554     0.9911                      0.983661            0.0997048       0.401771                   99.3128   100.788
    9        0.299984                    0.944821           1.95696     1.99092            0.965964         0.96062     0.982731                    0.975989            0.195474        0.597245                   95.6957   99.0924
    10       0.400032                    0.854554           1.80627     1.94474            0.891586         0.909362    0.959935                    0.959326            0.180715        0.77796                    80.6273   94.4743
    11       0.500081                    0.502485           1.38667     1.83309            0.684466         0.711811    0.904824                    0.909807            0.138734        0.916694                   38.6667   83.3091
    12       0.599968                    0.129386           0.554909    1.62029            0.273906         0.283095    0.799784                    0.805468            0.055428        0.972122                   -44.5091  62.0291
    13       0.700016                    0.0348157          0.180299    1.41448            0.0889968        0.070609    0.698196                    0.700439            0.0180387       0.990161                   -81.9701  41.4483
    14       0.799903                    0.01335            0.0689532   1.24646            0.0340357        0.0215484   0.61526                     0.615664            0.0068875       0.997048                   -93.1047  24.6462
    15       0.899951                    0.00687329         0.0262254   1.11081            0.012945         0.00960675  0.5483                      0.548288            0.00262381      0.999672                   -97.3775  11.0807
    16       1                           0.00118209         0.00327817  1                  0.00161812       0.00466677  0.493605                    0.493899            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:03:46  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:03:53  1:57:11.305  1242 obs/sec      0.34236   1             8559       0.349066         0.477956            0.512609       0.921021        0.742622           1.99562          0.155626                         0.334837           0.436473              0.551462         0.929467          0.751694             2.02591            0.146349
    2019-08-03 18:04:08  1:57:26.265  1234 obs/sec      1.02356   3             25589      0.299166         0.296044            0.641998       0.946741        0.927331           1.99562          0.119812                         0.293289           0.28514               0.655869         0.950281          0.925191             2.02591            0.109924
    2019-08-03 18:04:22  1:57:40.906  1248 obs/sec      1.71096   5             42774      0.293455         0.286761            0.655534       0.950234        0.933133           1.99562          0.113827                         0.287521           0.27568               0.669272         0.953655          0.923076             2.02591            0.111381
    2019-08-03 18:04:38  1:57:56.049  1244 obs/sec      2.40376   7             60094      0.290565         0.281628            0.662286       0.952642        0.932165           1.99562          0.112729                         0.281564           0.264357              0.682834         0.95783           0.947244             2.02591            0.105391
    2019-08-03 18:04:52  1:58:10.808  1245 obs/sec      3.08512   9             77128      0.291259         0.281574            0.66067        0.951538        0.944641           1.99562          0.117618                         0.282164           0.266451              0.681482         0.957002          0.946583             2.02591            0.109114
    2019-08-03 18:05:07  1:58:25.782  1242 obs/sec      3.7644    11            94110      0.289249         0.277752            0.665338       0.953369        0.940284           1.99562          0.113428                         0.278072           0.259215              0.690654         0.958876          0.951814             2.02591            0.102639
    2019-08-03 18:05:22  1:58:40.495  1244 obs/sec      4.448     13            111200     0.289798         0.278978            0.664066       0.953227        0.947076           1.99562          0.112231                         0.279006           0.261114              0.688572         0.958605          0.949259             2.02591            0.105715
    2019-08-03 18:05:37  1:58:55.245  1246 obs/sec      5.13176   15            128294     0.283051         0.268446            0.679527       0.956249        0.949321           1.99562          0.109038                         0.274691           0.255551              0.698129         0.960678          0.95065              2.02591            0.101991
    2019-08-03 18:05:51  1:59:09.781  1249 obs/sec      5.81508   17            145377     0.281171         0.26557             0.68377        0.958671        0.949673           1.99562          0.106844                         0.271075           0.249259              0.706026         0.962765          0.949417             2.02591            0.0977821
    2019-08-03 18:06:06  1:59:24.724  1248 obs/sec      6.50116   19            162529     0.274894         0.253688            0.697732       0.961085        0.955102           1.99562          0.101756                         0.268964           0.243216              0.710587         0.964276          0.955651             1.99323            0.0987534
    2019-08-03 18:06:21  1:59:39.580  1249 obs/sec      7.18884   21            179721     0.278563         0.260286            0.689609       0.959123        0.954997           1.99562          0.107143                         0.271774           0.248439              0.704508         0.962522          0.955243             2.02591            0.102477
    2019-08-03 18:06:37  1:59:55.594  1240 obs/sec      7.87376   23            196844     0.274012         0.253429            0.699667       0.960557        0.956046           1.97586          0.098763                         0.265656           0.239263              0.717662         0.965004          0.958181             2.02591            0.0917921
    2019-08-03 18:06:52  2:00:10.841  1239 obs/sec      8.56068   25            214017     0.272966         0.250946            0.701957       0.961454        0.95563            1.99562          0.0985634                        0.264636           0.236742              0.719826         0.965726          0.957043             2.02591            0.0932492
    2019-08-03 18:07:07  2:00:25.474  1240 obs/sec      9.2412    27            231030     0.266745         0.242451            0.715387       0.963719        0.959549           1.99562          0.0950718                        0.262337           0.233013              0.724672         0.966969          0.959868             2.02591            0.0916302
    2019-08-03 18:07:22  2:00:40.253  1241 obs/sec      9.92548   29            248137     0.271238         0.25121             0.705719       0.962259        0.957463           1.99562          0.0999601                        0.264474           0.238                 0.720168         0.96613           0.957668             2.02591            0.0950299
    2019-08-03 18:07:30  2:00:48.037  1242 obs/sec      10.2644   30            256611     0.262857         0.237524            0.723623       0.965207        0.958953           1.99562          0.0925778                        0.257016           0.225232              0.735728         0.969027          0.964871             2.02591            0.0877449
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004483544336644825
C438        0.8187072277069092     0.8187072277069092   0.0036707101541554976
C374        0.7161297798156738     0.7161297798156738   0.0032107996185952695
C322        0.640562117099762      0.640562117099762    0.0028719886523918565
C863        0.6372122764587402     0.6372122764587402   0.002856969493357141
---         ---                    ---                  ---
C539        0.13370828330516815    0.13370828330516815  0.0005994870163753885
C762        0.13027898967266083    0.13027898967266083  0.000584111626330668
C963        0.13000431656837463    0.13000431656837463  0.000582880117289517
C633        0.12995845079421997    0.12995845079421997  0.0005826744760575601
C888        0.12552298605442047    0.12552298605442047  0.0005627878732430442

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_208

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  --------------------  ------------------
    1        980      Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.005696421975485743   0.00657779723405838   0.0         0.02088162877528064   0.08351370692253113  0.12673625746621955   0.2112107276916504
    3        2        Softmax                      0.0   0.0   0.0002856049926549531  7.29019520804286e-05  0.0         0.004757390753184154  0.5059163570404053   0.000556715619604381  0.1464688777923584


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.06567893104545454
RMSE: 0.25627901015388393
LogLoss: 0.23417075108192306
Mean Per-Class Error: 0.07464839505987553
AUC: 0.9708310823341584
pr_auc: 0.836103414761334
Gini: 0.9416621646683168
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5503004816338857: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4604  345   0.0697   (345.0/4949.0)
1      403   4659  0.0796   (403.0/5062.0)
Total  5007  5004  0.0747   (748.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.5503       0.92569   192
max f2                       0.368037     0.940103  249
max f0point5                 0.607151     0.93364   173
max accuracy                 0.553684     0.925282  191
max precision                0.99991      0.99562   0
max recall                   3.22127e-05  1         399
max specificity              0.99991      0.999394  0
max absolute_mcc             0.553684     0.850652  191
max min_per_class_accuracy   0.541788     0.923943  195
max mean_per_class_accuracy  0.553684     0.925352  191
Gains/Lift Table: Avg response rate: 50.56 %, avg score: 50.59 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   1                  1.97768     1.97768            1                1            1                           1                   0.0199526       0.0199526                  97.7677   97.7677
    2        0.0200779                   0.999997           1.9579      1.96784            0.99             0.999999     0.995025                    0.999999            0.0195575       0.0395101                  95.79     96.7838
    3        0.0300669                   0.999986           1.9579      1.96454            0.99             0.999992     0.993355                    0.999997            0.0195575       0.0590676                  95.79     96.4536
    4        0.0400559                   0.999953           1.9579      1.96288            0.99             0.999972     0.992519                    0.999991            0.0195575       0.078625                   95.79     96.2881
    5        0.050045                    0.999881           1.97768     1.96583            1                0.999919     0.994012                    0.999976            0.019755        0.0983801                  97.7677   96.5834
    6        0.10009                     0.998164           1.96978     1.96781            0.996008         0.999283     0.99501                     0.99963             0.0985776       0.196958                   96.9782   96.7808
    7        0.150035                    0.99184            1.9579      1.96451            0.99             0.995651     0.993342                    0.998305            0.0977874       0.294745                   95.79     96.451
    8        0.20008                     0.979402           1.9461      1.9599             0.984032         0.986256     0.991013                    0.995291            0.0973923       0.392137                   94.6097   95.9904
    9        0.30007                     0.906478           1.90853     1.94278            0.965035         0.948733     0.982357                    0.979777            0.190834        0.582971                   90.8527   94.2784
    10       0.40006                     0.762676           1.83345     1.91546            0.927073         0.839825     0.968539                    0.944798            0.183327        0.766298                   83.3451   91.5458
    11       0.50005                     0.548402           1.54105     1.84059            0.779221         0.660791     0.930683                    0.888008            0.154089        0.920387                   54.1047   84.0591
    12       0.60004                     0.279051           0.503804    1.61783            0.254745         0.414883     0.818046                    0.809167            0.0503753       0.970763                   -49.6196  61.783
    13       0.70003                     0.0758031          0.18374     1.41299            0.0929071        0.167087     0.714469                    0.717454            0.0183722       0.989135                   -81.626   41.2989
    14       0.80002                     0.00866629         0.0711252   1.24528            0.035964         0.0335412    0.629667                    0.631976            0.00711181      0.996247                   -92.8875  24.5277
    15       0.90001                     0.000231534        0.0276598   1.11               0.013986         0.00268523   0.561265                    0.562062            0.00276571      0.999012                   -97.234   11.0001
    16       1                           4.80192e-23        0.00987851  1                  0.004995         3.88038e-05  0.505644                    0.505866            0.000987752     1                          -99.0121  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06384389733290895
RMSE: 0.2526734994670176
LogLoss: 0.2275464881748065
Mean Per-Class Error: 0.07161717732282358
AUC: 0.9725329213636772
pr_auc: 0.8341523370561027
Gini: 0.9450658427273544
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5475255575381821: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2919  209   0.0668   (209.0/3128.0)
1      233   2816  0.0764   (233.0/3049.0)
Total  3152  3025  0.0716   (442.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.547526     0.927231  187
max f2                       0.369762     0.942762  245
max f0point5                 0.588799     0.934719  174
max accuracy                 0.549727     0.928444  186
max precision                0.995849     0.997602  6
max recall                   4.61775e-05  1         399
max specificity              0.999909     0.999361  0
max absolute_mcc             0.549727     0.856888  186
max min_per_class_accuracy   0.536585     0.927189  191
max mean_per_class_accuracy  0.547526     0.928383  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.78 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999995           1.99323     2.00957            0.983871         0.999998     0.991935                    0.999999            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999977           2.02591     2.01502            1                0.999988     0.994624                    0.999995            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999942           1.99323     2.00957            0.983871         0.999962     0.991935                    0.999987            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999859           2.02591     2.0128             1                0.999902     0.993528                    0.99997             0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.998365           2.02591     2.01935            1                0.999314     0.996764                    0.999642            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.992488           2.00624     2.01498            0.990291         0.996142     0.994606                    0.998476            0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.979399           1.98657     2.00788            0.980583         0.986384     0.9911                      0.995453            0.0993768       0.401771                   98.6572   100.788
    9        0.299984                    0.907069           1.96024     1.99202            0.967585         0.949089     0.98327                     0.980015            0.195802        0.597573                   96.024    99.2017
    10       0.400032                    0.743501           1.86528     1.96032            0.920712         0.830671     0.967624                    0.942664            0.186619        0.784192                   86.528    96.032
    11       0.500081                    0.520694           1.47518     1.86326            0.728155         0.635848     0.919715                    0.881281            0.147589        0.931781                   47.5177   86.326
    12       0.599968                    0.258737           0.436703    1.62576            0.215559         0.383403     0.802482                    0.798391            0.0436209       0.975402                   -56.3297  62.5757
    13       0.700016                    0.0700127          0.14424     1.41401            0.0711974        0.153124     0.697965                    0.706167            0.014431        0.989833                   -85.576   41.4014
    14       0.799903                    0.00916172         0.0689532   1.24605            0.0340357        0.0321202    0.615058                    0.621997            0.0068875       0.99672                    -93.1047  24.6052
    15       0.899951                    0.000265935        0.0229472   1.11008            0.0113269        0.00288134   0.54794                     0.553169            0.00229583      0.999016                   -97.7053  11.0078
    16       1                           1.06672e-21        0.00983452  1                  0.00485437       4.33676e-05  0.493605                    0.497829            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:21:16  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:21:18  4:14:35.741  14188 obs/sec     1         1             25000      0.309064         0.343768            0.617868       0.940873        0.773175           1.9581           0.12766                          0.304743           0.336832              0.628466         0.94267           0.772305             2.02591            0.11899
    2019-08-03 20:21:23  4:14:41.067  14909 obs/sec     4         4             100000     0.270807         0.256447            0.706616       0.963344        0.855948           1.9581           0.0925981                        0.266615           0.24944               0.715618         0.965068          0.8723               2.02591            0.0864497
    2019-08-03 20:21:28  4:14:46.154  15326 obs/sec     7         7             175000     0.26224          0.24308             0.724886       0.967872        0.85302            1.97768          0.080012                         0.257807           0.235214              0.734099         0.969947          0.855833             2.02591            0.074146
    2019-08-03 20:21:33  4:14:51.311  15498 obs/sec     10        10            250000     0.256279         0.234171            0.737251       0.970831        0.836103           1.97768          0.0747178                        0.252673           0.227546              0.744583         0.972533          0.834152             2.02591            0.0715558
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004091728096013774
C35         0.884331226348877      0.884331226348877    0.003618442925034016
C28         0.8421003818511963     0.8421003818511963   0.0034456457920844672
C36         0.83038330078125       0.83038330078125     0.003397702682267297
C438        0.8290384411811829     0.8290384411811829   0.0033921998824565083
---         ---                    ---                  ---
C667        0.14373502135276794    0.14373502135276794  0.0005881246252502603
C573        0.14120860397815704    0.14120860397815704  0.0005777872122963076
C439        0.13810744881629944    0.13810744881629944  0.0005650981285904367
C476        0.13195586204528809    0.13195586204528809  0.0005399275081644228
C721        0.12866030633449554    0.12866030633449554  0.0005264429902705944

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_148

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 252,734 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.07027205811296436    0.10323899984359741    0.0         0.0015094355959224008   0.10195779800415039  -0.008281164253767686   0.1279492974281311
    3        2        Softmax                 0.0   0.0   0.0019857423892517545  0.0005774225573986769  0.0         -0.0016464595781826574  0.2514113187789917   0.00027839410745628124  0.20022982358932495


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07203224036120516
RMSE: 0.2683882269422509
LogLoss: 0.24449504874083566
Mean Per-Class Error: 0.09349143298083162
AUC: 0.9634478565313257
pr_auc: 0.9579175803754426
Gini: 0.9268957130626514
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47204233928156875: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4460  520   0.1044   (520.0/4980.0)
1      426   4612  0.0846   (426.0/5038.0)
Total  4886  5132  0.0944   (946.0/10018.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.472042     0.906981  212
max f2                       0.147276     0.930317  310
max f0point5                 0.732143     0.916863  138
max accuracy                 0.54744      0.906468  191
max precision                0.99662      1         0
max recall                   0.00337723   1         397
max specificity              0.99662      1         0
max absolute_mcc             0.54744      0.813038  191
max min_per_class_accuracy   0.518018     0.904724  198
max mean_per_class_accuracy  0.54744      0.906509  191
Gains/Lift Table: Avg response rate: 50.29 %, avg score: 49.72 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100819                   0.994303           1.9688     1.9688             0.990099         0.99542     0.990099                    0.99542             0.0198491       0.0198491                  96.88     96.88
    2        0.0200639                   0.993013           1.98849    1.97859            1                0.993616    0.995025                    0.994522            0.0198491       0.0396983                  98.8487   97.8595
    3        0.0300459                   0.99195            1.98849    1.98188            1                0.992468    0.996678                    0.99384             0.0198491       0.0595474                  98.8487   98.1881
    4        0.0400279                   0.990935           1.98849    1.98353            1                0.991483    0.997506                    0.993252            0.0198491       0.0793966                  98.8487   98.3529
    5        0.05001                     0.989977           1.9686     1.98055            0.99             0.990438    0.996008                    0.99269             0.0196507       0.0990472                  96.8603   98.0549
    6        0.10002                     0.985287           1.96864    1.9746             0.99002          0.98758     0.993014                    0.990135            0.0984518       0.197499                   96.8642   97.4596
    7        0.15003                     0.979574           1.97658    1.97526            0.994012         0.982682    0.993347                    0.987651            0.0988487       0.296348                   97.658    97.5257
    8        0.20004                     0.971737           1.94086    1.96666            0.976048         0.975941    0.989022                    0.984723            0.0970623       0.39341                    94.0859   96.6658
    9        0.30006                     0.940541           1.91506    1.94946            0.963074         0.959299    0.980373                    0.976249            0.191544        0.584954                   91.506    94.9459
    10       0.39998                     0.838572           1.76203    1.90264            0.886114         0.898712    0.956826                    0.956879            0.176062        0.761016                   76.2026   90.2636
    11       0.5                         0.522182           1.41893    1.80588            0.713573         0.707367    0.908165                    0.906967            0.141921        0.902938                   41.8931   80.5875
    12       0.60002                     0.150353           0.61917    1.60806            0.311377         0.312925    0.808684                    0.807943            0.0619293       0.964867                   -38.083   60.8058
    13       0.70004                     0.0412968          0.238142   1.41233            0.11976          0.0833722   0.710252                    0.704418            0.023819        0.988686                   -76.1858  41.2328
    14       0.79996                     0.0152567          0.0695275  1.2446             0.034965         0.0251938   0.625905                    0.619579            0.0069472       0.995633                   -93.0472  24.4604
    15       0.89998                     0.0075994          0.0277833  1.10937            0.0139721        0.0109493   0.557897                    0.551938            0.00277888      0.998412                   -97.2217  10.9371
    16       1                           0.00114213         0.0158761  1                  0.00798403       0.00497389  0.502895                    0.497231            0.00158793      1                          -98.4124  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06651190929415438
RMSE: 0.2578990292617527
LogLoss: 0.227741613397326
Mean Per-Class Error: 0.08569609842311299
AUC: 0.9678875154236977
pr_auc: 0.9620846902856043
Gini: 0.9357750308473953
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47898185796188275: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2834  294   0.094    (294.0/3128.0)
1      236   2813  0.0774   (236.0/3049.0)
Total  3070  3107  0.0858   (530.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.478982     0.913905  210
max f2                       0.217108     0.93395   280
max f0point5                 0.729066     0.923242  139
max accuracy                 0.49703      0.914198  205
max precision                0.996662     1         0
max recall                   0.00524009   1         395
max specificity              0.996662     1         0
max absolute_mcc             0.478982     0.828555  210
max min_per_class_accuracy   0.518294     0.913414  199
max mean_per_class_accuracy  0.478982     0.914304  210
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.11 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.994348           2.02591     2.02591            1                0.995466   1                           0.995466            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.992923           2.02591     2.02591            1                0.993572   1                           0.994519            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.991961           1.99323     2.01502            0.983871         0.992433   0.994624                    0.993824            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.990864           2.02591     2.01774            1                0.991433   0.995968                    0.993226            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.989972           2.02591     2.01935            1                0.990419   0.996764                    0.992672            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.985143           2.00624     2.0128             0.990291         0.987704   0.993528                    0.990188            0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.979578           2.00624     2.01061            0.990291         0.982464   0.992449                    0.987613            0.100361        0.301738                   100.624   101.061
    8        0.200097                    0.970662           1.9669      1.99968            0.970874         0.975217   0.987055                    0.984514            0.0983929       0.400131                   96.6903   99.9685
    9        0.299984                    0.93924            1.96024     1.98655            0.967585         0.957439   0.980572                    0.975499            0.195802        0.595933                   96.024    98.6551
    10       0.400032                    0.838947           1.80299     1.94064            0.889968         0.899324   0.957912                    0.956448            0.180387        0.77632                    80.2994   94.0643
    11       0.500081                    0.489419           1.43256     1.83899            0.70712          0.696633   0.907737                    0.904468            0.143326        0.919646                   43.2561   83.8994
    12       0.599968                    0.127383           0.538492    1.62248            0.265802         0.273536   0.800863                    0.799426            0.0537881       0.973434                   -46.1508  62.2477
    13       0.700016                    0.0388807          0.177021    1.41589            0.0873786        0.0743108  0.69889                     0.69579             0.0177107       0.991145                   -82.2979  41.5888
    14       0.799903                    0.0149056          0.0591027   1.24646            0.0291734        0.0243043  0.61526                     0.611939            0.00590357      0.997048                   -94.0897  24.6462
    15       0.899951                    0.00751963         0.0262254   1.11081            0.012945         0.0106272  0.5483                      0.545091            0.00262381      0.999672                   -97.3775  11.0807
    16       1                           0.00106877         0.00327817  1                  0.00161812       0.0050354  0.493605                    0.491059            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:50:14  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:50:21  2:43:40.040  1239 obs/sec      0.35844   1             8961       0.340207         0.463436            0.537021       0.923642        0.722401           1.98849          0.147534                         0.333795           0.425993              0.554251         0.931054          0.788598             2.02591            0.144569
    2019-08-03 18:50:37  2:43:55.497  1240 obs/sec      1.07632   3             26908      0.300926         0.29874             0.637763       0.945514        0.927254           1.98849          0.12198                          0.29535            0.285636              0.651015         0.950147          0.926766             2.02591            0.119314
    2019-08-03 18:50:53  2:44:11.038  1243 obs/sec      1.7982    5             44955      0.2936           0.287228            0.655186       0.949428        0.934816           1.9688           0.117788                         0.283912           0.267394              0.677523         0.956334          0.934046             2.02591            0.1062
    2019-08-03 18:51:08  2:44:26.723  1243 obs/sec      2.52244   7             63061      0.292912         0.284356            0.656799       0.950537        0.941113           1.98849          0.114394                         0.283955           0.269056              0.677426         0.955554          0.939381             2.02591            0.11041
    2019-08-03 18:51:24  2:44:42.301  1246 obs/sec      3.2476    9             81190      0.292096         0.284999            0.658709       0.951434        0.936168           1.98849          0.114494                         0.283516           0.268382              0.678422         0.956374          0.939255             2.02591            0.109762
    2019-08-03 18:51:39  2:44:57.945  1248 obs/sec      3.9752    11            99380      0.287191         0.277133            0.670075       0.954392        0.938252           1.98849          0.111699                         0.276879           0.258964              0.693303         0.959525          0.937006             2.02591            0.102153
    2019-08-03 18:51:55  2:45:13.224  1251 obs/sec      4.69216   13            117304     0.290776         0.285032            0.661787       0.953577        0.937729           1.98849          0.113096                         0.280204           0.265208              0.685891         0.95886           0.935318             2.02591            0.101829
    2019-08-03 18:52:11  2:45:29.858  1238 obs/sec      5.4122    15            135305     0.282615         0.267313            0.680505       0.956555        0.95121            1.9688           0.106009                         0.27321            0.251949              0.701375         0.961832          0.956586             1.99323            0.0998867
    2019-08-03 18:52:27  2:45:45.404  1238 obs/sec      6.12784   17            153196     0.278405         0.262144            0.689953       0.959035        0.946318           1.98849          0.105211                         0.270759           0.24858               0.70671          0.962917          0.947133             2.02591            0.0960013
    2019-08-03 18:52:43  2:46:01.011  1239 obs/sec      6.84856   19            171214     0.277224         0.258348            0.692577       0.959614        0.956006           1.94911          0.102915                         0.267716           0.242837              0.713266         0.96444           0.95601              1.99323            0.0940586
    2019-08-03 18:52:58  2:46:16.777  1240 obs/sec      7.58384   21            189596     0.273032         0.252515            0.701805       0.960783        0.951489           1.9688           0.0980236                        0.264245           0.237736              0.720652         0.965686          0.959838             2.02591            0.0896876
    2019-08-03 18:53:14  2:46:32.487  1241 obs/sec      8.31016   23            207754     0.274123         0.258078            0.699416       0.961013        0.955454           1.9688           0.100419                         0.266559           0.247431              0.715739         0.964421          0.95764              1.99323            0.0924397
    2019-08-03 18:53:29  2:46:47.874  1242 obs/sec      9.02724   25            225681     0.268388         0.244495            0.711861       0.963448        0.957918           1.9688           0.09443                          0.257899           0.227742              0.733909         0.967888          0.962085             2.02591            0.0858022
    2019-08-03 18:53:45  2:47:03.659  1242 obs/sec      9.74992   27            243748     0.267545         0.243643            0.713669       0.964928        0.959901           1.9688           0.0942304                        0.258496           0.229283              0.732676         0.968169          0.959269             1.96056            0.0877449
    2019-08-03 18:53:53  2:47:11.719  1243 obs/sec      10.1094   28            252734     0.273518         0.251735            0.700742       0.961511        0.955138           1.98849          0.098323                         0.267635           0.242823              0.71344          0.964383          0.955117             2.02591            0.0929254
    2019-08-03 18:53:54  2:47:12.816  1242 obs/sec      10.1094   28            252734     0.268388         0.244495            0.711861       0.963448        0.957918           1.9688           0.09443                          0.257899           0.227742              0.733909         0.967888          0.962085             2.02591            0.0858022
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0041392555044947295
C438        0.877912163734436      0.877912163734436    0.003633902756200643
C374        0.7725176811218262     0.7725176811218262   0.0031976480639030235
C88         0.7122465968132019     0.7122465968132019   0.0029481706464166845
C322        0.6740719676017761     0.6740719676017761   0.002790156102321245
---         ---                    ---                  ---
C737        0.15603980422019958    0.15603980422019958  0.0006458886185387411
C857        0.15495528280735016    0.15495528280735016  0.0006413995073108617
C973        0.15425249934196472    0.15425249934196472  0.0006384905069832972
C880        0.1529727727174759     0.1529727727174759   0.0006331933915086333
C908        0.14850006997585297    0.14850006997585297  0.0006146797320654019

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_191

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,979 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.07109060087577235   0.10499706864356995    0.0         -0.0002385985003734517  0.10838428139686584  0.019629335012897608   0.14168739318847656
    3        2        Softmax                 0.0   0.0   0.001919030863291482  0.0004850245313718915  0.0         0.01667087329030892     0.24341517686843872  0.0006794539378476988  0.22944551706314087


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07403295843157509
RMSE: 0.27208998223303826
LogLoss: 0.2536193770159358
Mean Per-Class Error: 0.0973086899896658
AUC: 0.9614270972807403
pr_auc: 0.9559597207819943
Gini: 0.9228541945614805
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44078986852344193: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4425  573   0.1146   (573.0/4998.0)
1      410   4601  0.0818   (410.0/5011.0)
Total  4835  5174  0.0982   (983.0/10009.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.44079      0.903486  219
max f2                       0.14481      0.931348  309
max f0point5                 0.772816     0.914916  126
max accuracy                 0.546566     0.902688  190
max precision                0.996794     1         0
max recall                   0.00300431   1         397
max specificity              0.996794     1         0
max absolute_mcc             0.546566     0.805391  190
max min_per_class_accuracy   0.533242     0.901761  193
max mean_per_class_accuracy  0.546566     0.902691  190
Gains/Lift Table: Avg response rate: 50.06 %, avg score: 49.85 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100909                   0.994558           1.99741    1.99741            1                0.995674    1                           0.995674            0.0201557       0.0201557                  99.7406   99.7406
    2        0.0200819                   0.993242           1.99741    1.99741            1                0.993844    1                           0.994763            0.0199561       0.0401118                  99.7406   99.7406
    3        0.0300729                   0.992438           1.99741    1.99741            1                0.992812    1                           0.994115            0.0199561       0.0600679                  99.7406   99.7406
    4        0.0400639                   0.991762           1.97743    1.99242            0.99             0.992109    0.997506                    0.993615            0.0197565       0.0798244                  97.7432   99.2425
    5        0.050055                    0.991016           1.99741    1.99342            1                0.991361    0.998004                    0.993165            0.0199561       0.0997805                  99.7406   99.3419
    6        0.10001                     0.987569           1.97743    1.98543            0.99             0.9893      0.994006                    0.991234            0.0987827       0.198563                   97.7432   98.5433
    7        0.150065                    0.983614           1.96551    1.97879            0.984032         0.985693    0.990679                    0.989386            0.0983836       0.296947                   96.5511   97.8788
    8        0.20002                     0.978264           1.94947    1.97147            0.976            0.981143    0.987013                    0.987327            0.0973858       0.394332                   94.9468   97.1465
    9        0.30003                     0.955197           1.92358    1.9555             0.963037         0.968859    0.979021                    0.981171            0.192377        0.586709                   92.3576   95.5502
    10       0.40004                     0.867452           1.75995    1.90661            0.881119         0.922087    0.954545                    0.9664              0.176013        0.762722                   75.9952   90.6615
    11       0.50005                     0.533364           1.38881    1.80305            0.695305         0.728225    0.902697                    0.918765            0.138894        0.901616                   38.8806   80.3053
    12       0.59996                     0.123777           0.661141   1.61289            0.331            0.294968    0.807494                    0.814885            0.0660547       0.967671                   -33.8859  61.2893
    13       0.69997                     0.0289314          0.191559   1.40982            0.0959041        0.0643708   0.705824                    0.707654            0.0191579       0.986829                   -80.8441  40.9816
    14       0.79998                     0.0117937          0.067844   1.24205            0.033966         0.0187029   0.621831                    0.621524            0.00678507      0.993614                   -93.2156  24.2049
    15       0.89999                     0.00628799         0.0419036  1.10868            0.020979         0.00858034  0.555062                    0.553412            0.00419078      0.997805                   -95.8096  10.8684
    16       1                           0.000651776        0.0219495  1                  0.010989         0.00434372  0.500649                    0.498499            0.00219517      1                          -97.805   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06711858419927962
RMSE: 0.2590725462091258
LogLoss: 0.22996394782754864
Mean Per-Class Error: 0.08590318069988978
AUC: 0.9679743327022654
pr_auc: 0.9610031912575281
Gini: 0.9359486654045308
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43882023334032605: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2818  310   0.0991   (310.0/3128.0)
1      226   2823  0.0741   (226.0/3049.0)
Total  3044  3133  0.0868   (536.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.43882      0.913297  217
max f2                       0.139904     0.933266  308
max f0point5                 0.756952     0.921553  131
max accuracy                 0.55225      0.914198  187
max precision                0.996664     1         0
max recall                   0.00370847   1         396
max specificity              0.996664     1         0
max absolute_mcc             0.55225      0.828414  187
max min_per_class_accuracy   0.514481     0.913363  197
max mean_per_class_accuracy  0.55225      0.914097  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.15 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.994562           2.02591     2.02591            1                0.995609    1                           0.995609            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.993273           2.02591     2.02591            1                0.993825    1                           0.994717            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.992315           2.02591     2.02591            1                0.992766    1                           0.994066            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.991588           2.02591     2.02591            1                0.99194     1                           0.993535            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.990777           2.02591     2.02591            1                0.991182    1                           0.99307             0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.987057           2.0128      2.01935            0.993528         0.989012    0.996764                    0.991041            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.983421           2.0128      2.01717            0.993528         0.985317    0.995685                    0.989133            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.978223           1.98657     2.00952            0.980583         0.980856    0.991909                    0.987064            0.0993768       0.402099                   98.6572   100.952
    9        0.299984                    0.955715           1.93726     1.98546            0.95624          0.968734    0.980032                    0.98096             0.193506        0.595605                   93.7256   98.5458
    10       0.400032                    0.860096           1.81611     1.9431             0.89644          0.920473    0.959126                    0.965832            0.181699        0.777304                   81.6107   94.3103
    11       0.500081                    0.47375            1.40306     1.83506            0.692557         0.70387     0.905795                    0.913423            0.140374        0.917678                   40.3058   83.5059
    12       0.599968                    0.108911           0.535208    1.61865            0.264182         0.257629    0.798975                    0.804242            0.0534602       0.971138                   -46.4792  61.8651
    13       0.700016                    0.0282291          0.203247    1.41636            0.100324         0.0585136   0.699121                    0.69766             0.0203345       0.991473                   -79.6753  41.6357
    14       0.799903                    0.0113786          0.0525358   1.24605            0.0259319        0.0182611   0.615058                    0.612821            0.00524762      0.99672                    -94.7464  24.6052
    15       0.899951                    0.00619429         0.0262254   1.11044            0.012945         0.00846037  0.54812                     0.545634            0.00262381      0.999344                   -97.3775  11.0442
    16       1                           0.000657425        0.00655634  1                  0.00323625       0.00428597  0.493605                    0.491473            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:00:40  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:00:47  3:54:05.289  1260 obs/sec      0.34788   1             8697       0.360408         0.485859            0.480424       0.912775        0.773976           1.99741          0.171546                         0.347329           0.44603               0.517371         0.922194          0.785409             2.02591            0.156872
    2019-08-03 20:01:02  3:54:20.837  1221 obs/sec      1.04428   3             26107      0.307942         0.313418            0.620687       0.940889        0.925032           1.99741          0.126786                         0.294616           0.28672               0.65275          0.950004          0.926048             2.02591            0.115914
    2019-08-03 20:01:18  3:54:36.115  1222 obs/sec      1.73956   5             43489      0.297429         0.296207            0.646142       0.946608        0.925784           1.99741          0.118194                         0.284562           0.270793              0.676045         0.95514           0.935559             2.02591            0.108143
    2019-08-03 20:01:33  3:54:51.756  1218 obs/sec      2.43756   7             60939      0.293282         0.287919            0.655943       0.949228        0.935603           1.99741          0.112599                         0.280876           0.263326              0.684383         0.957698          0.951438             2.02591            0.104258
    2019-08-03 20:01:48  3:55:06.843  1223 obs/sec      3.13128   9             78282      0.29953          0.297488            0.641126       0.945947        0.934319           1.99741          0.12169                          0.286777           0.273293              0.670981         0.954339          0.944137             2.02591            0.112352
    2019-08-03 20:02:03  3:55:21.996  1226 obs/sec      3.82152   11            95538      0.293492         0.286287            0.655448       0.949774        0.940377           1.93808          0.116295                         0.279212           0.260711              0.688112         0.958623          0.954376             2.02591            0.102477
    2019-08-03 20:02:19  3:55:37.388  1222 obs/sec      4.50804   13            112701     0.284838         0.272038            0.675468       0.954448        0.944818           1.99741          0.109801                         0.272879           0.251055              0.7021           0.961268          0.956305             2.02591            0.0990772
    2019-08-03 20:02:34  3:55:52.738  1222 obs/sec      5.20236   15            130059     0.285392         0.275973            0.674205       0.953615        0.939044           1.99741          0.106904                         0.271765           0.249598              0.704527         0.961819          0.946729             1.99323            0.0953537
    2019-08-03 20:02:51  3:56:09.108  1210 obs/sec      5.89196   17            147299     0.283103         0.268066            0.67941        0.956416        0.948042           1.99741          0.110301                         0.269232           0.242954              0.710009         0.964341          0.954165             2.02591            0.0985915
    2019-08-03 20:03:06  3:56:24.554  1211 obs/sec      6.58948   19            164737     0.286861         0.276898            0.670843       0.954086        0.946184           1.97763          0.107903                         0.273285           0.250978              0.701211         0.961747          0.950367             2.02591            0.0981059
    2019-08-03 20:03:21  3:56:39.942  1210 obs/sec      7.2754    21            181885     0.280804         0.266117            0.684595       0.95696         0.945286           1.95785          0.105005                         0.267185           0.241611              0.714402         0.96433           0.959817             2.02591            0.0935729
    2019-08-03 20:03:37  3:56:55.102  1213 obs/sec      7.97064   23            199266     0.280835         0.265648            0.684527       0.957139        0.94556            1.95785          0.106105                         0.267031           0.24352               0.714732         0.963406          0.954098             2.02591            0.0930873
    2019-08-03 20:03:52  3:57:10.296  1212 obs/sec      8.652     25            216300     0.279128         0.264281            0.688349       0.958047        0.947857           1.97763          0.103007                         0.266388           0.243263              0.716104         0.963746          0.958925             1.99323            0.0927635
    2019-08-03 20:04:07  3:57:25.592  1213 obs/sec      9.34488   27            233622     0.271608         0.250328            0.704916       0.961637        0.949651           1.99741          0.0990109                        0.260294           0.231077              0.728943         0.967213          0.959566             2.02591            0.0896876
    2019-08-03 20:04:22  3:57:40.943  1214 obs/sec      10.0392   29            250979     0.27209          0.253619            0.703868       0.961427        0.95596            1.99741          0.0982116                        0.259073           0.229964              0.731482         0.967974          0.961003             2.02591            0.0867735
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0045832559327524105
C438        0.8363859057426453     0.8363859057426453   0.0038333706645654773
C374        0.7265923619270325     0.7265923619270325   0.0033301587534946583
C322        0.6758264303207397     0.6758264303207397   0.003097485496278414
C88         0.6439009308815002     0.6439009308815002   0.0029511627615674356
---         ---                    ---                  ---
C888        0.1354781985282898     0.1354781985282898   0.0006209312571633931
C945        0.13384756445884705    0.13384756445884705  0.0006134576438904714
C925        0.13196566700935364    0.13196566700935364  0.0006048324262402491
C810        0.1310555785894394     0.1310555785894394   0.0006006612580903479
C876        0.13069894909858704    0.13069894909858704  0.0005990267338606043

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_96

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 258,185 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.06776318852471053    0.10597270727157593    0.0         -0.0003838109400962534  0.10942786931991577  0.011503505881305543    0.13918161392211914
    3        2        Softmax                 0.0   0.0   0.0020032382512908953  0.0005883453413844109  0.0         0.014309581834140772    0.2496492862701416   -0.0026221297354460105  0.24839144945144653


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07350650742045521
RMSE: 0.27112083545986504
LogLoss: 0.2488530067986519
Mean Per-Class Error: 0.09745549297331613
AUC: 0.9622904701698156
pr_auc: 0.9524188772008229
Gini: 0.9245809403396312
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5252535403587739: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4482  525   0.1049   (525.0/5007.0)
1      452   4567  0.0901   (452.0/5019.0)
Total  4934  5092  0.0974   (977.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525254     0.903373  198
max f2                       0.238567     0.928494  278
max f0point5                 0.801232     0.916333  114
max accuracy                 0.525254     0.902553  198
max precision                0.994871     1         0
max recall                   0.00285322   1         398
max specificity              0.994871     1         0
max absolute_mcc             0.525254     0.805188  198
max min_per_class_accuracy   0.554862     0.902337  189
max mean_per_class_accuracy  0.525254     0.902545  198
Gains/Lift Table: Avg response rate: 50.06 %, avg score: 50.63 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.99308            1.99761    1.99761            1                0.994224    1                           0.994224            0.0201235       0.0201235                  99.7609   99.7609
    2        0.0200479                   0.991359           1.97763    1.98767            0.99             0.992233    0.995025                    0.993233            0.019725        0.0398486                  97.7633   98.7671
    3        0.0300219                   0.990261           1.99761    1.99097            1                0.990801    0.996678                    0.992425            0.0199243       0.0597729                  99.7609   99.0973
    4        0.0400958                   0.989316           1.99761    1.99264            1                0.989797    0.997512                    0.991765            0.0201235       0.0798964                  99.7609   99.264
    5        0.0500698                   0.988364           1.99761    1.99363            1                0.988833    0.998008                    0.991181            0.0199243       0.0998207                  99.7609   99.363
    6        0.10004                     0.983276           1.97369    1.98367            0.988024         0.985873    0.993021                    0.98853             0.0986252       0.198446                   97.3686   98.3668
    7        0.15001                     0.976768           1.98565    1.98433            0.994012         0.980253    0.993351                    0.985773            0.099223        0.297669                   98.5647   98.4327
    8        0.20008                     0.968641           1.9419     1.97371            0.972112         0.972961    0.988036                    0.982567            0.0972305       0.394899                   94.1899   97.3709
    9        0.30002                     0.941596           1.92584    1.95776            0.964072         0.956474    0.980053                    0.973875            0.192469        0.587368                   92.5839   95.7763
    10       0.40006                     0.853151           1.76658    1.90996            0.884347         0.905924    0.956121                    0.956883            0.176728        0.764096                   76.658    90.9955
    11       0.5                         0.554694           1.3756     1.80315            0.688623         0.733125    0.902653                    0.912158            0.137478        0.901574                   37.5599   80.3148
    12       0.60004                     0.180993           0.631348   1.60778            0.316052         0.350062    0.804854                    0.818444            0.06316         0.964734                   -36.8652  60.7783
    13       0.69998                     0.0504713          0.221292   1.40983            0.110778         0.100542    0.705757                    0.715945            0.022116        0.98685                    -77.8708  40.9826
    14       0.80002                     0.019265           0.0657239  1.24175            0.0329013        0.0316014   0.621618                    0.63037             0.00657501      0.993425                   -93.4276  24.175
    15       0.89996                     0.00938533         0.0478469  1.10917            0.0239521        0.0138401   0.555248                    0.561905            0.00478183      0.998207                   -95.2153  10.9168
    16       1                           0.00137544         0.0179247  1                  0.00897308       0.00600549  0.500598                    0.506293            0.00179319      1                          -98.2075  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06826197516554693
RMSE: 0.2612699277864694
LogLoss: 0.23402122525326324
Mean Per-Class Error: 0.08990013077114711
AUC: 0.966321868559479
pr_auc: 0.9642158501703181
Gini: 0.932643737118958
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4655096930962633: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2780  348   0.1113   (348.0/3128.0)
1      209   2840  0.0685   (209.0/3049.0)
Total  2989  3188  0.0902   (557.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.46551      0.910694  213
max f2                       0.257782     0.933708  273
max f0point5                 0.783489     0.920909  122
max accuracy                 0.46551      0.909827  213
max precision                0.997085     1         0
max recall                   0.00441818   1         396
max specificity              0.997085     1         0
max absolute_mcc             0.46551      0.820559  213
max min_per_class_accuracy   0.54673      0.908823  193
max mean_per_class_accuracy  0.46551      0.9101    213
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.98 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.99344            2.02591     2.02591            1                0.99439     1                           0.99439             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.991671           2.02591     2.02591            1                0.992498    1                           0.993444            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.99051            1.99323     2.01502            0.983871         0.991025    0.994624                    0.992638            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.989489           2.02591     2.01774            1                0.990032    0.995968                    0.991986            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.988216           1.9927      2.0128             0.983607         0.988914    0.993528                    0.99138             0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.98283            2.0128      2.0128             0.993528         0.985503    0.993528                    0.988441            0.100689        0.201378                   101.28    101.28
    7        0.150073                    0.977048           2.00624     2.01061            0.990291         0.980117    0.992449                    0.985667            0.100361        0.301738                   100.624   101.061
    8        0.200097                    0.96982            1.98657     2.0046             0.980583         0.973522    0.989482                    0.98263             0.0993768       0.401115                   98.6572   100.46
    9        0.299984                    0.941983           1.96352     1.99092            0.969206         0.957561    0.982731                    0.974283            0.19613         0.597245                   96.3524   99.0924
    10       0.400032                    0.850956           1.80299     1.94392            0.889968         0.907382    0.959531                    0.957551            0.180387        0.777632                   80.2994   94.3923
    11       0.500081                    0.524888           1.36372     1.82784            0.673139         0.717681    0.902234                    0.909561            0.136438        0.91407                    36.3719   82.7844
    12       0.599968                    0.146635           0.554909    1.61592            0.273906         0.314098    0.797625                    0.810425            0.055428        0.969498                   -44.5091  61.5918
    13       0.700016                    0.046903           0.177021    1.41027            0.0873786        0.0866642   0.696115                    0.706983            0.0177107       0.987209                   -82.2979  41.0266
    14       0.799903                    0.0184221          0.0886541   1.24523            0.0437601        0.0301222   0.614653                    0.622461            0.00885536      0.996064                   -91.1346  24.5232
    15       0.899951                    0.00907958         0.0295035   1.11008            0.0145631        0.0131784   0.54794                     0.554726            0.00295179      0.999016                   -97.0496  11.0078
    16       1                           0.00142538         0.00983452  1                  0.00485437       0.00587181  0.493605                    0.499814            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:50:21  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:50:28  1:43:47.007  1268 obs/sec      0.34576   1             8644       0.338638         0.407362            0.541297       0.924032        0.795453           1.97783          0.151706                         0.334872           0.394147              0.551369         0.927974          0.831454             2.02591            0.14813
    2019-08-03 17:50:44  1:44:02.080  1241 obs/sec      1.0344    3             25860      0.307765         0.30875             0.621122       0.943251        0.929298           1.99761          0.133952                         0.297618           0.290163              0.645635         0.949596          0.930972             2.02591            0.123685
    2019-08-03 17:50:58  1:44:16.779  1253 obs/sec      1.72644   5             43161      0.298282         0.292769            0.644112       0.947938        0.934124           1.99761          0.121883                         0.286379           0.272898              0.671895         0.95436           0.943137             2.02591            0.109924
    2019-08-03 17:51:13  1:44:31.416  1258 obs/sec      2.4128    7             60320      0.294726         0.286287            0.652546       0.950097        0.943487           1.99761          0.117694                         0.28547            0.270225              0.673973         0.955478          0.949745             2.02591            0.109924
    2019-08-03 17:51:29  1:44:47.298  1233 obs/sec      3.0956    9             77390      0.293911         0.285323            0.654464       0.950256        0.945302           1.99761          0.117594                         0.281738           0.265796              0.682444         0.956482          0.938387             2.02591            0.104743
    2019-08-03 17:51:44  1:45:02.078  1239 obs/sec      3.7858    11            94645      0.292385         0.283453            0.658044       0.952272        0.944787           1.99761          0.117794                         0.282037           0.265044              0.681769         0.957903          0.948058             2.02591            0.105877
    2019-08-03 17:51:59  1:45:17.034  1241 obs/sec      4.48052   13            112013     0.288351         0.2787              0.667415       0.953716        0.941759           1.97783          0.110912                         0.275297           0.256161              0.696796         0.960049          0.948645             2.02591            0.0997248
    2019-08-03 17:52:13  1:45:31.851  1242 obs/sec      5.16688   15            129172     0.288471         0.275945            0.667137       0.954849        0.941094           1.99761          0.111909                         0.275305           0.25495               0.696779         0.960823          0.947609             2.02591            0.0985915
    2019-08-03 17:52:28  1:45:46.891  1239 obs/sec      5.8476    17            146190     0.285546         0.27251             0.673853       0.95603         0.948111           1.97783          0.11141                          0.272069           0.251557              0.703864         0.961554          0.952047             2.02591            0.0981059
    2019-08-03 17:52:43  1:46:01.894  1239 obs/sec      6.5344    19            163360     0.282508         0.267461            0.680756       0.957043        0.947888           1.99761          0.107022                         0.271405           0.249079              0.70531          0.962152          0.950352             2.02591            0.103286
    2019-08-03 17:52:58  1:46:16.577  1241 obs/sec      7.21696   21            180424     0.280288         0.264957            0.685754       0.958321        0.953684           1.97783          0.105526                         0.268138           0.245243              0.71236          0.963557          0.952456             1.99323            0.0938967
    2019-08-03 17:53:13  1:46:31.689  1241 obs/sec      7.90904   23            197726     0.281145         0.268357            0.683829       0.957168        0.948689           1.97783          0.104229                         0.270302           0.250101              0.707699         0.96214           0.952448             2.02591            0.0958394
    2019-08-03 17:53:28  1:46:46.357  1243 obs/sec      8.5962    25            214905     0.282591         0.268945            0.680569       0.956505        0.946291           1.99761          0.10752                          0.270003           0.248499              0.708347         0.962195          0.951027             2.02591            0.0926016
    2019-08-03 17:53:43  1:47:01.428  1244 obs/sec      9.28932   27            232233     0.281429         0.266684            0.68319        0.957261        0.946809           1.99761          0.107919                         0.268817           0.24568               0.710903         0.962864          0.958122             2.02591            0.0951918
    2019-08-03 17:53:58  1:47:16.249  1244 obs/sec      9.97768   29            249442     0.273242         0.254701            0.701356       0.960786        0.949286           1.99761          0.0985438                        0.261791           0.234543              0.725817         0.966183          0.960868             2.02591            0.0917921
    2019-08-03 17:54:06  1:47:24.293  1244 obs/sec      10.3274   30            258185     0.271121         0.248853            0.705974       0.96229         0.952419           1.99761          0.0974466                        0.26127            0.234021              0.726907         0.966322          0.964216             2.02591            0.0901732
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004340657159099263
C438        0.8461831212043762     0.8461831212043762   0.003672990822964735
C374        0.7697049379348755     0.7697049379348755   0.003341025249241071
C88         0.6904866695404053     0.6904866695404053   0.0029971659054031674
C322        0.6686409115791321     0.6686409115791321   0.002902340959712617
---         ---                    ---                  ---
C691        0.14275328814983368    0.14275328814983368  0.0006196430821925356
C975        0.1422051638364792     0.1422051638364792   0.000617263862467697
C839        0.14107181131839752    0.14107181131839752  0.0006123443677463026
C633        0.13967324793338776    0.13967324793338776  0.0006062736835767059
C969        0.13705290853977203    0.13705290853977203  0.000594899688628538

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_45

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 251,998 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.07215397542130798   0.10585114359855652    0.0         4.744065578695598e-06  0.10797026753425598  -0.004359812573982949    0.14157730340957642
    3        2        Softmax                 0.0   0.0   0.001898299611184484  0.0004898835904896259  0.0         0.009715300458879028   0.2485727071762085   -0.00039971201516195154  0.25225019454956055


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07310282170385542
RMSE: 0.27037533486591453
LogLoss: 0.2476839863170707
Mean Per-Class Error: 0.09624413649770336
AUC: 0.9627262165081666
pr_auc: 0.956955523889335
Gini: 0.9254524330163332
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4901866006340126: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4470  516   0.1035   (516.0/4986.0)
1      449   4593  0.0891   (449.0/5042.0)
Total  4919  5109  0.0962   (965.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.490187     0.904935  206
max f2                       0.119049     0.930661  322
max f0point5                 0.807287     0.914723  111
max accuracy                 0.514296     0.903769  200
max precision                0.991995     0.996466  4
max recall                   0.00369391   1         397
max specificity              0.996791     0.999799  0
max absolute_mcc             0.490187     0.807591  206
max min_per_class_accuracy   0.523736     0.903329  197
max mean_per_class_accuracy  0.514296     0.903756  200
Gains/Lift Table: Avg response rate: 50.28 %, avg score: 49.92 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   0.993935           1.9692     1.9692             0.990099         0.995309    0.990099                    0.995309            0.0198334       0.0198334                  96.9201   96.9201
    2        0.0200439                   0.992591           1.98889    1.979              1                0.993255    0.995025                    0.994287            0.0198334       0.0396668                  98.8893   97.8998
    3        0.030016                    0.991351           1.98889    1.98229            1                0.991956    0.996678                    0.993512            0.0198334       0.0595002                  98.8893   98.2286
    4        0.0400878                   0.990345           1.9692     1.979              0.990099         0.990851    0.995025                    0.992844            0.0198334       0.0793336                  96.9201   97.8998
    5        0.0500598                   0.989408           1.94912    1.97305            0.98             0.989858    0.992032                    0.992249            0.0194367       0.0987703                  94.9115   97.3046
    6        0.10002                     0.984558           1.97698    1.97501            0.994012         0.987141    0.993021                    0.989698            0.0987703       0.197541                   97.6984   97.5013
    7        0.15008                     0.979073           1.96512    1.97171            0.988048         0.982065    0.991362                    0.987152            0.0983737       0.295914                   96.5122   97.1713
    8        0.20004                     0.971736           1.95316    1.96708            0.982036         0.975523    0.989033                    0.984248            0.0975803       0.393495                   95.3165   96.7081
    9        0.30006                     0.94547            1.91156    1.94857            0.961117         0.960776    0.979727                    0.976424            0.191194        0.584689                   91.1558   94.8573
    10       0.39998                     0.852397           1.75269    1.89964            0.881238         0.910363    0.955123                    0.959921            0.175129        0.759818                   75.2687   89.9639
    11       0.5                         0.536036           1.40789    1.80127            0.707876         0.722331    0.905664                    0.912394            0.140817        0.900635                   40.7891   80.1269
    12       0.60002                     0.143942           0.654372   1.61009            0.329013         0.31275     0.80954                     0.812436            0.0654502       0.966085                   -34.5628  61.0088
    13       0.69994                     0.0389583          0.222311   1.41198            0.111776         0.0787443   0.70993                     0.707698            0.0222134       0.988298                   -77.7689  41.1975
    14       0.79996                     0.0145783          0.0654372  1.24362            0.0329013        0.0236202   0.62528                     0.622167            0.00654502      0.994843                   -93.4563  24.3616
    15       0.89998                     0.00729754         0.0396589  1.10981            0.0199402        0.0104297   0.558006                    0.554181            0.00396668      0.99881                    -96.0341  10.9813
    16       1                           0.00110906         0.0118977  1                  0.00598205       0.00484268  0.502792                    0.499236            0.00119         1                          -98.8102  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06774226073418024
RMSE: 0.26027343455331786
LogLoss: 0.2341162639449204
Mean Per-Class Error: 0.08768052331945664
AUC: 0.9662237797139476
pr_auc: 0.9581237194492649
Gini: 0.9324475594278951
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47302647507963147: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2830  298   0.0953   (298.0/3128.0)
1      245   2804  0.0804   (245.0/3049.0)
Total  3075  3102  0.0879   (543.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.473026     0.911722  207
max f2                       0.206504     0.93196   281
max f0point5                 0.786165     0.923576  121
max accuracy                 0.484463     0.912255  204
max precision                0.980846     0.993266  16
max recall                   0.00505929   1         395
max specificity              0.996446     0.99968   0
max absolute_mcc             0.484463     0.824572  204
max min_per_class_accuracy   0.509538     0.911774  197
max mean_per_class_accuracy  0.484463     0.912319  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.10 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.9938             1.99323     1.99323            0.983871         0.995088    0.983871                    0.995088            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.992467           2.02591     2.00957            1                0.993121    0.991935                    0.994104            0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.991253           1.99323     2.00413            0.983871         0.99177     0.989247                    0.993326            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.990161           2.02591     2.00957            1                0.990756    0.991935                    0.992684            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.989266           1.9927      2.00624            0.983607         0.989694    0.990291                    0.992093            0.0196786       0.100361                   99.2698   100.624
    6        0.100049                    0.984763           2.00624     2.00624            0.990291         0.987005    0.990291                    0.989549            0.100361        0.200722                   100.624   100.624
    7        0.150073                    0.979655           2.00624     2.00624            0.990291         0.982317    0.990291                    0.987139            0.100361        0.301082                   100.624   100.624
    8        0.200097                    0.972331           1.98002     1.99968            0.977346         0.975731    0.987055                    0.984287            0.0990489       0.400131                   98.0016   99.9685
    9        0.299984                    0.943572           1.97337     1.99092            0.974068         0.960209    0.982731                    0.97627             0.197114        0.597245                   97.3374   99.0924
    10       0.400032                    0.850215           1.80955     1.94556            0.893204         0.908496    0.96034                     0.959319            0.181043        0.778288                   80.9551   94.5562
    11       0.500081                    0.481514           1.39322     1.83506            0.687702         0.699878    0.905795                    0.907414            0.13939         0.917678                   39.3223   83.5059
    12       0.599968                    0.122938           0.515507    1.61537            0.254457         0.269985    0.797356                    0.801291            0.0514923       0.96917                    -48.4493  61.5371
    13       0.700016                    0.0330291          0.180299    1.41027            0.0889968        0.0665662   0.696115                    0.696282            0.0180387       0.987209                   -81.9701  41.0266
    14       0.799903                    0.0137906          0.0853706   1.24482            0.0421394        0.0214186   0.614451                    0.612009            0.00852739      0.995736                   -91.4629  24.4822
    15       0.899951                    0.00715933         0.0327817   1.11008            0.0161812        0.0101008   0.54794                     0.545094            0.00327976      0.999016                   -96.7218  11.0078
    16       1                           0.00078522         0.00983452  1                  0.00485437       0.00479063  0.493605                    0.491038            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:53:33  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:53:40  46 min 58.101 sec  1297 obs/sec      0.32112   1             8028       0.360414         0.484453            0.480391       0.913747        0.768741           1.98889          0.166633                         0.350652           0.456514              0.508094         0.920918          0.776229             2.02591            0.160434
    2019-08-03 16:53:54  47 min 12.269 sec  1264 obs/sec      0.9762    3             24405      0.309881         0.314066            0.615883       0.939945        0.926784           1.98889          0.13203                          0.301071           0.29598               0.637365         0.94637           0.932198             2.02591            0.119152
    2019-08-03 16:54:08  47 min 26.945 sec  1238 obs/sec      1.62736   5             40684      0.300358         0.295976            0.63913        0.946432        0.942158           1.98889          0.12156                          0.292188           0.281966              0.658448         0.951805          0.942081             2.02591            0.113162
    2019-08-03 16:54:23  47 min 41.163 sec  1239 obs/sec      2.27812   7             56953      0.29513          0.288093            0.651582       0.949521        0.938933           1.9692           0.117571                         0.2866             0.271125              0.671388         0.955434          0.943028             1.99323            0.110248
    2019-08-03 16:54:37  47 min 55.412 sec  1236 obs/sec      2.92292   9             73073      0.291171         0.279991            0.660868       0.95231         0.943553           1.98889          0.114978                         0.282365           0.263991              0.681027         0.957721          0.952297             2.02591            0.107657
    2019-08-03 16:54:51  48 min  9.512 sec  1237 obs/sec      3.57248   11            89312      0.290386         0.278447            0.662693       0.953011        0.940466           1.98889          0.112385                         0.27954            0.260433              0.687378         0.958564          0.948141             2.02591            0.103286
    2019-08-03 16:55:06  48 min 23.980 sec  1232 obs/sec      4.22184   13            105546     0.29474          0.290945            0.652503       0.951815        0.927529           1.98889          0.116773                         0.283973           0.270876              0.677384         0.95732           0.932706             2.02591            0.108143
    2019-08-03 16:55:20  48 min 38.210 sec  1234 obs/sec      4.87588   15            121897     0.286416         0.273349            0.671854       0.954136        0.944895           1.9692           0.113183                         0.276932           0.256967              0.693185         0.959807          0.956061             1.99323            0.104096
    2019-08-03 16:55:34  48 min 52.618 sec  1232 obs/sec      5.52992   17            138248     0.285654         0.273589            0.673597       0.953932        0.942624           1.94951          0.109294                         0.272907           0.252138              0.702039         0.960997          0.949205             1.99323            0.0989153
    2019-08-03 16:55:48  49 min  6.769 sec  1232 obs/sec      6.1756    19            154390     0.285213         0.273397            0.674605       0.954876        0.942261           1.94951          0.110092                         0.273302           0.25233               0.701175         0.961314          0.954857             2.02591            0.0974583
    2019-08-03 16:56:04  49 min 22.417 sec  1220 obs/sec      6.8276    21            170690     0.279472         0.262817            0.687571       0.95875         0.951918           1.98889          0.104009                         0.266598           0.241902              0.715657         0.964504          0.956644             2.02591            0.0938967
    2019-08-03 16:56:18  49 min 36.912 sec  1220 obs/sec      7.4812    23            187030     0.276538         0.257115            0.694098       0.959744        0.956526           1.9692           0.101316                         0.267473           0.242793              0.713786         0.96385           0.956149             2.02591            0.0947062
    2019-08-03 16:56:33  49 min 51.415 sec  1219 obs/sec      8.13232   25            203308     0.275054         0.254635            0.697371       0.960357        0.956181           1.98889          0.10002                          0.264038           0.238382              0.72109          0.965234          0.960511             2.02591            0.0879068
    2019-08-03 16:56:47  50 min  5.614 sec  1221 obs/sec      8.78088   27            219522     0.275116         0.254769            0.697235       0.960742        0.952335           1.9692           0.10012                          0.264696           0.239881              0.719699         0.964714          0.958976             2.02591            0.0922778
    2019-08-03 16:57:01  50 min 19.998 sec  1221 obs/sec      9.4294    29            235735     0.27405          0.253282            0.699576       0.961587        0.951873           1.9692           0.100419                         0.264524           0.240857              0.720062         0.964225          0.956752             2.02591            0.093411
    2019-08-03 16:57:16  50 min 34.252 sec  1222 obs/sec      10.0799   31            251998     0.270375         0.247684            0.70758        0.962726        0.956956           1.9692           0.0962306                        0.260273           0.234116              0.728987         0.966224          0.958124             1.99323            0.0879068
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004473347660801662
C438        0.8272931575775146     0.8272931575775146   0.0037007699112465956
C374        0.7350618243217468     0.7350618243217468   0.003288187092374288
C88         0.6910648345947266     0.6910648345947266   0.0030913732612966073
C863        0.6616299152374268     0.6616299152374268   0.0029597006336437447
---         ---                    ---                  ---
C785        0.14097806811332703    0.14097806811332703  0.0006306439112190887
C998        0.13980232179164886    0.13980232179164886  0.0006253843891613136
C476        0.1382608711719513     0.1382608711719513   0.0006184889446374482
C780        0.13356079161167145    0.13356079161167145  0.0005974638547308886
C838        0.12846845388412476    0.12846845388412476  0.0005746840576693556

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_51

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 258,314 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0682727020610869     0.10069894790649414     0.0         -0.0003130817445673241  0.10285741090774536  0.0053373307587332875   0.13413256406784058
    3        2        Softmax                 0.0   0.0   0.0017195043762967543  0.00033231754787266254  0.0         -0.02008803027911199    0.23712825775146484  -0.0011816317336626886  0.21437311172485352


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07070866716025036
RMSE: 0.26591101361216757
LogLoss: 0.24164592624239814
Mean Per-Class Error: 0.09355959602229014
AUC: 0.9651476920163315
pr_auc: 0.9608996940954165
Gini: 0.9302953840326631
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4594987819844134: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4459  588   0.1165   (588.0/5047.0)
1      369   4611  0.0741   (369.0/4980.0)
Total  4828  5199  0.0954   (957.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.459499     0.905983  215
max f2                       0.212553     0.932184  289
max f0point5                 0.770504     0.919151  124
max accuracy                 0.551133     0.906453  190
max precision                0.99265      1         0
max recall                   0.00631777   1         397
max specificity              0.99265      1         0
max absolute_mcc             0.551133     0.812896  190
max min_per_class_accuracy   0.544516     0.906281  192
max mean_per_class_accuracy  0.551133     0.90644   190
Gains/Lift Table: Avg response rate: 49.67 %, avg score: 49.92 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   0.984949           1.99352    1.99352            0.990099         0.987543   0.990099                    0.987543            0.0200803       0.0200803                  99.3519   99.3519
    2        0.0200459                   0.981523           1.99332    1.99342            0.99             0.98319    0.99005                     0.985377            0.0198795       0.0399598                  99.3319   99.3419
    3        0.0300189                   0.979471           2.01345    2.00008            1                0.980462   0.993355                    0.983744            0.0200803       0.0600402                  101.345   100.008
    4        0.0400918                   0.977726           1.99352    1.99843            0.990099         0.978601   0.992537                    0.982452            0.0200803       0.0801205                  99.3519   99.8428
    5        0.0500648                   0.976129           2.01345    2.00142            1                0.976925   0.994024                    0.981351            0.0200803       0.100201                   101.345   100.142
    6        0.10003                     0.968471           1.99336    1.99739            0.99002          0.972205   0.992024                    0.976783            0.0995984       0.199799                   99.3359   99.7394
    7        0.149995                    0.960253           1.9813     1.99203            0.984032         0.96456    0.989362                    0.972711            0.098996        0.298795                   98.1303   99.2034
    8        0.20006                     0.950391           1.98538    1.99037            0.986056         0.955366   0.988534                    0.968371            0.0993976       0.398193                   98.5378   99.0368
    9        0.29999                     0.916611           1.94915    1.97664            0.968064         0.935382   0.981715                    0.957382            0.194779        0.592972                   94.9152   97.6639
    10       0.40002                     0.821071           1.79264    1.93063            0.890329         0.878528   0.958863                    0.937663            0.179317        0.772289                   79.2636   93.0627
    11       0.50005                     0.531505           1.36104    1.81669            0.675972         0.698899   0.902274                    0.889901            0.136145        0.908434                   36.1039   81.6686
    12       0.59998                     0.196823           0.612878   1.61618            0.304391         0.34614    0.802693                    0.799334            0.061245        0.969679                   -38.7122  61.6185
    13       0.70001                     0.0676843          0.212788   1.41564            0.105683         0.118852   0.703092                    0.702095            0.0212851       0.990964                   -78.7212  41.5642
    14       0.79994                     0.0295938          0.0502359  1.24507            0.0249501        0.0449363  0.618377                    0.620001            0.00502008      0.995984                   -94.9764  24.5073
    15       0.89997                     0.0155508          0.0260966  1.10959            0.0129611        0.0216696  0.551086                    0.553498            0.00261044      0.998594                   -97.3903  10.9586
    16       1                           0.002779           0.014052   1                  0.00697906       0.0106824  0.496659                    0.4992              0.00140562      1                          -98.5948  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06829110272350163
RMSE: 0.26132566411185415
LogLoss: 0.234844517868469
Mean Per-Class Error: 0.09118640005234202
AUC: 0.9672006838014057
pr_auc: 0.9624260729258906
Gini: 0.9344013676028113
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4388416798711772: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2749  379   0.1212   (379.0/3128.0)
1      197   2852  0.0646   (197.0/3049.0)
Total  2946  3231  0.0932   (576.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.438842     0.90828   221
max f2                       0.289688     0.933512  263
max f0point5                 0.771649     0.925583  120
max accuracy                 0.562155     0.908855  188
max precision                0.991694     1         0
max recall                   0.0110743    1         393
max specificity              0.991694     1         0
max absolute_mcc             0.562155     0.817678  188
max min_per_class_accuracy   0.544029     0.908248  193
max mean_per_class_accuracy  0.562155     0.908814  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.69 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.984745           2.02591     2.02591            1                0.987716   1                           0.987716            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.981808           1.99323     2.00957            0.983871         0.983171   0.991935                    0.985443            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.979393           2.02591     2.01502            1                0.980397   0.994624                    0.983761            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.977861           2.02591     2.01774            1                0.978606   0.995968                    0.982473            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.976221           2.02591     2.01935            1                0.977034   0.996764                    0.981399            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.968831           1.99968     2.00952            0.987055         0.97249    0.991909                    0.976945            0.100033        0.20105                    99.9685   100.952
    7        0.150073                    0.960777           1.98002     1.99968            0.977346         0.964856   0.987055                    0.972915            0.0990489       0.300098                   98.0016   99.9685
    8        0.200097                    0.950963           1.99968     1.99968            0.987055         0.95612    0.987055                    0.968716            0.100033        0.400131                   99.9685   99.9685
    9        0.299984                    0.917541           1.96352     1.98764            0.969206         0.935667   0.981112                    0.957712            0.19613         0.596261                   96.3524   98.7644
    10       0.400032                    0.822573           1.85217     1.95376            0.914239         0.878143   0.964387                    0.937812            0.185307        0.781568                   85.2167   95.3761
    11       0.500081                    0.526569           1.31783     1.82653            0.650485         0.69074    0.901586                    0.888381            0.131847        0.913414                   31.7825   82.6533
    12       0.599968                    0.183429           0.568043    1.61701            0.280389         0.338851   0.798165                    0.796892            0.0567399       0.970154                   -43.1957  61.7011
    13       0.700016                    0.0651729          0.203247    1.41495            0.100324         0.111957   0.698427                    0.698999            0.0203345       0.990489                   -79.6753  41.4951
    14       0.799903                    0.0297492          0.0591027   1.24564            0.0291734        0.0438381  0.614855                    0.617187            0.00590357      0.996392                   -94.0897  24.5642
    15       0.899951                    0.0156047          0.0295035   1.11044            0.0145631        0.0217109  0.54812                     0.550987            0.00295179      0.999344                   -97.0496  11.0442
    16       1                           0.00289395         0.00655634  1                  0.00323625       0.0108642  0.493605                    0.496948            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:03:34  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:03:41  56 min 59.799 sec  1266 obs/sec      0.3442    1             8605       0.347461         0.451693            0.517062       0.921432        0.749578           2.01345          0.161464                         0.332595           0.411549              0.55745          0.930172          0.785008             2.02591            0.14813
    2019-08-03 17:03:56  57 min 14.287 sec  1270 obs/sec      1.02812   3             25703      0.303055         0.304356            0.632614       0.944259        0.912214           2.01345          0.122669                         0.297849           0.293146              0.645086         0.948005          0.910145             2.02591            0.119475
    2019-08-03 17:04:11  57 min 29.122 sec  1263 obs/sec      1.72124   5             43031      0.293499         0.284395            0.655417       0.950846        0.933766           2.01345          0.117383                         0.289235           0.276666              0.665318         0.953576          0.938337             2.02591            0.116238
    2019-08-03 17:04:25  57 min 43.784 sec  1265 obs/sec      2.4096    7             60240      0.290158         0.279687            0.663219       0.952875        0.937168           2.01345          0.112795                         0.28699            0.270914              0.670493         0.956095          0.935192             2.02591            0.109762
    2019-08-03 17:04:40  57 min 58.578 sec  1262 obs/sec      3.09424   9             77356      0.287371         0.273155            0.669657       0.954658        0.943678           2.01345          0.113494                         0.283507           0.267348              0.678443         0.956931          0.949163             2.02591            0.109114
    2019-08-03 17:04:55  58 min 13.556 sec  1260 obs/sec      3.79008   11            94752      0.280682         0.264342            0.684857       0.957098        0.944835           2.01345          0.106413                         0.27636            0.254219              0.694451         0.960764          0.955988             2.02591            0.103772
    2019-08-03 17:05:10  58 min 28.630 sec  1255 obs/sec      4.48092   13            112023     0.278751         0.260376            0.689178       0.958689        0.946783           2.01345          0.104518                         0.273926           0.250978              0.699808         0.961943          0.951094             2.02591            0.0990772
    2019-08-03 17:05:25  58 min 43.556 sec  1255 obs/sec      5.17344   15            129336     0.275301         0.254771            0.696823       0.960067        0.9541             2.01345          0.102523                         0.269104           0.244361              0.710284         0.963554          0.960522             2.02591            0.0982678
    2019-08-03 17:05:40  58 min 58.310 sec  1254 obs/sec      5.8622    17            146555     0.275464         0.25586             0.696464       0.959626        0.949148           2.01345          0.101725                         0.270248           0.243613              0.707815         0.964213          0.956599             1.99323            0.100049
    2019-08-03 17:05:55  59 min 13.276 sec  1253 obs/sec      6.54988   19            163747     0.274971         0.255934            0.69755        0.961042        0.949867           2.01345          0.101526                         0.269542           0.245805              0.70934          0.964091          0.954196             2.02591            0.0972964
    2019-08-03 17:06:11  59 min 29.276 sec  1242 obs/sec      7.23396   21            180849     0.273525         0.253428            0.700723       0.960779        0.945089           1.99352          0.0999302                        0.270499           0.246403              0.707274         0.963428          0.956671             2.02591            0.0987534
    2019-08-03 17:06:26  59 min 44.088 sec  1244 obs/sec      7.92844   23            198211     0.269296         0.244615            0.709906       0.964434        0.953126           2.01345          0.0974369                        0.267203           0.239102              0.714364         0.96643           0.959559             2.02591            0.0947062
    2019-08-03 17:06:40  59 min 58.869 sec  1245 obs/sec      8.61616   25            215404     0.269505         0.245434            0.709455       0.964348        0.955481           2.01345          0.094445                         0.264287           0.235733              0.720564         0.967259          0.957726             2.02591            0.0916302
    2019-08-03 17:06:55  1:00:13.563        1246 obs/sec      9.3064    27            232660     0.265911         0.241646            0.717153       0.965148        0.9609             1.99352          0.0954423                        0.261326           0.234845              0.726791         0.967201          0.962426             2.02591            0.0932492
    2019-08-03 17:07:10  1:00:28.069        1248 obs/sec      9.99096   29            249774     0.268701         0.24422             0.711187       0.963814        0.960551           2.01345          0.0942455                        0.262605           0.236038              0.724108         0.966015          0.961467             1.99323            0.0874211
    2019-08-03 17:07:18  1:00:35.943        1247 obs/sec      10.3326   30            258314     0.266822         0.247734            0.715212       0.964944        0.949308           2.01345          0.0943453                        0.260908           0.237818              0.727664         0.967585          0.951464             2.02591            0.0898494
    2019-08-03 17:07:19  1:00:37.016        1247 obs/sec      10.3326   30            258314     0.265911         0.241646            0.717153       0.965148        0.9609             1.99352          0.0954423                        0.261326           0.234845              0.726791         0.967201          0.962426             2.02591            0.0932492
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004197393411407655
C438        0.7879348993301392     0.7879348993301392   0.00330727275506648
C374        0.765593409538269      0.765593409538269    0.0032134967330130527
C88         0.7072213888168335     0.7072213888168335   0.002968486397826348
C863        0.6620627641677856     0.6620627641677856   0.0027789378842562034
---         ---                    ---                  ---
C889        0.15423108637332916    0.15423108637332916  0.0006473685457776567
C892        0.15376019477844238    0.15376019477844238  0.0006453920284997918
C785        0.15347981452941895    0.15347981452941895  0.0006442151622898519
C925        0.14881061017513275    0.14881061017513275  0.0006246166746966551
C828        0.1479518711566925     0.1479518711566925   0.0006210122091985353

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_164

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 254,757 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  ------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.08176334346716227    0.12378963828086853    0.0         -0.0020993458549802037  0.10853466391563416  0.0025052531483042624  0.1565750241279602
    3        2        Softmax                 0.0   0.0   0.0019162140774824366  0.0004996240604668856  0.0         -0.002442825461457687   0.24851852655410767  0.0028171280948976474  0.2737910747528076


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07415808687859242
RMSE: 0.27231982461545545
LogLoss: 0.252373469826264
Mean Per-Class Error: 0.09955852530702836
AUC: 0.9610251225820088
pr_auc: 0.9557435127373596
Gini: 0.9220502451640176
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.412303446857898: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4368  642   0.1281   (642.0/5010.0)
1      370   4635  0.0739   (370.0/5005.0)
Total  4738  5277  0.101    (1012.0/10015.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.412303     0.901576  223
max f2                       0.196934     0.929693  288
max f0point5                 0.726705     0.914958  137
max accuracy                 0.641946     0.900449  162
max precision                0.997346     1         0
max recall                   0.00175526   1         399
max specificity              0.997346     1         0
max absolute_mcc             0.641946     0.801733  162
max min_per_class_accuracy   0.543066     0.899101  188
max mean_per_class_accuracy  0.610608     0.900441  170
Gains/Lift Table: Avg response rate: 49.98 %, avg score: 49.98 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100849                   0.993156           1.96138    1.96138            0.980198         0.994875    0.980198                    0.994875            0.0197802       0.0197802                  96.1375   96.1375
    2        0.0200699                   0.991488           1.98099    1.97113            0.99             0.992227    0.985075                    0.993557            0.0197802       0.0395604                  98.0989   97.1133
    3        0.0300549                   0.990154           1.98099    1.97441            0.99             0.990799    0.986711                    0.992641            0.0197802       0.0593407                  98.0989   97.4408
    4        0.0400399                   0.988769           2.001      1.98104            1                0.989415    0.990025                    0.991836            0.01998         0.0793207                  100.1     98.1039
    5        0.050025                    0.987616           1.98099    1.98103            0.99             0.988195    0.99002                     0.99111             0.0197802       0.0991009                  98.0989   98.1029
    6        0.10005                     0.982305           1.99301    1.98702            0.996008         0.984949    0.993014                    0.988029            0.0997003       0.198801                   99.3011   98.702
    7        0.150075                    0.976855           1.96905    1.98103            0.984032         0.979637    0.99002                     0.985232            0.0985015       0.297303                   96.9047   98.1029
    8        0.2                         0.96877            1.93697    1.97003            0.968            0.972986    0.984523                    0.982175            0.0967033       0.394006                   93.6967   97.003
    9        0.30005                     0.941225           1.92112    1.95372            0.96008          0.956961    0.976373                    0.973767            0.192208        0.586214                   92.1119   95.3721
    10       0.4                         0.851341           1.77911    1.91009            0.889111         0.906748    0.954568                    0.957021            0.177822        0.764036                   77.911    91.009
    11       0.50005                     0.539016           1.35197    1.79842            0.675649         0.721074    0.898762                    0.909813            0.135265        0.899301                   35.1972   79.8422
    12       0.6                         0.149728           0.673663   1.61106            0.336663         0.322504    0.805126                    0.811977            0.0673327       0.966633                   -32.6337  61.1056
    13       0.69995                     0.0416375          0.203898   1.41012            0.101898         0.0828689   0.704708                    0.707863            0.0203796       0.987013                   -79.6102  41.0119
    14       0.8                         0.0163154          0.0738892  1.24301            0.0369261        0.0262197   0.621193                    0.622615            0.00739261      0.994406                   -92.6111  24.3007
    15       0.89995                     0.0083608          0.035982   1.10895            0.017982         0.011954    0.554199                    0.554794            0.0035964       0.998002                   -96.4018  10.8953
    16       1                           0.00100116         0.01997    1                  0.00998004       0.00545107  0.49975                     0.499832            0.001998        1                          -98.003   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06895074376360683
RMSE: 0.2625847363492532
LogLoss: 0.23661107672589152
Mean Per-Class Error: 0.08944051296848832
AUC: 0.9655460177711195
pr_auc: 0.9619473354783529
Gini: 0.931092035542239
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.42613339741310663: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2782  346   0.1106   (346.0/3128.0)
1      214   2835  0.0702   (214.0/3049.0)
Total  2996  3181  0.0907   (560.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.426133     0.910112  224
max f2                       0.146959     0.930497  305
max f0point5                 0.752699     0.921118  135
max accuracy                 0.551982     0.910636  190
max precision                0.997559     1         0
max recall                   0.00378234   1         397
max specificity              0.997559     1         0
max absolute_mcc             0.551982     0.82126   190
max min_per_class_accuracy   0.524709     0.909207  197
max mean_per_class_accuracy  0.551982     0.910559  190
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.25 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.99357            2.02591     2.02591            1                0.995317    1                           0.995317            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.991622           2.02591     2.02591            1                0.992444    1                           0.993881            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.990164           1.99323     2.01502            0.983871         0.990853    0.994624                    0.992872            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.988932           2.02591     2.01774            1                0.989474    0.995968                    0.992022            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.987854           2.02591     2.01935            1                0.988398    0.996764                    0.991307            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.9822             2.02591     2.02263            1                0.984959    0.998382                    0.988133            0.101345        0.202361                   102.591   102.263
    7        0.150073                    0.976596           1.98657     2.01061            0.980583         0.979402    0.992449                    0.985223            0.0993768       0.301738                   98.6572   101.061
    8        0.200097                    0.968668           1.98002     2.00296            0.977346         0.972901    0.988673                    0.982142            0.0990489       0.400787                   98.0016   100.296
    9        0.299984                    0.940742           1.94054     1.98218            0.957861         0.957374    0.978413                    0.973895            0.193834        0.594621                   94.054    98.2178
    10       0.400032                    0.852539           1.80955     1.939              0.893204         0.905849    0.957102                    0.956877            0.181043        0.775664                   80.9551   93.9003
    11       0.500081                    0.491656           1.39978     1.83112            0.690939         0.708899    0.903852                    0.907265            0.140046        0.91571                    39.9779   83.1124
    12       0.599968                    0.123168           0.528641    1.61428            0.26094          0.27636     0.796816                    0.802228            0.0528042       0.968514                   -47.1359  61.4278
    13       0.700016                    0.0363691          0.209803    1.41355            0.10356          0.071021    0.697734                    0.697721            0.0209905       0.989505                   -79.0197  41.3546
    14       0.799903                    0.0153441          0.0525358   1.24359            0.0259319        0.0233053   0.613843                    0.613505            0.00524762      0.994752                   -94.7464  24.3591
    15       0.899951                    0.00836939         0.0426162   1.11008            0.0210356        0.0115182   0.54794                     0.546581            0.00426369      0.999016                   -95.7384  11.0078
    16       1                           0.00100116         0.00983452  1                  0.00485437       0.00557008  0.493605                    0.492454            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:14:50  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:14:57  3:08:15.757  1259 obs/sec      0.3546    1             8865       0.340844         0.402306            0.535303       0.92362         0.814314           2.001            0.159061                         0.332013           0.387121              0.558998         0.929521          0.826985             2.02591            0.149911
    2019-08-03 19:15:12  3:08:30.634  1263 obs/sec      1.05348   3             26337      0.306251         0.305266            0.62484        0.943393        0.928859           2.001            0.127908                         0.296214           0.288194              0.648973         0.950001          0.93811              2.02591            0.118018
    2019-08-03 19:15:27  3:08:45.722  1261 obs/sec      1.75664   5             43916      0.29686          0.290687            0.647497       0.948329        0.935064           2.001            0.119121                         0.286032           0.269772              0.672689         0.955662          0.934021             2.02591            0.110895
    2019-08-03 19:15:42  3:09:00.867  1257 obs/sec      2.45708   7             61427      0.29579          0.288976            0.650034       0.949109        0.942768           2.001            0.121318                         0.284081           0.269519              0.67714          0.956231          0.947003             2.02591            0.107496
    2019-08-03 19:15:58  3:09:16.191  1253 obs/sec      3.16232   9             79058      0.296831         0.289325            0.647566       0.949067        0.9398             1.98119          0.11972                          0.28142            0.264281              0.68316          0.957149          0.950152             2.02591            0.105229
    2019-08-03 19:16:13  3:09:31.418  1251 obs/sec      3.86236   11            96559      0.291886         0.281721            0.659211       0.952636        0.945029           2.001            0.115726                         0.277712           0.257722              0.691455         0.959849          0.950071             2.02591            0.103772
    2019-08-03 19:16:28  3:09:46.374  1251 obs/sec      4.55556   13            113889     0.29304          0.283582            0.656511       0.951324        0.947776           1.98119          0.117524                         0.280449           0.26373               0.685341         0.957484          0.945443             1.99323            0.104258
    2019-08-03 19:16:43  3:10:01.491  1251 obs/sec      5.25576   15            131394     0.28927          0.279827            0.665291       0.954722        0.934678           2.001            0.112431                         0.276266           0.257905              0.694658         0.960849          0.943852             2.02591            0.10102
    2019-08-03 19:16:58  3:10:16.877  1249 obs/sec      5.957     17            148925     0.288019         0.276676            0.668179       0.955132        0.941564           2.001            0.11353                          0.276799           0.259287              0.693479         0.959942          0.946045             2.02591            0.102153
    2019-08-03 19:17:15  3:10:33.579  1235 obs/sec      6.65888   19            166472     0.279101         0.260477            0.688411       0.95875         0.953569           2.001            0.104843                         0.269442           0.24448               0.709557         0.96374           0.957222             2.02591            0.0947062
    2019-08-03 19:17:30  3:10:48.855  1236 obs/sec      7.36804   21            184201     0.276983         0.257662            0.693122       0.960371        0.949051           2.001            0.100849                         0.265194           0.238625              0.718643         0.965773          0.959714             2.02591            0.0896876
    2019-08-03 19:17:45  3:11:03.809  1238 obs/sec      8.06936   23            201734     0.280569         0.263396            0.685125       0.958587        0.949481           2.001            0.106141                         0.269578           0.246473              0.709263         0.962938          0.954676             2.02591            0.0966489
    2019-08-03 19:18:00  3:11:18.918  1239 obs/sec      8.77348   25            219337     0.275738         0.254975            0.695875       0.960874        0.95765            2.001            0.101448                         0.266108           0.238313              0.7167           0.966134          0.961013             2.02591            0.0937348
    2019-08-03 19:18:16  3:11:34.086  1240 obs/sec      9.47904   27            236976     0.27462          0.256079            0.698335       0.959463        0.950813           1.96138          0.10025                          0.262901           0.238175              0.723488         0.964595          0.958559             1.99323            0.0892019
    2019-08-03 19:18:31  3:11:49.512  1241 obs/sec      10.1903   29            254757     0.27232          0.252373            0.703368       0.961025        0.955744           1.96138          0.101048                         0.262585           0.236611              0.724152         0.965546          0.961947             2.02591            0.0906589
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004343219226604502
C438        0.7952691912651062     0.7952691912651062   0.0034540284418288227
C374        0.7247323989868164     0.7247323989868164   0.0031476716894227466
C88         0.7038113474845886     0.7038113474845886   0.0030568069762974878
C322        0.664772629737854      0.664772629737854    0.0028872532667978835
---         ---                    ---                  ---
C539        0.14175386726856232    0.14175386726856232  0.0006156681217663625
C921        0.1416492462158203     0.1416492462158203   0.0006152137295985858
C591        0.1398293823003769     0.1398293823003769   0.0006073096616512283
C908        0.13769249618053436    0.13769249618053436  0.0005980286967704638
C925        0.1344267576932907     0.1344267576932907   0.000583844878583605

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_80

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 251,844 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.05954594859838891   0.09641152620315552    0.0         6.899049198788977e-05  0.12757986783981323  -0.0010636800770034557  0.15700596570968628
    3        2        Softmax                 0.0   0.0   0.001911711536195071  0.0005226063076406717  0.0         -0.06016356696636649   0.34420955181121826  -5.527227607440843e-05  0.16997677087783813


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07470207763506934
RMSE: 0.2733168081824997
LogLoss: 0.2523886723635049
Mean Per-Class Error: 0.099433133094192
AUC: 0.9612029503650367
pr_auc: 0.9568246096283245
Gini: 0.9224059007300733
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5001169708144605: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4449  549   0.1098   (549.0/4998.0)
1      448   4582  0.0891   (448.0/5030.0)
Total  4897  5131  0.0994   (997.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.500117     0.90188   204
max f2                       0.209217     0.931812  287
max f0point5                 0.733232     0.909918  136
max accuracy                 0.526594     0.900578  197
max precision                0.988861     1         0
max recall                   0.00952908   1         395
max specificity              0.988861     1         0
max absolute_mcc             0.500117     0.801305  204
max min_per_class_accuracy   0.544984     0.89936   192
max mean_per_class_accuracy  0.526594     0.900567  197
Gains/Lift Table: Avg response rate: 50.16 %, avg score: 50.08 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   0.984208           1.9739      1.9739             0.990099         0.986256   0.990099                    0.986256            0.0198807       0.0198807                  97.3899   97.3899
    2        0.0200439                   0.982615           1.99364     1.98372            1                0.983342   0.995025                    0.984806            0.0198807       0.0397614                  99.3638   98.372
    3        0.030016                    0.980872           1.99364     1.98701            1                0.981745   0.996678                    0.983789            0.0198807       0.0596421                  99.3638   98.7015
    4        0.0400878                   0.979582           1.99364     1.98868            1                0.98021    0.997512                    0.98289             0.0200795       0.0797217                  99.3638   98.8679
    5        0.0500598                   0.978379           1.99364     1.98967            1                0.979039   0.998008                    0.982123            0.0198807       0.0996024                  99.3638   98.9667
    6        0.10002                     0.972851           1.95782     1.97376            0.982036         0.975547   0.99003                     0.978838            0.0978131       0.197416                   95.7824   97.3761
    7        0.15008                     0.966751           1.96584     1.97112            0.986056         0.96985    0.988704                    0.97584             0.0984095       0.295825                   96.5838   97.1119
    8        0.20004                     0.959043           1.94987     1.96581            0.978044         0.963234   0.986042                    0.972692            0.0974155       0.393241                   94.9866   96.5811
    9        0.30006                     0.929531           1.91016     1.94726            0.958126         0.94685    0.976736                    0.964078            0.191054        0.584294                   91.0156   94.7259
    10       0.39998                     0.842878           1.75886     1.90019            0.882236         0.896274   0.953129                    0.94714             0.175746        0.76004                    75.8858   90.0194
    11       0.5                         0.548225           1.37945     1.79602            0.691924         0.720098   0.900878                    0.901722            0.137972        0.898012                   37.9447   79.6024
    12       0.60002                     0.171244           0.691711    1.61194            0.346959         0.342014   0.808542                    0.808422            0.0691849       0.967197                   -30.8289  61.1941
    13       0.69994                     0.0505113          0.216873    1.41279            0.108782         0.0943612  0.708648                    0.706486            0.02167         0.988867                   -78.3127  41.2788
    14       0.79996                     0.0229936          0.0636056   1.2441             0.0319043        0.0338713  0.624034                    0.622388            0.00636183      0.995229                   -93.6394  24.4098
    15       0.89998                     0.014008           0.0377658   1.11003            0.0189432        0.018048   0.556787                    0.555225            0.00377734      0.999006                   -96.2234  11.0031
    16       1                           0.00501361         0.00993838  1                  0.00498504       0.0107692  0.501596                    0.500768            0.000994036     1                          -99.0062  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06929815516202227
RMSE: 0.26324542761845315
LogLoss: 0.2370414392965506
Mean Per-Class Error: 0.0901088906764953
AUC: 0.9660567508193119
pr_auc: 0.9639825948621236
Gini: 0.9321135016386237
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5426991415424034: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2855  273   0.0873   (273.0/3128.0)
1      284   2765  0.0931   (284.0/3049.0)
Total  3139  3038  0.0902   (557.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.542699     0.908494  190
max f2                       0.249624     0.933971  272
max f0point5                 0.814401     0.920552  111
max accuracy                 0.5642       0.909989  185
max precision                0.98985      1         0
max recall                   0.0106882    1         393
max specificity              0.98985      1         0
max absolute_mcc             0.5642       0.819987  185
max min_per_class_accuracy   0.531981     0.907928  194
max mean_per_class_accuracy  0.5642       0.909891  185
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.45 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.983922           2.02591     2.02591            1                0.985929   1                           0.985929            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.982012           2.02591     2.02591            1                0.982926   1                           0.984427            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980443           2.02591     2.02591            1                0.98116    1                           0.983338            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.979198           2.02591     2.02591            1                0.979793   1                           0.982452            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.977945           2.02591     2.02591            1                0.978652   1                           0.981702            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.972845           2.00624     2.01608            0.990291         0.975399   0.995146                    0.97855             0.100361        0.201705                   100.624   101.608
    7        0.150073                    0.966961           1.99968     2.01061            0.987055         0.969883   0.992449                    0.975661            0.100033        0.301738                   99.9685   101.061
    8        0.200097                    0.959853           1.99313     2.00624            0.983819         0.963487   0.990291                    0.972618            0.0997048       0.401443                   99.3128   100.624
    9        0.299984                    0.931058           1.93397     1.98218            0.954619         0.947655   0.978413                    0.964306            0.193178        0.594621                   93.3973   98.2178
    10       0.400032                    0.845399           1.82266     1.94228            0.899676         0.898066   0.958721                    0.947739            0.182355        0.776976                   82.2663   94.2283
    11       0.500081                    0.51               1.35061     1.82391            0.666667         0.704559   0.900291                    0.899087            0.135126        0.912102                   35.0607   82.3909
    12       0.599968                    0.147311           0.594311    1.6192             0.293355         0.306067   0.799244                    0.800357            0.0593637       0.971466                   -40.5689  61.9197
    13       0.700016                    0.0455761          0.163909    1.4112             0.0809061        0.0831507  0.696577                    0.697852            0.0163988       0.987865                   -83.6091  41.1203
    14       0.799903                    0.0227136          0.0952211   1.24687            0.0470016        0.032006   0.615462                    0.614705            0.00951132      0.997376                   -90.4779  24.6872
    15       0.899951                    0.013736           0.0163909   1.11008            0.00809061       0.0176149  0.54794                     0.548326            0.00163988      0.999016                   -98.3609  11.0078
    16       1                           0.00501361         0.00983452  1                  0.00485437       0.0107353  0.493605                    0.494541            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:35:32  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:35:39  1:28:56.947  2419 obs/sec      0.62844   1             15711      0.31525          0.335171            0.602464       0.936756        0.882351           1.99364          0.132928                         0.310724           0.320689              0.61374          0.941025          0.888536             2.02591            0.128218
    2019-08-03 17:35:46  1:29:04.251  2388 obs/sec      1.2568    2             31420      0.298014         0.293689            0.644746       0.947538        0.932447           1.99364          0.119067                         0.289281           0.278299              0.66521          0.953078          0.940708             2.02591            0.110571
    2019-08-03 17:35:53  1:29:11.463  2391 obs/sec      1.88952   3             47238      0.293752         0.283575            0.654836       0.950831        0.943327           1.99364          0.120164                         0.283979           0.267397              0.677371         0.956671          0.94809              2.02591            0.111057
    2019-08-03 17:36:01  1:29:18.692  2391 obs/sec      2.51836   4             62959      0.290826         0.279871            0.661678       0.952067        0.943658           1.99364          0.11418                          0.280735           0.262727              0.684699         0.957937          0.948225             2.02591            0.105391
    2019-08-03 17:36:08  1:29:25.896  2385 obs/sec      3.14444   5             78611      0.287698         0.27658             0.668916       0.954801        0.93436            1.99364          0.11438                          0.275693           0.255424              0.695924         0.960832          0.943445             2.02591            0.104096
    2019-08-03 17:36:15  1:29:33.201  2381 obs/sec      3.78052   6             94513      0.298715         0.295291            0.643073       0.947575        0.93741            1.99364          0.119964                         0.28567            0.272156              0.673516         0.954899          0.942217             2.02591            0.107496
    2019-08-03 17:36:24  1:29:41.685  2318 obs/sec      4.41616   7             110404     0.2874           0.275746            0.669602       0.95346         0.947997           1.99364          0.112385                         0.274035           0.252793              0.69957          0.96093           0.948481             2.02591            0.102801
    2019-08-03 17:36:31  1:29:48.960  2324 obs/sec      5.04392   8             126098     0.283752         0.269058            0.677936       0.957008        0.956397           1.99364          0.109892                         0.273532           0.25354               0.700671         0.962549          0.958134             2.02591            0.102801
    2019-08-03 17:36:38  1:29:56.225  2330 obs/sec      5.67332   9             141833     0.282106         0.266135            0.681661       0.956725        0.951905           1.9739           0.107499                         0.272195           0.249623              0.703592         0.962217          0.956224             2.02591            0.0977821
    2019-08-03 17:36:45  1:30:03.447  2336 obs/sec      6.30316   10            157579     0.280975         0.266406            0.684209       0.958069        0.95399            1.95416          0.105205                         0.271575           0.252551              0.70494          0.96301           0.9577               1.96056            0.0982678
    2019-08-03 17:36:53  1:30:10.727  2339 obs/sec      6.933     11            173325     0.282486         0.26608             0.680804       0.95843         0.94914            1.9739           0.1071                           0.272702           0.249936              0.702486         0.962798          0.956767             2.02591            0.10021
    2019-08-03 17:37:00  1:30:17.983  2344 obs/sec      7.56748   12            189187     0.28482          0.271724            0.675507       0.954863        0.949797           1.9739           0.105205                         0.272715           0.252114              0.702457         0.961051          0.954908             2.02591            0.100372
    2019-08-03 17:37:07  1:30:25.219  2345 obs/sec      8.19252   13            204813     0.279232         0.261944            0.688114       0.95837         0.952197           1.93442          0.105704                         0.269221           0.245585              0.710033         0.963483          0.955841             1.99323            0.0951918
    2019-08-03 17:37:14  1:30:32.485  2348 obs/sec      8.82396   14            220599     0.281635         0.270498            0.682723       0.958023        0.948655           1.95416          0.105505                         0.269493           0.249251              0.709447         0.963764          0.950697             1.99323            0.0945443
    2019-08-03 17:37:21  1:30:39.432  2355 obs/sec      9.44504   15            236126     0.279589         0.264962            0.687318       0.958819        0.949803           1.95416          0.10361                          0.269111           0.245973              0.710271         0.96414           0.957609             1.99323            0.0942205
    2019-08-03 17:37:29  1:30:46.789  2354 obs/sec      10.0738   16            251844     0.273317         0.252389            0.701189       0.961203        0.956825           1.9739           0.0994216                        0.263245           0.237041              0.722762         0.966057          0.963983             2.02591            0.0901732
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005392036135947262
C438        0.8658882975578308     0.8658882975578308   0.0046689009901256795
C374        0.7696088552474976     0.7696088552474976   0.004149758758039513
C88         0.6946024894714355     0.6946024894714355   0.003745321723348909
C863        0.6687373518943787     0.6687373518943787   0.0036058559668721703
---         ---                    ---                  ---
C667        0.09564826637506485    0.09564826637506485  0.0005157389086350592
C835        0.0954255536198616     0.0954255536198616   0.0005145380334110669
C520        0.09490735083818436    0.09490735083818436  0.0005117438652865148
C949        0.09278224408626556    0.09278224408626556  0.0005002852128874231
C921        0.09177849441766739    0.09177849441766739  0.0004948729584028967

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_167

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 253,379 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  ------------------
    1        980      Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.07006185117855573   0.10359311103820801    0.0         -0.0011990652259389891  0.10826906561851501  0.018259738265523986  0.1408834457397461
    3        2        Softmax                 0.0   0.0   0.002069534193879008  0.0005980622954666615  0.0         0.01743834667399824     0.2660874128341675   0.001113819597578572  0.2369270920753479


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07445771656030452
RMSE: 0.2728694130171143
LogLoss: 0.25362927430196114
Mean Per-Class Error: 0.09875334317262174
AUC: 0.9614601149895051
pr_auc: 0.9534836405764464
Gini: 0.9229202299790102
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.40011424314209837: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4406  593   0.1186   (593.0/4999.0)
1      402   4614  0.0801   (402.0/5016.0)
Total  4808  5207  0.0994   (995.0/10015.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.400114     0.90267   229
max f2                       0.153675     0.93      303
max f0point5                 0.834417     0.914051  98
max accuracy                 0.492313     0.901248  204
max precision                0.997069     1         0
max recall                   0.00161062   1         399
max specificity              0.997069     1         0
max absolute_mcc             0.492313     0.802496  204
max min_per_class_accuracy   0.495154     0.90078   203
max mean_per_class_accuracy  0.492313     0.901247  204
Gains/Lift Table: Avg response rate: 50.08 %, avg score: 49.59 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100849                   0.995444           1.99661    1.99661            1                0.996211    1                           0.996211            0.0201356       0.0201356                  99.6611   99.6611
    2        0.0200699                   0.994336           1.99661    1.99661            1                0.994888    1                           0.995553            0.0199362       0.0400718                  99.6611   99.6611
    3        0.0300549                   0.99347            1.97664    1.98998            0.99             0.993912    0.996678                    0.995008            0.0197368       0.0598086                  97.6645   98.9978
    4        0.0400399                   0.992736           1.99661    1.99163            1                0.993098    0.997506                    0.994531            0.0199362       0.0797448                  99.6611   99.1632
    5        0.050025                    0.992058           1.99661    1.99263            1                0.992448    0.998004                    0.994116            0.0199362       0.099681                   99.6611   99.2626
    6        0.10005                     0.988798           1.9727     1.98266            0.988024         0.990462    0.993014                    0.992289            0.0986842       0.198365                   97.2699   98.2662
    7        0.150075                    0.984724           1.94879    1.97137            0.976048         0.986833    0.987359                    0.99047             0.097488        0.295853                   94.8788   97.1371
    8        0.2                         0.979356           1.96467    1.9697             0.984            0.982301    0.98652                     0.988431            0.0980861       0.393939                   96.4665   96.9697
    9        0.30005                     0.953577           1.90495    1.94811            0.954092         0.968742    0.975707                    0.981866            0.19059         0.58453                    90.495    94.8107
    10       0.4                         0.858832           1.80313    1.91188            0.903097         0.917674    0.957564                    0.965826            0.180223        0.764753                   80.3133   91.1882
    11       0.50005                     0.495445           1.35299    1.80006            0.677645         0.712513    0.901558                    0.915143            0.135367        0.90012                    35.2993   80.0059
    12       0.6                         0.128586           0.654234   1.60918            0.327672         0.281109    0.805958                    0.809523            0.0653907       0.96551                    -34.5766  60.9184
    13       0.69995                     0.033156           0.219408   1.41073            0.10989          0.0698317   0.706562                    0.703898            0.0219298       0.98744                    -78.0592  41.0729
    14       0.8                         0.0118909          0.0876755  1.24527            0.0439122        0.020316    0.623689                    0.618408            0.00877193      0.996212                   -91.2324  24.5265
    15       0.89995                     0.00531049         0.0239354  1.10962            0.011988         0.00798846  0.555753                    0.550614            0.00239234      0.998604                   -97.6065  10.9622
    16       1                           0.00107101         0.0139484  1                  0.00698603       0.00354213  0.500849                    0.495879            0.00139553      1                          -98.6052  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06972205114278836
RMSE: 0.2640493346759055
LogLoss: 0.23797670539882596
Mean Per-Class Error: 0.09154583197375521
AUC: 0.9655424003845124
pr_auc: 0.9559547192234655
Gini: 0.9310848007690249
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4804637737394904: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2814  314   0.1004   (314.0/3128.0)
1      253   2796  0.083    (253.0/3049.0)
Total  3067  3110  0.0918   (567.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.480464     0.90794   209
max f2                       0.153173     0.934066  304
max f0point5                 0.820342     0.919869  110
max accuracy                 0.496369     0.90837   205
max precision                0.996811     1         0
max recall                   0.00393094   1         395
max specificity              0.996811     1         0
max absolute_mcc             0.492685     0.816845  206
max min_per_class_accuracy   0.524587     0.90665   196
max mean_per_class_accuracy  0.492685     0.908454  206
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.58 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.995636           2.02591     2.02591            1                0.996269    1                           0.996269            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.994573           2.02591     2.02591            1                0.995092    1                           0.99568             0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.993898           2.02591     2.02591            1                0.994225    1                           0.995195            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.993104           2.02591     2.02591            1                0.993475    1                           0.994765            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.992586           2.02591     2.02591            1                0.992828    1                           0.994383            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.988791           2.0128      2.01935            0.993528         0.990736    0.996764                    0.992559            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.984881           1.99968     2.0128             0.987055         0.986913    0.993528                    0.990677            0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.979262           1.9669      2.00132            0.970874         0.982312    0.987864                    0.988586            0.0983929       0.400459                   96.6903   100.132
    9        0.299984                    0.952703           1.94382     1.98218            0.959481         0.968553    0.978413                    0.981915            0.194162        0.594621                   94.3823   98.2178
    10       0.400032                    0.861441           1.80299     1.93736            0.889968         0.918899    0.956293                    0.966155            0.180387        0.775008                   80.2994   93.7364
    11       0.500081                    0.499717           1.38339     1.82653            0.682848         0.711998    0.901586                    0.915307            0.138406        0.913414                   38.3388   82.6533
    12       0.599968                    0.128567           0.58446     1.61974            0.288493         0.281233    0.799514                    0.809742            0.0583798       0.971794                   -41.554   61.9744
    13       0.700016                    0.032035           0.167187    1.41214            0.0825243        0.0685344   0.69704                     0.703806            0.0167268       0.988521                   -83.2813  41.214
    14       0.799903                    0.0115056          0.0755202   1.24523            0.0372771        0.0196249   0.614653                    0.61837             0.00754346      0.996064                   -92.448   24.5232
    15       0.899951                    0.00540455         0.0295035   1.11008            0.0145631        0.0079408   0.54794                     0.550508            0.00295179      0.999016                   -97.0496  11.0078
    16       1                           0.000778521        0.00983452  1                  0.00485437       0.00365263  0.493605                    0.495796            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:22:44  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:22:51  3:16:09.881  1258 obs/sec      0.36032   1             9008       0.328581         0.382764            0.568137       0.930452        0.81184            1.99661          0.143784                         0.321438           0.361251              0.586644         0.936282          0.829565             2.02591            0.137445
    2019-08-03 19:23:07  3:16:25.343  1255 obs/sec      1.08004   3             27001      0.30432          0.304357            0.629557       0.944003        0.918017           1.99661          0.125412                         0.295896           0.288591              0.649724         0.949344          0.928709             2.02591            0.117857
    2019-08-03 19:23:23  3:16:41.027  1253 obs/sec      1.8094    5             45235      0.298068         0.29226             0.644621       0.94779         0.9406             1.99661          0.121518                         0.29128            0.280899              0.660569         0.952063          0.940362             2.02591            0.114781
    2019-08-03 19:23:38  3:16:56.535  1250 obs/sec      2.5238    7             63095      0.291057         0.279529            0.661143       0.952578        0.93762            1.99661          0.117424                         0.282039           0.263973              0.681764         0.957414          0.938715             2.02591            0.109114
    2019-08-03 19:23:54  3:17:12.555  1245 obs/sec      3.2512    9             81280      0.289075         0.278287            0.665741       0.952697        0.940843           1.99661          0.114828                         0.283814           0.267562              0.677746         0.956329          0.94606              2.02591            0.113162
    2019-08-03 19:24:09  3:17:27.963  1249 obs/sec      3.97568   11            99392      0.289667         0.282745            0.66437        0.954261        0.938936           1.97684          0.110434                         0.279542           0.263256              0.687374         0.959416          0.950182             2.02591            0.100696
    2019-08-03 19:24:25  3:17:43.550  1250 obs/sec      4.70168   13            117542     0.285145         0.271787            0.674767       0.956251        0.946783           1.99661          0.110634                         0.277187           0.256756              0.692619         0.960562          0.94472              2.02591            0.104258
    2019-08-03 19:24:41  3:17:59.053  1251 obs/sec      5.42464   15            135616     0.280665         0.263253            0.684909       0.957903        0.952285           1.99661          0.10634                          0.273802           0.251471              0.700081         0.961484          0.957022             2.02591            0.0997248
    2019-08-03 19:24:56  3:18:14.497  1253 obs/sec      6.1492    17            153730     0.281221         0.266293            0.683657       0.956397        0.95032            1.99661          0.107139                         0.276224           0.25642               0.69475          0.96001           0.953955             2.02591            0.104096
    2019-08-03 19:25:11  3:18:29.916  1254 obs/sec      6.86736   19            171684     0.279785         0.263669            0.68688        0.957774        0.954747           1.97684          0.106241                         0.273547           0.252537              0.700638         0.961092          0.95404              1.99323            0.101344
    2019-08-03 19:25:27  3:18:45.700  1253 obs/sec      7.5932    21            189830     0.279679         0.263589            0.687119       0.958835        0.94853            1.99661          0.104643                         0.272985           0.250759              0.701867         0.962842          0.948375             2.02591            0.100534
    2019-08-03 19:25:43  3:19:01.133  1254 obs/sec      8.32084   23            208021     0.27582          0.256043            0.695692       0.959732        0.95433            1.99661          0.101048                         0.267797           0.243403              0.713091         0.963569          0.957653             2.02591            0.091954
    2019-08-03 19:25:58  3:19:16.615  1255 obs/sec      9.0448    25            226120     0.275675         0.2569              0.696012       0.960101        0.95171            1.99661          0.101048                         0.265865           0.240584              0.717218         0.964722          0.95429              2.02591            0.0932492
    2019-08-03 19:26:13  3:19:31.937  1256 obs/sec      9.77008   27            244252     0.274396         0.255532            0.698827       0.960942        0.947659           1.97684          0.0999501                        0.265359           0.240352              0.718293         0.964998          0.949837             1.99323            0.0924397
    2019-08-03 19:26:22  3:19:40.151  1257 obs/sec      10.1352   28            253379     0.272869         0.253629            0.702168       0.96146         0.953484           1.99661          0.099351                         0.264049           0.237977              0.721066         0.965542          0.955955             2.02591            0.0917921
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004363339698658842
C438        0.7971876263618469     0.7971876263618469   0.003478400417384258
C374        0.7076454162597656     0.7076454162597656   0.0030876973373401965
C88         0.6699357628822327     0.6699357628822327   0.0029231573097353424
C322        0.6664921641349792     0.6664921641349792   0.0029081317186151995
---         ---                    ---                  ---
C632        0.14469844102859497    0.14469844102859497  0.0006313684520741137
C880        0.14381849765777588    0.14381849765777588  0.0006275289602316472
C885        0.14251233637332916    0.14251233637332916  0.0006218297348463696
C921        0.13976667821407318    0.13976667821407318  0.0006098494956011414
C916        0.136535182595253      0.136535182595253    0.0005957493824815011

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_61

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 260,458 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.05281448354670996    0.0842278003692627     0.0         -0.0029021284037678923  0.13348615169525146  0.012640137579711823   0.14338809251785278
    3        2        Softmax                 0.0   0.0   0.0018020954821622581  0.0003851233050227165  0.0         0.005318487240799641    0.33577585220336914  0.0005926584131642487  0.17420166730880737


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07752420393302527
RMSE: 0.27843168629490656
LogLoss: 0.2622736164389512
Mean Per-Class Error: 0.10203449298622247
AUC: 0.9584690564757009
pr_auc: 0.9518815304312673
Gini: 0.9169381129514018
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43423093349989395: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4385  613   0.1226   (613.0/4998.0)
1      415   4616  0.0825   (415.0/5031.0)
Total  4800  5229  0.1025   (1028.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.434231     0.899805  219
max f2                       0.129983     0.926704  313
max f0point5                 0.772424     0.910047  123
max accuracy                 0.485818     0.897996  204
max precision                0.993025     1         0
max recall                   0.00469349   1         398
max specificity              0.993025     1         0
max absolute_mcc             0.485818     0.796103  204
max min_per_class_accuracy   0.535561     0.896959  192
max mean_per_class_accuracy  0.485818     0.897966  204
Gains/Lift Table: Avg response rate: 50.16 %, avg score: 50.09 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   0.990104           1.9737     1.9737             0.990099         0.991607    0.990099                    0.991607            0.0198768       0.0198768                  97.3704   97.3704
    2        0.0200419                   0.988328           1.97351    1.97361            0.99             0.989051    0.99005                     0.990335            0.019678        0.0395548                  97.3506   97.3605
    3        0.030013                    0.987038           1.99344    1.9802             1                0.987624    0.993355                    0.989435            0.0198768       0.0594315                  99.3441   98.0195
    4        0.0400838                   0.985957           1.99344    1.98352            1                0.986518    0.995025                    0.988702            0.0200755       0.0795071                  99.3441   98.3523
    5        0.0500548                   0.985091           1.99344    1.9855             1                0.985487    0.996016                    0.988061            0.0198768       0.0993838                  99.3441   98.5499
    6        0.10001                     0.98092            1.97355    1.97953            0.99002          0.982954    0.993021                    0.98551             0.0985887       0.197973                   97.3546   97.9528
    7        0.150065                    0.97588            1.96961    1.97622            0.988048         0.978506    0.991362                    0.983174            0.0985887       0.296561                   96.9615   97.6222
    8        0.20002                     0.969514           1.94569    1.9686             0.976048         0.97285     0.987537                    0.980596            0.0971974       0.393759                   94.5694   96.8597
    9        0.30003                     0.944538           1.88612    1.9411             0.946162         0.958635    0.973745                    0.973276            0.18863         0.582389                   88.6117   94.1104
    10       0.40004                     0.863651           1.77482    1.89953            0.890329         0.913662    0.952891                    0.958372            0.1775          0.759889                   77.4818   89.9532
    11       0.50005                     0.540805           1.35149    1.78992            0.677966         0.735875    0.897906                    0.913873            0.135162        0.895051                   35.1485   78.9923
    12       0.59996                     0.140251           0.674428   1.60416            0.338323         0.31015     0.80472                     0.813336            0.0673822       0.962433                   -32.5572  60.4161
    13       0.69997                     0.0403464          0.24446    1.40989            0.122632         0.078597    0.707265                    0.708358            0.0244484       0.986881                   -75.554   40.9891
    14       0.79998                     0.0188235          0.0616118  1.24133            0.0309073        0.0273234   0.62271                     0.623218            0.0061618       0.993043                   -93.8388  24.1335
    15       0.89999                     0.0113381          0.0437245  1.10825            0.0219342        0.0145414   0.555949                    0.55558             0.00437289      0.997416                   -95.6275  10.8252
    16       1                           0.00309829         0.0258372  1                  0.0129611        0.00854987  0.501645                    0.500872            0.00258398      1                          -97.4163  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.06982289075737541
RMSE: 0.26424021411847104
LogLoss: 0.2382976378716774
Mean Per-Class Error: 0.0916328065300015
AUC: 0.9652033621354198
pr_auc: 0.9591598793884428
Gini: 0.9304067242708396
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48530929654066174: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2817  311   0.0994   (311.0/3128.0)
1      258   2791  0.0846   (258.0/3049.0)
Total  3075  3102  0.0921   (569.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.485309     0.907495  206
max f2                       0.182449     0.93401   294
max f0point5                 0.806268     0.918585  115
max accuracy                 0.536301     0.90837   194
max precision                0.993051     1         0
max recall                   0.00561767   1         398
max specificity              0.993051     1         0
max absolute_mcc             0.536301     0.816716  194
max min_per_class_accuracy   0.536301     0.908167  194
max mean_per_class_accuracy  0.536301     0.908367  194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.57 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.989791           2.02591    2.02591            1                0.991309    1                           0.991309            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.98816            2.02591    2.02591            1                0.988968    1                           0.990139            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.987071           2.02591    2.02591            1                0.987662    1                           0.989313            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.986011           2.02591    2.02591            1                0.986548    1                           0.988622            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.985168           2.02591    2.02591            1                0.985636    1                           0.988033            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.980829           1.98002    2.00296            0.977346         0.982975    0.988673                    0.985504            0.0990489       0.200394                   98.0016   100.296
    7        0.150073                    0.975875           2.02591    2.01061            1                0.978448    0.992449                    0.983152            0.101345        0.301738                   102.591   101.061
    8        0.200097                    0.969696           1.98657    2.0046             0.980583         0.972994    0.989482                    0.980612            0.0993768       0.401115                   98.6572   100.46
    9        0.299984                    0.945168           1.94711    1.98546            0.961102         0.959356    0.980032                    0.973535            0.19449         0.595605                   94.7106   98.5458
    10       0.400032                    0.855664           1.81283    1.94228            0.894822         0.912213    0.958721                    0.958198            0.181371        0.776976                   81.2829   94.2283
    11       0.500081                    0.507639           1.35716    1.82522            0.669903         0.72025     0.900939                    0.910593            0.135782        0.912758                   35.7163   82.5221
    12       0.599968                    0.130964           0.587744   1.6192             0.290113         0.284399    0.799244                    0.80634             0.0587078       0.971466                   -41.2256  61.9197
    13       0.700016                    0.0379599          0.177021   1.41308            0.0873786        0.0712669   0.697502                    0.701281            0.0177107       0.989177                   -82.2979  41.3077
    14       0.799903                    0.0178217          0.0689532  1.24523            0.0340357        0.0261059   0.614653                    0.61697             0.0068875       0.996064                   -93.1047  24.5232
    15       0.899951                    0.0109096          0.0262254  1.10971            0.012945         0.0138506   0.54776                     0.54992             0.00262381      0.998688                   -97.3775  10.9713
    16       1                           0.00309829         0.0131127  1                  0.00647249       0.00844058  0.493605                    0.495746            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:13:38  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:13:44  1:07:02.177  2604 obs/sec      0.61272   1             15318      0.322036         0.361019            0.585167       0.933844        0.827557           1.99344          0.142088                         0.315644           0.3449                0.601411         0.938337          0.855739             2.02591            0.138255
    2019-08-03 17:13:57  1:07:15.287  2513 obs/sec      1.8434    3             46085      0.296594         0.289875            0.648124       0.948825        0.938469           1.99344          0.121348                         0.284418           0.270212              0.676373         0.956338          0.948385             2.02591            0.106686
    2019-08-03 17:14:04  1:07:22.216  2495 obs/sec      2.46196   4             61549      0.292071         0.281938            0.658774       0.951195        0.930569           1.99344          0.115066                         0.279665           0.262458              0.687098         0.957525          0.941231             2.02591            0.102477
    2019-08-03 17:14:11  1:07:28.952  2498 obs/sec      3.07292   5             76823      0.288071         0.275259            0.668056       0.953656        0.940937           1.99344          0.112075                         0.276201           0.255985              0.694803         0.960028          0.946832             2.02591            0.103286
    2019-08-03 17:14:18  1:07:35.672  2502 obs/sec      3.68784   6             92196      0.287432         0.274512            0.669528       0.953959        0.940979           1.99344          0.111776                         0.27602            0.254855              0.695202         0.960752          0.947248             2.02591            0.101344
    2019-08-03 17:14:24  1:07:42.564  2494 obs/sec      4.29672   7             107418     0.287525         0.275405            0.669314       0.954704        0.943075           1.99344          0.111178                         0.275079           0.252797              0.697276         0.961514          0.947105             2.02591            0.10442
    2019-08-03 17:14:31  1:07:49.456  2485 obs/sec      4.9076    8             122690     0.289284         0.277005            0.665256       0.953968        0.943256           1.99344          0.114368                         0.277223           0.256425              0.692539         0.960853          0.956133             2.02591            0.101991
    2019-08-03 17:14:38  1:07:56.098  2493 obs/sec      5.52112   9             138028     0.287925         0.277569            0.668393       0.952654        0.936294           1.9737           0.108386                         0.276241           0.256386              0.694714         0.959709          0.95397              2.02591            0.101667
    2019-08-03 17:14:45  1:08:02.660  2501 obs/sec      6.12756   10            153189     0.285924         0.273124            0.672987       0.954932        0.947517           1.99344          0.11028                          0.273139           0.251076              0.701531         0.961903          0.953113             2.02591            0.0989153
    2019-08-03 17:14:58  1:08:15.543  2503 obs/sec      7.3568    12            183920     0.284137         0.271318            0.67706        0.954837        0.950548           1.95397          0.10689                          0.27299            0.252827              0.701858         0.961065          0.955004             2.02591            0.0989153
    2019-08-03 17:15:04  1:08:22.358  2500 obs/sec      7.96408   13            199102     0.282222         0.268404            0.681399       0.956315        0.950891           1.95397          0.105095                         0.271145           0.248591              0.705874         0.962529          0.958247             2.02591            0.099401
    2019-08-03 17:15:11  1:08:29.142  2499 obs/sec      8.57648   14            214412     0.280485         0.263824            0.685309       0.957829        0.954006           1.9737           0.105295                         0.268896           0.24521               0.710733         0.963401          0.958565             2.02591            0.0976202
    2019-08-03 17:15:18  1:08:35.915  2501 obs/sec      9.19096   15            229774     0.277904         0.261724            0.691073       0.959288        0.954099           1.9737           0.0994117                        0.26596            0.240764              0.717015         0.964969          0.952942             1.99323            0.0930873
    2019-08-03 17:15:31  1:08:48.586  2506 obs/sec      10.4183   17            260458     0.278432         0.262274            0.6899         0.958469        0.951882           1.9737           0.102503                         0.26424            0.238298              0.720663         0.965203          0.95916              2.02591            0.0921159
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005465961857389762
C438        0.84532630443573       0.84532630443573     0.0046205213370939455
C374        0.7546824216842651     0.7546824216842651   0.004125065331368729
C322        0.6964058876037598     0.6964058876037598   0.003806528018903812
C863        0.6828445196151733     0.6828445196151733   0.0037324020987441722
---         ---                    ---                  ---
C862        0.09991975873708725    0.09991975873708725  0.0005461575900565063
C925        0.09889904409646988    0.09889904409646988  0.0005405784027636124
C741        0.09709055721759796    0.09709055721759796  0.0005306932824641087
C880        0.08879971504211426    0.08879971504211426  0.0004853758553672764
C762        0.0829063281416893     0.0829063281416893   0.0004531628273587131

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_113

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 250,201 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.06479143909114936   0.10218286514282227    0.0         -0.0009792666297502104  0.12694668769836426  -0.012205903022254796  0.14938616752624512
    3        2        Softmax                 0.0   0.0   0.001841964682625985  0.0004679097328335047  0.0         -0.018221748778216806   0.3752497434616089   0.0020906100902437497  0.1859591007232666


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07629754313768501
RMSE: 0.2762200990834755
LogLoss: 0.25883217372585215
Mean Per-Class Error: 0.10211900783150041
AUC: 0.958802865654843
pr_auc: 0.9542549001463111
Gini: 0.9176057313096859
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4197165150780301: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4374  655   0.1302   (655.0/5029.0)
1      376   4616  0.0753   (376.0/4992.0)
Total  4750  5271  0.1029   (1031.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.419717     0.899542  227
max f2                       0.146551     0.927896  310
max f0point5                 0.783682     0.91029   119
max accuracy                 0.473538     0.897815  213
max precision                0.989837     1         0
max recall                   0.00887514   1         397
max specificity              0.989837     1         0
max absolute_mcc             0.473538     0.796191  213
max min_per_class_accuracy   0.562217     0.897196  189
max mean_per_class_accuracy  0.473538     0.897881  213
Gains/Lift Table: Avg response rate: 49.82 %, avg score: 49.91 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   0.984388           2.00741    2.00741            1                0.986625   1                           0.986625            0.0202324       0.0202324                  100.741   100.741
    2        0.0200579                   0.982348           1.98734    1.99742            0.99             0.983248   0.995025                    0.984945            0.0198317       0.0400641                  98.7338   99.7425
    3        0.0300369                   0.980647           1.96726    1.9874             0.98             0.981505   0.990033                    0.983802            0.0196314       0.0596955                  96.7264   98.7404
    4        0.040016                    0.979391           1.98734    1.98739            0.99             0.980055   0.990025                    0.982868            0.0198317       0.0795272                  98.7338   98.7388
    5        0.0500948                   0.978056           1.98754    1.98742            0.990099         0.978635   0.99004                     0.982016            0.0200321       0.0995593                  98.7536   98.7418
    6        0.10009                     0.971576           1.98337    1.9854             0.988024         0.974789   0.989033                    0.978406            0.0991587       0.198718                   98.3371   98.5396
    7        0.150085                    0.965144           1.94731    1.97271            0.97006          0.96834    0.982713                    0.975053            0.0973558       0.296074                   94.731    97.2709
    8        0.20008                     0.956711           1.97536    1.97337            0.984032         0.961085   0.983042                    0.971563            0.098758        0.394832                   97.5357   97.3371
    9        0.30007                     0.929672           1.91125    1.95267            0.952096         0.94527    0.97273                     0.962801            0.191106        0.585938                   91.1248   95.267
    10       0.40006                     0.846312           1.77902    1.90927            0.886228         0.89663    0.95111                     0.946263            0.177885        0.763822                   77.9024   90.9269
    11       0.50005                     0.555955           1.34829    1.7971             0.671657         0.724791   0.89523                     0.901977            0.134816        0.898638                   34.8292   79.7096
    12       0.60004                     0.158191           0.669137   1.60913            0.333333         0.331297   0.801597                    0.80688             0.0669071       0.965545                   -33.0863  60.9134
    13       0.70003                     0.0462232          0.220375   1.41077            0.10978          0.0865546  0.70278                     0.703991            0.0220353       0.98758                    -77.9625  41.0768
    14       0.80002                     0.0239247          0.0601022  1.24196            0.0299401        0.032937   0.618685                    0.620119            0.00600962      0.99359                    -93.9898  24.1956
    15       0.90001                     0.0143916          0.0340579  1.10776            0.0169661        0.0185402  0.551835                    0.553285            0.00340545      0.996995                   -96.5942  10.776
    16       1                           0.00454541         0.0300511  1                  0.0149701        0.010892   0.498154                    0.499051            0.00300481      1                          -96.9949  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.069694302645547
RMSE: 0.26399678529396337
LogLoss: 0.23908499081122414
Mean Per-Class Error: 0.09080704629164393
AUC: 0.9652613975988102
pr_auc: 0.9618623464609369
Gini: 0.9305227951976205
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46779434535711084: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2801  327   0.1045   (327.0/3128.0)
1      235   2814  0.0771   (235.0/3049.0)
Total  3036  3141  0.091    (562.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.467794     0.909208  212
max f2                       0.20569      0.930417  287
max f0point5                 0.801546     0.921567  118
max accuracy                 0.467794     0.909017  212
max precision                0.989568     1         0
max recall                   0.0076582    1         398
max specificity              0.989568     1         0
max absolute_mcc             0.467794     0.818437  212
max min_per_class_accuracy   0.540231     0.906969  193
max mean_per_class_accuracy  0.467794     0.909193  212
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.53 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.984423           2.02591    2.02591            1                0.986572   1                           0.986572            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.982022           2.02591    2.02591            1                0.982984   1                           0.984778            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980617           2.02591    2.02591            1                0.981324   1                           0.983627            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.979271           2.02591    2.02591            1                0.979969   1                           0.982712            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.977974           1.95949    2.0128             0.967213         0.978589   0.993528                    0.981898            0.0193506       0.100689                   95.9487   101.28
    6        0.100049                    0.9717             2.01935    2.01608            0.996764         0.974975   0.995146                    0.978437            0.101017        0.201705                   101.935   101.608
    7        0.150073                    0.965602           2.00624    2.0128             0.990291         0.968649   0.993528                    0.975174            0.100361        0.302066                   100.624   101.28
    8        0.200097                    0.957544           1.98002    2.0046             0.977346         0.961776   0.989482                    0.971825            0.0990489       0.401115                   98.0016   100.46
    9        0.299984                    0.930447           1.94382    1.98436            0.959481         0.945995   0.979493                    0.963224            0.194162        0.595277                   94.3823   98.4364
    10       0.400032                    0.850166           1.82594    1.94474            0.901294         0.899154   0.959935                    0.9472              0.182683        0.77796                    82.5942   94.4743
    11       0.500081                    0.517037           1.36372    1.8285             0.673139         0.715581   0.902557                    0.900861            0.136438        0.914398                   36.3719   82.85
    12       0.599968                    0.14459            0.554909   1.61646            0.273906         0.303677   0.797895                    0.801438            0.055428        0.969826                   -44.5091  61.6464
    13       0.700016                    0.0455849          0.186856   1.41214            0.092233         0.0829898  0.69704                     0.698755            0.0186947       0.988521                   -81.3144  41.214
    14       0.799903                    0.0233209          0.0722367  1.24482            0.0356564        0.0324668  0.614451                    0.615553            0.00721548      0.995736                   -92.7763  24.4822
    15       0.899951                    0.0141342          0.0262254  1.10935            0.012945         0.0182728  0.547581                    0.549153            0.00262381      0.99836                    -97.3775  10.9349
    16       1                           0.00492674         0.0163909  1                  0.00809061       0.0107938  0.493605                    0.495291            0.00163988      1                          -98.3609  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:14:32  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:14:39  2:07:56.654  2432 obs/sec      0.58972   1             14743      0.314994         0.334866            0.603111       0.937403        0.873974           2.00741          0.136813                         0.301998           0.301246              0.63513          0.947679          0.885571             2.02591            0.125304
    2019-08-03 18:14:45  2:08:03.115  2470 obs/sec      1.17616   2             29404      0.298145         0.296059            0.644433       0.946626        0.927628           2.00741          0.119549                         0.289071           0.277838              0.665698         0.953081          0.931278             2.02591            0.11041
    2019-08-03 18:14:52  2:08:09.709  2462 obs/sec      1.762     3             44050      0.298908         0.297223            0.64261        0.946515        0.938478           1.98754          0.118551                         0.291342           0.281753              0.660424         0.951746          0.939864             2.02591            0.114457
    2019-08-03 18:14:58  2:08:16.213  2471 obs/sec      2.35108   4             58777      0.285418         0.273421            0.674142       0.95405         0.933223           2.00741          0.10957                          0.28023            0.260775              0.685833         0.958525          0.944249             2.02591            0.107334
    2019-08-03 18:15:05  2:08:22.957  2468 obs/sec      2.94536   5             73634      0.286075         0.272962            0.672639       0.954314        0.948182           2.00741          0.111965                         0.279725           0.26015               0.686965         0.959004          0.951962             2.02591            0.107334
    2019-08-03 18:15:18  2:08:35.624  2461 obs/sec      4.12056   7             103014     0.284504         0.272744            0.676225       0.953821        0.94147            2.00741          0.10957                          0.274972           0.253716              0.697513         0.960694          0.951183             2.02591            0.0998867
    2019-08-03 18:15:24  2:08:42.285  2461 obs/sec      4.7114    8             117785     0.28219          0.269301            0.68147        0.955424        0.946618           2.00741          0.10498                          0.273204           0.251676              0.701389         0.96128           0.949733             2.02591            0.0976202
    2019-08-03 18:15:31  2:08:48.988  2458 obs/sec      5.30264   9             132566     0.284585         0.272493            0.676041       0.954298        0.950038           2.00741          0.110867                         0.274266           0.253815              0.699064         0.960632          0.958324             2.02591            0.101182
    2019-08-03 18:15:38  2:08:55.733  2454 obs/sec      5.8894    10            147235     0.281699         0.266478            0.682577       0.956929        0.948315           1.98754          0.107674                         0.272666           0.25061               0.702564         0.962131          0.952754             2.02591            0.103124
    2019-08-03 18:15:44  2:09:02.410  2454 obs/sec      6.47916   11            161979     0.281882         0.270879            0.682165       0.957013        0.947621           1.94779          0.107375                         0.272351           0.252446              0.703252         0.962428          0.954634             2.02591            0.0981059
    2019-08-03 18:15:57  2:09:14.802  2458 obs/sec      7.6528    13            191320     0.280197         0.266248            0.685954       0.956234        0.949899           1.98754          0.105379                         0.271076           0.24872               0.706024         0.962314          0.959273             2.02591            0.0961632
    2019-08-03 18:16:03  2:09:21.345  2459 obs/sec      8.24324   14            206081     0.2765           0.258422            0.694186       0.958939        0.952625           2.00741          0.104181                         0.267362           0.242608              0.714024         0.964536          0.959806             2.02591            0.0990772
    2019-08-03 18:16:10  2:09:27.895  2461 obs/sec      8.83112   15            220778     0.279584         0.26476             0.687328       0.956449        0.949221           1.98754          0.105578                         0.268179           0.245109              0.712273         0.96314           0.960416             2.02591            0.0958394
    2019-08-03 18:16:17  2:09:34.522  2460 obs/sec      9.418     16            235450     0.276538         0.259595            0.694104       0.958518        0.953746           2.00741          0.102385                         0.264517           0.239845              0.720078         0.965573          0.963081             2.02591            0.0916302
    2019-08-03 18:16:23  2:09:40.946  2466 obs/sec      10.008    17            250201     0.27622          0.258832            0.694806       0.958803        0.954255           2.00741          0.102884                         0.263997           0.239085              0.721177         0.965261          0.961862             2.02591            0.0909827
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005696779978887248
C438        0.8518701791763306     0.8518701791763306   0.004852916981342812
C374        0.7127363085746765     0.7127363085746765   0.00406030193291422
C863        0.6894908547401428     0.6894908547401428   0.003927877696909501
C322        0.6442340612411499     0.6442340612411499   0.003670059701795804
---         ---                    ---                  ---
C921        0.08919155597686768    0.08919155597686768  0.000508104670374821
C849        0.08891662955284119    0.08891662955284119  0.0005065384750267599
C555        0.08696932345628738    0.08696932345628738  0.0004954451006431471
C889        0.08596030622720718    0.08596030622720718  0.0004896969514941707
C741        0.08358025550842285    0.08358025550842285  0.0004761383262106639

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_55

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 251,541 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.06299287947617442    0.09588047862052917    0.0         0.0003470179002491961  0.11042526364326477  -0.005519793457128721  0.11486020684242249
    3        2        Softmax                 0.0   0.0   0.0018828379379556281  0.0004639460239559412  0.0         -0.021476674565519716  0.32899701595306396  5.029456720753722e-05  0.16887003183364868


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07744700625640775
RMSE: 0.2782930222919859
LogLoss: 0.26012606999913584
Mean Per-Class Error: 0.10297217618440246
AUC: 0.9593288680360903
pr_auc: 0.9513882920889077
Gini: 0.9186577360721806
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.40082849238405777: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4364  612   0.123    (612.0/4976.0)
1      420   4632  0.0831   (420.0/5052.0)
Total  4784  5244  0.1029   (1032.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.400828     0.899767  235
max f2                       0.15324      0.929939  308
max f0point5                 0.755373     0.906889  131
max accuracy                 0.455035     0.897088  218
max precision                0.994615     1         0
max recall                   0.00329928   1         399
max specificity              0.994615     1         0
max absolute_mcc             0.400828     0.794688  235
max min_per_class_accuracy   0.49369      0.896477  207
max mean_per_class_accuracy  0.455035     0.897028  218
Gains/Lift Table: Avg response rate: 50.38 %, avg score: 49.38 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   0.992837           1.98496    1.98496            1                0.993894    1                           0.993894            0.0199921       0.0199921                  98.4956   98.4956
    2        0.0200439                   0.991613           1.98496    1.98496            1                0.992185    1                           0.993044            0.0197941       0.0397862                  98.4956   98.4956
    3        0.030016                    0.990448           1.98496    1.98496            1                0.991007    1                           0.992367            0.0197941       0.0595804                  98.4956   98.4956
    4        0.0400878                   0.989534           1.98496    1.98496            1                0.989981    1                           0.991768            0.0199921       0.0795724                  98.4956   98.4956
    5        0.0500598                   0.988548           1.94526    1.97705            0.98             0.989029    0.996016                    0.991222            0.0193983       0.0989707                  94.5257   97.7048
    6        0.10002                     0.984207           1.97703    1.97704            0.996008         0.986319    0.996012                    0.988773            0.0987728       0.197743                   97.7032   97.704
    7        0.15008                     0.978953           1.96123    1.97177            0.988048         0.98168     0.993355                    0.986407            0.0981789       0.295922                   96.1232   97.1767
    8        0.20004                     0.971009           1.92156    1.95923            0.968064         0.975212    0.987039                    0.983611            0.0960016       0.391924                   92.1565   95.9229
    9        0.30006                     0.940243           1.87809    1.93218            0.946162         0.958702    0.973413                    0.975308            0.187846        0.57977                    87.8089   93.2183
    10       0.39998                     0.835041           1.74922    1.88648            0.881238         0.899011    0.950386                    0.956248            0.174782        0.754553                   74.9218   88.6476
    11       0.5                         0.507397           1.39125    1.78741            0.700897         0.69485     0.900479                    0.903958            0.139153        0.893705                   39.1251   78.7411
    12       0.60002                     0.139813           0.710468   1.60789            0.357926         0.299518    0.810038                    0.803201            0.071061        0.964766                   -28.9532  60.7891
    13       0.69994                     0.0392392          0.229795   1.41116            0.115768         0.0764227   0.710927                    0.69945             0.0229612       0.987728                   -77.0205  41.116
    14       0.79996                     0.0159387          0.0692657  1.24338            0.0348953        0.0249389   0.626402                    0.615115            0.00692795      0.994656                   -93.0734  24.3381
    15       0.89998                     0.00841838         0.0435384  1.11004            0.0219342        0.0115594   0.559224                    0.548038            0.00435471      0.99901                    -95.6462  11.0036
    16       1                           0.00203276         0.0098951  1                  0.00498504       0.00609343  0.503789                    0.493833            0.000989707     1                          -99.0105  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07080985754123137
RMSE: 0.2661012167225685
LogLoss: 0.24090913156628604
Mean Per-Class Error: 0.09398494663882917
AUC: 0.9646036099211598
pr_auc: 0.9605347043233017
Gini: 0.9292072198423196
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3916856803370763: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2757  371   0.1186   (371.0/3128.0)
1      218   2831  0.0715   (218.0/3049.0)
Total  2975  3202  0.0954   (589.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.391686     0.905775  237
max f2                       0.150188     0.931518  304
max f0point5                 0.733699     0.918345  141
max accuracy                 0.511063     0.905941  204
max precision                0.994755     1         0
max recall                   0.00309066   1         399
max specificity              0.994755     1         0
max absolute_mcc             0.46426      0.811964  216
max min_per_class_accuracy   0.484596     0.905051  210
max mean_per_class_accuracy  0.46426      0.906015  216
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.88 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.9928             2.02591     2.02591            1                0.993876   1                           0.993876            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.991882           2.02591     2.02591            1                0.99233    1                           0.993103            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.990931           2.02591     2.02591            1                0.99143    1                           0.992545            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.989968           2.02591     2.02591            1                0.990461   1                           0.992024            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.989017           2.02591     2.02591            1                0.989527   1                           0.991531            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.984379           2.01935     2.02263            0.996764         0.986731   0.998382                    0.989131            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.979351           1.99968     2.01498            0.987055         0.982012   0.994606                    0.986758            0.100033        0.302394                   99.9685   101.498
    8        0.200097                    0.971318           1.98657     2.00788            0.980583         0.975586   0.9911                      0.983965            0.0993768       0.401771                   98.6572   100.788
    9        0.299984                    0.939887           1.92412     1.97999            0.949757         0.958909   0.977334                    0.975622            0.192194        0.593965                   92.4122   97.9991
    10       0.400032                    0.836427           1.80627     1.93654            0.891586         0.900068   0.955888                    0.956726            0.180715        0.77468                    80.6273   93.6544
    11       0.500081                    0.464772           1.36372     1.82194            0.673139         0.679078   0.89932                     0.901178            0.136438        0.911118                   36.3719   82.1942
    12       0.599968                    0.12591            0.587744    1.61646            0.290113         0.271016   0.797895                    0.796265            0.0587078       0.969826                   -41.2256  61.6464
    13       0.700016                    0.0368883          0.177021    1.41073            0.0873786        0.0692277  0.696346                    0.692354            0.0177107       0.987537                   -82.2979  41.0734
    14       0.799903                    0.0151519          0.0820871   1.24482            0.0405186        0.0236539  0.614451                    0.608851            0.00819941      0.995736                   -91.7913  24.4822
    15       0.899951                    0.00847901         0.0327817   1.11008            0.0161812        0.0113311  0.54794                     0.542424            0.00327976      0.999016                   -96.7218  11.0078
    16       1                           0.0024529          0.00983452  1                  0.00485437       0.0061386  0.493605                    0.48877             0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:08:26  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:08:32  1:01:49.891  2442 obs/sec      0.58908   1             14727      0.321454         0.354166            0.586645       0.935829        0.858121           1.98496          0.133825                         0.312196           0.338785              0.61007          0.939825          0.875775             2.02591            0.123361
    2019-08-03 17:08:39  1:01:56.567  2434 obs/sec      1.18228   2             29557      0.292993         0.284524            0.656601       0.95049         0.927046           1.98496          0.11777                          0.285917           0.271999              0.672952         0.954803          0.920892             2.02591            0.108467
    2019-08-03 17:08:45  1:02:03.184  2440 obs/sec      1.773     3             44325      0.288608         0.276788            0.666802       0.95302         0.934924           1.98496          0.112984                         0.28181            0.265244              0.682281         0.957213          0.949679             2.02591            0.107334
    2019-08-03 17:08:52  1:02:09.754  2452 obs/sec      2.36624   4             59156      0.287808         0.27431             0.668646       0.953997        0.949034           1.98496          0.112585                         0.280283           0.2611                0.685715         0.958683          0.950463             2.02591            0.107496
    2019-08-03 17:08:58  1:02:16.414  2453 obs/sec      2.96264   5             74066      0.286914         0.272618            0.670703       0.954637        0.946108           1.98496          0.11777                          0.280323           0.261512              0.685625         0.958725          0.951018             2.02591            0.108467
    2019-08-03 17:09:05  1:02:23.010  2458 obs/sec      3.55644   6             88911      0.283534         0.268072            0.678416       0.955911        0.948665           1.98496          0.108596                         0.275667           0.254562              0.695982         0.96082           0.950469             2.02591            0.100696
    2019-08-03 17:09:12  1:02:29.584  2463 obs/sec      4.1488    7             103720     0.28175          0.266232            0.682451       0.956854        0.948986           1.98496          0.107998                         0.273245           0.251709              0.701301         0.96145           0.94745              2.02591            0.099401
    2019-08-03 17:09:18  1:02:36.166  2463 obs/sec      4.7392    8             118480     0.280922         0.265585            0.684313       0.956467        0.948886           1.94565          0.105903                         0.273059           0.251961              0.701706         0.961525          0.953825             2.02591            0.0989153
    2019-08-03 17:09:25  1:02:42.659  2468 obs/sec      5.32972   9             133243     0.277362         0.259043            0.692265       0.958889        0.952799           1.98496          0.103111                         0.27046            0.246794              0.707358         0.963088          0.952015             2.02591            0.0995629
    2019-08-03 17:09:31  1:02:49.058  2480 obs/sec      5.92456   10            148114     0.27804          0.259725            0.690757       0.958648        0.955867           1.98496          0.105205                         0.270355           0.247337              0.707586         0.962602          0.955041             2.02591            0.0982678
    2019-08-03 17:09:43  1:03:01.169  2495 obs/sec      7.10792   12            177698     0.280451         0.264222            0.685371       0.957251        0.954503           1.9653           0.103809                         0.270783           0.248704              0.706658         0.961973          0.957828             2.02591            0.0985915
    2019-08-03 17:09:50  1:03:07.899  2490 obs/sec      7.70148   13            192537     0.278293         0.260126            0.690194       0.959329        0.951388           1.98496          0.102912                         0.266101           0.240909              0.716714         0.964604          0.960535             2.02591            0.0953537
    2019-08-03 17:09:56  1:03:14.537  2488 obs/sec      8.29248   14            207312     0.279013         0.265593            0.688588       0.958975        0.941555           1.9653           0.101117                         0.267736           0.24698               0.713222         0.963657          0.959122             2.02591            0.093411
    2019-08-03 17:10:09  1:03:26.971  2489 obs/sec      9.47432   16            236858     0.274279         0.25455             0.699066       0.960368        0.953881           1.98496          0.0997208                        0.264861           0.241127              0.719349         0.963974          0.960031             2.02591            0.0908208
    2019-08-03 17:10:15  1:03:33.448  2490 obs/sec      10.0616   17            251541     0.27331          0.253282            0.70119        0.960561        0.957144           1.98496          0.0997208                        0.265247           0.241652              0.718531         0.963985          0.962138             2.02591            0.0913065
    2019-08-03 17:10:16  1:03:34.052  2490 obs/sec      10.0616   17            251541     0.278293         0.260126            0.690194       0.959329        0.951388           1.98496          0.102912                         0.266101           0.240909              0.716714         0.964604          0.960535             2.02591            0.0953537
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005511811964199689
C438        0.8067828416824341     0.8067828416824341   0.004446835319296264
C374        0.7399280071258545     0.7399280071258545   0.004078344042322718
C322        0.7063685655593872     0.7063685655593872   0.0038933707107848027
C88         0.661186695098877      0.661186695098877    0.0036443367366156415
---         ---                    ---                  ---
C443        0.0984390452504158     0.0984390452504158   0.0005425775073556364
C780        0.09781994670629501    0.09781994670629501  0.0005391651525931328
C943        0.09727069735527039    0.09727069735527039  0.0005361377934488263
C476        0.09695363789796829    0.09695363789796829  0.000534390221338706
C835        0.09204080700874329    0.09204080700874329  0.0005073116212653858

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_7

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 252,303 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight              weight_rms           mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  -----------------------  -------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.05229698263781162    0.07654595375061035    0.0         -2.2694260909258343e-05  0.1298997402191162   -0.02763258226767708     0.14813143014907837
    3        2        Softmax                 0.0   0.0   0.0018199247920165362  0.0004107553977519274  0.0         0.0030779839853494195    0.36044275760650635  -0.00015835257889552923  0.1542167067527771


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07597827084756306
RMSE: 0.27564156226440717
LogLoss: 0.25789231903548393
Mean Per-Class Error: 0.10186075540616657
AUC: 0.959759412448091
pr_auc: 0.9515249835562757
Gini: 0.9195188248961821
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3512180400868101: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4299  675   0.1357   (675.0/4974.0)
1      356   4702  0.0704   (356.0/5058.0)
Total  4655  5377  0.1028   (1031.0/10032.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.351218     0.901198  248
max f2                       0.138287     0.929865  313
max f0point5                 0.781481     0.913534  126
max accuracy                 0.471276     0.898226  218
max precision                0.986695     0.995122  6
max recall                   0.00417994   1         399
max specificity              0.993107     0.999799  0
max absolute_mcc             0.380668     0.796599  240
max min_per_class_accuracy   0.525658     0.896995  203
max mean_per_class_accuracy  0.471276     0.898139  218
Gains/Lift Table: Avg response rate: 50.42 %, avg score: 49.99 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100678                   0.990579           1.96376    1.96376            0.990099         0.992021   0.990099                    0.992021            0.0197707       0.0197707                  96.3755   96.3755
    2        0.0200359                   0.988894           1.98339    1.97353            1                0.989741   0.995025                    0.990887            0.0197707       0.0395413                  98.3393   97.3525
    3        0.030004                    0.987726           1.96356    1.97021            0.99             0.98829    0.993355                    0.990024            0.019573        0.0591143                  96.3559   97.0214
    4        0.0400718                   0.986644           1.98339    1.97353            1                0.987209   0.995025                    0.989317            0.0199684       0.0790826                  98.3393   97.3525
    5        0.0500399                   0.985557           1.96356    1.97154            0.99             0.986108   0.994024                    0.988678            0.019573        0.0986556                  96.3559   97.154
    6        0.10008                     0.98091            1.96364    1.96759            0.99004          0.983196   0.992032                    0.985937            0.0982602       0.196916                   96.3638   96.7589
    7        0.15002                     0.975535           1.9636     1.96626            0.99002          0.97837    0.991362                    0.983418            0.0980625       0.294978                   96.3598   96.626
    8        0.20006                     0.96947            1.93993    1.95967            0.978088         0.972747   0.988042                    0.980749            0.0970739       0.392052                   93.9932   95.9675
    9        0.30004                     0.946145           1.88847    1.93595            0.952144         0.959819   0.97608                     0.973775            0.18881         0.580862                   88.8475   93.5949
    10       0.40002                     0.866417           1.75796    1.89146            0.886341         0.91473    0.953651                    0.959017            0.175761        0.756623                   75.7962   89.1464
    11       0.5                         0.539707           1.37236    1.78766            0.691924         0.730153   0.901316                    0.913253            0.137208        0.893832                   37.2357   78.7663
    12       0.59998                     0.14055            0.703976   1.60708            0.354935         0.308742   0.810267                    0.812518            0.0703836       0.964215                   -29.6024  60.7079
    13       0.69996                     0.0393658          0.215543   1.40832            0.108674         0.0758031  0.710054                    0.707288            0.02155         0.985765                   -78.4457  40.8316
    14       0.79994                     0.0180961          0.0850308  1.24293            0.0428714        0.0264077  0.626667                    0.622189            0.00850138      0.994267                   -91.4969  24.2926
    15       0.89992                     0.0110123          0.0336168  1.10857            0.0169492        0.0141232  0.558928                    0.554633            0.00336101      0.997628                   -96.6383  10.8573
    16       1                           0.00223785         0.0237059  1                  0.0119522        0.0081501  0.504187                    0.499942            0.00237248      1                          -97.6294  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07118359356616603
RMSE: 0.2668025366561683
LogLoss: 0.2411183377723662
Mean Per-Class Error: 0.09486119301200602
AUC: 0.964754596492582
pr_auc: 0.9551181131077023
Gini: 0.929509192985164
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43248880908607557: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2790  338   0.1081   (338.0/3128.0)
1      249   2800  0.0817   (249.0/3049.0)
Total  3039  3138  0.095    (587.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.432489     0.905124  219
max f2                       0.13578      0.933396  307
max f0point5                 0.809345     0.918543  112
max accuracy                 0.471128     0.90497   210
max precision                0.99317      1         0
max recall                   0.00951687   1         392
max specificity              0.99317      1         0
max absolute_mcc             0.432489     0.810315  219
max min_per_class_accuracy   0.511784     0.902263  199
max mean_per_class_accuracy  0.432489     0.905139  219
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 48.92 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.990511           2.02591    2.02591            1                0.992007    1                           0.992007            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.989022           2.02591    2.02591            1                0.989797    1                           0.990902            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.987852           2.02591    2.02591            1                0.988396    1                           0.990067            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.986671           2.02591    2.02591            1                0.987283    1                           0.989371            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.985533           2.02591    2.02591            1                0.98608     1                           0.988721            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.980985           2.00624    2.01608            0.990291         0.983268    0.995146                    0.985995            0.100361        0.201705                   100.624   101.608
    7        0.150073                    0.97565            1.99968    2.01061            0.987055         0.978475    0.992449                    0.983488            0.100033        0.301738                   99.9685   101.061
    8        0.200097                    0.968944           1.98002    2.00296            0.977346         0.972574    0.988673                    0.980759            0.0990489       0.400787                   98.0016   100.296
    9        0.299984                    0.944781           1.94382    1.98327            0.959481         0.958687    0.978953                    0.97341             0.194162        0.594949                   94.3823   98.3271
    10       0.400032                    0.852333           1.82594    1.94392            0.901294         0.90882     0.959531                    0.957256            0.182683        0.777632                   82.5942   94.3923
    11       0.500081                    0.476036           1.32438    1.81997            0.653722         0.696241    0.898349                    0.905036            0.132502        0.910134                   32.4381   81.9974
    12       0.599968                    0.113431           0.617295   1.61974            0.3047           0.256446    0.799514                    0.797054            0.0616596       0.971794                   -38.2705  61.9744
    13       0.700016                    0.0345363          0.177021   1.41355            0.0873786        0.0645883   0.697734                    0.692368            0.0177107       0.989505                   -82.2979  41.3546
    14       0.799903                    0.0172755          0.0656697  1.24523            0.0324149        0.0239817   0.614653                    0.608904            0.00655953      0.996064                   -93.433   24.5232
    15       0.899951                    0.010813           0.0229472  1.10935            0.0113269        0.0136003   0.547581                    0.542724            0.00229583      0.99836                    -97.7053  10.9349
    16       1                           0.00251629         0.0163909  1                  0.00809061       0.00812189  0.493605                    0.489237            0.00163988      1                          -98.3609  0

Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:14:47  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:14:53  8 min 11.528 sec  2438 obs/sec      0.62904   1             15726      0.313473         0.333144            0.60691        0.93724         0.861644           1.98339          0.133573                         0.301702           0.307802              0.635843         0.944955          0.881841             2.02591            0.123847
    2019-08-03 16:15:01  8 min 18.546 sec  2450 obs/sec      1.26024   2             31506      0.3003           0.299843            0.639254       0.946203        0.929408           1.98339          0.121711                         0.291979           0.283252              0.658938         0.951766          0.933226             2.02591            0.114295
    2019-08-03 16:15:08  8 min 25.589 sec  2455 obs/sec      1.89464   3             47366      0.292791         0.284824            0.65707        0.950582        0.93793            1.98339          0.115829                         0.282913           0.266651              0.679788         0.95646           0.942665             2.02591            0.105391
    2019-08-03 16:15:15  8 min 32.525 sec  2460 obs/sec      2.5256    4             63140      0.289638         0.279425            0.664416       0.952113        0.943416           1.98339          0.116726                         0.280284           0.262404              0.685712         0.957952          0.947433             2.02591            0.108305
    2019-08-03 16:15:22  8 min 39.666 sec  2453 obs/sec      3.15836   5             78959      0.285758         0.273213            0.673347       0.954131        0.94383            1.98339          0.110148                         0.276344           0.255737              0.694486         0.959996          0.947305             2.02591            0.10102
    2019-08-03 16:15:29  8 min 46.540 sec  2459 obs/sec      3.78312   6             94578      0.289481         0.279783            0.664779       0.952682        0.944454           1.98339          0.113636                         0.27768            0.259351              0.691524         0.958975          0.955153             2.02591            0.102639
    2019-08-03 16:15:36  8 min 54.486 sec  2404 obs/sec      4.40408   7             110102     0.283177         0.268192            0.679221       0.957024        0.947362           1.98339          0.10945                          0.271253           0.246948              0.70564          0.963225          0.942122             2.02591            0.0969726
    2019-08-03 16:15:43  9 min  1.501 sec  2412 obs/sec      5.0368    8             125920     0.283909         0.26962             0.67756        0.955637        0.945256           1.98339          0.10935                          0.271799           0.249976              0.704454         0.961874          0.952505             2.02591            0.0992391
    2019-08-03 16:15:50  9 min  8.368 sec  2425 obs/sec      5.67028   9             141757     0.282598         0.269019            0.680532       0.955749        0.944621           1.96376          0.106559                         0.271898           0.249273              0.704237         0.962062          0.95567              2.02591            0.0972964
    2019-08-03 16:15:57  9 min 15.235 sec  2434 obs/sec      6.30344   10            157586     0.287252         0.276504            0.669922       0.953689        0.949154           1.98339          0.113238                         0.278221           0.260223              0.690321         0.959034          0.95119              2.02591            0.102477
    2019-08-03 16:16:04  9 min 22.230 sec  2438 obs/sec      6.93252   11            173313     0.283946         0.27288             0.677475       0.95561         0.945427           1.96376          0.109151                         0.273524           0.252795              0.70069          0.96154           0.951999             2.02591            0.100696
    2019-08-03 16:16:11  9 min 29.122 sec  2445 obs/sec      7.56376   12            189094     0.284428         0.273451            0.67638        0.955156        0.947286           1.96376          0.108054                         0.274711           0.254859              0.698086         0.960799          0.953754             2.02591            0.100696
    2019-08-03 16:16:18  9 min 36.234 sec  2443 obs/sec      8.18832   13            204708     0.280335         0.265644            0.685628       0.957024        0.954844           1.96376          0.104266                         0.270853           0.248247              0.706507         0.962553          0.957087             2.02591            0.0969726
    2019-08-03 16:16:25  9 min 43.176 sec  2448 obs/sec      8.82272   14            220568     0.28408          0.274277            0.677172       0.953273        0.946276           1.96376          0.106659                         0.274771           0.257633              0.697954         0.959071          0.953477             2.02591            0.096487
    2019-08-03 16:16:32  9 min 50.212 sec  2449 obs/sec      9.45444   15            236361     0.278759         0.263476            0.689152       0.958031        0.954812           1.96376          0.105163                         0.269513           0.246574              0.709404         0.963041          0.959398             2.02591            0.0938967
    2019-08-03 16:16:39  9 min 57.277 sec  2453 obs/sec      10.0921   16            252303     0.275642         0.257892            0.696066       0.959759        0.951525           1.96376          0.102771                         0.266803           0.241118              0.715219         0.964755          0.955118             2.02591            0.0950299
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005737024257060209
C438        0.8244289755821228     0.8244289755821228   0.004729769031137938
C374        0.7402711510658264     0.7402711510658264   0.004246953550466529
C322        0.6593659520149231     0.6593659520149231   0.0037827984609892116
C88         0.651912271976471      0.651912271976471    0.003740036517804246
---         ---                    ---                  ---
C925        0.09219990670681       0.09219990670681     0.0005289531012756572
C916        0.09059979766607285    0.09059979766607285  0.0005197732368950068
C974        0.09053057432174683    0.09053057432174683  0.0005193761008894536
C758        0.08956940472126007    0.08956940472126007  0.0005138618475763122
C375        0.08869878947734833    0.08869878947734833  0.0005088671068034242

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_16

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 251,846 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  ------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.05256867584891218    0.08757975697517395    0.0         0.00029740027886361614  0.10889822244644165  0.010972341224572753    0.1235840916633606
    3        2        Softmax                 0.0   0.0   0.0017858382757367508  0.0003286543069407344  0.0         -0.04664781234293969    0.33851611614227295  -0.0004524399130527712  0.1459636688232422


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07697448514307026
RMSE: 0.27744276012011965
LogLoss: 0.2586013780627658
Mean Per-Class Error: 0.10244939015294241
AUC: 0.9599453999143738
pr_auc: 0.9534165437962245
Gini: 0.9198907998287476
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4773618158064147: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4394  633   0.1259   (633.0/5027.0)
1      408   4598  0.0815   (408.0/5006.0)
Total  4802  5231  0.1038   (1041.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.477362     0.89831   209
max f2                       0.182654     0.931293  297
max f0point5                 0.779248     0.908517  120
max accuracy                 0.555885     0.897538  188
max precision                0.991518     1         0
max recall                   0.00572703   1         399
max specificity              0.991518     1         0
max absolute_mcc             0.555885     0.795141  188
max min_per_class_accuracy   0.57533      0.89636   181
max mean_per_class_accuracy  0.555885     0.897551  188
Gains/Lift Table: Avg response rate: 49.90 %, avg score: 50.81 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   0.987619           1.96451    1.96451            0.980198         0.989112    0.980198                    0.989112            0.0197763       0.0197763                  96.4508   96.4508
    2        0.0200339                   0.986281           1.98415    1.97428            0.99             0.986926    0.985075                    0.988024            0.0197763       0.0395525                  98.4153   97.4282
    3        0.030001                    0.985183           1.98415    1.97756            0.99             0.985743    0.986711                    0.987267            0.0197763       0.0593288                  98.4153   97.7561
    4        0.0400678                   0.984291           1.96451    1.97428            0.980198         0.984773    0.985075                    0.98664             0.0197763       0.0791051                  96.4508   97.4282
    5        0.0500349                   0.983534           1.96411    1.97226            0.98             0.983889    0.984064                    0.986092            0.0195765       0.0986816                  96.4111   97.2256
    6        0.10007                     0.97964            1.98024    1.97625            0.988048         0.981597    0.986056                    0.983844            0.0990811       0.197763                   98.024    97.6248
    7        0.150005                    0.975315           2.00019    1.98422            0.998004         0.977656    0.990033                    0.981784            0.0998801       0.297643                   100.019   98.422
    8        0.20004                     0.969994           1.95229    1.97623            0.974104         0.972803    0.986049                    0.979538            0.0976828       0.395326                   95.2294   97.6234
    9        0.30001                     0.948771           1.90828    1.95359            0.952144         0.961014    0.974751                    0.973365            0.190771        0.586097                   90.8281   95.3591
    10       0.39998                     0.872371           1.73644    1.89932            0.866401         0.918866    0.94767                     0.959744            0.173592        0.759688                   73.6436   89.9316
    11       0.50005                     0.571932           1.37738    1.79487            0.687251         0.751777    0.895555                    0.918126            0.137835        0.897523                   37.7385   79.4867
    12       0.60002                     0.165816           0.705365   1.61334            0.351944         0.349355    0.804983                    0.823362            0.0705154       0.968038                   -29.4635  61.3344
    13       0.69999                     0.0432595          0.207813   1.41261            0.103689         0.0888438   0.704827                    0.718461            0.0207751       0.988813                   -79.2187  41.2611
    14       0.79996                     0.0182833          0.069937   1.24482            0.0348953        0.0278766   0.621106                    0.632159            0.00699161      0.995805                   -93.0063  24.4818
    15       0.89993                     0.0114968          0.0279748  1.10964            0.0139581        0.0144037   0.55366                     0.563535            0.00279664      0.998602                   -97.2025  10.9643
    16       1                           0.00279956         0.0139735  1                  0.00697211       0.00913941  0.498953                    0.508057            0.00139832      1                          -98.6027  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07207112103626538
RMSE: 0.2684606508154694
LogLoss: 0.24229594515427144
Mean Per-Class Error: 0.09639260576819031
AUC: 0.9650151007541778
pr_auc: 0.9601366828772039
Gini: 0.9300302015083557
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4902373197934382: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2771  357   0.1141   (357.0/3128.0)
1      248   2801  0.0813   (248.0/3049.0)
Total  3019  3158  0.0979   (605.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.490237     0.902529  201
max f2                       0.192857     0.933426  293
max f0point5                 0.833249     0.91836   102
max accuracy                 0.592837     0.903675  174
max precision                0.991529     1         0
max recall                   0.00724281   1         397
max specificity              0.991529     1         0
max absolute_mcc             0.592837     0.807325  174
max min_per_class_accuracy   0.568701     0.902919  180
max mean_per_class_accuracy  0.592837     0.903607  174
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.33 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.987726           1.99323    1.99323            0.983871         0.989148    0.983871                    0.989148            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.986542           2.02591    2.00957            1                0.987043    0.991935                    0.988096            0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.98546            2.02591    2.01502            1                0.986043    0.994624                    0.987411            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.984486           1.99323    2.00957            0.983871         0.984974    0.991935                    0.986802            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.983745           1.9927     2.00624            0.983607         0.984097    0.990291                    0.986268            0.0196786       0.100361                   99.2698   100.624
    6        0.100049                    0.979868           2.01935    2.0128             0.996764         0.981753    0.993528                    0.98401             0.101017        0.201378                   101.935   101.28
    7        0.150073                    0.976002           2.0128     2.0128             0.993528         0.978085    0.993528                    0.982035            0.100689        0.302066                   101.28    101.28
    8        0.200097                    0.970812           1.98657    2.00624            0.980583         0.973572    0.990291                    0.979919            0.0993768       0.401443                   98.6572   100.624
    9        0.299984                    0.94993            1.94054    1.98436            0.957861         0.962053    0.979493                    0.97397             0.193834        0.595277                   94.054    98.4364
    10       0.400032                    0.872281           1.7866     1.9349             0.881877         0.91961     0.955079                    0.960375            0.178747        0.774024                   78.6604   93.4904
    11       0.500081                    0.541345           1.33094    1.81407            0.656958         0.735412    0.895435                    0.915368            0.133158        0.907183                   33.0938   81.4072
    12       0.599968                    0.15418            0.646847   1.61974            0.319287         0.320967    0.799514                    0.816408            0.0646113       0.971794                   -35.3153  61.9744
    13       0.700016                    0.0431863          0.183578   1.41448            0.0906149        0.0835622   0.698196                    0.711667            0.0183667       0.990161                   -81.6422  41.4483
    14       0.799903                    0.0180369          0.0689532  1.24646            0.0340357        0.0278716   0.61526                     0.626279            0.0068875       0.997048                   -93.1047  24.6462
    15       0.899951                    0.0114102          0.0163909  1.10971            0.00809061       0.0142731   0.54776                     0.558242            0.00163988      0.998688                   -98.3609  10.9713
    16       1                           0.00410986         0.0131127  1                  0.00647249       0.00924061  0.493605                    0.503315            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:25:54  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:25:59  19 min 17.577 sec  2567 obs/sec      0.59732   1             14933      0.318457         0.352719            0.59434        0.935654        0.8717             2.00419          0.134755                         0.308184           0.325051              0.620028         0.943185          0.866677             2.02591            0.126275
    2019-08-03 16:26:12  19 min 30.127 sec  2525 obs/sec      1.79132   3             44783      0.289339         0.277388            0.665131       0.953079        0.938712           2.00419          0.11203                          0.280132           0.260716              0.686052         0.959359          0.94447              2.02591            0.106686
    2019-08-03 16:26:19  19 min 36.651 sec  2519 obs/sec      2.38316   4             59579      0.289125         0.276638            0.665625       0.953036        0.943141           2.00419          0.111532                         0.278801           0.259337              0.68903          0.959057          0.947676             2.02591            0.102477
    2019-08-03 16:26:25  19 min 43.272 sec  2513 obs/sec      2.97728   5             74432      0.286038         0.271582            0.672728       0.954915        0.952421           2.00419          0.110037                         0.276107           0.255321              0.69501          0.960561          0.949808             2.02591            0.0992391
    2019-08-03 16:26:38  19 min 55.660 sec  2511 obs/sec      4.15736   7             103934     0.287282         0.274928            0.669875       0.955048        0.947076           2.00419          0.111731                         0.278297           0.261008              0.690153         0.959777          0.954331             2.02591            0.102963
    2019-08-03 16:26:45  20 min  2.512 sec  2491 obs/sec      4.7466    8             118665     0.279672         0.261232            0.687134       0.958584        0.94966            2.00419          0.105651                         0.270163           0.246578              0.708            0.962981          0.951837             2.02591            0.0974583
    2019-08-03 16:26:51  20 min  9.223 sec  2487 obs/sec      5.33812   9             133453     0.281902         0.266121            0.682125       0.956993        0.951944           2.00419          0.107246                         0.271547           0.251116              0.705002         0.961636          0.956946             2.02591            0.097944
    2019-08-03 16:26:58  20 min 16.072 sec  2477 obs/sec      5.93568   10            148392     0.280888         0.264271            0.684406       0.957712        0.952586           1.98435          0.105153                         0.272212           0.250442              0.703554         0.961865          0.956939             2.02591            0.10021
    2019-08-03 16:27:05  20 min 22.641 sec  2482 obs/sec      6.53212   11            163303     0.279873         0.262274            0.686682       0.958273        0.951481           2.00419          0.104854                         0.270735           0.248193              0.706763         0.962642          0.954979             2.02591            0.0950299
    2019-08-03 16:27:17  20 min 35.138 sec  2483 obs/sec      7.71324   13            192831     0.277443         0.258601            0.692101       0.959945        0.953417           1.96451          0.103758                         0.268461           0.242296              0.711668         0.965015          0.960137             1.99323            0.097944
    2019-08-03 16:27:24  20 min 41.615 sec  2484 obs/sec      8.30068   14            207517     0.279864         0.263665            0.686704       0.957691        0.951688           2.00419          0.106449                         0.272269           0.249602              0.70343          0.962325          0.951782             1.99323            0.102639
    2019-08-03 16:27:30  20 min 48.195 sec  2484 obs/sec      8.894     15            222350     0.276961         0.259366            0.69317        0.958996        0.95016            2.00419          0.101764                         0.268044           0.244782              0.712563         0.963502          0.95678              1.99323            0.0963251
    2019-08-03 16:27:37  20 min 54.648 sec  2486 obs/sec      9.48288   16            237072     0.278094         0.262167            0.690653       0.958075        0.947876           1.96451          0.106249                         0.268636           0.246065              0.711291         0.96262           0.953694             2.02591            0.0958394
    2019-08-03 16:27:43  21 min  1.061 sec  2490 obs/sec      10.0738   17            251846     0.279233         0.264979            0.688115       0.957628        0.948889           2.00419          0.104057                         0.268676           0.246747              0.711206         0.962647          0.95563              2.02591            0.0968107
    2019-08-03 16:27:44  21 min  1.703 sec  2489 obs/sec      10.0738   17            251846     0.277443         0.258601            0.692101       0.959945        0.953417           1.96451          0.103758                         0.268461           0.242296              0.711668         0.965015          0.960137             1.99323            0.097944
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.00545051106085014
C438        0.7983458638191223     0.7983458638191223   0.004351392961130086
C374        0.7394508719444275     0.7394508719444275   0.004030385156488383
C322        0.6797791719436646     0.6797791719436646   0.003705143895614493
C79         0.6498398184776306     0.6498398184776306   0.003541959118393173
---         ---                    ---                  ---
C969        0.10023301094770432    0.10023301094770432  0.0005463211348327756
C493        0.09972619265317917    0.09972619265317917  0.000543558716112625
C458        0.09873203188180923    0.09873203188180923  0.0005381400318320099
C961        0.09532304108142853    0.09532304108142853  0.0005195592897681985
C908        0.0937550738453865     0.0937550738453865   0.0005110130670051008

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_171

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 251,357 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  ------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.05836578216002246    0.09353747963905334    0.0         0.002543513735945577    0.11267665028572083  -0.024345592615846897  0.1397419571876526
    3        2        Softmax                 0.0   0.0   0.0017594898704373918  0.0003618464106693864  0.0         -0.0020650915326996255  0.3379448652267456   0.0001582790775091214  0.1453222632408142


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0770172508732127
RMSE: 0.277519820685321
LogLoss: 0.26020392350276705
Mean Per-Class Error: 0.10202628526616253
AUC: 0.9591472788484894
pr_auc: 0.9546491996557565
Gini: 0.9182945576969788
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4416870044909119: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4352  632   0.1268   (632.0/4984.0)
1      402   4627  0.0799   (402.0/5029.0)
Total  4754  5259  0.1033   (1034.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.441687     0.899495  219
max f2                       0.145698     0.926237  313
max f0point5                 0.787948     0.912559  119
max accuracy                 0.593444     0.897933  178
max precision                0.991143     1         0
max recall                   0.00729171   1         397
max specificity              0.991143     1         0
max absolute_mcc             0.593444     0.796025  178
max min_per_class_accuracy   0.556125     0.896669  189
max mean_per_class_accuracy  0.593444     0.897974  178
Gains/Lift Table: Avg response rate: 50.22 %, avg score: 50.53 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   0.98837            1.97134    1.97134            0.990099         0.989437   0.990099                    0.989437            0.0198847       0.0198847                  97.1339   97.1339
    2        0.0200739                   0.987237           1.99105    1.98115            1                0.987764   0.995025                    0.988605            0.0198847       0.0397693                  99.1052   98.1146
    3        0.0300609                   0.986405           1.97114    1.97782            0.99             0.986819   0.993355                    0.988011            0.0196858       0.0594552                  97.1141   97.7822
    4        0.0400479                   0.985631           1.97114    1.97616            0.99             0.986069   0.992519                    0.987527            0.0196858       0.079141                   97.1141   97.6156
    5        0.050035                    0.984932           1.99105    1.97913            1                0.985271   0.994012                    0.987077            0.0198847       0.0990257                  99.1052   97.9129
    6        0.10007                     0.980556           1.97516    1.97714            0.992016         0.982824   0.993014                    0.98495             0.0988268       0.197852                   97.5155   97.7142
    7        0.150005                    0.975146           1.9592     1.97117            0.984            0.978006   0.990013                    0.982639            0.0978326       0.295685                   95.9195   97.1168
    8        0.20004                     0.968227           1.93939    1.96322            0.974052         0.971816   0.986021                    0.979932            0.0970372       0.392722                   93.9388   96.3219
    9        0.30001                     0.945036           1.88364    1.9367             0.946054         0.958745   0.972703                    0.972872            0.188308        0.58103                    88.3643   93.6702
    10       0.39998                     0.867296           1.77623    1.8966             0.892108         0.914215   0.952559                    0.958211            0.17757         0.7586                     77.6233   89.6595
    11       0.50005                     0.563396           1.35916    1.78904            0.682635         0.735475   0.898542                    0.913637            0.136011        0.894611                   35.9161   78.9044
    12       0.60002                     0.16224            0.670314   1.60265            0.336663         0.341612   0.804927                    0.818332            0.0670113       0.961623                   -32.9686  60.2651
    13       0.69999                     0.0455438          0.256589   1.41041            0.128871         0.0894981  0.708375                    0.714242            0.0256512       0.987274                   -74.3411  41.0411
    14       0.79996                     0.0193811          0.0815516  1.24435            0.040959         0.0296901  0.624969                    0.628695            0.00815271      0.995427                   -91.8448  24.4345
    15       0.89993                     0.0110585          0.0338141  1.10987            0.016983         0.014595   0.55743                     0.560476            0.00338039      0.998807                   -96.6186  10.9872
    16       1                           0.00488997         0.0119225  1                  0.00598802       0.0087606  0.502247                    0.505266            0.00119308      1                          -98.8078  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07165826645630338
RMSE: 0.26769061704942776
LogLoss: 0.2432725593569986
Mean Per-Class Error: 0.0952554357262747
AUC: 0.9640060071685069
pr_auc: 0.9595344290016996
Gini: 0.9280120143370139
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5127450024488187: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2806  322   0.1029   (322.0/3128.0)
1      267   2782  0.0876   (267.0/3049.0)
Total  3073  3104  0.0954   (589.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.512745     0.904274  197
max f2                       0.213518     0.931251  282
max f0point5                 0.788909     0.919147  118
max accuracy                 0.51785      0.904646  196
max precision                0.99168      1         0
max recall                   0.00800267   1         396
max specificity              0.99168      1         0
max absolute_mcc             0.512745     0.809433  197
max min_per_class_accuracy   0.558602     0.903575  185
max mean_per_class_accuracy  0.512745     0.904745  197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.02 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.988305           1.99323     1.99323            0.983871         0.989325    0.983871                    0.989325            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.987045           2.02591     2.00957            1                0.987621    0.991935                    0.988473            0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.986295           1.99323     2.00413            0.983871         0.986642    0.989247                    0.987863            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.985447           2.02591     2.00957            1                0.985946    0.991935                    0.987384            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.984654           2.02591     2.0128             1                0.985065    0.993528                    0.986926            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.980416           2.01935     2.01608            0.996764         0.982567    0.995146                    0.984746            0.101017        0.201705                   101.935   101.608
    7        0.150073                    0.97479            1.99313     2.00843            0.983819         0.977745    0.99137                     0.982413            0.0997048       0.30141                    99.3128   100.843
    8        0.200097                    0.968723           1.96035     1.99641            0.967638         0.971963    0.985437                    0.9798              0.0980649       0.399475                   96.0347   99.6407
    9        0.299984                    0.943223           1.93726     1.97671            0.95624          0.958334    0.975715                    0.972652            0.193506        0.592981                   93.7256   97.6711
    10       0.400032                    0.85944            1.81611     1.93654            0.89644          0.911239    0.955888                    0.957293            0.181699        0.77468                    81.6107   93.6544
    11       0.500081                    0.528323           1.34733     1.81866            0.665049         0.722294    0.897702                    0.910278            0.134798        0.909479                   34.7329   81.8663
    12       0.599968                    0.1561             0.594311    1.61482            0.293355         0.310704    0.797086                    0.810457            0.0593637       0.968842                   -40.5689  61.4824
    13       0.700016                    0.0453872          0.193412    1.41167            0.0954693        0.0863019   0.696809                    0.706958            0.0193506       0.988193                   -80.6588  41.1671
    14       0.799903                    0.0194569          0.0722367   1.24441            0.0356564        0.0295021   0.614248                    0.622362            0.00721548      0.995408                   -92.7763  24.4412
    15       0.899951                    0.0111913          0.0393381   1.11044            0.0194175        0.0146917   0.54812                     0.554807            0.00393572      0.999344                   -96.0662  11.0442
    16       1                           0.00494816         0.00655634  1                  0.00323625       0.00879021  0.493605                    0.500178            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:33:41  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:33:47  3:27:05.483  2479 obs/sec      0.6252    1             15630      0.321252         0.35552             0.587179       0.934232        0.843644           1.99105          0.13862                          0.310137           0.331387              0.615196         0.940237          0.875195             2.02591            0.128218
    2019-08-03 19:33:54  3:27:12.423  2491 obs/sec      1.25868   2             31467      0.297449         0.293203            0.646089       0.94757         0.926522           1.97134          0.119345                         0.288827           0.276785              0.666262         0.953191          0.923666             2.02591            0.113
    2019-08-03 19:34:02  3:27:19.743  2447 obs/sec      1.88632   3             47158      0.289368         0.27881             0.665057       0.952251        0.938804           1.99105          0.115849                         0.281029           0.263442              0.684039         0.957565          0.949013             2.02591            0.105553
    2019-08-03 19:34:09  3:27:26.860  2443 obs/sec      2.51092   4             62773      0.288864         0.276517            0.666222       0.953303        0.943796           1.99105          0.117447                         0.279775           0.261273              0.686852         0.958342          0.948732             2.02591            0.10701
    2019-08-03 19:34:16  3:27:34.095  2432 obs/sec      3.14224   5             78556      0.28598          0.272552            0.672854       0.954679        0.945086           1.99105          0.111255                         0.276657           0.256965              0.693793         0.960087          0.950096             2.02591            0.105553
    2019-08-03 19:34:23  3:27:41.130  2437 obs/sec      3.76928   6             94232      0.286319         0.273751            0.672078       0.954377        0.949961           1.99105          0.109258                         0.275305           0.255733              0.696778         0.960496          0.954421             2.02591            0.104582
    2019-08-03 19:34:30  3:27:48.141  2442 obs/sec      4.39664   7             109916     0.283754         0.269754            0.677928       0.955872        0.945166           1.99105          0.10746                          0.273984           0.252071              0.699683         0.961302          0.955612             2.02591            0.100049
    2019-08-03 19:34:37  3:27:55.318  2441 obs/sec      5.03004   8             125751     0.285514         0.273558            0.673921       0.954668        0.949779           1.99105          0.111255                         0.277118           0.259794              0.692773         0.959434          0.956502             2.02591            0.103124
    2019-08-03 19:34:44  3:28:02.189  2452 obs/sec      5.65936   9             141484     0.280761         0.264316            0.684687       0.957913        0.947595           1.99105          0.105763                         0.270816           0.247565              0.706587         0.96268           0.958879             2.02591            0.0974583
    2019-08-03 19:34:51  3:28:09.210  2454 obs/sec      6.28316   10            157079     0.283864         0.271091            0.677678       0.955886        0.953386           1.97134          0.108159                         0.274115           0.255869              0.699394         0.96045           0.956298             1.99323            0.101506
    2019-08-03 19:34:58  3:28:16.475  2448 obs/sec      6.91456   11            172864     0.282821         0.270622            0.680044       0.956791        0.948423           1.95163          0.10796                          0.272473           0.251961              0.702985         0.961631          0.956119             1.99323            0.0997248
    2019-08-03 19:35:05  3:28:23.545  2449 obs/sec      7.54376   12            188594     0.280221         0.265497            0.685898       0.957131        0.950131           1.95163          0.106162                         0.270799           0.248559              0.706624         0.962097          0.952494             1.96056            0.0990772
    2019-08-03 19:35:12  3:28:30.472  2455 obs/sec      8.17236   13            204309     0.27752          0.260204            0.691925       0.959147        0.954649           1.97134          0.103266                         0.267691           0.243273              0.71332          0.964006          0.959534             1.99323            0.0953537
    2019-08-03 19:35:19  3:28:37.498  2457 obs/sec      8.80096   14            220024     0.27759          0.260647            0.691769       0.958865        0.954848           1.97134          0.0998702                        0.266513           0.243986              0.715837         0.963193          0.957115             1.99323            0.091954
    2019-08-03 19:35:32  3:28:50.489  2469 obs/sec      10.0543   16            251357     0.279153         0.266436            0.688287       0.956131        0.948257           1.95163          0.101268                         0.271574           0.253619              0.704943         0.959921          0.948453             1.99323            0.0961632
    2019-08-03 19:35:33  3:28:51.159  2469 obs/sec      10.0543   16            251357     0.27752          0.260204            0.691925       0.959147        0.954649           1.97134          0.103266                         0.267691           0.243273              0.71332          0.964006          0.959534             1.99323            0.0953537
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.005450671752184176
C438        0.8132850527763367     0.8132850527763367   0.004432949863641594
C374        0.7560044527053833     0.7560044527053833   0.00412073211488669
C863        0.7010526657104492     0.7010526657104492   0.0038212079617813612
C88         0.6810455918312073     0.6810455918312073   0.0037121559693439154
---         ---                    ---                  ---
C964        0.09918978810310364    0.09918978810310364  0.000540650976118721
C880        0.09863999485969543    0.09863999485969543  0.0005376542336173342
C913        0.09827207028865814    0.09827207028865814  0.0005356487975510467
C535        0.09341392666101456    0.09341392666101456  0.0005091686513117963
C888        0.08953036367893219    0.08953036367893219  0.00048800062426753176

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_174

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 264,431 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.04916258547428994    0.08959370851516724    0.0         0.0011180807831192674  0.13743972778320312  0.008933730060928537  0.16652625799179077
    3        2        Softmax                 0.0   0.0   0.0017793766101021902  0.0004030258860439062  0.0         -0.028361617776567982  0.37071430683135986  -0.0547569218229714   0.17193514108657837


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07716048653321328
RMSE: 0.2777777646486725
LogLoss: 0.2616305109757376
Mean Per-Class Error: 0.10136472921358441
AUC: 0.9576979059001962
pr_auc: 0.947993449334477
Gini: 0.9153958118003924
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4226091926590063: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4417  620   0.1231   (620.0/5037.0)
1      401   4576  0.0806   (401.0/4977.0)
Total  4818  5196  0.102    (1021.0/10014.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.422609     0.899636  223
max f2                       0.168116     0.926571  299
max f0point5                 0.777588     0.906906  120
max accuracy                 0.508676     0.898642  198
max precision                0.992988     1         0
max recall                   0.008525     1         395
max specificity              0.992988     1         0
max absolute_mcc             0.508676     0.797276  198
max min_per_class_accuracy   0.506375     0.89773   199
max mean_per_class_accuracy  0.508676     0.898635  198
Gains/Lift Table: Avg response rate: 49.70 %, avg score: 49.31 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100859                   0.98902            2.01206    2.01206            1                0.991097    1                           0.991097            0.0202933       0.0202933                  101.206   101.206
    2        0.0200719                   0.986774           1.99193    2.00205            0.99             0.987886    0.995025                    0.989499            0.0198915       0.0401849                  99.1935   100.205
    3        0.0300579                   0.985175           1.99193    1.99869            0.99             0.985934    0.993355                    0.988315            0.0198915       0.0600764                  99.1935   99.8686
    4        0.0400439                   0.98373            1.97181    1.99199            0.98             0.984463    0.990025                    0.987354            0.0196906       0.0797669                  97.1814   99.1985
    5        0.05003                     0.982071           1.97181    1.98796            0.98             0.982888    0.988024                    0.986463            0.0196906       0.0994575                  97.1814   98.7959
    6        0.10006                     0.975732           1.98796    1.98796            0.988024         0.978814    0.988024                    0.982638            0.0994575       0.198915                   98.7959   98.7959
    7        0.14999                     0.968201           1.97584    1.98392            0.982            0.971972    0.986019                    0.979088            0.0986538       0.297569                   97.5838   98.3924
    8        0.20002                     0.959195           1.9478     1.97489            0.968064         0.963922    0.981528                    0.975294            0.0974483       0.395017                   94.7798   97.4888
    9        0.29998                     0.927019           1.90552    1.95177            0.947053         0.945209    0.97004                     0.965269            0.190476        0.585493                   90.5523   95.1774
    10       0.40004                     0.83113            1.7731     1.90708            0.881238         0.888178    0.947828                    0.945987            0.177416        0.762909                   77.3099   90.7083
    11       0.5                         0.496685           1.37286    1.80028            0.682318         0.689853    0.894747                    0.894781            0.137231        0.900141                   37.2861   80.0281
    12       0.59996                     0.15435            0.637184   1.6065             0.316683         0.304461    0.798435                    0.796427            0.063693        0.963834                   -36.2816  60.6496
    13       0.70002                     0.0509974          0.218876   1.40815            0.108782         0.0909024   0.699857                    0.69558             0.0219007       0.985734                   -78.1124  40.8152
    14       0.79998                     0.0233181          0.090452   1.2435             0.044955         0.034342    0.618025                    0.612956            0.00904159      0.994776                   -90.9548  24.3501
    15       0.89994                     0.0133357          0.0321607  1.10895            0.015984         0.0177833   0.551154                    0.546848            0.00321479      0.997991                   -96.7839  10.8952
    16       1                           0.00266931         0.0200804  1                  0.00998004       0.00976037  0.497004                    0.493107            0.00200924      1                          -97.992   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07149388858836994
RMSE: 0.2673834112063984
LogLoss: 0.2436793342589278
Mean Per-Class Error: 0.09158142915500367
AUC: 0.963590112560489
pr_auc: 0.9592830193090092
Gini: 0.927180225120978
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44650066671845334: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2783  345   0.1103   (345.0/3128.0)
1      223   2826  0.0731   (223.0/3049.0)
Total  3006  3171  0.092    (568.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.446501     0.908682  221
max f2                       0.152935     0.93161   304
max f0point5                 0.75146      0.911775  136
max accuracy                 0.491298     0.908208  209
max precision                0.995042     1         0
max recall                   0.0115314    1         391
max specificity              0.995042     1         0
max absolute_mcc             0.455922     0.816977  218
max min_per_class_accuracy   0.528976     0.906199  199
max mean_per_class_accuracy  0.455922     0.908419  218
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.26 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.988636           2.02591     2.02591            1                0.991131   1                           0.991131            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.986625           2.02591     2.02591            1                0.987654   1                           0.989392            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.985136           2.02591     2.02591            1                0.985779   1                           0.988188            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.983413           1.96056     2.00957            0.967742         0.98434    0.991935                    0.987226            0.0196786       0.0806822                  96.0558   100.957
    5        0.0500243                   0.981781           1.9927      2.00624            0.983607         0.982548   0.990291                    0.986303            0.0196786       0.100361                   99.2698   100.624
    6        0.100049                    0.97578            2.0128      2.00952            0.993528         0.978785   0.991909                    0.982544            0.100689        0.20105                    101.28    100.952
    7        0.150073                    0.968515           1.99313     2.00406            0.983819         0.972042   0.989213                    0.979043            0.0997048       0.300754                   99.3128   100.406
    8        0.200097                    0.960105           2.00624     2.0046             0.990291         0.964534   0.989482                    0.975416            0.100361        0.401115                   100.624   100.46
    9        0.299984                    0.927166           1.90114     1.97015            0.938412         0.945704   0.972477                    0.965523            0.189898        0.591013                   90.1138   97.0151
    10       0.400032                    0.83365            1.79644     1.92671            0.886731         0.889738   0.951032                    0.946569            0.179731        0.770745                   79.6438   92.6705
    11       0.500081                    0.49916            1.40961     1.82325            0.695793         0.697613   0.899968                    0.896762            0.14103         0.911774                   40.9614   82.3254
    12       0.599968                    0.14115            0.58446     1.61701            0.288493         0.297284   0.798165                    0.796957            0.0583798       0.970154                   -41.554   61.7011
    13       0.700016                    0.0482497          0.199968    1.41448            0.0987055        0.0842025  0.698196                    0.695087            0.0200066       0.990161                   -80.0032  41.4483
    14       0.799903                    0.0232954          0.0623862   1.24564            0.0307942        0.0328798  0.614855                    0.612395            0.00623155      0.996392                   -93.7614  24.5642
    15       0.899951                    0.0135517          0.0327817   1.11081            0.0161812        0.0178161  0.5483                      0.546295            0.00327976      0.999672                   -96.7218  11.0807
    16       1                           0.00284309         0.00327817  1                  0.00161812       0.0100499  0.493605                    0.492645            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:40:18  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:40:25  3:33:43.274  2380 obs/sec      0.62032   1             15508      0.318949         0.34531             0.593073       0.933834        0.867321           1.99213          0.133014                         0.311212           0.328815              0.612524         0.938661          0.858477             2.02591            0.127894
    2019-08-03 19:40:32  3:33:50.447  2385 obs/sec      1.24488   2             31122      0.300887         0.297783            0.637856       0.945743        0.931241           1.99213          0.124026                         0.291771           0.281368              0.659424         0.951667          0.94201              2.02591            0.117209
    2019-08-03 19:40:40  3:33:57.739  2366 obs/sec      1.87204   3             46801      0.291783         0.280822            0.659438       0.951772        0.939445           2.01206          0.116537                         0.283393           0.267891              0.6787           0.956398          0.943628             2.02591            0.111381
    2019-08-03 19:40:47  3:34:04.915  2370 obs/sec      2.49336   4             62334      0.293078         0.283784            0.65641        0.951141        0.939526           2.01206          0.113741                         0.285388           0.270703              0.674161         0.955274          0.943017             2.02591            0.110895
    2019-08-03 19:40:54  3:34:11.978  2387 obs/sec      3.11596   5             77899      0.288822         0.277088            0.666316       0.953279        0.942977           1.99213          0.11464                          0.279216           0.260352              0.688103         0.958889          0.952715             2.02591            0.103286
    2019-08-03 19:41:08  3:34:25.624  2388 obs/sec      4.35536   7             108884     0.283298         0.267465            0.678957       0.956615        0.947256           2.01206          0.109646                         0.273771           0.250794              0.70015          0.962031          0.955037             2.02591            0.103286
    2019-08-03 19:41:15  3:34:32.961  2381 obs/sec      4.97844   8             124461     0.286815         0.275276            0.670937       0.954149        0.94691            2.01206          0.112742                         0.278279           0.259791              0.690194         0.959031          0.955312             2.02591            0.101829
    2019-08-03 19:41:22  3:34:40.136  2383 obs/sec      5.6004    9             140010     0.284272         0.271517            0.676746       0.954899        0.949294           1.97221          0.107949                         0.27534            0.256355              0.696702         0.960006          0.955473             1.99323            0.100696
    2019-08-03 19:41:29  3:34:47.488  2381 obs/sec      6.22424   10            155606     0.280626         0.264507            0.684985       0.957919        0.946927           2.01206          0.104154                         0.272519           0.250242              0.702885         0.96219           0.955332             1.99323            0.0987534
    2019-08-03 19:41:43  3:35:01.227  2383 obs/sec      7.47064   12            186766     0.278387         0.264003            0.689992       0.959174        0.954825           2.01206          0.102956                         0.269737           0.250397              0.70892          0.964247          0.961136             1.99323            0.0956775
    2019-08-03 19:41:50  3:35:08.435  2384 obs/sec      8.09436   13            202359     0.28047          0.264586            0.685334       0.957894        0.952293           2.01206          0.10705                          0.269938           0.245317              0.708486         0.963965          0.956581             2.02591            0.0995629
    2019-08-03 19:41:58  3:35:15.649  2383 obs/sec      8.71232   14            217808     0.280055         0.265173            0.686266       0.958779        0.951831           2.01206          0.103855                         0.270073           0.245319              0.708194         0.964995          0.957689             2.02591            0.0963251
    2019-08-03 19:42:05  3:35:22.639  2388 obs/sec      9.3358    15            233395     0.281594         0.266242            0.682807       0.957271        0.952914           2.01206          0.107849                         0.270267           0.246539              0.707776         0.963025          0.957733             2.02591            0.096487
    2019-08-03 19:42:12  3:35:29.694  2393 obs/sec      9.96012   16            249003     0.278416         0.262112            0.689926       0.957842        0.948381           2.01206          0.104154                         0.26871            0.244001              0.711132         0.963862          0.957814             2.02591            0.0985915
    2019-08-03 19:42:19  3:35:36.636  2397 obs/sec      10.5772   17            264431     0.277778         0.261631            0.691347       0.957698        0.947993           2.01206          0.101957                         0.267383           0.243679              0.713978         0.96359           0.959283             2.02591            0.091954
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0053493669223052135
C438        0.8543068766593933     0.8543068766593933   0.004570000947499638
C322        0.6854820847511292     0.6854820847511292   0.003666895190000509
C88         0.664272129535675      0.664272129535675    0.0035534353571473843
C374        0.6638479232788086     0.6638479232788086   0.003551166122228668
---         ---                    ---                  ---
C888        0.09659981727600098    0.09659981727600098  0.0005167478672369674
C835        0.09542098641395569    0.09542098641395569  0.0005104418684165498
C953        0.09496872872114182    0.09496872872114182  0.0005080225760742531
C741        0.09464051574468613    0.09464051574468613  0.0005062668444345297
C862        0.09216557443141937    0.09216557443141937  0.0004930274752386939

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_221

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 265,419 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.03695039016949188   0.06596997380256653   0.0         0.0043656636437900695  0.1591782569885254   -0.01566775916938061    0.16645365953445435
    3        2        Softmax                 0.0   0.0   0.001831848891924892  0.000441962038166821  0.0         0.014034723087661405   0.43850505352020264  -0.0014227695198346171  0.12320688366889954


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07742624892632113
RMSE: 0.2782557257745492
LogLoss: 0.26119700248674776
Mean Per-Class Error: 0.1022953661217767
AUC: 0.95891868112359
pr_auc: 0.9499228676187457
Gini: 0.91783736224718
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46680702116355993: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4433  596   0.1185   (596.0/5029.0)
1      440   4542  0.0883   (440.0/4982.0)
Total  4873  5138  0.1035   (1036.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.466807     0.897628  214
max f2                       0.133377     0.926567  317
max f0point5                 0.830336     0.909536  99
max accuracy                 0.545192     0.897713  190
max precision                0.977384     0.992561  7
max recall                   0.012947     1         395
max specificity              0.984969     0.999801  0
max absolute_mcc             0.545192     0.795421  190
max min_per_class_accuracy   0.536239     0.897196  192
max mean_per_class_accuracy  0.545192     0.897705  190
Gains/Lift Table: Avg response rate: 49.77 %, avg score: 49.71 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   0.981731           1.94975    1.94975            0.970297         0.983232   0.970297                    0.983232            0.0196708       0.0196708                  94.9748   94.9748
    2        0.0200779                   0.980453           2.00943    1.97944            1                0.98105    0.985075                    0.982146            0.0200723       0.0397431                  100.943   97.9442
    3        0.0300669                   0.979822           1.98934    1.98273            0.99             0.980084   0.986711                    0.981461            0.0198715       0.0596146                  98.934    98.2731
    4        0.0400559                   0.97964            1.98934    1.98438            0.99             0.979688   0.987531                    0.981019            0.0198715       0.0794862                  98.934    98.4379
    5        0.050045                    0.979621           2.00943    1.98938            1                0.979636   0.99002                     0.980743            0.0200723       0.0995584                  100.943   98.938
    6        0.10009                     0.9763             1.9974     1.99339            0.994012         0.978411   0.992016                    0.979577            0.0999599       0.199518                   99.7401   99.3391
    7        0.150035                    0.97155            1.97326    1.98669            0.982            0.973943   0.988682                    0.977701            0.0985548       0.298073                   97.3264   98.6691
    8        0.20008                     0.963797           1.95328    1.97833            0.972056         0.967851   0.984523                    0.975237            0.0977519       0.395825                   95.3282   97.8334
    9        0.30007                     0.939039           1.88899    1.94856            0.94006          0.953237   0.969707                    0.967906            0.18888         0.584705                   88.8988   94.8562
    10       0.40006                     0.847643           1.80869    1.9136             0.9001           0.9048     0.95231                     0.952134            0.180851        0.765556                   80.8691   91.3603
    11       0.50005                     0.52574            1.32892    1.79669            0.661339         0.716188   0.894127                    0.904954            0.132878        0.898434                   32.8916   79.6689
    12       0.60004                     0.142461           0.648399   1.60534            0.322677         0.305921   0.798901                    0.805132            0.0648334       0.963268                   -35.1601  60.5339
    13       0.70003                     0.0433125          0.256951   1.41274            0.127872         0.0792009  0.703054                    0.701442            0.0256925       0.98896                    -74.3049  41.274
    14       0.80002                     0.0223257          0.0642376  1.2442             0.031968         0.0306818  0.619178                    0.617608            0.00642312      0.995383                   -93.5762  24.4198
    15       0.90001                     0.0137972          0.0361337  1.10998            0.017982         0.0174823  0.552386                    0.550934            0.00361301      0.998996                   -96.3866  10.9984
    16       1                           0.00783967         0.0100371  1                  0.004995         0.0124452  0.497653                    0.497091            0.00100361      1                          -98.9963  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07197966575493625
RMSE: 0.26829026399580036
LogLoss: 0.24511525892713476
Mean Per-Class Error: 0.09408681014864628
AUC: 0.9636113450470952
pr_auc: 0.9566442628791677
Gini: 0.9272226900941904
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4634547365784253: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2801  327   0.1045   (327.0/3128.0)
1      255   2794  0.0836   (255.0/3049.0)
Total  3056  3121  0.0942   (582.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.463455     0.905673  213
max f2                       0.168324     0.930578  301
max f0point5                 0.726735     0.915518  141
max accuracy                 0.557638     0.90578   186
max precision                0.978458     0.993737  7
max recall                   0.0110594    1         398
max specificity              0.985537     0.99968   0
max absolute_mcc             0.463455     0.811805  213
max min_per_class_accuracy   0.523155     0.905051  197
max mean_per_class_accuracy  0.463455     0.905913  213
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.22 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.981647           1.99323     1.99323            0.983871         0.98315    0.983871                    0.98315             0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.980355           1.99323     1.99323            0.983871         0.980967   0.983871                    0.982059            0.0200066       0.0400131                  99.3234   99.3234
    3        0.0301117                   0.979788           2.02591     2.00413            1                0.980019   0.989247                    0.981379            0.0203345       0.0603477                  102.591   100.413
    4        0.0401489                   0.979641           2.02591     2.00957            1                0.979688   0.991935                    0.980956            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.979629           2.02591     2.0128             1                0.979638   0.993528                    0.980696            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.976298           2.00624     2.00952            0.990291         0.978316   0.991909                    0.979506            0.100361        0.20105                    100.624   100.952
    7        0.150073                    0.971539           2.00624     2.00843            0.990291         0.9742     0.99137                     0.977737            0.100361        0.30141                    100.624   100.843
    8        0.200097                    0.963737           1.95379     1.99477            0.964401         0.967684   0.984628                    0.975224            0.097737        0.399147                   95.379    99.4768
    9        0.299984                    0.935717           1.95039     1.97999            0.962723         0.952009   0.977334                    0.967494            0.194818        0.593965                   95.039    97.9991
    10       0.400032                    0.844015           1.78005     1.92998            0.878641         0.901346   0.952651                    0.95095             0.178091        0.772056                   78.0047   92.9985
    11       0.500081                    0.489282           1.38339     1.82063            0.682848         0.701917   0.898673                    0.901128            0.138406        0.910462                   38.3388   82.063
    12       0.599968                    0.132878           0.597594    1.61701            0.294976         0.280976   0.798165                    0.79788             0.0596917       0.970154                   -40.2406  61.7011
    13       0.700016                    0.0423542          0.183578    1.41214            0.0906149        0.0753294  0.69704                     0.694611            0.0183667       0.988521                   -81.6422  41.214
    14       0.800065                    0.0218935          0.0786761   1.24539            0.038835         0.030104   0.614731                    0.611514            0.00787143      0.996392                   -92.1324  24.539
    15       0.899951                    0.0134516          0.0328348   1.11081            0.0162075        0.0169681  0.5483                      0.545525            0.00327976      0.999672                   -96.7165  11.0807
    16       1                           0.00863979         0.00327817  1                  0.00161812       0.0123818  0.493605                    0.492185            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:34:37  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:34:42  4:28:00.211  4864 obs/sec      0.96608   1             24152      0.299922         0.300071            0.640178       0.945737        0.895237           2.00943          0.121067                         0.292004           0.284691              0.658878         0.950777          0.922001             2.02591            0.114457
    2019-08-03 20:34:48  4:28:05.861  4716 obs/sec      1.93032   2             48258      0.288847         0.274988            0.666263       0.953863        0.938111           2.00943          0.114574                         0.280443           0.261677              0.685354         0.958364          0.944906             2.02591            0.106039
    2019-08-03 20:34:54  4:28:11.568  4641 obs/sec      2.89648   3             72412      0.285453         0.269667            0.674059       0.955873        0.942283           2.00943          0.111377                         0.276464           0.255817              0.694221         0.960411          0.94406              2.02591            0.104582
    2019-08-03 20:34:59  4:28:17.090  4665 obs/sec      3.8614    4             96535      0.281181         0.264143            0.683742       0.957913        0.950739           2.00943          0.107981                         0.272758           0.251415              0.702363         0.962177          0.950559             2.02591            0.100049
    2019-08-03 20:35:05  4:28:22.636  4678 obs/sec      4.82724   5             120681     0.2827           0.266588            0.680317       0.956957        0.943702           2.00943          0.108481                         0.27366            0.252459              0.700391         0.961281          0.937434             2.02591            0.100534
    2019-08-03 20:35:10  4:28:28.295  4667 obs/sec      5.7902    6             144755     0.2797           0.264734            0.687064       0.958328        0.933647           1.98954          0.105084                         0.271964           0.25311               0.704095         0.962431          0.939877             2.02591            0.0972964
    2019-08-03 20:35:16  4:28:33.695  4686 obs/sec      6.7542    7             168855     0.278935         0.261408            0.688775       0.95898         0.912073           2.00943          0.104685                         0.269915           0.247665              0.708535         0.963218          0.916271             2.02591            0.0966489
    2019-08-03 20:35:21  4:28:39.127  4705 obs/sec      7.72056   8             193014     0.281058         0.265163            0.684019       0.957578        0.95211            1.96964          0.106383                         0.271472           0.249964              0.705163         0.962108          0.958352             1.96056            0.0985915
    2019-08-03 20:35:27  4:28:44.572  4711 obs/sec      8.68448   9             217112     0.277513         0.261435            0.691938       0.958695        0.9498             1.92985          0.103686                         0.268036           0.247358              0.71258          0.963353          0.956712             1.99323            0.0940586
    2019-08-03 20:35:32  4:28:50.034  4723 obs/sec      9.6516    10            241290     0.278256         0.261197            0.690288       0.958919        0.949923           1.94975          0.103486                         0.26829            0.245115              0.712034         0.963611          0.956644             1.99323            0.0942205
    2019-08-03 20:35:38  4:28:55.340  4743 obs/sec      10.6168   11            265419     0.28072          0.266258            0.684778       0.95717         0.952609           1.96964          0.104485                         0.271015           0.250834              0.706156         0.961804          0.95711              1.99323            0.0971345
    2019-08-03 20:35:38  4:28:55.782  4742 obs/sec      10.6168   11            265419     0.278256         0.261197            0.690288       0.958919        0.949923           1.94975          0.103486                         0.26829            0.245115              0.712034         0.963611          0.956644             1.99323            0.0942205
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007318876400264836
C438        0.8645840883255005     0.8645840883255005    0.006327784080089994
C374        0.7342443466186523     0.7342443466186523    0.005373843620495129
C863        0.6899178624153137     0.6899178624153137    0.0050494235613526015
C322        0.6688494086265564     0.6688494086265564    0.004895226152127996
---         ---                    ---                   ---
C722        0.05147569999098778    0.05147569999098778   0.0003767442858511533
C935        0.05146883800625801    0.05146883800625801   0.0003766940638330556
C925        0.04983159154653549    0.04983159154653549   0.00036471125935757533
C720        0.049691591411828995   0.049691591411828995  0.0003636866156756381
C980        0.04792284965515137    0.04792284965515137   0.0003507414133745272

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_87

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.04917728674270583    0.08777159452438354     0.0         -0.006517205162327456  0.1705661416053772  0.027807058418220554    0.17043596506118774
    3        2        Softmax                 0.0   0.0   0.0017446779775127652  0.00030652224086225033  0.0         -0.14180300854968664   0.4362673759460449  -0.0022824968015583216  0.10447877645492554


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07650008757507089
RMSE: 0.2765864920329098
LogLoss: 0.2580641629758522
Mean Per-Class Error: 0.10096009341871093
AUC: 0.9600636125262859
pr_auc: 0.9546533203118887
Gini: 0.9201272250525718
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4075497189114996: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4391  656   0.13     (656.0/5047.0)
1      366   4613  0.0735   (366.0/4979.0)
Total  4757  5269  0.1019   (1022.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.40755      0.900273  234
max f2                       0.137252     0.928216  321
max f0point5                 0.749537     0.906186  131
max accuracy                 0.510924     0.898963  206
max precision                0.982749     1         0
max recall                   0.0123605    1         399
max specificity              0.982749     1         0
max absolute_mcc             0.496423     0.798182  210
max min_per_class_accuracy   0.552227     0.89757   194
max mean_per_class_accuracy  0.496423     0.89904   210
Gains/Lift Table: Avg response rate: 49.66 %, avg score: 49.72 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.980619           1.97378    1.97378            0.980198         0.98126    0.980198                    0.98126             0.0198835       0.0198835                  97.3783   97.3783
    2        0.0200479                   0.980053           1.99352    1.9836             0.99             0.98032    0.985075                    0.980792            0.0198835       0.039767                   99.3521   98.3603
    3        0.0300219                   0.979813           2.01366    1.99359            1                0.979883   0.990033                    0.98049             0.0200844       0.0598514                  101.366   99.3588
    4        0.0400958                   0.979796           2.01366    1.99863            1                0.979808   0.992537                    0.980319            0.0202852       0.0801366                  101.366   99.863
    5        0.0500698                   0.979623           2.01366    2.00162            1                0.979723   0.994024                    0.9802              0.0200844       0.100221                   101.366   100.162
    6        0.10004                     0.976049           1.99356    1.9976             0.99002          0.978331   0.992024                    0.979267            0.0996184       0.199839                   99.3561   99.7596
    7        0.15001                     0.970456           1.97346    1.98956            0.98004          0.973446   0.988032                    0.977327            0.0986142       0.298454                   97.3465   98.9558
    8        0.20008                     0.961684           1.96953    1.98455            0.978088         0.96626    0.985543                    0.974558            0.0986142       0.397068                   96.9533   98.4547
    9        0.30002                     0.939008           1.92523    1.96479            0.956088         0.952297   0.975731                    0.967142            0.192408        0.589476                   92.5233   96.4789
    10       0.40006                     0.853851           1.73861    1.90823            0.86341          0.905965   0.947644                    0.951844            0.173931        0.763406                   73.8611   90.823
    11       0.5                         0.537184           1.3766     1.80197            0.683633         0.72261    0.894873                    0.906025            0.137578        0.900984                   37.6602   80.1968
    12       0.60004                     0.139931           0.652481   1.61032            0.324028         0.306769   0.799701                    0.806116            0.0652742       0.966258                   -34.7519  61.0323
    13       0.69998                     0.040308           0.237137   1.41427            0.117764         0.0742377  0.702337                    0.701621            0.0236995       0.989958                   -76.2863  41.4266
    14       0.80002                     0.0224884          0.0481832  1.24344            0.0239282        0.0298264  0.617504                    0.617616            0.00482025      0.994778                   -95.1817  24.3442
    15       0.89996                     0.0140079          0.0422024  1.11004            0.0209581        0.0175251  0.551258                    0.550976            0.00421771      0.998996                   -95.7798  11.0045
    16       1                           0.0108809          0.0100382  1                  0.00498504       0.013363   0.496609                    0.497193            0.00100422      1                          -98.9962  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07185121081099968
RMSE: 0.26805076163107555
LogLoss: 0.24542518632388188
Mean Per-Class Error: 0.0948628706405773
AUC: 0.9633116262176439
pr_auc: 0.9567480485002108
Gini: 0.9266232524352878
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4032187700059624: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2740  388   0.124    (388.0/3128.0)
1      213   2836  0.0699   (213.0/3049.0)
Total  2953  3224  0.0973   (601.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.403219     0.904193  225
max f2                       0.166804     0.93281   300
max f0point5                 0.801669     0.916501  111
max accuracy                 0.538471     0.905132  191
max precision                0.982559     1         0
max recall                   0.0134115    1         397
max specificity              0.982559     1         0
max absolute_mcc             0.538471     0.810245  191
max min_per_class_accuracy   0.538471     0.904731  191
max mean_per_class_accuracy  0.538471     0.905137  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.50 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.980757           1.99323     1.99323            0.983871         0.98146    0.983871                    0.98146             0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.980117           2.02591     2.00957            1                0.98044    0.991935                    0.98095             0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.979816           2.02591     2.01502            1                0.979924   0.994624                    0.980608            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.979806           2.02591     2.01774            1                0.979812   0.995968                    0.980409            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.979641           2.02591     2.01935            1                0.979742   0.996764                    0.980277            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.976881           2.00624     2.0128             0.990291         0.978551   0.993528                    0.979414            0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.97146            1.98657     2.00406            0.980583         0.974226   0.989213                    0.977685            0.0993768       0.300754                   98.6572   100.406
    8        0.200097                    0.963037           1.95379     1.99149            0.964401         0.967576   0.98301                     0.975158            0.097737        0.398491                   95.379    99.1489
    9        0.299984                    0.940617           1.96024     1.98108            0.967585         0.95377    0.977874                    0.968036            0.195802        0.594293                   96.024    98.1084
    10       0.400032                    0.858121           1.78988     1.93326            0.883495         0.909243   0.95427                     0.953332            0.179075        0.773368                   78.9882   93.3264
    11       0.500081                    0.51151            1.36372     1.81932            0.673139         0.721565   0.898025                    0.906964            0.136438        0.909806                   36.3719   81.9318
    12       0.599968                    0.124442           0.610728    1.6181             0.301459         0.285698   0.798705                    0.803531            0.0610036       0.97081                    -38.9272  61.8104
    13       0.700016                    0.0388411          0.190134    1.41401            0.0938511        0.0694083  0.697965                    0.698608            0.0190226       0.989833                   -80.9866  41.4014
    14       0.799903                    0.0222941          0.0426853   1.24277            0.0210697        0.0294797  0.613439                    0.615051            0.00426369      0.994096                   -95.7315  24.2771
    15       0.899951                    0.0138497          0.0524507   1.11044            0.02589          0.0171909  0.54812                     0.548587            0.00524762      0.999344                   -94.7549  11.0442
    16       1                           0.0108809          0.00655634  1                  0.00323625       0.0133306  0.493605                    0.495035            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:43:15  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:43:20  1:36:38.072  4869 obs/sec      1         1             25000      0.300683         0.297765            0.638343       0.946308        0.904615           2.01366          0.123978                         0.295124           0.289927              0.65155          0.948949          0.910266             2.02591            0.116885
    2019-08-03 17:43:26  1:36:43.636  4850 obs/sec      2         2             50000      0.288778         0.274853            0.666415       0.954416        0.948157           2.01366          0.114602                         0.281777           0.264822              0.682354         0.957842          0.948948             2.02591            0.107819
    2019-08-03 17:43:31  1:36:49.238  4840 obs/sec      3         3             75000      0.28336          0.266667            0.678813       0.957312        0.950289           2.01366          0.109715                         0.275987           0.256002              0.695275         0.960591          0.952789             2.02591            0.104743
    2019-08-03 17:43:37  1:36:54.768  4854 obs/sec      4         4             100000     0.28102          0.263279            0.684097       0.958644        0.950123           1.99372          0.106224                         0.27308            0.25237               0.70166          0.961671          0.947529             2.02591            0.102477
    2019-08-03 17:43:43  1:37:00.341  4850 obs/sec      5         5             125000     0.279952         0.261352            0.686493       0.959259        0.953088           2.01366          0.104728                         0.271726           0.249665              0.704612         0.962409          0.957072             2.02591            0.10021
    2019-08-03 17:43:48  1:37:05.828  4864 obs/sec      6         6             150000     0.280071         0.263166            0.686226       0.958299        0.950496           2.01366          0.105226                         0.271902           0.252219              0.70423          0.961032          0.952068             1.99323            0.0984297
    2019-08-03 17:43:54  1:37:11.459  4856 obs/sec      7         7             175000     0.283884         0.269116            0.677626       0.95667         0.945015           2.01366          0.110513                         0.274923           0.256639              0.69762          0.959956          0.956681             2.02591            0.100858
    2019-08-03 17:43:59  1:37:16.983  4872 obs/sec      8         8             200000     0.278111         0.260067            0.690602       0.960251        0.957716           1.99372          0.103032                         0.270019           0.248493              0.708311         0.963245          0.959568             1.99323            0.100534
    2019-08-03 17:44:05  1:37:22.559  4870 obs/sec      9         9             225000     0.276738         0.259209            0.693651       0.960733        0.957337           1.99372          0.102533                         0.269348           0.248702              0.709759         0.963498          0.958454             2.02591            0.0974583
    2019-08-03 17:44:10  1:37:27.898  4887 obs/sec      10        10            250000     0.276586         0.258064            0.693986       0.960064        0.954653           1.97378          0.101935                         0.268051           0.245425              0.712548         0.963312          0.956748             1.99323            0.0972964
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.006970694256117811
C438        0.8747705817222595     0.8747705817222595   0.006097758269432191
C374        0.7535901665687561     0.7535901665687561   0.005253046645567693
C322        0.7212096452713013     0.7212096452713013   0.005027331931749424
C88         0.6575767397880554     0.6575767397880554   0.004583766402997275
---         ---                    ---                  ---
C892        0.05656048282980919    0.05656048282980919  0.000394265832785001
C476        0.05603724718093872    0.05603724718093872  0.00039061851705282354
C835        0.05469227582216263    0.05469227582216263  0.0003812431329275601
C885        0.05440869927406311    0.05440869927406311  0.00037926640751255306
C555        0.0542653389275074     0.0542653389275074   0.0003782670863682621

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_108

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 254,503 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.07252393776707136    0.11762779951095581    0.0         0.0003470612437024335  0.1298896074295044  0.005664095894591609    0.16568595170974731
    3        2        Softmax                 0.0   0.0   0.0017945303334272467  0.0003857837291434407  0.0         0.026610762208292726   0.3638104200363159  0.00032557627437054815  0.20225292444229126


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07540254915876916
RMSE: 0.27459524606003133
LogLoss: 0.256737020255473
Mean Per-Class Error: 0.09928918924634389
AUC: 0.9596150474019198
pr_auc: 0.9503551724192467
Gini: 0.9192300948038397
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49743167477877925: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4456  533   0.1068   (533.0/4989.0)
1      463   4570  0.092    (463.0/5033.0)
Total  4919  5103  0.0994   (996.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.497432     0.901736  203
max f2                       0.194233     0.928412  291
max f0point5                 0.748408     0.911532  130
max accuracy                 0.530397     0.900718  195
max precision                0.993204     1         0
max recall                   0.00492547   1         397
max specificity              0.993204     1         0
max absolute_mcc             0.530397     0.801433  195
max min_per_class_accuracy   0.541648     0.90006   192
max mean_per_class_accuracy  0.530397     0.900711  195
Gains/Lift Table: Avg response rate: 50.22 %, avg score: 50.26 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   0.991017           1.99126    1.99126            1                0.992187    1                           0.992187            0.0200676       0.0200676                  99.1258   99.1258
    2        0.0200559                   0.989382           1.95143    1.97144            0.98             0.990087    0.99005                     0.991142            0.0194715       0.039539                   95.1433   97.1444
    3        0.0300339                   0.98818            1.99126    1.97803            1                0.988832    0.993355                    0.990374            0.0198689       0.0594079                  99.1258   97.8027
    4        0.040012                    0.987138           1.99126    1.98133            1                0.987631    0.995012                    0.98969             0.0198689       0.0792768                  99.1258   98.1326
    5        0.0500898                   0.986239           1.99126    1.98332            1                0.986716    0.996016                    0.989092            0.0200676       0.0993443                  99.1258   98.3324
    6        0.10008                     0.981861           1.97536    1.97935            0.992016         0.984075    0.994018                    0.986586            0.0987483       0.198093                   97.5359   97.9346
    7        0.15007                     0.976801           1.93561    1.96478            0.972056         0.979444    0.986702                    0.984207            0.0967614       0.294854                   93.5614   96.4778
    8        0.20006                     0.970337           1.91574    1.95253            0.962076         0.973544    0.980549                    0.981543            0.0957679       0.390622                   91.5741   95.2525
    9        0.30004                     0.947216           1.91574    1.94027            0.962076         0.9607      0.974393                    0.974597            0.191536        0.582158                   91.5741   94.0268
    10       0.40002                     0.863714           1.77862    1.89987            0.893214         0.914643    0.954103                    0.959612            0.177826        0.759984                   77.8618   89.9865
    11       0.5                         0.545689           1.37719    1.79535            0.691617         0.732853    0.901616                    0.91427             0.137691        0.897675                   37.7187   79.5351
    12       0.59998                     0.1559             0.659778   1.60612            0.331337         0.325877    0.806586                    0.816221            0.0659646       0.96364                    -34.0222  60.612
    13       0.69996                     0.0412837          0.234499   1.4102             0.117764         0.0826486   0.708197                    0.711439            0.0234453       0.987085                   -76.5501  41.0202
    14       0.79994                     0.0174209          0.077504   1.24364            0.0389222        0.0262627   0.624548                    0.625803            0.00774886      0.994834                   -92.2496  24.3636
    15       0.89992                     0.00970726         0.0377584  1.10966            0.0189621        0.0131453   0.557268                    0.557738            0.00377508      0.998609                   -96.2242  10.9664
    16       1                           0.00255831         0.0138971  1                  0.00697906       0.00688091  0.502195                    0.502608            0.00139082      1                          -98.6103  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07199042123243247
RMSE: 0.2683103077267671
LogLoss: 0.24581902213076057
Mean Per-Class Error: 0.09406777954953993
AUC: 0.9629511982042663
pr_auc: 0.9534421301043359
Gini: 0.9259023964085327
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48493048495686664: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2797  331   0.1058   (331.0/3128.0)
1      254   2795  0.0833   (254.0/3049.0)
Total  3051  3126  0.0947   (585.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.48493      0.905263  208
max f2                       0.155974     0.930203  305
max f0point5                 0.781528     0.916193  123
max accuracy                 0.5462       0.905941  191
max precision                0.993304     1         0
max recall                   0.00516921   1         397
max specificity              0.993304     1         0
max absolute_mcc             0.5462       0.811855  191
max min_per_class_accuracy   0.541897     0.905691  192
max mean_per_class_accuracy  0.5462       0.905932  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.78 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.990875           2.02591     2.02591            1                0.992223    1                           0.992223            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.989483           2.02591     2.02591            1                0.990098    1                           0.99116             0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.988449           2.02591     2.02591            1                0.988961    1                           0.990427            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.987324           2.02591     2.02591            1                0.987859    1                           0.989785            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.986653           1.95949     2.0128             0.967213         0.986977    0.993528                    0.989231            0.0193506       0.100689                   95.9487   101.28
    6        0.100049                    0.982302           1.99968     2.00624            0.987055         0.984368    0.990291                    0.986799            0.100033        0.200722                   99.9685   100.624
    7        0.150073                    0.977412           2.00624     2.00624            0.990291         0.979908    0.990291                    0.984502            0.100361        0.301082                   100.624   100.624
    8        0.200097                    0.970364           1.97346     1.99805            0.97411          0.974001    0.986246                    0.981877            0.0987209       0.399803                   97.3459   99.8046
    9        0.299984                    0.947234           1.93069     1.97562            0.952998         0.960675    0.975175                    0.974817            0.19285         0.592653                   93.0689   97.5618
    10       0.400032                    0.867469           1.78988     1.92916            0.883495         0.914826    0.952246                    0.959813            0.179075        0.771728                   78.9882   92.9165
    11       0.500081                    0.511872           1.38339     1.81997            0.682848         0.725726    0.898349                    0.912981            0.138406        0.910134                   38.3388   81.9974
    12       0.599968                    0.137978           0.591027    1.61537            0.291734         0.293848    0.797356                    0.809903            0.0590357       0.96917                    -40.8973  61.5371
    13       0.700016                    0.0369851          0.206525    1.41401            0.101942         0.0739227   0.697965                    0.704715            0.0206625       0.989833                   -79.3475  41.4014
    14       0.799903                    0.0170709          0.0558192   1.24441            0.0275527        0.0248547   0.614248                    0.619818            0.0055756       0.995408                   -94.4181  24.4412
    15       0.899951                    0.00975049         0.0360599   1.11008            0.0177994        0.0129963   0.54794                     0.552357            0.00360774      0.999016                   -96.394   11.0078
    16       1                           0.00275034         0.00983452  1                  0.00485437       0.00700243  0.493605                    0.497795            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:08:55  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:09:01  2:02:19.451  2524 obs/sec      0.67692   1             16923      0.305779         0.313856            0.625988       0.942729        0.896634           1.99126          0.129615                         0.303884           0.307103              0.630558         0.944666          0.878327             2.02591            0.126113
    2019-08-03 18:09:09  2:02:26.982  2493 obs/sec      1.35828   2             33957      0.291312         0.281516            0.660543       0.951808        0.936664           1.99126          0.114847                         0.286233           0.272466              0.672228         0.954648          0.942826             2.02591            0.1096
    2019-08-03 18:09:16  2:02:34.466  2481 obs/sec      2.03492   3             50873      0.287463         0.273467            0.669453       0.954433        0.942568           1.99126          0.110457                         0.28104            0.262714              0.684014         0.958267          0.944828             2.02591            0.107172
    2019-08-03 18:09:24  2:02:42.003  2476 obs/sec      2.7166    4             67915      0.285277         0.269776            0.674462       0.955633        0.942985           1.99126          0.10896                          0.279491           0.261148              0.687489         0.958356          0.944692             2.02591            0.103448
    2019-08-03 18:09:31  2:02:49.411  2483 obs/sec      3.3998    5             84995      0.283167         0.269776            0.679259       0.956814        0.953067           1.97154          0.10906                          0.277145           0.260255              0.692713         0.960291          0.955589             2.02591            0.102639
    2019-08-03 18:09:39  2:02:56.996  2477 obs/sec      4.07776   6             101944     0.280026         0.261531            0.686337       0.958739        0.953524           1.97154          0.107464                         0.275262           0.253999              0.696874         0.961293          0.9539               2.02591            0.105067
    2019-08-03 18:09:46  2:03:04.498  2475 obs/sec      4.75388   7             118847     0.277917         0.258872            0.691044       0.959471        0.951005           1.99126          0.104969                         0.272835           0.250567              0.702196         0.961959          0.957016             2.02591            0.0990772
    2019-08-03 18:09:54  2:03:12.123  2468 obs/sec      5.4272    8             135680     0.279911         0.263221            0.686593       0.957993        0.948459           1.99126          0.108461                         0.274047           0.252973              0.699543         0.961143          0.949338             2.02591            0.100049
    2019-08-03 18:10:02  2:03:19.583  2473 obs/sec      6.10844   9             152711     0.281683         0.266282            0.682614       0.956934        0.954058           1.95183          0.107364                         0.272856           0.252693              0.70215          0.961168          0.955048             1.99323            0.099401
    2019-08-03 18:10:09  2:03:26.891  2479 obs/sec      6.78396   10            169599     0.279499         0.263999            0.687515       0.957117        0.953396           1.95183          0.102674                         0.271432           0.250779              0.705251         0.96119           0.955113             1.99323            0.0953537
    2019-08-03 18:10:16  2:03:34.337  2483 obs/sec      7.4678    11            186695     0.279087         0.267238            0.688436       0.959116        0.954519           1.95183          0.103772                         0.272096           0.256731              0.703806         0.963198          0.960672             2.02591            0.0990772
    2019-08-03 18:10:24  2:03:41.768  2485 obs/sec      8.14468   12            203617     0.278795         0.262454            0.689088       0.958266        0.953231           1.97154          0.102973                         0.268774           0.247808              0.710995         0.962839          0.956711             1.99323            0.0953537
    2019-08-03 18:10:31  2:03:49.164  2486 obs/sec      8.81908   13            220477     0.275525         0.256345            0.696338       0.960127        0.95468            1.97154          0.101277                         0.26902            0.246037              0.710466         0.963587          0.960166             2.02591            0.0960013
    2019-08-03 18:10:38  2:03:56.365  2490 obs/sec      9.49708   14            237427     0.27489          0.256449            0.697737       0.959755        0.952095           1.97154          0.102075                         0.269009           0.246112              0.710489         0.963092          0.959043             2.02591            0.0961632
    2019-08-03 18:10:46  2:04:03.717  2492 obs/sec      10.1801   15            254503     0.274595         0.256737            0.698384       0.959615        0.950355           1.99126          0.0993814                        0.26831            0.245819              0.711991         0.962951          0.953442             2.02591            0.0947062
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005505137589933895
C438        0.8967406749725342     0.8967406749725342   0.004936680798213991
C374        0.7235528230667114     0.7235528230667114   0.003983257844567342
C322        0.7177078127861023     0.7177078127861023   0.003951080258758011
C863        0.6907067894935608     0.6907067894935608   0.0038024359104635594
---         ---                    ---                  ---
C743        0.09540422260761261    0.09540422260761261  0.0005252133721155893
C639        0.09520646184682846    0.09520646184682846  0.0005241246719175826
C758        0.09485073387622833    0.09485073387622833  0.0005221663404948409
C764        0.09433234483003616    0.09433234483003616  0.0005193125374704385
C633        0.08801888674497604    0.08801888674497604  0.0004845560820439019

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_175

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.03825354170953409    0.0582454651594162     0.0         -0.008042926084564582  0.1702878475189209  0.006686080892690672   0.1843578815460205
    3        2        Softmax                 0.0   0.0   0.0019818833179670037  0.0005913698114454746  0.0         -0.08339672139118193   0.5118694305419922  -0.001238645932480159  0.15794676542282104


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07929480146824153
RMSE: 0.28159332639152074
LogLoss: 0.2673170743807232
Mean Per-Class Error: 0.10564595426142676
AUC: 0.9572244455336575
pr_auc: 0.9495698035933039
Gini: 0.914448891067315
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4213894152818842: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4448  637   0.1253   (637.0/5085.0)
1      424   4505  0.086    (424.0/4929.0)
Total  4872  5142  0.106    (1061.0/10014.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.421389     0.894648  222
max f2                       0.176836     0.923892  299
max f0point5                 0.747071     0.906392  133
max accuracy                 0.554881     0.894148  187
max precision                0.989251     1         0
max recall                   0.0068677    1         398
max specificity              0.989251     1         0
max absolute_mcc             0.421389     0.788899  222
max min_per_class_accuracy   0.528432     0.893215  194
max mean_per_class_accuracy  0.421389     0.894354  222
Gains/Lift Table: Avg response rate: 49.22 %, avg score: 49.19 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100859                   0.987092           2.01153    2.01153            0.990099         0.988111   0.990099                    0.988111            0.0202881       0.0202881                  101.153   101.153
    2        0.0200719                   0.985321           2.03165    2.02154            1                0.986238   0.995025                    0.987179            0.0202881       0.0405762                  103.165   102.154
    3        0.0300579                   0.983982           2.03165    2.0249             1                0.984599   0.996678                    0.986322            0.0202881       0.0608643                  103.165   102.49
    4        0.0400439                   0.982547           2.03165    2.02658            1                0.983261   0.997506                    0.985559            0.0202881       0.0811524                  103.165   102.658
    5        0.05003                     0.981661           2.01133    2.02354            0.99             0.982011   0.996008                    0.984851            0.0200852       0.101238                   101.133   102.354
    6        0.10006                     0.976485           2.01543    2.01948            0.992016         0.979087   0.994012                    0.981969            0.100832        0.202069                   101.543   101.948
    7        0.14999                     0.970548           1.97476    2.0046             0.972            0.973715   0.986684                    0.979221            0.0986001       0.30067                    97.4763   100.46
    8        0.20002                     0.963345           1.97488    1.99716            0.972056         0.966989   0.983025                    0.976162            0.098803        0.399473                   97.4877   99.7163
    9        0.29998                     0.93791            1.92205    1.97213            0.946054         0.952552   0.970706                    0.968294            0.192128        0.591601                   92.205    97.2134
    10       0.40004                     0.851085           1.76603    1.92058            0.869261         0.90583    0.945332                    0.952671            0.176709        0.76831                    76.6035   92.0583
    11       0.5                         0.497547           1.31316    1.79915            0.646354         0.706336   0.88556                     0.903423            0.131264        0.899574                   31.3164   79.9148
    12       0.59996                     0.128834           0.633241   1.60489            0.311688         0.27595    0.789947                    0.798879            0.0632988       0.962873                   -36.6759  60.4895
    13       0.70002                     0.0389989          0.233173   1.40882            0.11477          0.0713204  0.693438                    0.694883            0.0233313       0.986204                   -76.6827  40.8823
    14       0.79998                     0.020286           0.0893033  1.24394            0.043956         0.028026   0.612283                    0.611557            0.00892676      0.995131                   -91.0697  24.3945
    15       0.89994                     0.013544           0.0284147  1.10893            0.013986         0.0165793  0.545828                    0.54547             0.00284033      0.997971                   -97.1585  10.8931
    16       1                           0.00537252         0.0202759  1                  0.00998004       0.0102886  0.492211                    0.49192             0.00202881      1                          -97.9724  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07278483800229779
RMSE: 0.26978665275046093
LogLoss: 0.24727762942225634
Mean Per-Class Error: 0.09678270683692358
AUC: 0.9630664827426543
pr_auc: 0.9558735814884209
Gini: 0.9261329654853085
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3970267376820163: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2750  378   0.1208   (378.0/3128.0)
1      231   2818  0.0758   (231.0/3049.0)
Total  2981  3196  0.0986   (609.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.397027     0.902482  233
max f2                       0.164635     0.930093  301
max f0point5                 0.768259     0.91636   129
max accuracy                 0.573589     0.903351  187
max precision                0.989382     1         0
max recall                   0.0125145    1         391
max specificity              0.989382     1         0
max absolute_mcc             0.573589     0.806763  187
max min_per_class_accuracy   0.514237     0.902263  203
max mean_per_class_accuracy  0.573589     0.903217  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.23 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.987104           2.02591    2.02591            1                0.98827    1                           0.98827             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.985436           2.02591    2.02591            1                0.98628    1                           0.987275            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.984017           2.02591    2.02591            1                0.984631   1                           0.986394            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.982563           2.02591    2.02591            1                0.983266   1                           0.985612            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.981655           1.9927     2.01935            0.983607         0.982073   0.996764                    0.984913            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.976717           2.0128     2.01608            0.993528         0.979173   0.995146                    0.982043            0.100689        0.201705                   101.28    101.608
    7        0.150073                    0.971601           1.98657    2.00624            0.980583         0.974273   0.990291                    0.979453            0.0993768       0.301082                   98.6572   100.624
    8        0.200097                    0.964905           1.97346    1.99805            0.97411          0.968144   0.986246                    0.976626            0.0987209       0.399803                   97.3459   99.8046
    9        0.299984                    0.939906           1.94054    1.9789             0.957861         0.954363   0.976794                    0.969213            0.193834        0.593637                   94.054    97.8898
    10       0.400032                    0.859107           1.81611    1.93818            0.89644          0.909552   0.956698                    0.954292            0.181699        0.775336                   81.6107   93.8184
    11       0.500081                    0.481823           1.31127    1.81276            0.647249         0.708213   0.894788                    0.90506             0.131191        0.906527                   31.1269   81.276
    12       0.599968                    0.12489            0.620579   1.61428            0.306321         0.27281    0.796816                    0.799799            0.0619875       0.968514                   -37.9421  61.4278
    13       0.700016                    0.0378643          0.199968   1.41214            0.0987055        0.0692568  0.69704                     0.695387            0.0200066       0.988521                   -80.0032  41.214
    14       0.799903                    0.0202555          0.0755202  1.24523            0.0372771        0.0282907  0.614653                    0.612085            0.00754346      0.996064                   -92.448   24.5232
    15       0.899951                    0.0137413          0.0262254  1.10971            0.012945         0.016554   0.54776                     0.545879            0.00262381      0.998688                   -97.3775  10.9713
    16       1                           0.00521047         0.0131127  1                  0.00647249       0.0103448  0.493605                    0.4923              0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:42:19  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:42:25  3:35:43.942  4442 obs/sec      1         1             25000      0.304913         0.302208            0.628021       0.944701        0.931373           2.03165          0.127022                         0.293844           0.285188              0.654566         0.950891          0.938806             2.02591            0.113809
    2019-08-03 19:42:42  3:35:59.627  4782 obs/sec      4         4             100000     0.286426         0.273186            0.67176        0.955363        0.935448           2.01153          0.110246                         0.271705           0.249245              0.704656         0.962273          0.938218             2.02591            0.0966489
    2019-08-03 19:42:47  3:36:04.935  4850 obs/sec      5         5             125000     0.285918         0.272947            0.672924       0.955366        0.950783           2.01153          0.109047                         0.271443           0.250046              0.705226         0.96218           0.957171             1.99323            0.0972964
    2019-08-03 19:42:53  3:36:10.471  4858 obs/sec      6         6             150000     0.284655         0.271687            0.675807       0.955627        0.948693           1.99142          0.109147                         0.270447           0.249322              0.707386         0.961951          0.958237             2.02591            0.0972964
    2019-08-03 19:42:58  3:36:16.080  4856 obs/sec      7         7             175000     0.283245         0.26989             0.679012       0.956381        0.952499           2.01153          0.106651                         0.270822           0.250058              0.706574         0.962274          0.957821             2.02591            0.0961632
    2019-08-03 19:43:04  3:36:21.688  4856 obs/sec      8         8             200000     0.283839         0.271555            0.677664       0.95507         0.95041            2.03165          0.109147                         0.270194           0.250218              0.707934         0.96144           0.955321             2.02591            0.0987534
    2019-08-03 19:43:09  3:36:27.169  4861 obs/sec      9         9             225000     0.281559         0.268003            0.682822       0.95634         0.95254            2.03165          0.104454                         0.268489           0.247869              0.711608         0.962607          0.95488              2.02591            0.0950299
    2019-08-03 19:43:15  3:36:32.686  4868 obs/sec      10        10            250000     0.281593         0.267317            0.682744       0.957224        0.94957            2.01153          0.105952                         0.269787           0.247278              0.708813         0.963066          0.955874             2.02591            0.0985915
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006690573201884643
C438        0.9125779271125793     0.9125779271125793    0.006105669423770861
C374        0.7794411778450012     0.7794411778450012    0.0052149082569351675
C322        0.6960339546203613     0.6960339546203613    0.004656866124384781
C863        0.6779011487960815     0.6779011487960815    0.004535547259661877
---         ---                    ---                   ---
C785        0.06319771707057953    0.06319771707057953   0.00042282895225270706
C639        0.062351107597351074   0.062351107597351074  0.0004171646495986631
C946        0.06224183738231659    0.06224183738231659   0.00041643356922618915
C575        0.06183161586523056    0.06183161586523056   0.00041368895213713693
C973        0.05822647362947464    0.05822647362947464   0.0003895684841056059

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_8

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 272,362 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.03512658409554577    0.06028078496456146    0.0         -0.003384901737946594  0.1818084716796875   -0.027814694903599387  0.16356682777404785
    3        2        Softmax                 0.0   0.0   0.0018512693495722488  0.0004851964768022299  0.0         -0.03917900443320832   0.46430182456970215  -0.0307393464805523    0.10379305481910706


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07885326361958314
RMSE: 0.2808082328201635
LogLoss: 0.2661176818014531
Mean Per-Class Error: 0.10258590631503117
AUC: 0.95752137211349
pr_auc: 0.9524431641383163
Gini: 0.91504274422698
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6057193355899768: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4552  502   0.0993   (502.0/5054.0)
1      527   4452  0.1058   (527.0/4979.0)
Total  5079  4954  0.1026   (1029.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.605719     0.896406  176
max f2                       0.154648     0.925798  310
max f0point5                 0.823892     0.908658  105
max accuracy                 0.605719     0.897438  176
max precision                0.983608     1         0
max recall                   0.0152455    1         396
max specificity              0.983608     1         0
max absolute_mcc             0.605719     0.794868  176
max min_per_class_accuracy   0.59554      0.896164  179
max mean_per_class_accuracy  0.605719     0.897414  176
Gains/Lift Table: Avg response rate: 49.63 %, avg score: 50.69 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   0.979867           1.97516    1.97516            0.980198         0.981089   0.980198                    0.981089            0.0198835       0.0198835                  97.5161   97.5161
    2        0.0200339                   0.978515           1.99491    1.98499            0.99             0.979159   0.985075                    0.980129            0.0198835       0.039767                   99.4913   98.4988
    3        0.030001                    0.977248           1.97476    1.98159            0.98             0.97782    0.983389                    0.979362            0.0196827       0.0594497                  97.4762   98.159
    4        0.0400678                   0.976353           1.99511    1.98499            0.990099         0.976808   0.985075                    0.97872             0.0200844       0.079534                   99.5112   98.4988
    5        0.0500349                   0.975739           1.99491    1.98696            0.99             0.975964   0.986056                    0.978171            0.0198835       0.0994176                  99.4913   98.6965
    6        0.10007                     0.97097            2.00302    1.99499            0.994024         0.973693   0.99004                     0.975932            0.100221        0.199638                   100.302   99.4993
    7        0.150005                    0.965969           1.98289    1.99096            0.984032         0.968516   0.98804                     0.973463            0.0990159       0.298654                   98.2887   99.0963
    8        0.20004                     0.959899           1.96288    1.98394            0.974104         0.963022   0.984554                    0.970852            0.0982125       0.396867                   96.288    98.3939
    9        0.30001                     0.937202           1.90055    1.95615            0.94317          0.950243   0.970764                    0.963984            0.189998        0.586865                   90.0548   95.6151
    10       0.39998                     0.863881           1.78202    1.91263            0.884347         0.908496   0.949165                    0.950116            0.178148        0.765013                   78.2015   91.2628
    11       0.50005                     0.580564           1.3407     1.79817            0.665339         0.747002   0.892366                    0.909469            0.134163        0.899177                   34.0699   79.8174
    12       0.60002                     0.164343           0.648919   1.60669            0.322034         0.35483    0.797342                    0.81706             0.0648725       0.964049                   -35.1081  60.6695
    13       0.69999                     0.0512256          0.223003   1.40908            0.110668         0.0907911  0.699274                    0.713336            0.0222936       0.986343                   -77.6997  40.9081
    14       0.79996                     0.02714            0.0763434  1.24253            0.0378863        0.0372818  0.616621                    0.628851            0.00763205      0.993975                   -92.3657  24.253
    15       0.89993                     0.0186577          0.0401807  1.10897            0.0199402        0.0223717  0.550338                    0.561479            0.00401687      0.997992                   -95.9819  10.8965
    16       1                           0.0109333          0.0200704  1                  0.00996016       0.0159658  0.496262                    0.50689             0.00200844      1                          -97.993   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07247349664559674
RMSE: 0.26920902036446837
LogLoss: 0.2474568653108602
Mean Per-Class Error: 0.09576978616107412
AUC: 0.962970123951587
pr_auc: 0.9575795397261052
Gini: 0.925940247903174
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4920830709230588: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2780  348   0.1113   (348.0/3128.0)
1      249   2800  0.0817   (249.0/3049.0)
Total  3029  3148  0.0966   (597.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.492083     0.903663  202
max f2                       0.20768      0.932015  291
max f0point5                 0.823322     0.91566   106
max accuracy                 0.606698     0.904322  173
max precision                0.98319      1         0
max recall                   0.0161977    1         394
max specificity              0.98319      1         0
max absolute_mcc             0.606698     0.808658  173
max min_per_class_accuracy   0.57776      0.903453  183
max mean_per_class_accuracy  0.603664     0.90423   174
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.18 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.98016            1.99323     1.99323            0.983871         0.981189   0.983871                    0.981189            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.978575           1.99323     1.99323            0.983871         0.979262   0.983871                    0.980226            0.0200066       0.0400131                  99.3234   99.3234
    3        0.0301117                   0.977452           1.99323     1.99323            0.983871         0.977987   0.983871                    0.97948             0.0200066       0.0600197                  99.3234   99.3234
    4        0.0401489                   0.976595           2.02591     2.0014             1                0.976971   0.987903                    0.978853            0.0203345       0.0803542                  102.591   100.14
    5        0.0500243                   0.975864           1.9927      1.99968            0.983607         0.976215   0.987055                    0.978332            0.0196786       0.100033                   99.2698   99.9685
    6        0.100049                    0.971372           2.0128      2.00624            0.993528         0.974061   0.990291                    0.976196            0.100689        0.200722                   101.28    100.624
    7        0.150073                    0.96632            2.0128      2.00843            0.993528         0.968755   0.99137                     0.973716            0.100689        0.30141                    101.28    100.843
    8        0.200097                    0.959583           1.96035     1.99641            0.967638         0.96336    0.985437                    0.971127            0.0980649       0.399475                   96.0347   99.6407
    9        0.299984                    0.936051           1.95367     1.98218            0.964344         0.949422   0.978413                    0.9639              0.195146        0.594621                   95.3673   98.2178
    10       0.400032                    0.863107           1.80299     1.93736            0.889968         0.907812   0.956293                    0.949872            0.180387        0.775008                   80.2994   93.7364
    11       0.500081                    0.540139           1.33749     1.81735            0.660194         0.733254   0.897054                    0.906534            0.133814        0.908823                   33.7494   81.7351
    12       0.599968                    0.150573           0.617295    1.61756            0.3047           0.320892   0.798435                    0.809033            0.0616596       0.970482                   -38.2705  61.7557
    13       0.700016                    0.0520433          0.173743    1.4112             0.0857605        0.0880094  0.696577                    0.705982            0.0173827       0.987865                   -82.6257  41.1203
    14       0.799903                    0.0273676          0.0689532   1.24359            0.0340357        0.0374881  0.613843                    0.622505            0.0068875       0.994752                   -93.1047  24.3591
    15       0.899951                    0.0185777          0.0426162   1.11008            0.0210356        0.0224485  0.54794                     0.555796            0.00426369      0.999016                   -95.7384  11.0078
    16       1                           0.011352           0.00983452  1                  0.00485437       0.0159154  0.493605                    0.501781            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:16:40  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:16:45  10 min  2.651 sec  4961 obs/sec      0.9064    1             22660      0.307828         0.315446            0.620946       0.940596        0.905192           2.01506          0.128077                         0.297619           0.292434              0.645633         0.948012          0.915347             2.02591            0.119637
    2019-08-03 16:16:50  10 min  7.696 sec  4923 obs/sec      1.81716   2             45429      0.292867         0.283835            0.656897       0.950932        0.940166           2.01506          0.115519                         0.282536           0.266352              0.680642         0.957269          0.948293             2.02591            0.107981
    2019-08-03 16:16:55  10 min 12.823 sec  4870 obs/sec      2.72384   3             68096      0.288401         0.277112            0.667282       0.953334        0.948395           2.01506          0.112728                         0.277314           0.259827              0.692338         0.9595            0.952038             2.02591            0.106039
    2019-08-03 16:17:00  10 min 18.053 sec  4825 obs/sec      3.63216   4             90804      0.285843         0.273003            0.673156       0.954628        0.942049           1.99511          0.110137                         0.274271           0.254088              0.699053         0.960779          0.950626             2.02591            0.101344
    2019-08-03 16:17:06  10 min 23.320 sec  4793 obs/sec      4.53788   5             113447     0.285568         0.273265            0.673785       0.954596        0.942884           1.97516          0.110436                         0.275008           0.25535               0.697432         0.96033           0.956654             2.02591            0.103772
    2019-08-03 16:17:11  10 min 28.379 sec  4803 obs/sec      5.44576   6             136144     0.286232         0.276368            0.672267       0.953794        0.945941           1.97516          0.108741                         0.276259           0.26054               0.694673         0.959285          0.954648             2.02591            0.100858
    2019-08-03 16:17:16  10 min 33.520 sec  4797 obs/sec      6.35268   7             158817     0.285429         0.27325             0.674103       0.955385        0.946643           1.97516          0.110336                         0.274336           0.254166              0.69891          0.96102           0.95565              2.02591            0.102153
    2019-08-03 16:17:21  10 min 38.561 sec  4804 obs/sec      7.2582    8             181455     0.281322         0.268273            0.683415       0.956934        0.951891           1.99511          0.105552                         0.27027            0.251731              0.707768         0.962248          0.954571             2.02591            0.0981059
    2019-08-03 16:17:26  10 min 43.629 sec  4808 obs/sec      8.16652   9             204163     0.283127         0.270373            0.679338       0.956111        0.948107           1.99511          0.106648                         0.271194           0.250995              0.705767         0.961424          0.95449              2.02591            0.0961632
    2019-08-03 16:17:35  10 min 53.051 sec  4848 obs/sec      9.98544   11            249636     0.280921         0.266991            0.684317       0.956646        0.952281           1.97516          0.103558                         0.270017           0.250274              0.708316         0.961497          0.956737             1.99323            0.0971345
    2019-08-03 16:17:40  10 min 58.041 sec  4854 obs/sec      10.8945   12            272362     0.280808         0.266118            0.684569       0.957521        0.952443           1.97516          0.102562                         0.269209           0.247457              0.710059         0.96297           0.95758              1.99323            0.0966489
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006987938382030061
C438        0.892825722694397      0.892825722694397     0.006239011136079905
C374        0.7515382766723633     0.7515382766723633    0.005251703169123535
C863        0.6729670166969299     0.6729670166969299    0.004702652045816742
C322        0.6473599672317505     0.6473599672317505    0.0045237115620084725
---         ---                    ---                   ---
C758        0.05869762971997261    0.05869762971997261   0.00041017541965438506
C980        0.05769958719611168    0.05769958719611168   0.0004032011599949991
C690        0.053725212812423706   0.053725212812423706  0.00037542847669466884
C577        0.053711436688899994   0.053711436688899994  0.0003753322099923419
C744        0.05282727628946304    0.05282727628946304   0.00036915375160124543

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_50

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 269,882 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.04406229397206089    0.07488647103309631     0.0         -0.005066792311699895  0.12489786744117737  0.019987131783606827    0.1304357647895813
    3        2        Softmax                 0.0   0.0   0.0018196726859969203  0.00041436043102294207  0.0         -0.021123689542946522  0.4996689558029175   -0.0009292043319885993  0.11953482031822205


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0750197830210089
RMSE: 0.27389739506064836
LogLoss: 0.25556123138522635
Mean Per-Class Error: 0.09884180312283963
AUC: 0.9598562884398292
pr_auc: 0.9490311030337035
Gini: 0.9197125768796584
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46481190180113513: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4422  576   0.1152   (576.0/4998.0)
1      417   4613  0.0829   (417.0/5030.0)
Total  4839  5189  0.099    (993.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.464812     0.902828  214
max f2                       0.197578     0.92864   295
max f0point5                 0.799618     0.912985  115
max accuracy                 0.515392     0.901177  200
max precision                0.982708     1         0
max recall                   0.0110788    1         399
max specificity              0.982708     1         0
max absolute_mcc             0.515392     0.802393  200
max min_per_class_accuracy   0.545408     0.900795  192
max mean_per_class_accuracy  0.515392     0.901158  200
Gains/Lift Table: Avg response rate: 50.16 %, avg score: 50.14 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   0.98131            1.99364    1.99364            1                0.982161   1                           0.982161            0.0200795       0.0200795                  99.3638   99.3638
    2        0.0200439                   0.98052            1.9737     1.98372            0.99             0.98084    0.995025                    0.981504            0.0196819       0.0397614                  97.3702   98.372
    3        0.030016                    0.980138           1.99364    1.98701            1                0.980297   0.996678                    0.981103            0.0198807       0.0596421                  99.3638   98.7015
    4        0.0400878                   0.979823           1.9739     1.98372            0.990099         0.980037   0.995025                    0.980835            0.0198807       0.0795229                  97.3899   98.372
    5        0.0500598                   0.979364           1.99364    1.9857             1                0.979581   0.996016                    0.980585            0.0198807       0.0994036                  99.3638   98.5695
    6        0.10002                     0.97454            1.94987    1.9678             0.978044         0.977005   0.987039                    0.978797            0.0974155       0.196819                   94.9866   96.7798
    7        0.15008                     0.968914           1.96584    1.96714            0.986056         0.971747   0.986711                    0.976446            0.0984095       0.295229                   96.5838   96.7145
    8        0.20004                     0.961556           1.94191    1.96084            0.974052         0.965365   0.983549                    0.973678            0.0970179       0.392247                   94.1907   96.0842
    9        0.30006                     0.935647           1.88233    1.93467            0.944167         0.950252   0.970422                    0.965869            0.18827         0.580517                   88.2328   93.467
    10       0.39998                     0.85688            1.79069    1.8987             0.898204         0.90555    0.952381                    0.950801            0.178926        0.759443                   79.0693   89.8703
    11       0.5                         0.549457           1.39734    1.79841            0.700897         0.730696   0.902074                    0.906771            0.139761        0.899205                   39.7336   79.841
    12       0.60002                     0.155986           0.651957   1.6073             0.327019         0.327711   0.806216                    0.810245            0.0652087       0.964414                   -34.8043  60.7302
    13       0.69994                     0.0483885          0.246718   1.41307            0.123752         0.0866458  0.70879                     0.706947            0.0246521       0.989066                   -75.3282  41.3072
    14       0.79996                     0.0245381          0.0616179  1.2441             0.0309073        0.0341354  0.624034                    0.622825            0.00616302      0.995229                   -93.8382  24.4098
    15       0.89998                     0.0149201          0.0318028  1.10937            0.0159521        0.0190482  0.556454                    0.555724            0.00318091      0.99841                    -96.8197  10.9369
    16       1                           0.0102636          0.0159014  1                  0.00797607       0.0128145  0.501596                    0.501422            0.00159046      1                          -98.4099  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0730591538006662
RMSE: 0.2702945685741136
LogLoss: 0.24777992992266246
Mean Per-Class Error: 0.09568695325036347
AUC: 0.9630307807096201
pr_auc: 0.9473413829410454
Gini: 0.9260615614192402
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5389713816089164: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2831  297   0.0949   (297.0/3128.0)
1      294   2755  0.0964   (294.0/3049.0)
Total  3125  3052  0.0957   (591.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.538971     0.903131  190
max f2                       0.167624     0.931165  302
max f0point5                 0.815416     0.914006  110
max accuracy                 0.538971     0.904322  190
max precision                0.98245      1         0
max recall                   0.0127939    1         396
max specificity              0.98245      1         0
max absolute_mcc             0.538971     0.808616  190
max min_per_class_accuracy   0.535285     0.903903  191
max mean_per_class_accuracy  0.538971     0.904313  190
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.58 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.981266           2.02591     2.02591            1                0.982166   1                           0.982166            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.980404           2.02591     2.02591            1                0.980719   1                           0.981442            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980113           2.02591     2.02591            1                0.98024    1                           0.981042            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.979805           2.02591     2.02591            1                0.979991   1                           0.980779            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.979372           1.9927      2.01935            0.983607         0.97959    0.996764                    0.980544            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.974686           2.00624     2.0128             0.990291         0.977255   0.993528                    0.9789              0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.969211           1.99313     2.00624            0.983819         0.971854   0.990291                    0.976551            0.0997048       0.301082                   99.3128   100.624
    8        0.200097                    0.961606           1.99313     2.00296            0.983819         0.965537   0.988673                    0.973798            0.0997048       0.400787                   99.3128   100.296
    9        0.299984                    0.932689           1.94054     1.98218            0.957861         0.949707   0.978413                    0.965776            0.193834        0.594621                   94.054    98.2178
    10       0.400032                    0.853644           1.77677     1.9308             0.877023         0.901283   0.953055                    0.949646            0.177763        0.772384                   77.6769   93.0805
    11       0.500081                    0.51393            1.35061     1.81473            0.666667         0.717574   0.895759                    0.903217            0.135126        0.907511                   35.0607   81.4728
    12       0.599968                    0.137302           0.627146    1.61701            0.309562         0.296958   0.798165                    0.802283            0.0626435       0.970154                   -37.2854  61.7011
    13       0.700016                    0.0465204          0.186856    1.41261            0.092233         0.0799233  0.697271                    0.699041            0.0186947       0.988849                   -81.3144  41.2608
    14       0.799903                    0.0237441          0.0623862   1.244              0.0307942        0.032976   0.614046                    0.615867            0.00623155      0.99508                    -93.7614  24.4001
    15       0.899951                    0.0148404          0.0426162   1.11044            0.0210356        0.0185778  0.54812                     0.549466            0.00426369      0.999344                   -95.7384  11.0442
    16       1                           0.0102636          0.00655634  1                  0.00323625       0.0127167  0.493605                    0.495765            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:02:34  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:02:39  55 min 56.763 sec  4798 obs/sec      0.98136   1             24534      0.295818         0.289714            0.649963       0.9489          0.934952           1.99364          0.118967                         0.290836           0.280326              0.661602         0.952306          0.930346             2.02591            0.115104
    2019-08-03 17:02:44  56 min  2.214 sec  4825 obs/sec      1.9634    2             49085      0.285746         0.272474            0.673393       0.955096        0.944009           1.99364          0.111189                         0.2817             0.265352              0.682529         0.957833          0.946743             2.02591            0.108629
    2019-08-03 17:02:50  56 min  7.733 sec  4810 obs/sec      2.9454    3             73635      0.280397         0.26422             0.685507       0.957359        0.941284           1.99364          0.105205                         0.275031           0.254681              0.697382         0.96093           0.940249             2.02591            0.10021
    2019-08-03 17:02:56  56 min 13.319 sec  4786 obs/sec      3.92584   4             98146      0.277631         0.26157             0.69168        0.958192        0.927467           1.99364          0.102712                         0.273287           0.253783              0.701207         0.961285          0.942346             2.02591            0.0992391
    2019-08-03 17:03:01  56 min 18.776 sec  4791 obs/sec      4.90592   5             122648     0.276641         0.258982            0.693876       0.959034        0.921219           1.99364          0.10351                          0.272156           0.25109               0.703677         0.962025          0.923077             1.99323            0.10102
    2019-08-03 17:03:07  56 min 24.365 sec  4779 obs/sec      5.88856   6             147214     0.27633          0.259439            0.694564       0.958606        0.948062           1.9739           0.0999202                        0.271637           0.250815              0.704805         0.961954          0.952628             2.02591            0.0976202
    2019-08-03 17:03:12  56 min 29.927 sec  4775 obs/sec      6.87056   7             171764     0.273897         0.255561            0.699918       0.959856        0.949031           1.99364          0.0990227                        0.270295           0.24778               0.707716         0.963031          0.947341             2.02591            0.0956775
    2019-08-03 17:03:17  56 min 35.156 sec  4810 obs/sec      7.85172   8             196293     0.273872         0.25576             0.699973       0.959955        0.946734           1.99364          0.100718                         0.270409           0.249081              0.707469         0.962707          0.951557             2.02591            0.0972964
    2019-08-03 17:03:23  56 min 40.480 sec  4827 obs/sec      8.83236   9             220809     0.274088         0.258896            0.6995         0.958921        0.954963           1.99364          0.0992222                        0.271214           0.253032              0.705724         0.961849          0.95735              2.02591            0.0972964
    2019-08-03 17:03:28  56 min 45.785 sec  4845 obs/sec      9.81376   10            245344     0.276512         0.262171            0.69416        0.956844        0.950711           1.9739           0.101416                         0.271729           0.252654              0.704604         0.960192          0.955717             2.02591            0.0977821
    2019-08-03 17:03:33  56 min 51.148 sec  4855 obs/sec      10.7953   11            269882     0.274756         0.260406            0.698033       0.957826        0.953215           1.95416          0.097128                         0.271305           0.251904              0.705526         0.961102          0.957113             2.02591            0.097944
    2019-08-03 17:03:34  56 min 51.520 sec  4854 obs/sec      10.7953   11            269882     0.273897         0.255561            0.699918       0.959856        0.949031           1.99364          0.0990227                        0.270295           0.24778               0.707716         0.963031          0.947341             2.02591            0.0956775
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006991945750397669
C438        0.8260270357131958     0.8260270357131958    0.005775536222068463
C374        0.7102691531181335     0.7102691531181335    0.004966163386782885
C322        0.6719688773155212     0.6719688773155212    0.004698369936145751
C863        0.6478781700134277     0.6478781700134277    0.004529929017600805
---         ---                    ---                   ---
C925        0.06054997816681862    0.06054997816681862   0.0004233621625301591
C727        0.06012910231947899    0.06012910231947899   0.00042041942143790774
C880        0.05964122340083122    0.05964122340083122   0.0004170081985059599
C969        0.059616632759571075   0.059616632759571075  0.00041683626207630143
C953        0.05562363192439079    0.05562363192439079   0.00038891741685542834

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_162

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  --------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.03113115731038473   0.05504380166530609   0.0         0.004756762510597435  0.13689720630645752  -0.018742384500114832   0.14529794454574585
    3        2        Softmax                 0.0   0.0   0.001956635907845339  0.000581010477617383  0.0         -0.07640754847670905  0.5160543918609619   -0.0005854903000632045  0.11782762408256531


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07678778507032173
RMSE: 0.2771060899192252
LogLoss: 0.25953949026461426
Mean Per-Class Error: 0.10343240852940672
AUC: 0.960212489383547
pr_auc: 0.9551271409373595
Gini: 0.920424978767094
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49048504251887604: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4460  624   0.1227   (624.0/5084.0)
1      423   4509  0.0858   (423.0/4932.0)
Total  4883  5133  0.1045   (1047.0/10016.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.490485     0.895976  206
max f2                       0.174471     0.927322  306
max f0point5                 0.806416     0.913648  106
max accuracy                 0.542654     0.896466  191
max precision                0.978211     1         0
max recall                   0.0152669    1         399
max specificity              0.978211     1         0
max absolute_mcc             0.542654     0.793045  191
max min_per_class_accuracy   0.571221     0.894768  183
max mean_per_class_accuracy  0.542654     0.896568  191
Gains/Lift Table: Avg response rate: 49.24 %, avg score: 49.96 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100839                   0.971315           2.03082    2.03082            1                0.973128   1                           0.973128            0.0204785       0.0204785                  103.082   103.082
    2        0.0200679                   0.969678           1.9902     2.01061            0.98             0.970535   0.99005                     0.971838            0.0198702       0.0403487                  99.0203   101.061
    3        0.0300519                   0.967771           2.01051    2.01058            0.99             0.968714   0.990033                    0.9708              0.020073        0.0604217                  101.051   101.058
    4        0.0400359                   0.966039           2.01051    2.01056            0.99             0.966954   0.990025                    0.969841            0.020073        0.0804947                  101.051   101.056
    5        0.05002                     0.964526           2.01051    2.01055            0.99             0.965199   0.99002                     0.968915            0.020073        0.100568                   101.051   101.055
    6        0.10004                     0.960556           2.00244    2.0065             0.986028         0.962048   0.988024                    0.965481            0.100162        0.20073                    100.244   100.65
    7        0.15006                     0.956571           1.99028    2.00109            0.98004          0.95871    0.985363                    0.963224            0.0995539       0.300284                   99.0284   100.109
    8        0.20008                     0.949767           1.99434    1.9994             0.982036         0.953381   0.984531                    0.960764            0.0997567       0.400041                   99.4337   99.9404
    9        0.30002                     0.923503           1.9517     1.98351            0.961039         0.938889   0.976705                    0.953477            0.195053        0.595093                   95.1696   98.3512
    10       0.40006                     0.839127           1.78153    1.933              0.877246         0.89199    0.951834                    0.938102            0.178224        0.773317                   78.1527   93.3003
    11       0.5                         0.543508           1.29234    1.80495            0.636364         0.715571   0.888778                    0.893622            0.129157        0.902474                   29.2339   80.4947
    12       0.60004                     0.172124           0.650592   1.61249            0.320359         0.338077   0.79401                     0.801               0.0650852       0.967559                   -34.9408  61.2491
    13       0.69998                     0.0570779          0.208965   1.4121             0.102897         0.0985001  0.695336                    0.700701            0.020884        0.988443                   -79.1035  41.2101
    14       0.80002                     0.0318036          0.0871509  1.24642            0.0429142        0.0418196  0.613753                    0.61831             0.00871857      0.997161                   -91.2849  24.6421
    15       0.89996                     0.024846           0.010144   1.10913            0.004995         0.0275633  0.54615                     0.552708            0.00101379      0.998175                   -98.9856  10.9133
    16       1                           0.0134078          0.0182409  1                  0.00898204       0.0223337  0.492412                    0.499649            0.00182482      1                          -98.1759  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07236677979620704
RMSE: 0.2690107429011099
LogLoss: 0.24799363581830716
Mean Per-Class Error: 0.09448105286291508
AUC: 0.96379929187298
pr_auc: 0.9575044291457466
Gini: 0.9275985837459599
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5316267254552632: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2817  311   0.0994   (311.0/3128.0)
1      273   2776  0.0895   (273.0/3049.0)
Total  3090  3087  0.0945   (584.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.531627     0.904824  192
max f2                       0.182571     0.931663  295
max f0point5                 0.780456     0.916867  116
max accuracy                 0.534298     0.905456  191
max precision                0.975888     1         0
max recall                   0.0176417    1         397
max specificity              0.975888     1         0
max absolute_mcc             0.531627     0.810972  192
max min_per_class_accuracy   0.551037     0.904412  186
max mean_per_class_accuracy  0.531627     0.905519  192
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.84 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.971325           2.02591     2.02591            1                0.972833   1                           0.972833            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.969638           1.92788     1.9769             0.951613         0.970467   0.975806                    0.97165             0.0193506       0.0396851                  92.7882   97.6896
    3        0.0301117                   0.967741           1.99323     1.98234            0.983871         0.968535   0.978495                    0.970612            0.0200066       0.0596917                  99.3234   98.2342
    4        0.0401489                   0.965806           2.02591     1.99323            1                0.966712   0.983871                    0.969637            0.0203345       0.0800262                  102.591   99.3234
    5        0.0500243                   0.964446           1.9927      1.99313            0.983607         0.9652     0.983819                    0.968761            0.0196786       0.0997048                  99.2698   99.3128
    6        0.100049                    0.960435           1.99968     1.99641            0.987055         0.961993   0.985437                    0.965377            0.100033        0.199738                   99.9685   99.6407
    7        0.150073                    0.956868           2.01935     2.00406            0.996764         0.958775   0.989213                    0.963176            0.101017        0.300754                   101.935   100.406
    8        0.200097                    0.950615           2.0128      2.00624            0.993528         0.953896   0.990291                    0.960856            0.100689        0.401443                   101.28    100.624
    9        0.299984                    0.92436            1.94711     1.98655            0.961102         0.939178   0.980572                    0.953638            0.19449         0.595933                   94.7106   98.6551
    10       0.400032                    0.845429           1.78988     1.93736            0.883495         0.893324   0.956293                    0.938553            0.179075        0.775008                   78.9882   93.7364
    11       0.500081                    0.530022           1.35388     1.82063            0.668285         0.716556   0.898673                    0.89414             0.135454        0.910462                   35.3885   82.063
    12       0.599968                    0.161323           0.604161    1.6181             0.298217         0.322741   0.798705                    0.799009            0.0603477       0.97081                    -39.5839  61.8104
    13       0.700016                    0.0585134          0.163909    1.41027            0.0809061        0.097874   0.696115                    0.698801            0.0163988       0.987209                   -83.6091  41.0266
    14       0.799903                    0.0316199          0.0952211   1.24605            0.0470016        0.0425052  0.615058                    0.616847            0.00951132      0.99672                    -90.4779  24.6052
    15       0.899951                    0.0248539          0.0229472   1.11008            0.0113269        0.0275407  0.54794                     0.551333            0.00229583      0.999016                   -97.7053  11.0078
    16       1                           0.0134078          0.00983452  1                  0.00485437       0.0224104  0.493605                    0.498415            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:13:24  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:13:29  3:06:47.078  4693 obs/sec      1         1             25000      0.295779         0.287103            0.649979       0.950165        0.941375           2.03082          0.11901                          0.289552           0.2769                0.664584         0.953908          0.948601             2.02591            0.114295
    2019-08-03 19:13:35  3:06:52.675  4742 obs/sec      2         2             50000      0.288464         0.276351            0.667078       0.954327        0.944815           2.03082          0.114417                         0.281815           0.267046              0.682269         0.957556          0.950267             2.02591            0.107172
    2019-08-03 19:13:40  3:06:58.273  4767 obs/sec      3         3             75000      0.284945         0.269361            0.67515        0.956301        0.947235           2.03082          0.11262                          0.278832           0.260244              0.688961         0.959299          0.949497             2.02591            0.107819
    2019-08-03 19:13:46  3:07:04.000  4759 obs/sec      4         4             100000     0.282195         0.26585             0.68139        0.957375        0.953719           2.03082          0.110523                         0.274667           0.254933              0.698184         0.960776          0.957039             2.02591            0.101829
    2019-08-03 19:13:52  3:07:09.592  4778 obs/sec      5         5             125000     0.282998         0.268068            0.679576       0.956329        0.942403           2.03082          0.111621                         0.275502           0.256779              0.696345         0.959813          0.955119             2.02591            0.103124
    2019-08-03 19:13:57  3:07:15.175  4796 obs/sec      6         6             150000     0.28159          0.265751            0.682756       0.95728         0.948124           2.03082          0.108926                         0.274714           0.255657              0.698079         0.960347          0.949902             2.02591            0.102315
    2019-08-03 19:14:03  3:07:20.740  4810 obs/sec      7         7             175000     0.281943         0.266335            0.681958       0.957517        0.950375           2.03082          0.109425                         0.274059           0.255134              0.699518         0.96045           0.951686             2.02591            0.102963
    2019-08-03 19:14:08  3:07:26.316  4818 obs/sec      8         8             200000     0.277106         0.259539            0.692778       0.960212        0.955127           2.03082          0.104533                         0.269011           0.247994              0.710486         0.963799          0.957504             2.02591            0.0945443
    2019-08-03 19:14:14  3:07:31.849  4829 obs/sec      9         9             225000     0.279065         0.263078            0.688419       0.958001        0.952787           2.01071          0.103534                         0.272351           0.253825              0.703251         0.960633          0.956259             1.99323            0.0963251
    2019-08-03 19:14:19  3:07:37.253  4844 obs/sec      10        10            250000     0.27696          0.25922             0.693101       0.959845        0.954794           2.01071          0.104034                         0.269703           0.248755              0.708993         0.962766          0.956392             2.02591            0.0966489
    2019-08-03 19:14:20  3:07:37.705  4843 obs/sec      10        10            250000     0.277106         0.259539            0.692778       0.960212        0.955127           2.03082          0.104533                         0.269011           0.247994              0.710486         0.963799          0.957504             2.02591            0.0945443
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007083357182510634
C438        0.7980117201805115     0.7980117201805115    0.005652602049868293
C374        0.7076818346977234     0.7076818346977234    0.005012763206738422
C322        0.6337188482284546     0.6337188482284546    0.0044888569552913905
C863        0.6323341727256775     0.6323341727256775    0.004479048804123348
---         ---                    ---                   ---
C835        0.05739033222198486    0.05739033222198486   0.000406516221951268
C969        0.05545833334326744    0.05545833334326744   0.00039283118381710244
C696        0.054678112268447876   0.054678112268447876  0.00038730459926283314
C780        0.053722601383924484   0.053722601383924484  0.00038053637437597727
C958        0.05305581912398338    0.05305581912398338   0.0003758133174658528

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_212

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.03177222261007157    0.046976059675216675   0.0         0.0008353630877711637  0.12493470311164856  0.00290461152974217    0.14123088121414185
    3        2        Softmax                 0.0   0.0   0.0021280328155626194  0.0006855588871985674  0.0         -0.05176398918410996   0.47164249420166016  0.0024525123847006294  0.09564575552940369


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07947573049427627
RMSE: 0.2819144027790639
LogLoss: 0.26489662081053583
Mean Per-Class Error: 0.10826956144872613
AUC: 0.9580298240352697
pr_auc: 0.944461871438871
Gini: 0.9160596480705394
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4754232833755542: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4408  634   0.1257   (634.0/5042.0)
1      458   4510  0.0922   (458.0/4968.0)
Total  4866  5144  0.1091   (1092.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.475423     0.892009  210
max f2                       0.11935      0.926145  326
max f0point5                 0.786217     0.907537  116
max accuracy                 0.534834     0.891708  192
max precision                0.975772     0.993827  9
max recall                   0.0139963    1         396
max specificity              0.983001     0.999802  0
max absolute_mcc             0.534834     0.783439  192
max min_per_class_accuracy   0.546149     0.89052   189
max mean_per_class_accuracy  0.534834     0.89173   192
Gains/Lift Table: Avg response rate: 49.63 %, avg score: 50.06 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   0.981661           1.95505    1.95505            0.970297         0.982501   0.970297                    0.982501            0.0197262       0.0197262                  95.5047   95.5047
    2        0.0200799                   0.980651           2.0149     1.98482            1                0.981082   0.985075                    0.981795            0.0201288       0.0398551                  101.49    98.4822
    3        0.0300699                   0.980058           2.0149     1.99481            1                0.980355   0.990033                    0.981316            0.0201288       0.0599839                  101.49    99.4813
    4        0.0400599                   0.979681           1.99475    1.9948             0.99             0.979833   0.990025                    0.980946            0.0199275       0.0799114                  99.4746   99.4797
    5        0.05005                     0.979222           1.99475    1.99479            0.99             0.979469   0.99002                     0.980652            0.0199275       0.099839                   99.4746   99.4787
    6        0.1                         0.974945           2.00684    2.00081            0.996            0.97738    0.993007                    0.979017            0.100242        0.200081                   100.684   100.081
    7        0.15005                     0.968223           1.97066    1.99075            0.978044         0.971725   0.988016                    0.976585            0.0986312       0.298712                   97.0656   99.0749
    8        0.2                         0.960943           1.96654    1.9847             0.976            0.964469   0.985015                    0.973559            0.0982287       0.39694                    96.6538   98.4702
    9        0.3                         0.934874           1.91626    1.96189            0.951049         0.950137   0.973693                    0.965751            0.191626        0.588567                   91.6264   96.1889
    10       0.4                         0.843887           1.75322    1.90972            0.87013          0.898135   0.947802                    0.948847            0.175322        0.763889                   75.3221   90.9722
    11       0.5                         0.53319            1.30837    1.78945            0.649351         0.717576   0.888112                    0.902593            0.130837        0.894726                   30.8374   78.9452
    12       0.6                         0.166443           0.682367   1.60494            0.338661         0.328126   0.796537                    0.806849            0.0682367       0.962963                   -31.7633  60.4938
    13       0.7                         0.0511763          0.263688   1.41333            0.130869         0.0940986  0.701441                    0.705027            0.0263688       0.989332                   -73.6312  41.3331
    14       0.8                         0.0264937          0.0644122  1.24472            0.031968         0.0360025  0.617757                    0.621399            0.00644122      0.995773                   -93.5588  24.4716
    15       0.9                         0.0156818          0.0281804  1.10955            0.013986         0.0205734  0.550672                    0.554641            0.00281804      0.998591                   -97.182   10.9546
    16       1                           0.0111051          0.0140902  1                  0.00699301       0.0140152  0.496304                    0.500578            0.00140902      1                          -98.591   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07338884884518102
RMSE: 0.2709037630694358
LogLoss: 0.24876817600941487
Mean Per-Class Error: 0.09789167174848323
AUC: 0.9625420665364267
pr_auc: 0.9558305103924805
Gini: 0.9250841330728534
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48517547011004925: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2782  346   0.1106   (346.0/3128.0)
1      263   2786  0.0863   (263.0/3049.0)
Total  3045  3132  0.0986   (609.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.485175     0.901472  209
max f2                       0.187544     0.931211  295
max f0point5                 0.775759     0.914807  121
max accuracy                 0.544674     0.902056  193
max precision                0.983488     1         0
max recall                   0.0132572    1         397
max specificity              0.983488     1         0
max absolute_mcc             0.525298     0.804153  198
max min_per_class_accuracy   0.544674     0.901535  193
max mean_per_class_accuracy  0.525298     0.902108  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.65 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.981536           2.02591     2.02591            1                0.982506   1                           0.982506            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.980633           2.02591     2.02591            1                0.981053   1                           0.98178             0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980062           2.02591     2.02591            1                0.980349   1                           0.981303            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.979672           2.02591     2.02591            1                0.979806   1                           0.980929            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.979216           2.02591     2.02591            1                0.979465   1                           0.98064             0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.97509            2.0128      2.01935            0.993528         0.977404   0.996764                    0.979022            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.968633           1.97346     2.00406            0.97411          0.971848   0.989213                    0.976631            0.0987209       0.300754                   97.3459   100.406
    8        0.200097                    0.96158            1.98002     1.99805            0.977346         0.965036   0.986246                    0.973732            0.0990489       0.399803                   98.0016   99.8046
    9        0.299984                    0.933693           1.94382     1.97999            0.959481         0.949601   0.977334                    0.965697            0.194162        0.593965                   94.3823   97.9991
    10       0.400032                    0.839327           1.78333     1.9308             0.880259         0.895577   0.953055                    0.94816             0.178419        0.772384                   78.3325   93.0805
    11       0.500081                    0.516076           1.34405     1.81342            0.66343          0.708013   0.895112                    0.900115            0.13447         0.906855                   34.405    81.3416
    12       0.599968                    0.152218           0.627146    1.61592            0.309562         0.304291   0.797625                    0.800918            0.0626435       0.969498                   -37.2854  61.5918
    13       0.700016                    0.0499393          0.186856    1.41167            0.092233         0.0894417  0.696809                    0.699232            0.0186947       0.988193                   -81.3144  41.1671
    14       0.799903                    0.0265832          0.0689532   1.244              0.0340357        0.0358415  0.614046                    0.616392            0.0068875       0.99508                    -93.1047  24.4001
    15       0.899951                    0.0155535          0.0393381   1.11008            0.0194175        0.020616   0.54794                     0.550159            0.00393572      0.999016                   -96.0662  11.0078
    16       1                           0.0111051          0.00983452  1                  0.00485437       0.0139075  0.493605                    0.496508            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:27:05  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:27:10  4:20:28.020  4927 obs/sec      1         1             25000      0.302635         0.299252            0.633629       0.945471        0.924827           2.0149           0.125774                         0.29418            0.285103              0.653775         0.950641          0.931991             2.02591            0.123523
    2019-08-03 20:27:16  4:20:33.698  4825 obs/sec      2         2             50000      0.290985         0.279111            0.661293       0.953116        0.943699           2.0149           0.117982                         0.282389           0.266259              0.680973         0.957606          0.950878             2.02591            0.108305
    2019-08-03 20:27:22  4:20:39.379  4796 obs/sec      3         3             75000      0.288356         0.275872            0.667385       0.954523        0.94537            1.99495          0.113487                         0.279471           0.262727              0.687532         0.95913           0.954756             2.02591            0.103934
    2019-08-03 20:27:27  4:20:45.063  4795 obs/sec      4         4             100000     0.287944         0.275477            0.668334       0.954466        0.947355           1.975            0.113387                         0.278241           0.260237              0.690276         0.95944           0.955941             2.02591            0.107496
    2019-08-03 20:27:33  4:20:50.770  4784 obs/sec      5         5             125000     0.285411         0.270319            0.674144       0.956319        0.942873           1.95505          0.112488                         0.275602           0.255794              0.696124         0.960579          0.951102             2.02591            0.102153
    2019-08-03 20:27:38  4:20:56.236  4814 obs/sec      6         6             150000     0.284649         0.269455            0.675881       0.956699        0.950536           1.99495          0.10989                          0.274857           0.255052              0.697764         0.960574          0.956393             2.02591            0.105553
    2019-08-03 20:27:44  4:21:01.730  4835 obs/sec      7         7             175000     0.281914         0.264897            0.68208        0.95803         0.944462           1.95505          0.109091                         0.270904           0.248768              0.706397         0.962542          0.955831             2.02591            0.0985915
    2019-08-03 20:27:50  4:21:08.326  4810 obs/sec      8         8             200000     0.282621         0.267712            0.680483       0.957006        0.948147           1.99495          0.108492                         0.272491           0.252718              0.702947         0.960916          0.954808             2.02591            0.0989153
    2019-08-03 20:28:01  4:21:19.116  4815 obs/sec      10        10            250000     0.280901         0.264375            0.684362       0.958735        0.954431           1.99495          0.105794                         0.271406           0.249781              0.705306         0.962729          0.959147             2.02591            0.0997248
    2019-08-03 20:28:02  4:21:19.582  4814 obs/sec      10        10            250000     0.281914         0.264897            0.68208        0.95803         0.944462           1.95505          0.109091                         0.270904           0.248768              0.706397         0.962542          0.955831             2.02591            0.0985915
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.006857244139435093
C438        0.8594749569892883     0.8594749569892883   0.005893629611806026
C374        0.7400178909301758     0.7400178909301758   0.005074483345658066
C863        0.6381207704544067     0.6381207704544067   0.004375749913450287
C322        0.6223477721214294     0.6223477721214294   0.004267590613070159
---         ---                    ---                  ---
C880        0.06407676637172699    0.06407676637172699  0.00043939003067647656
C963        0.06392782926559448    0.06392782926559448  0.000438368732578305
C827        0.06279721856117249    0.06279721856117249  0.00043061585895142466
C476        0.0600648932158947     0.0600648932158947   0.0004118796369904886
C762        0.05974709615111351    0.05974709615111351  0.00040970042493048813

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_57

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 271,882 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.032150300276355535   0.0584774911403656      0.0         -0.000256894275076654  0.18595105409622192  -0.031183504845538154   0.1572299599647522
    3        2        Softmax                 0.0   0.0   0.0017871419804578181  0.00044526648707687855  0.0         0.0026093406031577615  0.49287354946136475  -0.0003314378499909912  0.10973697900772095


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07519447473296276
RMSE: 0.27421610954311704
LogLoss: 0.25793246300063255
Mean Per-Class Error: 0.09870791140768487
AUC: 0.9587322372023102
pr_auc: 0.9504607192530896
Gini: 0.9174644744046203
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38458425775091226: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4398  665   0.1313   (665.0/5063.0)
1      344   4622  0.0693   (344.0/4966.0)
Total  4742  5287  0.1006   (1009.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.384584     0.90159   237
max f2                       0.198012     0.929802  290
max f0point5                 0.692255     0.911131  147
max accuracy                 0.477204     0.901187  209
max precision                0.968979     0.987654  9
max recall                   0.0168423    1         398
max specificity              0.978699     0.999802  0
max absolute_mcc             0.477204     0.802626  209
max min_per_class_accuracy   0.531874     0.898874  194
max mean_per_class_accuracy  0.477204     0.901292  209
Gains/Lift Table: Avg response rate: 49.52 %, avg score: 49.29 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   0.973032           1.97954    1.97954            0.980198         0.975477   0.980198                    0.975477            0.0199356       0.0199356                  97.9542   97.9542
    2        0.0200419                   0.971146           1.95895    1.9693             0.97             0.97205    0.975124                    0.973772            0.0195328       0.0394684                  95.8947   96.9296
    3        0.030013                    0.970815           2.01953    1.98599            1                0.970919   0.983389                    0.972824            0.0201369       0.0596053                  101.953   98.5986
    4        0.0400838                   0.970143           1.99954    1.98939            0.990099         0.97053    0.985075                    0.972248            0.0201369       0.0797422                  99.9537   98.9391
    5        0.0500548                   0.969498           1.97914    1.98735            0.98             0.96975    0.984064                    0.97175             0.0197342       0.0994764                  97.9142   98.7349
    6        0.10001                     0.965067           1.99132    1.98933            0.986028         0.967664   0.985045                    0.969709            0.0994764       0.198953                   99.1316   98.933
    7        0.150065                    0.95853            1.96723    1.98196            0.974104         0.96125    0.981395                    0.966888            0.0984696       0.297422                   96.7234   98.196
    8        0.20002                     0.951264           1.9631     1.97725            0.972056         0.955152   0.979063                    0.963957            0.0980669       0.395489                   96.3099   97.7249
    9        0.30003                     0.920422           1.9108     1.9551             0.946162         0.937806   0.968096                    0.95524             0.191099        0.586589                   91.0804   95.5101
    10       0.40004                     0.836686           1.79604    1.91533            0.889332         0.885526   0.948405                    0.937811            0.179621        0.76621                    79.6035   91.5335
    11       0.50005                     0.506684           1.38126    1.80852            0.683948         0.705164   0.895513                    0.891282            0.138139        0.90435                    38.1256   80.8519
    12       0.59996                     0.143731           0.632868   1.61274            0.313373         0.299497   0.798571                    0.792733            0.06323         0.96758                    -36.7132  61.274
    13       0.69997                     0.0538252          0.211417   1.41252            0.104686         0.0876014  0.69943                     0.691986            0.0211438       0.988723                   -78.8583  41.2522
    14       0.79998                     0.0305147          0.0543643  1.24273            0.0269192        0.0399539  0.615356                    0.610471            0.00543697      0.99416                    -94.5636  24.2731
    15       0.89999                     0.0211277          0.0442968  1.10956            0.0219342        0.0256779  0.549413                    0.545487            0.00443012      0.99859                    -95.5703  10.9557
    16       1                           0.0136292          0.0140944  1                  0.00697906       0.0193329  0.495164                    0.492867            0.00140959      1                          -98.5906  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07264784448128911
RMSE: 0.26953264084575934
LogLoss: 0.24921113083741112
Mean Per-Class Error: 0.09636193662087023
AUC: 0.9622949308775088
pr_auc: 0.9550819795237055
Gini: 0.9245898617550177
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4600308665923136: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2785  343   0.1097   (343.0/3128.0)
1      254   2795  0.0833   (254.0/3049.0)
Total  3039  3138  0.0966   (597.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.460031     0.903507  216
max f2                       0.197571     0.93194   291
max f0point5                 0.801035     0.915781  114
max accuracy                 0.488436     0.903513  208
max precision                0.9653       0.988691  15
max recall                   0.0173414    1         396
max specificity              0.979561     0.99968   0
max absolute_mcc             0.476735     0.807244  211
max min_per_class_accuracy   0.53879      0.901935  196
max mean_per_class_accuracy  0.476735     0.903638  211
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.10 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.973024           1.96056     1.96056            0.967742         0.975571   0.967742                    0.975571            0.0196786       0.0196786                  96.0558   96.0558
    2        0.0200745                   0.971363           1.99323     1.9769             0.983871         0.972105   0.975806                    0.973838            0.0200066       0.0396851                  99.3234   97.6896
    3        0.0301117                   0.970862           2.02591     1.99323            1                0.97099    0.983871                    0.972889            0.0203345       0.0600197                  102.591   99.3234
    4        0.0401489                   0.970077           2.02591     2.0014             1                0.970547   0.987903                    0.972303            0.0203345       0.0803542                  102.591   100.14
    5        0.0500243                   0.969504           2.02591     2.00624            1                0.969771   0.990291                    0.971803            0.0200066       0.100361                   102.591   100.624
    6        0.100049                    0.964898           1.99968     2.00296            0.987055         0.967723   0.988673                    0.969763            0.100033        0.200394                   99.9685   100.296
    7        0.150073                    0.958405           1.97346     1.99313            0.97411          0.961031   0.983819                    0.966852            0.0987209       0.299114                   97.3459   99.3128
    8        0.200097                    0.951496           1.98657     1.99149            0.980583         0.955173   0.98301                     0.963933            0.0993768       0.398491                   98.6572   99.1489
    9        0.299984                    0.918267           1.94054     1.97452            0.957861         0.936772   0.974636                    0.954889            0.193834        0.592325                   94.054    97.4524
    10       0.400032                    0.837408           1.81611     1.9349             0.89644          0.885834   0.955079                    0.937618            0.181699        0.774024                   81.6107   93.4904
    11       0.500081                    0.500627           1.34077     1.81604            0.661812         0.701729   0.896407                    0.890425            0.134142        0.908167                   34.0772   81.6039
    12       0.599968                    0.134854           0.610728    1.61537            0.301459         0.2877     0.797356                    0.790079            0.0610036       0.96917                    -38.9272  61.5371
    13       0.700016                    0.0537538          0.199968    1.41308            0.0987055        0.0855407  0.697502                    0.689384            0.0200066       0.989177                   -80.0032  41.3077
    14       0.799903                    0.0301913          0.0656697   1.24482            0.0324149        0.0399017  0.614451                    0.608281            0.00655953      0.995736                   -93.433   24.4822
    15       0.899951                    0.0211587          0.0327817   1.11008            0.0161812        0.0253808  0.54794                     0.54348             0.00327976      0.999016                   -96.7218  11.0078
    16       1                           0.012566           0.00983452  1                  0.00485437       0.0193     0.493605                    0.491036            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:11:18  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:11:24  1:04:41.668  4759 obs/sec      0.9886    1             24715      0.296005         0.290696            0.649491       0.948338        0.925236           2.01953          0.120251                         0.290962           0.28122               0.661309         0.951902          0.938309             2.02591            0.117533
    2019-08-03 17:11:29  1:04:47.154  4822 obs/sec      1.9766    2             49415      0.283558         0.268554            0.678349       0.956558        0.942532           2.01953          0.10679                          0.27907            0.261029              0.688428         0.959516          0.950169             2.02591            0.104258
    2019-08-03 17:11:35  1:04:52.485  4874 obs/sec      2.96496   3             74124      0.27964          0.264854            0.687177       0.95757         0.942561           2.01953          0.104896                         0.276478           0.258591              0.694189         0.960323          0.94487              2.02591            0.103124
    2019-08-03 17:11:40  1:04:58.009  4857 obs/sec      3.95376   4             98844      0.278717         0.261437            0.689239       0.958417        0.942069           2.01953          0.105295                         0.275567           0.254812              0.696203         0.961018          0.946587             2.02591            0.101991
    2019-08-03 17:11:46  1:05:03.686  4820 obs/sec      4.9434    5             123585     0.276262         0.259441            0.694688       0.958615        0.950841           1.99954          0.101605                         0.273037           0.252613              0.701755         0.961517          0.949108             2.02591            0.0981059
    2019-08-03 17:11:51  1:05:09.218  4811 obs/sec      5.93164   6             148291     0.275092         0.256935            0.69727        0.959851        0.954133           2.01953          0.100309                         0.271291           0.249286              0.705557         0.962811          0.957502             1.99323            0.100049
    2019-08-03 17:11:57  1:05:14.899  4794 obs/sec      6.92024   7             173006     0.274794         0.256084            0.697925       0.960015        0.946566           1.99954          0.10011                          0.271543           0.249233              0.705008         0.962502          0.949755             1.99323            0.100858
    2019-08-03 17:12:03  1:05:20.401  4809 obs/sec      7.90872   8             197718     0.276337         0.260252            0.694522       0.958185        0.949799           1.97954          0.100608                         0.272401           0.252251              0.703143         0.961175          0.953379             2.02591            0.0974583
    2019-08-03 17:12:08  1:05:25.843  4820 obs/sec      8.8978    9             222445     0.275222         0.258871            0.696982       0.958247        0.947438           1.97954          0.0995114                        0.271052           0.25091               0.706076         0.961407          0.954383             1.99323            0.0976202
    2019-08-03 17:12:13  1:05:31.274  4832 obs/sec      9.88608   10            247152     0.275944         0.258756            0.69539        0.959271        0.952522           1.97954          0.101406                         0.270746           0.249582              0.706739         0.96216           0.955777             1.96056            0.096487
    2019-08-03 17:12:19  1:05:36.665  4844 obs/sec      10.8753   11            271882     0.274216         0.257932            0.699194       0.958732        0.950461           1.97954          0.100608                         0.269533           0.249211              0.709361         0.962295          0.955082             1.96056            0.0966489
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007113797627145644
C438        0.9100816249847412     0.9100816249847412    0.006474136504325304
C374        0.7965338230133057     0.7965338230133057    0.0056663804200933025
C863        0.690277636051178      0.690277636051178     0.004910495409412575
C322        0.6763871908187866     0.6763871908187866    0.004811681593078393
---         ---                    ---                   ---
C908        0.05280360206961632    0.05280360206961632   0.00037563413910757937
C835        0.052089739590883255   0.052089739590883255  0.0003705558659002598
C949        0.05190504714846611    0.05190504714846611   0.000369242001241641
C363        0.05154673010110855    0.05154673010110855   0.000366693006280383
C981        0.049460314214229584   0.049460314214229584  0.0003518506658950644

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_62

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms              momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  --------------------  ----------  --------------------  -------------------  ---------------------  ------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0026214123698286578   0.001772334799170494  0.0         0.023147824838180498  0.08468696475028992  -0.033947717032166626  0.4056661128997803
    3        2        Softmax                      0.0   0.0   0.00027902499550691573  5.11397811351344e-05  0.0         -0.04253282236186351  0.6184999942779541   0.001290862188295147   0.1364174485206604


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07336278550809709
RMSE: 0.2708556543771924
LogLoss: 0.25759071481715706
Mean Per-Class Error: 0.08672254136772373
AUC: 0.9648480834977007
pr_auc: 0.8634810307306138
Gini: 0.9296961669954014
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49144198798729405: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4514  537   0.1063   (537.0/5051.0)
1      342   4636  0.0687   (342.0/4978.0)
Total  4856  5173  0.0876   (879.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.491442     0.913408  209
max f2                       0.39728      0.933781  237
max f0point5                 0.602311     0.922307  168
max accuracy                 0.525832     0.913252  197
max precision                0.999941     0.991952  0
max recall                   4.07223e-05  1         399
max specificity              0.999941     0.999208  0
max absolute_mcc             0.525832     0.826534  197
max min_per_class_accuracy   0.533003     0.911899  194
max mean_per_class_accuracy  0.525832     0.913277  197
Gains/Lift Table: Avg response rate: 49.64 %, avg score: 49.45 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   0.999999           2.01466    2.01466            1                1            1                           1                   0.0202893       0.0202893                  101.466   101.466
    2        0.0200419                   0.99999            1.99452    2.00464            0.99             0.999996     0.995025                    0.999998            0.0198875       0.0401768                  99.4518   100.464
    3        0.030013                    0.999965           2.01466    2.00797            1                0.99998      0.996678                    0.999992            0.0200884       0.0602652                  101.466   100.797
    4        0.0400838                   0.99989            1.99472    2.00464            0.990099         0.999936     0.995025                    0.999978            0.0200884       0.0803536                  99.4717   100.464
    5        0.0500548                   0.999764           1.99452    2.00262            0.99             0.999831     0.994024                    0.999949            0.0198875       0.100241                   99.4518   100.262
    6        0.10001                     0.997178           1.98652    1.99458            0.986028         0.998828     0.99003                     0.999389            0.0992366       0.199478                   98.6516   99.4578
    7        0.150065                    0.989238           1.99058    1.99325            0.988048         0.993748     0.989369                    0.997507            0.0996384       0.299116                   99.0585   99.3246
    8        0.20002                     0.97061            1.97445    1.98855            0.98004          0.980918     0.987039                    0.993364            0.098634        0.39775                    97.4452   98.8552
    9        0.30003                     0.88085            1.91624    1.96445            0.951147         0.934341     0.975075                    0.973689            0.191643        0.589393                   91.6241   96.4449
    10       0.40004                     0.703061           1.80175    1.92377            0.894317         0.79822      0.954885                    0.929822            0.180193        0.769586                   80.1749   92.3774
    11       0.50005                     0.525415           1.46831    1.83268            0.728814         0.608239     0.909671                    0.865505            0.146846        0.916432                   46.8315   83.2682
    12       0.59996                     0.281139           0.53282    1.61622            0.264471         0.405092     0.802227                    0.788834            0.0532342       0.969667                   -46.718   61.6218
    13       0.69997                     0.0844608          0.17676    1.41055            0.0877368        0.172439     0.700142                    0.700765            0.0176778       0.987344                   -82.324   41.0552
    14       0.79998                     0.00914608         0.0843628  1.24476            0.0418744        0.03667      0.617849                    0.617742            0.00843712      0.995781                   -91.5637  24.4758
    15       0.89999                     0.000206933        0.0321382  1.11001            0.0159521        0.00278391   0.550964                    0.549406            0.00321414      0.998996                   -96.7862  11.0007
    16       1                           2.46511e-22        0.0100432  1                  0.00498504       3.29783e-05  0.496361                    0.494463            0.00100442      1                          -98.9957  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0712979048219002
RMSE: 0.2670166751757279
LogLoss: 0.2505172875477412
Mean Per-Class Error: 0.07932294475820756
AUC: 0.9675600108710332
pr_auc: 0.832365917550035
Gini: 0.9351200217420663
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5251053334157071: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2879  249   0.0796   (249.0/3128.0)
1      241   2808  0.079    (241.0/3049.0)
Total  3120  3057  0.0793   (490.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.525105     0.919751  195
max f2                       0.348717     0.933804  257
max f0point5                 0.601461     0.930084  167
max accuracy                 0.525105     0.920673  195
max precision                0.995775     0.997326  5
max recall                   8.05234e-05  1         399
max specificity              0.999863     0.999361  0
max absolute_mcc             0.525105     0.841329  195
max min_per_class_accuracy   0.525105     0.920396  195
max mean_per_class_accuracy  0.525105     0.920677  195
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.16 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.99999            1.99323     2.00957            0.983871         0.999996     0.991935                    0.999998            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999961           2.02591     2.01502            1                0.999979     0.994624                    0.999991            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999894           2.02591     2.01774            1                0.999934     0.995968                    0.999977            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.999766           2.02591     2.01935            1                0.999829     0.996764                    0.999948            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.997603           2.01935     2.01935            0.996764         0.99895      0.996764                    0.999449            0.101017        0.202033                   101.935   101.935
    7        0.150073                    0.989702           1.99968     2.0128             0.987055         0.994357     0.993528                    0.997752            0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.971403           1.98657     2.00624            0.980583         0.981526     0.990291                    0.993695            0.0993768       0.401443                   98.6572   100.624
    9        0.299984                    0.873832           1.93726     1.98327            0.95624          0.931432     0.978953                    0.972963            0.193506        0.594949                   93.7256   98.3271
    10       0.400032                    0.698349           1.82594     1.94392            0.901294         0.790071     0.959531                    0.927222            0.182683        0.777632                   82.5942   94.3923
    11       0.500081                    0.512208           1.46534     1.84818            0.723301         0.600971     0.912269                    0.86195             0.146605        0.924237                   46.5343   84.8176
    12       0.599968                    0.284933           0.462971    1.61756            0.228525         0.398468     0.798435                    0.784787            0.0462447       0.970482                   -53.7029  61.7557
    13       0.700016                    0.0796242          0.16063     1.40933            0.079288         0.169573     0.695652                    0.696858            0.0160708       0.986553                   -83.937   40.9329
    14       0.799903                    0.0095353          0.0755202   1.24277            0.0372771        0.0347075    0.613439                    0.614173            0.00754346      0.994096                   -92.448   24.2771
    15       0.899951                    0.000244129        0.0491726   1.11008            0.0242718        0.00277742   0.54794                     0.546204            0.00491965      0.999016                   -95.0827  11.0078
    16       1                           2.46511e-22        0.00983452  1                  0.00485437       3.69419e-05  0.493605                    0.491561            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:15:31  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:15:33  1:08:50.317  25125 obs/sec     1         1             25000      0.318046         0.389863            0.595365       0.933767        0.753553           1.99472          0.134011                         0.315542           0.378335              0.601667         0.936102          0.724414             1.99323            0.134369
    2019-08-03 17:15:38  1:08:55.842  28049 obs/sec     7         7             175000     0.275531         0.266422            0.696316       0.961937        0.825699           1.99472          0.091036                         0.272203           0.259322              0.703574         0.964364          0.857613             2.02591            0.0862878
    2019-08-03 17:15:41  1:08:58.512  28905 obs/sec     10        10            250000     0.270856         0.257591            0.706533       0.964848        0.863481           2.01466          0.0876458                        0.267017           0.250517              0.714762         0.96756           0.832366             2.02591            0.0793265
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.0046204407771879025
C438        0.8904887437820435     0.8904887437820435   0.004114450503397383
C88         0.7501364350318909     0.7501364350318909   0.003465960972875712
C36         0.7139002084732056     0.7139002084732056   0.0032985336340725434
C374        0.6943679451942444     0.6943679451942444   0.003208285968347661
---         ---                    ---                  ---
C439        0.1026771292090416     0.1026771292090416   0.0004744135946820468
C562        0.10207780450582504    0.10207780450582504  0.000471644450384529
C315        0.09774748235940933    0.09774748235940933  0.00045163645336087
C588        0.0959172174334526     0.0959172174334526   0.00044317982266392275
C344        0.09324989467859268    0.09324989467859268  0.0004308556158414468

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_141

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.002888533359548871    0.0019165747798979282  0.0         0.022631946906961683  0.08267542719841003  0.017291234271086694   0.3923213481903076
    3        2        Softmax                      0.0   0.0   0.00029595263890769274  7.09637242835015e-05   0.0         -0.31518419944040943  0.6303615570068359   0.0022669370672239297  0.02324681729078293


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0744590183931993
RMSE: 0.2728717984570764
LogLoss: 0.2594084572588743
Mean Per-Class Error: 0.08659593044382996
AUC: 0.9643417962748331
pr_auc: 0.8424142740396381
Gini: 0.9286835925496661
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5110768845396658: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4472  484   0.0977   (484.0/4956.0)
1      389   4675  0.0768   (389.0/5064.0)
Total  4861  5159  0.0871   (873.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.511077     0.914604  203
max f2                       0.38669      0.935119  247
max f0point5                 0.571051     0.921458  177
max accuracy                 0.520246     0.913373  199
max precision                0.99992      0.996753  0
max recall                   6.98564e-05  1         399
max specificity              0.99992      0.999596  0
max absolute_mcc             0.520246     0.826764  199
max min_per_class_accuracy   0.515488     0.912717  201
max mean_per_class_accuracy  0.520246     0.913404  199
Gains/Lift Table: Avg response rate: 50.54 %, avg score: 50.57 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100798                   1                  1.97867    1.97867            1                1            1                           1                   0.0199447       0.0199447                  97.8673   97.8673
    2        0.0200599                   0.999994           1.97867    1.97867            1                0.999998     1                           0.999999            0.0197472       0.0396919                  97.8673   97.8673
    3        0.0300399                   0.999974           1.95889    1.9721             0.99             0.999986     0.996678                    0.999995            0.0195498       0.0592417                  95.8886   97.2099
    4        0.04002                     0.999924           1.95889    1.9688             0.99             0.999952     0.995012                    0.999984            0.0195498       0.0787915                  95.8886   96.8804
    5        0.05                        0.999833           1.97867    1.97077            1                0.999884     0.996008                    0.999964            0.0197472       0.0985387                  97.8673   97.0774
    6        0.1                         0.998097           1.96682    1.9688             0.994012         0.999198     0.99501                     0.999581            0.0983412       0.19688                    96.6825   96.8799
    7        0.15                        0.9914             1.93523    1.95761            0.978044         0.995362     0.989355                    0.998175            0.0967615       0.293641                   93.5229   95.7609
    8        0.2                         0.975293           1.92338    1.94905            0.972056         0.984303     0.98503                     0.994707            0.096169        0.38981                    92.3381   94.9052
    9        0.3                         0.889762           1.88191    1.92667            0.951098         0.939134     0.973719                    0.976183            0.188191        0.578002                   88.1912   92.6672
    10       0.4                         0.729032           1.80687    1.89672            0.913174         0.817947     0.958583                    0.936624            0.180687        0.758689                   80.6872   89.6722
    11       0.5                         0.521293           1.49882    1.81714            0.757485         0.61881      0.918363                    0.873061            0.149882        0.90857                    49.8815   81.7141
    12       0.6                         0.31822            0.590442   1.61269            0.298403         0.431643     0.815037                    0.799491            0.0590442       0.967615                   -40.9558  61.2691
    13       0.7                         0.106533           0.195498   1.41023            0.0988024        0.206992     0.712717                    0.714849            0.0195498       0.987164                   -80.4502  41.0235
    14       0.8                         0.0131608          0.0829384  1.24432            0.0419162        0.048762     0.628867                    0.631588            0.00829384      0.995458                   -91.7062  24.4323
    15       0.9                         0.000378085        0.0335703  1.10979            0.0169661        0.00431114   0.560878                    0.56189             0.00335703      0.998815                   -96.643   10.9795
    16       1                           1.31892e-18        0.0118483  1                  0.00598802       6.34607e-05  0.505389                    0.505708            0.00118483      1                          -98.8152  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07217879506857712
RMSE: 0.2686611156616773
LogLoss: 0.25124520319105814
Mean Per-Class Error: 0.0830929955651889
AUC: 0.9668992873433828
pr_auc: 0.8438866025200052
Gini: 0.9337985746867656
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5112376709117071: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2839  289   0.0924   (289.0/3128.0)
1      225   2824  0.0738   (225.0/3049.0)
Total  3064  3113  0.0832   (514.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.511238     0.916586  199
max f2                       0.326767     0.935663  260
max f0point5                 0.616673     0.921418  161
max accuracy                 0.518829     0.916788  196
max precision                0.997567     0.997059  4
max recall                   3.56436e-05  1         399
max specificity              0.999931     0.999361  0
max absolute_mcc             0.511238     0.833772  199
max min_per_class_accuracy   0.513559     0.915921  198
max mean_per_class_accuracy  0.511238     0.916907  199
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.84 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999994           2.02591     2.02591            1                0.999997     1                           0.999999            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999974           1.99323     2.01502            0.983871         0.999985     0.994624                    0.999994            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999928           1.99323     2.00957            0.983871         0.999951     0.991935                    0.999983            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999839           2.02591     2.0128             1                0.999886     0.993528                    0.999964            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.998143           2.02591     2.01935            1                0.999195     0.996764                    0.99958             0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.991288           1.99313     2.01061            0.983819         0.995425     0.992449                    0.998195            0.0997048       0.301738                   99.3128   101.061
    8        0.200097                    0.974533           1.95379     1.99641            0.964401         0.983934     0.985437                    0.99463             0.097737        0.399475                   95.379    99.6407
    9        0.299984                    0.886787           1.96024     1.98436            0.967585         0.938948     0.979493                    0.976089            0.195802        0.595277                   96.024    98.4364
    10       0.400032                    0.710376           1.79316     1.93654            0.885113         0.801325     0.955888                    0.93238             0.179403        0.77468                    79.316    93.6544
    11       0.503319                    0.511231           1.45751     1.83824            0.719436         0.602478     0.907366                    0.864681            0.150541        0.925221                   45.7512   83.8241
    12       0.599968                    0.29806            0.492055    1.62138            0.242881         0.407362     0.800324                    0.791011            0.0475566       0.972778                   -50.7945  62.1384
    13       0.700016                    0.093305           0.147518    1.41073            0.0728155        0.187626     0.696346                    0.704774            0.0147589       0.987537                   -85.2482  41.0734
    14       0.799903                    0.013623           0.0853706   1.24523            0.0421394        0.0456133    0.614653                    0.622462            0.00852739      0.996064                   -91.4629  24.5232
    15       0.899951                    0.000462174        0.0295035   1.11008            0.0145631        0.00438902   0.54794                     0.55375             0.00295179      0.999016                   -97.0496  11.0078
    16       1                           1.71213e-19        0.00983452  1                  0.00485437       7.85324e-05  0.493605                    0.498356            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:41:00  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:41:01  2:34:18.779  26315 obs/sec     1         1             25000      0.318491         0.375543            0.594206       0.93557         0.778806           1.97867          0.13493                          0.309522           0.353328              0.616723         0.940969          0.761479             2.02591            0.124494
    2019-08-03 18:41:07  2:34:24.319  28225 obs/sec     7         7             175000     0.276535         0.266961            0.694079       0.961288        0.840697           1.97867          0.0911178                        0.272644           0.258118              0.702612         0.963732          0.832859             2.02591            0.0879068
    2019-08-03 18:41:09  2:34:27.021  28958 obs/sec     10        10            250000     0.272872         0.259408            0.702129       0.964342        0.842414           1.97867          0.0871257                        0.268661           0.251245              0.711238         0.966899          0.843887             2.02591            0.0832119
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004834884036086324
C79         0.7625642418861389     0.7625642418861389   0.0036869096795855635
C88         0.720259428024292      0.720259428024292    0.0034823708103953166
C438        0.7101342082023621     0.7101342082023621   0.0034334165467164025
C35         0.7036014199256897     0.7036014199256897   0.0034018312729663875
---         ---                    ---                  ---
C588        0.10361506044864655    0.10361506044864655  0.0005009668016612807
C493        0.10240966081619263    0.10240966081619263  0.000495138834221225
C660        0.10199891030788422    0.10199891030788422  0.0004931529031457903
C606        0.09627937525510788    0.09627937525510788  0.0004654996144252858
C509        0.08946341276168823    0.08946341276168823  0.000432545226175288

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_101

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 259,649 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.06116010083735592    0.10024657845497131     0.0         -0.00197783468010358  0.1243714988231659  0.016245032547247195    0.14519447088241577
    3        2        Softmax                 0.0   0.0   0.0019101286989098298  0.00042517599649727345  0.0         0.011837497122428431  0.3450307846069336  -0.0004123076359605071  0.13677597045898438


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0784123627889163
RMSE: 0.280022075538548
LogLoss: 0.2694992798053831
Mean Per-Class Error: 0.10244601883833226
AUC: 0.956848503296736
pr_auc: 0.9465383147914753
Gini: 0.913697006593472
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4242660798997471: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4354  660   0.1316   (660.0/5014.0)
1      381   4630  0.076    (381.0/5011.0)
Total  4735  5290  0.1038   (1041.0/10025.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.424266     0.898942  226
max f2                       0.207707     0.927138  285
max f0point5                 0.823696     0.906485  111
max accuracy                 0.600585     0.897556  178
max precision                0.990415     0.986979  8
max recall                   0.00213042   1         399
max specificity              0.99712      0.999601  0
max absolute_mcc             0.600585     0.795191  178
max min_per_class_accuracy   0.56249      0.896428  188
max mean_per_class_accuracy  0.600585     0.897554  178
Gains/Lift Table: Avg response rate: 49.99 %, avg score: 50.81 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100748                   0.995464           1.94117    1.94117            0.970297         0.996296    0.970297                    0.996296            0.019557        0.019557                   94.1175   94.1175
    2        0.0200499                   0.994161           1.96059    1.95083            0.98             0.994718    0.975124                    0.995511            0.019557        0.0391139                  96.0587   95.0833
    3        0.0300249                   0.993283           2.0006     1.96737            1                0.993718    0.983389                    0.994915            0.0199561       0.05907                    100.06    96.7366
    4        0.04                        0.992441           2.0006     1.97565            1                0.992856    0.987531                    0.994402            0.0199561       0.0790261                  100.06    97.5654
    5        0.0500748                   0.991796           1.94117    1.96872            0.970297         0.992102    0.984064                    0.993939            0.019557        0.0985831                  94.1175   96.8717
    6        0.10005                     0.98817            1.95268    1.96071            0.976048         0.990054    0.98006                     0.991998            0.0975853       0.196168                   95.268    96.0706
    7        0.150025                    0.984279           1.95667    1.95936            0.978044         0.98628     0.979388                    0.990094            0.0977849       0.293953                   95.6673   95.9363
    8        0.2                         0.979057           1.93671    1.9537             0.968064         0.981876    0.976559                    0.98804             0.0967871       0.39074                    93.6707   95.3702
    9        0.30005                     0.959603           1.89488    1.93409            0.947159         0.970803    0.966755                    0.982293            0.189583        0.580323                   89.4884   93.4089
    10       0.4                         0.889688           1.79295    1.89882            0.896208         0.933118    0.949127                    0.970005            0.179206        0.759529                   79.2952   89.8823
    11       0.50005                     0.561077           1.3703     1.79308            0.684945         0.764933    0.89627                     0.928974            0.137098        0.896627                   37.03     79.3076
    12       0.6                         0.142743           0.66487    1.60514            0.332335         0.326371    0.802328                    0.828591            0.0664538       0.963081                   -33.513   60.5135
    13       0.69995                     0.0343136          0.245582   1.411              0.122754         0.0729257   0.705287                    0.720685            0.024546        0.987627                   -75.4418  41.0997
    14       0.8                         0.013842           0.0738007  1.24376            0.0368893        0.0217092   0.621696                    0.633269            0.00738376      0.995011                   -92.6199  24.3764
    15       0.89995                     0.00719927         0.0319457  1.10918            0.0159681        0.0102065   0.554423                    0.564071            0.00319298      0.998204                   -96.8054  10.9177
    16       1                           0.00107749         0.0179515  1                  0.00897308       0.00485883  0.49985                     0.508122            0.00179605      1                          -98.2048  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07335733174660561
RMSE: 0.27084558653706287
LogLoss: 0.25175874638144274
Mean Per-Class Error: 0.09612675406552307
AUC: 0.9617025707141413
pr_auc: 0.9572405422084737
Gini: 0.9234051414282827
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44282058072148034: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2757  371   0.1186   (371.0/3128.0)
1      232   2817  0.0761   (232.0/3049.0)
Total  2989  3188  0.0976   (603.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.442821     0.903319  214
max f2                       0.20864      0.930262  281
max f0point5                 0.82204      0.916406  109
max accuracy                 0.614486     0.903999  171
max precision                0.997317     1         0
max recall                   0.00292428   1         398
max specificity              0.997317     1         0
max absolute_mcc             0.614486     0.808043  171
max min_per_class_accuracy   0.567704     0.900295  184
max mean_per_class_accuracy  0.614486     0.903873  171
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.26 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.995283           2.02591    2.02591            1                0.99612     1                           0.99612             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.994276           2.02591    2.02591            1                0.99475     1                           0.995435            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.993434           2.02591    2.02591            1                0.993846    1                           0.994905            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.992704           1.99323    2.01774            0.983871         0.993057    0.995968                    0.994443            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.991944           2.02591    2.01935            1                0.992352    0.996764                    0.99403             0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.988319           1.98002    1.99968            0.977346         0.990185    0.987055                    0.992108            0.0990489       0.200066                   98.0016   99.9685
    7        0.150073                    0.98419            1.99968    1.99968            0.987055         0.986439    0.987055                    0.990218            0.100033        0.300098                   99.9685   99.9685
    8        0.200097                    0.979323           1.9669     1.99149            0.970874         0.981905    0.98301                     0.98814             0.0983929       0.398491                   96.6903   99.1489
    9        0.299984                    0.958993           1.94382    1.97562            0.959481         0.971194    0.975175                    0.982497            0.194162        0.592653                   94.3823   97.5618
    10       0.400032                    0.882165           1.80627    1.93326            0.891586         0.928564    0.95427                     0.969008            0.180715        0.773368                   80.6273   93.3264
    11       0.500081                    0.53499            1.31783    1.81014            0.650485         0.74598     0.893493                    0.924388            0.131847        0.905215                   31.7825   81.0137
    12       0.599968                    0.134454           0.620579   1.61209            0.306321         0.297192    0.795737                    0.819968            0.0619875       0.967202                   -37.9421  61.2091
    13       0.700016                    0.0342504          0.203247   1.41073            0.100324         0.0694662   0.696346                    0.712704            0.0203345       0.987537                   -79.6753  41.0734
    14       0.799903                    0.0136586          0.0656697  1.24277            0.0324149        0.0216008   0.613439                    0.626404            0.00655953      0.994096                   -93.433   24.2771
    15       0.899951                    0.00705368         0.0327817  1.10826            0.0161812        0.00999353  0.547041                    0.557877            0.00327976      0.997376                   -96.7218  10.8256
    16       1                           0.00133873         0.0262254  1                  0.012945         0.00489977  0.493605                    0.502552            0.00262381      1                          -97.3775  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:58:02  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:58:11  1:51:29.359  2476 obs/sec      0.94568   1             23642      0.299392         0.29565             0.641458       0.946701        0.929338           2.0006           0.122095                         0.296434           0.289818              0.64845          0.949004          0.931475             2.02591            0.115914
    2019-08-03 17:58:22  1:51:39.947  2424 obs/sec      1.89024   2             47256      0.288135         0.276442            0.667913       0.953243        0.942829           1.98079          0.111222                         0.282405           0.267064              0.680938         0.956861          0.948379             2.02591            0.106362
    2019-08-03 17:58:32  1:51:50.222  2432 obs/sec      2.83264   3             70816      0.284319         0.270316            0.676652       0.955355        0.947648           1.98079          0.111322                         0.279718           0.262086              0.686981         0.958623          0.948278             2.02591            0.106039
    2019-08-03 17:58:43  1:52:00.583  2434 obs/sec      3.77944   4             94486      0.283208         0.269774            0.679172       0.955943        0.948332           1.98079          0.109526                         0.27699            0.25949               0.693055         0.960082          0.955989             2.02591            0.103124
    2019-08-03 17:58:53  1:52:10.945  2434 obs/sec      4.72404   5             118101     0.281618         0.267078            0.682765       0.956169        0.9503             1.94117          0.106933                         0.277432           0.258587              0.692076         0.959448          0.957152             2.02591            0.102639
    2019-08-03 17:59:03  1:52:21.194  2436 obs/sec      5.66484   6             141621     0.282162         0.267241            0.681537       0.956523        0.94779            1.98079          0.106733                         0.276678           0.257788              0.693747         0.959836          0.957514             1.99323            0.10102
    2019-08-03 17:59:14  1:52:31.486  2435 obs/sec      6.60832   7             165208     0.280978         0.266459            0.684204       0.957346        0.948915           1.96098          0.105835                         0.274956           0.255088              0.697547         0.961002          0.949021             1.99323            0.100696
    2019-08-03 17:59:24  1:52:41.718  2438 obs/sec      7.55328   8             188832     0.28339          0.272015            0.678761       0.954348        0.945859           1.96098          0.108329                         0.275956           0.260096              0.695344         0.958767          0.954364             2.02591            0.100534
    2019-08-03 17:59:34  1:52:52.045  2440 obs/sec      8.49744   9             212436     0.282972         0.273369            0.679708       0.953043        0.940281           1.94117          0.105536                         0.27512            0.259756              0.697187         0.957598          0.952744             1.99323            0.0981059
    2019-08-03 17:59:44  1:53:02.297  2442 obs/sec      9.444     10            236100     0.280022         0.269499            0.686351       0.956849        0.946538           1.94117          0.10384                          0.270846           0.251759              0.706523         0.961703          0.957241             2.02591            0.0976202
    2019-08-03 17:59:54  1:53:12.317  2448 obs/sec      10.386    11            259649     0.282212         0.273594            0.681425       0.953126        0.938534           1.88175          0.106534                         0.275185           0.261222              0.697044         0.956821          0.948142             1.99323            0.0998867
    2019-08-03 17:59:55  1:53:12.985  2448 obs/sec      10.386    11            259649     0.280022         0.269499            0.686351       0.956849        0.946538           1.94117          0.10384                          0.270846           0.251759              0.706523         0.961703          0.957241             2.02591            0.0976202
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0055986986529637265
C438        0.8720830082893372     0.8720830082893372   0.004882529963782066
C374        0.7171646952629089     0.7171646952629089   0.00401518901332159
C88         0.652119517326355      0.652119517326355    0.003651020663226419
C863        0.6511231064796448     0.6511231064796448   0.0036454420591611443
---         ---                    ---                  ---
C765        0.10032780468463898    0.10032780468463898  0.0005617051449426961
C982        0.09878332167863846    0.09878332167863846  0.0005530580500174757
C690        0.09847892820835114    0.09847892820835114  0.0005513538427054071
C873        0.0953521579504013     0.0953521579504013   0.0005338479982740963
C958        0.09046829491853714    0.09046829491853714  0.000506504720896339

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_34

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.04456187141894941   0.0865219235420227     0.0         0.0025769527693858363  0.1254042387008667   -0.0018297320538589574  0.14092165231704712
    3        2        Softmax                 0.0   0.0   0.001798186586711381  0.0004255946259945631  0.0         -0.020300344185670838  0.48676812648773193  -0.00467981917710459    0.1093870997428894


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07875442507193126
RMSE: 0.28063218823209013
LogLoss: 0.26714186373934595
Mean Per-Class Error: 0.10341250539972269
AUC: 0.9562771428048646
pr_auc: 0.9490933322217869
Gini: 0.9125542856097293
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5595151673728701: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4477  533   0.1064   (533.0/5010.0)
1      504   4514  0.1004   (504.0/5018.0)
Total  4981  5047  0.1034   (1037.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.559515     0.89697   186
max f2                       0.162449     0.927681  305
max f0point5                 0.803234     0.906667  110
max accuracy                 0.561953     0.89659   185
max precision                0.9812       1         0
max recall                   0.0129825    1         399
max specificity              0.9812       1         0
max absolute_mcc             0.559515     0.793191  186
max min_per_class_accuracy   0.572197     0.895808  182
max mean_per_class_accuracy  0.561953     0.896587  185
Gains/Lift Table: Avg response rate: 50.04 %, avg score: 50.67 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   0.976754           1.97862    1.97862            0.990099         0.978762   0.990099                    0.978762            0.0199283       0.0199283                  97.862    97.862
    2        0.0200439                   0.974357           1.97842    1.97852            0.99             0.975511   0.99005                     0.977144            0.019729        0.0396572                  97.8422   97.8521
    3        0.030016                    0.973325           1.97842    1.97849            0.99             0.973814   0.990033                    0.976038            0.019729        0.0593862                  97.8422   97.8488
    4        0.0400878                   0.972204           1.95883    1.97355            0.980198         0.972725   0.987562                    0.975206            0.019729        0.0791152                  95.8833   97.355
    5        0.0500598                   0.971836           1.97842    1.97452            0.99             0.971966   0.988048                    0.97456             0.019729        0.0988442                  97.8422   97.452
    6        0.10002                     0.968157           1.97846    1.97649            0.99002          0.970299   0.989033                    0.972432            0.0988442       0.197688                   97.8462   97.6489
    7        0.15008                     0.963365           1.94267    1.96521            0.972112         0.965931   0.983389                    0.970264            0.0972499       0.294938                   94.2673   96.521
    8        0.20004                     0.956932           1.92661    1.95557            0.964072         0.960436   0.978564                    0.967809            0.0962535       0.391192                   92.6607   95.5569
    9        0.30006                     0.933248           1.90078    1.9373             0.951147         0.946641   0.969425                    0.960753            0.190116        0.581307                   90.0777   93.7305
    10       0.39998                     0.854804           1.77503    1.89677            0.888224         0.902435   0.94914                     0.946184            0.177361        0.758669                   77.5031   89.6767
    11       0.5                         0.57255            1.37079    1.79155            0.685942         0.739294   0.89649                     0.904798            0.137106        0.895775                   37.0791   79.155
    12       0.60002                     0.181686           0.687388   1.60749            0.343968         0.36087    0.804388                    0.814128            0.0687525       0.964528                   -31.2612  60.7493
    13       0.69994                     0.055189           0.213403   1.40848            0.106786         0.100424   0.704801                    0.712243            0.0213232       0.985851                   -78.6597  40.8479
    14       0.79996                     0.0298496          0.0777047  1.24209            0.0388833        0.0402118  0.621541                    0.628218            0.00777202      0.993623                   -92.2295  24.2091
    15       0.89998                     0.0195331          0.0498107  1.10959            0.0249252        0.0238388  0.555235                    0.56105             0.00498206      0.998605                   -95.0189  10.9586
    16       1                           0.0115855          0.013947   1                  0.00697906       0.0176093  0.500399                    0.506695            0.00139498      1                          -98.6053  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07438899820071927
RMSE: 0.2727434659175528
LogLoss: 0.2518967734488253
Mean Per-Class Error: 0.099569614875197
AUC: 0.9624990248783929
pr_auc: 0.9574446855631915
Gini: 0.9249980497567858
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44813849659739907: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2739  389   0.1244   (389.0/3128.0)
1      228   2821  0.0748   (228.0/3049.0)
Total  2967  3210  0.0999   (617.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.448138     0.901422  220
max f2                       0.164316     0.93073   303
max f0point5                 0.830892     0.913609  104
max accuracy                 0.586554     0.900437  181
max precision                0.981488     1         0
max recall                   0.0144321    1         397
max specificity              0.981488     1         0
max absolute_mcc             0.448138     0.801416  220
max min_per_class_accuracy   0.576094     0.899311  184
max mean_per_class_accuracy  0.448138     0.90043   220
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.13 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.976915           2.02591     2.02591            1                0.97878    1                           0.97878             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.974433           1.99323     2.00957            0.983871         0.97561    0.991935                    0.977195            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.97327            2.02591     2.01502            1                0.973825   0.994624                    0.976072            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.972219           1.96056     2.0014             0.967742         0.972656   0.987903                    0.975218            0.0196786       0.0803542                  96.0558   100.14
    5        0.0500243                   0.971834           2.02591     2.00624            1                0.971955   0.990291                    0.974574            0.0200066       0.100361                   102.591   100.624
    6        0.100049                    0.968299           2.0128      2.00952            0.993528         0.97043    0.991909                    0.972502            0.100689        0.20105                    101.28    100.952
    7        0.150073                    0.96331            2.0128      2.01061            0.993528         0.966023   0.992449                    0.970342            0.100689        0.301738                   101.28    101.061
    8        0.200097                    0.956852           1.9669      1.99968            0.970874         0.960274   0.987055                    0.967825            0.0983929       0.400131                   96.6903   99.9685
    9        0.299984                    0.932898           1.94382     1.98108            0.959481         0.946297   0.977874                    0.960657            0.194162        0.594293                   94.3823   98.1084
    10       0.400032                    0.857276           1.7866      1.93244            0.881877         0.90285    0.953865                    0.946199            0.178747        0.77304                    78.6604   93.2444
    11       0.500081                    0.548274           1.30471     1.80686            0.644013         0.732939   0.891874                    0.903534            0.130535        0.903575                   30.4712   80.6857
    12       0.599968                    0.156592           0.669831    1.61756            0.330632         0.322423   0.798435                    0.806786            0.0669072       0.970482                   -33.0169  61.7557
    13       0.700016                    0.0546252          0.173743    1.4112             0.0857605        0.0926614  0.696577                    0.704721            0.0173827       0.987865                   -82.6257  41.1203
    14       0.799903                    0.0281159          0.0788036   1.24482            0.0388979        0.0391959  0.614451                    0.621615            0.00787143      0.995736                   -92.1196  24.4822
    15       0.899951                    0.0192186          0.0393381   1.11081            0.0194175        0.0229894  0.5483                      0.555065            0.00393572      0.999672                   -96.0662  11.0807
    16       1                           0.0113579          0.00327817  1                  0.00161812       0.0174652  0.493605                    0.501279            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:44:44  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:44:49  38 min  6.794 sec  4753 obs/sec      1         1             25000      0.300138         0.302119            0.63967        0.944843        0.91451            1.99841          0.121161                         0.293909           0.286128              0.654415         0.950386          0.918975             2.02591            0.116723
    2019-08-03 16:44:55  38 min 12.309 sec  4818 obs/sec      2         2             50000      0.290754         0.281207            0.661847       0.952204        0.944417           1.99841          0.115576                         0.281627           0.26493               0.682694         0.958635          0.95136              2.02591            0.109438
    2019-08-03 16:45:00  38 min 17.865 sec  4840 obs/sec      3         3             75000      0.284686         0.271628            0.675816       0.954894        0.937216           1.99841          0.107898                         0.274978           0.255038              0.697499         0.960874          0.948147             2.02591            0.100696
    2019-08-03 16:45:06  38 min 23.307 sec  4865 obs/sec      4         4             100000     0.28345          0.26944             0.678625       0.955518        0.942148           1.99841          0.109294                         0.273472           0.252141              0.700804         0.961576          0.948213             2.02591            0.100372
    2019-08-03 16:45:11  38 min 28.894 sec  4858 obs/sec      5         5             125000     0.282637         0.268938            0.680465       0.956046        0.953205           1.99841          0.1073                           0.2737             0.252404              0.700303         0.962274          0.959591             2.02591            0.103124
    2019-08-03 16:45:17  38 min 34.353 sec  4875 obs/sec      6         6             150000     0.281715         0.268364            0.682546       0.955402        0.941099           1.99841          0.107998                         0.27375            0.254524              0.700196         0.960192          0.939839             2.02591            0.0985915
    2019-08-03 16:45:22  38 min 39.754 sec  4889 obs/sec      7         7             175000     0.280632         0.267142            0.684982       0.956277        0.949093           1.97862          0.10341                          0.272743           0.251897              0.702395         0.962499          0.957445             2.02591            0.0998867
    2019-08-03 16:45:27  38 min 45.248 sec  4898 obs/sec      8         8             200000     0.282155         0.270425            0.681554       0.954775        0.947296           1.99841          0.105903                         0.274134           0.255249              0.699352         0.960374          0.953086             2.02591            0.100534
    2019-08-03 16:45:33  38 min 50.587 sec  4918 obs/sec      9         9             225000     0.280177         0.267878            0.686003       0.955359        0.946581           1.99841          0.101915                         0.272155           0.252695              0.703678         0.96056           0.95168              2.02591            0.0968107
    2019-08-03 16:45:38  38 min 55.877 sec  4936 obs/sec      10        10            250000     0.280734         0.268814            0.684754       0.954849        0.949486           1.99841          0.10341                          0.272684           0.254541              0.702524         0.959654          0.953806             2.02591            0.0968107
    2019-08-03 16:45:38  38 min 56.316 sec  4935 obs/sec      10        10            250000     0.280632         0.267142            0.684982       0.956277        0.949093           1.97862          0.10341                          0.272743           0.251897              0.702395         0.962499          0.957445             2.02591            0.0998867
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007036969995750012
C438        0.84715735912323       0.84715735912323      0.005961420917828987
C374        0.7535058856010437     0.7535058856010437    0.0053023983085955856
C863        0.6466490626335144     0.6466490626335144    0.004550450051531911
C88         0.6396729350090027     0.6396729350090027    0.004501359250751699
---         ---                    ---                   ---
C921        0.060223497450351715   0.060223497450351715  0.00042379094459725237
C974        0.05998334661126137    0.05998334661126137   0.0004221010103481194
C961        0.059693533927202225   0.059693533927202225  0.0004200616071860074
C539        0.05659514293074608    0.05659514293074608   0.00039825832270884356
C725        0.05524417757987976    0.05524417757987976   0.0003887516200694994

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_146

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight          weight_rms           mean_bias                bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  -------------------  -------------------  -----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.003282373176777898    0.003247191198170185   0.0         0.02356762219257216  0.09199443459510803  0.0353112401061647       0.3955780267715454
    3        2        Softmax                      0.0   0.0   0.00028246861347724916  6.137503078207374e-05  0.0         0.15961063722443214  0.7551741600036621   -0.00048114941008195466  0.15495038032531738


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07563115839784654
RMSE: 0.2750111968590489
LogLoss: 0.266278542255571
Mean Per-Class Error: 0.08875631134982775
AUC: 0.9619605360283016
pr_auc: 0.8580294450824386
Gini: 0.9239210720566031
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5376508199475973: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4565  463   0.0921   (463.0/5028.0)
1      431   4559  0.0864   (431.0/4990.0)
Total  4996  5022  0.0892   (894.0/10018.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.537651     0.910707  199
max f2                       0.369258     0.932151  254
max f0point5                 0.622378     0.918639  167
max accuracy                 0.551109     0.91126   194
max precision                0.999947     0.996086  0
max recall                   4.67576e-05  1         399
max specificity              0.999947     0.999602  0
max absolute_mcc             0.551109     0.822537  194
max min_per_class_accuracy   0.542332     0.9107    197
max mean_per_class_accuracy  0.551109     0.911244  194
Gains/Lift Table: Avg response rate: 49.81 %, avg score: 49.55 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100819                   0.999999           2.00762    2.00762            1                1            1                           1                   0.0202405       0.0202405                  100.762   100.762
    2        0.0200639                   0.999993           1.98754    1.99763            0.99             0.999997     0.995025                    0.999998            0.0198397       0.0400802                  98.7539   99.7627
    3        0.0300459                   0.999972           2.00762    2.00095            1                0.999984     0.996678                    0.999994            0.0200401       0.0601202                  100.762   100.095
    4        0.0400279                   0.9999             2.00762    2.00261            1                0.999942     0.997506                    0.999981            0.0200401       0.0801603                  100.762   100.261
    5        0.05001                     0.999767           1.98754    1.9996             0.99             0.999841     0.996008                    0.999953            0.0198397       0.1                        98.7539   99.9601
    6        0.10002                     0.997243           1.9996     1.9996             0.996008         0.998816     0.996008                    0.999384            0.1             0.2                        99.9601   99.9601
    7        0.15003                     0.988116           1.9435     1.9809             0.968064         0.993371     0.986693                    0.99738             0.0971944       0.297194                   94.35     98.09
    8        0.20004                     0.967795           1.92346    1.96654            0.958084         0.979247     0.979541                    0.992847            0.0961924       0.393387                   92.3464   96.6541
    9        0.30006                     0.871562           1.92747    1.95352            0.96008          0.925442     0.973054                    0.970379            0.192786        0.586172                   92.7471   95.3518
    10       0.39998                     0.712873           1.80104    1.91543            0.897103         0.79598      0.95408                     0.926812            0.17996         0.766132                   80.1037   91.5426
    11       0.5                         0.538377           1.46063    1.82445            0.727545         0.621586     0.908764                    0.865754            0.146092        0.912224                   46.063    82.4449
    12       0.60002                     0.278943           0.542978   1.61083            0.270459         0.414846     0.802362                    0.79059             0.0543086       0.966533                   -45.7022  61.0835
    13       0.69994                     0.0830514          0.194544   1.40865            0.0969031        0.16975      0.701654                    0.701962            0.0194389       0.985972                   -80.5456  40.8652
    14       0.79996                     0.0102769          0.0861551  1.2433             0.0429142        0.0380981    0.619291                    0.618959            0.00861723      0.994589                   -91.3845  24.3299
    15       0.89998                     0.000310273        0.0420758  1.1098             0.0209581        0.0033469    0.552795                    0.550542            0.00420842      0.998798                   -95.7924  10.98
    16       1                           3.52037e-21        0.0120216  1                  0.00598802       5.23456e-05  0.498103                    0.495482            0.0012024       1                          -98.7978  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07198800802081726
RMSE: 0.2683058106355829
LogLoss: 0.2520261240717644
Mean Per-Class Error: 0.08312366471250898
AUC: 0.9667438445710681
pr_auc: 0.8560378310472134
Gini: 0.9334876891421362
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5297999344515577: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2851  277   0.0886   (277.0/3128.0)
1      240   2809  0.0787   (240.0/3049.0)
Total  3091  3086  0.0837   (517.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.5298       0.915729  202
max f2                       0.373238     0.934946  249
max f0point5                 0.586942     0.92548   180
max accuracy                 0.55727      0.91695   191
max precision                0.996107     0.997203  5
max recall                   5.49642e-05  1         399
max specificity              0.99992      0.999361  0
max absolute_mcc             0.55727      0.833959  191
max min_per_class_accuracy   0.537088     0.915281  199
max mean_per_class_accuracy  0.548628     0.916876  194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.38 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999999           2.02591     2.02591            1                1           1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999988           1.99323     2.00957            0.983871         0.999995    0.991935                    0.999997            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999952           1.99323     2.00413            0.983871         0.999972    0.989247                    0.999989            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.999876           2.02591     2.00957            1                0.999916    0.991935                    0.999971            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999746           2.02591     2.0128             1                0.999816    0.993528                    0.99994             0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.997306           2.02591     2.01935            1                0.998856    0.996764                    0.999398            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.988482           1.99968     2.0128             0.987055         0.993614    0.993528                    0.99747             0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.970346           1.96035     1.99968            0.967638         0.980001    0.987055                    0.993103            0.0980649       0.400131                   96.0347   99.9685
    9        0.299984                    0.871266           1.93726     1.9789             0.95624          0.928602    0.976794                    0.971626            0.193506        0.593637                   93.7256   97.8898
    10       0.400032                    0.706535           1.84889     1.94638            0.912621         0.790434    0.960745                    0.92631             0.184979        0.778616                   84.8889   94.6382
    11       0.500081                    0.527895           1.426       1.84227            0.703883         0.6142      0.909356                    0.863867            0.14267         0.921286                   42.6005   84.2273
    12       0.599968                    0.276654           0.502373    1.6192             0.247974         0.403522    0.799244                    0.787226            0.0501804       0.971466                   -49.7627  61.9197
    13       0.700016                    0.0856302          0.157352    1.41027            0.0776699        0.173865    0.696115                    0.699562            0.0157429       0.987209                   -84.2648  41.0266
    14       0.799903                    0.00964275         0.0820871   1.24441            0.0405186        0.0381799   0.614248                    0.616973            0.00819941      0.995408                   -91.7913  24.4412
    15       0.899951                    0.000321338        0.0426162   1.11081            0.0210356        0.00312884  0.5483                      0.548732            0.00426369      0.999672                   -95.7384  11.0807
    16       1                           3.52037e-21        0.00327817  1                  0.00161812       5.3902e-05  0.493605                    0.493837            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:48:34  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:48:35  2:41:52.636  25667 obs/sec     1         1             25000      0.325827         0.408232            0.575341       0.928765        0.786652           1.96786          0.139349                         0.317111           0.377722              0.597696         0.936521          0.792964             1.99323            0.134693
    2019-08-03 18:48:41  2:41:58.169  28044 obs/sec     7         7             175000     0.277801         0.271701            0.691302       0.960074        0.848749           1.98774          0.0943302                        0.271259           0.257942              0.705627         0.964571          0.85843              1.99323            0.0882305
    2019-08-03 18:48:43  2:42:00.930  28522 obs/sec     10        10            250000     0.275011         0.266279            0.697471       0.961961        0.858029           2.00762          0.0892394                        0.268306           0.252026              0.712001         0.966744          0.856038             2.02591            0.0836976
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.004898569461263946
C79         0.7313244342803955     0.7313244342803955   0.0035824435400420764
C88         0.7105491757392883     0.7105491757392883   0.003480674493002746
C438        0.6956602931022644     0.6956602931022644   0.0034077402672046775
C36         0.6581101417541504     0.6581101417541504   0.003223798242544967
---         ---                    ---                  ---
C347        0.10116453468799591    0.10116453468799591  0.0004955615001855938
C218        0.09529632329940796    0.09529632329940796  0.0004668156590852156
C628        0.09010389447212219    0.09010389447212219  0.000441380185802087
C813        0.08971032500267029    0.08971032500267029  0.00043945225841814404
C379        0.08421897143125534    0.08421897143125534  0.0004125524815122081

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_98

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.032781154784476844   0.05449257791042328    0.0         0.0006920373783574724  0.15481919050216675  0.010946755345314725   0.17232286930084229
    3        2        Softmax                 0.0   0.0   0.0020498899275480653  0.0006396952085196972  0.0         0.018222540578108237   0.4616990089416504   0.0021259033106841713  0.10313495993614197


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07630664176690055
RMSE: 0.2762365684823437
LogLoss: 0.25842612982016
Mean Per-Class Error: 0.10193090828519913
AUC: 0.9591346153846154
pr_auc: 0.9493306348499099
Gini: 0.9182692307692308
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5085468101687851: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4406  586   0.1174   (586.0/4992.0)
1      448   4586  0.089    (448.0/5034.0)
Total  4854  5172  0.1031   (1034.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.508547     0.898687  204
max f2                       0.189472     0.930518  299
max f0point5                 0.805513     0.914069  113
max accuracy                 0.575758     0.898065  185
max precision                0.989583     1         0
max recall                   0.00964613   1         397
max specificity              0.989583     1         0
max absolute_mcc             0.650747     0.796182  164
max min_per_class_accuracy   0.57164      0.897497  186
max mean_per_class_accuracy  0.575758     0.898069  185
Gains/Lift Table: Avg response rate: 50.21 %, avg score: 50.93 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.985978           1.95222    1.95222            0.980198         0.987741   0.980198                    0.987741            0.0196663       0.0196663                  95.2218   95.2218
    2        0.0200479                   0.983812           1.97174    1.96193            0.99             0.98476    0.985075                    0.986258            0.0196663       0.0393325                  97.174    96.1931
    3        0.0300219                   0.982219           1.95182    1.95857            0.98             0.983058   0.983389                    0.985195            0.0194676       0.0588002                  95.1824   95.8573
    4        0.0400958                   0.98045            1.9325     1.95202            0.970297         0.981281   0.9801                      0.984211            0.0194676       0.0782678                  93.2499   95.2022
    5        0.0500698                   0.979149           1.95182    1.95198            0.98             0.979838   0.98008                     0.98334             0.0194676       0.0977354                  95.1824   95.1982
    6        0.10004                     0.974117           1.95985    1.95591            0.984032         0.97642    0.982054                    0.979883            0.097934        0.195669                   95.9854   95.5914
    7        0.15001                     0.969141           1.95588    1.9559             0.982036         0.971676   0.982048                    0.977149            0.0977354       0.293405                   95.5878   95.5902
    8        0.20008                     0.962751           1.95198    1.95492            0.98008          0.965954   0.981555                    0.974348            0.0977354       0.39114                    95.1982   95.4921
    9        0.30002                     0.943034           1.91612    1.942              0.962076         0.954301   0.975066                    0.96767             0.191498        0.582638                   91.6125   94.1998
    10       0.40006                     0.875575           1.77919    1.90128            0.89332          0.91676    0.954625                    0.954939            0.17799         0.760628                   77.9187   90.1285
    11       0.5                         0.578722           1.3556     1.79221            0.680639         0.75867    0.89986                     0.915709            0.135479        0.896106                   35.5599   79.2213
    12       0.60004                     0.167499           0.700952   1.61028            0.351944         0.354477   0.808511                    0.822139            0.0701232       0.96623                    -29.9048  61.0276
    13       0.69998                     0.0492364          0.204731   1.4096             0.102794         0.0911044  0.707751                    0.717765            0.0204609       0.986691                   -79.5269  40.9598
    14       0.80002                     0.0254396          0.0734709  1.24252            0.0368893        0.0346312  0.623862                    0.632341            0.00735002      0.994041                   -92.6529  24.252
    15       0.89996                     0.0169251          0.0457167  1.10962            0.0229541        0.0205923  0.557132                    0.564407            0.00456893      0.998609                   -95.4283  10.9615
    16       1                           0.00611143         0.0138999  1                  0.00697906       0.0133766  0.502095                    0.509282            0.00139054      1                          -98.61    0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07428480425280287
RMSE: 0.27255238808860743
LogLoss: 0.2522470237443225
Mean Per-Class Error: 0.0978875301029476
AUC: 0.9612152720400551
pr_auc: 0.9556542570436292
Gini: 0.9224305440801102
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.537665370688519: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2808  320   0.1023   (320.0/3128.0)
1      285   2764  0.0935   (285.0/3049.0)
Total  3093  3084  0.0979   (605.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.537665     0.901353  192
max f2                       0.159815     0.930599  298
max f0point5                 0.817271     0.914612  106
max accuracy                 0.537665     0.902056  192
max precision                0.98972      1         0
max recall                   0.0106475    1         396
max specificity              0.98972      1         0
max absolute_mcc             0.537665     0.80416   192
max min_per_class_accuracy   0.565757     0.899967  185
max mean_per_class_accuracy  0.537665     0.902112  192
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.10 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.986102           2.02591    2.02591            1                0.987736   1                           0.987736            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.983976           1.99323    2.00957            0.983871         0.984899   0.991935                    0.986317            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.982644           2.02591    2.01502            1                0.983344   0.994624                    0.985326            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.981014           2.02591    2.01774            1                0.98181    0.995968                    0.984447            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.979676           1.92628    1.99968            0.95082          0.980408   0.987055                    0.98365             0.0190226       0.100033                   92.6275   99.9685
    6        0.100049                    0.974322           2.0128     2.00624            0.993528         0.976777   0.990291                    0.980214            0.100689        0.200722                   101.28    100.624
    7        0.150073                    0.968912           1.99968    2.00406            0.987055         0.971835   0.989213                    0.977421            0.100033        0.300754                   99.9685   100.406
    8        0.200097                    0.961881           1.9669     1.99477            0.970874         0.96566    0.984628                    0.97448             0.0983929       0.399147                   96.6903   99.4768
    9        0.299984                    0.941048           1.94711    1.9789             0.961102         0.953261   0.976794                    0.967415            0.19449         0.593637                   94.7106   97.8898
    10       0.400032                    0.866303           1.80955    1.93654            0.893204         0.912841   0.955888                    0.953766            0.181043        0.77468                    80.9551   93.6544
    11       0.500081                    0.526838           1.31783    1.81276            0.650485         0.733827   0.894788                    0.909764            0.131847        0.906527                   31.7825   81.276
    12       0.599968                    0.144171           0.627146   1.61537            0.309562         0.311824   0.797356                    0.810215            0.0626435       0.96917                    -37.2854  61.5371
    13       0.700016                    0.0455371          0.163909   1.40792            0.0809061        0.0814907  0.694958                    0.706063            0.0163988       0.985569                   -83.6091  40.7923
    14       0.799903                    0.0251201          0.0820871  1.24236            0.0405186        0.0337433  0.613236                    0.622108            0.00819941      0.993768                   -91.7913  24.2361
    15       0.899951                    0.016845           0.0327817  1.10789            0.0161812        0.0203711  0.546861                    0.555212            0.00327976      0.997048                   -96.7218  10.7891
    16       1                           0.00682127         0.0295035  1                  0.0145631        0.0134712  0.493605                    0.501012            0.00295179      1                          -97.0496  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:55:38  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:55:43  1:49:00.835  4850 obs/sec      1         1             25000      0.29586          0.288839            0.64986        0.949158        0.931027           1.99166          0.117893                         0.293063           0.285192              0.656401         0.950865          0.937199             2.02591            0.117695
    2019-08-03 17:55:49  1:49:06.316  4887 obs/sec      2         2             50000      0.284882         0.269869            0.675363       0.95632         0.948182           1.99166          0.11141                          0.281108           0.264874              0.683861         0.958196          0.950121             2.02591            0.105877
    2019-08-03 17:55:54  1:49:11.971  4852 obs/sec      3         3             75000      0.283289         0.268468            0.678985       0.956296        0.951949           1.99166          0.11161                          0.279046           0.262415              0.688482         0.958685          0.954791             2.02591            0.102153
    2019-08-03 17:56:00  1:49:17.493  4864 obs/sec      4         4             100000     0.279436         0.261717            0.687656       0.958399        0.934396           1.99166          0.106822                         0.274624           0.254158              0.698277         0.960892          0.940786             2.02591            0.104582
    2019-08-03 17:56:05  1:49:23.173  4838 obs/sec      5         5             125000     0.278932         0.26216             0.688783       0.957736        0.951698           1.99166          0.104129                         0.274537           0.25494               0.698468         0.960067          0.951317             2.02591            0.101667
    2019-08-03 17:56:11  1:49:28.879  4822 obs/sec      6         6             150000     0.277856         0.261392            0.691179       0.957708        0.949842           1.99166          0.10383                          0.273593           0.254286              0.700538         0.960279          0.953075             2.02591            0.0987534
    2019-08-03 17:56:17  1:49:34.352  4841 obs/sec      7         7             175000     0.277297         0.260808            0.69242        0.957934        0.952592           1.99166          0.103631                         0.274121           0.255173              0.699381         0.960036          0.950798             2.02591            0.100534
    2019-08-03 17:56:22  1:49:39.893  4847 obs/sec      8         8             200000     0.277143         0.261657            0.692763       0.957312        0.944975           1.97194          0.10403                          0.273708           0.25569               0.700288         0.959272          0.949781             1.99323            0.101506
    2019-08-03 17:56:28  1:49:46.719  4772 obs/sec      9         9             225000     0.276237         0.258426            0.694768       0.959135        0.949331           1.95222          0.103132                         0.272552           0.252247              0.702812         0.961215          0.955654             2.02591            0.097944
    2019-08-03 17:56:34  1:49:52.173  4792 obs/sec      10        10            250000     0.27743          0.261853            0.692126       0.957352        0.94633            1.95222          0.102932                         0.273152           0.254282              0.701503         0.960038          0.951101             2.02591            0.101991
    2019-08-03 17:56:35  1:49:52.610  4791 obs/sec      10        10            250000     0.276237         0.258426            0.694768       0.959135        0.949331           1.95222          0.103132                         0.272552           0.252247              0.702812         0.961215          0.955654             2.02591            0.097944
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.006499543708025088
C438        0.9340085387229919     0.9340085387229919    0.006070629321098729
C374        0.7819319367408752     0.7819319367408752    0.005082200799548027
C322        0.7131758332252502     0.7131758332252502    0.004635317499554725
C863        0.6966253519058228     0.6966253519058228    0.004527746922830253
---         ---                    ---                   ---
C741        0.06248863413929939    0.06248863413929939   0.0004061476088431651
C708        0.06146056950092316    0.06146056950092316   0.00039946565779136375
C874        0.060126274824142456   0.060126274824142456  0.0003907933512202424
C773        0.05933811515569687    0.05933811515569687   0.0003856706730062777
C916        0.056552596390247345   0.056552596390247345  0.0003675660720407145

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_155

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.002927126828586663    0.0025246450677514076  0.0         0.023537508429034844  0.085765540599823   0.019357577286021672  0.44622159004211426
    3        2        Softmax                      0.0   0.0   0.00024336631986443535  6.095381104387343e-05  0.0         -0.20288454025285318  0.7063262462615967  0.00189387898027717   0.04223033785820007


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07799890366964704
RMSE: 0.27928283812230037
LogLoss: 0.27451242792984104
Mean Per-Class Error: 0.09051054822043625
AUC: 0.9597048411787218
pr_auc: 0.8520306631046328
Gini: 0.9194096823574436
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5078190847887301: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4516  509   0.1013   (509.0/5025.0)
1      398   4594  0.0797   (398.0/4992.0)
Total  4914  5103  0.0905   (907.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.507819     0.910154  203
max f2                       0.41477      0.928549  234
max f0point5                 0.620182     0.912865  163
max accuracy                 0.507819     0.909454  203
max precision                0.999614     0.997503  1
max recall                   6.60027e-05  1         399
max specificity              0.999961     0.999602  0
max absolute_mcc             0.507819     0.81912   203
max min_per_class_accuracy   0.520669     0.904478  198
max mean_per_class_accuracy  0.507819     0.909489  203
Gains/Lift Table: Avg response rate: 49.84 %, avg score: 50.04 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   1                  2.00661    2.00661            1                1            1                           1                   0.0202324       0.0202324                  100.661   100.661
    2        0.0200659                   0.999995           1.98654    1.99663            0.99             0.999998     0.995025                    0.999999            0.0198317       0.0400641                  98.6544   99.6627
    3        0.0300489                   0.999979           2.00661    1.99994            1                0.999988     0.996678                    0.999996            0.0200321       0.0600962                  100.661   99.9944
    4        0.0400319                   0.999943           2.00661    2.00161            1                0.999964     0.997506                    0.999988            0.0200321       0.0801282                  100.661   100.161
    5        0.050015                    0.999871           1.98654    1.9986             0.99             0.99991      0.996008                    0.999972            0.0198317       0.0999599                  98.6544   99.86
    6        0.10003                     0.998121           1.9986     1.9986             0.996008         0.999294     0.996008                    0.999633            0.0999599       0.19992                    99.86     99.86
    7        0.150045                    0.992087           1.94653    1.98124            0.97006          0.995678     0.987359                    0.998315            0.0973558       0.297276                   94.6532   98.1244
    8        0.20006                     0.97571            1.93051    1.96856            0.962076         0.985163     0.981038                    0.995027            0.0965545       0.39383                    93.0512   96.8561
    9        0.29999                     0.887534           1.89636    1.94451            0.945055         0.940209     0.969052                    0.976766            0.189503        0.583333                   89.6357   94.4509
    10       0.40002                     0.717555           1.80034    1.90846            0.897206         0.8067       0.951086                    0.934239            0.180088        0.763421                   80.0342   90.8458
    11       0.501348                    0.520721           1.45899    1.81762            0.727094         0.610793     0.905814                    0.868867            0.147837        0.911258                   45.8994   81.7617
    12       0.59998                     0.299736           0.534148   1.60662            0.266194         0.413542     0.800666                    0.794015            0.0526843       0.963942                   -46.5852  60.6624
    13       0.70001                     0.0972124          0.202263   1.40594            0.100798         0.18889      0.700656                    0.707544            0.0202324       0.984175                   -79.7737  40.5944
    14       0.79994                     0.0136055          0.10424    1.24333            0.0519481        0.0467135    0.619618                    0.624992            0.0104167       0.994591                   -89.576   24.3332
    15       0.89997                     0.000447351        0.0380495  1.10937            0.0189621        0.00448797   0.552856                    0.556024            0.00380609      0.998397                   -96.195   10.9367
    16       1                           3.06582e-19        0.0160208  1                  0.00798403       7.48716e-05  0.498353                    0.500412            0.00160256      1                          -98.3979  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07286450968110396
RMSE: 0.26993426918622976
LogLoss: 0.2530533546890722
Mean Per-Class Error: 0.08604478303649099
AUC: 0.9660590051327047
pr_auc: 0.8421562374276851
Gini: 0.9321180102654094
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5079318919903018: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2828  300   0.0959   (300.0/3128.0)
1      233   2816  0.0764   (233.0/3049.0)
Total  3061  3116  0.0863   (533.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.507932     0.913544  203
max f2                       0.369219     0.934856  250
max f0point5                 0.572924     0.921716  179
max accuracy                 0.518062     0.913874  200
max precision                0.996875     0.997372  5
max recall                   5.15367e-05  1         399
max specificity              0.999927     0.999361  0
max absolute_mcc             0.514213     0.827845  201
max min_per_class_accuracy   0.520698     0.910806  199
max mean_per_class_accuracy  0.514213     0.913955  201
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.81 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   1                  2.02591    2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999995           1.99323    2.00957            0.983871         0.999998     0.991935                    0.999999            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999974           2.02591    2.01502            1                0.999986     0.994624                    0.999995            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.999924           2.02591    2.01774            1                0.999949     0.995968                    0.999983            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.99983            1.9927     2.0128             0.983607         0.999884     0.993528                    0.999964            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.998235           2.02591    2.01935            1                0.999281     0.996764                    0.999622            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.99171            1.99968    2.0128             0.987055         0.995674     0.993528                    0.998306            0.100033        0.302066                   99.9685   101.28
    8        0.200097                    0.977034           1.97346    2.00296            0.97411          0.98504      0.988673                    0.99499             0.0987209       0.400787                   97.3459   100.296
    9        0.299984                    0.887539           1.94054    1.98218            0.957861         0.940593     0.978413                    0.976877            0.193834        0.594621                   94.054    98.2178
    10       0.400032                    0.707599           1.80627    1.93818            0.891586         0.805582     0.956698                    0.934036            0.180715        0.775336                   80.6273   93.8184
    11       0.500081                    0.514589           1.43912    1.83834            0.710356         0.602961     0.907413                    0.8678              0.143982        0.919318                   43.9117   83.8338
    12       0.599968                    0.287592           0.515507   1.6181             0.254457         0.409588     0.798705                    0.791513            0.0514923       0.97081                    -48.4493  61.8104
    13       0.700016                    0.0922663          0.157352   1.40933            0.0776699        0.183807     0.695652                    0.704658            0.0157429       0.986553                   -84.2648  40.9329
    14       0.799903                    0.0129204          0.0919376  1.24482            0.0453809        0.0437477    0.614451                    0.622128            0.00918334      0.995736                   -90.8062  24.4822
    15       0.899951                    0.000493451        0.0295035  1.10971            0.0145631        0.00431755   0.54776                     0.553445            0.00295179      0.998688                   -97.0496  10.9713
    16       1                           1.7e-20            0.0131127  1                  0.00647249       7.38701e-05  0.493605                    0.498081            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:05:16  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:05:17  2:58:34.409  26427 obs/sec     1         1             25000      0.318103         0.383649            0.595238       0.932783        0.732242           1.98674          0.136368                         0.310874           0.355385              0.613366         0.938936          0.786896             1.99323            0.129351
    2019-08-03 19:05:22  2:58:39.893  28487 obs/sec     7         7             175000     0.283308         0.283943            0.678943       0.956758        0.818465           2.00661          0.0973345                        0.272633           0.260221              0.702637         0.963846          0.835825             2.02591            0.086126
    2019-08-03 19:05:25  2:58:42.987  28261 obs/sec     10        10            250000     0.279283         0.274512            0.688001       0.959705        0.852031           2.00661          0.0905461                        0.269934           0.253053              0.708494         0.966059          0.842156             2.02591            0.0862878
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.004478640183564989
C88         0.7944463491439819     0.7944463491439819   0.0035580393429627383
C28         0.7834722995758057     0.7834722995758057   0.0035088905235902703
C36         0.7776747941970825     0.7776747941970825   0.0034829255830366866
C438        0.7127543091773987     0.7127543091773987   0.0031921700900910017
---         ---                    ---                  ---
C482        0.11220516264438629    0.11220516264438629  0.0005025265502225936
C510        0.1102500632405281     0.1102500632405281   0.0004937703634696105
C459        0.1049506738781929     0.1049506738781929   0.0004700363053230991
C423        0.09966655820608139    0.09966655820608139  0.000446370652539375
C721        0.08725685626268387    0.08725685626268387  0.00039079206274961035

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_14

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.003991129076073739    0.0062714871019124985  0.0         0.022171794693412607  0.09253162145614624  0.16905016030137543     0.27073609828948975
    3        2        Softmax                      0.0   0.0   0.00031746800004839315  6.718013901263475e-05  0.0         0.07051539499661885   0.8179202079772949   -0.0018152990654745488  0.23851346969604492


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0763869512221291
RMSE: 0.2763818938029934
LogLoss: 0.2653001793613037
Mean Per-Class Error: 0.09143238250937946
AUC: 0.9616258324170694
pr_auc: 0.8745438144956039
Gini: 0.9232516648341389
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5633845294725677: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4527  432   0.0871   (432.0/4959.0)
1      487   4587  0.096    (487.0/5074.0)
Total  5014  5019  0.0916   (919.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.563385     0.908947  189
max f2                       0.334757     0.931945  263
max f0point5                 0.618673     0.919829  169
max accuracy                 0.566363     0.908502  188
max precision                0.999252     0.994437  1
max recall                   5.74718e-05  1         399
max specificity              0.99993      0.999395  0
max absolute_mcc             0.566363     0.817083  188
max min_per_class_accuracy   0.553258     0.907038  193
max mean_per_class_accuracy  0.566363     0.908568  188
Gains/Lift Table: Avg response rate: 50.57 %, avg score: 50.29 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   0.999997           1.97734    1.97734            1                0.999999    1                           0.999999            0.0199054       0.0199054                  97.7335   97.7335
    2        0.0200339                   0.999977           1.97734    1.97734            1                0.999987    1                           0.999993            0.0197083       0.0396137                  97.7335   97.7335
    3        0.030001                    0.999919           1.95756    1.97077            0.99             0.999952    0.996678                    0.99998             0.0195112       0.059125                   95.7562   97.0766
    4        0.0400678                   0.999781           1.93818    1.96258            0.980198         0.999861    0.992537                    0.99995             0.0195112       0.0786362                  93.818    96.2579
    5        0.0500349                   0.999505           1.97734    1.96552            1                0.99966     0.994024                    0.999892            0.0197083       0.0983445                  97.7335   96.5519
    6        0.10007                     0.996165           1.94976    1.95764            0.986056         0.998226    0.99004                     0.999059            0.0975562       0.195901                   94.9763   95.7641
    7        0.150005                    0.986003           1.93392    1.94974            0.978044         0.991966    0.986047                    0.996698            0.0965708       0.292471                   93.3921   94.9745
    8        0.20004                     0.964268           1.91825    1.94187            0.97012          0.976392    0.982063                    0.991619            0.0959795       0.388451                   91.8252   94.1868
    9        0.30001                     0.873432           1.87876    1.92084            0.95015          0.924516    0.971429                    0.969259            0.18782         0.576271                   87.8764   92.084
    10       0.39998                     0.721696           1.79596    1.88963            0.908275         0.80444     0.955644                    0.928064            0.179543        0.755814                   79.5965   88.9629
    11       0.50005                     0.56281            1.47709    1.80707            0.747012         0.642386    0.913893                    0.870895            0.147812        0.903626                   47.7093   80.7073
    12       0.60002                     0.306458           0.624941   1.61012            0.316052         0.438667    0.814286                    0.798881            0.0624754       0.966102                   -37.5059  61.0116
    13       0.69999                     0.0915043          0.210942   1.41029            0.10668          0.18888     0.713228                    0.711762            0.0210879       0.98719                    -78.9058  41.0291
    14       0.79996                     0.0122289          0.0847711  1.24464            0.0428714        0.042407    0.629454                    0.628114            0.00847458      0.995664                   -91.5229  24.4642
    15       0.89993                     0.000382143        0.0315427  1.10988            0.0159521        0.00403417  0.561302                    0.558787            0.00315333      0.998818                   -96.8457  10.9883
    16       1                           8.15392e-20        0.0118167  1                  0.0059761        6.9041e-05  0.505731                    0.502876            0.0011825       1                          -98.8183  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07289878817864805
RMSE: 0.2699977558770592
LogLoss: 0.25345201419648145
Mean Per-Class Error: 0.0846699664222641
AUC: 0.9660961226648459
pr_auc: 0.8582669058178695
Gini: 0.9321922453296918
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5579122089917543: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2866  262   0.0838   (262.0/3128.0)
1      263   2786  0.0863   (263.0/3049.0)
Total  3129  3048  0.085    (525.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.557912     0.913892  193
max f2                       0.367686     0.933741  257
max f0point5                 0.618698     0.925319  168
max accuracy                 0.577137     0.915493  185
max precision                0.995142     0.997072  6
max recall                   8.67289e-05  1         399
max specificity              0.999853     0.999361  0
max absolute_mcc             0.577137     0.831134  185
max min_per_class_accuracy   0.555978     0.914398  194
max mean_per_class_accuracy  0.577137     0.91533   185
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.55 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999995           2.02591     2.02591            1                0.999999     1                           0.999999            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999972           1.99323     2.00957            0.983871         0.999986     0.991935                    0.999993            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999905           1.99323     2.00413            0.983871         0.999941     0.989247                    0.999975            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.999737           2.02591     2.00957            1                0.999837     0.991935                    0.999941            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999502           2.02591     2.0128             1                0.999633     0.993528                    0.99988             0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.996157           2.02591     2.01935            1                0.998247     0.996764                    0.999064            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.985988           1.99313     2.01061            0.983819         0.991949     0.992449                    0.996692            0.0997048       0.301738                   99.3128   101.061
    8        0.200097                    0.964354           1.94723     1.99477            0.961165         0.976092     0.984628                    0.991542            0.097409        0.399147                   94.7234   99.4768
    9        0.299984                    0.872352           1.95367     1.98108            0.964344         0.924968     0.977874                    0.969375            0.195146        0.594293                   95.3673   98.1084
    10       0.400032                    0.706367           1.81611     1.93982            0.89644          0.791039     0.957507                    0.924773            0.181699        0.775992                   81.6107   93.9823
    11       0.500081                    0.540436           1.426       1.83703            0.703883         0.625337     0.906766                    0.864866            0.14267         0.918662                   42.6005   83.7026
    12       0.599968                    0.28288            0.49909     1.61428            0.246353         0.415678     0.796816                    0.790082            0.0498524       0.968514                   -50.091   61.4278
    13       0.700016                    0.0806488          0.183578    1.4098             0.0906149        0.174265     0.695883                    0.702068            0.0183667       0.986881                   -81.6422  40.9797
    14       0.799903                    0.0104032          0.0788036   1.24359            0.0388979        0.0368267    0.613843                    0.618997            0.00787143      0.994752                   -92.1196  24.3591
    15       0.899951                    0.000393508        0.0458944   1.11044            0.0226537        0.00345541   0.54812                     0.550566            0.00459167      0.999344                   -95.4106  11.0442
    16       1                           5.31759e-19        0.00655634  1                  0.00323625       7.25235e-05  0.493605                    0.49549             0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:24:45  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:24:46  18 min  3.582 sec  27262 obs/sec     1         1             25000      0.308346         0.32646             0.61964        0.939593        0.850553           1.97734          0.129174                         0.300066           0.3076                0.639782         0.94573           0.852654             2.02591            0.121256
    2019-08-03 16:24:52  18 min  9.222 sec  27786 obs/sec     7         7             175000     0.279189         0.268719            0.688174       0.960295        0.878198           1.97734          0.0971793                        0.273756           0.258762              0.700182         0.963797          0.896593             2.02591            0.0908208
    2019-08-03 16:24:55  18 min 12.232 sec  27759 obs/sec     10        10            250000     0.276382         0.2653              0.694412       0.961626        0.874544           1.97734          0.0915977                        0.269998           0.253452              0.708357         0.966096          0.858267             2.02591            0.0849927
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.005662012201829004
C438        0.8161249756813049     0.8161249756813049   0.004620909570524948
C88         0.6601954102516174     0.6601954102516174   0.003738034468436163
C28         0.6237170696258545     0.6237170696258545   0.0035314936587106187
C374        0.5970642566680908     0.5970642566680908   0.0033805851065306946
---         ---                    ---                  ---
C323        0.08559516817331314    0.08559516817331314  0.00048464088661490464
C344        0.08542000502347946    0.08542000502347946  0.00048364911072323554
C489        0.08019573241472244    0.08019573241472244  0.0004540692154667722
C311        0.07925812155008316    0.07925812155008316  0.00044876045131061717
C745        0.07705565541982651    0.07705565541982651  0.0004362900612069889

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_116

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  --------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0034362200243943947   0.0023159366101026535  0.0         0.022974861058395638   0.08755850791931152  0.06747220859587705     0.34574079513549805
    3        2        Softmax                      0.0   0.0   0.00030856017428959603  4.753163375426084e-05  0.0         -0.057594151818193495  0.6203427314758301   -0.0012063484470179048  0.023403361439704895


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0771656505711837
RMSE: 0.2777870597619401
LogLoss: 0.26327057019711086
Mean Per-Class Error: 0.08939452397583314
AUC: 0.9621324890464059
pr_auc: 0.8474691231160701
Gini: 0.9242649780928118
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49910651939920564: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4548  486   0.0965   (486.0/5034.0)
1      411   4575  0.0824   (411.0/4986.0)
Total  4959  5061  0.0895   (897.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.499107     0.91072   201
max f2                       0.370565     0.930723  246
max f0point5                 0.58943      0.915979  168
max accuracy                 0.501964     0.910579  200
max precision                0.999904     0.994662  0
max recall                   4.99574e-05  1         399
max specificity              0.999904     0.999404  0
max absolute_mcc             0.501964     0.821223  200
max min_per_class_accuracy   0.511304     0.909019  196
max mean_per_class_accuracy  0.501964     0.910605  200
Gains/Lift Table: Avg response rate: 49.76 %, avg score: 49.25 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100798                   0.999999           2.00963     2.00963            1                1           1                           1                   0.0202567       0.0202567                  100.963   100.963
    2        0.0200599                   0.999989           1.98953     1.99963            0.99             0.999995    0.995025                    0.999998            0.0198556       0.0401123                  98.9531   99.9629
    3        0.0300399                   0.999958           2.00963     2.00295            1                0.999977    0.996678                    0.999991            0.0200562       0.0601685                  100.963   100.295
    4        0.04002                     0.999861           1.98953     1.9996             0.99             0.999912    0.995012                    0.999971            0.0198556       0.0800241                  98.9531   99.9604
    5        0.05                        0.99975            1.98953     1.99759            0.99             0.999809    0.994012                    0.999939            0.0198556       0.0998797                  98.9531   99.7593
    6        0.1                         0.996875           1.98957     1.99358            0.99002          0.998698    0.992016                    0.999318            0.0994785       0.199358                   98.9571   99.3582
    7        0.15                        0.986771           1.97353     1.9869             0.982036         0.992632    0.988689                    0.99709             0.0986763       0.298034                   97.3526   98.6897
    8        0.2                         0.966766           1.95748     1.97954            0.974052         0.977876    0.98503                     0.992286            0.097874        0.395909                   95.7481   97.9543
    9        0.3                         0.873367           1.88528     1.94812            0.938124         0.925643    0.969395                    0.970072            0.188528        0.584436                   88.5279   94.8121
    10       0.4                         0.689766           1.785       1.90734            0.888224         0.785118    0.949102                    0.923833            0.1785          0.762936                   78.4998   90.7341
    11       0.5                         0.508168           1.48616     1.8231             0.739521         0.59171     0.907186                    0.857409            0.148616        0.911552                   48.6161   82.3105
    12       0.6                         0.287943           0.551544    1.61118            0.274451         0.401774    0.80173                     0.78147             0.0551544       0.966707                   -44.8456  61.1178
    13       0.7                         0.0977849          0.214601    1.41167            0.106786         0.186029    0.702452                    0.696407            0.0214601       0.988167                   -78.5399  41.1667
    14       0.8                         0.0133693          0.0882471   1.24624            0.0439122        0.0450513   0.620135                    0.614987            0.00882471      0.996992                   -91.1753  24.6239
    15       0.9                         0.00057915         0.0240674   1.11044            0.011976         0.00480081  0.552562                    0.547189            0.00240674      0.999398                   -97.5933  11.0443
    16       1                           5.04086e-18        0.00601685  1                  0.00299401       0.00010928  0.497605                    0.492481            0.000601685     1                          -99.3983  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07347138109156579
RMSE: 0.27105604787859977
LogLoss: 0.25349274861207416
Mean Per-Class Error: 0.08296795981073002
AUC: 0.966377177876441
pr_auc: 0.8541711145850284
Gini: 0.9327543557528819
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5067849438419634: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2852  276   0.0882   (276.0/3128.0)
1      241   2808  0.079    (241.0/3049.0)
Total  3093  3084  0.0837   (517.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.506785     0.915702  203
max f2                       0.399872     0.934436  241
max f0point5                 0.529645     0.92085   194
max accuracy                 0.513923     0.917112  200
max precision                0.995897     0.995798  5
max recall                   0.000516977  1         398
max specificity              0.999896     0.999361  0
max absolute_mcc             0.513923     0.834219  200
max min_per_class_accuracy   0.511443     0.915281  201
max mean_per_class_accuracy  0.513923     0.917032  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.30 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999987           1.99323     2.00957            0.983871         0.999995     0.991935                    0.999997            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999945           1.99323     2.00413            0.983871         0.99997      0.989247                    0.999988            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.999858           2.02591     2.00957            1                0.999906     0.991935                    0.999967            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999701           2.02591     2.0128             1                0.99978      0.993528                    0.999931            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.996854           2.01935     2.01608            0.996764         0.998665     0.995146                    0.999298            0.101017        0.201705                   101.935   101.608
    7        0.150073                    0.987894           2.00624     2.0128             0.990291         0.993279     0.993528                    0.997292            0.100361        0.302066                   100.624   101.28
    8        0.200097                    0.968923           1.98657     2.00624            0.980583         0.979231     0.990291                    0.992776            0.0993768       0.401443                   98.6572   100.624
    9        0.299984                    0.872131           1.93397     1.98218            0.954619         0.927657     0.978413                    0.971093            0.193178        0.594621                   93.3973   98.2178
    10       0.400032                    0.687138           1.80627     1.93818            0.891586         0.785102     0.956698                    0.924577            0.180715        0.775336                   80.6273   93.8184
    11       0.500081                    0.50302            1.45879     1.84227            0.720065         0.588471     0.909356                    0.857334            0.145949        0.921286                   45.8786   84.2273
    12       0.599968                    0.296461           0.485956    1.61646            0.23987          0.401444     0.797895                    0.781434            0.0485405       0.969826                   -51.4044  61.6464
    13       0.700016                    0.0986901          0.163909    1.40886            0.0809061        0.190002     0.695421                    0.696905            0.0163988       0.986225                   -83.6091  40.886
    14       0.799903                    0.0147195          0.0952211   1.24482            0.0470016        0.0464286    0.614451                    0.615678            0.00951132      0.995736                   -90.4779  24.4822
    15       0.899951                    0.000811701        0.0360599   1.11044            0.0177994        0.00549991   0.54812                     0.547843            0.00360774      0.999344                   -96.394   11.0442
    16       1                           5.04086e-18        0.00655634  1                  0.00323625       0.000153113  0.493605                    0.493048            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:19:05  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:19:06  2:12:23.556  25826 obs/sec     1         1             25000      0.320798         0.370402            0.588344       0.932151        0.76195            2.00963          0.13523                          0.309872           0.34333               0.615855         0.939579          0.76764              1.99323            0.125627
    2019-08-03 18:19:12  2:12:29.335  27288 obs/sec     7         7             175000     0.280503         0.268708            0.685265       0.959499        0.836              2.00963          0.0947106                        0.272048           0.256619              0.70391          0.964489          0.841513             2.02591            0.0874211
    2019-08-03 18:19:15  2:12:32.180  27821 obs/sec     10        10            250000     0.277787         0.263271            0.69133        0.962132        0.847469           2.00963          0.089521                         0.271056           0.253493              0.706066         0.966377          0.854171             2.02591            0.0836976
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.004911698755798975
C438        0.7518259882926941     0.7518259882926941   0.0036927427712745604
C88         0.7258965969085693     0.7258965969085693   0.00356538541187453
C35         0.6849176287651062     0.6849176287651062   0.0033641090650303566
C79         0.6817563772201538     0.6817563772201538   0.003348581949750246
---         ---                    ---                  ---
C459        0.0973869040608406     0.0973869040608406   0.00047833513550674496
C721        0.09599632024765015    0.09599632024765015  0.0004715050067216632
C178        0.09597152471542358    0.09597152471542358  0.0004713832185368766
C748        0.09448691457509995    0.09448691457509995  0.0004640912607578025
C649        0.08788878470659256    0.08788878470659256  0.00043168323449205466

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_238

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  ------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.003865244169934826   0.00698620080947876    0.0         0.023411762361547097  0.09326052665710449  0.08670313352790407    0.3319054841995239
    3        2        Softmax                      0.0   0.0   0.0003300653008864174  6.723776459693909e-05  0.0         0.14460255207450246   0.6026523113250732   0.0009747548421054561  0.0812695324420929


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07676349244491673
RMSE: 0.2770622537353595
LogLoss: 0.2668188221965963
Mean Per-Class Error: 0.0915742474434682
AUC: 0.9615167511629122
pr_auc: 0.8642341554165417
Gini: 0.9230335023258245
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5248645373713436: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4568  467   0.0928   (467.0/5035.0)
1      450   4528  0.0904   (450.0/4978.0)
Total  5018  4995  0.0916   (917.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.524865     0.908052  197
max f2                       0.344184     0.928919  257
max f0point5                 0.585715     0.91796   173
max accuracy                 0.524865     0.908419  197
max precision                0.999563     0.993976  1
max recall                   2.88885e-05  1         399
max specificity              0.999943     0.999206  0
max absolute_mcc             0.524865     0.81684   197
max min_per_class_accuracy   0.524865     0.907249  197
max mean_per_class_accuracy  0.524865     0.908426  197
Gains/Lift Table: Avg response rate: 49.72 %, avg score: 49.39 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   0.999999           2.01145    2.01145            1                1            1                           1                   0.0202893       0.0202893                  101.145   101.145
    2        0.0200739                   0.999988           1.99134    2.00144            0.99             0.999995     0.995025                    0.999997            0.0198875       0.0401768                  99.1336   100.144
    3        0.0300609                   0.999953           1.97122    1.9914             0.98             0.999972     0.990033                    0.999989            0.0196866       0.0598634                  97.1221   99.1403
    4        0.0400479                   0.999861           2.01145    1.9964             1                0.99991      0.992519                    0.999969            0.0200884       0.0799518                  101.145   99.6402
    5        0.050035                    0.999726           2.01145    1.99941            1                0.999803     0.994012                    0.999936            0.0200884       0.10004                    101.145   99.9406
    6        0.10007                     0.997323           1.99539    1.9974             0.992016         0.998807     0.993014                    0.999372            0.0998393       0.199879                   99.5391   99.7398
    7        0.150005                    0.989485           1.97927    1.99136            0.984            0.993953     0.990013                    0.997568            0.0988349       0.298714                   97.9267   99.1363
    8        0.20004                     0.970108           1.94721    1.98032            0.968064         0.981237     0.984523                    0.993483            0.0974287       0.396143                   94.7212   98.032
    9        0.30001                     0.875042           1.91098    1.95721            0.95005          0.929262     0.973036                    0.972083            0.191041        0.587184                   91.0978   95.7214
    10       0.39998                     0.705277           1.7884     1.91502            0.889111         0.794651     0.95206                     0.927736            0.178787        0.76597                    78.8402   91.5021
    11       0.50005                     0.521854           1.44535    1.82103            0.718563         0.605181     0.905333                    0.863187            0.144636        0.910607                   44.5354   82.1031
    12       0.60002                     0.277584           0.556615   1.61037            0.276723         0.405697     0.800599                    0.786964            0.0556448       0.966252                   -44.3385  61.0366
    13       0.69999                     0.0824241          0.196925   1.4085             0.0979021        0.174777     0.700243                    0.699534            0.0196866       0.985938                   -80.3075  40.8503
    14       0.79996                     0.0113642          0.0904248  1.24378            0.044955         0.0385472    0.618352                    0.616931            0.00903978      0.994978                   -90.9575  24.3784
    15       0.89993                     0.000453806        0.0401888  1.11008            0.01998          0.00380266   0.551881                    0.548821            0.00401768      0.998996                   -95.9811  11.0081
    16       1                           3.39779e-20        0.0100372  1                  0.00499002       8.30067e-05  0.497154                    0.493909            0.00100442      1                          -98.9963  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07299493221698217
RMSE: 0.2701757432061253
LogLoss: 0.2535899005436161
Mean Per-Class Error: 0.08420531573389112
AUC: 0.965752837918432
pr_auc: 0.8411940344881764
Gini: 0.931505675836864
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5147487720707556: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2844  284   0.0908   (284.0/3128.0)
1      240   2809  0.0787   (240.0/3049.0)
Total  3084  3093  0.0848   (524.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.514749     0.914686  202
max f2                       0.370553     0.933593  250
max f0point5                 0.575921     0.922794  177
max accuracy                 0.528014     0.915817  197
max precision                0.99556      0.997264  6
max recall                   9.2117e-05   1         399
max specificity              0.999857     0.999361  0
max absolute_mcc             0.528014     0.831604  197
max min_per_class_accuracy   0.525695     0.914642  198
max mean_per_class_accuracy  0.528014     0.915795  197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.01 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999987           2.02591     2.02591            1                0.999994     1                           0.999997            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999942           1.96056     2.00413            0.967742         0.999969     0.989247                    0.999988            0.0196786       0.0603477                  96.0558   100.413
    4        0.0401489                   0.999852           2.02591     2.00957            1                0.999902     0.991935                    0.999966            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999699           2.02591     2.0128             1                0.999787     0.993528                    0.999931            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.997098           2.02591     2.01935            1                0.998723     0.996764                    0.999327            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.988364           2.0128      2.01717            0.993528         0.993641     0.995685                    0.997432            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.96986            1.98002     2.00788            0.977346         0.980063     0.9911                      0.99309             0.0990489       0.401771                   98.0016   100.788
    9        0.299984                    0.871713           1.93397     1.98327            0.954619         0.927713     0.978953                    0.971321            0.193178        0.594949                   93.3973   98.3271
    10       0.400032                    0.693811           1.80627     1.939              0.891586         0.788524     0.957102                    0.925603            0.180715        0.775664                   80.6273   93.9003
    11       0.500081                    0.514356           1.44567     1.84031            0.713592         0.596238     0.908385                    0.859709            0.144638        0.920302                   44.5674   84.0306
    12       0.599968                    0.269436           0.495806    1.61646            0.244733         0.395725     0.797895                    0.782462            0.0495244       0.969826                   -50.4194  61.6464
    13       0.700016                    0.0802627          0.163909    1.40886            0.0809061        0.166062     0.695421                    0.694364            0.0163988       0.986225                   -83.6091  40.886
    14       0.799903                    0.0113477          0.0886541   1.244              0.0437601        0.0365859    0.614046                    0.612225            0.00885536      0.99508                    -91.1346  24.4001
    15       0.899951                    0.00045319         0.0426162   1.11044            0.0210356        0.00373728   0.54812                     0.544579            0.00426369      0.999344                   -95.7384  11.0442
    16       1                           7.31526e-19        0.00655634  1                  0.00323625       7.66529e-05  0.493605                    0.490102            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:58:15  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:58:16  4:51:34.207  26068 obs/sec     1         1             25000      0.318708         0.360238            0.593687       0.933996        0.737444           1.99154          0.13872                          0.307969           0.335951              0.620557         0.940584          0.746455             2.02591            0.128703
    2019-08-03 20:58:22  4:51:39.280  26338 obs/sec     6         6             150000     0.283566         0.275419            0.678351       0.957935        0.847338           2.01145          0.0989713                        0.275671           0.262059              0.695972         0.962672          0.846181             2.02591            0.0908208
    2019-08-03 20:58:26  4:51:43.323  26621 obs/sec     10        10            250000     0.277062         0.266819            0.692936       0.961517        0.864234           2.01145          0.0915809                        0.270176           0.25359               0.707973         0.965753          0.841194             2.02591            0.0848308
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.0049468436557906625
C88         0.7850328683853149     0.7850328683853149   0.0038834348645590414
C438        0.7446703314781189     0.7446703314781189   0.0036837677049280622
C374        0.6939361095428467     0.6939361095428467   0.0034327934410160856
C55         0.6556972861289978     0.6556972861289978   0.0032436319600063876
---         ---                    ---                  ---
C429        0.10270240902900696    0.10270240902900696  0.0005080527605395607
C274        0.09805740416049957    0.09805740416049957  0.00048507464767466824
C588        0.09688935428857803    0.09688935428857803  0.00047929648757610605
C320        0.09239945560693741    0.09239945560693741  0.0004570856607676893
C366        0.09145062416791916    0.09145062416791916  0.0004523919399831671

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_99

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.022733161522109538   0.04431438446044922    0.0         0.0011202250458667345  0.19674330949783325  -0.006905888371534637  0.16976773738861084
    3        2        Softmax                 0.0   0.0   0.0021636194596794667  0.0007048416882753372  0.0         -0.19524860510136932   0.7303488254547119   0.007332573706815913   0.09552067518234253


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0815750997795552
RMSE: 0.28561354971281594
LogLoss: 0.27533846710472865
Mean Per-Class Error: 0.10848229389311459
AUC: 0.9547225174235097
pr_auc: 0.8231785306273255
Gini: 0.9094450348470193
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45660607297000005: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4384  661   0.131    (661.0/5045.0)
1      428   4552  0.0859   (428.0/4980.0)
Total  4812  5213  0.1086   (1089.0/10025.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.456606     0.893162  220
max f2                       0.147381     0.925335  320
max f0point5                 0.805871     0.902753  104
max accuracy                 0.510319     0.891372  204
max precision                0.962428     0.986355  4
max recall                   0.024464     1         399
max specificity              0.964904     0.998216  0
max absolute_mcc             0.456606     0.783646  220
max min_per_class_accuracy   0.572059     0.890562  185
max mean_per_class_accuracy  0.456606     0.891518  220
Gains/Lift Table: Avg response rate: 49.68 %, avg score: 50.08 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100748                   0.964909           2.01305    2.01305            1                0.965004   1                           0.965004            0.0202811       0.0202811                  101.305   101.305
    2        0.0200499                   0.964909           1.99292    2.00304            0.99             0.964909   0.995025                    0.964957            0.0198795       0.0401606                  99.2922   100.304
    3        0.0300249                   0.964908           1.99292    1.99968            0.99             0.964909   0.993355                    0.964941            0.0198795       0.0600402                  99.2922   99.9676
    4        0.04                        0.964905           1.95266    1.98795            0.97             0.964907   0.987531                    0.964932            0.0194779       0.0795181                  95.2661   98.7952
    5        0.0500748                   0.964884           1.95326    1.98097            0.970297         0.964898   0.984064                    0.964925            0.0196787       0.0991968                  95.3259   98.0972
    6        0.10005                     0.962405           1.98894    1.98495            0.988024         0.964134   0.986042                    0.96453             0.0993976       0.198594                   98.8944   98.4954
    7        0.150025                    0.955654           1.97689    1.98227            0.982036         0.9583     0.984707                    0.962455            0.0987952       0.29739                    97.689    98.2268
    8        0.2                         0.946067           1.95278    1.9749             0.97006          0.95014    0.981047                    0.959378            0.0975904       0.39498                    95.2781   97.49
    9        0.30005                     0.926998           1.90467    1.95148            0.946162         0.938434   0.969415                    0.952394            0.190562        0.585542                   90.4673   95.1483
    10       0.4                         0.850549           1.74183    1.8991             0.865269         0.897439   0.943392                    0.938662            0.174096        0.759639                   74.1833   89.9096
    11       0.50005                     0.556761           1.33066    1.78536            0.661017         0.733235   0.886894                    0.89756             0.133133        0.892771                   33.0662   78.5364
    12       0.6                         0.158702           0.705171   1.60542            0.350299         0.327512   0.797506                    0.8026              0.0704819       0.963253                   -29.4829  60.5422
    13       0.69995                     0.0575395          0.22903    1.40888            0.113772         0.0929276  0.699872                    0.701261            0.0228916       0.986145                   -77.097   40.8878
    14       0.8                         0.0374423          0.0742602  1.24197            0.0368893        0.0445211  0.616958                    0.619128            0.00742972      0.993574                   -92.574   24.1968
    15       0.89995                     0.0248116          0.0482168  1.10939            0.0239521        0.0302835  0.551097                    0.55373             0.00481928      0.998394                   -95.1783  10.9388
    16       1                           0.0238233          0.0160562  1                  0.00797607       0.0244633  0.496758                    0.500777            0.00160643      1                          -98.3944  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07413502009145613
RMSE: 0.2722774689383169
LogLoss: 0.2544667579508532
Mean Per-Class Error: 0.09716531100297865
AUC: 0.9613430863668353
pr_auc: 0.9580396761930242
Gini: 0.9226861727336706
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5041722670771543: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2792  336   0.1074   (336.0/3128.0)
1      265   2784  0.0869   (265.0/3049.0)
Total  3057  3120  0.0973   (601.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.504172     0.902577  200
max f2                       0.170547     0.930167  307
max f0point5                 0.829131     0.913119  93
max accuracy                 0.50854      0.902704  199
max precision                0.966644     1         0
max recall                   0.0244625    1         399
max specificity              0.966644     1         0
max absolute_mcc             0.504172     0.805645  200
max min_per_class_accuracy   0.567715     0.902174  184
max mean_per_class_accuracy  0.504172     0.902835  200
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.80 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.964909           2.02591     2.02591            1                0.964974   1                           0.964974            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.964909           2.02591     2.02591            1                0.964909   1                           0.964942            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.964909           2.02591     2.02591            1                0.964909   1                           0.964931            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.964905           2.02591     2.02591            1                0.964907   1                           0.964925            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.96489            1.95949     2.0128             0.967213         0.9649     0.993528                    0.96492             0.0193506       0.100689                   95.9487   101.28
    6        0.100049                    0.962663           2.00624     2.00952            0.990291         0.964272   0.991909                    0.964596            0.100361        0.20105                    100.624   100.952
    7        0.150073                    0.955831           1.98657     2.00187            0.980583         0.958694   0.988134                    0.962629            0.0993768       0.300426                   98.6572   100.187
    8        0.200097                    0.946388           1.9669      1.99313            0.970874         0.950681   0.983819                    0.959642            0.0983929       0.398819                   96.6903   99.3128
    9        0.299984                    0.925238           1.91756     1.96796            0.946515         0.93813    0.971398                    0.952479            0.191538        0.590357                   91.7555   96.7965
    10       0.400032                    0.856982           1.81283     1.92916            0.894822         0.899629   0.952246                    0.939261            0.181371        0.771728                   81.2829   92.9165
    11       0.500081                    0.540694           1.35716     1.81473            0.669903         0.725273   0.895759                    0.89645             0.135782        0.907511                   35.7163   81.4728
    12       0.599968                    0.14956            0.620579    1.61592            0.306321         0.309414   0.797625                    0.798716            0.0619875       0.969498                   -37.9421  61.5918
    13       0.700016                    0.0574935          0.180299    1.41073            0.0889968        0.0894167  0.696346                    0.697341            0.0180387       0.987537                   -81.9701  41.0734
    14       0.799903                    0.0373034          0.0820871   1.24482            0.0405186        0.0446917  0.614451                    0.615842            0.00819941      0.995736                   -91.7913  24.4822
    15       0.899951                    0.024665           0.0360599   1.11044            0.0177994        0.029757   0.54812                     0.550686            0.00360774      0.999344                   -96.394   11.0442
    16       1                           0.0237423          0.00655634  1                  0.00323625       0.024447   0.493605                    0.498037            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:56:35  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:56:38  1:49:56.161  9035 obs/sec      1         1             25000      0.301267         0.297959            0.636938       0.94595         0.933252           2.01305          0.12389                          0.291729           0.283667              0.659522         0.951436          0.937258             2.02591            0.120285
    2019-08-03 17:56:44  1:50:01.922  9082 obs/sec      3         3             75000      0.290907         0.280822            0.661478       0.952837        0.926905           1.99312          0.119002                         0.277753           0.260539              0.691362         0.959335          0.932479             2.02591            0.104743
    2019-08-03 17:56:50  1:50:07.669  9096 obs/sec      5         5             125000     0.288934         0.280144            0.666056       0.952984        0.906803           1.97319          0.114015                         0.27547            0.258799              0.696416         0.959988          0.914485             2.02591            0.102963
    2019-08-03 17:56:56  1:50:13.248  9212 obs/sec      7         7             175000     0.287677         0.278584            0.668954       0.953109        0.929906           1.99312          0.112219                         0.273525           0.256321              0.700687         0.959661          0.93818              2.02591            0.100049
    2019-08-03 17:57:01  1:50:18.812  9275 obs/sec      9         9             225000     0.285614         0.275338            0.673686       0.954723        0.823179           2.01305          0.108628                         0.272277           0.254467              0.703411         0.961343          0.95804              2.02591            0.0972964
    2019-08-03 17:57:04  1:50:21.695  9315 obs/sec      10        10            250000     0.285952         0.277283            0.672912       0.953897        0.949734           1.99312          0.110823                         0.272695           0.257176              0.702501         0.960098          0.956185             2.02591            0.101344
    2019-08-03 17:57:04  1:50:22.011  9311 obs/sec      10        10            250000     0.285614         0.275338            0.673686       0.954723        0.823179           2.01305          0.108628                         0.272277           0.254467              0.703411         0.961343          0.95804              2.02591            0.0972964
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.00782622258426396
C438        0.9160411953926086     0.9160411953926086    0.0071691422914977885
C374        0.7813339233398438     0.7813339233398438    0.006114893196693851
C88         0.6705030202865601     0.6705030202865601    0.005247505880183872
C322        0.6696732044219971     0.6696732044219971    0.005241011556523849
---         ---                    ---                   ---
C641        0.03940518572926521    0.03940518572926521   0.0003083937544914913
C912        0.03922075778245926    0.03922075778245926   0.00030695038032902913
C892        0.03874850645661354    0.03874850645661354   0.00030325443633724675
C925        0.037557292729616165   0.037557292729616165  0.00029393173256433465
C945        0.03396647796034813    0.03396647796034813   0.0002658292169211806

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_183

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0027330292236985437  0.0017380188219249249  0.0         0.02256708908356432   0.08086273074150085  0.011629694536587966   0.40405571460723877
    3        2        Softmax                      0.0   0.0   0.0002813086373407714  5.662070179823786e-05  0.0         -0.11053723197983345  0.7077474594116211   0.0024630570121161113  0.1026652455329895


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07504083074453502
RMSE: 0.27393581500879916
LogLoss: 0.2637836189439977
Mean Per-Class Error: 0.08859476095464136
AUC: 0.9629383841442615
pr_auc: 0.8542861288090704
Gini: 0.9258767682885229
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5244621000870067: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4569  461   0.0917   (461.0/5030.0)
1      430   4553  0.0863   (430.0/4983.0)
Total  4999  5014  0.089    (891.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.524462     0.910873  198
max f2                       0.314293     0.932394  266
max f0point5                 0.574561     0.919422  180
max accuracy                 0.534308     0.911415  195
max precision                0.999951     0.992481  0
max recall                   3.5165e-05   1         399
max specificity              0.999951     0.999205  0
max absolute_mcc             0.534308     0.822828  195
max min_per_class_accuracy   0.531856     0.910496  196
max mean_per_class_accuracy  0.534308     0.911405  195
Gains/Lift Table: Avg response rate: 49.77 %, avg score: 49.79 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   1                  2.00943     2.00943            1                1            1                           1                   0.0202689       0.0202689                  100.943   100.943
    2        0.0200739                   0.999995           1.98934     1.99943            0.99             0.999998     0.995025                    0.999999            0.0198675       0.0401365                  98.9338   99.9435
    3        0.0300609                   0.999975           1.98934     1.99608            0.99             0.999986     0.993355                    0.999995            0.0198675       0.060004                   98.9338   99.608
    4        0.0400479                   0.999923           2.00943     1.99941            1                0.999953     0.995012                    0.999984            0.0200682       0.0800722                  100.943   99.941
    5        0.050035                    0.999818           1.96924     1.99339            0.98             0.999876     0.992016                    0.999963            0.0196669       0.0997391                  96.9243   99.3389
    6        0.10007                     0.997797           1.97735     1.98537            0.984032         0.999075     0.988024                    0.999519            0.0989364       0.198675                   97.7345   98.5367
    7        0.150005                    0.990883           1.97728     1.98268            0.984            0.994893     0.986684                    0.997979            0.0987357       0.297411                   97.7281   98.2675
    8        0.20004                     0.971246           1.94526     1.97332            0.968064         0.982295     0.982027                    0.994056            0.0973309       0.394742                   94.5259   97.3316
    9        0.30001                     0.883579           1.92311     1.95659            0.957043         0.935336     0.973702                    0.974489            0.192254        0.586996                   92.3113   95.6587
    10       0.39998                     0.711793           1.80668     1.91912            0.899101         0.803015     0.955056                    0.931631            0.180614        0.76761                    80.6682   91.9121
    11       0.50005                     0.524782           1.45192     1.82563            0.722555         0.61179      0.908528                    0.867625            0.145294        0.912904                   45.1925   82.5625
    12       0.60002                     0.286458           0.560071    1.61477            0.278721         0.410345     0.803595                    0.791437            0.0559904       0.968894                   -43.9929  61.477
    13       0.69999                     0.0934779          0.172639    1.40881            0.0859141        0.183708     0.701099                    0.704643            0.0172587       0.986153                   -82.7361  40.881
    14       0.79996                     0.012371           0.0863193   1.24354            0.042957         0.0426194    0.618851                    0.621911            0.00862934      0.994782                   -91.3681  24.354
    15       0.89993                     0.000383352        0.0461708   1.11053            0.022977         0.00388297   0.552658                    0.553256            0.00461569      0.999398                   -95.3829  11.0528
    16       1                           1.3477e-20         0.00601626  1                  0.00299401       6.24264e-05  0.497653                    0.497898            0.000602047     1                          -99.3984  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07314988909038478
RMSE: 0.2704623616889877
LogLoss: 0.25456272806812674
Mean Per-Class Error: 0.08673801061771125
AUC: 0.965762222153253
pr_auc: 0.8513683403481753
Gini: 0.931524444306506
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5164343902579045: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2829  299   0.0956   (299.0/3128.0)
1      239   2810  0.0784   (239.0/3049.0)
Total  3068  3109  0.0871   (538.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.516434     0.912634  202
max f2                       0.33791      0.932402  259
max f0point5                 0.574317     0.922966  179
max accuracy                 0.526873     0.913226  198
max precision                0.995049     0.996212  6
max recall                   4.2122e-05   1         399
max specificity              0.999937     0.999361  0
max absolute_mcc             0.526873     0.826467  198
max min_per_class_accuracy   0.53441      0.911774  195
max mean_per_class_accuracy  0.526873     0.913262  198
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.49 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999999           2.02591     2.02591            1                1            1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999993           1.99323     2.00957            0.983871         0.999997     0.991935                    0.999999            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.999969           1.99323     2.00413            0.983871         0.999983     0.989247                    0.999993            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.999915           2.02591     2.00957            1                0.999944     0.991935                    0.999981            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999815           2.02591     2.0128             1                0.999871     0.993528                    0.999959            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.997831           2.01935     2.01608            0.996764         0.99913      0.995146                    0.999544            0.101017        0.201705                   101.935   101.608
    7        0.150073                    0.990464           2.0128      2.01498            0.993528         0.994638     0.994606                    0.997909            0.100689        0.302394                   101.28    101.498
    8        0.200097                    0.971104           1.94723     1.99805            0.961165         0.981873     0.986246                    0.9939              0.097409        0.399803                   94.7234   99.8046
    9        0.299984                    0.883528           1.95039     1.98218            0.962723         0.933768     0.978413                    0.973878            0.194818        0.594621                   95.039    98.2178
    10       0.400032                    0.703941           1.81611     1.94064            0.89644          0.79674      0.957912                    0.929575            0.181699        0.77632                    81.6107   94.0643
    11       0.500081                    0.521791           1.41289     1.83506            0.697411         0.603675     0.905795                    0.864374            0.141358        0.917678                   41.2892   83.5059
    12       0.599968                    0.284309           0.518791    1.61592            0.256078         0.404467     0.797625                    0.787805            0.0518203       0.969498                   -48.1209  61.5918
    13       0.700016                    0.0886224          0.173743    1.4098             0.0857605        0.179135     0.695883                    0.700812            0.0173827       0.986881                   -82.6257  40.9797
    14       0.799903                    0.0111896          0.0886541   1.24482            0.0437601        0.0400168    0.614451                    0.618296            0.00885536      0.995736                   -91.1346  24.4822
    15       0.899951                    0.000370814        0.0360599   1.11044            0.0177994        0.00351481   0.54812                     0.54995             0.00360774      0.999344                   -96.394   11.0442
    16       1                           1.3477e-20         0.00655634  1                  0.00323625       5.95576e-05  0.493605                    0.494935            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:53:54  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:53:56  3:47:13.324  26455 obs/sec     1         1             25000      0.314748         0.371276            0.603725       0.935809        0.705868           1.98954          0.128833                         0.30762            0.350944              0.621418         0.940497          0.748194             2.02591            0.123037
    2019-08-03 19:54:01  3:47:18.816  28358 obs/sec     7         7             175000     0.276526         0.26909             0.694126       0.961009        0.844018           2.00943          0.0916808                        0.271995           0.258576              0.704025         0.964512          0.83294              2.02591            0.0867735
    2019-08-03 19:54:04  3:47:21.704  28623 obs/sec     10        10            250000     0.273936         0.263784            0.69983        0.962938        0.854286           2.00943          0.0889843                        0.270462           0.254563              0.707353         0.965762          0.851368             2.02591            0.0870973
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.004798334920625405
C438        0.7790107131004333     0.7790107131004333   0.0037379543082111085
C88         0.7214720845222473     0.7214720845222473   0.0034618646974195035
C36         0.6947600245475769     0.6947600245475769   0.0033336912872412023
C28         0.6939208507537842     0.6939208507537842   0.003329664650321973
---         ---                    ---                  ---
C443        0.10524498671293259    0.10524498671293259  0.0005050006949654213
C497        0.10336820781230927    0.10336820781230927  0.0004959952812282674
C813        0.10290408134460449    0.10290408134460449  0.0004937682469906931
C271        0.09467507153749466    0.09467507153749466  0.00045428270187106905
C310        0.0940086618065834     0.0940086618065834   0.000451085044787793

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_234

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.024837583237732195   0.05179798603057861    0.0         0.0037864625664646937  0.21606534719467163  0.04420075074257492    0.18926596641540527
    3        2        Softmax                 0.0   0.0   0.0016911107322812313  0.0002841544337570667  0.0         -0.4202972905768547    0.6363532543182373   -0.001723283546461167  0.0734662115573883


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0820074101266132
RMSE: 0.2863693596155378
LogLoss: 0.27754059436790207
Mean Per-Class Error: 0.10955363570109589
AUC: 0.9543183032500658
pr_auc: 0.9430402396715458
Gini: 0.9086366065001317
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4341210018270122: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4279  705   0.1415   (705.0/4984.0)
1      403   4623  0.0802   (403.0/5026.0)
Total  4682  5328  0.1107   (1108.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.434121     0.892988  225
max f2                       0.159885     0.925175  314
max f0point5                 0.821229     0.906108  94
max accuracy                 0.511267     0.890509  202
max precision                0.962727     1         0
max recall                   0.0284393    1         399
max specificity              0.962727     1         0
max absolute_mcc             0.511267     0.781321  202
max min_per_class_accuracy   0.58695      0.888844  180
max mean_per_class_accuracy  0.511267     0.890446  202
Gains/Lift Table: Avg response rate: 50.21 %, avg score: 50.98 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   0.962123           1.99164    1.99164            1                0.962478   1                           0.962478            0.0200955       0.0200955                  99.1643   99.1643
    2        0.0200799                   0.962112           1.99164    1.99164            1                0.962113   1                           0.962297            0.0198965       0.039992                   99.1643   99.1643
    3        0.0300699                   0.962112           1.99164    1.99164            1                0.962112   1                           0.962235            0.0198965       0.0598886                  99.1643   99.1643
    4        0.0400599                   0.962112           1.99164    1.99164            1                0.962112   1                           0.962204            0.0198965       0.0797851                  99.1643   99.1643
    5        0.05005                     0.962112           1.95181    1.98369            0.98             0.962112   0.996008                    0.962186            0.0194986       0.0992837                  95.1811   98.3693
    6        0.1                         0.961984           1.95978    1.97175            0.984            0.962093   0.99001                     0.96214             0.097891        0.197175                   95.9777   97.1747
    7        0.15005                     0.957402           1.93996    1.96115            0.974052         0.960023   0.984687                    0.961433            0.0970951       0.29427                    93.9964   96.1146
    8        0.2                         0.9554             1.93588    1.95483            0.972            0.956344   0.981518                    0.960162            0.0966972       0.390967                   93.5877   95.4835
    9        0.3                         0.939261           1.90211    1.93726            0.955045         0.94907    0.972694                    0.956465            0.190211        0.581178                   90.2109   93.726
    10       0.4                         0.876542           1.74493    1.88918            0.876124         0.914322   0.948551                    0.945929            0.174493        0.755671                   74.4926   88.9176
    11       0.5                         0.59327            1.31516    1.77437            0.66034          0.762872   0.890909                    0.909318            0.131516        0.887187                   31.5161   77.4373
    12       0.6                         0.164824           0.736172   1.60134            0.36963          0.355024   0.804029                    0.816936            0.0736172       0.960804                   -26.3828  60.134
    13       0.7                         0.0548585          0.226821   1.40498            0.113886         0.0957254  0.705437                    0.713906            0.0226821       0.983486                   -77.3179  40.498
    14       0.8                         0.0335195          0.0935137  1.24105            0.046953         0.0411398  0.623127                    0.62981             0.00935137      0.992837                   -90.6486  24.1047
    15       0.9                         0.0284411          0.0417827  1.1078             0.020979         0.0307159  0.556222                    0.563244            0.00417827      0.997016                   -95.8217  10.7795
    16       1                           0.0276733          0.0298448  1                  0.014985         0.0284264  0.502098                    0.509762            0.00298448      1                          -97.0155  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07419506668384979
RMSE: 0.27238771390033323
LogLoss: 0.25471545963963044
Mean Per-Class Error: 0.09904787238950508
AUC: 0.961528936157006
pr_auc: 0.9448875876059166
Gini: 0.9230578723140119
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.40698005148142474: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2733  395   0.1263   (395.0/3128.0)
1      221   2828  0.0725   (221.0/3049.0)
Total  2954  3223  0.0997   (616.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.40698      0.901786  226
max f2                       0.163631     0.931267  309
max f0point5                 0.835975     0.915655  89
max accuracy                 0.547824     0.900923  185
max precision                0.962647     1         0
max recall                   0.0284443    1         399
max specificity              0.962647     1         0
max absolute_mcc             0.40698      0.801934  226
max min_per_class_accuracy   0.563885     0.900295  181
max mean_per_class_accuracy  0.547824     0.900952  185
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.09 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.962124           2.02591    2.02591            1                0.962509   1                           0.962509            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.962112           2.02591    2.02591            1                0.962114   1                           0.962311            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.962112           2.02591    2.02591            1                0.962112   1                           0.962245            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.962112           1.99323    2.01774            0.983871         0.962112   0.995968                    0.962211            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.962112           2.02591    2.01935            1                0.962112   0.996764                    0.962192            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.962028           1.99968    2.00952            0.987055         0.9621     0.991909                    0.962146            0.100033        0.20105                    99.9685   100.952
    7        0.150073                    0.957614           1.97346    1.9975             0.97411          0.960293   0.985976                    0.961528            0.0987209       0.29977                    97.3459   99.7499
    8        0.200097                    0.955577           1.98657    1.99477            0.980583         0.95642    0.984628                    0.960251            0.0993768       0.399147                   98.6572   99.4768
    9        0.299984                    0.936944           1.94382    1.9778             0.959481         0.948758   0.976255                    0.956424            0.194162        0.593309                   94.3823   97.7804
    10       0.400032                    0.867269           1.81283    1.93654            0.894822         0.911214   0.955888                    0.945117            0.181371        0.77468                    81.2829   93.6544
    11       0.500081                    0.536213           1.30471    1.81014            0.644013         0.740044   0.893493                    0.904089            0.130535        0.905215                   30.4712   81.0137
    12       0.599968                    0.143217           0.65013    1.61701            0.320908         0.305175   0.798165                    0.804378            0.0649393       0.970154                   -34.987   61.7011
    13       0.700016                    0.0529078          0.173743   1.41073            0.0857605        0.0842256  0.696346                    0.701451            0.0173827       0.987537                   -82.6257  41.0734
    14       0.799903                    0.033053           0.0722367  1.24359            0.0356564        0.0398732  0.613843                    0.618838            0.00721548      0.994752                   -92.7763  24.3591
    15       0.899951                    0.0284393          0.0393381  1.10971            0.0194175        0.0302459  0.54776                     0.553403            0.00393572      0.998688                   -96.0662  10.9713
    16       1                           0.027742           0.0131127  1                  0.00647249       0.0284329  0.493605                    0.500881            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:55:13  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:55:16  4:48:33.877  9765 obs/sec      1         1             25000      0.302284         0.301603            0.634492       0.944418        0.928309           1.97192          0.125375                         0.291829           0.282768              0.659288         0.951474          0.938038             2.02591            0.113486
    2019-08-03 20:55:22  4:48:39.682  9258 obs/sec      3         3             75000      0.290053         0.28035             0.66347        0.952738        0.917416           1.99164          0.114186                         0.275809           0.257178              0.695667         0.960352          0.923381             2.02591            0.101991
    2019-08-03 20:55:28  4:48:45.294  9299 obs/sec      5         5             125000     0.287867         0.278251            0.668525       0.954077        0.862835           1.99164          0.112388                         0.274              0.255467              0.699646         0.961628          0.86259              2.02591            0.102963
    2019-08-03 20:55:33  4:48:50.920  9350 obs/sec      7         7             175000     0.286762         0.277561            0.671065       0.953758        0.799877           1.99164          0.11009                          0.272993           0.255304              0.70185          0.960803          0.7982               2.02591            0.102153
    2019-08-03 20:55:39  4:48:56.442  9404 obs/sec      9         9             225000     0.28657          0.278758            0.671504       0.953605        0.796157           1.99164          0.111588                         0.273357           0.257613              0.701055         0.960634          0.772833             2.02591            0.100858
    2019-08-03 20:55:42  4:48:59.284  9456 obs/sec      10        10            250000     0.286369         0.277541            0.671965       0.954318        0.94304            1.99164          0.110689                         0.272388           0.254715              0.703171         0.961529          0.944888             2.02591            0.0997248
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.008243625165485212
C438        0.9092934131622314     0.9092934131622314    0.007495874063554114
C374        0.7760070562362671     0.7760070562362671    0.006397111297383389
C863        0.6922959089279175     0.6922959089279175    0.005707027976800639
C322        0.6671011447906494     0.6671011447906494    0.005499331785120192
---         ---                    ---                   ---
C908        0.035244911909103394   0.035244911909103394  0.0002905458427691942
C829        0.0343385711312294     0.0343385711312294    0.00028307430912420667
C958        0.03375628963112831    0.03375628963112831   0.0002782741986965769
C885        0.03365131467580795    0.03365131467580795   0.0002774088245131523
C913        0.031233787536621094   0.031233787536621094  0.000257479636950308

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_165

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.02891627525192717    0.05531668663024902     0.0         -0.006218084836317563  0.21237415075302124  0.03967417346648797    0.20601129531860352
    3        2        Softmax                 0.0   0.0   0.0017475376625952777  0.00031210901215672493  0.0         -0.040672614704817533  0.6660275459289551   0.0015734250882438322  0.08311402797698975


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08023964228100593
RMSE: 0.2832660274035803
LogLoss: 0.2716508168960703
Mean Per-Class Error: 0.10537846042889099
AUC: 0.9563208044484326
pr_auc: 0.7865833700953441
Gini: 0.9126416088968652
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49577944135309826: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4345  624   0.1256   (624.0/4969.0)
1      432   4613  0.0856   (432.0/5045.0)
Total  4777  5237  0.1055   (1056.0/10014.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.495779     0.897296  203
max f2                       0.110254     0.925129  336
max f0point5                 0.817656     0.908688  98
max accuracy                 0.513092     0.894747  198
max precision                0.969074     0.990719  0
max recall                   0.0225092    1         399
max specificity              0.969074     0.99839   0
max absolute_mcc             0.510659     0.789835  199
max min_per_class_accuracy   0.602391     0.892936  173
max mean_per_class_accuracy  0.513092     0.894622  198
Gains/Lift Table: Avg response rate: 50.38 %, avg score: 51.16 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100859                   0.969076           1.96528     1.96528            0.990099         0.969231   0.990099                    0.969231            0.0198216       0.0198216                  96.5283   96.5283
    2        0.0200719                   0.969076           1.98494     1.97506            1                0.969076   0.995025                    0.969154            0.0198216       0.0396432                  98.4936   97.506
    3        0.0300579                   0.969076           1.94524     1.96515            0.98             0.969076   0.990033                    0.969128            0.0194252       0.0590684                  94.5237   96.5152
    4        0.0400439                   0.969076           1.98494     1.97009            1                0.969076   0.992519                    0.969115            0.0198216       0.07889                    98.4936   97.0086
    5        0.05003                     0.969076           1.98494     1.97305            1                0.969076   0.994012                    0.969107            0.0198216       0.0987116                  98.4936   97.305
    6        0.10006                     0.968052           1.95324     1.96314            0.984032         0.968891   0.989022                    0.968999            0.0977205       0.196432                   95.324    96.3145
    7        0.14999                     0.964279           1.95318     1.95983            0.984            0.965775   0.98735                     0.967926            0.0975223       0.293954                   95.3177   95.9827
    8        0.20002                     0.95572            1.92551     1.95124            0.97006          0.960325   0.983025                    0.966025            0.096333        0.390287                   92.5506   95.1242
    9        0.29998                     0.93509            1.89174     1.93141            0.953047         0.945349   0.973036                    0.959135            0.189098        0.579386                   89.1737   93.1414
    10       0.40004                     0.877486           1.74524     1.88485            0.879242         0.913862   0.949576                    0.947811            0.174628        0.754014                   74.5238   88.4846
    11       0.5                         0.613134           1.35237     1.77839            0.681319         0.771558   0.895946                    0.912575            0.135183        0.889197                   35.2374   77.8394
    12       0.59996                     0.17083            0.701965    1.59905            0.353646         0.368108   0.805593                    0.82186             0.0701685       0.959366                   -29.8035  59.9049
    13       0.70002                     0.0540328          0.249603    1.40616            0.125749         0.0953934  0.708417                    0.71802             0.0249752       0.984341                   -75.0397  40.6161
    14       0.79998                     0.0306848          0.0971647   1.2426             0.048951         0.0413881  0.626014                    0.633473            0.00971259      0.994054                   -90.2835  24.2598
    15       0.89994                     0.0225219          0.0535397   1.11052            0.026973         0.0254064  0.559476                    0.565932            0.00535183      0.999405                   -94.646   11.0524
    16       1                           0.0220268          0.00594292  1                  0.00299401       0.0224762  0.503795                    0.511554            0.000594648     1                          -99.4057  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07437675788423703
RMSE: 0.2727210257465255
LogLoss: 0.2547813119761592
Mean Per-Class Error: 0.09772521953866886
AUC: 0.9612711056159455
pr_auc: 0.7757421264954719
Gini: 0.9225422112318911
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.504920355608106: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2781  347   0.1109   (347.0/3128.0)
1      262   2787  0.0859   (262.0/3049.0)
Total  3043  3134  0.0986   (609.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.50492      0.901504  198
max f2                       0.148954     0.929413  312
max f0point5                 0.858932     0.913001  81
max accuracy                 0.641434     0.90238   158
max precision                0.969068     0.99292   0
max recall                   0.0224887    1         399
max specificity              0.969068     0.998721  0
max absolute_mcc             0.641434     0.804883  158
max min_per_class_accuracy   0.581613     0.901535  177
max mean_per_class_accuracy  0.620939     0.902275  165
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.27 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.969077           2.02591     2.02591            1                0.969255   1                           0.969255            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.969076           2.02591     2.02591            1                0.969076   1                           0.969166            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.969076           1.99323     2.01502            0.983871         0.969076   0.994624                    0.969136            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.969076           2.02591     2.01774            1                0.969076   0.995968                    0.969121            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.969076           2.02591     2.01935            1                0.969076   0.996764                    0.969112            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.968254           1.99968     2.00952            0.987055         0.968932   0.991909                    0.969022            0.100033        0.20105                    99.9685   100.952
    7        0.150073                    0.964062           1.98002     1.99968            0.977346         0.965839   0.987055                    0.967961            0.0990489       0.300098                   98.0016   99.9685
    8        0.200097                    0.955713           1.98002     1.99477            0.977346         0.960097   0.984628                    0.965995            0.0990489       0.399147                   98.0016   99.4768
    9        0.299984                    0.933886           1.93726     1.97562            0.95624          0.945217   0.975175                    0.959076            0.193506        0.592653                   93.7256   97.5618
    10       0.400032                    0.876412           1.79644     1.9308             0.886731         0.913306   0.953055                    0.947629            0.179731        0.772384                   79.6438   93.0805
    11       0.500081                    0.542364           1.33749     1.8121             0.660194         0.750057   0.894464                    0.908102            0.133814        0.906199                   33.7494   81.2104
    12       0.599968                    0.142045           0.620579    1.61373            0.306321         0.313437   0.796546                    0.809098            0.0619875       0.968186                   -37.9421  61.3731
    13       0.700016                    0.0518291          0.186856    1.4098             0.092233         0.0845399  0.695883                    0.705542            0.0186947       0.986881                   -81.3144  40.9797
    14       0.799903                    0.0299754          0.0788036   1.24359            0.0388979        0.0405026  0.613843                    0.622496            0.00787143      0.994752                   -92.1196  24.3591
    15       0.899951                    0.0225086          0.0426162   1.11008            0.0210356        0.0249537  0.54794                     0.556067            0.00426369      0.999016                   -95.7384  11.0078
    16       1                           0.0220268          0.00983452  1                  0.00485437       0.0224767  0.493605                    0.502682            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:18:32  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:18:35  3:11:52.935  9402 obs/sec      1         1             25000      0.303533         0.300604            0.631451       0.944804        0.929668           1.98494          0.129319                         0.294367           0.285503              0.653335         0.950479          0.937585             2.02591            0.118018
    2019-08-03 19:18:41  3:11:58.615  9299 obs/sec      3         3             75000      0.287276         0.274987            0.66987        0.954697        0.938935           1.96528          0.111644                         0.278059           0.261245              0.690682         0.95914           0.941218             2.02591            0.10361
    2019-08-03 19:18:47  3:12:04.260  9307 obs/sec      5         5             125000     0.285509         0.27346             0.673921       0.955068        0.897722           1.96528          0.109746                         0.274626           0.257663              0.698273         0.959575          0.891531             2.02591            0.0990772
    2019-08-03 19:18:52  3:12:09.856  9352 obs/sec      7         7             175000     0.284392         0.27273             0.676467       0.955874        0.854954           1.96528          0.108348                         0.273255           0.255454              0.701278         0.961024          0.866795             2.02591            0.0998867
    2019-08-03 19:18:58  3:12:15.411  9389 obs/sec      9         9             225000     0.283671         0.27248             0.678104       0.955702        0.814579           1.96528          0.106351                         0.272957           0.255634              0.70193          0.960976          0.806583             2.02591            0.0987534
    2019-08-03 19:19:00  3:12:18.185  9460 obs/sec      10        10            250000     0.283266         0.271651            0.679023       0.956321        0.786583           1.96528          0.105452                         0.272721           0.254781              0.702444         0.961271          0.775742             2.02591            0.0985915
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.008246804049610515
C438        0.900067150592804      0.900067150592804    0.0074226774224301325
C374        0.7892054915428162     0.7892054915428162   0.0065084230436301535
C863        0.6880979537963867     0.6880979537963867   0.005674608991896751
C322        0.6536638140678406     0.6536638140678406   0.005390637388938522
---         ---                    ---                  ---
C888        0.03667627274990082    0.03667627274990082  0.00030246203463850184
C969        0.0366373248398304     0.0366373248398304   0.00030214083885600924
C482        0.0333685576915741     0.0333685576915741   0.00027518395670053533
C639        0.03155526891350746    0.03155526891350746  0.00026023011946246213
C998        0.02914177067577839    0.02914177067577839  0.00024032647242183016

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_119

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ----------------------  ----------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.003646481236779548    0.0021330229938030243   0.0         0.022213990843698937  0.08911412954330444  0.21822774458775235    0.30463123321533203
    3        2        Softmax                      0.0   0.0   0.00028142558016952535  5.7033030316233635e-05  0.0         0.08068539195664926   0.741379976272583    -0.009019781659940163  0.139421284198761


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07584519988981893
RMSE: 0.2754000724215935
LogLoss: 0.2626879422896855
Mean Per-Class Error: 0.0907103679292145
AUC: 0.9626679897241298
pr_auc: 0.8748038198018869
Gini: 0.9253359794482596
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4977364637610534: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4415  555   0.1117   (555.0/4970.0)
1      366   4685  0.0725   (366.0/5051.0)
Total  4781  5240  0.0919   (921.0/10021.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.497736     0.910504  213
max f2                       0.325201     0.932609  267
max f0point5                 0.609653     0.919371  172
max accuracy                 0.535069     0.90929   200
max precision                0.998084     0.993639  3
max recall                   5.27978e-05  1         399
max specificity              0.999929     0.999195  0
max absolute_mcc             0.56449      0.818683  190
max min_per_class_accuracy   0.540699     0.908731  198
max mean_per_class_accuracy  0.56449      0.90929   190
Gains/Lift Table: Avg response rate: 50.40 %, avg score: 50.01 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100788                   0.999996           1.98396     1.98396            1                0.999999     1                           0.999999            0.019996        0.019996                   98.3964   98.3964
    2        0.0200579                   0.999972           1.92444     1.95435            0.97             0.999987     0.985075                    0.999993            0.0192041       0.0392002                  92.4445   95.4352
    3        0.0300369                   0.999907           1.98396     1.96419            1                0.999942     0.990033                    0.999976            0.0197981       0.0589982                  98.3964   96.419
    4        0.040016                    0.999799           1.98396     1.96912            1                0.999861     0.992519                    0.999947            0.0197981       0.0787963                  98.3964   96.9121
    5        0.0500948                   0.999547           1.96432     1.96816            0.990099         0.999684     0.992032                    0.999894            0.0197981       0.0985943                  96.432    96.8155
    6        0.10009                     0.99595            1.97208     1.97012            0.994012         0.998035     0.993021                    0.998966            0.0985943       0.197189                   97.2084   97.0117
    7        0.150085                    0.986326           1.95228     1.96418            0.984032         0.991684     0.990027                    0.99654             0.0976044       0.294793                   95.2284   96.4177
    8        0.20008                     0.967475           1.9008      1.94834            0.958084         0.977706     0.982045                    0.991834            0.0950307       0.389824                   90.0803   94.8341
    9        0.30007                     0.874263           1.88694     1.92788            0.951098         0.927899     0.971733                    0.970529            0.188676        0.578499                   88.6943   92.7882
    10       0.40006                     0.715697           1.79784     1.89538            0.906188         0.799274     0.95535                     0.927726            0.179766        0.758266                   79.7843   89.5381
    11       0.50005                     0.546568           1.47114     1.81055            0.741517         0.625901     0.912592                    0.867373            0.1471          0.905365                   47.1143   81.055
    12       0.60004                     0.303863           0.613801    1.61112            0.309381         0.428312     0.812074                    0.794209            0.061374        0.966739                   -38.6199  61.1125
    13       0.70003                     0.0938132          0.20196     1.40984            0.101796         0.1877       0.71062                     0.707577            0.020194        0.986933                   -79.804   40.9844
    14       0.80002                     0.0127518          0.0990002   1.24601            0.0499002        0.0430456    0.62804                     0.624521            0.00989903      0.996832                   -90.1     24.6009
    15       0.90001                     0.000581616        0.02376     1.11022            0.011976         0.00457276   0.559596                    0.555645            0.00237577      0.999208                   -97.624   11.0219
    16       1                           2.23395e-18        0.00792001  1                  0.00399202       0.000113651  0.504042                    0.500098            0.000791922     1                          -99.208   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07370032496739674
RMSE: 0.2714780377257003
LogLoss: 0.2551586538198497
Mean Per-Class Error: 0.0843502733276349
AUC: 0.9654359233961243
pr_auc: 0.8723144747989445
Gini: 0.9308718467922485
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.531150762348146: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2862  266   0.085    (266.0/3128.0)
1      259   2790  0.0849   (259.0/3049.0)
Total  3121  3056  0.085    (525.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.531151     0.914005  203
max f2                       0.366337     0.931351  255
max f0point5                 0.579134     0.923939  185
max accuracy                 0.559613     0.915817  192
max precision                0.994049     0.997183  6
max recall                   7.75254e-05  1         399
max specificity              0.999892     0.999361  0
max absolute_mcc             0.559613     0.831817  192
max min_per_class_accuracy   0.531151     0.914962  203
max mean_per_class_accuracy  0.557048     0.91565   193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.26 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999994           2.02591     2.02591            1                0.999999     1                           0.999999            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999962           1.96056     1.99323            0.967742         0.999981     0.983871                    0.99999             0.0196786       0.0400131                  96.0558   99.3234
    3        0.0301117                   0.999881           2.02591     2.00413            1                0.999923     0.989247                    0.999968            0.0203345       0.0603477                  102.591   100.413
    4        0.0401489                   0.999722           2.02591     2.00957            1                0.999804     0.991935                    0.999927            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.999451           2.02591     2.0128             1                0.999595     0.993528                    0.999861            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.995765           2.02591     2.01935            1                0.997969     0.996764                    0.998915            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.984971           2.0128      2.01717            0.993528         0.991184     0.995685                    0.996338            0.100689        0.302722                   101.28    101.717
    8        0.200097                    0.963525           1.94068     1.99805            0.957929         0.97559      0.986246                    0.991151            0.097081        0.399803                   94.0678   99.8046
    9        0.299984                    0.871518           1.94382     1.97999            0.959481         0.923397     0.977334                    0.968591            0.194162        0.593965                   94.3823   97.9991
    10       0.400032                    0.69903            1.81939     1.93982            0.898058         0.787662     0.957507                    0.92334             0.182027        0.775992                   81.9385   93.9823
    11       0.500081                    0.522567           1.44567     1.84096            0.713592         0.605878     0.908708                    0.859827            0.144638        0.92063                    44.5674   84.0961
    12       0.599968                    0.282206           0.482672    1.61482            0.23825          0.406317     0.797086                    0.784324            0.0482125       0.968842                   -51.7328  61.4824
    13       0.700016                    0.0858235          0.186856    1.41073            0.092233         0.175377     0.696346                    0.697291            0.0186947       0.987537                   -81.3144  41.0734
    14       0.799903                    0.0130167          0.0788036   1.24441            0.0388979        0.0402968    0.614248                    0.61525             0.00787143      0.995408                   -92.1196  24.4412
    15       0.899951                    0.000610401        0.0393381   1.11044            0.0194175        0.00443363   0.54812                     0.547345            0.00393572      0.999344                   -96.0662  11.0442
    16       1                           2.55525e-18        0.00655634  1                  0.00323625       0.000113111  0.493605                    0.492595            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:20:28  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:20:29  2:13:46.646  27027 obs/sec     1         1             25000      0.305742         0.32376             0.626064       0.941493        0.831497           1.98396          0.123441                         0.301581           0.311877              0.636136         0.945015          0.845347             2.02591            0.121742
    2019-08-03 18:20:35  2:13:52.329  27716 obs/sec     7         7             175000     0.278338         0.267907            0.690091       0.960441        0.866234           1.98396          0.0946013                        0.274574           0.258588              0.698387         0.963612          0.880469             2.02591            0.0877449
    2019-08-03 18:20:38  2:13:55.292  27768 obs/sec     10        10            250000     0.2754           0.262688            0.696599       0.962668        0.874804           1.98396          0.091907                         0.271478           0.255159              0.70515          0.965436          0.872314             2.02591            0.0849927
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.005134311676395075
C438        0.8029837012290955     0.8029837012290955   0.004122768593175479
C88         0.7748886346817017     0.7748886346817017   0.003978519764952099
C374        0.6820834875106812     0.6820834875106812   0.0035020292142023644
C36         0.6739270687103271     0.6739270687103271   0.003460151617918139
---         ---                    ---                  ---
C326        0.1011229008436203     0.1011229008436203   0.0005191964905523411
C773        0.0999538004398346     0.0999538004398346   0.0005131939646983059
C688        0.09621822088956833    0.09621822088956833  0.0004940143349952712
C267        0.08978711813688278    0.08978711813688278  0.00046099504904006125
C887        0.08661111444234848    0.08661111444234848  0.0004446884561869399

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_111

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms          mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  ------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.022129707860645165  0.036746978759765625    0.0         0.003339759078943779  0.2139338254928589  -0.022296109824762465    0.21259057521820068
    3        2        Softmax                 0.0   0.0   0.001638209869270213  0.00017872045282274485  0.0         0.009038398096890887  0.6145265102386475  -0.00042773286863640597  0.11996492743492126


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08059683287825298
RMSE: 0.28389581342149617
LogLoss: 0.2742761622858228
Mean Per-Class Error: 0.1064330573614829
AUC: 0.9538886064586453
pr_auc: 0.9492482509352601
Gini: 0.9077772129172905
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49433187850068305: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4390  595   0.1194   (595.0/4985.0)
1      471   4566  0.0935   (471.0/5037.0)
Total  4861  5161  0.1064   (1066.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.494332     0.89547   204
max f2                       0.138467     0.926088  322
max f0point5                 0.791174     0.90542   113
max accuracy                 0.494332     0.893634  204
max precision                0.968353     1         0
max recall                   0.0212431    1         398
max specificity              0.968353     1         0
max absolute_mcc             0.494332     0.787476  204
max min_per_class_accuracy   0.560615     0.891007  185
max mean_per_class_accuracy  0.494332     0.893567  204
Gains/Lift Table: Avg response rate: 50.26 %, avg score: 50.27 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   0.965963           1.96998    1.96998            0.990099         0.966519   0.990099                    0.966519            0.0198531       0.0198531                  96.9977   96.9977
    2        0.0200559                   0.9659             1.96978    1.96988            0.99             0.96591    0.99005                     0.966216            0.0196546       0.0395076                  96.978    96.9879
    3        0.0324287                   0.9659             1.97363    1.97131            0.991935         0.9659     0.990769                    0.966095            0.0244193       0.0639269                  97.3631   97.131
    4        0.040012                    0.9659             1.98968    1.97479            1                0.9659     0.992519                    0.966058            0.0150883       0.0790153                  98.9676   97.4791
    5        0.0500898                   0.9659             1.98968    1.97779            1                0.9659     0.994024                    0.966027            0.0200516       0.0990669                  98.9676   97.7786
    6        0.10008                     0.965063           1.95393    1.96587            0.982036         0.965729   0.988036                    0.965878            0.0976772       0.196744                   95.3934   96.5872
    7        0.15007                     0.957351           1.94599    1.95925            0.978044         0.961794   0.984707                    0.964517            0.0972801       0.294024                   94.5991   95.9249
    8        0.20006                     0.951005           1.91819    1.94899            0.964072         0.954437   0.979551                    0.961999            0.0958904       0.389915                   91.8191   94.899
    9        0.30004                     0.927834           1.86656    1.92152            0.938124         0.939306   0.965747                    0.954437            0.186619        0.576534                   86.6563   92.1523
    10       0.40002                     0.865527           1.78713    1.88793            0.898204         0.902504   0.948865                    0.941457            0.178678        0.755211                   78.7134   88.7934
    11       0.5                         0.56521            1.33837    1.77804            0.672655         0.749796   0.893634                    0.903132            0.13381         0.889021                   33.8365   77.8042
    12       0.59998                     0.157858           0.724782   1.60253            0.364271         0.332345   0.805422                    0.808017            0.0724638       0.961485                   -27.5218  60.2528
    13       0.69996                     0.0554462          0.208499   1.40341            0.10479          0.0926487  0.705346                    0.705836            0.0208457       0.982331                   -79.1501  40.341
    14       0.79994                     0.029963           0.105242   1.24116            0.0528942        0.0409738  0.623799                    0.622739            0.0105221       0.992853                   -89.4758  24.1159
    15       0.89992                     0.0212484          0.0476569  1.10856            0.0239521        0.0245916  0.557157                    0.556285            0.00476474      0.997618                   -95.2343  10.8562
    16       1                           0.0190159          0.0238047  1                  0.0119641        0.0212121  0.502594                    0.502735            0.00238237      1                          -97.6195  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07462923748987679
RMSE: 0.27318352345973723
LogLoss: 0.25550063360614833
Mean Per-Class Error: 0.09891455334397503
AUC: 0.9609073223454254
pr_auc: 0.9574333889230379
Gini: 0.9218146446908508
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3634958766444548: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2704  424   0.1355   (424.0/3128.0)
1      209   2840  0.0685   (209.0/3049.0)
Total  2913  3264  0.1025   (633.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.363496     0.899731  240
max f2                       0.171026     0.928752  302
max f0point5                 0.762236     0.912972  126
max accuracy                 0.597988     0.901247  174
max precision                0.968435     1         0
max recall                   0.0212482    1         398
max specificity              0.968435     1         0
max absolute_mcc             0.597988     0.80261   174
max min_per_class_accuracy   0.544167     0.900256  190
max mean_per_class_accuracy  0.597988     0.901085  174
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.38 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.965967           2.02591     2.02591            1                0.966561   1                           0.966561            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.9659             2.02591     2.02591            1                0.96591    1                           0.966235            0.0203345       0.0406691                  102.591   102.591
    3        0.0314068                   0.9659             1.99697     2.01547            0.985714         0.9659     0.994845                    0.966114            0.0226304       0.0632994                  99.6969   101.547
    4        0.0401489                   0.9659             2.02591     2.01774            1                0.9659     0.995968                    0.966068            0.0177107       0.0810102                  102.591   101.774
    5        0.0500243                   0.9659             2.02591     2.01935            1                0.9659     0.996764                    0.966035            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.965              2.00624     2.0128             0.990291         0.965698   0.993528                    0.965866            0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.957516           1.98002     2.00187            0.977346         0.961849   0.988134                    0.964527            0.0990489       0.300426                   98.0016   100.187
    8        0.200097                    0.951151           1.98002     1.99641            0.977346         0.954468   0.985437                    0.962012            0.0990489       0.399475                   98.0016   99.6407
    9        0.299984                    0.926629           1.93069     1.97452            0.952998         0.939047   0.974636                    0.954365            0.19285         0.592325                   93.0689   97.4524
    10       0.400032                    0.854689           1.79644     1.92998            0.886731         0.898374   0.952651                    0.940362            0.179731        0.772056                   79.6438   92.9985
    11       0.500081                    0.512255           1.3211      1.80817            0.652104         0.720121   0.892522                    0.896299            0.132174        0.904231                   32.1103   80.8169
    12       0.599968                    0.140948           0.633713    1.61264            0.312804         0.289908   0.796006                    0.795343            0.0632994       0.96753                    -36.6287  61.2638
    13       0.700016                    0.051442           0.183578    1.40839            0.0906149        0.0818479  0.69519                     0.693368            0.0183667       0.985897                   -81.6422  40.8392
    14       0.799903                    0.0288734          0.0853706   1.24318            0.0421394        0.0388596  0.613641                    0.611637            0.00852739      0.994424                   -91.4629  24.3181
    15       0.899951                    0.0212388          0.0458944   1.11008            0.0226537        0.0239835  0.54794                     0.546307            0.00459167      0.999016                   -95.4106  11.0078
    16       1                           0.0202144          0.00983452  1                  0.00485437       0.021215   0.493605                    0.493772            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:12:20  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:12:23  2:05:41.030  8934 obs/sec      1         1             25000      0.303593         0.305273            0.631315       0.943251        0.918871           1.96998          0.123628                         0.292716           0.283955              0.657213         0.951017          0.931848             2.02591            0.113971
    2019-08-03 18:12:29  2:05:47.084  8760 obs/sec      3         3             75000      0.288894         0.279497            0.666153       0.952292        0.925429           1.98968          0.11385                          0.277037           0.259138              0.692951         0.959687          0.931353             2.02591            0.103934
    2019-08-03 18:12:35  2:05:52.602  9050 obs/sec      5         5             125000     0.286503         0.2767              0.671655       0.953255        0.878158           1.98968          0.10896                          0.275283           0.2564                0.696828         0.960494          0.891067             2.02591            0.10102
    2019-08-03 18:12:40  2:05:58.127  9176 obs/sec      7         7             175000     0.285729         0.276594            0.673428       0.952738        0.845475           1.98968          0.107962                         0.274342           0.256389              0.698896         0.960048          0.846863             2.02591            0.0992391
    2019-08-03 18:12:46  2:06:03.531  9314 obs/sec      9         9             225000     0.284395         0.274887            0.67647        0.953573        0.816568           1.98968          0.107164                         0.273627           0.255836              0.700465         0.960644          0.82323              2.02591            0.10102
    2019-08-03 18:12:49  2:06:06.303  9396 obs/sec      10        10            250000     0.283896         0.274276            0.677604       0.953889        0.949248           1.96998          0.106366                         0.273184           0.255501              0.701434         0.960907          0.957433             2.02591            0.102477
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.0077134958662449194
C438        0.9178692102432251     0.9178692102432251    0.007079980358964606
C374        0.7767547965049744     0.7767547965049744    0.005991494911927034
C322        0.7075486183166504     0.7075486183166504    0.005457673342552787
C863        0.6868333220481873     0.6868333220481873    0.005297885990417958
---         ---                    ---                   ---
C797        0.03888440132141113    0.03888440132141113   0.0002999346688541133
C510        0.038777247071266174   0.038777247071266174  0.00029910813498856955
C765        0.0383104532957077     0.0383104532957077    0.00029550752313041044
C785        0.037456829100847244   0.037456829100847244  0.00028892309643202763
C839        0.03404707834124565    0.03404707834124565   0.0002626219980429153

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_23

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.003969982949696046  0.007267966866493225   0.0         0.023881021936494815  0.09242826700210571  0.027351533386617364   0.401814341545105
    3        2        Softmax                      0.0   0.0   0.000301552190876464  6.095852586440742e-05  0.0         0.08416757189843338   0.7169785499572754   0.0016200741015489281  0.07620123028755188


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07858883577293192
RMSE: 0.28033700393086164
LogLoss: 0.2729293653503657
Mean Per-Class Error: 0.09346707490867301
AUC: 0.9597176915531772
pr_auc: 0.8319681629406108
Gini: 0.9194353831063544
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4566691530751324: 
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4360  595   0.1201   (595.0/4955.0)
1      349   4730  0.0687   (349.0/5079.0)
Total  4709  5325  0.0941   (944.0/10034.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.456669     0.909266  218
max f2                       0.364411     0.932226  250
max f0point5                 0.598185     0.912666  166
max accuracy                 0.463732     0.906717  215
max precision                0.99937      0.997561  1
max recall                   4.55255e-05  1         399
max specificity              0.999898     0.999596  0
max absolute_mcc             0.463732     0.813651  215
max min_per_class_accuracy   0.487732     0.903918  206
max mean_per_class_accuracy  0.463732     0.906533  215
Gains/Lift Table: Avg response rate: 50.62 %, avg score: 49.80 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100658                   1                  1.97559    1.97559            1                1            1                           1                   0.0198858       0.0198858                  97.5586   97.5586
    2        0.0200319                   0.999994           1.97559    1.97559            1                0.999998     1                           0.999999            0.0196889       0.0395747                  97.5586   97.5586
    3        0.029998                    0.999973           1.97559    1.97559            1                0.999986     1                           0.999995            0.0196889       0.0592636                  97.5586   97.5586
    4        0.0400638                   0.999919           1.95603    1.97067            0.990099         0.999951     0.997512                    0.999984            0.0196889       0.0789525                  95.6025   97.0671
    5        0.0500299                   0.999833           1.97559    1.97165            1                0.99988      0.998008                    0.999963            0.0196889       0.0986415                  97.5586   97.165
    6        0.10006                     0.997884           1.96378    1.96771            0.994024         0.999135     0.996016                    0.999549            0.0982477       0.196889                   96.3779   96.7715
    7        0.14999                     0.991342           1.93615    1.95721            0.98004          0.995151     0.990698                    0.998085            0.0966726       0.293562                   93.6153   95.7208
    8        0.20002                     0.973634           1.92049    1.94802            0.972112         0.98373      0.986049                    0.994494            0.0960819       0.389644                   92.049    94.8024
    9        0.29998                     0.886078           1.85741    1.91783            0.940179         0.937885     0.970764                    0.975631            0.185666        0.57531                    85.7405   91.7828
    10       0.40004                     0.70019            1.76898    1.8806             0.895418         0.801475     0.951918                    0.93207             0.177003        0.752313                   76.8976   88.0596
    11       0.5                         0.496735           1.46938    1.79839            0.743769         0.599304     0.910305                    0.865543            0.146879        0.899193                   46.9379   79.8386
    12       0.59996                     0.300264           0.644084   1.60607            0.326022         0.409072     0.812957                    0.78949             0.0643828       0.963576                   -35.5916  60.6066
    13       0.70002                     0.0969401          0.194804   1.40434            0.0986056        0.191525     0.710849                    0.704018            0.019492        0.983068                   -80.5196  40.4342
    14       0.79998                     0.0141575          0.116211   1.24339            0.0588235        0.0469809    0.629376                    0.621919            0.0116165       0.994684                   -88.3789  24.3386
    15       0.89994                     0.00043714         0.0393935  1.10965            0.0199402        0.00488791   0.561683                    0.553383            0.00393778      0.998622                   -96.0606  10.9653
    16       1                           2.07658e-19        0.013774   1                  0.00697211       7.40341e-05  0.506179                    0.498019            0.00137822      1                          -98.6226  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07339104236879991
RMSE: 0.27090781156843724
LogLoss: 0.2556886169399862
Mean Per-Class Error: 0.08508984539813902
AUC: 0.9651607398845288
pr_auc: 0.8524438862681232
Gini: 0.9303214797690575
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48070171743876766: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2846  282   0.0902   (282.0/3128.0)
1      244   2805  0.08     (244.0/3049.0)
Total  3090  3087  0.0852   (526.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.480702     0.914276  206
max f2                       0.368519     0.934505  245
max f0point5                 0.606687     0.920098  166
max accuracy                 0.480702     0.914845  206
max precision                0.996103     0.997372  5
max recall                   4.31245e-05  1         399
max specificity              0.999927     0.999361  0
max absolute_mcc             0.480702     0.829753  206
max min_per_class_accuracy   0.490453     0.913043  202
max mean_per_class_accuracy  0.480702     0.91491   206
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.23 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.999999           2.02591    2.02591            1                1           1                           1                   0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.999992           2.02591    2.02591            1                0.999996    1                           0.999998            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.999961           1.99323    2.01502            0.983871         0.99998     0.994624                    0.999992            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.999893           1.99323    2.00957            0.983871         0.999931    0.991935                    0.999976            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.999785           2.02591    2.0128             1                0.999841    0.993528                    0.99995             0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.99781            2.02591    2.01935            1                0.999025    0.996764                    0.999488            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.990426           2.00624    2.01498            0.990291         0.994967    0.994606                    0.997981            0.100361        0.302394                   100.624   101.498
    8        0.200097                    0.973329           1.9669     2.00296            0.970874         0.983152    0.988673                    0.994273            0.0983929       0.400787                   96.6903   100.296
    9        0.299984                    0.885293           1.94382    1.98327            0.959481         0.936609    0.978953                    0.975073            0.194162        0.594949                   94.3823   98.3271
    10       0.400032                    0.697512           1.80627    1.939              0.891586         0.798421    0.957102                    0.930892            0.180715        0.775664                   80.6273   93.9003
    11       0.500081                    0.478292           1.4424     1.83965            0.711974         0.585076    0.908061                    0.861706            0.14431         0.919974                   44.2396   83.965
    12       0.599968                    0.276315           0.482672   1.61373            0.23825          0.385125    0.796546                    0.782362            0.0482125       0.968186                   -51.7328  61.3731
    13       0.700016                    0.0953563          0.170465   1.40745            0.0841424        0.179787    0.694727                    0.69624             0.0170548       0.985241                   -82.9535  40.7455
    14       0.799903                    0.0136105          0.0919376  1.24318            0.0453809        0.0448567   0.613641                    0.614899            0.00918334      0.994424                   -90.8062  24.3181
    15       0.899951                    0.000476255        0.0426162  1.10971            0.0210356        0.00449905  0.54776                     0.547041            0.00426369      0.998688                   -95.7384  10.9713
    16       1                           5.83838e-20        0.0131127  1                  0.00647249       7.8976e-05  0.493605                    0.492318            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:33:14  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:33:15  26 min 32.547 sec  27233 obs/sec     1         1             25000      0.31737          0.370969            0.597043       0.932931        0.786482           1.97559          0.133446                         0.30637            0.341095              0.624488         0.940654          0.796928             2.02591            0.124818
    2019-08-03 16:33:20  26 min 38.087 sec  28266 obs/sec     7         7             175000     0.283794         0.277665            0.677795       0.957572        0.814294           1.97559          0.0975683                        0.274614           0.261781              0.698298         0.962733          0.863597             2.02591            0.0887162
    2019-08-03 16:33:23  26 min 40.943 sec  28480 obs/sec     10        10            250000     0.280337         0.272929            0.685597       0.959718        0.831968           1.97559          0.0940801                        0.270908           0.255689              0.706388         0.965161          0.852444             2.02591            0.0851546
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004258255218472785
C28         0.8821260333061218     0.8821260333061218   0.003756317784676491
C35         0.8128583431243896     0.8128583431243896   0.0034613582814885737
C36         0.8067104816436768     0.8067104816436768   0.00343517911825588
C88         0.7973311543464661     0.7973311543464661   0.0033952395488467684
---         ---                    ---                  ---
C534        0.11370845884084702    0.11370845884084702  0.0004841996382435347
C342        0.11338609457015991    0.11338609457015991  0.0004828269289056321
C414        0.1115378737449646     0.1115378737449646   0.0004749567329318541
C422        0.10965877026319504    0.10965877026319504  0.0004669550307245585
C423        0.0956224724650383     0.0956224724650383   0.0004071848923775195

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_143

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.01913558733919059    0.02580837905406952    0.0         -0.006822719733804473  0.16019004583358765  0.012148985420450502    0.1535072922706604
    3        2        Softmax                 0.0   0.0   0.0024043746634561103  0.0007352523971349001  0.0         -0.15730154058110202   0.7355637550354004   -0.0059018132887514105  0.07761812210083008


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08102738868852166
RMSE: 0.28465310236939567
LogLoss: 0.27413997265556
Mean Per-Class Error: 0.10766025031457105
AUC: 0.9538266000321706
pr_auc: 0.9165494924837306
Gini: 0.9076532000643411
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4440532869022406: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4316  632   0.1277   (632.0/4948.0)
1      445   4626  0.0878   (445.0/5071.0)
Total  4761  5258  0.1075   (1077.0/10019.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.444053     0.89573   218
max f2                       0.136915     0.925184  318
max f0point5                 0.758741     0.904949  126
max accuracy                 0.479031     0.892504  208
max precision                0.974969     0.990494  4
max recall                   0.0167083    1         398
max specificity              0.978094     0.999596  0
max absolute_mcc             0.444053     0.785426  218
max min_per_class_accuracy   0.54274      0.89016   190
max mean_per_class_accuracy  0.479031     0.89234   208
Gains/Lift Table: Avg response rate: 50.61 %, avg score: 50.47 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100808                   0.978117           1.95618    1.95618            0.990099         0.978183   0.990099                    0.978183            0.01972         0.01972                    95.6183   95.6183
    2        0.0200619                   0.97763            1.93623    1.94626            0.98             0.977931   0.985075                    0.978058            0.0193256       0.0390456                  93.623    94.6256
    3        0.0300429                   0.976787           1.97574    1.95605            1                0.977284   0.990033                    0.977801            0.01972         0.0587655                  97.5744   95.6053
    4        0.040024                    0.975847           1.93623    1.95111            0.98             0.976396   0.987531                    0.97745             0.0193256       0.0780911                  93.623    95.1109
    5        0.050005                    0.974866           1.97574    1.95603            1                0.975357   0.99002                     0.977032            0.01972         0.0978111                  97.5744   95.6026
    6        0.10001                     0.971836           1.95208    1.95405            0.988024         0.973917   0.989022                    0.975475            0.0976139       0.195425                   95.2083   95.4055
    7        0.150015                    0.962852           1.9087     1.93894            0.966068         0.967283   0.981371                    0.972744            0.0954447       0.29087                    90.8703   93.8937
    8        0.20002                     0.957134           1.89293    1.92744            0.958084         0.960017   0.975549                    0.969562            0.0946559       0.385526                   89.2929   92.7435
    9        0.30003                     0.932254           1.86927    1.90805            0.946108         0.947027   0.965735                    0.962051            0.186945        0.572471                   86.9267   90.8046
    10       0.40004                     0.850054           1.7549     1.86976            0.888224         0.900417   0.946357                    0.946642            0.175508        0.747979                   75.4903   86.976
    11       0.50005                     0.561978           1.37435    1.77068            0.695609         0.734521   0.896208                    0.904218            0.137448        0.885427                   37.4345   77.0677
    12       0.59996                     0.16688            0.734243   1.59808            0.371628         0.343538   0.80885                     0.810849            0.0733583       0.958785                   -26.5757  59.8082
    13       0.69997                     0.055566           0.26225    1.40722            0.132735         0.0988695  0.712249                    0.709123            0.0262276       0.985013                   -73.775   40.7221
    14       0.79998                     0.0310458          0.0828156  1.24165            0.0419162        0.0405188  0.628447                    0.625537            0.00828239      0.993295                   -91.7184  24.165
    15       0.89999                     0.0193715          0.059154   1.11025            0.0299401        0.02508    0.561939                    0.558812            0.00591599      0.999211                   -94.0846  11.0247
    16       1                           0.016062           0.0078872  1                  0.00399202       0.0179434  0.506138                    0.50472             0.000788799     1                          -99.2113  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07532394426109461
RMSE: 0.27445208008155925
LogLoss: 0.25645481715288254
Mean Per-Class Error: 0.09976841386090274
AUC: 0.9601272250597446
pr_auc: 0.9195503126026738
Gini: 0.9202544501194891
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5026175464373316: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2787  341   0.109    (341.0/3128.0)
1      276   2773  0.0905   (276.0/3049.0)
Total  3063  3114  0.0999   (617.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.502618     0.899886  209
max f2                       0.225801     0.929271  290
max f0point5                 0.781534     0.911278  125
max accuracy                 0.565984     0.900275  191
max precision                0.978067     1         0
max recall                   0.0171621    1         398
max specificity              0.978067     1         0
max absolute_mcc             0.565984     0.800514  191
max min_per_class_accuracy   0.547659     0.899311  196
max mean_per_class_accuracy  0.502618     0.900232  209
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.77 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.978109           2.02591     2.02591            1                0.978176   1                           0.978176            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.97761            2.02591     2.02591            1                0.977892   1                           0.978034            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.976794           2.02591     2.02591            1                0.977252   1                           0.977773            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.975954           1.96056     2.00957            0.967742         0.976406   0.991935                    0.977432            0.0196786       0.0806822                  96.0558   100.957
    5        0.0500243                   0.975002           2.02591     2.0128             1                0.975483   0.993528                    0.977047            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.972368           1.99968     2.00624            0.987055         0.974033   0.990291                    0.97554             0.100033        0.200722                   99.9685   100.624
    7        0.150073                    0.963199           1.9669      1.99313            0.970874         0.967838   0.983819                    0.972973            0.0983929       0.299114                   96.6903   99.3128
    8        0.200097                    0.957217           1.98002     1.98985            0.977346         0.960174   0.982201                    0.969773            0.0990489       0.398163                   98.0016   98.985
    9        0.299984                    0.932167           1.92412     1.96796            0.949757         0.94685    0.971398                    0.96214             0.192194        0.590357                   92.4122   96.7965
    10       0.400032                    0.848391           1.80299     1.92671            0.889968         0.89777    0.951032                    0.946041            0.180387        0.770745                   80.2994   92.6705
    11       0.500081                    0.516918           1.34405     1.81014            0.66343          0.715648   0.893493                    0.899948            0.13447         0.905215                   34.405    81.0137
    12       0.599968                    0.149113           0.614012    1.611              0.303079         0.308059   0.795197                    0.801406            0.0613316       0.966546                   -38.5988  61.0998
    13       0.700016                    0.0520368          0.206525    1.41027            0.101942         0.088072   0.696115                    0.699454            0.0206625       0.987209                   -79.3475  41.0266
    14       0.799903                    0.030533           0.0853706   1.24482            0.0421394        0.0387259  0.614451                    0.616947            0.00852739      0.995736                   -91.4629  24.4822
    15       0.899951                    0.0191386          0.0393381   1.11081            0.0194175        0.0244354  0.5483                      0.551077            0.00393572      0.999672                   -96.0662  11.0807
    16       1                           0.016062           0.00327817  1                  0.00161812       0.0178621  0.493605                    0.497729            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:42:40  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:42:43  2:36:00.490  9005 obs/sec      1         1             25000      0.300322         0.297354            0.639173       0.94554         0.931066           1.95618          0.120771                         0.291768           0.282712              0.659431         0.951233          0.933568             2.02591            0.115752
    2019-08-03 18:42:49  2:36:06.229  9096 obs/sec      3         3             75000      0.288214         0.27853             0.667681       0.95276         0.932614           1.95618          0.113285                         0.278292           0.260986              0.690164         0.959025          0.936998             2.02591            0.107819
    2019-08-03 18:42:54  2:36:12.060  9082 obs/sec      5         5             125000     0.286108         0.275818            0.672518       0.953928        0.904158           1.97574          0.109592                         0.276393           0.258939              0.694377         0.960002          0.897107             2.02591            0.103772
    2019-08-03 18:43:00  2:36:17.430  9288 obs/sec      7         7             175000     0.284653         0.27414             0.675842       0.953827        0.916549           1.95618          0.107496                         0.274452           0.256455              0.698655         0.960127          0.91955              2.02591            0.0998867
    2019-08-03 18:43:05  2:36:22.868  9388 obs/sec      9         9             225000     0.284618         0.275462            0.675922       0.953207        0.940757           1.8975           0.108394                         0.274799           0.258771              0.697892         0.959252          0.946188             1.99323            0.0989153
    2019-08-03 18:43:08  2:36:25.677  9448 obs/sec      10        10            250000     0.282666         0.272859            0.680352       0.954574        0.941695           1.91706          0.1053                           0.274125           0.258145              0.699372         0.960546          0.943414             1.99323            0.100534
    2019-08-03 18:43:08  2:36:25.986  9443 obs/sec      10        10            250000     0.284653         0.27414             0.675842       0.953827        0.916549           1.95618          0.107496                         0.274452           0.256455              0.698655         0.960127          0.91955              2.02591            0.0998867
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.00796526303922006
C438        0.8274516463279724     0.8274516463279724    0.0065908700152379875
C374        0.7562255263328552     0.7562255263328552    0.006023535234213828
C863        0.6396446228027344     0.6396446228027344    0.005094937672246477
C88         0.6257323026657104     0.6257323026657104    0.004984122382869243
---         ---                    ---                   ---
C564        0.041021112352609634   0.041021112352609634  0.000326743950049935
C880        0.039199210703372955   0.039199210703372955  0.00031223202418217597
C841        0.03814685717225075    0.03814685717225075   0.00030384975149653554
C888        0.03758367896080017    0.03758367896080017   0.0002993638889043742
C889        0.03546466678380966    0.03546466678380966   0.00028248539953133447

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_187

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms          mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  ------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.01738549429608388    0.02741669863462448   0.0         -0.01372422739475399  0.2118133306503296  0.056812065331942885     0.19072860479354858
    3        2        Softmax                 0.0   0.0   0.0017077677275665337  0.000358144985511899  0.0         0.03652092645643279   0.7549853324890137  -0.00022355123821205664  0.09093740582466125


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07987813141345528
RMSE: 0.2826271951059474
LogLoss: 0.272771636175512
Mean Per-Class Error: 0.10656831489515417
AUC: 0.9544169269495506
pr_auc: 0.9186180878280027
Gini: 0.9088338538991012
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.42452310287882417: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4229  695   0.1411   (695.0/4924.0)
1      382   4705  0.0751   (382.0/5087.0)
Total  4611  5400  0.1076   (1077.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.424523     0.897301  224
max f2                       0.173019     0.927131  305
max f0point5                 0.791219     0.908709  109
max accuracy                 0.500025     0.893717  202
max precision                0.966328     0.988235  0
max recall                   0.025607     1         397
max specificity              0.966328     0.999594  0
max absolute_mcc             0.500025     0.787661  202
max min_per_class_accuracy   0.585846     0.891685  177
max mean_per_class_accuracy  0.500025     0.893432  202
Gains/Lift Table: Avg response rate: 50.81 %, avg score: 50.95 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   0.96633            1.94847    1.94847            0.990099         0.966517   0.990099                    0.966517            0.019658        0.019658                   94.8473   94.8473
    2        0.0200779                   0.965243           1.94828    1.94838            0.99             0.96588    0.99005                     0.9662              0.0194614       0.0391193                  94.8278   94.8376
    3        0.0300669                   0.963563           1.90892    1.93527            0.97             0.964434   0.983389                    0.965613            0.0190682       0.0581875                  90.8919   93.5267
    4        0.0400559                   0.961454           1.9286     1.9336             0.98             0.962606   0.982544                    0.964863            0.0192648       0.0774523                  92.8598   93.3604
    5        0.050045                    0.959552           1.9286     1.93261            0.98             0.960388   0.982036                    0.96397             0.0192648       0.0967171                  92.8598   93.2605
    6        0.10009                     0.957686           1.94832    1.94046            0.99002          0.958003   0.986028                    0.960987            0.0975034       0.194221                   94.8317   94.0461
    7        0.150035                    0.951105           1.91679    1.93258            0.974            0.955573   0.982024                    0.959185            0.0957342       0.289955                   91.6791   93.2581
    8        0.20008                     0.943617           1.91296    1.92767            0.972056         0.946996   0.979531                    0.956136            0.0957342       0.385689                   91.2965   92.7675
    9        0.30007                     0.917134           1.86573    1.90703            0.948052         0.931604   0.969041                    0.947961            0.186554        0.572243                   86.5726   90.7032
    10       0.40006                     0.852125           1.76153    1.87067            0.895105         0.892319   0.950562                    0.934054            0.176135        0.748378                   76.1528   87.0665
    11       0.50005                     0.607461           1.3703     1.77061            0.696304         0.752551   0.89972                     0.897761            0.137016        0.885394                   37.0296   77.0611
    12       0.60004                     0.188663           0.747077   1.60005            0.37962          0.382612   0.813051                    0.811917            0.0747002       0.960094                   -25.2923  60.0051
    13       0.70003                     0.066025           0.237885   1.40548            0.120879         0.108738   0.714184                    0.711477            0.0237861       0.98388                    -76.2115  40.5483
    14       0.80002                     0.0407054          0.0786397  1.23965            0.03996          0.051824   0.629916                    0.629031            0.00786318      0.991744                   -92.136   23.9649
    15       0.90001                     0.0301745          0.0511158  1.1076             0.025974         0.0340429  0.562819                    0.562928            0.00511107      0.996855                   -94.8884  10.7604
    16       1                           0.0237537          0.0314559  1                  0.015984         0.0285107  0.508141                    0.509492            0.00314527      1                          -96.8544  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07422094551817236
RMSE: 0.27243521343279464
LogLoss: 0.2565703497496027
Mean Per-Class Error: 0.09790991595919674
AUC: 0.9603031139302727
pr_auc: 0.9294785379330189
Gini: 0.9206062278605454
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4900512566171007: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2782  346   0.1106   (346.0/3128.0)
1      265   2784  0.0869   (265.0/3049.0)
Total  3047  3130  0.0989   (611.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.490051     0.901117  208
max f2                       0.166113     0.928914  305
max f0point5                 0.790966     0.914987  115
max accuracy                 0.592699     0.902218  179
max precision                0.966421     1         0
max recall                   0.0278398    1         395
max specificity              0.966421     1         0
max absolute_mcc             0.592699     0.804483  179
max min_per_class_accuracy   0.55241      0.901279  191
max mean_per_class_accuracy  0.592699     0.90209   179
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.62 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.966318           2.02591     2.02591            1                0.96652    1                           0.96652             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.96549            2.02591     2.02591            1                0.965936   1                           0.966228            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.963472           1.99323     2.01502            0.983871         0.964552   0.994624                    0.965669            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.96085            1.96056     2.0014             0.967742         0.962285   0.987903                    0.964823            0.0196786       0.0803542                  96.0558   100.14
    5        0.0500243                   0.959661           1.9927      1.99968            0.983607         0.960231   0.987055                    0.963917            0.0196786       0.100033                   99.2698   99.9685
    6        0.100049                    0.957686           1.99968     1.99968            0.987055         0.958057   0.987055                    0.960987            0.100033        0.200066                   99.9685   99.9685
    7        0.150073                    0.951712           1.97346     1.99094            0.97411          0.955893   0.98274                     0.959289            0.0987209       0.298786                   97.3459   99.0943
    8        0.200097                    0.944063           1.97346     1.98657            0.97411          0.947416   0.980583                    0.956321            0.0987209       0.397507                   97.3459   98.6572
    9        0.299984                    0.916061           1.94382     1.97234            0.959481         0.930538   0.973556                    0.947736            0.194162        0.591669                   94.3823   97.2338
    10       0.400032                    0.840518           1.80299     1.92998            0.889968         0.886668   0.952651                    0.932462            0.180387        0.772056                   80.2994   92.9985
    11       0.500081                    0.519747           1.34077     1.8121             0.661812         0.713694   0.894464                    0.888695            0.134142        0.906199                   34.0772   81.2104
    12       0.599968                    0.153787           0.620579    1.61373            0.306321         0.310817   0.796546                    0.792486            0.0619875       0.968186                   -37.9421  61.3731
    13       0.700016                    0.0617377          0.190134    1.41027            0.0938511        0.0955133  0.696115                    0.692872            0.0190226       0.987209                   -80.9866  41.0266
    14       0.799903                    0.0398472          0.0591027   1.24154            0.0291734        0.0498653  0.612831                    0.612577            0.00590357      0.993112                   -94.0897  24.1541
    15       0.899951                    0.0301743          0.0622853   1.11044            0.0307443        0.0333646  0.54812                     0.548186            0.00623155      0.999344                   -93.7715  11.0442
    16       1                           0.0237537          0.00655634  1                  0.00323625       0.028348   0.493605                    0.496177            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:59:11  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:59:14  3:52:31.353  9031 obs/sec      1         1             25000      0.30365          0.304798            0.631089       0.943195        0.923624           1.96796          0.126361                         0.294786           0.289926              0.652349         0.948434          0.913541             2.02591            0.114619
    2019-08-03 19:59:19  3:52:36.972  9253 obs/sec      3         3             75000      0.287946         0.276991            0.668261       0.953595        0.930897           1.96796          0.113275                         0.278525           0.261274              0.689645         0.959078          0.931291             2.02591            0.110248
    2019-08-03 19:59:25  3:52:42.538  9326 obs/sec      5         5             125000     0.285796         0.275467            0.673196       0.95376         0.897609           1.94847          0.110778                         0.277067           0.261689              0.692884         0.958423          0.902631             2.02591            0.102963
    2019-08-03 19:59:31  3:52:48.257  9315 obs/sec      7         7             175000     0.283846         0.272804            0.677641       0.954389        0.842154           1.96796          0.107082                         0.274608           0.257574              0.698312         0.959595          0.844332             2.02591            0.0992391
    2019-08-03 19:59:36  3:52:53.557  9471 obs/sec      9         9             225000     0.282472         0.27285             0.680755       0.95444         0.945              1.94847          0.107382                         0.272997           0.257518              0.701841         0.960139          0.950581             2.02591            0.10102
    2019-08-03 19:59:39  3:52:56.296  9544 obs/sec      10        10            250000     0.282627         0.272772            0.680403       0.954417        0.918618           1.94847          0.107582                         0.272435           0.25657               0.703068         0.960303          0.929479             2.02591            0.0989153
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007426943149277113
C438        0.9721975922584534     0.9721975922584534    0.0072204562475676245
C374        0.8047440052032471     0.8047440052032471    0.005976787976366082
C863        0.6896505355834961     0.6896505355834961    0.005121995320647138
C88         0.6878174543380737     0.6878174543380737    0.00510838113044938
---         ---                    ---                   ---
C823        0.04054142162203789    0.04054142162203789   0.00030109883357774933
C908        0.03899002447724342    0.03899002447724342   0.00028957669518141
C525        0.03658308461308479    0.03658308461308479   0.00027170048964657507
C765        0.036581289023160934   0.036581289023160934  0.00027168715390229114
C329        0.0362418107688427     0.0362418107688427    0.0002691658682070538

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_213

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.02093498559277726    0.03780783712863922    0.0         -0.013659583904350379  0.21254336833953857  0.04739213365328473   0.17473870515823364
    3        2        Softmax                 0.0   0.0   0.0024107591543724993  0.0007472229190170765  0.0         -0.10635438247118145   0.66680908203125     0.027345254623389062  0.09773698449134827


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08047555584868686
RMSE: 0.2836821387551336
LogLoss: 0.27398830511947825
Mean Per-Class Error: 0.10630251387978207
AUC: 0.9540996629730427
pr_auc: 0.9337799272546178
Gini: 0.9081993259460854
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4923488319873781: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4388  607   0.1215   (607.0/4995.0)
1      463   4552  0.0923   (463.0/5015.0)
Total  4851  5159  0.1069   (1070.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.492349     0.89483   210
max f2                       0.144128     0.924495  319
max f0point5                 0.803347     0.909656  110
max accuracy                 0.55374      0.893706  194
max precision                0.962437     0.985926  9
max recall                   0.0201312    1         399
max specificity              0.970831     0.9996    0
max absolute_mcc             0.55374      0.787436  194
max min_per_class_accuracy   0.570327     0.891692  188
max mean_per_class_accuracy  0.55374      0.893697  194
Gains/Lift Table: Avg response rate: 50.10 %, avg score: 50.37 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   0.970033           1.95649    1.95649            0.980198         0.970725   0.980198                    0.970725            0.0197408       0.0197408                  95.6487   95.6487
    2        0.0200799                   0.968012           1.93613    1.94636            0.97             0.969046   0.975124                    0.96989             0.019342        0.0390828                  93.6132   94.636
    3        0.0300699                   0.965738           1.97605    1.95622            0.99             0.966883   0.980066                    0.968891            0.0197408       0.0588235                  97.6052   95.6224
    4        0.0400599                   0.964058           1.95609    1.95619            0.98             0.96483    0.98005                     0.967878            0.0195414       0.0783649                  95.6092   95.6191
    5        0.05005                     0.962766           1.93613    1.95219            0.97             0.963347   0.978044                    0.966974            0.019342        0.0977069                  93.6132   95.2187
    6        0.1                         0.962448           1.98803    1.97009            0.996            0.96247    0.987013                    0.964724            0.0993021       0.197009                   98.8028   97.009
    7        0.15005                     0.960663           1.9482     1.96279            0.976048         0.962099   0.983356                    0.963849            0.0975075       0.294516                   94.8203   96.2789
    8        0.2                         0.951601           1.92416    1.95314            0.964            0.95612    0.978521                    0.961918            0.0961117       0.390628                   92.4156   95.3141
    9        0.3                         0.924607           1.89033    1.9322             0.947053         0.939495   0.968032                    0.954444            0.189033        0.579661                   89.0329   93.2203
    10       0.4                         0.867954           1.78664    1.89581            0.895105         0.903573   0.9498                      0.941726            0.178664        0.758325                   78.664    89.5813
    11       0.5                         0.571055           1.32602    1.78185            0.664336         0.748444   0.892707                    0.90307             0.132602        0.890927                   32.6022   78.1854
    12       0.6                         0.155553           0.6999     1.60153            0.350649         0.332522   0.802364                    0.807978            0.06999         0.960917                   -30.01    60.1529
    13       0.7                         0.0574853          0.221336   1.40436            0.110889         0.0923826  0.703582                    0.70575             0.0221336       0.983051                   -77.8664  40.4358
    14       0.8                         0.0328226          0.0877368  1.23978            0.043956         0.0438628  0.621129                    0.623015            0.00877368      0.991825                   -91.2263  23.9781
    15       0.9                         0.0258637          0.0598205  1.10867            0.02997          0.0275151  0.555445                    0.556848            0.00598205      0.997807                   -94.0179  10.8674
    16       1                           0.0198783          0.0219342  1                  0.010989         0.0249446  0.500999                    0.503658            0.00219342      1                          -97.8066  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07503601261169299
RMSE: 0.2739270205943419
LogLoss: 0.2572347691991186
Mean Per-Class Error: 0.09897085875290124
AUC: 0.9603300608392001
pr_auc: 0.9417741107252796
Gini: 0.9206601216784003
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5630158883515809: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2805  323   0.1033   (323.0/3128.0)
1      291   2758  0.0954   (291.0/3049.0)
Total  3096  3081  0.0994   (614.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.563016     0.899837  192
max f2                       0.140035     0.928338  317
max f0point5                 0.792389     0.915447  115
max accuracy                 0.595709     0.901085  180
max precision                0.970756     1         0
max recall                   0.0223495    1         397
max specificity              0.970756     1         0
max absolute_mcc             0.595709     0.802137  180
max min_per_class_accuracy   0.581539     0.899967  186
max mean_per_class_accuracy  0.595709     0.901029  180
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.92 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.969965           2.02591     2.02591            1                0.970658   1                           0.970658            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.967862           2.02591     2.02591            1                0.969019   1                           0.969838            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.96542            2.02591     2.02591            1                0.966638   1                           0.968771            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.963734           2.02591     2.02591            1                0.964531   1                           0.967711            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.962714           1.9927      2.01935            0.983607         0.963106   0.996764                    0.966802            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.962448           2.0128      2.01608            0.993528         0.962469   0.995146                    0.964636            0.100689        0.201705                   101.28    101.608
    7        0.150073                    0.961022           1.96035     1.9975             0.967638         0.962203   0.985976                    0.963825            0.0980649       0.29977                    96.0347   99.7499
    8        0.200097                    0.95081            1.95379     1.98657            0.964401         0.956195   0.980583                    0.961917            0.097737        0.397507                   95.379    98.6572
    9        0.299984                    0.92462            1.93726     1.97015            0.95624          0.939468   0.972477                    0.954442            0.193506        0.591013                   93.7256   97.0151
    10       0.400032                    0.86269            1.81283     1.9308             0.894822         0.902603   0.953055                    0.941477            0.181371        0.772384                   81.2829   93.0805
    11       0.500081                    0.552869           1.32438     1.80948            0.653722         0.738604   0.893169                    0.900889            0.132502        0.904887                   32.4381   80.9481
    12       0.599968                    0.136015           0.630429    1.61318            0.311183         0.308056   0.796276                    0.80219             0.0629715       0.967858                   -36.9571  61.3184
    13       0.700016                    0.0564002          0.186856    1.40933            0.092233         0.0849469  0.695652                    0.69968             0.0186947       0.986553                   -81.3144  40.9329
    14       0.799903                    0.031678           0.0820871   1.24359            0.0405186        0.0425773  0.613843                    0.617625            0.00819941      0.994752                   -91.7913  24.3591
    15       0.899951                    0.0258637          0.0426162   1.11008            0.0210356        0.0270117  0.54794                     0.551966            0.00426369      0.999016                   -95.7384  11.0078
    16       1                           0.019879           0.00983452  1                  0.00485437       0.0249107  0.493605                    0.499235            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:28:02  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:28:05  4:21:23.064  9398 obs/sec      1         1             25000      0.298541         0.294338            0.643491       0.94759         0.942115           1.99601          0.120579                         0.291857           0.282805              0.659223         0.952102          0.942931             2.02591            0.117857
    2019-08-03 20:28:11  4:21:28.909  9070 obs/sec      3         3             75000      0.286358         0.275717            0.671996       0.954271        0.930498           1.99601          0.110689                         0.278907           0.263318              0.688793         0.958853          0.93389              2.02591            0.104743
    2019-08-03 20:28:17  4:21:34.613  9122 obs/sec      5         5             125000     0.287377         0.278803            0.669657       0.952451        0.858023           1.99601          0.110889                         0.277167           0.262186              0.692664         0.957891          0.857345             2.02591            0.102801
    2019-08-03 20:28:23  4:21:40.432  9089 obs/sec      7         7             175000     0.284788         0.274863            0.675582       0.954231        0.946595           1.93672          0.108392                         0.275711           0.258868              0.695884         0.959781          0.951086             2.02591            0.10361
    2019-08-03 20:28:28  4:21:45.856  9244 obs/sec      9         9             225000     0.283443         0.274032            0.678639       0.954673        0.947041           1.97625          0.106693                         0.274712           0.25933               0.698084         0.960363          0.951986             2.02591            0.10021
    2019-08-03 20:28:31  4:21:48.707  9307 obs/sec      10        10            250000     0.283682         0.273988            0.678096       0.9541          0.93378            1.95649          0.106893                         0.273927           0.257235              0.699807         0.96033           0.941774             2.02591            0.099401
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007671495003520081
C438        0.9762446880340576     0.9762446880340576    0.007489256246466293
C374        0.8046873807907104     0.8046873807907104    0.006173155221131596
C322        0.6790605187416077     0.6790605187416077    0.005209409376613998
C863        0.6754034757614136     0.6754034757614136    0.00518135438966378
---         ---                    ---                   ---
C762        0.039699431508779526   0.039699431508779526  0.0003045539904621898
C810        0.03924112021923065    0.03924112021923065   0.0003010380576943588
C591        0.03922952339053154    0.03922952339053154   0.0003009490926809368
C652        0.038827262818813324   0.038827262818813324  0.00029786315271488744
C839        0.03313887491822243    0.03313887491822243   0.0002542247133574203

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_6

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight           weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  --------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.021077035535348173  0.03485505282878876    0.0         0.007629511797541197  0.214025616645813   0.0001597699145784639  0.18587243556976318
    3        2        Softmax                 0.0   0.0   0.00183633235792513   0.0004815879510715604  0.0         -0.26444644236107706  0.7526974678039551  0.001015651142298457   0.09738844633102417


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.07638207525034019
RMSE: 0.27637307258548216
LogLoss: 0.2616229499604284
Mean Per-Class Error: 0.10119058313468021
AUC: 0.9580132464914597
pr_auc: 0.8159745723001213
Gini: 0.9160264929829194
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4330034684284389: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4354  612   0.1232   (612.0/4966.0)
1      412   4654  0.0813   (412.0/5066.0)
Total  4766  5266  0.1021   (1024.0/10032.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.433003     0.90089   223
max f2                       0.112235     0.930342  331
max f0point5                 0.762911     0.912944  121
max accuracy                 0.584935     0.898724  180
max precision                0.968131     0.992997  0
max recall                   0.0219604    1         399
max specificity              0.968131     0.998993  0
max absolute_mcc             0.584935     0.797613  180
max min_per_class_accuracy   0.547426     0.89775   192
max mean_per_class_accuracy  0.584935     0.898809  180
Gains/Lift Table: Avg response rate: 50.50 %, avg score: 50.23 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100678                   0.968156           1.98026    1.98026            1                0.968156   1                           0.968156            0.0199368       0.0199368                  98.0261   98.0261
    2        0.0200359                   0.968156           1.98026    1.98026            1                0.968156   1                           0.968156            0.0197394       0.0396763                  98.0261   98.0261
    3        0.030004                    0.968156           1.96046    1.97368            0.99             0.968156   0.996678                    0.968156            0.019542        0.0592183                  96.0458   97.3682
    4        0.0400718                   0.968155           1.94105    1.96548            0.980198         0.968156   0.992537                    0.968156            0.019542        0.0787604                  94.1047   96.5482
    5        0.0500399                   0.968149           1.94066    1.96054            0.98             0.968153   0.99004                     0.968155            0.0193447       0.098105                   94.0655   96.0537
    6        0.10008                     0.964072           1.94081    1.95067            0.98008          0.966812   0.98506                     0.967484            0.097118        0.195223                   94.0813   95.0675
    7        0.15002                     0.958574           1.94073    1.94737            0.98004          0.960898   0.983389                    0.965291            0.0969206       0.292144                   94.0734   94.7366
    8        0.20006                     0.951229           1.88953    1.9329             0.954183         0.954655   0.976084                    0.962631            0.0945519       0.386696                   88.9531   93.29
    9        0.30004                     0.929144           1.89734    1.92105            0.958126         0.940198   0.9701                      0.955156            0.189696        0.576392                   89.7338   92.105
    10       0.40002                     0.868007           1.79467    1.88946            0.906281         0.905771   0.954149                    0.942812            0.179432        0.755823                   79.4673   88.9464
    11       0.5                         0.563597           1.38006    1.7876             0.696909         0.749796   0.902711                    0.904217            0.137979        0.893802                   38.0062   78.7604
    12       0.59998                     0.146626           0.681146   1.60322            0.343968         0.328212   0.809603                    0.808232            0.0681011       0.961903                   -31.8854  60.3225
    13       0.69996                     0.050833           0.248767   1.40976            0.125623         0.082726   0.711905                    0.704603            0.0248717       0.986775                   -75.1233  40.9758
    14       0.79994                     0.0336308          0.0631788  1.24146            0.0319043        0.0422732  0.626916                    0.621822            0.00631662      0.993091                   -93.6821  24.1457
    15       0.89992                     0.0221726          0.0473841  1.1088             0.0239282        0.0272167  0.559925                    0.555762            0.00473747      0.997829                   -95.2616  10.8797
    16       1                           0.0218717          0.0216961  1                  0.0109562        0.0219476  0.504984                    0.502338            0.00217134      1                          -97.8304  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07523611650784275
RMSE: 0.2742920277876168
LogLoss: 0.25763644034399
Mean Per-Class Error: 0.09989266322696888
AUC: 0.9597750803374383
pr_auc: 0.8089839916659372
Gini: 0.9195501606748766
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4357408827413283: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2754  374   0.1196   (374.0/3128.0)
1      247   2802  0.081    (247.0/3049.0)
Total  3001  3176  0.1005   (621.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.435741     0.900241  224
max f2                       0.119672     0.928787  327
max f0point5                 0.790314     0.914594  116
max accuracy                 0.538059     0.900113  195
max precision                0.968123     0.993407  0
max recall                   0.0219434    1         399
max specificity              0.968123     0.999041  0
max absolute_mcc             0.538059     0.800199  195
max min_per_class_accuracy   0.538059     0.899639  195
max mean_per_class_accuracy  0.538059     0.900107  195
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.40 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.968156           2.02591     2.02591            1                0.968156   1                           0.968156            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.968156           2.02591     2.02591            1                0.968156   1                           0.968156            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.968156           1.99323     2.01502            0.983871         0.968156   0.994624                    0.968156            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.968155           1.99323     2.00957            0.983871         0.968156   0.991935                    0.968156            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.968149           1.9927      2.00624            0.983607         0.968153   0.990291                    0.968155            0.0196786       0.100361                   99.2698   100.624
    6        0.100049                    0.964235           2.00624     2.00624            0.990291         0.967118   0.990291                    0.967637            0.100361        0.200722                   100.624   100.624
    7        0.150073                    0.959601           1.96035     1.99094            0.967638         0.961725   0.98274                     0.965666            0.0980649       0.298786                   96.0347   99.0943
    8        0.200097                    0.951444           1.97346     1.98657            0.97411          0.95571    0.980583                    0.963177            0.0987209       0.397507                   97.3459   98.6572
    9        0.299984                    0.928082           1.93397     1.96906            0.954619         0.940069   0.971937                    0.955483            0.193178        0.590685                   93.3973   96.9058
    10       0.400032                    0.859961           1.79644     1.92589            0.886731         0.902358   0.950627                    0.942196            0.179731        0.770417                   79.6438   92.5885
    11       0.500081                    0.507051           1.33422     1.80751            0.658576         0.722647   0.892198                    0.898272            0.133486        0.903903                   33.4216   80.7513
    12       0.599968                    0.124059           0.643563    1.61373            0.317666         0.28271    0.796546                    0.795789            0.0642834       0.968186                   -35.6437  61.3731
    13       0.700016                    0.0497474          0.186856    1.4098             0.092233         0.0755852  0.695883                    0.692855            0.0186947       0.986881                   -81.3144  40.9797
    14       0.799903                    0.0330301          0.0623862   1.24154            0.0307942        0.0413785  0.612831                    0.611503            0.00623155      0.993112                   -93.7614  24.1541
    15       0.899951                    0.02203            0.0590071   1.11008            0.0291262        0.0263844  0.54794                     0.546455            0.00590357      0.999016                   -94.0993  11.0078
    16       1                           0.0219308          0.00983452  1                  0.00485437       0.0219386  0.493605                    0.493978            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:14:19  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:14:22  7 min 39.334 sec  9100 obs/sec      1         1             25000      0.292633         0.285796            0.65743        0.949835        0.9399             1.98026          0.114533                         0.291007           0.281044              0.661205         0.952009          0.937862             2.02591            0.114781
    2019-08-03 16:14:27  7 min 45.111 sec  9040 obs/sec      3         3             75000      0.279969         0.26508             0.686439       0.957293        0.933904           1.98026          0.105762                         0.27795            0.260768              0.690924         0.959365          0.929002             2.02591            0.103124
    2019-08-03 16:14:33  7 min 50.759 sec  9161 obs/sec      5         5             125000     0.277666         0.262476            0.691577       0.958129        0.891055           1.98026          0.102572                         0.27566            0.25863               0.695996         0.960081          0.896667             2.02591            0.100696
    2019-08-03 16:14:39  7 min 56.209 sec  9309 obs/sec      7         7             175000     0.275137         0.260415            0.697168       0.959337        0.86999            1.98026          0.100379                         0.273965           0.257895              0.699724         0.960844          0.868744             2.02591            0.0998867
    2019-08-03 16:14:44  8 min  1.370 sec  9496 obs/sec      9         9             225000     0.275144         0.260937            0.697153       0.959055        0.809279           1.94105          0.101774                         0.274018           0.258515              0.699608         0.960466          0.801149             1.99323            0.10021
    2019-08-03 16:14:46  8 min  4.041 sec  9579 obs/sec      10        10            250000     0.276373         0.261623            0.694441       0.958013        0.815975           1.98026          0.102073                         0.274292           0.257636              0.699006         0.959775          0.808984             2.02591            0.100534
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.008256582913437928
C438        0.896022617816925      0.896022617816925     0.007398085036321146
C374        0.7922680377960205     0.7922680377960205    0.006541426743729617
C863        0.68441241979599       0.68441241979599      0.005650907891032278
C322        0.6674821376800537     0.6674821376800537    0.0055111216129941545
---         ---                    ---                   ---
C885        0.033039871603250504   0.033039871603250504  0.00027279643934158114
C981        0.03273039683699608    0.03273039683699608   0.0002702412352743846
C811        0.03267291933298111    0.03267291933298111   0.00026976666749682756
C943        0.031748466193675995   0.031748466193675995  0.0002621338435025669
C633        0.025990862399339676   0.025990862399339676  0.00021459571039190428

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_225

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.021392588172491334   0.044072434306144714   0.0         0.0064086886617437215  0.121270090341568   0.014945471891538307   0.14145112037658691
    3        2        Softmax                 0.0   0.0   0.0018041456114588073  0.0004602099070325494  0.0         -0.0430501247610664    0.5689544677734375  0.0029123427321242415  0.09678378701210022


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08165571065762643
RMSE: 0.285754633659065
LogLoss: 0.2750326185622766
Mean Per-Class Error: 0.10858093702863114
AUC: 0.9541669008211158
pr_auc: 0.9259042483603296
Gini: 0.9083338016422315
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47441840365507826: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4359  628   0.1259   (628.0/4987.0)
1      467   4557  0.093    (467.0/5024.0)
Total  4826  5185  0.1094   (1095.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.474418     0.892742  210
max f2                       0.177187     0.925968  307
max f0point5                 0.750598     0.90445   125
max accuracy                 0.546676     0.891419  189
max precision                0.970289     0.99247   3
max recall                   0.0199986    1         398
max specificity              0.972197     0.999599  0
max absolute_mcc             0.546676     0.782837  189
max min_per_class_accuracy   0.546676     0.891317  189
max mean_per_class_accuracy  0.546676     0.891419  189
Gains/Lift Table: Avg response rate: 50.18 %, avg score: 50.44 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   0.972055           1.95318     1.95318            0.980198         0.972263   0.980198                    0.972263            0.0197054       0.0197054                  95.3177   95.3177
    2        0.0200779                   0.971286           1.99264     1.97281            1                0.97167    0.99005                     0.971968            0.0199045       0.0396099                  99.2635   97.2808
    3        0.0300669                   0.971029           1.97271     1.97278            0.99             0.97108    0.990033                    0.971673            0.0197054       0.0593153                  97.2709   97.2775
    4        0.0400559                   0.971024           1.99264     1.97773            1                0.971027   0.992519                    0.971512            0.0199045       0.0792197                  99.2635   97.7728
    5        0.050045                    0.970937           1.97271     1.97673            0.99             0.970998   0.992016                    0.971409            0.0197054       0.0989252                  97.2709   97.6726
    6        0.10009                     0.966265           1.96479     1.97076            0.986028         0.968872   0.989022                    0.970141            0.098328        0.197253                   96.4794   97.076
    7        0.150035                    0.958162           1.94083     1.9608             0.974            0.962408   0.984021                    0.967566            0.0969347       0.294188                   94.0827   96.0796
    8        0.20008                     0.95039            1.90513     1.94687            0.956088         0.953992   0.977034                    0.964171            0.0953424       0.38953                    90.5134   94.6873
    9        0.30007                     0.926684           1.91102     1.93493            0.959041         0.940714   0.971039                    0.956355            0.191083        0.580613                   91.1019   93.4926
    10       0.40006                     0.845283           1.71594     1.88019            0.861139         0.894427   0.943571                    0.940877            0.171576        0.752189                   71.5936   88.0192
    11       0.50005                     0.555891           1.37354     1.77888            0.689311         0.727249   0.892729                    0.89816             0.137341        0.88953                    37.3545   77.8883
    12       0.60004                     0.185343           0.718623    1.6022             0.360639         0.353168   0.804062                    0.807343            0.0718551       0.961385                   -28.1377  60.2202
    13       0.70003                     0.0598151          0.242859    1.40804            0.121878         0.108529   0.706621                    0.707527            0.0242834       0.985669                   -75.7141  40.8038
    14       0.80002                     0.0338301          0.0816164   1.24226            0.040959         0.043665   0.623424                    0.624554            0.00816083      0.99383                    -91.8384  24.2256
    15       0.90001                     0.0218834          0.0517568   1.10999            0.025974         0.0274411  0.557048                    0.558216            0.00517516      0.999005                   -94.8243  10.9993
    16       1                           0.0187262          0.00995322  1                  0.004995         0.0201241  0.501848                    0.504412            0.000995223     1                          -99.0047  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07587171884625284
RMSE: 0.27544821445464635
LogLoss: 0.2577404716437356
Mean Per-Class Error: 0.10169239170278466
AUC: 0.9602118928767052
pr_auc: 0.9340255112709545
Gini: 0.9204237857534103
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4477221960460914: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2737  391   0.125    (391.0/3128.0)
1      240   2809  0.0787   (240.0/3049.0)
Total  2977  3200  0.1022   (631.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.447722     0.899024  218
max f2                       0.177332     0.928877  302
max f0point5                 0.764079     0.91238   122
max accuracy                 0.587981     0.898333  179
max precision                0.969771     0.997691  4
max recall                   0.0205082    1         397
max specificity              0.972241     0.99968   0
max absolute_mcc             0.447722     0.79674   218
max min_per_class_accuracy   0.554871     0.897343  188
max mean_per_class_accuracy  0.559115     0.898308  187
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.83 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.972067           1.99323     1.99323            0.983871         0.972309   0.983871                    0.972309            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.971231           2.02591     2.00957            1                0.971663   0.991935                    0.971986            0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.971029           2.02591     2.01502            1                0.971071   0.994624                    0.971681            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.971025           2.02591     2.01774            1                0.971028   0.995968                    0.971518            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.970928           2.02591     2.01935            1                0.970996   0.996764                    0.971415            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.966294           1.99968     2.00952            0.987055         0.968789   0.991909                    0.970102            0.100033        0.20105                    99.9685   100.952
    7        0.150073                    0.95892            1.98657     2.00187            0.980583         0.962776   0.988134                    0.96766             0.0993768       0.300426                   98.6572   100.187
    8        0.200097                    0.950649           1.95379     1.98985            0.964401         0.954513   0.982201                    0.964373            0.097737        0.398163                   95.379    98.985
    9        0.299984                    0.927094           1.93069     1.97015            0.952998         0.940956   0.972477                    0.956576            0.19285         0.591013                   93.0689   97.0151
    10       0.400032                    0.836743           1.78988     1.92507            0.883495         0.891531   0.950223                    0.940308            0.179075        0.770089                   78.9882   92.5066
    11       0.500081                    0.518206           1.32438     1.80489            0.653722         0.706979   0.890903                    0.893627            0.132502        0.902591                   32.4381   80.489
    12       0.599968                    0.166541           0.653413    1.61318            0.322528         0.324131   0.796276                    0.798814            0.0652673       0.967858                   -34.6587  61.3184
    13       0.700016                    0.0583555          0.183578    1.40886            0.0906149        0.0998285  0.695421                    0.698912            0.0183667       0.986225                   -81.6422  40.886
    14       0.799903                    0.0337045          0.0952211   1.24482            0.0470016        0.0430595  0.614451                    0.617014            0.00951132      0.995736                   -90.4779  24.4822
    15       0.899951                    0.0216573          0.0327817   1.11008            0.0161812        0.0271121  0.54794                     0.551434            0.00327976      0.999016                   -96.7218  11.0078
    16       1                           0.0187262          0.00983452  1                  0.00485437       0.0200742  0.493605                    0.498272            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:44:56  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:44:59  4:38:16.572  9147 obs/sec      1         1             25000      0.300973         0.299375            0.637655       0.945135        0.923218           1.99264          0.12746                          0.292132           0.283646              0.658579         0.950976          0.93618              2.02591            0.115104
    2019-08-03 20:45:05  4:38:22.238  9220 obs/sec      3         3             75000      0.29101          0.282399            0.661248       0.951809        0.920436           1.99264          0.114974                         0.279414           0.263569              0.687661         0.958193          0.925255             2.02591            0.104743
    2019-08-03 20:45:10  4:38:28.111  9140 obs/sec      5         5             125000     0.285755         0.275033            0.673373       0.954167        0.925904           1.95318          0.10938                          0.275448           0.25774               0.696463         0.960212          0.934026             1.99323            0.102153
    2019-08-03 20:45:16  4:38:33.651  9238 obs/sec      7         7             175000     0.284608         0.274741            0.675988       0.954391        0.907621           1.99264          0.108081                         0.274689           0.258482              0.698135         0.960068          0.912868             2.02591            0.0982678
    2019-08-03 20:45:21  4:38:38.978  9396 obs/sec      9         9             225000     0.285212         0.27612             0.674613       0.953256        0.847006           1.99264          0.106783                         0.275722           0.259612              0.695859         0.959014          0.860437             2.02591            0.10102
    2019-08-03 20:45:24  4:38:41.883  9427 obs/sec      10        10            250000     0.286331         0.278988            0.672054       0.952675        0.841791           1.99264          0.110079                         0.275799           0.261784              0.695691         0.958399          0.855939             2.02591            0.102153
    2019-08-03 20:45:24  4:38:42.214  9424 obs/sec      10        10            250000     0.285755         0.275033            0.673373       0.954167        0.925904           1.95318          0.10938                          0.275448           0.25774               0.696463         0.960212          0.934026             1.99323            0.102153
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007568548574866763
C438        0.906175971031189      0.906175971031189     0.0068584368541266105
C374        0.7824255228042603     0.7824255228042603    0.005921825575559566
C88         0.6696822643280029     0.6696822643280029    0.005068522747293253
C322        0.6601220965385437     0.6601220965385437    0.0049961661529948544
---         ---                    ---                   ---
C633        0.052046965807676315   0.052046965807676315  0.0003939199888898277
C375        0.05152741074562073    0.05152741074562073   0.00038998771116534206
C810        0.05113141983747482    0.05113141983747482   0.0003869906347418342
C839        0.050560127943754196   0.050560127943754196  0.00038266678429378203
C943        0.05004654452204704    0.05004654452204704   0.00037877970321934515

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_71

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.01613043442994611   0.021447226405143738   0.0         -0.004522736969335659  0.11991581320762634  0.013971955644884734  0.15524345636367798
    3        2        Softmax                 0.0   0.0   0.001782975592504954  0.0003637113841250539  0.0         0.13450214159092866    0.7816996574401855   0.004277088520995821  0.07835859060287476


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08291747501249723
RMSE: 0.28795394599223195
LogLoss: 0.2789588169992777
Mean Per-Class Error: 0.11056318962552747
AUC: 0.9532203164102799
pr_auc: 0.8728661803078243
Gini: 0.9064406328205599
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5156844214965446: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4382  599   0.1203   (599.0/4981.0)
1      510   4540  0.101    (510.0/5050.0)
Total  4892  5139  0.1106   (1109.0/10031.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.515684     0.891157  200
max f2                       0.132155     0.922047  324
max f0point5                 0.768363     0.907845  117
max accuracy                 0.547813     0.889443  191
max precision                0.970306     0.99435   1
max recall                   0.0214297    1         399
max specificity              0.970924     0.999398  0
max absolute_mcc             0.515684     0.778971  200
max min_per_class_accuracy   0.551775     0.889109  190
max mean_per_class_accuracy  0.547813     0.889437  191
Gains/Lift Table: Avg response rate: 50.34 %, avg score: 50.34 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100688                   0.970986           1.98634    1.98634            1                0.970987   1                           0.970987            0.02            0.02                       98.6337   98.6337
    2        0.0200379                   0.970973           1.98634    1.98634            1                0.970982   1                           0.970984            0.019802        0.039802                   98.6337   98.6337
    3        0.030007                    0.970891           1.94661    1.97314            0.98             0.97094    0.993355                    0.97097             0.0194059       0.0592079                  94.661    97.3138
    4        0.0400758                   0.970649           1.96667    1.97151            0.990099         0.970792   0.992537                    0.970925            0.019802        0.0790099                  96.667    97.1513
    5        0.0500449                   0.970114           1.98634    1.97447            1                0.970405   0.994024                    0.970821            0.019802        0.0988119                  98.6337   97.4466
    6        0.10009                     0.965899           1.95864    1.96655            0.986056         0.968011   0.99004                     0.969416            0.0980198       0.196832                   95.8639   96.6552
    7        0.150035                    0.958058           1.91497    1.94938            0.964072         0.961495   0.981395                    0.966779            0.0956436       0.292475                   91.4971   94.9382
    8        0.20008                     0.952783           1.92303    1.94279            0.968127         0.955644   0.978077                    0.963994            0.0962376       0.388713                   92.3027   94.279
    9        0.30007                     0.929516           1.89524    1.92694            0.954138         0.943279   0.9701                      0.957092            0.189505        0.578218                   89.5238   92.6945
    10       0.40006                     0.841621           1.75463    1.88388            0.88335          0.895109   0.948418                    0.9416              0.175446        0.753663                   75.463    88.3877
    11       0.50005                     0.557612           1.32488    1.7721             0.666999         0.720125   0.892145                    0.897314            0.132475        0.886139                   32.4885   77.2101
    12       0.60004                     0.178203           0.685217   1.59098            0.344965         0.351227   0.800964                    0.806314            0.0685149       0.954653                   -31.4783  59.0983
    13       0.70003                     0.0584804          0.295079   1.40588            0.148554         0.102706   0.707776                    0.705813            0.029505        0.984158                   -70.4921  40.5881
    14       0.80002                     0.0339795          0.095059   1.24205            0.0478564        0.0424266  0.625296                    0.6229              0.00950495      0.993663                   -90.4941  24.2048
    15       0.90001                     0.0238996          0.0495099  1.10956            0.0249252        0.0287072  0.558595                    0.556886            0.0049505       0.998614                   -95.049   10.9559
    16       1                           0.0213867          0.0138628  1                  0.00697906       0.0221134  0.503439                    0.503414            0.00138614      1                          -98.6137  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07596108137752525
RMSE: 0.27561037966216956
LogLoss: 0.25784745246887514
Mean Per-Class Error: 0.10115072737780784
AUC: 0.9602852891267021
pr_auc: 0.8809269330716637
Gini: 0.9205705782534042
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5265837846187047: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2804  324   0.1036   (324.0/3128.0)
1      301   2748  0.0987   (301.0/3049.0)
Total  3105  3072  0.1012   (625.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.526584     0.897893  191
max f2                       0.209188     0.929156  288
max f0point5                 0.840226     0.912395  91
max accuracy                 0.526584     0.898818  191
max precision                0.970168     0.996644  1
max recall                   0.0214506    1         399
max specificity              0.970892     0.99968   0
max absolute_mcc             0.526584     0.797645  191
max min_per_class_accuracy   0.547557     0.898327  186
max mean_per_class_accuracy  0.526584     0.898849  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.61 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.970986           2.02591     2.02591            1                0.970987   1                           0.970987            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.97096            1.99323     2.00957            0.983871         0.970976   0.991935                    0.970982            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.970806           2.02591     2.01502            1                0.970894   0.994624                    0.970953            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.970369           2.02591     2.01774            1                0.970625   0.995968                    0.970871            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.969725           2.02591     2.01935            1                0.970052   0.996764                    0.970709            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.965896           1.98657     2.00296            0.980583         0.967985   0.988673                    0.969347            0.0993768       0.200394                   98.6572   100.296
    7        0.150073                    0.958064           1.98002     1.99531            0.977346         0.961922   0.984898                    0.966872            0.0990489       0.299442                   98.0016   99.5314
    8        0.200097                    0.953185           1.99968     1.99641            0.987055         0.956152   0.985437                    0.964192            0.100033        0.399475                   99.9685   99.6407
    9        0.299984                    0.928187           1.94054     1.9778             0.957861         0.943241   0.976255                    0.957216            0.193834        0.593309                   94.054    97.7804
    10       0.400032                    0.839307           1.80627     1.9349             0.891586         0.892435   0.955079                    0.941014            0.180715        0.774024                   80.6273   93.4904
    11       0.500081                    0.513755           1.2916      1.8062             0.63754          0.702952   0.891551                    0.893387            0.129223        0.903247                   29.16     80.6202
    12       0.599968                    0.1563             0.653413    1.61428            0.322528         0.308677   0.796816                    0.79604             0.0652673       0.968514                   -34.6587  61.4278
    13       0.700016                    0.0545935          0.186856    1.41027            0.092233         0.0938382  0.696115                    0.695679            0.0186947       0.987209                   -81.3144  41.0266
    14       0.799903                    0.0339628          0.0788036   1.244              0.0388979        0.0415159  0.614046                    0.613992            0.00787143      0.99508                    -92.1196  24.4001
    15       0.899951                    0.0237603          0.0458944   1.11081            0.0226537        0.0281065  0.5483                      0.548858            0.00459167      0.999672                   -95.4106  11.0807
    16       1                           0.0213867          0.00327817  1                  0.00161812       0.0220048  0.493605                    0.496147            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:25:27  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:25:30  1:18:47.797  8996 obs/sec      1         1             25000      0.302247         0.299984            0.634569       0.94492         0.934016           1.98634          0.123417                         0.289637           0.278347              0.664386         0.952816          0.940122             2.02591            0.113162
    2019-08-03 17:25:36  1:18:53.482  9157 obs/sec      3         3             75000      0.290101         0.28151             0.663351       0.952072        0.923455           1.98634          0.113448                         0.277753           0.260506              0.691364         0.959392          0.935169             2.02591            0.102963
    2019-08-03 17:25:41  1:18:59.115  9223 obs/sec      5         5             125000     0.287954         0.278959            0.668314       0.95322         0.872866           1.98634          0.110557                         0.27561            0.257847              0.696106         0.960285          0.880927             2.02591            0.101182
    2019-08-03 17:25:47  1:19:04.877  9201 obs/sec      7         7             175000     0.286811         0.278779            0.670942       0.953329        0.948744           1.96667          0.107367                         0.274895           0.258483              0.697682         0.959889          0.951366             1.96056            0.100696
    2019-08-03 17:25:53  1:19:10.385  9286 obs/sec      9         9             225000     0.288037         0.281214            0.668124       0.952755        0.914687           1.98634          0.108863                         0.275164           0.258199              0.69709          0.959535          0.914558             1.99323            0.100696
    2019-08-03 17:25:55  1:19:13.089  9389 obs/sec      10        10            250000     0.287122         0.279824            0.670228       0.952945        0.889646           1.98634          0.106968                         0.274767           0.25842               0.697963         0.959202          0.877108             2.02591            0.101667
    2019-08-03 17:25:56  1:19:13.401  9385 obs/sec      10        10            250000     0.287954         0.278959            0.668314       0.95322         0.872866           1.98634          0.110557                         0.27561            0.257847              0.696106         0.960285          0.880927             2.02591            0.101182
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007981591135218593
C438        0.8723268508911133     0.8723268508911133    0.006962556260085661
C374        0.7388477325439453     0.7388477325439453    0.005897180512349112
C88         0.6494317054748535     0.6494317054748535    0.005183498343347984
C322        0.6353781223297119     0.6353781223297119    0.0050713283886986635
---         ---                    ---                   ---
C963        0.04717229679226875    0.04717229679226875   0.0003765099859050728
C885        0.04706823453307152    0.04706823453307152   0.0003756794034995533
C762        0.04691961035132408    0.04691961035132408   0.00037449314604803884
C789        0.046627242118120193   0.046627242118120193  0.00037215958234967917
C743        0.04497075080871582    0.04497075080871582   0.00035893814599897056

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_153

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 252,263 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.05300767024159077   0.06796836853027344    0.0         0.00022794849493834658  0.10056760907173157  0.006768038443647651   0.12046101689338684
    3        2        Softmax                 0.0   0.0   0.001915155315600714  0.0005338052287697792  0.0         -0.006739119243093228   0.2493407130241394   0.0022812558971590513  0.131577730178833


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08528916285870103
RMSE: 0.29204308390835254
LogLoss: 0.2825930397741409
Mean Per-Class Error: 0.11776233270092384
AUC: 0.9524400741861198
pr_auc: 0.9511423425955224
Gini: 0.9048801483722395
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.42425162275827394: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4295  721   0.1437   (721.0/5016.0)
1      460   4541  0.092    (460.0/5001.0)
Total  4755  5262  0.1179   (1181.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.424252     0.884926  224
max f2                       0.157238     0.919966  311
max f0point5                 0.73431      0.901552  129
max accuracy                 0.43646      0.8822    221
max precision                0.982037     1         0
max recall                   0.0149132    1         396
max specificity              0.982037     1         0
max absolute_mcc             0.429309     0.765387  223
max min_per_class_accuracy   0.526228     0.880781  193
max mean_per_class_accuracy  0.429309     0.882238  223
Gains/Lift Table: Avg response rate: 49.93 %, avg score: 49.63 %

    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   0.976836           1.98317   1.98317            0.990099         0.977898   0.990099                    0.977898            0.019996        0.019996                   98.3168   98.3168
    2        0.0200659                   0.975694           2.003     1.99303            1                0.976231   0.995025                    0.977069            0.019996        0.039992                   100.3     99.3034
    3        0.0300489                   0.974836           2.003     1.99634            1                0.975263   0.996678                    0.976469            0.019996        0.059988                   100.3     99.6345
    4        0.0400319                   0.973981           1.98297   1.99301            0.99             0.97442    0.995012                    0.975958            0.019796        0.079784                   98.2969   99.3009
    5        0.050015                    0.973242           2.003     1.995              1                0.97366    0.996008                    0.975499            0.019996        0.09978                    100.3     99.5003
    6        0.10003                     0.968798           1.99101   1.993              0.994012         0.971132   0.99501                     0.973316            0.0995801       0.19936                    99.1005   99.3004
    7        0.150045                    0.962526           1.95103   1.97901            0.974052         0.965919   0.988024                    0.97085             0.0975805       0.296941                   95.1025   97.9011
    8        0.20006                     0.953204           1.95902   1.97401            0.978044         0.958281   0.985529                    0.967708            0.0979804       0.394921                   95.9021   97.4014
    9        0.29999                     0.915746           1.87894   1.94234            0.938062         0.937542   0.969717                    0.957659            0.187762        0.582683                   87.8937   94.2343
    10       0.40002                     0.815943           1.75113   1.89453            0.874251         0.875511   0.945845                    0.937117            0.175165        0.757848                   75.1125   89.4527
    11       0.50005                     0.524956           1.24338   1.76427            0.620758         0.684314   0.880815                    0.886546            0.124375        0.882224                   24.3379   76.4271
    12       0.59998                     0.185545           0.736367  1.59307            0.367632         0.339112   0.795341                    0.795368            0.0735853       0.955809                   -26.3633  59.3068
    13       0.70001                     0.0615337          0.271864  1.40427            0.135729         0.11014    0.701084                    0.69745             0.0271946       0.983003                   -72.8136  40.4271
    14       0.79994                     0.0295499          0.114057  1.24309            0.0569431        0.0425421  0.620616                    0.615638            0.0113977       0.994401                   -88.5943  24.3094
    15       0.89997                     0.0182839          0.049975  1.11048            0.0249501        0.0231381  0.554409                    0.549783            0.004999        0.9994                     -95.0025  11.0482
    16       1                           0.0112463          0.005997  1                  0.00299401       0.015577   0.499251                    0.496346            0.00059988      1                          -99.4003  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.07996712088075701
RMSE: 0.2827845838810118
LogLoss: 0.2671795516259567
Mean Per-Class Error: 0.10702363317309183
AUC: 0.9575742937812826
pr_auc: 0.9457511398923628
Gini: 0.9151485875625651
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4662711719676572: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2751  377   0.1205   (377.0/3128.0)
1      286   2763  0.0938   (286.0/3049.0)
Total  3037  3140  0.1073   (663.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.466271     0.892874  216
max f2                       0.19145      0.923378  298
max f0point5                 0.808549     0.905633  105
max accuracy                 0.474144     0.892828  214
max precision                0.978612     1         0
max recall                   0.0163163    1         394
max specificity              0.978612     1         0
max absolute_mcc             0.474144     0.785956  214
max min_per_class_accuracy   0.518892     0.89144   200
max mean_per_class_accuracy  0.474144     0.892976  214
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.16 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.97676            2.02591     2.02591            1                0.977899   1                           0.977899            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.975491           2.02591     2.02591            1                0.97602    1                           0.976959            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.974618           2.02591     2.02591            1                0.975005   1                           0.976308            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.973842           2.02591     2.02591            1                0.974229   1                           0.975788            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.973029           2.02591     2.02591            1                0.9734     1                           0.975317            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.969083           2.00624     2.01608            0.990291         0.971099   0.995146                    0.973208            0.100361        0.201705                   100.624   101.608
    7        0.150073                    0.963346           1.98657     2.00624            0.980583         0.966291   0.990291                    0.970902            0.0993768       0.301082                   98.6572   100.624
    8        0.200097                    0.953636           1.97346     1.99805            0.97411          0.958952   0.986246                    0.967915            0.0987209       0.399803                   97.3459   99.8046
    9        0.299984                    0.914619           1.91427     1.97015            0.944895         0.937545   0.972477                    0.957802            0.19121         0.591013                   91.4272   97.0151
    10       0.400032                    0.812999           1.76693     1.91933            0.872168         0.874422   0.94739                     0.936949            0.176779        0.767793                   76.6935   91.9326
    11       0.500081                    0.497517           1.29816     1.79505            0.640777         0.673557   0.886047                    0.884253            0.129879        0.897671                   29.8156   79.5052
    12       0.599968                    0.168789           0.646847    1.60389            0.319287         0.314738   0.791689                    0.789437            0.0646113       0.962283                   -35.3153  60.3891
    13       0.700016                    0.0580145          0.236028    1.40839            0.116505         0.101045   0.69519                     0.691049            0.0236143       0.985897                   -76.3972  40.8392
    14       0.799903                    0.0289599          0.101788    1.24523            0.0502431        0.0405279  0.614653                    0.609817            0.0101673       0.996064                   -89.8212  24.5232
    15       0.899951                    0.018015           0.0360599   1.11081            0.0177994        0.0225359  0.5483                      0.544528            0.00360774      0.999672                   -96.394   11.0807
    16       1                           0.0111867          0.00327817  1                  0.00161812       0.0154111  0.493605                    0.491591            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:00:43  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:00:50  2:54:08.154  1293 obs/sec      0.34644   1             8661       0.341515         0.449242            0.533468       0.925482        0.748079           2.003            0.149047                         0.330844           0.420159              0.562098         0.931736          0.760339             2.02591            0.146997
    2019-08-03 19:01:04  2:54:22.841  1291 obs/sec      1.04696   3             26174      0.316962         0.327065            0.598139       0.936528        0.900704           2.003            0.138564                         0.309137           0.312932              0.617675         0.941837          0.919547             2.02591            0.131294
    2019-08-03 19:01:19  2:54:37.388  1294 obs/sec      1.74532   5             43633      0.29983          0.294968            0.640408       0.946791        0.93445            2.003            0.121693                         0.292188           0.281543              0.658448         0.9518            0.935053             2.02591            0.1164
    2019-08-03 19:01:34  2:54:52.181  1283 obs/sec      2.43476   7             60869      0.298131         0.293562            0.644472       0.947888        0.939822           2.003            0.121194                         0.290463           0.2801                0.66247          0.952363          0.940624             2.02591            0.117371
    2019-08-03 19:01:49  2:55:07.133  1279 obs/sec      3.1308    9             78270      0.29743          0.292874            0.64614        0.948946        0.935173           2.003            0.120695                         0.290066           0.277987              0.663392         0.953891          0.944315             2.02591            0.114295
    2019-08-03 19:02:05  2:55:23.231  1257 obs/sec      3.8274    11            95685      0.296307         0.289892            0.648808       0.950009        0.942464           2.003            0.118299                         0.287757           0.274869              0.668729         0.954791          0.945151             2.02591            0.112352
    2019-08-03 19:02:20  2:55:38.331  1256 obs/sec      4.52172   13            113043     0.297705         0.294475            0.645486       0.950586        0.941508           2.003            0.120495                         0.288578           0.278126              0.666836         0.955321          0.949086             2.02591            0.1096
    2019-08-03 19:02:35  2:55:53.211  1257 obs/sec      5.21976   15            130494     0.294601         0.288345            0.652839       0.951857        0.947597           2.003            0.119397                         0.285686           0.27246               0.673481         0.956584          0.94977              2.02591            0.110571
    2019-08-03 19:02:50  2:56:08.051  1258 obs/sec      5.91448   17            147862     0.292043         0.282593            0.658843       0.95244         0.951142           1.98317          0.1179                           0.282785           0.26718               0.680079         0.957574          0.945751             2.02591            0.107334
    2019-08-03 19:03:04  2:56:22.791  1259 obs/sec      6.6074    19            165185     0.298195         0.295343            0.644318       0.949942        0.939806           2.003            0.117999                         0.288543           0.278013              0.666916         0.955172          0.943861             1.99323            0.111057
    2019-08-03 19:03:19  2:56:37.530  1260 obs/sec      7.2982    21            182455     0.294064         0.288131            0.654104       0.951362        0.948732           2.003            0.121194                         0.285317           0.274441              0.674324         0.955982          0.951029             2.02591            0.108467
    2019-08-03 19:03:34  2:56:52.128  1262 obs/sec      7.9904    23            199760     0.294819         0.28898             0.652327       0.951216        0.948182           2.003            0.119098                         0.286264           0.274476              0.672157         0.955888          0.949102             1.99323            0.11041
    2019-08-03 19:03:48  2:57:07.019  1262 obs/sec      8.68464   25            217116     0.292908         0.285153            0.65682        0.952652        0.94622            1.98317          0.120894                         0.284              0.271061              0.677324         0.956932          0.949157             1.99323            0.108467
    2019-08-03 19:04:03  2:57:21.895  1263 obs/sec      9.38832   27            234708     0.294755         0.289487            0.652477       0.952018        0.948451           2.003            0.119896                         0.286835           0.276443              0.67085          0.95541           0.948149             1.99323            0.11041
    2019-08-03 19:04:18  2:57:36.678  1265 obs/sec      10.0905   29            252263     0.29583          0.290759            0.649937       0.952153        0.943574           2.003            0.119597                         0.287114           0.276008              0.670208         0.956442          0.947144             1.99323            0.110248
    2019-08-03 19:04:19  2:57:37.824  1265 obs/sec      10.0905   29            252263     0.292043         0.282593            0.658843       0.95244         0.951142           1.98317          0.1179                           0.282785           0.26718               0.680079         0.957574          0.945751             2.02591            0.107334
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005808558479437433
C438        0.8361102938652039     0.8361102938652039   0.004856595537175653
C88         0.7017707228660583     0.7017707228660583   0.00407627628292458
C374        0.6803339123725891     0.6803339123725891   0.003951759315560645
C863        0.6518436670303345     0.6518436670303345   0.0037862720593966398
---         ---                    ---                  ---
C982        0.0979703813791275     0.0979703813791275   0.0005690666894934502
C762        0.0967845544219017     0.0967845544219017   0.0005621787442659108
C917        0.09656034409999847    0.09656034409999847  0.0005608764054994424
C911        0.0960048958659172     0.0960048958659172   0.0005576500519494811
C879        0.09348156303167343    0.09348156303167343  0.0005429931256186915

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_224

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 254,740 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate            rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  -------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.05964483882201337  0.07901719212532043    0.0         0.00048689493009715086  0.10182276368141174  -0.002722447084897386  0.11758068203926086
    3        2        Softmax                 0.0   0.0   0.00198970707879198  0.0005770116113126278  0.0         0.016256250433173136    0.24614226818084717  -0.017583858615580737  0.06798645853996277


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0874122795330068
RMSE: 0.2956556773224671
LogLoss: 0.2901218872324007
Mean Per-Class Error: 0.11653632333638053
AUC: 0.9508364169256214
pr_auc: 0.9408336400597255
Gini: 0.9016728338512427
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5024598155863678: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4270  696   0.1402   (696.0/4966.0)
1      470   4576  0.0931   (470.0/5046.0)
Total  4740  5272  0.1165   (1166.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.50246      0.886994  203
max f2                       0.156122     0.921719  312
max f0point5                 0.837296     0.897477  95
max accuracy                 0.564123     0.88354   187
max precision                0.986665     1         0
max recall                   0.00985968   1         399
max specificity              0.986665     1         0
max absolute_mcc             0.50246      0.767764  203
max min_per_class_accuracy   0.607937     0.881796  175
max mean_per_class_accuracy  0.564123     0.883464  187
Gains/Lift Table: Avg response rate: 50.40 %, avg score: 52.13 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   0.985572           1.98415    1.98415            1                0.9862     1                           0.9862              0.0200159       0.0200159                  98.4146   98.4146
    2        0.0200759                   0.984773           1.9643     1.97427            0.99             0.985122   0.995025                    0.985664            0.0196195       0.0396354                  96.4304   97.4274
    3        0.0300639                   0.984185           1.98415    1.97755            1                0.984477   0.996678                    0.985269            0.0198177       0.059453                   98.4146   97.7554
    4        0.0400519                   0.983569           1.9643     1.97425            0.99             0.983854   0.995012                    0.984916            0.0196195       0.0790725                  96.4304   97.425
    5        0.05004                     0.983096           1.9643     1.97226            0.99             0.983336   0.994012                    0.984601            0.0196195       0.098692                   96.4304   97.2265
    6        0.10008                     0.980256           1.96434    1.9683             0.99002          0.981706   0.992016                    0.983153            0.0982957       0.196988                   96.4344   96.8304
    7        0.15002                     0.97639            1.94049    1.95905            0.978            0.978467   0.98735                     0.981593            0.0969084       0.293896                   94.0495   95.9047
    8        0.20006                     0.971178           1.90098    1.94452            0.958084         0.97394    0.98003                     0.979679            0.0951249       0.389021                   90.0978   94.4522
    9        0.30004                     0.94957            1.86918    1.91942            0.942058         0.962291   0.967377                    0.973885            0.186881        0.575902                   86.918    91.9417
    10       0.40002                     0.875756           1.72052    1.8697             0.867133         0.920087   0.942322                    0.960439            0.172017        0.747919                   72.0518   86.9704
    11       0.5                         0.617623           1.30823    1.75743            0.659341         0.768302   0.885737                    0.922019            0.130797        0.878716                   30.8228   75.7432
    12       0.59998                     0.230615           0.757187   1.59075            0.381618         0.410383   0.801731                    0.836761            0.0757035       0.954419                   -24.2813  59.0752
    13       0.69996                     0.0608213          0.287414   1.40459            0.144855         0.122625   0.707905                    0.734756            0.0287356       0.983155                   -71.2586  40.4587
    14       0.79994                     0.024898           0.111001   1.24291            0.0559441        0.0389238  0.62642                     0.647788            0.0110979       0.994253                   -88.8999  24.2909
    15       0.89992                     0.0147214          0.0416254  1.10945            0.020979         0.0187559  0.559156                    0.577903            0.00416171      0.998415                   -95.8375  10.9448
    16       1                           0.00916842         0.0158415  1                  0.00798403       0.0125087  0.503995                    0.521318            0.00158541      1                          -98.4159  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08039740656445908
RMSE: 0.2835443643673051
LogLoss: 0.2682265069404495
Mean Per-Class Error: 0.10759014737128192
AUC: 0.95753329673307
pr_auc: 0.9477816517690162
Gini: 0.9150665934661399
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45710304027467685: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2704  424   0.1355   (424.0/3128.0)
1      247   2802  0.081    (247.0/3049.0)
Total  2951  3226  0.1086   (671.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.457103     0.893068  212
max f2                       0.207054     0.924418  286
max f0point5                 0.859463     0.906778  88
max accuracy                 0.659347     0.892343  156
max precision                0.986906     1         0
max recall                   0.0139351    1         393
max specificity              0.986906     1         0
max absolute_mcc             0.659347     0.784951  156
max min_per_class_accuracy   0.57928      0.890784  179
max mean_per_class_accuracy  0.55539      0.89241   185
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.79 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.985633           2.02591     2.02591            1                0.986326   1                           0.986326            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.984803           2.02591     2.02591            1                0.985179   1                           0.985753            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.98425            2.02591     2.02591            1                0.984518   1                           0.985341            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.983675           1.99323     2.01774            0.983871         0.983974   0.995968                    0.984999            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.983166           2.02591     2.01935            1                0.983432   0.996764                    0.98469             0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.980335           1.99968     2.00952            0.987055         0.981851   0.991909                    0.98327             0.100033        0.20105                    99.9685   100.952
    7        0.150073                    0.976359           1.98657     2.00187            0.980583         0.978505   0.988134                    0.981682            0.0993768       0.300426                   98.6572   100.187
    8        0.200097                    0.970379           1.98657     1.99805            0.980583         0.973698   0.986246                    0.979686            0.0993768       0.399803                   98.6572   99.8046
    9        0.299984                    0.94659            1.92084     1.97234            0.948136         0.960865   0.973556                    0.973419            0.191866        0.591669                   92.0839   97.2338
    10       0.400032                    0.86205            1.77021     1.92179            0.873786         0.913007   0.948604                    0.95831             0.177107        0.768777                   77.0213   92.1786
    11       0.500081                    0.555694           1.28832     1.79505            0.635922         0.734686   0.886047                    0.913571            0.128895        0.897671                   28.8321   79.5052
    12       0.599968                    0.180678           0.656697    1.60553            0.324149         0.343774   0.792499                    0.818707            0.0655953       0.963267                   -34.3303  60.5531
    13       0.700016                    0.0544783          0.222916    1.40792            0.110032         0.101718   0.694958                    0.716233            0.0223024       0.985569                   -77.7084  40.7923
    14       0.799903                    0.0231113          0.111638    1.24605            0.0551053        0.0350898  0.615058                    0.631176            0.0111512       0.99672                    -88.8362  24.6052
    15       0.899951                    0.014531           0.0262254   1.11044            0.012945         0.0180462  0.54812                     0.563014            0.00262381      0.999344                   -97.3775  11.0442
    16       1                           0.00885861         0.00655634  1                  0.00323625       0.0124457  0.493605                    0.50793             0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:41:13  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:41:20  4:34:38.856  1238 obs/sec      0.33992   1             8498       0.341034         0.431056            0.534753       0.923285        0.796079           1.98415          0.152217                         0.331258           0.399743              0.560999         0.930652          0.775894             2.02591            0.143273
    2019-08-03 20:41:35  4:34:53.179  1272 obs/sec      1.02216   3             25554      0.305543         0.305802            0.62655        0.942914        0.922234           1.98415          0.128046                         0.297731           0.291932              0.645368         0.94793           0.925313             2.02591            0.120447
    2019-08-03 20:41:49  4:35:07.856  1264 obs/sec      1.69564   5             42391      0.317937         0.327052            0.595637       0.93577         0.928464           1.98415          0.138734                         0.311752           0.314592              0.61118          0.940737          0.929123             2.02591            0.133236
    2019-08-03 20:42:04  4:35:22.432  1266 obs/sec      2.37868   7             59467      0.299411         0.294542            0.641388       0.947293        0.942249           1.98415          0.123252                         0.292825           0.281692              0.656957         0.951922          0.942714             2.02591            0.121094
    2019-08-03 20:42:19  4:35:37.218  1265 obs/sec      3.06564   9             76641      0.298198         0.292601            0.644289       0.947634        0.932914           1.98415          0.122853                         0.290528           0.279162              0.662318         0.952581          0.942907             2.02591            0.116076
    2019-08-03 20:42:33  4:35:51.649  1266 obs/sec      3.74324   11            93581      0.296236         0.29059             0.648955       0.948313        0.942281           1.98415          0.120955                         0.288054           0.276044              0.668046         0.953765          0.946521             2.02591            0.109276
    2019-08-03 20:42:48  4:36:06.312  1266 obs/sec      4.42092   13            110523     0.295662         0.290004            0.650313       0.949014        0.941315           1.94486          0.117359                         0.285525           0.272905              0.673849         0.955007          0.946016             1.99323            0.108143
    2019-08-03 20:43:04  4:36:22.213  1251 obs/sec      5.10316   15            127579     0.294935         0.289275            0.652031       0.949892        0.94375            1.98415          0.117159                         0.285522           0.273204              0.673855         0.955952          0.949566             2.02591            0.109276
    2019-08-03 20:43:18  4:36:36.866  1252 obs/sec      5.779     17            144475     0.295656         0.290122            0.650329       0.950836        0.940834           1.98415          0.11646                          0.283544           0.268227              0.678358         0.957533          0.947782             2.02591            0.108629
    2019-08-03 20:43:33  4:36:51.406  1254 obs/sec      6.46312   19            161578     0.296487         0.297283            0.648359       0.950146        0.948958           1.98415          0.120455                         0.286503           0.281745              0.67161          0.956377          0.952881             2.02591            0.108305
    2019-08-03 20:43:47  4:37:05.974  1255 obs/sec      7.14072   21            178518     0.295787         0.289408            0.650017       0.95055         0.946832           1.9645           0.119257                         0.285395           0.27138               0.674146         0.956681          0.953291             1.99323            0.11041
    2019-08-03 20:44:02  4:37:20.272  1258 obs/sec      7.8162    23            195405     0.295146         0.288441            0.651534       0.950672        0.947229           1.98415          0.119157                         0.284608           0.271038              0.675941         0.956939          0.952242             1.99323            0.109438
    2019-08-03 20:44:16  4:37:34.832  1258 obs/sec      8.4922    25            212305     0.297041         0.292223            0.647044       0.949502        0.941409           1.98415          0.120455                         0.28744            0.275433              0.66946          0.955637          0.952705             2.02591            0.110733
    2019-08-03 20:44:31  4:37:49.477  1257 obs/sec      9.1634    27            229085     0.298346         0.296857            0.643935       0.94805         0.943448           1.9645           0.122253                         0.28677            0.277945              0.670999         0.954855          0.951279             2.02591            0.109276
    2019-08-03 20:44:46  4:38:04.290  1257 obs/sec      9.85008   29            246252     0.29689          0.292529            0.647404       0.950054        0.943344           1.98415          0.119457                         0.28537            0.27274               0.674202         0.956117          0.951271             2.02591            0.109438
    2019-08-03 20:44:53  4:38:11.928  1259 obs/sec      10.1896   30            254740     0.296768         0.292772            0.647692       0.950785        0.94134            1.9645           0.118857                         0.287751           0.275221              0.668743         0.956417          0.949292             1.99323            0.113647
    2019-08-03 20:44:55  4:38:13.073  1259 obs/sec      10.1896   30            254740     0.295656         0.290122            0.650329       0.950836        0.940834           1.98415          0.11646                          0.283544           0.268227              0.678358         0.957533          0.947782             2.02591            0.108629
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006084994564709199
C438        0.8461354970932007     0.8461354970932007   0.005148729900819642
C374        0.754774808883667      0.754774808883667    0.0045928006096365385
C88         0.6489911675453186     0.6489911675453186   0.003949107727057541
C863        0.6403589248657227     0.6403589248657227   0.0038965805772709487
---         ---                    ---                  ---
C916        0.08994005620479584    0.08994005620479584  0.0005472847531558225
C703        0.0891558900475502     0.0891558900475502   0.000542513106351154
C921        0.08840997517108917    0.08840997517108917  0.0005379742183821528
C972        0.08788599818944931    0.08788599818944931  0.0005347858212968416
C801        0.08754147589206696    0.08754147589206696  0.0005326894049898488

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_37

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 202,880 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.03914657923187963    0.06650400161743164     0.0         0.0015012517511538773  0.07987070083618164  -0.0030340778685943037  0.09433981776237488
    3        2        Softmax                 0.0   0.0   0.0017762768839020282  0.00036033603828400373  0.0         -0.043867289501577034  0.37527430057525635  0.0015335069425350956   0.1098807156085968


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0881930859114552
RMSE: 0.2969732073966525
LogLoss: 0.29068958028202824
Mean Per-Class Error: 0.12001802687936902
AUC: 0.9493342364682886
pr_auc: 0.9359202373203703
Gini: 0.8986684729365773
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3854925423798247: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4125  822   0.1662   (822.0/4947.0)
1      425   4654  0.0837   (425.0/5079.0)
Total  4550  5476  0.1244   (1247.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.385493     0.881857  235
max f2                       0.163595     0.918819  309
max f0point5                 0.74905      0.896857  124
max accuracy                 0.521854     0.880012  196
max precision                0.978352     1         0
max recall                   0.0144103    1         398
max specificity              0.978352     1         0
max absolute_mcc             0.521854     0.759979  196
max min_per_class_accuracy   0.533884     0.879725  193
max mean_per_class_accuracy  0.521854     0.879982  196
Gains/Lift Table: Avg response rate: 50.66 %, avg score: 50.36 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.977541           1.97401     1.97401            1                0.978161   1                           0.978161            0.0198858       0.0198858                  97.4011   97.4011
    2        0.0200479                   0.976515           1.97401     1.97401            1                0.976997   1                           0.977582            0.0196889       0.0395747                  97.4011   97.4011
    3        0.0300219                   0.975765           1.95427     1.96745            0.99             0.976112   0.996678                    0.977093            0.019492        0.0590667                  95.4271   96.7452
    4        0.0400958                   0.97494            1.97401     1.9691             1                0.975356   0.997512                    0.976657            0.0198858       0.0789525                  97.4011   96.91
    5        0.0500698                   0.974146           1.97401     1.97008            1                0.974505   0.998008                    0.976228            0.0196889       0.0986415                  97.4011   97.0078
    6        0.10004                     0.968785           1.94643     1.95827            0.986028         0.971679   0.992024                    0.973956            0.0972632       0.195905                   94.643    95.8266
    7        0.15001                     0.961727           1.93067     1.94907            0.978044         0.965464   0.987367                    0.971127            0.0964757       0.29238                    93.0669   94.9073
    8        0.20008                     0.951625           1.92682     1.9435             0.976096         0.95684    0.984546                    0.967552            0.0964757       0.388856                   92.6823   94.3505
    9        0.30002                     0.914751           1.85384     1.91364            0.939122         0.935757   0.969415                    0.956961            0.185273        0.574129                   85.3836   91.3635
    10       0.40006                     0.806579           1.69848     1.85983            0.860419         0.870788   0.942159                    0.935412            0.169915        0.744044                   69.8476   85.9832
    11       0.5                         0.551672           1.29828     1.74759            0.657685         0.69586    0.885298                    0.88753             0.12975         0.873794                   29.8276   74.7588
    12       0.60004                     0.229001           0.759689    1.58288            0.384845         0.375195   0.801862                    0.802113            0.0759992       0.949793                   -24.0311  58.2884
    13       0.69998                     0.0744354          0.327032    1.40358            0.165669         0.135294   0.711029                    0.706907            0.0326836       0.982477                   -67.2968  40.3578
    14       0.80002                     0.0311454          0.11415     1.24234            0.0578265        0.0482156  0.629348                    0.62454             0.0114196       0.993896                   -88.585   24.234
    15       0.89996                     0.0184468          0.0512218   1.11007            0.0259481        0.0235519  0.562341                    0.557801            0.00511912      0.999016                   -94.8778  11.0066
    16       1                           0.0132919          0.00984053  1                  0.00498504       0.015894   0.506583                    0.503588            0.000984446     1                          -99.0159  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08050191318719485
RMSE: 0.28372859071160744
LogLoss: 0.2682937411587779
Mean Per-Class Error: 0.10778726872841626
AUC: 0.957045211670591
pr_auc: 0.9391935711712206
Gini: 0.914090423341182
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5157167849619275: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2783  345   0.1103   (345.0/3128.0)
1      321   2728  0.1053   (321.0/3049.0)
Total  3104  3073  0.1078   (666.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.515717     0.891212  201
max f2                       0.167357     0.922889  308
max f0point5                 0.767168     0.906699  121
max accuracy                 0.515717     0.892181  201
max precision                0.978311     1         0
max recall                   0.0145384    1         398
max specificity              0.978311     1         0
max absolute_mcc             0.515717     0.784371  201
max min_per_class_accuracy   0.529364     0.891112  198
max mean_per_class_accuracy  0.515717     0.892213  201
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.30 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.977552           2.02591     2.02591            1                0.978194   1                           0.978194            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.976647           2.02591     2.02591            1                0.977091   1                           0.977642            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.975944           2.02591     2.02591            1                0.976314   1                           0.977199            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.975173           2.02591     2.02591            1                0.97561    1                           0.976802            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.97419            2.02591     2.02591            1                0.974715   1                           0.97639             0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.969148           1.99313     2.00952            0.983819         0.971783   0.991909                    0.974087            0.0997048       0.20105                    99.3128   100.952
    7        0.150073                    0.962245           1.99968     2.00624            0.987055         0.965868   0.990291                    0.971347            0.100033        0.301082                   99.9685   100.624
    8        0.200097                    0.951696           1.98002     1.99968            0.977346         0.956904   0.987055                    0.967736            0.0990489       0.400131                   98.0016   99.9685
    9        0.299984                    0.907656           1.91427     1.97124            0.944895         0.932625   0.973017                    0.956045            0.19121         0.591341                   91.4272   97.1244
    10       0.400032                    0.797948           1.74399     1.91441            0.860841         0.861354   0.944962                    0.932363            0.174483        0.765825                   74.3987   91.4407
    11       0.500081                    0.503563           1.29816     1.79112            0.640777         0.668648   0.884105                    0.879603            0.129879        0.895704                   29.8156   79.1117
    12       0.599968                    0.188322           0.656697    1.60225            0.324149         0.332606   0.79088                     0.788535            0.0655953       0.961299                   -34.3303  60.2251
    13       0.700016                    0.0641346          0.258976    1.41027            0.127832         0.116698   0.696115                    0.692514            0.0259101       0.987209                   -74.1024  41.0266
    14       0.799903                    0.0303436          0.0853706   1.24482            0.0421394        0.0437844  0.614451                    0.611505            0.00852739      0.995736                   -91.4629  24.4822
    15       0.899951                    0.0182441          0.0393381   1.11081            0.0194175        0.0232117  0.5483                      0.546104            0.00393572      0.999672                   -96.0662  11.0807
    16       1                           0.0134984          0.00327817  1                  0.00161812       0.0157746  0.493605                    0.493045            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:47:04  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:47:11  40 min 28.592 sec  2459 obs/sec      0.62212   1             15553      0.322103         0.360307            0.584927       0.935086        0.834435           1.97401          0.138839                         0.313278           0.340658              0.607362         0.940279          0.853196             2.02591            0.128379
    2019-08-03 16:47:17  40 min 35.236 sec  2500 obs/sec      1.24448   2             31112      0.305444         0.306522            0.626751       0.942579        0.922943           1.97401          0.128965                         0.294446           0.286864              0.653149         0.949866          0.927636             2.02591            0.118504
    2019-08-03 16:47:24  40 min 42.081 sec  2497 obs/sec      1.87224   3             46806      0.30252          0.299193            0.633864       0.945206        0.930631           1.97401          0.126471                         0.289917           0.278492              0.663737         0.952594          0.939199             2.02591            0.113324
    2019-08-03 16:47:31  40 min 48.860 sec  2497 obs/sec      2.4956    4             62390      0.297286         0.291193            0.646422       0.948643        0.93581            1.97401          0.121384                         0.286456           0.272373              0.671717         0.955454          0.935696             2.02591            0.109762
    2019-08-03 16:47:38  40 min 55.672 sec  2500 obs/sec      3.11944   5             77986      0.296973         0.29069             0.647166       0.949334        0.93592            1.97401          0.124377                         0.283729           0.268294              0.67794          0.957045          0.939194             2.02591            0.107819
    2019-08-03 16:47:45  41 min  2.500 sec  2498 obs/sec      3.7418    6             93545      0.296719         0.290882            0.647771       0.949402        0.937899           1.95447          0.121783                         0.28334            0.268755              0.678822         0.956903          0.950332             2.02591            0.106362
    2019-08-03 16:47:51  41 min  9.273 sec  2498 obs/sec      4.36608   7             109152     0.296902         0.292011            0.647335       0.949705        0.946028           1.97401          0.122282                         0.285686           0.272359              0.67348          0.956223          0.950365             2.02591            0.114943
    2019-08-03 16:47:58  41 min 16.092 sec  2498 obs/sec      4.98952   8             124738     0.297986         0.295153            0.644755       0.949153        0.932706           1.97401          0.11909                          0.285593           0.273377              0.673693         0.955867          0.927558             2.02591            0.111057
    2019-08-03 16:48:05  41 min 22.921 sec  2497 obs/sec      5.61104   9             140276     0.297682         0.295249            0.645481       0.948986        0.920102           1.97401          0.118791                         0.285631           0.273835              0.673607         0.955864          0.948905             2.02591            0.113324
    2019-08-03 16:48:12  41 min 29.782 sec  2495 obs/sec      6.23516   10            155879     0.297795         0.296659            0.645211       0.949145        0.939789           1.97401          0.117096                         0.285071           0.274522              0.674884         0.956558          0.949024             2.02591            0.108305
    2019-08-03 16:48:18  41 min 36.508 sec  2501 obs/sec      6.85976   11            171494     0.298362         0.298152            0.643859       0.948001        0.940736           1.93492          0.118492                         0.285582           0.275356              0.673719         0.955278          0.940046             2.02591            0.108467
    2019-08-03 16:48:25  41 min 43.105 sec  2507 obs/sec      7.48788   12            187197     0.299573         0.300945            0.640961       0.946869        0.931358           1.95447          0.118891                         0.287142           0.279434              0.670143         0.954431          0.9394               1.99323            0.108791
    2019-08-03 16:48:32  41 min 49.728 sec  2514 obs/sec      8.1152    13            202880     0.300247         0.303622            0.639344       0.946112        0.941447           1.91538          0.119589                         0.287416           0.281704              0.669513         0.954446          0.946937             1.99323            0.108953
    2019-08-03 16:48:32  41 min 50.298 sec  2513 obs/sec      8.1152    13            202880     0.296973         0.29069             0.647166       0.949334        0.93592            1.97401          0.124377                         0.283729           0.268294              0.67794          0.957045          0.939194             2.02591            0.107819
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005617572793242506
C438        0.8728705644607544     0.8728705644607544   0.004903413934936963
C374        0.7733389139175415     0.7733389139175415   0.00434428764277889
C88         0.7018316984176636     0.7018316984176636   0.003942590654466246
C322        0.6962366104125977     0.6962366104125977   0.0039111598403131905
---         ---                    ---                  ---
C968        0.10655057430267334    0.10655057430267334  0.0005985556073070618
C818        0.10603167861700058    0.10603167861700058  0.0005956406730206956
C899        0.1056891456246376     0.1056891456246376   0.0005937164690020094
C338        0.1028837338089943     0.1028837338089943   0.0005779568639126105
C961        0.10227114707231522    0.10227114707231522  0.0005745156133271409

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_69

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 253,575 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0509876415505506     0.06651660799980164    0.0         0.00034660809116954147  0.09461212158203125  0.00456566313834655    0.11158177256584167
    3        2        Softmax                 0.0   0.0   0.0023315691655625415  0.0008002570830285549  0.0         -0.04002410385204058    0.23991596698760986  0.0032665862710797647  0.10338151454925537


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08562218572835718
RMSE: 0.292612688939419
LogLoss: 0.28320903338084696
Mean Per-Class Error: 0.11611165605776796
AUC: 0.9519880502276914
pr_auc: 0.9456468761719716
Gini: 0.9039761004553828
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.506457732233044: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4269  676   0.1367   (676.0/4945.0)
1      493   4593  0.0969   (493.0/5086.0)
Total  4762  5269  0.1165   (1169.0/10031.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.506458     0.887108  201
max f2                       0.136075     0.921479  320
max f0point5                 0.778071     0.901341  115
max accuracy                 0.657493     0.883561  156
max precision                0.982483     1         0
max recall                   0.0136619    1         397
max specificity              0.982483     1         0
max absolute_mcc             0.657493     0.768193  156
max min_per_class_accuracy   0.579084     0.88271   179
max mean_per_class_accuracy  0.657493     0.883888  156
Gains/Lift Table: Avg response rate: 50.70 %, avg score: 51.50 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100688                   0.980508           1.97228    1.97228            1                0.981536   1                           0.981536            0.0198584       0.0198584                  97.2277   97.2277
    2        0.0200379                   0.979269           1.97228    1.97228            1                0.979822   1                           0.980684            0.0196618       0.0395203                  97.2277   97.2277
    3        0.030007                    0.978346           1.97228    1.97228            1                0.978809   1                           0.980061            0.0196618       0.0591821                  97.2277   97.2277
    4        0.0400758                   0.977398           1.93322    1.96246            0.980198         0.977864   0.995025                    0.979509            0.0194652       0.0786473                  93.3222   96.2465
    5        0.0500449                   0.976612           1.93283    1.95656            0.98             0.977002   0.992032                    0.979009            0.0192686       0.0979158                  93.2831   95.6561
    6        0.10009                     0.972155           1.96049    1.95853            0.994024         0.974435   0.993028                    0.976722            0.0981125       0.196028                   96.049    95.8526
    7        0.150035                    0.966631           1.94078    1.95262            0.984032         0.969658   0.990033                    0.974371            0.0969328       0.292961                   94.0783   95.262
    8        0.20008                     0.958218           1.90549    1.94083            0.966135         0.962565   0.984056                    0.971418            0.0953598       0.388321                   90.5487   94.083
    9        0.30007                     0.926089           1.85823    1.91331            0.942173         0.944991   0.9701                      0.962612            0.185804        0.574125                   85.8227   91.3305
    10       0.40006                     0.834332           1.72451    1.86612            0.874377         0.88891    0.946175                    0.944191            0.172434        0.746559                   72.4513   86.6119
    11       0.50005                     0.597694           1.30174    1.75327            0.66002          0.731543   0.888955                    0.90167             0.130161        0.87672                    30.1742   75.3266
    12       0.60004                     0.242899           0.757055   1.58726            0.383848         0.414577   0.804785                    0.820501            0.075698        0.952418                   -24.2945  58.7259
    13       0.70003                     0.0752792          0.322486   1.4066             0.163509         0.139569   0.713187                    0.723239            0.0322454       0.984664                   -67.7514  40.6602
    14       0.80002                     0.030912           0.100285   1.24333            0.0508475        0.0490436  0.630405                    0.638975            0.0100275       0.994691                   -89.9715  24.3333
    15       0.90001                     0.0181048          0.0412939  1.10979            0.0209372        0.0233046  0.562694                    0.570575            0.00412898      0.99882                    -95.8706  10.9788
    16       1                           0.0108604          0.0117983  1                  0.00598205       0.0150145  0.507028                    0.515024            0.00117971      1                          -98.8202  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08055922469951618
RMSE: 0.28382956981173785
LogLoss: 0.26848684254047184
Mean Per-Class Error: 0.10918447119889207
AUC: 0.9571356463357655
pr_auc: 0.9495820096106236
Gini: 0.9142712926715311
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4607579603586978: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2703  425   0.1359   (425.0/3128.0)
1      257   2792  0.0843   (257.0/3049.0)
Total  2960  3217  0.1104   (682.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.460758     0.891159  216
max f2                       0.189022     0.923333  296
max f0point5                 0.780718     0.905488  118
max accuracy                 0.630841     0.890724  166
max precision                0.982649     1         0
max recall                   0.0185977    1         389
max specificity              0.982649     1         0
max absolute_mcc             0.630841     0.781817  166
max min_per_class_accuracy   0.549822     0.890128  189
max mean_per_class_accuracy  0.52366      0.890816  196
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.16 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.980479           2.02591    2.02591            1                0.981584   1                           0.981584            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.979131           2.02591    2.02591            1                0.979791   1                           0.980687            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.97838            1.99323    2.01502            0.983871         0.978717   0.994624                    0.980031            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.977415           2.02591    2.01774            1                0.977866   0.995968                    0.979489            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.976594           1.95949    2.00624            0.967213         0.97705    0.990291                    0.979008            0.0193506       0.100361                   95.9487   100.624
    6        0.100049                    0.971986           2.01935    2.0128             0.996764         0.974319   0.993528                    0.976664            0.101017        0.201378                   101.935   101.28
    7        0.150073                    0.966061           2.00624    2.01061            0.990291         0.969365   0.992449                    0.974231            0.100361        0.301738                   100.624   101.061
    8        0.200097                    0.957735           1.9669     1.99968            0.970874         0.962329   0.987055                    0.971255            0.0983929       0.400131                   96.6903   99.9685
    9        0.299984                    0.920567           1.91099    1.97015            0.943274         0.941893   0.972477                    0.961479            0.190882        0.591013                   91.0988   97.0151
    10       0.400032                    0.823465           1.73743    1.91195            0.857605         0.88156    0.943747                    0.941491            0.173827        0.764841                   73.7431   91.1948
    11       0.500081                    0.532725           1.29816    1.78915            0.640777         0.700028   0.883134                    0.893183            0.129879        0.89472                    29.8156   78.915
    12       0.599968                    0.196687           0.679681   1.60444            0.335494         0.35152    0.791959                    0.803003            0.0678911       0.962611                   -32.0319  60.4438
    13       0.700016                    0.0653664          0.226194   1.40745            0.11165          0.116674   0.694727                    0.704911            0.0226304       0.985241                   -77.3806  40.7455
    14       0.799903                    0.0293645          0.114922   1.24605            0.0567261        0.0438982  0.615058                    0.622368            0.0114792       0.99672                    -88.5078  24.6052
    15       0.899951                    0.0177105          0.0327817  1.11117            0.0161812        0.022339   0.54848                     0.555662            0.00327976      1                          -96.7218  11.1171
    16       1                           0.0103708          0          1                  0                0.0148917  0.493605                    0.501559            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:20:59  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:21:08  1:14:27.451  1275 obs/sec      0.42152   1             10538      0.324419         0.35869             0.578925       0.931552        0.866978           1.97228          0.139667                         0.31804            0.340333              0.595337         0.936824          0.866757             2.02591            0.135826
    2019-08-03 17:21:35  1:14:53.784  1258 obs/sec      1.69152   4             42288      0.300758         0.297904            0.638108       0.945841        0.940173           1.97228          0.12272                          0.294543           0.285946              0.652922         0.95057           0.94001              2.02591            0.118666
    2019-08-03 17:21:53  1:15:11.149  1269 obs/sec      2.5318    6             63295      0.297204         0.291565            0.646609       0.948397        0.946243           1.97228          0.121224                         0.289839           0.279022              0.663919         0.952771          0.945935             2.02591            0.113324
    2019-08-03 17:22:10  1:15:28.891  1270 obs/sec      3.38324   8             84581      0.297457         0.292146            0.646008       0.948224        0.940159           1.97228          0.121822                         0.28937            0.277465              0.665005         0.953444          0.942707             2.02591            0.115428
    2019-08-03 17:22:28  1:15:46.543  1272 obs/sec      4.23008   10            105752     0.294366         0.287443            0.653326       0.950098        0.942784           1.95275          0.118632                         0.28633            0.273295              0.672007         0.95507           0.946199             2.02591            0.110895
    2019-08-03 17:22:46  1:16:04.087  1272 obs/sec      5.07116   12            126779     0.292613         0.283209            0.657444       0.951988        0.945647           1.97228          0.116539                         0.28383            0.268487              0.67771          0.957136          0.949582             2.02591            0.11041
    2019-08-03 17:23:03  1:16:21.849  1273 obs/sec      5.92344   14            148086     0.296977         0.294253            0.647149       0.949346        0.937902           1.95275          0.117237                         0.288959           0.279155              0.665957         0.954199          0.937972             1.99323            0.112514
    2019-08-03 17:23:21  1:16:39.222  1275 obs/sec      6.7676    16            169190     0.296049         0.291102            0.64935        0.948978        0.946083           1.97228          0.118233                         0.286452           0.273495              0.671728         0.955412          0.950443             2.02591            0.114619
    2019-08-03 17:23:38  1:16:56.706  1277 obs/sec      7.6122    18            190305     0.293344         0.286239            0.655729       0.951132        0.946726           1.97228          0.112651                         0.286356           0.271918              0.671946         0.956744          0.952419             2.02591            0.113647
    2019-08-03 17:23:56  1:17:14.211  1277 obs/sec      8.45988   20            211497     0.293198         0.286894            0.656072       0.950624        0.947687           1.93322          0.115642                         0.28454            0.270636              0.676095         0.956922          0.948886             2.02591            0.108305
    2019-08-03 17:24:13  1:17:31.413  1279 obs/sec      9.2964    22            232410     0.291979         0.284601            0.658926       0.952446        0.944793           1.97228          0.113747                         0.283184           0.268897              0.679176         0.958376          0.95007              2.02591            0.110733
    2019-08-03 17:24:31  1:17:49.136  1278 obs/sec      10.143    24            253575     0.295387         0.291788            0.650917       0.949585        0.948008           1.97228          0.117137                         0.286608           0.27492               0.671371         0.955253          0.950919             2.02591            0.111381
    2019-08-03 17:24:32  1:17:50.169  1278 obs/sec      10.143    24            253575     0.292613         0.283209            0.657444       0.951988        0.945647           1.97228          0.116539                         0.28383            0.268487              0.67771          0.957136          0.949582             2.02591            0.11041
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005591276037918243
C438        0.88200443983078       0.88200443983078     0.0049315302897633435
C374        0.7642438411712646     0.7642438411712646   0.0042730982762674875
C88         0.7041861414909363     0.7041861414909363   0.003937299099152377
C322        0.6684464812278748     0.6684464812278748   0.0037374687931201827
---         ---                    ---                  ---
C443        0.10246092081069946    0.10246092081069946  0.0005728872913519026
C913        0.10148467123508453    0.10148467123508453  0.0005674288104927389
C953        0.10021311789751053    0.10021311789751053  0.0005603192047854264
C964        0.10009104758501053    0.10009104758501053  0.000559636675972204
C961        0.10003114491701126    0.10003114491701126  0.0005593017436200124

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_102

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 227,584 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.05525550831246953    0.07149386405944824    0.0         -0.0002204270526751595  0.07930833101272583  0.0019801878520284634  0.09531286358833313
    3        2        Softmax                 0.0   0.0   0.0017876609636005014  0.0004246743628755212  0.0         0.0005199102215556195   0.23694533109664917  0.04982282170470053    0.10498777031898499


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08657587282716747
RMSE: 0.29423778280018265
LogLoss: 0.28717129671225783
Mean Per-Class Error: 0.11669818199012694
AUC: 0.9502515414766414
pr_auc: 0.9425106047341992
Gini: 0.9005030829532827
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4620751013165152: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4329  654   0.1312   (654.0/4983.0)
1      518   4524  0.1027   (518.0/5042.0)
Total  4847  5178  0.1169   (1172.0/10025.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.462075     0.885323  214
max f2                       0.150254     0.919299  313
max f0point5                 0.740076     0.899592  129
max accuracy                 0.535707     0.883292  192
max precision                0.984767     1         0
max recall                   0.0110351    1         398
max specificity              0.984767     1         0
max absolute_mcc             0.535707     0.766591  192
max min_per_class_accuracy   0.527388     0.882785  194
max mean_per_class_accuracy  0.535707     0.883302  192
Gains/Lift Table: Avg response rate: 50.29 %, avg score: 50.09 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100748                   0.982849           1.9883     1.9883             1                0.983887   1                           0.983887            0.0200317       0.0200317                  98.8298   98.8298
    2        0.0200499                   0.981723           1.94853    1.96851            0.98             0.982236   0.99005                     0.983066            0.0194367       0.0394685                  94.8532   96.8514
    3        0.0300249                   0.980711           1.9883     1.97509            1                0.981175   0.993355                    0.982437            0.0198334       0.0593019                  98.8298   97.5087
    4        0.04                        0.979946           1.9883     1.97838            1                0.980336   0.995012                    0.981913            0.0198334       0.0791353                  98.8298   97.8382
    5        0.0500748                   0.979222           1.96861    1.97642            0.990099         0.979567   0.994024                    0.981441            0.0198334       0.0989687                  96.8612   97.6416
    6        0.10005                     0.975098           1.97639    1.9764             0.994012         0.977301   0.994018                    0.979373            0.0987703       0.197739                   97.6392   97.6404
    7        0.150025                    0.969638           1.95655    1.96979            0.984032         0.972491   0.990691                    0.977081            0.0977787       0.295518                   95.6549   96.979
    8        0.2                         0.960937           1.92877    1.95954            0.97006          0.965549   0.985536                    0.974199            0.0963903       0.391908                   92.8768   95.954
    9        0.30005                     0.926298           1.83962    1.91955            0.925224         0.946105   0.965426                    0.964831            0.184054        0.575962                   83.9622   91.9554
    10       0.4                         0.826738           1.73629    1.87376            0.873253         0.886017   0.942394                    0.945138            0.173542        0.749504                   73.6288   87.376
    11       0.50005                     0.53534            1.31232    1.76143            0.66002          0.695068   0.885897                    0.895104            0.131297        0.880801                   31.2317   76.1427
    12       0.6                         0.196237           0.720312   1.58799            0.362275         0.345062   0.79867                     0.803476            0.0719952       0.952797                   -27.9688  58.7994
    13       0.69995                     0.0614981          0.303602   1.40459            0.152695         0.114435   0.706427                    0.705083            0.0303451       0.983142                   -69.6398  40.4588
    14       0.8                         0.0260605          0.114976   1.24331            0.0578265        0.0400572  0.625312                    0.621914            0.0115034       0.994645                   -88.5024  24.3306
    15       0.89995                     0.0158349          0.0257963  1.10809            0.0129741        0.020102   0.557304                    0.555075            0.00257834      0.997223                   -97.4204  10.8087
    16       1                           0.00832625         0.0277529  1                  0.0139581        0.0132291  0.502943                    0.500864            0.00277668      1                          -97.2247  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08095347427898344
RMSE: 0.2845232403143607
LogLoss: 0.26865397270135444
Mean Per-Class Error: 0.10782040189270048
AUC: 0.9569821433214866
pr_auc: 0.9530794315227655
Gini: 0.9139642866429731
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4873283557281555: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2755  373   0.1192   (373.0/3128.0)
1      297   2752  0.0974   (297.0/3049.0)
Total  3052  3125  0.1085   (670.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.487328     0.89148   209
max f2                       0.169517     0.92111   305
max f0point5                 0.823957     0.908036  103
max accuracy                 0.540415     0.892181  194
max precision                0.985791     1         0
max recall                   0.0123137    1         396
max specificity              0.985791     1         0
max absolute_mcc             0.540415     0.784336  194
max min_per_class_accuracy   0.540415     0.892096  194
max mean_per_class_accuracy  0.540415     0.89218   194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.57 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.98285            2.02591    2.02591            1                0.984019   1                           0.984019            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.9817             2.02591    2.02591            1                0.98226    1                           0.98314             0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980682           2.02591    2.02591            1                0.981143   1                           0.982474            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.97999            2.02591    2.02591            1                0.980321   1                           0.981936            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.979398           2.02591    2.02591            1                0.979676   1                           0.98149             0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.975474           2.01935    2.02263            0.996764         0.977477   0.998382                    0.979483            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.970095           1.97346    2.00624            0.97411          0.972871   0.990291                    0.977279            0.0987209       0.301082                   97.3459   100.624
    8        0.200097                    0.96104            1.97346    1.99805            0.97411          0.96578    0.986246                    0.974405            0.0987209       0.399803                   97.3459   99.8046
    9        0.299984                    0.92224            1.91756    1.97124            0.946515         0.944609   0.973017                    0.964483            0.191538        0.591341                   91.7555   97.1244
    10       0.400032                    0.822363           1.78988    1.92589            0.883495         0.879953   0.950627                    0.943342            0.179075        0.770417                   78.9882   92.5885
    11       0.500081                    0.511823           1.2621     1.79308            0.622977         0.688075   0.885076                    0.892272            0.126271        0.896687                   26.2096   79.3085
    12       0.599968                    0.174888           0.636996   1.60061            0.314425         0.321624   0.79007                     0.797267            0.0636274       0.960315                   -36.3004  60.0611
    13       0.700016                    0.0549598          0.26881    1.41027            0.132686         0.104077   0.696115                    0.698194            0.0268941       0.987209                   -73.119   41.0266
    14       0.799903                    0.025296           0.0952211  1.24605            0.0470016        0.037149   0.615058                    0.615647            0.00951132      0.99672                    -90.4779  24.6052
    15       0.899951                    0.0156071          0.019669   1.10971            0.00970874       0.0197976  0.54776                     0.549406            0.00196786      0.998688                   -98.0331  10.9713
    16       1                           0.00918898         0.0131127  1                  0.00647249       0.0130476  0.493605                    0.495744            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:59:56  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:00:06  1:53:24.792  1305 obs/sec      0.53712   1             13428      0.323659         0.357567            0.580965       0.931363        0.844601           1.9883           0.144838                         0.311989           0.330916              0.610589         0.938996          0.85365              2.02591            0.130322
    2019-08-03 18:00:18  1:53:36.280  1288 obs/sec      1.07004   2             26751      0.306545         0.308239            0.624108       0.942277        0.932858           1.9883           0.13217                          0.300824           0.295508              0.63796          0.94662           0.925591             2.02591            0.12498
    2019-08-03 18:00:29  1:53:47.691  1290 obs/sec      1.60624   3             40156      0.308159         0.309723            0.620139       0.941652        0.928158           1.9883           0.125486                         0.300917           0.296235              0.637737         0.94656           0.934788             2.02591            0.120447
    2019-08-03 18:00:41  1:53:59.171  1287 obs/sec      2.142     4             53550      0.296515         0.291204            0.648303       0.948836        0.940715           1.9883           0.118603                         0.290036           0.277854              0.663462         0.953897          0.948053             2.02591            0.113324
    2019-08-03 18:00:52  1:54:10.885  1282 obs/sec      2.67636   5             66909      0.297203         0.292024            0.646669       0.948736        0.938919           1.9883           0.121796                         0.287663           0.275862              0.668947         0.95409           0.944201             2.02591            0.112514
    2019-08-03 18:01:14  1:54:32.536  1286 obs/sec      3.74096   7             93524      0.294238         0.287171            0.653685       0.950252        0.942511           1.9883           0.116908                         0.284523           0.268654              0.676133         0.956982          0.953079             2.02591            0.108467
    2019-08-03 18:01:26  1:54:44.025  1287 obs/sec      4.27552   8             106888     0.295965         0.291182            0.649607       0.948679        0.94361            1.9883           0.116608                         0.28535            0.272649              0.674249         0.955614          0.952343             1.99323            0.107657
    2019-08-03 18:01:38  1:54:56.826  1269 obs/sec      4.80992   9             120248     0.29254          0.28473             0.65767        0.951268        0.946963           1.9883           0.115212                         0.285323           0.271551              0.674311         0.955868          0.944335             2.02591            0.1096
    2019-08-03 18:01:50  1:55:08.501  1268 obs/sec      5.34892   10            133723     0.292708         0.284814            0.657276       0.95192         0.945745           1.9883           0.114613                         0.286398           0.272409              0.671851         0.956352          0.94563              2.02591            0.11041
    2019-08-03 18:02:01  1:55:19.785  1272 obs/sec      5.8822    11            147055     0.293507         0.285701            0.655403       0.951723        0.950161           1.94893          0.117706                         0.28592            0.27207               0.672946         0.956309          0.9523               2.02591            0.108629
    2019-08-03 18:02:13  1:55:31.305  1274 obs/sec      6.42288   12            160572     0.294005         0.287848            0.654232       0.950335        0.949206           1.96861          0.118204                         0.287306           0.275007              0.669768         0.954819          0.952555             2.02591            0.114619
    2019-08-03 18:02:24  1:55:43.074  1273 obs/sec      6.96024   13            174006     0.294608         0.290681            0.652812       0.95222         0.936132           1.9883           0.115711                         0.286164           0.274486              0.672386         0.957092          0.946061             2.02591            0.1096
    2019-08-03 18:02:46  1:56:04.835  1276 obs/sec      8.03508   15            200877     0.293303         0.287013            0.655882       0.951655        0.9461             1.9883           0.117207                         0.286174           0.275538              0.672364         0.95578           0.94989              1.99323            0.1096
    2019-08-03 18:02:58  1:56:15.983  1279 obs/sec      8.57064   16            214266     0.294478         0.289314            0.653119       0.94997         0.949183           1.9883           0.119002                         0.286211           0.275234              0.67228          0.95482           0.949287             1.99323            0.111381
    2019-08-03 18:03:09  1:56:27.465  1279 obs/sec      9.10336   17            227584     0.295691         0.291585            0.650255       0.94949         0.946821           1.96861          0.1202                           0.288181           0.278324              0.667753         0.953813          0.948                2.02591            0.110571
    2019-08-03 18:03:10  1:56:28.578  1279 obs/sec      9.10336   17            227584     0.294238         0.287171            0.653685       0.950252        0.942511           1.9883           0.116908                         0.284523           0.268654              0.676133         0.956982          0.953079             2.02591            0.108467
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.004932214497913086
C438        0.8684672713279724     0.8684672713279724   0.004283466866606843
C374        0.7593643665313721     0.7593643665313721   0.0037453479378046196
C88         0.7350829243659973     0.7350829243659973   0.00362558665672632
C322        0.7045367956161499     0.7045367956161499   0.003474926597651203
---         ---                    ---                  ---
C542        0.12695351243019104    0.12695351243019104  0.0006261619545691774
C764        0.12591664493083954    0.12591664493083954  0.000621047901656461
C974        0.12584461271762848    0.12584461271762848  0.0006206926233301446
C774        0.1251877397298813     0.1251877397298813   0.0006174527848566905
C964        0.12308309972286224    0.12308309972286224  0.0006070722489011833

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_76

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,622 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.05511468335542174   0.07767853140830994    0.0         0.0005514459305741627   0.07860305905342102  -0.005372985265906344   0.09005013108253479
    3        2        Softmax                 0.0   0.0   0.002116722512710112  0.0007104803808033466  0.0         -0.0003874571041251329  0.24961721897125244  -0.0008144264259667827  0.0979662537574768


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08644873756458984
RMSE: 0.2940216617268018
LogLoss: 0.2862796254128362
Mean Per-Class Error: 0.11650866519144709
AUC: 0.9510448499619
pr_auc: 0.9400619773171447
Gini: 0.9020896999238
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4938700763288683: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4397  648   0.1284   (648.0/5045.0)
1      524   4460  0.1051   (524.0/4984.0)
Total  4921  5108  0.1169   (1172.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.49387      0.883868  206
max f2                       0.175201     0.918791  303
max f0point5                 0.748687     0.897856  131
max accuracy                 0.507283     0.883438  203
max precision                0.990353     1         0
max recall                   0.00968482   1         395
max specificity              0.990353     1         0
max absolute_mcc             0.507283     0.767032  203
max min_per_class_accuracy   0.54406      0.881665  194
max mean_per_class_accuracy  0.507283     0.883491  203
Gains/Lift Table: Avg response rate: 49.70 %, avg score: 50.26 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   0.989015           2.01224     2.01224            1                0.989821    1                           0.989821            0.0202648       0.0202648                  101.224   101.224
    2        0.0200419                   0.987966           2.01224     2.01224            1                0.988439    1                           0.989134            0.0200642       0.0403291                  101.224   101.224
    3        0.030013                    0.987209           2.01224     2.01224            1                0.987589    1                           0.988621            0.0200642       0.0603933                  101.224   101.224
    4        0.0400838                   0.986557           1.99232     2.00723            0.990099         0.986873    0.997512                    0.988181            0.0200642       0.0804575                  99.2316   100.723
    5        0.0500548                   0.985887           2.01224     2.00823            1                0.986237    0.998008                    0.987794            0.0200642       0.100522                   101.224   100.823
    6        0.10001                     0.981761           1.99216     2.0002             0.99002          0.983952    0.994018                    0.985875            0.0995185       0.20004                    99.2157   100.02
    7        0.150065                    0.976184           1.96815     1.98951            0.978088         0.979222    0.988704                    0.983656            0.0985152       0.298555                   96.8146   98.951
    8        0.20002                     0.9674             1.96003     1.98215            0.974052         0.972072    0.985045                    0.980763            0.0979133       0.396469                   96.0025   98.2146
    9        0.30003                     0.932883           1.86779     1.94403            0.928215         0.953123    0.966102                    0.971549            0.186798        0.583266                   86.7791   94.4028
    10       0.40004                     0.826652           1.7093      1.88535            0.849452         0.890159    0.936939                    0.951202            0.170947        0.754213                   70.93     88.5346
    11       0.50005                     0.531778           1.30404     1.76909            0.648056         0.705922    0.879163                    0.902146            0.130417        0.884631                   30.4043   76.9085
    12       0.59996                     0.185524           0.720952    1.59454            0.358283         0.343892    0.792421                    0.809181            0.0720305       0.956661                   -27.9048  59.4542
    13       0.69997                     0.0568696          0.266827    1.40484            0.132602         0.109868    0.698148                    0.709265            0.0266854       0.983347                   -73.3173  40.4841
    14       0.79998                     0.0220718          0.114355    1.24351            0.0568295        0.0353189   0.617973                    0.625011            0.0114366       0.994783                   -88.5645  24.351
    15       0.89999                     0.0119406          0.0441369   1.11023            0.0219342        0.0163245   0.551739                    0.557372            0.00441413      0.999197                   -95.5863  11.0232
    16       1                           0.00543303         0.00802488  1                  0.00398804       0.00938785  0.496959                    0.502568            0.000802568     1                          -99.1975  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08121281192678247
RMSE: 0.2849786166132162
LogLoss: 0.2697295411353292
Mean Per-Class Error: 0.1080150592328708
AUC: 0.9565443346902551
pr_auc: 0.9487085648195511
Gini: 0.9130886693805103
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6039530578302013: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2838  290   0.0927   (290.0/3128.0)
1      376   2673  0.1233   (376.0/3049.0)
Total  3214  2963  0.1078   (666.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.603953     0.889222  174
max f2                       0.174092     0.921086  302
max f0point5                 0.7229       0.905779  141
max accuracy                 0.607501     0.892181  173
max precision                0.990596     1         0
max recall                   0.00896398   1         395
max specificity              0.990596     1         0
max absolute_mcc             0.607501     0.784579  173
max min_per_class_accuracy   0.542831     0.887468  192
max mean_per_class_accuracy  0.603953     0.891985  174
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.97 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.989029           2.02591     2.02591            1                0.989904    1                           0.989904            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.988042           2.02591     2.02591            1                0.988505    1                           0.989205            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.987206           2.02591     2.02591            1                0.987622    1                           0.988677            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.986524           1.99323     2.01774            0.983871         0.986834    0.995968                    0.988217            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.985657           2.02591     2.01935            1                0.986091    0.996764                    0.987797            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.981439           2.00624     2.0128             0.990291         0.983597    0.993528                    0.985697            0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.976076           1.99968     2.00843            0.987055         0.979083    0.99137                     0.983492            0.100033        0.30141                    99.9685   100.843
    8        0.200097                    0.967878           1.98657     2.00296            0.980583         0.972457    0.988673                    0.980733            0.0993768       0.400787                   98.6572   100.296
    9        0.299984                    0.933718           1.90114     1.96906            0.938412         0.95399     0.971937                    0.971829            0.189898        0.590685                   90.1138   96.9058
    10       0.400032                    0.830923           1.75054     1.91441            0.864078         0.891751    0.944962                    0.951801            0.175139        0.765825                   75.0544   91.4407
    11       0.500081                    0.516227           1.25882     1.78325            0.621359         0.700179    0.88022                     0.90146             0.125943        0.891768                   25.8818   78.3247
    12       0.599968                    0.176722           0.679681    1.59952            0.335494         0.32731     0.78953                     0.805872            0.0678911       0.959659                   -32.0319  59.9518
    13       0.700016                    0.0548325          0.245863    1.40605            0.121359         0.10354     0.694033                    0.705492            0.0245982       0.984257                   -75.4137  40.6049
    14       0.799903                    0.0217044          0.124772    1.24605            0.0615883        0.0337462   0.615058                    0.621609            0.0124631       0.99672                    -87.5228  24.6052
    15       0.899951                    0.0117732          0.0295035   1.11081            0.0145631        0.0157511   0.5483                      0.554255            0.00295179      0.999672                   -97.0496  11.0807
    16       1                           0.00543303         0.00327817  1                  0.00161812       0.00934824  0.493605                    0.499738            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:28:46  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:28:54  1:22:12.867  1256 obs/sec      0.39628   1             9907       0.336503         0.392282            0.547046       0.924633        0.828575           2.01224          0.149865                         0.32957            0.372989              0.565464         0.930026          0.850087             2.02591            0.14473
    2019-08-03 17:29:11  1:22:29.682  1266 obs/sec      1.20068   3             30017      0.302253         0.300734            0.634558       0.945204        0.928635           2.01224          0.125237                         0.293459           0.284049              0.655471         0.950934          0.922888             2.02591            0.114619
    2019-08-03 17:29:28  1:22:46.290  1276 obs/sec      2.00328   5             50082      0.301962         0.299134            0.635263       0.94579         0.941872           2.01224          0.123442                         0.293393           0.283084              0.655626         0.951621          0.94701              2.02591            0.12158
    2019-08-03 17:29:44  1:23:02.887  1279 obs/sec      2.80808   7             70202      0.29687          0.290884            0.647461       0.948816        0.940987           2.01224          0.119254                         0.288491           0.27663               0.667038         0.953799          0.946185             2.02591            0.113809
    2019-08-03 17:30:01  1:23:19.670  1279 obs/sec      3.61012   9             90253      0.294022         0.28628             0.654192       0.951045        0.940062           2.01224          0.116861                         0.284979           0.26973               0.675096         0.956544          0.948709             2.02591            0.107819
    2019-08-03 17:30:18  1:23:36.457  1278 obs/sec      4.40872   11            110218     0.293674         0.285415            0.65501        0.95157         0.94421            2.01224          0.115665                         0.285649           0.27039               0.673565         0.956489          0.944629             2.02591            0.113809
    2019-08-03 17:30:35  1:23:53.163  1278 obs/sec      5.21144   13            130286     0.293131         0.285952            0.656285       0.950777        0.94541            1.99232          0.116961                         0.28561            0.272557              0.673654         0.955751          0.952367             2.02591            0.113
    2019-08-03 17:30:52  1:24:10.193  1275 obs/sec      6.01068   15            150267     0.292895         0.286671            0.656837       0.95085         0.945647           2.01224          0.115166                         0.28513            0.272838              0.67475          0.95614           0.951175             2.02591            0.111867
    2019-08-03 17:31:08  1:24:26.919  1277 obs/sec      6.81364   17            170341     0.294145         0.287841            0.653903       0.950369        0.944774           1.99232          0.116662                         0.284743           0.272169              0.675632         0.95579           0.948091             1.99323            0.108791
    2019-08-03 17:31:26  1:24:44.954  1267 obs/sec      7.62084   19            190521     0.298045         0.295333            0.644664       0.947798        0.942776           2.01224          0.118257                         0.288042           0.276893              0.668072         0.954372          0.950613             2.02591            0.114457
    2019-08-03 17:31:43  1:25:01.404  1270 obs/sec      8.41716   21            210429     0.296357         0.291096            0.648678       0.95006         0.943997           1.99232          0.116562                         0.285657           0.272193              0.673547         0.956286          0.95186              2.02591            0.110895
    2019-08-03 17:31:59  1:25:17.864  1274 obs/sec      9.22324   23            230581     0.296601         0.291893            0.648099       0.951117        0.943927           1.99232          0.116861                         0.286601           0.2744                0.671385         0.956352          0.947318             2.02591            0.108791
    2019-08-03 17:32:16  1:25:34.589  1274 obs/sec      10.0249   25            250622     0.294558         0.288953            0.652929       0.951224        0.946443           1.99232          0.116861                         0.285374           0.273142              0.674194         0.956548          0.948872             2.02591            0.109762
    2019-08-03 17:32:17  1:25:35.722  1274 obs/sec      10.0249   25            250622     0.294022         0.28628             0.654192       0.951045        0.940062           2.01224          0.116861                         0.284979           0.26973               0.675096         0.956544          0.948709             2.02591            0.107819
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005059408598168967
C438        0.7524079084396362     0.7524079084396362   0.003806739041289825
C374        0.7128584980964661     0.7128584980964661   0.003606642414547077
C322        0.6500319838523865     0.6500319838523865   0.0032887774081875954
C88         0.6413083076477051     0.6413083076477051   0.0032446407657899883
---         ---                    ---                  ---
C975        0.12673665583133698    0.12673665583133698  0.0006412125262162475
C443        0.1256440132856369     0.1256440132856369   0.0006356844011258073
C969        0.12523822486400604    0.12523822486400604  0.0006336313516963708
C857        0.12484069168567657    0.12484069168567657  0.0006316200689158732
C811        0.12350963801145554    0.12350963801145554  0.0006248857245118949

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_184

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 254,855 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.060014853377199924   0.0769769549369812     0.0         -0.001090339302672472  0.11338141560554504  0.018227590730794805  0.13618063926696777
    3        2        Softmax                 0.0   0.0   0.0019439539962604613  0.0006158326286822557  0.0         0.022735615400677034   0.24561864137649536  0.004326875469373076  0.14286059141159058


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08834104925840244
RMSE: 0.2972222220130965
LogLoss: 0.2931626886800198
Mean Per-Class Error: 0.11834394774859103
AUC: 0.9490778165702971
pr_auc: 0.945667570970408
Gini: 0.8981556331405942
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5418963452936636: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4394  621   0.1238   (621.0/5015.0)
1      567   4431  0.1134   (567.0/4998.0)
Total  4961  5052  0.1186   (1188.0/10013.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.541896     0.881791  193
max f2                       0.146193     0.916756  316
max f0point5                 0.771438     0.897413  120
max accuracy                 0.554537     0.881654  189
max precision                0.977944     1         0
max recall                   0.0145482    1         398
max specificity              0.977944     1         0
max absolute_mcc             0.554537     0.763312  189
max min_per_class_accuracy   0.562146     0.880957  187
max mean_per_class_accuracy  0.554537     0.881656  189
Gains/Lift Table: Avg response rate: 49.92 %, avg score: 50.34 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100869                   0.973291           1.98357     1.98357            0.990099         0.974477   0.990099                    0.974477            0.020008        0.020008                   98.3566   98.3566
    2        0.0200739                   0.972073           2.0034      1.99343            1                0.972631   0.995025                    0.973559            0.020008        0.040016                   100.34    99.3434
    3        0.0300609                   0.971284           2.0034      1.99675            1                0.971634   0.996678                    0.972919            0.020008        0.060024                   100.34    99.6746
    4        0.0400479                   0.970613           2.0034      1.99841            1                0.970951   0.997506                    0.972428            0.020008        0.080032                   100.34    99.8405
    5        0.050035                    0.969994           1.96333     1.9914             0.98             0.970274   0.994012                    0.971999            0.0196078       0.0996399                  96.3333   99.1405
    6        0.10007                     0.966408           1.96341     1.97741            0.98004          0.968248   0.987026                    0.970123            0.0982393       0.197879                   96.3413   97.7409
    7        0.150005                    0.961732           1.95131     1.96872            0.974            0.964217   0.98269                     0.968157            0.097439        0.295318                   95.1313   96.8722
    8        0.20004                     0.954891           1.95542     1.96539            0.976048         0.958534   0.981028                    0.96575             0.0978391       0.393157                   95.5416   96.5394
    9        0.30001                     0.925885           1.87531     1.93538            0.936064         0.943106   0.966045                    0.958205            0.187475        0.580632                   87.5312   93.5376
    10       0.39998                     0.840508           1.72321     1.88235            0.86014          0.890601   0.939576                    0.941308            0.172269        0.752901                   72.3205   88.2347
    11       0.50005                     0.555925           1.29161     1.76413            0.644711         0.719106   0.880567                    0.896841            0.129252        0.882153                   29.1614   76.413
    12       0.60002                     0.192922           0.704493    1.58758            0.351648         0.361789   0.792443                    0.807695            0.0704282       0.952581                   -29.5507  58.7582
    13       0.69999                     0.0577793          0.30021     1.40372            0.14985          0.1092     0.700671                    0.707939            0.030012        0.982593                   -69.979   40.3724
    14       0.79996                     0.0274015          0.122085    1.24356            0.0609391        0.0392663  0.620724                    0.624376            0.0122049       0.994798                   -87.7915  24.3559
    15       0.89993                     0.0190201          0.0420294   1.11009            0.020979         0.022448   0.554101                    0.55751             0.00420168      0.999                      -95.7971  11.0086
    16       1                           0.0117531          0.00999701  1                  0.00499002       0.0167956  0.499151                    0.5034              0.0010004       1                          -99.0003  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08078316077706131
RMSE: 0.28422378643783724
LogLoss: 0.2699933272436407
Mean Per-Class Error: 0.10776823812930991
AUC: 0.9569344881848814
pr_auc: 0.9482948534810247
Gini: 0.9138689763697627
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3671257922447341: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2662  466   0.149    (466.0/3128.0)
1      226   2823  0.0741   (226.0/3049.0)
Total  2888  3289  0.112    (692.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.367126     0.890817  239
max f2                       0.146121     0.923327  313
max f0point5                 0.81823      0.906276  104
max accuracy                 0.599028     0.892343  176
max precision                0.976059     1         0
max recall                   0.0168186    1         395
max specificity              0.976059     1         0
max absolute_mcc             0.599028     0.784784  176
max min_per_class_accuracy   0.55793      0.890026  189
max mean_per_class_accuracy  0.584893     0.892232  181
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.66 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.973746           2.02591     2.02591            1                0.974815   1                           0.974815            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.972475           1.96056     1.99323            0.967742         0.973084   0.983871                    0.97395             0.0196786       0.0400131                  96.0558   99.3234
    3        0.0301117                   0.971658           2.02591     2.00413            1                0.972014   0.989247                    0.973305            0.0203345       0.0603477                  102.591   100.413
    4        0.0401489                   0.971036           2.02591     2.00957            1                0.971342   0.991935                    0.972814            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.970321           2.02591     2.0128             1                0.970657   0.993528                    0.972388            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.966756           1.99968     2.00624            0.987055         0.968668   0.990291                    0.970528            0.100033        0.200722                   99.9685   100.624
    7        0.150073                    0.961982           1.97346     1.99531            0.97411          0.964478   0.984898                    0.968511            0.0987209       0.299442                   97.3459   99.5314
    8        0.200097                    0.955871           1.98657     1.99313            0.980583         0.959165   0.983819                    0.966175            0.0993768       0.398819                   98.6572   99.3128
    9        0.299984                    0.927975           1.91756     1.96796            0.946515         0.944111   0.971398                    0.958828            0.191538        0.590357                   91.7555   96.7965
    10       0.400032                    0.840001           1.76366     1.91687            0.87055          0.891924   0.946176                    0.942095            0.176451        0.766809                   76.3656   91.6867
    11       0.500081                    0.530344           1.28832     1.79112            0.635922         0.707362   0.884105                    0.895134            0.128895        0.895704                   28.8321   79.1117
    12       0.599968                    0.162655           0.666547    1.60389            0.329011         0.31646    0.791689                    0.798792            0.0665792       0.962283                   -33.3453  60.3891
    13       0.700016                    0.0539426          0.242585    1.40933            0.119741         0.096204   0.695652                    0.698376            0.0242703       0.986553                   -75.7415  40.9329
    14       0.799903                    0.0269215          0.105072    1.24646            0.0518639        0.0375752  0.61526                     0.615859            0.0104952       0.997048                   -89.4928  24.6462
    15       0.899951                    0.0193918          0.0262254   1.11081            0.012945         0.0225441  0.5483                      0.5499              0.00262381      0.999672                   -97.3775  11.0807
    16       1                           0.0117531          0.00327817  1                  0.00161812       0.0168951  0.493605                    0.496574            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:54:05  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:54:12  3:47:30.384  1296 obs/sec      0.37244   1             9311       0.342721         0.43969             0.530168       0.924124        0.750789           2.0034           0.151104                         0.328499           0.400783              0.568284         0.933031          0.766504             2.02591            0.139388
    2019-08-03 19:54:28  3:47:46.126  1283 obs/sec      1.12152   3             28038      0.307601         0.310726            0.621525       0.941373        0.922118           2.0034           0.129931                         0.29656            0.290035              0.64815          0.948688          0.925267             2.02591            0.116885
    2019-08-03 19:54:43  3:48:01.908  1279 obs/sec      1.86996   5             46749      0.300606         0.296619            0.638543       0.946191        0.932299           2.0034           0.121242                         0.289619           0.278772              0.664428         0.952635          0.947254             2.02591            0.111381
    2019-08-03 19:55:00  3:48:18.035  1275 obs/sec      2.62896   7             65724      0.299676         0.296729            0.640777       0.946744        0.936361           2.0034           0.119844                         0.286859           0.274759              0.670794         0.953912          0.949411             2.02591            0.108629
    2019-08-03 19:55:15  3:48:33.978  1273 obs/sec      3.3792    9             84480      0.299935         0.295977            0.640156       0.947908        0.938989           2.0034           0.120743                         0.287915           0.275968              0.668364         0.954269          0.950429             2.02591            0.111381
    2019-08-03 19:55:32  3:48:50.172  1269 obs/sec      4.13448   11            103362     0.300245         0.299097            0.639411       0.948941        0.938588           2.0034           0.12284                          0.287749           0.276387              0.668747         0.955625          0.94746              2.02591            0.114133
    2019-08-03 19:55:48  3:49:06.241  1269 obs/sec      4.89672   13            122418     0.298786         0.295566            0.642907       0.947966        0.942355           1.98357          0.121143                         0.286534           0.274489              0.671539         0.954725          0.947629             1.99323            0.11041
    2019-08-03 19:56:04  3:49:22.358  1269 obs/sec      5.65728   15            141432     0.299            0.296561            0.642395       0.947301        0.941992           2.0034           0.122241                         0.285895           0.274199              0.673002         0.954903          0.950365             2.02591            0.111057
    2019-08-03 19:56:20  3:49:38.427  1268 obs/sec      6.41168   17            160292     0.298328         0.293841            0.644002       0.94926         0.940533           1.98357          0.121143                         0.286357           0.272887              0.671944         0.956162          0.953348             2.02591            0.111057
    2019-08-03 19:56:36  3:49:54.599  1267 obs/sec      7.17216   19            179304     0.297222         0.293163            0.646635       0.949078        0.945668           1.98357          0.118646                         0.284224           0.269993              0.676814         0.956934          0.948295             2.02591            0.112028
    2019-08-03 19:56:52  3:50:10.472  1270 obs/sec      7.9358    21            198395     0.298035         0.296909            0.644699       0.950382        0.938345           2.0034           0.118846                         0.285949           0.27377               0.672879         0.957569          0.955039             2.02591            0.1096
    2019-08-03 19:57:08  3:50:26.286  1272 obs/sec      8.69328   23            217332     0.301498         0.301722            0.636394       0.945954        0.93852            2.0034           0.12294                          0.287371           0.27608               0.669617         0.955165          0.949667             1.99323            0.111381
    2019-08-03 19:57:24  3:50:42.033  1272 obs/sec      9.4492    25            236230     0.300428         0.300076            0.638971       0.946965        0.940273           1.96373          0.122341                         0.285006           0.273154              0.675033         0.955742          0.950374             1.96056            0.110248
    2019-08-03 19:57:40  3:50:58.756  1266 obs/sec      10.1942   27            254855     0.298454         0.298442            0.643699       0.948089        0.943726           1.98357          0.116748                         0.285553           0.274585              0.673784         0.956118          0.949312             1.99323            0.107334
    2019-08-03 19:57:41  3:50:59.853  1266 obs/sec      10.1942   27            254855     0.297222         0.293163            0.646635       0.949078        0.945668           1.98357          0.118646                         0.284224           0.269993              0.676814         0.956934          0.948295             2.02591            0.112028
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.006056175696866325
C438        0.918025553226471      0.918025553226471    0.005559724044552416
C374        0.7677730917930603     0.7677730917930603   0.0046497687392250495
C863        0.7166194319725037     0.7166194319725037   0.004339973187814028
C322        0.6801282167434692     0.6801282167434692   0.004118975976994831
---         ---                    ---                  ---
C935        0.08310146629810333    0.08310146629810333  0.0005032770805685294
C571        0.08286278694868088    0.08286278694868088  0.0005018315964932132
C857        0.08242332935333252    0.08242332935333252  0.0004991701640844612
C908        0.07920560240745544    0.07920560240745544  0.00047968304435568856
C839        0.07564778625965118    0.07564778625965118  0.00045813628466743783

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_67

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 241,669 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms          mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  ------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.03658884982776597    0.05754196643829346   0.0         0.0005767892582881045  0.0905303955078125  -0.0032615406593253177  0.09820184111595154
    3        2        Softmax                 0.0   0.0   0.0019584770652727457  0.000667942687869072  0.0         -0.01823314861826475   0.3741708993911743  -0.023695565555234666   0.09600234031677246


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08621646107311291
RMSE: 0.29362639709861393
LogLoss: 0.2868061776832089
Mean Per-Class Error: 0.11624627368052487
AUC: 0.9505652917667831
pr_auc: 0.9415187068503822
Gini: 0.9011305835335661
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4499333548226539: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4363  728   0.143    (728.0/5091.0)
1      451   4488  0.0913   (451.0/4939.0)
Total  4814  5216  0.1175   (1179.0/10030.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.449933     0.8839    215
max f2                       0.136546     0.918269  320
max f0point5                 0.771885     0.898081  118
max accuracy                 0.632228     0.884048  165
max precision                0.975347     1         0
max recall                   0.017226     1         399
max specificity              0.975347     1         0
max absolute_mcc             0.632228     0.768398  165
max min_per_class_accuracy   0.556799     0.882931  185
max mean_per_class_accuracy  0.632228     0.883754  165
Gains/Lift Table: Avg response rate: 49.24 %, avg score: 49.89 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100698                   0.973274           1.99056    1.99056            0.980198         0.974215   0.980198                    0.974215            0.0200445       0.0200445                  99.0562   99.0562
    2        0.0200399                   0.972044           2.01047    2.00047            0.99             0.972581   0.985075                    0.973402            0.0200445       0.0400891                  101.047   100.047
    3        0.03001                     0.971218           1.99016    1.99704            0.98             0.971631   0.983389                    0.972814            0.0198421       0.0599312                  99.016    99.7042
    4        0.0400798                   0.970565           2.01067    2.00047            0.990099         0.970858   0.985075                    0.972322            0.020247        0.0801782                  101.067   100.047
    5        0.0500499                   0.969932           1.99016    1.99841            0.98             0.970272   0.984064                    0.971914            0.0198421       0.10002                    99.016    99.8413
    6        0.1                         0.966833           2.0024     2.0004             0.986028         0.968455   0.985045                    0.970186            0.10002         0.20004                    100.24    100.04
    7        0.15005                     0.962375           1.97819    1.99299            0.974104         0.964724   0.981395                    0.968364            0.0990079       0.299048                   97.8186   99.2994
    8        0.2                         0.95487            1.97808    1.98927            0.974052         0.959037   0.979561                    0.966035            0.0988054       0.397854                   97.8081   98.9269
    9        0.3                         0.920413           1.90727    1.96194            0.939182         0.940577   0.966102                    0.957549            0.190727        0.588581                   90.7269   96.1936
    10       0.4                         0.820519           1.71897    1.90119            0.846461         0.880331   0.936191                    0.938244            0.171897        0.760478                   71.8971   90.1195
    11       0.5                         0.529196           1.28771    1.7785             0.634098         0.697717   0.875773                    0.890139            0.128771        0.889249                   28.771    77.8498
    12       0.6                         0.185617           0.653979   1.59108            0.322034         0.339359   0.783483                    0.798342            0.0653979       0.954647                   -34.6021  59.1078
    13       0.7                         0.0631315          0.303705   1.40717            0.149551         0.110351   0.692921                    0.700058            0.0303705       0.985017                   -69.6295  40.7167
    14       0.8                         0.030753           0.095161   1.24317            0.0468594        0.0435785  0.612164                    0.617998            0.0095161       0.994533                   -90.4839  24.3167
    15       0.9                         0.0220029          0.0323952  1.10864            0.0159521        0.0253628  0.545918                    0.552149            0.00323952      0.997773                   -96.7605  10.8636
    16       1                           0.016142           0.0222717  1                  0.0109671        0.0201144  0.492423                    0.498946            0.00222717      1                          -97.7728  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08067411268565448
RMSE: 0.28403188674100394
LogLoss: 0.27008922791697604
Mean Per-Class Error: 0.10765394968288622
AUC: 0.9569704523473799
pr_auc: 0.9497775231684914
Gini: 0.9139409046947597
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.565777123897496: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2800  328   0.1049   (328.0/3128.0)
1      337   2712  0.1105   (337.0/3049.0)
Total  3137  3040  0.1077   (665.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.565777     0.890787  188
max f2                       0.259843     0.923194  277
max f0point5                 0.773773     0.907925  123
max accuracy                 0.609285     0.892504  175
max precision                0.971834     0.99435   4
max recall                   0.0211855    1         393
max specificity              0.975908     0.99968   0
max absolute_mcc             0.609285     0.785104  175
max min_per_class_accuracy   0.557717     0.891112  190
max mean_per_class_accuracy  0.609285     0.892346  175
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.14 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.973737           1.99323     1.99323            0.983871         0.974696   0.983871                    0.974696            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.972234           2.02591     2.00957            1                0.97289    0.991935                    0.973793            0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.97143            1.99323     2.00413            0.983871         0.971823   0.989247                    0.973136            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.970786           2.02591     2.00957            1                0.971079   0.991935                    0.972622            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.97028            2.02591     2.0128             1                0.970536   0.993528                    0.97221             0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.967006           2.0128      2.0128             0.993528         0.968679   0.993528                    0.970445            0.100689        0.201378                   101.28    101.28
    7        0.150073                    0.963072           1.99968     2.00843            0.987055         0.965241   0.99137                     0.96871             0.100033        0.30141                    99.9685   100.843
    8        0.200097                    0.955797           1.95379     1.99477            0.964401         0.959738   0.984628                    0.966467            0.097737        0.399147                   95.379    99.4768
    9        0.299984                    0.922829           1.91099     1.96687            0.943274         0.941429   0.970858                    0.95813             0.190882        0.59003                    91.0988   96.6871
    10       0.400032                    0.832467           1.7571      1.91441            0.867314         0.888953   0.944962                    0.940829            0.175795        0.765825                   75.71     91.4407
    11       0.500081                    0.532343           1.28832     1.78915            0.635922         0.707292   0.883134                    0.894106            0.128895        0.89472                    28.8321   78.915
    12       0.599968                    0.190538           0.666547    1.60225            0.329011         0.341509   0.79088                     0.802106            0.0665792       0.961299                   -33.3453  60.2251
    13       0.700016                    0.0623646          0.236028    1.40699            0.116505         0.112267   0.694496                    0.703512            0.0236143       0.984913                   -76.3972  40.6986
    14       0.799903                    0.0308849          0.111638    1.24523            0.0551053        0.0434464  0.614653                    0.621087            0.0111512       0.996064                   -88.8362  24.5232
    15       0.899951                    0.0220342          0.0360599   1.11081            0.0177994        0.0255514  0.5483                      0.554881            0.00360774      0.999672                   -96.394   11.0807
    16       1                           0.015939           0.00327817  1                  0.00161812       0.0201521  0.493605                    0.501382            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:17:39  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:17:46  1:11:04.155  2552 obs/sec      0.74188   1             18547      0.30823          0.315192            0.61989        0.941059        0.902642           2.03078          0.130907                         0.29724            0.292964              0.646537         0.948508          0.919342             2.02591            0.120771
    2019-08-03 17:17:54  1:11:11.993  2559 obs/sec      1.48504   2             37126      0.300573         0.297055            0.63854        0.946185        0.935563           2.03078          0.123829                         0.291175           0.280246              0.660813         0.952626          0.942729             2.02591            0.115428
    2019-08-03 17:18:02  1:11:19.677  2577 obs/sec      2.2256    3             55640      0.296815         0.29087             0.647522       0.948392        0.940581           2.03078          0.122832                         0.28796            0.274578              0.668262         0.954448          0.946644             2.02591            0.114943
    2019-08-03 17:18:10  1:11:27.791  2556 obs/sec      2.97152   4             74288      0.295868         0.290738            0.649768       0.948629        0.941275           2.01067          0.117647                         0.28599            0.27438               0.672786         0.954824          0.946447             2.02591            0.108953
    2019-08-03 17:18:18  1:11:35.848  2549 obs/sec      3.71456   5             92864      0.293626         0.286806            0.655055       0.950565        0.941519           1.99056          0.117547                         0.284032           0.270089              0.677251         0.95697           0.949778             1.99323            0.107657
    2019-08-03 17:18:26  1:11:43.804  2543 obs/sec      4.45584   6             111396     0.295474         0.290161            0.6507         0.949605        0.942233           2.01067          0.12004                          0.286944           0.274608              0.670598         0.955553          0.949776             2.02591            0.113324
    2019-08-03 17:18:34  1:11:51.758  2540 obs/sec      5.19636   7             129909     0.296407         0.294201            0.648491       0.947686        0.938454           1.95035          0.117448                         0.28595            0.277052              0.672876         0.954331          0.948133             2.02591            0.110895
    2019-08-03 17:18:42  1:11:59.732  2540 obs/sec      5.94104   8             148526     0.29688          0.294455            0.647368       0.948013        0.936252           1.99056          0.12004                          0.285773           0.27432               0.673282         0.954988          0.946084             2.02591            0.113647
    2019-08-03 17:18:50  1:12:07.660  2540 obs/sec      6.68524   9             167131     0.297262         0.296063            0.64646        0.947242        0.935903           1.97046          0.118345                         0.28736            0.277974              0.669642         0.954008          0.947131             1.99323            0.113
    2019-08-03 17:18:58  1:12:15.770  2536 obs/sec      7.43436   10            185859     0.299142         0.300951            0.641974       0.945274        0.932433           1.91014          0.116251                         0.289508           0.284184              0.664686         0.951693          0.943842             1.99323            0.112676
    2019-08-03 17:19:06  1:12:23.617  2541 obs/sec      8.17876   11            204469     0.295751         0.294143            0.650044       0.948287        0.936963           1.99056          0.117747                         0.286745           0.277842              0.671055         0.95476           0.944654             2.02591            0.110248
    2019-08-03 17:19:13  1:12:31.260  2548 obs/sec      8.9202    12            223005     0.299169         0.301039            0.64191        0.945585        0.921565           2.03078          0.118245                         0.289124           0.281992              0.665574         0.95272           0.932526             2.02591            0.11219
    2019-08-03 17:19:21  1:12:38.911  2555 obs/sec      9.66676   13            241669     0.298501         0.29937             0.643506       0.946539        0.937261           2.01067          0.11994                          0.289068           0.281971              0.665704         0.95319           0.94643              2.02591            0.11041
    2019-08-03 17:19:22  1:12:39.531  2554 obs/sec      9.66676   13            241669     0.293626         0.286806            0.655055       0.950565        0.941519           1.99056          0.117547                         0.284032           0.270089              0.677251         0.95697           0.949778             1.99323            0.107657
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006272319264278304
C438        0.8606242537498474     0.8606242537498474   0.005398110086100308
C374        0.7234013080596924     0.7234013080596924   0.004537403960346933
C88         0.6550499796867371     0.6550499796867371   0.004108682606654233
C322        0.6396377682685852     0.6396377682685852   0.0040120122960710285
---         ---                    ---                  ---
C862        0.09033367782831192    0.09033367782831192  0.0005666016676556308
C925        0.08981984108686447    0.08981984108686447  0.0005633787195635559
C743        0.08962994813919067    0.08962994813919067  0.000562187650369711
C446        0.08824034780263901    0.08824034780263901  0.0005534716334091104
C853        0.08813852816820145    0.08813852816820145  0.0005528329881545459

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_2

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 252,783 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.05453423743947589    0.07828885316848755    0.0         0.0005063891585016602  0.09805253148078918  -0.0001768290841224968  0.10574349761009216
    3        2        Softmax                 0.0   0.0   0.0020643463992655597  0.0007019143085926771  0.0         0.007620693642934384   0.2552424669265747   0.00038534194588612375  0.10729169845581055


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08472805972064644
RMSE: 0.2910808473957818
LogLoss: 0.2809120696545072
Mean Per-Class Error: 0.11471184834722514
AUC: 0.9532105457146934
pr_auc: 0.942457468982487
Gini: 0.9064210914293869
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3663909088119971: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4225  838   0.1655   (838.0/5063.0)
1      347   4620  0.0699   (347.0/4967.0)
Total  4572  5458  0.1181   (1185.0/10030.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.366391     0.886331  240
max f2                       0.183146     0.921864  301
max f0point5                 0.76938      0.895954  120
max accuracy                 0.546008     0.885244  191
max precision                0.969286     0.996078  7
max recall                   0.0175592    1         396
max specificity              0.976004     0.999802  0
max absolute_mcc             0.501701     0.770669  202
max min_per_class_accuracy   0.561766     0.884437  187
max mean_per_class_accuracy  0.543217     0.885288  192
Gains/Lift Table: Avg response rate: 49.52 %, avg score: 50.01 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100698                   0.973704           1.99933    1.99933            0.990099         0.975078   0.990099                    0.975078            0.0201329       0.0201329                  99.9334   99.9334
    2        0.0200399                   0.972405           2.01933    2.00928            1                0.972977   0.995025                    0.974033            0.0201329       0.0402658                  101.933   100.928
    3        0.03001                     0.971136           1.99913    2.00591            0.99             0.971764   0.993355                    0.973279            0.0199315       0.0601973                  99.9134   100.591
    4        0.0400798                   0.969962           2.01933    2.00928            1                0.970542   0.995025                    0.972592            0.0203342       0.0805315                  101.933   100.928
    5        0.0500499                   0.96899            2.01933    2.01128            1                0.969453   0.996016                    0.971966            0.0201329       0.100664                   101.933   101.128
    6        0.1                         0.9643             2.00321    2.00725            0.992016         0.966685   0.994018                    0.969328            0.10006         0.200725                   100.321   100.725
    7        0.15005                     0.959115           1.9791     1.99786            0.98008          0.961782   0.989369                    0.966811            0.0990538       0.299779                   97.9102   99.786
    8        0.2                         0.950598           1.95887    1.98812            0.97006          0.955121   0.984546                    0.963891            0.0978458       0.397624                   95.8869   98.8122
    9        0.3                         0.916615           1.90054    1.95893            0.941176         0.936936   0.97009                     0.954906            0.190054        0.587679                   90.0544   95.8929
    10       0.4                         0.818494           1.67908    1.88897            0.831505         0.87555    0.935444                    0.935067            0.167908        0.755587                   67.9082   88.8967
    11       0.5                         0.544226           1.3328     1.77773            0.66002          0.697281   0.880359                    0.88751             0.13328         0.888867                   33.2796   77.7733
    12       0.6                         0.192942           0.706664   1.59922            0.34995          0.353361   0.791957                    0.798485            0.0706664       0.959533                   -29.3336  59.9222
    13       0.7                         0.0672652          0.279847   1.41074            0.138584         0.115994   0.698618                    0.700986            0.0279847       0.987518                   -72.0153  41.0739
    14       0.8                         0.033609           0.0885847  1.24547            0.0438684        0.046915   0.616775                    0.619227            0.00885847      0.996376                   -91.1415  24.547
    15       0.9                         0.023153           0.0201329  1.10932            0.00997009       0.0275381  0.549352                    0.553484            0.00201329      0.998389                   -97.9867  10.9322
    16       1                           0.0127468          0.0161063  1                  0.00797607       0.0198742  0.495214                    0.500123            0.00161063      1                          -98.3894  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08083253594486124
RMSE: 0.2843106328382061
LogLoss: 0.27064664786491927
Mean Per-Class Error: 0.10944618125602368
AUC: 0.9565691321375757
pr_auc: 0.9528142343219617
Gini: 0.9131382642751513
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4680095318107414: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2726  402   0.1285   (402.0/3128.0)
1      277   2772  0.0908   (277.0/3049.0)
Total  3003  3174  0.1099   (679.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.46801      0.890889  212
max f2                       0.182593     0.923435  301
max f0point5                 0.800689     0.906238  110
max accuracy                 0.550975     0.890562  188
max precision                0.977934     1         0
max recall                   0.020848     1         393
max specificity              0.977934     1         0
max absolute_mcc             0.495702     0.781121  204
max min_per_class_accuracy   0.545548     0.889386  190
max mean_per_class_accuracy  0.495702     0.890554  204
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.71 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.973196           2.02591    2.02591            1                0.974984   1                           0.974984            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.971606           2.02591    2.02591            1                0.972313   1                           0.973649            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.970393           2.02591    2.02591            1                0.970976   1                           0.972758            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.969422           2.02591    2.02591            1                0.96985    1                           0.972031            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.968611           1.95949    2.0128             0.967213         0.969021   0.993528                    0.971437            0.0193506       0.100689                   95.9487   101.28
    6        0.100049                    0.964295           2.00624    2.00952            0.990291         0.966381   0.991909                    0.968909            0.100361        0.20105                    100.624   100.952
    7        0.150073                    0.958135           1.98657    2.00187            0.980583         0.961289   0.988134                    0.966369            0.0993768       0.300426                   98.6572   100.187
    8        0.200097                    0.949533           1.96035    1.99149            0.967638         0.954465   0.98301                     0.963393            0.0980649       0.398491                   96.0347   99.1489
    9        0.299984                    0.91697            1.93726    1.97343            0.95624          0.935877   0.974096                    0.954231            0.193506        0.591997                   93.7256   97.3431
    10       0.400032                    0.821313           1.74399    1.91605            0.860841         0.878907   0.945771                    0.935392            0.174483        0.766481                   74.3987   91.6047
    11       0.500081                    0.527571           1.28177    1.78915            0.632686         0.692456   0.883134                    0.886789            0.128239        0.89472                    28.1765   78.915
    12       0.599968                    0.18333            0.682965   1.60498            0.337115         0.331747   0.792229                    0.794382            0.0682191       0.962939                   -31.7035  60.4984
    13       0.700016                    0.0645846          0.229472   1.40839            0.113269         0.111064   0.69519                     0.69672             0.0229583       0.985897                   -77.0528  40.8392
    14       0.799903                    0.0336691          0.0985045  1.24482            0.0486224        0.0462004  0.614451                    0.615487            0.00983929      0.995736                   -90.1495  24.4822
    15       0.899951                    0.0233629          0.0295035  1.10971            0.0145631        0.0275162  0.54776                     0.550122            0.00295179      0.998688                   -97.0496  10.9713
    16       1                           0.0127468          0.0131127  1                  0.00647249       0.0198044  0.493605                    0.497064            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:08:15  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:08:27  1 min 45.230 sec  1254 obs/sec      0.59776   1             14944      0.31123          0.320502            0.612509       0.940722        0.901983           2.01933          0.133699                         0.307922           0.311655              0.620673         0.943713          0.903617             2.02591            0.130484
    2019-08-03 16:08:39  1 min 57.841 sec  1265 obs/sec      1.18956   2             29739      0.300089         0.294898            0.639755       0.946676        0.925257           1.99933          0.123729                         0.292347           0.282477              0.658078         0.951076          0.93135              2.02591            0.111705
    2019-08-03 16:08:52  2 min 10.336 sec  1280 obs/sec      1.78544   3             44636      0.299509         0.294072            0.641144       0.946905        0.932956           2.01933          0.12323                          0.291639           0.282103              0.659732         0.951181          0.942836             2.02591            0.116561
    2019-08-03 16:09:04  2 min 22.844 sec  1286 obs/sec      2.37988   4             59497      0.295571         0.286906            0.650519       0.949876        0.943165           2.01933          0.120937                         0.289403           0.276769              0.664928         0.953503          0.945554             2.02591            0.110571
    2019-08-03 16:09:17  2 min 35.507 sec  1284 obs/sec      2.97352   5             74338      0.29584          0.286956            0.649883       0.950035        0.941575           1.99933          0.118245                         0.289832           0.278457              0.663935         0.952997          0.943699             2.02591            0.113324
    2019-08-03 16:09:30  2 min 48.307 sec  1283 obs/sec      3.56824   6             89206      0.294146         0.284979            0.653881       0.950846        0.945833           1.99933          0.122034                         0.28624            0.273353              0.672214         0.954349          0.94536              2.02591            0.1096
    2019-08-03 16:09:42  3 min  0.950 sec  1283 obs/sec      4.16376   7             104094     0.293857         0.284248            0.654561       0.951493        0.944595           2.01933          0.119143                         0.287202           0.274495              0.670007         0.954578          0.949985             2.02591            0.11219
    2019-08-03 16:09:55  3 min 13.513 sec  1285 obs/sec      4.75696   8             118924     0.293669         0.284632            0.655003       0.951487        0.944722           2.01933          0.118245                         0.286879           0.274225              0.670748         0.954954          0.949874             2.02591            0.114781
    2019-08-03 16:10:08  3 min 26.554 sec  1282 obs/sec      5.35764   9             133941     0.291081         0.280912            0.661057       0.953211        0.942457           1.99933          0.118146                         0.284311           0.270647              0.676617         0.956569          0.952814             2.02591            0.109924
    2019-08-03 16:10:21  3 min 39.506 sec  1280 obs/sec      5.9522    10            148805     0.292561         0.283171            0.657601       0.952036        0.943804           2.01933          0.115952                         0.286121           0.272787              0.672486         0.955461          0.946313             2.02591            0.111219
    2019-08-03 16:10:35  3 min 53.507 sec  1266 obs/sec      6.54264   11            163566     0.293952         0.285843            0.654337       0.951094        0.941222           1.99933          0.11655                          0.286707           0.274812              0.671143         0.954652          0.950969             2.02591            0.109114
    2019-08-03 16:10:48  4 min  6.368 sec  1267 obs/sec      7.13976   12            178494     0.294643         0.288119            0.652709       0.952596        0.944966           1.99933          0.117248                         0.285182           0.272434              0.674632         0.956975          0.951592             2.02591            0.112514
    2019-08-03 16:11:01  4 min 19.211 sec  1266 obs/sec      7.7306    13            193265     0.295626         0.289357            0.650389       0.950246        0.944117           1.97934          0.118445                         0.288424           0.279418              0.667193         0.953113          0.947187             2.02591            0.1096
    2019-08-03 16:11:13  4 min 31.549 sec  1270 obs/sec      8.3264    14            208160     0.301783         0.30102             0.635674       0.947637        0.941584           1.99933          0.123729                         0.292655           0.287478              0.657356         0.951321          0.945192             1.99323            0.113324
    2019-08-03 16:11:26  4 min 44.083 sec  1272 obs/sec      8.91888   15            222972     0.294432         0.287109            0.653208       0.951862        0.944074           1.99933          0.118046                         0.287243           0.277047              0.669911         0.954231          0.948064             1.99323            0.108791
    2019-08-03 16:11:38  4 min 56.710 sec  1273 obs/sec      9.5146    16            237865     0.295082         0.289032            0.651675       0.950157        0.943789           1.99933          0.121436                         0.286825           0.276567              0.670871         0.954353          0.9504               2.02591            0.111057
    2019-08-03 16:11:51  5 min  9.141 sec  1275 obs/sec      10.1113   17            252783     0.297166         0.292825            0.646737       0.948501        0.942823           1.97934          0.122034                         0.28883            0.280343              0.666253         0.952134          0.943942             1.92788            0.110571
    2019-08-03 16:11:52  5 min 10.173 sec  1275 obs/sec      10.1113   17            252783     0.291081         0.280912            0.661057       0.953211        0.942457           1.99933          0.118146                         0.284311           0.270647              0.676617         0.956569          0.952814             2.02591            0.109924
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005686382943904971
C438        0.8692151308059692     0.8692151308059692   0.004942690094399192
C88         0.6978039145469666     0.6978039145469666   0.003967980277869993
C374        0.6812651753425598     0.6812651753425598   0.0038739346733443615
C863        0.6492807865142822     0.6492807865142822   0.003692059190240019
---         ---                    ---                  ---
C476        0.09908141940832138    0.09908141940832138  0.0005634148933813737
C963        0.09785912930965424    0.09785912930965424  0.0005564644838118089
C925        0.0977800041437149     0.0977800041437149   0.0005560145478177779
C949        0.09704525023698807    0.09704525023698807  0.0005518364557345988
C912        0.09332620352506638    0.09332620352506638  0.0005306885319443414

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_168

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 252,983 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.048007488421606986   0.06191651523113251     0.0         -0.0005133606105812983  0.10664844512939453  0.0022361366460867532  0.12602674961090088
    3        2        Softmax                 0.0   0.0   0.0018235719617223367  0.00048796599730849266  0.0         -0.008015503241836086   0.2526646852493286   -0.02686441894904501   0.12623101472854614


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08685251679434022
RMSE: 0.2947075105835279
LogLoss: 0.28771245032576664
Mean Per-Class Error: 0.11869058109999475
AUC: 0.9508511143099811
pr_auc: 0.948509619227006
Gini: 0.9017022286199623
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.39455341005754185: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4154  812   0.1635   (812.0/4966.0)
1      407   4643  0.0806   (407.0/5050.0)
Total  4561  5455  0.1217   (1219.0/10016.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.394553     0.88396   236
max f2                       0.134727     0.921799  322
max f0point5                 0.751265     0.89904   127
max accuracy                 0.517935     0.88139   199
max precision                0.975415     1         0
max recall                   0.0175557    1         397
max specificity              0.975415     1         0
max absolute_mcc             0.517935     0.762841  199
max min_per_class_accuracy   0.554143     0.879178  188
max mean_per_class_accuracy  0.517935     0.881309  199
Gains/Lift Table: Avg response rate: 50.42 %, avg score: 50.62 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100839                   0.971671           1.98337    1.98337            1                0.972962   1                           0.972962            0.02            0.02                       98.3366   98.3366
    2        0.0200679                   0.970174           1.96353    1.9735             0.99             0.970897   0.995025                    0.971934            0.019604        0.039604                   96.3533   97.3499
    3        0.0300519                   0.969331           1.9437     1.9636             0.98             0.96974    0.990033                    0.971205            0.0194059       0.0590099                  94.3699   96.3599
    4        0.0400359                   0.968232           1.98337    1.96853            1                0.968802   0.992519                    0.970606            0.019802        0.0788119                  98.3366   96.8528
    5        0.05002                     0.967169           1.96353    1.96753            0.99             0.967699   0.992016                    0.970026            0.019604        0.0984158                  96.3533   96.7531
    6        0.10004                     0.962431           1.97545    1.97149            0.996008         0.964798   0.994012                    0.967412            0.0988119       0.197228                   97.5449   97.149
    7        0.15006                     0.956601           1.9319     1.95829            0.974052         0.959557   0.987359                    0.964794            0.0966337       0.293861                   93.1902   95.8294
    8        0.20008                     0.94909            1.9319     1.9517             0.974052         0.952988   0.984032                    0.961842            0.0966337       0.390495                   93.1902   95.1696
    9        0.30002                     0.919094           1.86845    1.92396            0.942058         0.936652   0.97005                     0.953451            0.186733        0.577228                   86.8446   92.3964
    10       0.40006                     0.827672           1.6825     1.86358            0.848303         0.881945   0.939606                    0.93557             0.168317        0.745545                   68.2496   86.3582
    11       0.5                         0.566392           1.3097     1.75287            0.66034          0.716887   0.883786                    0.89186             0.130891        0.876436                   30.9695   75.2871
    12       0.60004                     0.216931           0.777907   1.59032            0.392216         0.379066   0.80183                     0.806366            0.0778218       0.954257                   -22.2093  59.0323
    13       0.69998                     0.0696718          0.303152   1.40655            0.152847         0.127563   0.709171                    0.709449            0.030297        0.984554                   -69.6848  40.6546
    14       0.80002                     0.0339332          0.0890733  1.2418             0.0449102        0.0481077  0.626108                    0.626751            0.00891089      0.993465                   -91.0927  24.1801
    15       0.89996                     0.0232023          0.051516   1.10962            0.025974         0.0276061  0.559463                    0.560216            0.00514851      0.998614                   -94.8484  10.962
    16       1                           0.0143623          0.0138559  1                  0.00698603       0.0198928  0.504193                    0.506162            0.00138614      1                          -98.6144  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08052986709722511
RMSE: 0.28377784814397533
LogLoss: 0.2707150471586486
Mean Per-Class Error: 0.10929875964531577
AUC: 0.9564770198438296
pr_auc: 0.9517433708213754
Gini: 0.9129540396876592
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4563401558447276: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2723  405   0.1295   (405.0/3128.0)
1      275   2774  0.0902   (275.0/3049.0)
Total  2998  3179  0.1101   (680.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.45634      0.890816  212
max f2                       0.248867     0.924762  275
max f0point5                 0.753957     0.906583  125
max accuracy                 0.494327     0.890562  201
max precision                0.974743     1         0
max recall                   0.0183492    1         395
max specificity              0.974743     1         0
max absolute_mcc             0.494327     0.781393  201
max min_per_class_accuracy   0.543647     0.889144  188
max mean_per_class_accuracy  0.494327     0.890701  201
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.72 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.971671           2.02591    2.02591            1                0.972883   1                           0.972883            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.97027            2.02591    2.02591            1                0.970953   1                           0.971918            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.969182           2.02591    2.02591            1                0.969689   1                           0.971175            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.968026           2.02591    2.02591            1                0.968598   1                           0.970531            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.966819           2.02591    2.02591            1                0.96741    1                           0.969915            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.962324           2.0128     2.01935            0.993528         0.964561   0.996764                    0.967238            0.100689        0.202033                   101.28    101.935
    7        0.150073                    0.95655            1.96035    1.99968            0.967638         0.959609   0.987055                    0.964695            0.0980649       0.300098                   96.0347   99.9685
    8        0.200097                    0.949509           1.9669     1.99149            0.970874         0.953362   0.98301                     0.961862            0.0983929       0.398491                   96.6903   99.1489
    9        0.299984                    0.917059           1.93726    1.97343            0.95624          0.936204   0.974096                    0.953318            0.193506        0.591997                   93.7256   97.3431
    10       0.400032                    0.822199           1.73415    1.91359            0.855987         0.877418   0.944557                    0.934336            0.1735          0.765497                   73.4153   91.3587
    11       0.500081                    0.517336           1.30143    1.79112            0.642395         0.695623   0.884105                    0.886578            0.130207        0.895704                   30.1434   79.1117
    12       0.599968                    0.189541           0.656697   1.60225            0.324149         0.33421    0.79088                     0.794616            0.0655953       0.961299                   -34.3303  60.2251
    13       0.700016                    0.0639535          0.245863   1.40839            0.121359         0.112919   0.69519                     0.697185            0.0245982       0.985897                   -75.4137  40.8392
    14       0.799903                    0.0327148          0.0952211  1.24441            0.0470016        0.0451395  0.614248                    0.615762            0.00951132      0.995408                   -90.4779  24.4412
    15       0.899951                    0.0228451          0.0327817  1.10971            0.0161812        0.0271879  0.54776                     0.55033             0.00327976      0.998688                   -96.7218  10.9713
    16       1                           0.0139212          0.0131127  1                  0.00647249       0.019742   0.493605                    0.497245            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:26:23  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:26:30  3:19:48.803  1272 obs/sec      0.35732   1             8933       0.344848         0.446704            0.524287       0.921258        0.771523           1.98337          0.157847                         0.336059           0.423407              0.548183         0.927197          0.763367             2.02591            0.14554
    2019-08-03 19:26:46  3:20:04.297  1262 obs/sec      1.07952   3             26988      0.30896          0.313487            0.618148       0.940417        0.915402           1.98337          0.129193                         0.297234           0.291783              0.646549         0.94793           0.911143             2.02591            0.11559
    2019-08-03 19:27:01  3:20:20.003  1255 obs/sec      1.80348   5             45087      0.301059         0.295831            0.637429       0.946606        0.939919           1.98337          0.128195                         0.290459           0.278592              0.662479         0.952873          0.943901             2.02591            0.116723
    2019-08-03 19:27:18  3:20:36.765  1238 obs/sec      2.5278    7             63195      0.298892         0.293056            0.64263        0.948241        0.94427            1.98337          0.120807                         0.288058           0.2753                0.668036         0.95386           0.948124             2.02591            0.114619
    2019-08-03 19:27:41  3:20:59.264  1245 obs/sec      3.6086    10            90215      0.29683          0.289808            0.647542       0.949565        0.946488           1.98337          0.119708                         0.286824           0.273574              0.670873         0.95494           0.949784             2.02591            0.113647
    2019-08-03 19:27:56  3:21:14.796  1248 obs/sec      4.33528   12            108382     0.297227         0.293018            0.646599       0.949207        0.942769           1.98337          0.11891                          0.286989           0.276256              0.670495         0.954331          0.942907             2.02591            0.109114
    2019-08-03 19:28:12  3:21:30.124  1251 obs/sec      5.05228   14            126307     0.296953         0.291915            0.647251       0.948995        0.936319           1.98337          0.121206                         0.288097           0.276772              0.667945         0.953976          0.941502             2.02591            0.112352
    2019-08-03 19:28:27  3:21:45.550  1255 obs/sec      5.7738    16            144345     0.298471         0.297591            0.643636       0.949084        0.930069           1.98337          0.120507                         0.287055           0.277131              0.670343         0.955098          0.934945             2.02591            0.108791
    2019-08-03 19:28:43  3:22:01.139  1255 obs/sec      6.50084   18            162521     0.294708         0.287712            0.652565       0.950851        0.94851            1.98337          0.121705                         0.283778           0.270715              0.677828         0.956477          0.951743             2.02591            0.110086
    2019-08-03 19:28:58  3:22:16.223  1259 obs/sec      7.221     20            180525     0.29478          0.289577            0.652395       0.951073        0.94587            1.96373          0.119908                         0.285304           0.275304              0.674353         0.955805          0.952866             2.02591            0.108305
    2019-08-03 19:29:14  3:22:32.196  1256 obs/sec      7.94772   22            198693     0.298377         0.295439            0.643859       0.950369        0.940531           1.98337          0.119509                         0.287586           0.277119              0.669123         0.955404          0.944976             2.02591            0.110086
    2019-08-03 19:29:29  3:22:47.601  1258 obs/sec      8.67232   24            216808     0.297655         0.293498            0.645582       0.951125        0.940003           1.96373          0.119908                         0.2886             0.2786                0.666785         0.955711          0.947573             2.02591            0.110733
    2019-08-03 19:29:44  3:23:02.864  1259 obs/sec      9.39736   26            234934     0.298666         0.296039            0.643169       0.948741        0.945623           1.94409          0.119109                         0.28898            0.280625              0.665907         0.954076          0.948873             1.99323            0.109924
    2019-08-03 19:30:00  3:23:18.317  1259 obs/sec      10.1193   28            252983     0.302071         0.308164            0.634988       0.950107        0.944571           1.98337          0.119509                         0.291126           0.2875                0.660928         0.95571           0.948044             2.02591            0.111381
    2019-08-03 19:30:01  3:23:19.460  1259 obs/sec      10.1193   28            252983     0.294708         0.287712            0.652565       0.950851        0.94851            1.98337          0.121705                         0.283778           0.270715              0.677828         0.956477          0.951743             2.02591            0.110086
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006016306216523724
C438        0.8625160455703735     0.8625160455703735   0.005189160646816498
C374        0.7466544508934021     0.7466544508934021   0.004492101814505082
C863        0.7028983235359192     0.7028983235359192   0.004228851553473255
C88         0.6845117211341858     0.6845117211341858   0.004118232123142956
---         ---                    ---                  ---
C652        0.09166216105222702    0.09166216105222702  0.0005514676293585122
C936        0.09120495617389679    0.09120495617389679  0.0005487169448067891
C758        0.09046521782875061    0.09046521782875061  0.0005442664524022852
C859        0.08961552381515503    0.08961552381515503  0.0005391544330261471
C785        0.08156818151473999    0.08156818151473999  0.0004907391575176657

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_46

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 233,347 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.035475129847333975   0.06100362539291382     0.0         0.001276116971686843  0.08193925023078918  -0.0015892376999561704  0.09839004278182983
    3        2        Softmax                 0.0   0.0   0.0016974976724668522  0.00024147704243659973  0.0         -0.0489808706258259   0.35237908363342285  0.003120650300406695    0.0935463011264801


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08764124508503779
RMSE: 0.2960426406533994
LogLoss: 0.28953056855879
Mean Per-Class Error: 0.12080098610517098
AUC: 0.9491550460084824
pr_auc: 0.9361114699095606
Gini: 0.8983100920169649
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.36933181795513675: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4173  819   0.1641   (819.0/4992.0)
1      399   4637  0.0792   (399.0/5036.0)
Total  4572  5456  0.1215   (1218.0/10028.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.369332     0.883912  242
max f2                       0.164848     0.919488  306
max f0point5                 0.757941     0.894855  120
max accuracy                 0.408779     0.879338  229
max precision                0.979169     0.995025  2
max recall                   0.0129401    1         399
max specificity              0.981388     0.9998    0
max absolute_mcc             0.408779     0.760079  229
max min_per_class_accuracy   0.513577     0.878005  198
max mean_per_class_accuracy  0.408779     0.879199  229
Gains/Lift Table: Avg response rate: 50.22 %, avg score: 49.68 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100718                   0.979914           1.97155     1.97155            0.990099         0.980808   0.990099                    0.980808            0.019857        0.019857                   97.1547   97.1547
    2        0.0200439                   0.978759           1.99126     1.98136            1                0.97934    0.995025                    0.980078            0.019857        0.0397141                  99.1263   98.1356
    3        0.030016                    0.977766           1.97135     1.97803            0.99             0.978292   0.993355                    0.979485            0.0196585       0.0593725                  97.135    97.8032
    4        0.0400878                   0.976792           1.93212     1.9665             0.970297         0.977298   0.987562                    0.978935            0.0194599       0.0788324                  93.2116   96.6496
    5        0.0500598                   0.975641           1.97135     1.96746            0.99             0.976237   0.988048                    0.978398            0.0196585       0.0984909                  97.135    96.7463
    6        0.10002                     0.96994            1.95947     1.96347            0.984032         0.972818   0.986042                    0.975611            0.0978952       0.196386                   95.9466   96.3469
    7        0.15008                     0.962              1.94366     1.95686            0.976096         0.966397   0.982724                    0.972537            0.0972994       0.293685                   94.3663   95.6862
    8        0.20004                     0.951274           1.9237      1.94858            0.966068         0.956941   0.978564                    0.968642            0.096108        0.389793                   92.3695   94.8579
    9        0.30006                     0.911554           1.87214     1.9231             0.940179         0.933598   0.965769                    0.956961            0.187252        0.577045                   87.2144   92.3101
    10       0.39998                     0.792702           1.70708     1.86914            0.857285         0.8631     0.938669                    0.933513            0.170572        0.747617                   70.7081   86.9136
    11       0.5                         0.518171           1.28648     1.75258            0.646062         0.671068   0.880136                    0.881014            0.128674        0.876291                   28.6479   75.2581
    12       0.60002                     0.197602           0.77427     1.5895             0.388833         0.352446   0.798238                    0.792904            0.0774424       0.953733                   -22.573   58.9502
    13       0.69994                     0.0698467          0.306042    1.40628            0.153693         0.123219   0.706226                    0.697303            0.0305798       0.984313                   -69.3958  40.6282
    14       0.79996                     0.0320384          0.105221    1.24361            0.0528415        0.0473955  0.624533                    0.616045            0.0105242       0.994837                   -89.4779  24.3608
    15       0.89998                     0.0186412          0.0436768   1.11025            0.0219342        0.0245151  0.557562                    0.550304            0.00436855      0.999206                   -95.6323  11.0253
    16       1                           0.0122111          0.00794123  1                  0.00398804       0.0155416  0.502194                    0.496818            0.000794281     1                          -99.2059  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08108730988343384
RMSE: 0.28475833593318006
LogLoss: 0.2707297719909951
Mean Per-Class Error: 0.11018664456670635
AUC: 0.9558939390634974
pr_auc: 0.9430096542297601
Gini: 0.9117878781269948
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.41818361787427943: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2701  427   0.1365   (427.0/3128.0)
1      265   2784  0.0869   (265.0/3049.0)
Total  2966  3211  0.112    (692.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.418184     0.889457  223
max f2                       0.154407     0.92427   309
max f0point5                 0.73816      0.902895  128
max accuracy                 0.5733       0.889914  178
max precision                0.98129      1         0
max recall                   0.0133966    1         398
max specificity              0.98129      1         0
max absolute_mcc             0.5733       0.780005  178
max min_per_class_accuracy   0.51348      0.887832  197
max mean_per_class_accuracy  0.548044     0.889813  186
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.26 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.980147           2.02591     2.02591            1                0.980947   1                           0.980947            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.979059           2.02591     2.02591            1                0.979519   1                           0.980233            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.978219           2.02591     2.02591            1                0.978623   1                           0.979697            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.977351           2.02591     2.02591            1                0.977768   1                           0.979214            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.976469           1.9927      2.01935            0.983607         0.976871   0.996764                    0.978752            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.970539           2.0128      2.01608            0.993528         0.973608   0.995146                    0.97618             0.100689        0.201705                   101.28    101.608
    7        0.150073                    0.963117           1.98002     2.00406            0.977346         0.96709    0.989213                    0.97315             0.0990489       0.300754                   98.0016   100.406
    8        0.200097                    0.952731           1.97346     1.99641            0.97411          0.958204   0.985437                    0.969414            0.0987209       0.399475                   97.3459   99.6407
    9        0.299984                    0.911589           1.90442     1.96578            0.940032         0.934999   0.970318                    0.957955            0.190226        0.589702                   90.4421   96.5778
    10       0.400032                    0.801985           1.75054     1.91195            0.864078         0.865427   0.943747                    0.934813            0.175139        0.764841                   75.0544   91.1948
    11       0.500081                    0.494358           1.27849     1.78521            0.631068         0.667737   0.881191                    0.881381            0.127911        0.892752                   27.8487   78.5214
    12       0.599968                    0.179357           0.705949    1.60553            0.34846          0.323085   0.792499                    0.788432            0.0705149       0.963267                   -29.4051  60.5531
    13       0.700016                    0.0663548          0.213081    1.40652            0.105178         0.111977   0.694265                    0.691751            0.0213185       0.984585                   -78.6919  40.6518
    14       0.799903                    0.0308239          0.111638    1.24482            0.0551053        0.0448861  0.614451                    0.610975            0.0111512       0.995736                   -88.8362  24.4822
    15       0.899951                    0.0184947          0.0393381   1.11081            0.0194175        0.0238148  0.5483                      0.545699            0.00393572      0.999672                   -96.0662  11.0807
    16       1                           0.0124027          0.00327817  1                  0.00161812       0.0154541  0.493605                    0.492649            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:57:17  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:57:23  50 min 41.469 sec  2504 obs/sec      0.62448   1             15612      0.319098         0.344964            0.592699       0.935945        0.860658           1.97155          0.137515                         0.310924           0.325307              0.613241         0.941769          0.850253             2.02591            0.131455
    2019-08-03 16:57:30  50 min 48.285 sec  2507 obs/sec      1.24752   2             31188      0.301528         0.299201            0.636317       0.945156        0.924558           1.97155          0.124651                         0.295319           0.28858               0.651089         0.949221          0.931612             2.02591            0.116238
    2019-08-03 16:57:37  50 min 55.008 sec  2508 obs/sec      1.87      3             46750      0.299115         0.293816            0.642113       0.947232        0.938974           1.97155          0.12495                          0.288945           0.27594               0.665988         0.953767          0.944182             2.02591            0.115752
    2019-08-03 16:57:44  51 min  1.762 sec  2517 obs/sec      2.4906    4             62265      0.295734         0.290766            0.650159       0.949103        0.939722           1.97155          0.119465                         0.285487           0.27439               0.673935         0.955601          0.949177             2.02591            0.109762
    2019-08-03 16:57:51  51 min  8.828 sec  2495 obs/sec      3.11044   5             77761      0.296043         0.289531            0.649428       0.949155        0.936111           1.97155          0.12146                          0.284758           0.27073               0.675598         0.955894          0.94301              2.02591            0.112028
    2019-08-03 16:57:58  51 min 15.577 sec  2502 obs/sec      3.73276   6             93319      0.297006         0.293861            0.647143       0.948396        0.934801           1.95183          0.122258                         0.286721           0.277306              0.671111         0.954965          0.950371             2.02591            0.109924
    2019-08-03 16:58:04  51 min 22.408 sec  2502 obs/sec      4.35264   7             108816     0.294474         0.289537            0.653135       0.9502          0.945451           1.97155          0.120762                         0.284747           0.274245              0.675623         0.955899          0.935625             1.99323            0.111057
    2019-08-03 16:58:11  51 min 29.187 sec  2505 obs/sec      4.97448   8             124362     0.294916         0.290106            0.652092       0.949295        0.937385           1.97155          0.120363                         0.28395            0.272461              0.677437         0.955738          0.939153             1.99323            0.107819
    2019-08-03 16:58:18  51 min 35.891 sec  2511 obs/sec      5.59612   9             139903     0.295852         0.291675            0.649879       0.948982        0.920538           1.99126          0.120562                         0.285189           0.27431               0.674616         0.95529           0.935764             2.02591            0.111219
    2019-08-03 16:58:25  51 min 42.832 sec  2508 obs/sec      6.2202    10            155505     0.294864         0.29211             0.652215       0.949444        0.943694           1.97155          0.119765                         0.285401           0.276561              0.674132         0.955708          0.949538             2.02591            0.109924
    2019-08-03 16:58:31  51 min 49.447 sec  2516 obs/sec      6.8406    11            171015     0.296166         0.292765            0.649136       0.949504        0.920107           1.95183          0.119266                         0.287219           0.276944              0.669967         0.955258          0.921454             2.02591            0.113162
    2019-08-03 16:58:38  51 min 56.082 sec  2523 obs/sec      7.46164   12            186541     0.297937         0.296315            0.644928       0.948708        0.930539           1.99126          0.118767                         0.288303           0.278884              0.66747          0.955012          0.943684             2.02591            0.113
    2019-08-03 16:58:50  52 min  8.539 sec  2540 obs/sec      8.71104   14            217776     0.29742          0.2967              0.646158       0.948084        0.921881           1.97155          0.119366                         0.288195           0.281673              0.667721         0.953654          0.933798             2.02591            0.111381
    2019-08-03 16:58:57  52 min 15.218 sec  2542 obs/sec      9.33388   15            233347     0.299479         0.299625            0.641242       0.946888        0.880544           1.95183          0.118967                         0.290329           0.283729              0.662782         0.952516          0.883157             2.02591            0.114133
    2019-08-03 16:58:58  52 min 15.880 sec  2542 obs/sec      9.33388   15            233347     0.296043         0.289531            0.649428       0.949155        0.936111           1.97155          0.12146                          0.284758           0.27073               0.675598         0.955894          0.94301              2.02591            0.112028
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006398774346401189
C438        0.8149320483207703     0.8149320483207703   0.005214566284855119
C374        0.7161833643913269     0.7161833643913269   0.004582695739386518
C88         0.5913079380989075     0.5913079380989075   0.0037836460651306716
C322        0.5815466046333313     0.5815466046333313   0.0037211854949644753
---         ---                    ---                  ---
C741        0.08778902888298035    0.08778902888298035  0.0005617421859118877
C921        0.08693394809961319    0.08693394809961319  0.0005562707169311773
C541        0.08691509068012238    0.08691509068012238  0.0005561500525591001
C879        0.0850725993514061     0.0850725993514061   0.0005443603663114438
C899        0.08414892107248306    0.08414892107248306  0.0005384499574359431

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_156

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 250,785 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.05085791739171578    0.07021796703338623    0.0         -0.000864167342320852  0.09421348571777344  0.0050619840072673875  0.11532041430473328
    3        2        Softmax                 0.0   0.0   0.0018296212499535613  0.0004573924234136939  0.0         -0.025990518899675408  0.2399558424949646   0.0008808673488199179  0.10209089517593384


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08667852372241068
RMSE: 0.29441216639672124
LogLoss: 0.286738981339574
Mean Per-Class Error: 0.11612310375617052
AUC: 0.9509090986680927
pr_auc: 0.9482611165609752
Gini: 0.9018181973361854
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47485491693234494: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4213  688   0.1404   (688.0/4901.0)
1      492   4624  0.0962   (492.0/5116.0)
Total  4705  5312  0.1178   (1180.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.474855     0.886843  214
max f2                       0.143973     0.920193  321
max f0point5                 0.7456       0.899669  130
max accuracy                 0.563372     0.883798  187
max precision                0.974632     0.992278  4
max recall                   0.0183895    1         395
max specificity              0.97949      0.999796  0
max absolute_mcc             0.563372     0.767609  187
max min_per_class_accuracy   0.547756     0.883085  191
max mean_per_class_accuracy  0.563372     0.883877  187
Gains/Lift Table: Avg response rate: 51.07 %, avg score: 51.28 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   0.976164           1.9192     1.9192             0.980198         0.977451   0.980198                    0.977451            0.0193511       0.0193511                  91.9203   91.9203
    2        0.0200659                   0.974682           1.95797    1.93849            1                0.975382   0.99005                     0.976421            0.0195465       0.0388976                  95.7975   93.8493
    3        0.0300489                   0.973694           1.9384     1.93846            0.99             0.974164   0.990033                    0.975671            0.0193511       0.0582486                  93.8395   93.846
    4        0.0400319                   0.972775           1.9384     1.93844            0.99             0.973266   0.990025                    0.975072            0.0193511       0.0775997                  93.8395   93.8444
    5        0.050015                    0.971823           1.95797    1.94234            1                0.972292   0.992016                    0.974517            0.0195465       0.0971462                  95.7975   94.2342
    6        0.10003                     0.967421           1.93843    1.94039            0.99002          0.969678   0.991018                    0.972097            0.0969507       0.194097                   93.8434   94.0388
    7        0.150045                    0.962185           1.94234    1.94104            0.992016         0.964966   0.991351                    0.96972             0.0971462       0.291243                   94.2342   94.104
    8        0.20006                     0.953675           1.90717    1.93257            0.974052         0.958138   0.987026                    0.966825            0.095387        0.38663                    90.7169   93.2572
    9        0.29999                     0.921069           1.84844    1.90455            0.944056         0.93967    0.972712                    0.957779            0.184715        0.571345                   84.8438   90.4546
    10       0.40002                     0.83046            1.69418    1.85194            0.865269         0.882458   0.945845                    0.938944            0.169468        0.740813                   69.4176   85.194
    11       0.50005                     0.578342           1.34049    1.74963            0.684631         0.723234   0.893592                    0.895794            0.134089        0.874902                   34.049    74.963
    12       0.59998                     0.246214           0.727639   1.57941            0.371628         0.406392   0.806656                    0.814281            0.0727131       0.947615                   -27.2361  57.9411
    13       0.70001                     0.0764406          0.34587    1.40314            0.176647         0.145501   0.716629                    0.718714            0.0345973       0.982213                   -65.413   40.3141
    14       0.79994                     0.0348423          0.121273   1.24301            0.0619381        0.0514068  0.634843                    0.635352            0.0121188       0.994332                   -87.8727  24.3007
    15       0.89997                     0.0219531          0.0390813  1.10919            0.0199601        0.0271339  0.5665                      0.56775             0.0039093       0.998241                   -96.0919  10.9193
    16       1                           0.0127169          0.0175866  1                  0.00898204       0.0186898  0.510732                    0.512828            0.00175919      1                          -98.2413  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08120273544332907
RMSE: 0.28496093669717093
LogLoss: 0.27076809889867093
Mean Per-Class Error: 0.10953147818369868
AUC: 0.956542657061684
pr_auc: 0.9527109265124052
Gini: 0.9130853141233679
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4618209766420624: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2717  411   0.1314   (411.0/3128.0)
1      268   2781  0.0879   (268.0/3049.0)
Total  2985  3192  0.1099   (679.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.461821     0.891203  211
max f2                       0.209847     0.922312  292
max f0point5                 0.770609     0.906498  119
max accuracy                 0.472357     0.890238  207
max precision                0.980811     1         0
max recall                   0.0167599    1         397
max specificity              0.980811     1         0
max absolute_mcc             0.472357     0.781139  207
max min_per_class_accuracy   0.543579     0.886829  188
max mean_per_class_accuracy  0.472357     0.890469  207
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.95 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.976392           2.02591     2.02591            1                0.977641   1                           0.977641            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.975083           2.02591     2.02591            1                0.975769   1                           0.976705            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.973945           1.99323     2.01502            0.983871         0.974464   0.994624                    0.975958            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.973041           1.99323     2.00957            0.983871         0.973503   0.991935                    0.975344            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.972216           2.02591     2.0128             1                0.972598   0.993528                    0.974802            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.967311           2.0128      2.0128             0.993528         0.969733   0.993528                    0.972268            0.100689        0.201378                   101.28    101.28
    7        0.150073                    0.961811           2.01935     2.01498            0.996764         0.964761   0.994606                    0.969766            0.101017        0.302394                   101.935   101.498
    8        0.200097                    0.953797           1.95379     1.99968            0.964401         0.957906   0.987055                    0.966801            0.097737        0.400131                   95.379    99.9685
    9        0.299984                    0.915926           1.90442     1.96796            0.940032         0.93802    0.971398                    0.957217            0.190226        0.590357                   90.4421   96.7965
    10       0.400032                    0.814984           1.7571      1.91523            0.867314         0.873286   0.945366                    0.936226            0.175795        0.766153                   75.71     91.5227
    11       0.500081                    0.520455           1.26537     1.78521            0.624595         0.688969   0.881191                    0.886759            0.126599        0.892752                   26.5374   78.5214
    12       0.599968                    0.201805           0.686248    1.60225            0.338736         0.347384   0.79088                     0.79696             0.0685471       0.961299                   -31.3752  60.2251
    13       0.700016                    0.0683194          0.258976    1.41027            0.127832         0.121649   0.696115                    0.700442            0.0259101       0.987209                   -74.1024  41.0266
    14       0.799903                    0.0328873          0.0952211   1.24605            0.0470016        0.0473734  0.615058                    0.618891            0.00951132      0.99672                    -90.4779  24.6052
    15       0.899951                    0.0216753          0.0229472   1.11008            0.0113269        0.0262531  0.54794                     0.553007            0.00229583      0.999016                   -97.7053  11.0078
    16       1                           0.0135452          0.00983452  1                  0.00485437       0.0185388  0.493605                    0.499534            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:05:26  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:05:34  2:58:51.975  1277 obs/sec      0.38384   1             9596       0.340754         0.44402             0.535332       0.924147        0.7797             1.95797          0.147549                         0.327256           0.40379               0.571545         0.932583          0.803313             2.02591            0.137607
    2019-08-03 19:05:50  2:59:08.353  1273 obs/sec      1.15892   3             28973      0.310401         0.315307            0.614426       0.940081        0.925056           1.95797          0.133673                         0.302627           0.299084              0.633607         0.94601           0.932082             2.02591            0.12498
    2019-08-03 19:06:06  2:59:24.624  1273 obs/sec      1.92888   5             48222      0.300073         0.295113            0.639658       0.946968        0.936342           1.95797          0.125187                         0.291447           0.279194              0.660178         0.952993          0.940347             2.02591            0.116076
    2019-08-03 19:06:22  2:59:40.897  1273 obs/sec      2.69884   7             67471      0.296479         0.290121            0.648239       0.948797        0.944042           1.9192           0.119996                         0.287314           0.273926              0.669748         0.954805          0.944432             2.02591            0.111219
    2019-08-03 19:06:38  2:59:56.812  1275 obs/sec      3.46176   9             86544      0.297459         0.2917              0.645909       0.948228        0.942206           1.95797          0.122192                         0.286902           0.274539              0.670695         0.954037          0.945752             2.02591            0.110895
    2019-08-03 19:06:55  3:00:13.609  1270 obs/sec      4.24256   11            106064     0.29474          0.28635             0.652354       0.951013        0.944733           1.95797          0.118099                         0.285711           0.271113              0.673423         0.956151          0.944874             2.02591            0.111057
    2019-08-03 19:07:13  3:00:31.104  1255 obs/sec      5.01068   13            125267     0.294412         0.286739            0.653126       0.950909        0.948261           1.9192           0.1178                           0.284961           0.270768              0.675136         0.956543          0.952711             2.02591            0.109924
    2019-08-03 19:07:29  3:00:47.861  1253 obs/sec      5.7852    15            144630     0.295038         0.289349            0.651651       0.949961        0.946536           1.9192           0.116602                         0.286196           0.274559              0.672315         0.955637          0.951822             2.02591            0.111867
    2019-08-03 19:07:46  3:01:04.211  1256 obs/sec      6.55816   17            163954     0.299346         0.297138            0.641402       0.950206        0.939065           1.95797          0.120395                         0.285826           0.274143              0.673161         0.956776          0.947306             2.02591            0.107981
    2019-08-03 19:08:02  3:01:20.407  1257 obs/sec      7.32612   19            183153     0.294221         0.28769             0.653576       0.950998        0.94709            1.95797          0.119397                         0.284726           0.271603              0.675672         0.956288          0.946828             1.99323            0.111057
    2019-08-03 19:08:18  3:01:36.677  1259 obs/sec      8.09496   21            202374     0.294415         0.288236            0.65312        0.950694        0.948002           1.93859          0.117301                         0.284574           0.271995              0.676017         0.956149          0.951641             2.02591            0.107334
    2019-08-03 19:08:34  3:01:53.012  1261 obs/sec      8.87524   23            221881     0.296246         0.292913            0.648791       0.94992         0.948337           1.9192           0.120695                         0.283226           0.271585              0.679079         0.956871          0.953291             2.02591            0.10701
    2019-08-03 19:08:51  3:02:09.131  1263 obs/sec      9.65056   25            241264     0.295654         0.290844            0.650195       0.950326        0.949894           1.95797          0.117001                         0.284171           0.27289               0.676935         0.955763          0.948117             2.02591            0.107981
    2019-08-03 19:08:59  3:02:17.481  1265 obs/sec      10.0314   26            250785     0.297391         0.293885            0.64607        0.950706        0.951063           1.93859          0.117001                         0.285092           0.27333               0.674837         0.956092          0.949261             2.02591            0.108953
    2019-08-03 19:09:00  3:02:18.605  1265 obs/sec      10.0314   26            250785     0.294412         0.286739            0.653126       0.950909        0.948261           1.9192           0.1178                           0.284961           0.270768              0.675136         0.956543          0.952711             2.02591            0.109924
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005486602517267076
C438        0.93202805519104       0.93202805519104     0.005113667473774698
C374        0.712448239326477      0.712448239326477    0.003908920303311145
C88         0.6722250580787659     0.6722250580787659   0.0036882316958249633
C863        0.6581701040267944     0.6581701040267944   0.0036111177495433437
---         ---                    ---                  ---
C879        0.1071401834487915     0.1071401834487915   0.0005878356002105958
C884        0.1058681383728981     0.1058681383728981   0.0005808563944951218
C671        0.10557106137275696    0.10557106137275696  0.0005792264510783253
C908        0.10464552044868469    0.10464552044868469  0.0005741483759144768
C899        0.10215767472982407    0.10215767472982407  0.0005604985553308039

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_72

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 218,014 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.04306002598352595    0.06190425157546997    0.0         -0.0012630712695982445  0.0954321026802063   -0.00031671151242271766  0.10131743550300598
    3        2        Softmax                 0.0   0.0   0.0017873565084300935  0.0003733376506716013  0.0         0.039342595032223926    0.35708558559417725  -0.0025288509377734067   0.08659085631370544


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08640298842013831
RMSE: 0.2939438524959117
LogLoss: 0.28761063536424303
Mean Per-Class Error: 0.11687505746069693
AUC: 0.950479675535152
pr_auc: 0.9372501401431902
Gini: 0.900959351070304
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4148387231107564: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4296  770   0.152    (770.0/5066.0)
1      428   4536  0.0862   (428.0/4964.0)
Total  4724  5306  0.1194   (1198.0/10030.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.414839     0.88335   231
max f2                       0.134903     0.917865  324
max f0point5                 0.763842     0.89754   125
max accuracy                 0.604068     0.883051  176
max precision                0.974231     1         0
max recall                   0.0201639    1         397
max specificity              0.974231     1         0
max absolute_mcc             0.604068     0.766354  176
max min_per_class_accuracy   0.5383       0.881366  194
max mean_per_class_accuracy  0.513763     0.883125  201
Gains/Lift Table: Avg response rate: 49.49 %, avg score: 49.85 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100698                   0.972818           2.02055    2.02055            1                0.973741   1                           0.973741            0.0203465       0.0203465                  102.055   102.055
    2        0.0200399                   0.971552           1.98014    2.00044            0.98             0.972144   0.99005                     0.972947            0.0197421       0.0400886                  98.0137   100.044
    3        0.03001                     0.97045            2.02055    2.00712            1                0.970973   0.993355                    0.972291            0.020145        0.0602337                  102.055   100.712
    4        0.0400798                   0.969441           2.00054    2.00547            0.990099         0.9699     0.992537                    0.97169             0.020145        0.0803787                  100.054   100.547
    5        0.0500499                   0.968673           2.00034    2.00445            0.99             0.969043   0.992032                    0.971163            0.0199436       0.100322                   100.034   100.445
    6        0.1                         0.963832           2.00442    2.00443            0.992016         0.966261   0.992024                    0.968715            0.100121        0.200443                   100.442   100.443
    7        0.15005                     0.957699           1.9642     1.99101            0.972112         0.960932   0.985382                    0.966119            0.0983078       0.298751                   96.4198   99.1012
    8        0.2                         0.947844           1.95199    1.98127            0.966068         0.952826   0.980558                    0.962799            0.097502        0.396253                   95.1986   98.1265
    9        0.3                         0.911428           1.88356    1.9487             0.932203         0.932621   0.96444                     0.952739            0.188356        0.584609                   88.3562   94.8697
    10       0.4                         0.810786           1.7365     1.89565            0.859422         0.869913   0.938185                    0.932033            0.17365         0.758259                   73.6503   89.5649
    11       0.5                         0.524111           1.28324    1.77317            0.635095         0.69194    0.877567                    0.884014            0.128324        0.886583                   28.3239   77.3167
    12       0.6                         0.197288           0.682917   1.59146            0.337986         0.347549   0.787637                    0.794603            0.0682917       0.954875                   -31.7083  59.1459
    13       0.7                         0.0687412          0.288074   1.40526            0.142572         0.119399   0.695485                    0.698146            0.0288074       0.983683                   -71.1926  40.5261
    14       0.8                         0.0348895          0.106769   1.24295            0.0528415        0.0480683  0.615155                    0.616886            0.0106769       0.994359                   -89.3231  24.2949
    15       0.9                         0.0244165          0.0423046  1.10954            0.0209372        0.0286943  0.54913                     0.551531            0.00423046      0.99859                    -95.7695  10.9544
    16       1                           0.0173784          0.0141015  1                  0.00697906       0.0215042  0.494915                    0.498529            0.00141015      1                          -98.5898  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08059707800208109
RMSE: 0.2838962451355796
LogLoss: 0.2710115718115974
Mean Per-Class Error: 0.10876291459444587
AUC: 0.9564024177982969
pr_auc: 0.9516951365926939
Gini: 0.9128048355965939
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49090862619890085: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2742  386   0.1234   (386.0/3128.0)
1      289   2760  0.0948   (289.0/3049.0)
Total  3031  3146  0.1093   (675.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.490909     0.891041  206
max f2                       0.17327      0.922793  303
max f0point5                 0.803199     0.907491  105
max accuracy                 0.536889     0.891209  192
max precision                0.974824     1         0
max recall                   0.02191      1         394
max specificity              0.974824     1         0
max absolute_mcc             0.536889     0.782423  192
max min_per_class_accuracy   0.546104     0.890026  190
max mean_per_class_accuracy  0.536889     0.891237  192
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.84 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.972832           2.02591     2.02591            1                0.97362    1                           0.97362             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.97133            2.02591     2.02591            1                0.971975   1                           0.972798            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.970449           1.99323     2.01502            0.983871         0.970889   0.994624                    0.972162            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.96961            2.02591     2.01774            1                0.970052   0.995968                    0.971634            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.968727           2.02591     2.01935            1                0.96919    0.996764                    0.971152            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.964293           2.0128      2.01608            0.993528         0.966458   0.995146                    0.968805            0.100689        0.201705                   101.28    101.608
    7        0.150073                    0.958055           1.9669      1.99968            0.970874         0.961309   0.987055                    0.966306            0.0983929       0.300098                   96.6903   99.9685
    8        0.200097                    0.949124           1.97346     1.99313            0.97411          0.953874   0.983819                    0.963198            0.0987209       0.398819                   97.3459   99.3128
    9        0.299984                    0.912489           1.92084     1.96906            0.948136         0.934294   0.971937                    0.953574            0.191866        0.590685                   92.0839   96.9058
    10       0.400032                    0.81439            1.78333     1.92261            0.880259         0.87348    0.949008                    0.933542            0.178419        0.769105                   78.3325   92.2606
    11       0.500081                    0.523406           1.26865     1.79177            0.626214         0.693233   0.884429                    0.885465            0.126927        0.896031                   26.8652   79.1773
    12       0.599968                    0.188945           0.656697    1.6028             0.324149         0.342213   0.791149                    0.795021            0.0655953       0.961627                   -34.3303  60.2798
    13       0.700016                    0.0652093          0.226194    1.40605            0.11165          0.116762   0.694033                    0.698082            0.0226304       0.984257                   -77.3806  40.6049
    14       0.799903                    0.0350173          0.118205    1.24523            0.0583468        0.0476376  0.614653                    0.616858            0.0118071       0.996064                   -88.1795  24.5232
    15       0.899951                    0.0241803          0.0327817   1.11044            0.0161812        0.0286515  0.54812                     0.551467            0.00327976      0.999344                   -96.7218  11.0442
    16       1                           0.017335           0.00655634  1                  0.00323625       0.0214476  0.493605                    0.498439            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:25:56  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:26:03  1:19:21.278  2466 obs/sec      0.67592   1             16898      0.315162         0.339925            0.602652       0.937653        0.874651           2.02055          0.135494                         0.309039           0.321446              0.617917         0.942782          0.8865               2.02591            0.131941
    2019-08-03 17:26:11  1:19:29.635  2435 obs/sec      1.3456    2             33640      0.301268         0.297652            0.636912       0.946133        0.933622           2.02055          0.126919                         0.292404           0.282716              0.657943         0.951956          0.943005             2.02591            0.115752
    2019-08-03 17:26:26  1:19:44.084  2431 obs/sec      2.68424   4             67106      0.29599          0.289698            0.649523       0.949227        0.941512           2.00054          0.120339                         0.285972           0.273017              0.672827         0.955155          0.950991             2.02591            0.1096
    2019-08-03 17:26:33  1:19:51.170  2460 obs/sec      3.35148   5             83787      0.293976         0.28736             0.654278       0.950342        0.942774           2.02055          0.117547                         0.284942           0.272505              0.675179         0.955525          0.949416             2.02591            0.110571
    2019-08-03 17:26:40  1:19:58.356  2476 obs/sec      4.0246    6             100615     0.293944         0.287611            0.654352       0.95048         0.93725            2.02055          0.119442                         0.283896           0.271012              0.677559         0.956402          0.951695             2.02591            0.109276
    2019-08-03 17:26:48  1:20:05.854  2470 obs/sec      4.69748   7             117437     0.296843         0.292651            0.6475         0.948921        0.936147           2.02055          0.119541                         0.288236           0.278546              0.667626         0.953643          0.946473             1.99323            0.111057
    2019-08-03 17:26:55  1:20:13.181  2475 obs/sec      5.37204   8             134301     0.293634         0.287349            0.655081       0.95106         0.940297           2.02055          0.115852                         0.284484           0.272458              0.676223         0.956089          0.948343             2.02591            0.108953
    2019-08-03 17:27:02  1:20:20.411  2481 obs/sec      6.04148   9             151037     0.296235         0.291734            0.648943       0.951025        0.937552           2.02055          0.117049                         0.287657           0.275789              0.668961         0.956387          0.943837             2.02591            0.111705
    2019-08-03 17:27:10  1:20:27.605  2488 obs/sec      6.70964   10            167741     0.294128         0.289352            0.65392        0.950925        0.94064            2.00054          0.115055                         0.285752           0.274931              0.673329         0.956181          0.948276             2.02591            0.110086
    2019-08-03 17:27:17  1:20:34.910  2490 obs/sec      7.37692   11            184423     0.294004         0.289634            0.654211       0.950615        0.925678           2.02055          0.114756                         0.285626           0.27546               0.673617         0.955934          0.935724             2.02591            0.108791
    2019-08-03 17:27:24  1:20:42.136  2495 obs/sec      8.04832   12            201208     0.294656         0.291309            0.652675       0.950351        0.944679           2.02055          0.114656                         0.285279           0.27494               0.674411         0.9563            0.92794              2.02591            0.108305
    2019-08-03 17:27:31  1:20:49.217  2502 obs/sec      8.72056   13            218014     0.297099         0.295555            0.646893       0.95001         0.938274           2.02055          0.117448                         0.288119           0.278915              0.667896         0.955729          0.945329             2.02591            0.113486
    2019-08-03 17:27:32  1:20:49.884  2502 obs/sec      8.72056   13            218014     0.293944         0.287611            0.654352       0.95048         0.93725            2.02055          0.119442                         0.283896           0.271012              0.677559         0.956402          0.951695             2.02591            0.109276
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.00625609860322275
C438        0.8490334749221802     0.8490334749221802   0.005311637136550009
C374        0.7143393158912659     0.7143393158912659   0.0044689771963744435
C88         0.6840636730194092     0.6840636730194092   0.00427956978929215
C322        0.6698077917098999     0.6698077917098999   0.004190383590144019
---         ---                    ---                  ---
C925        0.08630147576332092    0.08630147576332092  0.0005399105419789741
C848        0.08618228882551193    0.08618228882551193  0.0005391648967438249
C887        0.08540118485689163    0.08540118485689163  0.0005342782332967677
C958        0.08353711664676666    0.08353711664676666  0.0005226164387710929
C839        0.08064162731170654    0.08064162731170654  0.0005045019719863769

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_222

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 253,718 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.03344955919072033    0.05119884014129639    0.0         0.0009647981589566839  0.08966764807701111  -0.007462872868715406  0.09705844521522522
    3        2        Softmax                 0.0   0.0   0.0020311420771577104  0.0006200540810823441  0.0         -0.06345953433810791   0.3695880174636841   -0.017469143714803414  0.07975253462791443


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08558891437153314
RMSE: 0.29255583120411927
LogLoss: 0.2851280219726547
Mean Per-Class Error: 0.1155761541185173
AUC: 0.9516874925403281
pr_auc: 0.943343464972953
Gini: 0.9033749850806563
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4528607151733297: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4335  731   0.1443   (731.0/5066.0)
1      441   4504  0.0892   (441.0/4945.0)
Total  4776  5235  0.1171   (1172.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.452861     0.884872  215
max f2                       0.182221     0.918659  305
max f0point5                 0.794013     0.89833   111
max accuracy                 0.532833     0.884327  192
max precision                0.973282     1         0
max recall                   0.0222348    1         396
max specificity              0.973282     1         0
max absolute_mcc             0.532833     0.768809  192
max min_per_class_accuracy   0.560822     0.883721  184
max mean_per_class_accuracy  0.532833     0.884424  192
Gains/Lift Table: Avg response rate: 49.40 %, avg score: 50.02 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   0.971381           2.02447     2.02447            1                0.972323   1                           0.972323            0.0204247       0.0204247                  102.447   102.447
    2        0.0200779                   0.970507           2.02447     2.02447            1                0.970902   1                           0.971616            0.0202224       0.0406471                  102.447   102.447
    3        0.0300669                   0.969589           2.02447     2.02447            1                0.970011   1                           0.971083            0.0202224       0.0608696                  102.447   102.447
    4        0.0400559                   0.968666           2.02447     2.02447            1                0.969063   1                           0.970579            0.0202224       0.081092                   102.447   102.447
    5        0.050045                    0.967878           2.02447     2.02447            1                0.96824    1                           0.970112            0.0202224       0.101314                   102.447   102.447
    6        0.10009                     0.963047           1.99618     2.01033            0.986028         0.965455   0.993014                    0.967784            0.0998989       0.201213                   99.6183   101.033
    7        0.150035                    0.957294           1.98398     2.00156            0.98             0.960277   0.988682                    0.965285            0.09909         0.300303                   98.398    100.156
    8        0.20008                     0.947537           1.93153     1.98404            0.954092         0.952782   0.98003                     0.962157            0.0966633       0.396967                   93.1529   98.404
    9        0.30007                     0.910237           1.90312     1.95708            0.94006          0.931792   0.966711                    0.952039            0.190293        0.58726                    90.3122   95.7077
    10       0.40006                     0.810633           1.72717     1.89961            0.853147         0.868971   0.938327                    0.931277            0.1727          0.75996                    72.7169   89.9614
    11       0.50005                     0.542802           1.28628     1.77697            0.635365         0.69079    0.877747                    0.883189            0.128615        0.888574                   28.6276   77.6971
    12       0.60004                     0.202496           0.683587    1.59477            0.337662         0.356363   0.787748                    0.7954              0.0683519       0.956926                   -31.6413  59.4771
    13       0.70003                     0.0744979          0.279098    1.40684            0.137862         0.125158   0.69492                     0.699664            0.027907        0.984833                   -72.0902  40.6844
    14       0.80002                     0.0371491          0.105167    1.24415            0.0519481        0.0512104  0.614559                    0.618618            0.0105157       0.995349                   -89.4833  24.4155
    15       0.90001                     0.0253384          0.0404489   1.11042            0.01998          0.0303753  0.548502                    0.553265            0.00404449      0.999393                   -95.9551  11.0425
    16       1                           0.0188553          0.00606734  1                  0.002997         0.0226561  0.493957                    0.500209            0.000606673     1                          -99.3933  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08042875395159911
RMSE: 0.2835996367268462
LogLoss: 0.27106251734284553
Mean Per-Class Error: 0.10795125692126639
AUC: 0.9563875812706192
pr_auc: 0.9475040449065052
Gini: 0.9127751625412384
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38649289896885713: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2663  465   0.1487   (465.0/3128.0)
1      219   2830  0.0718   (219.0/3049.0)
Total  2882  3295  0.1107   (684.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.386493     0.892182  233
max f2                       0.192287     0.922086  297
max f0point5                 0.794146     0.904747  107
max accuracy                 0.525352     0.892019  194
max precision                0.972875     1         0
max recall                   0.0260494    1         390
max specificity              0.972875     1         0
max absolute_mcc             0.525352     0.784045  194
max min_per_class_accuracy   0.537672     0.890985  191
max mean_per_class_accuracy  0.525352     0.892049  194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.60 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.971189           2.02591    2.02591            1                0.972131   1                           0.972131            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.970475           1.99323    2.00957            0.983871         0.970771   0.991935                    0.971451            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.969556           2.02591    2.01502            1                0.970006   0.994624                    0.970969            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.968636           1.99323    2.00957            0.983871         0.969104   0.991935                    0.970503            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.967878           2.02591    2.0128             1                0.968277   0.993528                    0.970063            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.963137           2.00624    2.00952            0.990291         0.96564    0.991909                    0.967852            0.100361        0.20105                    100.624   100.952
    7        0.150073                    0.957333           2.0128     2.01061            0.993528         0.960395   0.992449                    0.965366            0.100689        0.301738                   101.28    101.061
    8        0.200097                    0.947567           1.94723    1.99477            0.961165         0.952826   0.984628                    0.962231            0.097409        0.399147                   94.7234   99.4768
    9        0.299984                    0.908246           1.92084    1.97015            0.948136         0.931133   0.972477                    0.951876            0.191866        0.591013                   92.0839   97.0151
    10       0.400032                    0.806014           1.74399    1.91359            0.860841         0.866611   0.944557                    0.930551            0.174483        0.765497                   74.3987   91.3587
    11       0.500081                    0.513524           1.31127    1.79308            0.647249         0.67714    0.885076                    0.879853            0.131191        0.896687                   31.1269   79.3085
    12       0.599968                    0.195018           0.643563   1.6017             0.317666         0.336967   0.79061                     0.789469            0.0642834       0.960971                   -35.6437  60.1704
    13       0.700016                    0.0717391          0.236028   1.40652            0.116505         0.119825   0.694265                    0.693762            0.0236143       0.984585                   -76.3972  40.6518
    14       0.799903                    0.0365094          0.108355   1.24441            0.0534846        0.0504784  0.614248                    0.613433            0.0108232       0.995408                   -89.1645  24.4412
    15       0.899951                    0.0254414          0.0458944  1.11117            0.0226537        0.030122   0.54848                     0.548585            0.00459167      1                          -95.4106  11.1171
    16       1                           0.0190902          0          1                  0                0.022678   0.493605                    0.495969            0               1                          -100      0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:35:39  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:35:45  4:29:02.865  2502 obs/sec      0.59944   1             14986      0.320877         0.344418            0.58809        0.93515         0.88219            2.02447          0.140645                         0.31283            0.326543              0.608485         0.940538          0.891063             2.02591            0.13356
    2019-08-03 20:35:51  4:29:09.491  2491 obs/sec      1.19656   2             29914      0.300861         0.297056            0.637878       0.946146        0.931158           2.02447          0.125961                         0.292379           0.282494              0.658003         0.95139           0.93847              2.02591            0.120285
    2019-08-03 20:35:58  4:29:16.173  2481 obs/sec      1.79588   3             44897      0.298418         0.293302            0.643735       0.947451        0.939125           2.02447          0.121466                         0.290422           0.279738              0.662566         0.952167          0.942783             2.02591            0.114619
    2019-08-03 20:36:05  4:29:22.953  2475 obs/sec      2.39564   4             59891      0.296475         0.290156            0.64836        0.949664        0.936789           2.02447          0.119968                         0.287847           0.275076              0.668523         0.954892          0.946252             2.02591            0.112514
    2019-08-03 20:36:17  4:29:35.535  2486 obs/sec      3.591     6             89775      0.292556         0.285128            0.657594       0.951687        0.943343           2.02447          0.117071                         0.2836             0.271063              0.678232         0.956388          0.947504             2.02591            0.110733
    2019-08-03 20:36:24  4:29:42.303  2480 obs/sec      4.18604   7             104651     0.29421          0.288682            0.653712       0.950795        0.941011           2.00442          0.11827                          0.285161           0.274084              0.674681         0.955762          0.951492             2.02591            0.110895
    2019-08-03 20:36:37  4:29:54.837  2489 obs/sec      5.37456   9             134364     0.294171         0.288207            0.653804       0.951122        0.937913           2.00442          0.116272                         0.284415           0.272414              0.67638          0.956118          0.942892             2.02591            0.108791
    2019-08-03 20:36:49  4:30:07.302  2498 obs/sec      6.56964   11            164241     0.295379         0.291957            0.650954       0.949835        0.919824           2.02447          0.119169                         0.285924           0.275735              0.672936         0.954619          0.916542             2.02591            0.111705
    2019-08-03 20:37:02  4:30:19.962  2498 obs/sec      7.766     13            194150     0.296894         0.295238            0.647364       0.9486          0.942173           2.02447          0.121067                         0.286395           0.277548              0.671858         0.953971          0.95112              2.02591            0.113
    2019-08-03 20:37:14  4:30:32.179  2507 obs/sec      8.95864   15            223966     0.29895          0.301961            0.642464       0.946445        0.927977           2.00442          0.116971                         0.28924            0.284007              0.665306         0.95147           0.934753             2.02591            0.113
    2019-08-03 20:37:20  4:30:38.499  2514 obs/sec      9.55096   16            238774     0.297103         0.299269            0.646868       0.947259        0.940838           1.96434          0.120068                         0.288927           0.28581               0.66603          0.952118          0.927788             2.02591            0.113324
    2019-08-03 20:37:27  4:30:44.957  2518 obs/sec      10.1487   17            253718     0.297085         0.297621            0.646911       0.946965        0.939053           1.92425          0.117371                         0.28893            0.283838              0.666023         0.951091          0.944627             1.99323            0.113
    2019-08-03 20:37:28  4:30:45.558  2517 obs/sec      10.1487   17            253718     0.292556         0.285128            0.657594       0.951687        0.943343           2.02447          0.117071                         0.2836             0.271063              0.678232         0.956388          0.947504             2.02591            0.110733
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006009796333819244
C438        0.7703452110290527     0.7703452110290527   0.004629617825017613
C374        0.6961635947227478     0.6961635947227478   0.004183801419303196
C863        0.6495548486709595     0.6495548486709595   0.0039036923481572464
C79         0.6482338905334473     0.6482338905334473   0.0038957536587852968
---         ---                    ---                  ---
C906        0.09568346291780472    0.09568346291780472  0.0005750381246505524
C727        0.09388058632612228    0.09388058632612228  0.0005642032035195308
C758        0.09373918920755386    0.09373918920755386  0.0005633534356347457
C743        0.0924827829003334     0.0924827829003334   0.0005558026896158248
C829        0.09176415950059891    0.09176415950059891  0.0005514839093427036

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_30

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 237,517 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.04024672114199125    0.06163862347602844    0.0         0.0006321024538365798  0.09340164065361023  -0.002513567484309918   0.09814152121543884
    3        2        Softmax                 0.0   0.0   0.0024482222597725922  0.0007768708746880293  0.0         0.05838857531747266    0.3482480049133301   -0.0009374957591915881  0.1229417622089386


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08985678992050573
RMSE: 0.29976122150889656
LogLoss: 0.2961576502144843
Mean Per-Class Error: 0.12147306766934873
AUC: 0.9478432938842138
pr_auc: 0.9382431902737123
Gini: 0.8956865877684277
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4497445285532084: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4297  701   0.1403   (701.0/4998.0)
1      518   4515  0.1029   (518.0/5033.0)
Total  4815  5216  0.1215   (1219.0/10031.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.449745     0.881062  220
max f2                       0.118312     0.916887  327
max f0point5                 0.705268     0.894307  141
max accuracy                 0.467941     0.878576  214
max precision                0.979126     1         0
max recall                   0.0136319    1         398
max specificity              0.979126     1         0
max absolute_mcc             0.458606     0.757527  217
max min_per_class_accuracy   0.527579     0.876416  196
max mean_per_class_accuracy  0.467941     0.878527  214
Gains/Lift Table: Avg response rate: 50.17 %, avg score: 49.65 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100688                   0.97852            1.99305     1.99305            1                0.97892    1                           0.97892             0.0200676       0.0200676                  99.3046   99.3046
    2        0.0200379                   0.977852           1.99305     1.99305            1                0.978213   1                           0.978568            0.0198689       0.0399364                  99.3046   99.3046
    3        0.030007                    0.977171           1.99305     1.99305            1                0.977489   1                           0.97821             0.0198689       0.0598053                  99.3046   99.3046
    4        0.0400758                   0.976414           1.99305     1.99305            1                0.97679    1                           0.977853            0.0200676       0.0798728                  99.3046   99.3046
    5        0.0500449                   0.97573            1.97312     1.98908            0.99             0.976077   0.998008                    0.977499            0.0196702       0.099543                   97.3115   98.9076
    6        0.10009                     0.971317           1.98114     1.98511            0.994024         0.973708   0.996016                    0.975604            0.0991456       0.198689                   98.1135   98.5105
    7        0.150035                    0.965071           1.95724     1.97583            0.982036         0.968415   0.991362                    0.973211            0.0977548       0.296443                   95.7243   97.583
    8        0.20008                     0.955355           1.88585     1.95332            0.946215         0.960669   0.98007                     0.970073            0.0943771       0.390821                   88.585    95.3324
    9        0.30007                     0.917862           1.84799     1.91822            0.927218         0.939364   0.962458                    0.95984             0.18478         0.575601                   84.7989   91.8224
    10       0.40006                     0.811102           1.70492     1.86491            0.855434         0.873632   0.935709                    0.938294            0.170475        0.746076                   70.4919   86.4911
    11       0.50005                     0.531808           1.29161     1.75027            0.648056         0.69001    0.87819                     0.888647            0.129148        0.875224                   29.1605   75.0273
    12       0.60004                     0.181992           0.753105    1.58411            0.377866         0.340438   0.794816                    0.797294            0.075303        0.950527                   -24.6895  58.4106
    13       0.70003                     0.0585079          0.331843    1.40524            0.1665           0.107871   0.70507                     0.698819            0.033181        0.983708                   -66.8157  40.5236
    14       0.80002                     0.0259368          0.105315    1.24277            0.0528415        0.0383115  0.623551                    0.616266            0.0105305       0.994238                   -89.4685  24.2767
    15       0.90001                     0.0163882          0.04769     1.10999            0.0239282        0.0204409  0.556934                    0.55007             0.00476853      0.999007                   -95.231   10.9995
    16       1                           0.0116906          0.00993542  1                  0.00498504       0.014371   0.501745                    0.496506            0.000993443     1                          -99.0065  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08154280424684461
RMSE: 0.2855570070000815
LogLoss: 0.2711556760019886
Mean Per-Class Error: 0.11129896473540857
AUC: 0.9561434863134867
pr_auc: 0.9527117410569887
Gini: 0.9122869726269733
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.451741803065278: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2725  403   0.1288   (403.0/3128.0)
1      294   2755  0.0964   (294.0/3049.0)
Total  3019  3158  0.1128   (697.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.451742     0.887707  214
max f2                       0.120696     0.923125  325
max f0point5                 0.803138     0.906161  109
max accuracy                 0.595585     0.888943  174
max precision                0.980095     1         0
max recall                   0.0171832    1         392
max specificity              0.980095     1         0
max absolute_mcc             0.595585     0.778226  174
max min_per_class_accuracy   0.525268     0.886192  195
max mean_per_class_accuracy  0.595585     0.888701  174
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.05 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.978501           2.02591    2.02591            1                0.978892   1                           0.978892            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.977872           2.02591    2.02591            1                0.978203   1                           0.978547            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.977169           1.99323    2.01502            0.983871         0.977495   0.994624                    0.978197            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.976407           2.02591    2.01774            1                0.976752   0.995968                    0.977836            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.975769           1.9927     2.0128             0.983607         0.976095   0.993528                    0.977492            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.971498           2.02591    2.01935            1                0.973761   0.996764                    0.975626            0.101345        0.202033                   102.591   101.935
    7        0.150073                    0.96483            1.98657    2.00843            0.980583         0.968333   0.99137                     0.973195            0.0993768       0.30141                    98.6572   100.843
    8        0.200097                    0.956077           1.96035    1.99641            0.967638         0.960925   0.985437                    0.970128            0.0980649       0.399475                   96.0347   99.6407
    9        0.299984                    0.916734           1.90442    1.96578            0.940032         0.938888   0.970318                    0.959726            0.190226        0.589702                   90.4421   96.5778
    10       0.400032                    0.807858           1.77349    1.91769            0.875405         0.872468   0.94658                     0.937903            0.177435        0.767137                   77.3491   91.7687
    11       0.500081                    0.495556           1.22276    1.77866            0.60356          0.675926   0.877954                    0.88549             0.122335        0.889472                   22.2758   77.8656
    12       0.599968                    0.16333            0.72565    1.60334            0.358185         0.309314   0.791419                    0.789565            0.0724828       0.961955                   -27.435   60.3344
    13       0.700016                    0.0547251          0.249141   1.4098             0.122977         0.0967573  0.695883                    0.690546            0.0249262       0.986881                   -75.0859  40.9797
    14       0.799903                    0.0252942          0.0820871  1.244              0.0405186        0.0367659  0.614046                    0.608906            0.00819941      0.99508                    -91.7913  24.4001
    15       0.899951                    0.016347           0.0491726  1.11117            0.0242718        0.0202768  0.54848                     0.543468            0.00491965      1                          -95.0827  11.1171
    16       1                           0.0118977          0          1                  0                0.0142853  0.493605                    0.490524            0               1                          -100      0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:41:22  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:41:28  34 min 46.416 sec  2546 obs/sec      0.63052   1             15763      0.315603         0.325617            0.601575       0.935879        0.902229           1.99305          0.135679                         0.307823           0.309075              0.620919         0.941876          0.918893             2.02591            0.128056
    2019-08-03 16:41:35  34 min 53.235 sec  2533 obs/sec      1.26152   2             31538      0.304314         0.301999            0.629569       0.944448        0.93498            1.99305          0.129299                         0.292603           0.282021              0.657478         0.951692          0.942974             2.02591            0.114781
    2019-08-03 16:41:42  35 min  0.217 sec  2516 obs/sec      1.89432   3             47358      0.30202          0.299667            0.635132       0.945769        0.940114           1.99305          0.121822                         0.290348           0.279448              0.662737         0.953664          0.950516             2.02591            0.117047
    2019-08-03 16:41:49  35 min  7.068 sec  2521 obs/sec      2.52884   4             63221      0.301788         0.298368            0.635691       0.946574        0.94191            1.99305          0.127405                         0.289152           0.277271              0.66551          0.953806          0.944041             2.02591            0.115266
    2019-08-03 16:41:56  35 min 14.011 sec  2515 obs/sec      3.16064   5             79016      0.300126         0.297468            0.639694       0.947473        0.945042           1.99305          0.119928                         0.287071           0.276921              0.670306         0.954694          0.949563             2.02591            0.111543
    2019-08-03 16:42:03  35 min 20.866 sec  2516 obs/sec      3.79352   6             94838      0.299761         0.296158            0.640568       0.947843        0.938243           1.99305          0.121523                         0.285557           0.271156              0.673775         0.956143          0.952712             2.02591            0.112838
    2019-08-03 16:42:10  35 min 27.727 sec  2520 obs/sec      4.42772   7             110693     0.299004         0.297263            0.642381       0.947758        0.943733           1.99305          0.123118                         0.285777           0.275786              0.673272         0.955789          0.949716             2.02591            0.111381
    2019-08-03 16:42:16  35 min 34.520 sec  2525 obs/sec      5.05852   8             126463     0.301186         0.300386            0.637144       0.947983        0.938939           1.97331          0.121324                         0.286652           0.274044              0.671268         0.956113          0.945229             2.02591            0.112676
    2019-08-03 16:42:23  35 min 41.350 sec  2530 obs/sec      5.69452   9             142363     0.301142         0.301187            0.63725        0.948453        0.935265           1.97331          0.123019                         0.287141           0.275363              0.670146         0.956333          0.935435             1.99323            0.111381
    2019-08-03 16:42:30  35 min 48.157 sec  2534 obs/sec      6.3306    10            158265     0.30105          0.30018             0.637471       0.948023        0.942814           1.97331          0.122022                         0.286485           0.274336              0.671653         0.956395          0.948778             1.99323            0.109438
    2019-08-03 16:42:37  35 min 55.141 sec  2530 obs/sec      6.96472   11            174118     0.301731         0.303499            0.635829       0.947854        0.936206           1.99305          0.119529                         0.287981           0.277475              0.668213         0.95593           0.944819             1.99323            0.110571
    2019-08-03 16:42:44  36 min  1.842 sec  2535 obs/sec      7.599     12            189975     0.300225         0.300988            0.639456       0.946978        0.939957           1.93385          0.121025                         0.285458           0.27501               0.674002         0.955897          0.95111              2.02591            0.106848
    2019-08-03 16:42:51  36 min  8.669 sec  2537 obs/sec      8.23552   13            205888     0.300739         0.302969            0.63822        0.946204        0.939579           1.91411          0.120825                         0.287079           0.278622              0.670289         0.954558          0.949666             2.02591            0.111867
    2019-08-03 16:42:57  36 min 15.332 sec  2543 obs/sec      8.86796   14            221699     0.302175         0.307646            0.634756       0.944527        0.93923            1.95358          0.121324                         0.287565           0.283209              0.669172         0.95406           0.947536             1.92788            0.111543
    2019-08-03 16:43:04  36 min 22.094 sec  2546 obs/sec      9.50068   15            237517     0.302983         0.306823            0.6328         0.944996        0.936971           1.93385          0.120427                         0.287774           0.27875               0.668691         0.954917          0.948154             1.96056            0.111219
    2019-08-03 16:43:05  36 min 22.661 sec  2545 obs/sec      9.50068   15            237517     0.299761         0.296158            0.640568       0.947843        0.938243           1.99305          0.121523                         0.285557           0.271156              0.673775         0.956143          0.952712             2.02591            0.112838
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0062355201365460605
C438        0.8571308255195618     0.8571308255195618   0.0053446565221815755
C374        0.7771704196929932     0.7771704196929932   0.004846061801523612
C88         0.722206175327301      0.722206175327301    0.0045033311489913
C863        0.6489388346672058     0.6489388346672058   0.004046471170954097
---         ---                    ---                  ---
C958        0.08554651588201523    0.08554651588201523  0.0005334270223936634
C758        0.08485310524702072    0.08485310524702072  0.00052910324641626
C990        0.08470079302787781    0.08470079302787781  0.0005281535005067522
C925        0.08301741629838943    0.08301741629838943  0.0005176567710126345
C947        0.08188813179731369    0.08188813179731369  0.0005106150947662872

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_207

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 251,650 weights/biases, 3.0 MB, 256,617 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight              weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  --------------------  ----------  -----------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0664440442679098    0.09063246846199036   0.0         -0.00013294513845126392  0.13188081979751587  -0.0029362719126731136  0.12832826375961304
    3        2        Softmax                 0.0   0.0   0.001981180051643605  0.000599077669903636  0.0         -0.00724227894284013     0.24886393547058105  -0.036145111292135663   0.1308368444442749


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08735628506835576
RMSE: 0.295560966753656
LogLoss: 0.29240628118567147
Mean Per-Class Error: 0.11444753219785342
AUC: 0.9487192077637011
pr_auc: 0.9434241134005269
Gini: 0.8974384155274022
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5287599968924895: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4396  632   0.1257   (632.0/5028.0)
1      515   4467  0.1034   (515.0/4982.0)
Total  4911  5099  0.1146   (1147.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.52876      0.886222  195
max f2                       0.13684      0.919292  318
max f0point5                 0.805503     0.89585   108
max accuracy                 0.541271     0.885514  192
max precision                0.976859     1         0
max recall                   0.0181202    1         395
max specificity              0.976859     1         0
max absolute_mcc             0.541271     0.771162  192
max min_per_class_accuracy   0.581965     0.884248  181
max mean_per_class_accuracy  0.541271     0.885552  192
Gains/Lift Table: Avg response rate: 49.77 %, avg score: 50.46 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   0.973215           2.00923    2.00923            1                0.97425    1                           0.97425             0.020273        0.020273                   100.923   100.923
    2        0.0200799                   0.972053           2.00923    2.00923            1                0.972556   1                           0.973407            0.0200723       0.0403452                  100.923   100.923
    3        0.0300699                   0.971334           2.00923    2.00923            1                0.971712   1                           0.972844            0.0200723       0.0604175                  100.923   100.923
    4        0.0400599                   0.970636           2.00923    2.00923            1                0.970951   1                           0.972372            0.0200723       0.0804898                  100.923   100.923
    5        0.05005                     0.969979           1.94896    1.9972             0.97             0.9703     0.994012                    0.971958            0.0194701       0.0999599                  94.8956   99.7202
    6        0.1                         0.966373           1.97709    1.98715            0.984            0.968255   0.989011                    0.970109            0.0987555       0.198715                   97.7086   98.7154
    7        0.15005                     0.962045           1.93303    1.9691             0.962076         0.964348   0.980027                    0.968187            0.0967483       0.295464                   93.3035   96.9102
    8        0.2                         0.956271           1.90877    1.95403            0.95             0.959588   0.972527                    0.966039            0.0953432       0.390807                   90.8772   95.4035
    9        0.3                         0.932425           1.87676    1.92828            0.934066         0.946218   0.959707                    0.959432            0.187676        0.578483                   87.6756   92.8275
    10       0.4                         0.853957           1.74026    1.88127            0.866134         0.900874   0.936314                    0.944793            0.174026        0.752509                   74.0265   88.1273
    11       0.5                         0.570267           1.33681    1.77238            0.665335         0.733208   0.882118                    0.902476            0.133681        0.88619                    33.6813   77.2381
    12       0.6                         0.177724           0.672421   1.58905            0.334665         0.350407   0.790876                    0.810464            0.0672421       0.953432                   -32.7579  58.9054
    13       0.7                         0.0555123          0.301084   1.40506            0.14985          0.103261   0.699301                    0.709435            0.0301084       0.983541                   -69.8916  40.5058
    14       0.8                         0.0277816          0.118426   1.24423            0.0589411        0.0386209  0.619256                    0.625583            0.0118426       0.995383                   -88.1574  24.4229
    15       0.9                         0.0202492          0.0361301  1.11               0.017982         0.0233263  0.552448                    0.558666            0.00361301      0.998996                   -96.387   10.9996
    16       1                           0.0132208          0.0100361  1                  0.004995         0.0179076  0.497702                    0.50459             0.00100361      1                          -98.9964  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08062435241603501
RMSE: 0.2839442769559461
LogLoss: 0.2711817101025214
Mean Per-Class Error: 0.10712135503737341
AUC: 0.9568655481357772
pr_auc: 0.9509557473945733
Gini: 0.9137310962715544
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3987994527310672: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2688  440   0.1407   (440.0/3128.0)
1      233   2816  0.0764   (233.0/3049.0)
Total  2921  3256  0.109    (673.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.398799     0.893259  229
max f2                       0.154094     0.92097   311
max f0point5                 0.805184     0.905998  110
max accuracy                 0.527493     0.892666  195
max precision                0.975783     1         0
max recall                   0.0175147    1         395
max specificity              0.975783     1         0
max absolute_mcc             0.468957     0.785904  210
max min_per_class_accuracy   0.553958     0.890985  188
max mean_per_class_accuracy  0.468957     0.892879  210
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.75 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.973391           2.02591     2.02591            1                0.974371   1                           0.974371            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.972029           2.02591     2.02591            1                0.97276    1                           0.973565            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.971336           2.02591     2.02591            1                0.971659   1                           0.97293             0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.970695           2.02591     2.02591            1                0.970986   1                           0.972444            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.970066           2.02591     2.02591            1                0.970409   1                           0.972042            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.966414           2.00624     2.01608            0.990291         0.968183   0.995146                    0.970113            0.100361        0.201705                   100.624   101.608
    7        0.150073                    0.962386           1.96035     1.9975             0.967638         0.964414   0.985976                    0.968213            0.0980649       0.29977                    96.0347   99.7499
    8        0.200097                    0.956464           1.98657     1.99477            0.980583         0.959739   0.984628                    0.966094            0.0993768       0.399147                   98.6572   99.4768
    9        0.299984                    0.930444           1.89785     1.9625             0.936791         0.945548   0.968699                    0.959253            0.18957         0.588718                   89.7854   96.2498
    10       0.400032                    0.848044           1.78005     1.91687            0.878641         0.896897   0.946176                    0.943658            0.178091        0.766809                   78.0047   91.6867
    11       0.500081                    0.531012           1.30799     1.79505            0.645631         0.719754   0.886047                    0.898862            0.130863        0.897671                   30.7991   79.5052
    12       0.599968                    0.15843            0.623862    1.60006            0.307942         0.312345   0.7898                      0.801215            0.0623155       0.959987                   -37.6138  60.0064
    13       0.700016                    0.0514492          0.252419    1.40745            0.124595         0.0908327  0.694727                    0.699685            0.0252542       0.985241                   -74.7581  40.7455
    14       0.799903                    0.0274065          0.121489    1.24687            0.0599676        0.0365072  0.615462                    0.616872            0.0121351       0.997376                   -87.8511  24.6872
    15       0.899951                    0.02009            0.019669    1.11044            0.00970874       0.0232225  0.54812                     0.550875            0.00196786      0.999344                   -98.0331  11.0442
    16       1                           0.0132208          0.00655634  1                  0.00323625       0.0178749  0.493605                    0.497549            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:17:36  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:17:43  4:11:02.403  1311 obs/sec      0.35836   1             8959       0.343286         0.463139            0.528609       0.925886        0.726983           2.00923          0.149451                         0.329586           0.421928              0.565422         0.935016          0.708784             2.02591            0.138093
    2019-08-03 20:18:07  4:11:25.091  1248 obs/sec      1.42376   4             35594      0.305661         0.306754            0.626277       0.941942        0.923703           2.00923          0.125674                         0.293709           0.284375              0.654884         0.95057           0.939064             2.02591            0.115752
    2019-08-03 20:18:21  4:11:40.057  1259 obs/sec      2.13144   6             53286      0.304002         0.304141            0.630323       0.943695        0.925744           2.00923          0.123876                         0.293007           0.28332               0.656531         0.951067          0.942054             2.02591            0.112676
    2019-08-03 20:18:36  4:11:54.963  1264 obs/sec      2.83868   8             70967      0.299417         0.296528            0.641391       0.946691        0.939809           2.00923          0.121079                         0.2896             0.277631              0.664472         0.953429          0.947849             2.02591            0.112838
    2019-08-03 20:18:51  4:12:09.731  1272 obs/sec      3.5532    10            88830      0.299439         0.297068            0.641337       0.945906        0.936032           1.98934          0.123576                         0.288225           0.27702               0.66765          0.953228          0.942638             2.02591            0.11219
    2019-08-03 20:19:06  4:12:24.858  1270 obs/sec      4.25676   12            106419     0.295823         0.290918            0.649948       0.94857         0.936938           2.00923          0.117582                         0.286355           0.273329              0.67195          0.955024          0.943276             2.02591            0.113647
    2019-08-03 20:19:21  4:12:39.766  1272 obs/sec      4.96228   14            124057     0.298195         0.297881            0.64431        0.947604        0.943531           2.00923          0.116983                         0.286984           0.275181              0.670506         0.955098          0.943133             2.02591            0.109924
    2019-08-03 20:19:36  4:12:54.641  1273 obs/sec      5.66872   16            141718     0.296438         0.292065            0.64849        0.948531        0.937282           2.00923          0.118282                         0.284435           0.271422              0.676333         0.955865          0.951638             2.02591            0.108143
    2019-08-03 20:19:51  4:13:09.583  1273 obs/sec      6.37376   18            159344     0.297199         0.294825            0.646683       0.9489          0.939806           2.00923          0.118182                         0.286022           0.272978              0.672713         0.956482          0.950582             2.02591            0.11041
    2019-08-03 20:20:06  4:13:24.273  1276 obs/sec      7.0784    20            176960     0.298252         0.296345            0.644175       0.948672        0.935494           2.00923          0.120579                         0.285905           0.272723              0.672979         0.956685          0.954223             2.02591            0.107657
    2019-08-03 20:20:21  4:13:39.310  1275 obs/sec      7.78468   22            194617     0.299709         0.300624            0.64069        0.94695         0.936708           2.00923          0.11988                          0.288824           0.27894               0.666269         0.954507          0.949685             2.02591            0.112838
    2019-08-03 20:20:36  4:13:54.361  1276 obs/sec      8.49864   24            212466     0.29607          0.292758            0.649363       0.947997        0.942329           1.98934          0.119481                         0.285284           0.273445              0.674398         0.955869          0.95267              2.02591            0.106362
    2019-08-03 20:20:51  4:14:09.400  1275 obs/sec      9.20848   26            230212     0.295561         0.292406            0.650567       0.948719        0.943424           2.00923          0.114585                         0.283944           0.271182              0.67745          0.956866          0.950956             2.02591            0.108953
    2019-08-03 20:21:06  4:14:24.236  1276 obs/sec      9.91436   28            247859     0.295979         0.293502            0.649578       0.948481        0.941973           2.00923          0.114486                         0.284396           0.272994              0.676422         0.956263          0.951053             2.02591            0.105553
    2019-08-03 20:21:14  4:14:32.123  1277 obs/sec      10.2647   29            256617     0.295465         0.291954            0.650795       0.94898         0.943375           2.00923          0.116983                         0.28364            0.271786              0.678141         0.956596          0.953528             2.02591            0.111867
    2019-08-03 20:21:15  4:14:33.180  1277 obs/sec      10.2647   29            256617     0.295561         0.292406            0.650567       0.948719        0.943424           2.00923          0.114585                         0.283944           0.271182              0.67745          0.956866          0.950956             2.02591            0.108953
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.006831968931038868
C438        0.8906586766242981     0.8906586766242981   0.006084952406857399
C374        0.6908888220787048     0.6908888220787048   0.004720130967243752
C863        0.6709414720535278     0.6709414720535278   0.004583851291615185
C88         0.6473672389984131     0.6473672389984131   0.004422792863809572
---         ---                    ---                  ---
C947        0.0719170942902565     0.0719170942902565   0.0004913353538016252
C591        0.07150635868310928    0.07150635868310928  0.000488529220894724
C973        0.0711793527007103     0.0711793527007103   0.0004862951261827103
C913        0.06910441815853119    0.06910441815853119  0.00047211923785660324
C964        0.06806723773479462    0.06806723773479462  0.00046503325342575326

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_147

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 206,601 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight              weight_rms           mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  -----------------------  -------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.03331963915887042   0.050894662737846375   0.0         -2.3598912140319923e-05  0.08143690228462219  0.0003699950300613829    0.09361207485198975
    3        2        Softmax                 0.0   0.0   0.002027474180522404  0.0006140898913145065  0.0         -0.048607826300212764    0.3349055051803589   -0.00026390272301512335  0.08889314532279968


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08710666699912463
RMSE: 0.2951383861837098
LogLoss: 0.2872655147988151
Mean Per-Class Error: 0.11843366417704859
AUC: 0.9505924959441672
pr_auc: 0.9429187729687271
Gini: 0.9011849918883343
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4631879618619808: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4270  722   0.1446   (722.0/4992.0)
1      475   4551  0.0945   (475.0/5026.0)
Total  4745  5273  0.1195   (1197.0/10018.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.463188     0.883775  215
max f2                       0.164519     0.92012   311
max f0point5                 0.784454     0.895835  110
max accuracy                 0.504746     0.881613  203
max precision                0.978547     1         0
max recall                   0.0170495    1         397
max specificity              0.978547     1         0
max absolute_mcc             0.500907     0.763525  204
max min_per_class_accuracy   0.5573       0.880024  188
max mean_per_class_accuracy  0.504746     0.881566  203
Gains/Lift Table: Avg response rate: 50.17 %, avg score: 50.50 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100819                   0.976897           1.99324    1.99324            1                0.977792   1                           0.977792            0.0200955       0.0200955                  99.3235   99.3235
    2        0.0200639                   0.975624           1.99324    1.99324            1                0.976175   1                           0.976987            0.0198965       0.039992                   99.3235   99.3235
    3        0.0300459                   0.974465           1.9733     1.98661            0.99             0.974993   0.996678                    0.976325            0.0196976       0.0596896                  97.3303   98.6613
    4        0.0400279                   0.973452           1.99324    1.98826            1                0.973963   0.997506                    0.975736            0.0198965       0.0795862                  99.3235   98.8265
    5        0.05001                     0.972393           1.99324    1.98926            1                0.972936   0.998004                    0.975177            0.0198965       0.0994827                  99.3235   98.9257
    6        0.10002                     0.967183           1.97334    1.9813             0.99002          0.969988   0.994012                    0.972582            0.0986868       0.19817                    97.3343   98.13
    7        0.15003                     0.960379           1.94947    1.97069            0.978044         0.963968   0.988689                    0.969711            0.097493        0.295663                   94.9472   97.069
    8        0.20004                     0.950747           1.89775    1.95246            0.952096         0.956082   0.979541                    0.966304            0.0949065       0.390569                   89.7751   95.2455
    9        0.30006                     0.91341            1.88184    1.92892            0.944112         0.935056   0.967731                    0.955888            0.188221        0.57879                    88.1837   92.8916
    10       0.39998                     0.812914           1.6826     1.86738            0.844156         0.871713   0.93686                     0.93486             0.168126        0.746916                   68.2601   86.7383
    11       0.5                         0.560669           1.31888    1.75766            0.661677         0.702778   0.881813                    0.888434            0.131914        0.87883                    31.8877   75.766
    12       0.60002                     0.223708           0.757907   1.59101            0.38024          0.381306   0.798203                    0.803899            0.0758058       0.954636                   -24.2093  59.1007
    13       0.69994                     0.0744275          0.310634   1.40823            0.155844         0.132578   0.706503                    0.708064            0.0310386       0.985674                   -68.9366  40.8227
    14       0.79996                     0.033598           0.103441   1.24509            0.0518962        0.0494147  0.624657                    0.625713            0.0103462       0.996021                   -89.6559  24.5088
    15       0.89998                     0.021378           0.0278496  1.10981            0.0139721        0.0264134  0.556788                    0.559109            0.00278552      0.998806                   -97.215   10.9809
    16       1                           0.014433           0.0119355  1                  0.00598802       0.0181961  0.501697                    0.505007            0.00119379      1                          -98.8064  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08108096457621021
RMSE: 0.28474719414984623
LogLoss: 0.2713339736781258
Mean Per-Class Error: 0.10934017610067115
AUC: 0.9558198612768934
pr_auc: 0.9466484899414587
Gini: 0.9116397225537869
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5180667763001554: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2762  366   0.117    (366.0/3128.0)
1      310   2739  0.1017   (310.0/3049.0)
Total  3072  3105  0.1094   (676.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.518067     0.890153  193
max f2                       0.20876      0.924012  288
max f0point5                 0.736614     0.902247  128
max accuracy                 0.521105     0.890562  192
max precision                0.97838      1         0
max recall                   0.0174517    1         396
max specificity              0.97838      1         0
max absolute_mcc             0.518067     0.781267  193
max min_per_class_accuracy   0.543675     0.889706  185
max mean_per_class_accuracy  0.518067     0.89066   193
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.65 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.976748           2.02591     2.02591            1                0.977656   1                           0.977656            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.975567           2.02591     2.02591            1                0.976067   1                           0.976861            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.974409           2.02591     2.02591            1                0.974967   1                           0.97623             0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.973378           2.02591     2.02591            1                0.973876   1                           0.975642            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.97232            2.02591     2.02591            1                0.972858   1                           0.975092            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.967474           1.98002     2.00296            0.977346         0.970086   0.988673                    0.972589            0.0990489       0.200394                   98.0016   100.296
    7        0.150073                    0.960769           1.99313     1.99968            0.983819         0.964248   0.987055                    0.969809            0.0997048       0.300098                   99.3128   99.9685
    8        0.200097                    0.951567           1.94723     1.98657            0.961165         0.956947   0.980583                    0.966593            0.097409        0.397507                   94.7234   98.6572
    9        0.299984                    0.911679           1.92741     1.96687            0.951378         0.934239   0.970858                    0.95582             0.192522        0.59003                    92.7406   96.6871
    10       0.400032                    0.805698           1.73415     1.90867            0.855987         0.868255   0.942129                    0.93392             0.1735          0.763529                   73.4153   90.8668
    11       0.500081                    0.526406           1.31127     1.78915            0.647249         0.679276   0.883134                    0.882974            0.131191        0.89472                    31.1269   78.915
    12       0.599968                    0.195861           0.682965    1.60498            0.337115         0.341495   0.792229                    0.792825            0.0682191       0.962939                   -31.7035  60.4984
    13       0.700016                    0.0664691          0.226194    1.40792            0.11165          0.117002   0.694958                    0.696234            0.0226304       0.985569                   -77.3806  40.7923
    14       0.799903                    0.033129           0.108355    1.24564            0.0534846        0.0468706  0.614855                    0.615146            0.0108232       0.996392                   -89.1645  24.5642
    15       0.899951                    0.0211688          0.0295035   1.11044            0.0145631        0.0262459  0.54812                     0.549677            0.00295179      0.999344                   -97.0496  11.0442
    16       1                           0.0140562          0.00655634  1                  0.00323625       0.0181691  0.493605                    0.496501            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:48:44  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:48:50  2:42:08.171  2549 obs/sec      0.634     1             15850      0.320971         0.343154            0.587905       0.934429        0.885943           1.99324          0.142643                         0.309783           0.32085               0.616075         0.941581          0.892341             2.02591            0.128056
    2019-08-03 18:48:57  2:42:15.072  2536 obs/sec      1.2702    2             31755      0.301544         0.296159            0.636281       0.946548        0.930393           1.99324          0.127471                         0.293278           0.283181              0.655896         0.951253          0.93666              2.02591            0.117209
    2019-08-03 18:49:04  2:42:21.914  2543 obs/sec      1.90636   3             47659      0.298784         0.293174            0.642907       0.947918        0.93959            1.99324          0.124875                         0.288298           0.277525              0.667484         0.953848          0.941584             2.02591            0.109924
    2019-08-03 18:49:11  2:42:28.925  2528 obs/sec      2.53728   4             63432      0.29589          0.288162            0.649793       0.950111        0.934302           1.99324          0.117788                         0.285778           0.272246              0.673271         0.95525           0.944952             2.02591            0.108143
    2019-08-03 18:49:18  2:42:35.993  2517 obs/sec      3.17096   5             79274      0.295138         0.287266            0.651569       0.950592        0.942919           1.99324          0.119485                         0.284747           0.271334              0.675623         0.95582           0.946648             2.02591            0.109438
    2019-08-03 18:49:25  2:42:42.789  2530 obs/sec      3.805     6             95125      0.296511         0.290245            0.648322       0.94992         0.944389           1.99324          0.121481                         0.286547           0.275374              0.67151          0.95467           0.949974             2.02591            0.108143
    2019-08-03 18:49:38  2:42:56.000  2531 obs/sec      5.07868   8             126967     0.29728          0.293183            0.646494       0.948915        0.945339           1.99324          0.119185                         0.287995           0.279003              0.668181         0.953114          0.946115             2.02591            0.115914
    2019-08-03 18:49:45  2:43:03.059  2526 obs/sec      5.717     9             142925     0.297585         0.293113            0.64577        0.949464        0.944702           1.99324          0.125075                         0.28859            0.279091              0.666808         0.953427          0.945179             2.02591            0.110895
    2019-08-03 18:49:52  2:43:10.017  2526 obs/sec      6.35344   10            158836     0.299127         0.297633            0.642087       0.947669        0.943299           1.9735           0.123478                         0.290622           0.284314              0.662101         0.952031          0.944716             2.02591            0.115428
    2019-08-03 18:49:59  2:43:16.924  2527 obs/sec      6.99044   11            174761     0.296097         0.292991            0.649302       0.950215        0.937507           1.99324          0.120184                         0.28684            0.27771               0.670837         0.955216          0.944177             2.02591            0.109438
    2019-08-03 18:50:06  2:43:23.712  2532 obs/sec      7.62836   12            190709     0.298593         0.296314            0.643365       0.948564        0.934466           1.99324          0.121681                         0.288884           0.280292              0.666129         0.953561          0.947628             2.02591            0.112838
    2019-08-03 18:50:12  2:43:30.519  2536 obs/sec      8.26404   13            206601     0.298126         0.296344            0.64448        0.949326        0.917809           1.99324          0.119784                         0.28811            0.279291              0.667916         0.954463          0.927966             2.02591            0.111381
    2019-08-03 18:50:13  2:43:31.196  2536 obs/sec      8.26404   13            206601     0.295138         0.287266            0.651569       0.950592        0.942919           1.99324          0.119485                         0.284747           0.271334              0.675623         0.95582           0.946648             2.02591            0.109438
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005591014477628038
C438        0.8437892198562622     0.8437892198562622   0.00471763774428283
C374        0.8056317567825317     0.8056317567825317   0.004504298815808046
C322        0.6438456773757935     0.6438456773757935   0.003599750503566292
C88         0.6323686838150024     0.6323686838150024   0.003535582466408266
---         ---                    ---                  ---
C843        0.10908497124910355    0.10908497124910355  0.0006098956535453762
C354        0.10815492272377014    0.10815492272377014  0.0006046957387753405
C472        0.10774648189544678    0.10774648189544678  0.0006024121401909302
C835        0.10720501840114594    0.10720501840114594  0.0005993848099551871
C880        0.10434039682149887    0.10434039682149887  0.0005833686692304547

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_47

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 217,393 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.03370248630077853   0.05537065863609314    0.0         0.0015959152159896299  0.07048407196998596  -0.0023006919062217327  0.07789039611816406
    3        2        Softmax                 0.0   0.0   0.002035989557953144  0.0005923623684793711  0.0         -0.00098758993260617   0.3463791608810425   0.0002926769339263932   0.11396905779838562


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08747908685773287
RMSE: 0.29576863738018755
LogLoss: 0.2887654876536288
Mean Per-Class Error: 0.11872339760150008
AUC: 0.9493981389491382
pr_auc: 0.9341547325181254
Gini: 0.8987962778982763
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44206174306398827: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4323  731   0.1446   (731.0/5054.0)
1      474   4499  0.0953   (474.0/4973.0)
Total  4797  5230  0.1202   (1205.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.442062     0.881897  222
max f2                       0.162584     0.92132   309
max f0point5                 0.749445     0.892687  126
max accuracy                 0.509449     0.881221  201
max precision                0.987489     1         0
max recall                   0.00863781   1         398
max specificity              0.987489     1         0
max absolute_mcc             0.509449     0.762551  201
max min_per_class_accuracy   0.534435     0.880354  194
max mean_per_class_accuracy  0.509449     0.881277  201
Gains/Lift Table: Avg response rate: 49.60 %, avg score: 49.61 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   0.98647            2.01629    2.01629            1                0.987205    1                           0.987205            0.0203097       0.0203097                  101.629   101.629
    2        0.0200459                   0.985185           2.01629    2.01629            1                0.985795    1                           0.986504            0.0201086       0.0404183                  101.629   101.629
    3        0.0300189                   0.984277           1.99613    2.00959            0.99             0.984746    0.996678                    0.98592             0.0199075       0.0603258                  99.6125   100.959
    4        0.0400918                   0.983469           2.01629    2.01127            1                0.983882    0.997512                    0.985408            0.0203097       0.0806354                  101.629   101.127
    5        0.0500648                   0.982587           2.01629    2.01227            1                0.983038    0.998008                    0.984936            0.0201086       0.100744                   101.629   101.227
    6        0.10003                     0.97774            1.98409    1.9982             0.984032         0.980298    0.991027                    0.982619            0.0991353       0.199879                   98.4092   99.8196
    7        0.149995                    0.97081            1.98409    1.9935             0.984032         0.974537    0.988697                    0.979927            0.0991353       0.299015                   98.4092   99.3497
    8        0.20006                     0.959619           1.93997    1.9801             0.962151         0.965634    0.982054                    0.97635             0.0971245       0.396139                   93.9974   98.0103
    9        0.29999                     0.91686            1.85933    1.93987            0.922156         0.941731    0.962101                    0.964818            0.185803        0.581942                   85.9331   93.9873
    10       0.40002                     0.802662           1.68661    1.87654            0.836491         0.868794    0.930691                    0.940806            0.168711        0.750654                   68.6606   87.654
    11       0.50005                     0.520989           1.3328     1.76777            0.661017         0.679275    0.876745                    0.888489            0.13332         0.883973                   33.2801   76.7771
    12       0.59998                     0.191063           0.750574   1.59835            0.372255         0.342453    0.792719                    0.797544            0.075005        0.958978                   -24.9426  59.8351
    13       0.70001                     0.0596275          0.249272   1.40557            0.123629         0.110939    0.697108                    0.699429            0.0249346       0.983913                   -75.0728  40.557
    14       0.79994                     0.0233755          0.108662   1.24356            0.0538922        0.037951    0.616756                    0.616796            0.0108586       0.994772                   -89.1338  24.3558
    15       0.89997                     0.0125067          0.0402051  1.10981            0.0199402        0.01716     0.550421                    0.550148            0.00402172      0.998793                   -95.9795  10.9807
    16       1                           0.00723655         0.0120615  1                  0.00598205       0.00999197  0.495961                    0.496116            0.00120652      1                          -98.7938  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08195364064446387
RMSE: 0.28627546287529404
LogLoss: 0.2720473848600641
Mean Per-Class Error: 0.11199297870502178
AUC: 0.9553578843090561
pr_auc: 0.9450006506348607
Gini: 0.9107157686181122
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4108249445498682: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2695  433   0.1384   (433.0/3128.0)
1      266   2783  0.0872   (266.0/3049.0)
Total  2961  3216  0.1132   (699.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.410825     0.888428  229
max f2                       0.164527     0.921788  308
max f0point5                 0.766714     0.904847  122
max accuracy                 0.505378     0.887972  201
max precision                0.987682     1         0
max recall                   0.0108175    1         395
max specificity              0.987682     1         0
max absolute_mcc             0.621527     0.77654   168
max min_per_class_accuracy   0.514559     0.887468  198
max mean_per_class_accuracy  0.505378     0.888007  201
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.17 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.986406           2.02591     2.02591            1                0.987147   1                           0.987147            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.985303           2.02591     2.02591            1                0.985781   1                           0.986464            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.984186           2.02591     2.02591            1                0.984674   1                           0.985867            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.983528           2.02591     2.02591            1                0.983893   1                           0.985374            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.98259            2.02591     2.02591            1                0.983038   1                           0.984913            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.977945           2.01935     2.02263            0.996764         0.980257   0.998382                    0.982585            0.101017        0.202361                   101.935   102.263
    7        0.150073                    0.971046           1.97346     2.00624            0.97411          0.974573   0.990291                    0.979914            0.0987209       0.301082                   97.3459   100.624
    8        0.200097                    0.960596           1.96035     1.99477            0.967638         0.966551   0.984628                    0.976573            0.0980649       0.399147                   96.0347   99.4768
    9        0.299984                    0.92034            1.91756     1.96906            0.946515         0.943704   0.971937                    0.965629            0.191538        0.590685                   91.7555   96.9058
    10       0.400032                    0.800398           1.73743     1.91113            0.857605         0.868164   0.943343                    0.941252            0.173827        0.764513                   73.7431   91.1128
    11       0.500081                    0.494738           1.28177     1.78521            0.632686         0.667559   0.881191                    0.886496            0.128239        0.892752                   28.1765   78.5214
    12       0.599968                    0.171471           0.676398    1.60061            0.333874         0.314966   0.79007                     0.791344            0.0675631       0.960315                   -32.3602  60.0611
    13       0.700016                    0.0591524          0.245863    1.40699            0.121359         0.10472    0.694496                    0.693209            0.0245982       0.984913                   -75.4137  40.6986
    14       0.799903                    0.0233999          0.111638    1.24523            0.0551053        0.0372052  0.614653                    0.611292            0.0111512       0.996064                   -88.8362  24.5232
    15       0.899951                    0.0127567          0.0295035   1.11008            0.0145631        0.01717    0.54794                     0.545243            0.00295179      0.999016                   -97.0496  11.0078
    16       1                           0.00733668         0.00983452  1                  0.00485437       0.0101231  0.493605                    0.491705            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:58:59  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:59:05  52 min 23.156 sec  2536 obs/sec      0.62752   1             15688      0.316679         0.331651            0.598833       0.93676         0.895567           2.01629          0.13703                          0.307302           0.311864              0.622201         0.94326           0.904433             2.02591            0.127246
    2019-08-03 16:59:12  52 min 29.934 sec  2548 obs/sec      1.25264   2             31316      0.302741         0.300477            0.633368       0.94456         0.932445           2.01629          0.122968                         0.294209           0.284552              0.653706         0.950682          0.942599             2.02591            0.118504
    2019-08-03 16:59:19  52 min 36.754 sec  2527 obs/sec      1.87012   3             46753      0.304945         0.3043              0.628009       0.943603        0.9311             1.99632          0.124763                         0.296148           0.288559              0.649127         0.949927          0.937449             2.02591            0.11899
    2019-08-03 16:59:25  52 min 43.369 sec  2541 obs/sec      2.49332   4             62333      0.295769         0.288765            0.650061       0.949398        0.934155           2.01629          0.120176                         0.286275           0.272047              0.672132         0.955358          0.945001             2.02591            0.113162
    2019-08-03 16:59:32  52 min 50.072 sec  2546 obs/sec      3.11608   5             77902      0.296133         0.290146            0.649198       0.949258        0.942676           2.01629          0.120874                         0.285858           0.272873              0.673088         0.955462          0.941723             2.02591            0.111381
    2019-08-03 16:59:39  52 min 57.029 sec  2524 obs/sec      3.731     6             93275      0.298862         0.294932            0.642702       0.948419        0.943027           1.9564           0.123566                         0.288934           0.27826               0.666013         0.954186          0.951566             2.02591            0.112676
    2019-08-03 16:59:46  53 min  3.714 sec  2525 obs/sec      4.3492    7             108730     0.296012         0.290876            0.649486       0.949315        0.935896           2.01629          0.118181                         0.285432           0.273514              0.674061         0.955762          0.947503             2.02591            0.108629
    2019-08-03 16:59:52  53 min 10.457 sec  2530 obs/sec      4.972     8             124300     0.296258         0.292528            0.648902       0.948591        0.937708           2.01629          0.121073                         0.285759           0.275431              0.673313         0.95544           0.945138             2.02591            0.108791
    2019-08-03 16:59:59  53 min 17.184 sec  2533 obs/sec      5.59332   9             139833     0.296872         0.292019            0.647446       0.949705        0.936528           2.01629          0.122769                         0.28725            0.275331              0.669897         0.955772          0.936106             2.02591            0.115104
    2019-08-03 17:00:06  53 min 24.003 sec  2528 obs/sec      6.2134    10            155335     0.294831         0.290093            0.652276       0.94968         0.942241           1.99632          0.119078                         0.28489            0.273702              0.675298         0.955893          0.935652             2.02591            0.107172
    2019-08-03 17:00:13  53 min 30.671 sec  2533 obs/sec      6.838     11            170950     0.296353         0.292545            0.648676       0.949199        0.935721           2.01629          0.119777                         0.285537           0.274586              0.673821         0.955445          0.941809             1.99323            0.111219
    2019-08-03 17:00:19  53 min 37.326 sec  2537 obs/sec      7.45968   12            186492     0.297075         0.293882            0.646962       0.948453        0.941257           1.99632          0.119378                         0.28712            0.276388              0.670195         0.955077          0.950986             1.99323            0.110733
    2019-08-03 17:00:32  53 min 49.580 sec  2553 obs/sec      8.69572   14            217393     0.298879         0.297888            0.642662       0.947657        0.932795           1.97636          0.11868                          0.289148           0.281313              0.665518         0.953636          0.949014             1.99323            0.110571
    2019-08-03 17:00:32  53 min 50.217 sec  2553 obs/sec      8.69572   14            217393     0.295769         0.288765            0.650061       0.949398        0.934155           2.01629          0.120176                         0.286275           0.272047              0.672132         0.955358          0.945001             2.02591            0.113162
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005742846607286911
C438        0.7042132616043091     0.7042132616043091   0.004044188740210756
C374        0.6008703112602234     0.6008703112602234   0.003450706028440204
C79         0.5802677273750305     0.5802677273750305   0.00333238854947378
C88         0.577989935874939      0.577989935874939    0.0033193075422853725
---         ---                    ---                  ---
C476        0.1092824786901474     0.1092824786901474   0.0006275925119816171
C841        0.10899226367473602    0.10899226367473602  0.0006259258516649782
C908        0.10802428424358368    0.10802428424358368  0.0006203668942728614
C835        0.10669096559286118    0.10669096559286118  0.0006127098497831273
C936        0.10248186439275742    0.10248186439275742  0.0005885376272363842

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_68

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 223,424 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.03871227415763259    0.06936463713645935     0.0         0.0009117453294653886  0.09246739745140076  -0.008718653601753803   0.0927848219871521
    3        2        Softmax                 0.0   0.0   0.0018416797634017712  0.00042567180935293436  0.0         -0.02519677165696521   0.3626828193664551   -0.0006133525531285058  0.08635282516479492


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08748533230386363
RMSE: 0.29577919518428547
LogLoss: 0.29136895658010076
Mean Per-Class Error: 0.11734399694643738
AUC: 0.9495139547412722
pr_auc: 0.9363402980489499
Gini: 0.8990279094825444
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5105680503502995: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4449  632   0.1244   (632.0/5081.0)
1      546   4404  0.1103   (546.0/4950.0)
Total  4995  5036  0.1174   (1178.0/10031.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.510568     0.882035  198
max f2                       0.19839      0.917008  295
max f0point5                 0.778284     0.897243  114
max accuracy                 0.510568     0.882564  198
max precision                0.982752     1         0
max recall                   0.0131207    1         398
max specificity              0.982752     1         0
max absolute_mcc             0.510568     0.765253  198
max min_per_class_accuracy   0.541266     0.88101   190
max mean_per_class_accuracy  0.510568     0.882656  198
Gains/Lift Table: Avg response rate: 49.35 %, avg score: 49.48 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100688                   0.9817             2.02646    2.02646            1                0.982385   1                           0.982385            0.020404        0.020404                   102.646   102.646
    2        0.0200379                   0.980967           2.02646    2.02646            1                0.981323   1                           0.981857            0.020202        0.0406061                  102.646   102.646
    3        0.030007                    0.980345           2.02646    2.02646            1                0.980642   1                           0.981453            0.020202        0.0608081                  102.646   102.646
    4        0.0400758                   0.979683           2.0064     2.02142            0.990099         0.979967   0.997512                    0.98108             0.020202        0.0810101                  100.64    102.142
    5        0.0500449                   0.979071           2.02646    2.02243            1                0.979382   0.998008                    0.980742            0.020202        0.101212                   102.646   102.243
    6        0.10009                     0.975794           1.97802    2.00023            0.976096         0.97747    0.987052                    0.979106            0.0989899       0.200202                   97.8023   100.023
    7        0.150035                    0.970795           1.99006    1.99684            0.982036         0.973472   0.985382                    0.97723             0.0993939       0.299596                   99.0061   99.6842
    8        0.20008                     0.963401           1.98206    1.99314            0.978088         0.96725    0.983558                    0.974734            0.0991919       0.398788                   98.206    99.3145
    9        0.30007                     0.931719           1.90524    1.96385            0.940179         0.949935   0.969103                    0.966471            0.190505        0.589293                   90.524    96.3853
    10       0.40006                     0.826086           1.70926    1.90022            0.84347          0.889911   0.937702                    0.947335            0.170909        0.760202                   70.9261   90.0221
    11       0.50005                     0.516417           1.27285    1.77477            0.628116         0.687723   0.875797                    0.895423            0.127273        0.887475                   27.2854   77.4773
    12       0.60004                     0.161456           0.686937   1.5935             0.338983         0.312294   0.786343                    0.798251            0.0686869       0.956162                   -31.3063  59.3497
    13       0.70003                     0.0508595          0.238408   1.39994            0.117647         0.0918457  0.690829                    0.69735             0.0238384       0.98                       -76.1592  39.994
    14       0.80002                     0.0234784          0.125265   1.24063            0.0618146        0.0337165  0.612212                    0.614406            0.0125253       0.992525                   -87.4735  24.0626
    15       0.90001                     0.0156902          0.0505101  1.10841            0.0249252        0.0187936  0.546965                    0.548235            0.00505051      0.997576                   -94.949   10.8405
    16       1                           0.0111374          0.0242448  1                  0.0119641        0.0140377  0.49347                     0.49482             0.00242424      1                          -97.5755  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08141923801287432
RMSE: 0.2853405649620718
LogLoss: 0.27236622648685516
Mean Per-Class Error: 0.10787424328466244
AUC: 0.9555827913894036
pr_auc: 0.9485333937939079
Gini: 0.9111655827788072
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5551481176191342: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2804  324   0.1036   (324.0/3128.0)
1      342   2707  0.1122   (342.0/3049.0)
Total  3146  3031  0.1078   (666.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.555148     0.890461  188
max f2                       0.198618     0.923982  292
max f0point5                 0.79228      0.904504  115
max accuracy                 0.583738     0.892181  181
max precision                0.982893     1         0
max recall                   0.01243      1         399
max specificity              0.982893     1         0
max absolute_mcc             0.583738     0.784398  181
max min_per_class_accuracy   0.542872     0.89144   192
max mean_per_class_accuracy  0.555148     0.892126  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.76 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.981582           2.02591    2.02591            1                0.982274   1                           0.982274            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.980851           2.02591    2.02591            1                0.981214   1                           0.981744            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980183           1.99323    2.01502            0.983871         0.980532   0.994624                    0.98134             0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.979608           2.02591    2.01774            1                0.979863   0.995968                    0.980971            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.979128           1.9927     2.0128             0.983607         0.979399   0.993528                    0.980661            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.976043           2.00624    2.00952            0.990291         0.977641   0.991909                    0.979151            0.100361        0.20105                    100.624   100.952
    7        0.150073                    0.971766           1.99968    2.00624            0.987055         0.974067   0.990291                    0.977456            0.100033        0.301082                   99.9685   100.624
    8        0.200097                    0.964576           1.95379    1.99313            0.964401         0.968277   0.983819                    0.975162            0.097737        0.398819                   95.379    99.3128
    9        0.299984                    0.932864           1.92412    1.97015            0.949757         0.951236   0.972477                    0.967195            0.192194        0.591013                   92.4122   97.0151
    10       0.400032                    0.837578           1.74071    1.91277            0.859223         0.894207   0.944152                    0.948941            0.174155        0.765169                   74.0709   91.2767
    11       0.500081                    0.513937           1.30471    1.79112            0.644013         0.702056   0.884105                    0.899548            0.130535        0.895704                   30.4712   79.1117
    12       0.599968                    0.165977           0.666547   1.60389            0.329011         0.31383    0.791689                    0.802033            0.0665792       0.962283                   -33.3453  60.3891
    13       0.700016                    0.0521493          0.219638   1.40605            0.108414         0.0964621  0.694033                    0.701191            0.0219744       0.984257                   -78.0362  40.6049
    14       0.799903                    0.0236591          0.118205   1.24523            0.0583468        0.0346254  0.614653                    0.617955            0.0118071       0.996064                   -88.1795  24.5232
    15       0.899951                    0.0159217          0.0262254  1.10971            0.012945         0.0191208  0.54776                     0.551382            0.00262381      0.998688                   -97.3775  10.9713
    16       1                           0.0114679          0.0131127  1                  0.00647249       0.0141381  0.493605                    0.497631            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:19:22  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:19:30  1:12:47.917  2513 obs/sec      0.74152   1             18538      0.316704         0.337426            0.598726       0.936414        0.893365           2.02646          0.139767                         0.306656           0.313273              0.623787         0.94351           0.905771             2.02591            0.128218
    2019-08-03 17:19:38  1:12:55.909  2518 obs/sec      1.48312   2             37078      0.300183         0.296207            0.639499       0.946487        0.934972           2.02646          0.126707                         0.291439           0.280902              0.660197         0.951888          0.941898             2.02591            0.120447
    2019-08-03 17:19:46  1:13:04.019  2509 obs/sec      2.22916   3             55729      0.298594         0.293781            0.643306       0.948073        0.94093            2.02646          0.121922                         0.286612           0.273416              0.67136          0.954543          0.947056             2.02591            0.113971
    2019-08-03 17:19:54  1:13:12.131  2498 obs/sec      2.96892   4             74223      0.297341         0.292924            0.646294       0.948818        0.935167           2.02646          0.11923                          0.286751           0.273878              0.671043         0.954807          0.949754             2.02591            0.111219
    2019-08-03 17:20:02  1:13:20.151  2497 obs/sec      3.71668   5             92917      0.295779         0.291369            0.649999       0.949514        0.93634            2.02646          0.117436                         0.285341           0.272366              0.67427          0.955583          0.948533             2.02591            0.107819
    2019-08-03 17:20:10  1:13:28.171  2503 obs/sec      4.46808   6             111702     0.296153         0.293371            0.649113       0.948939        0.935292           2.02646          0.120526                         0.28624            0.274548              0.672212         0.954998          0.946556             2.02591            0.110248
    2019-08-03 17:20:18  1:13:36.161  2509 obs/sec      5.21324   7             130331     0.297017         0.294178            0.647063       0.9493          0.939976           2.02646          0.117735                         0.287696           0.277427              0.66887          0.955302          0.939384             2.02591            0.113647
    2019-08-03 17:20:26  1:13:44.090  2512 obs/sec      5.9554    8             148885     0.296751         0.296287            0.647696       0.94791         0.939506           1.98634          0.119031                         0.286164           0.278661              0.672387         0.954498          0.947698             1.99323            0.112514
    2019-08-03 17:20:34  1:13:52.113  2514 obs/sec      6.70156   9             167539     0.298871         0.299294            0.642644       0.946642        0.938601           2.02646          0.12272                          0.288388           0.28046               0.667274         0.953521          0.949053             2.02591            0.117695
    2019-08-03 17:20:42  1:14:00.077  2517 obs/sec      7.44496   10            186124     0.299552         0.300476            0.641014       0.946409        0.93528            1.98634          0.121822                         0.289051           0.281092              0.665743         0.953295          0.942738             2.02591            0.114943
    2019-08-03 17:20:50  1:14:07.863  2524 obs/sec      8.1892    11            204730     0.299274         0.301188            0.641679       0.945602        0.934794           1.92614          0.120128                         0.288394           0.282309              0.66726          0.95251           0.947859             2.02591            0.114781
    2019-08-03 17:20:58  1:14:15.818  2526 obs/sec      8.93696   12            223424     0.299404         0.301582            0.641368       0.946792        0.942248           2.02646          0.11933                          0.28946            0.282643              0.664796         0.953617          0.929356             2.02591            0.111219
    2019-08-03 17:20:58  1:14:16.492  2526 obs/sec      8.93696   12            223424     0.295779         0.291369            0.649999       0.949514        0.93634            2.02646          0.117436                         0.285341           0.272366              0.67427          0.955583          0.948533             2.02591            0.107819
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0065047645624563034
C438        0.8601333498954773     0.8601333498954773   0.005594964933386929
C88         0.726553201675415      0.726553201675415    0.004726057518997407
C374        0.7043574452400208     0.7043574452400208   0.0045816793490995435
C322        0.631783127784729      0.631783127784729    0.004109600500771908
---         ---                    ---                  ---
C958        0.08205211907625198    0.08205211907625198  0.0005337297164416488
C946        0.08187823742628098    0.08187823742628098  0.0005325986572468559
C733        0.08149224519729614    0.08149224519729614  0.0005300878686743719
C691        0.08124135434627533    0.08124135434627533  0.0005284558827576072
C835        0.0789182186126709     0.0789182186126709   0.0005133444317638812

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_35

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.015223364759142951   0.02474375069141388    0.0         -0.0009863121688224476  0.07047411799430847  0.019831878660199153   0.0600518137216568
    3        2        Softmax                 0.0   0.0   0.0019955663237851695  0.0005642268806695938  0.0         -0.07565874494866875    0.4673302173614502   -0.015064692128537255  0.05605575442314148


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08971759261198982
RMSE: 0.2995289512083762
LogLoss: 0.29564371676068063
Mean Per-Class Error: 0.12214744835418712
AUC: 0.9469848381688667
pr_auc: 0.9213706761278202
Gini: 0.8939696763377334
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43075136059609304: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4250  809   0.1599   (809.0/5059.0)
1      444   4524  0.0894   (444.0/4968.0)
Total  4694  5333  0.125    (1253.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.430751     0.878361  223
max f2                       0.194431     0.9165    299
max f0point5                 0.77439      0.891894  115
max accuracy                 0.576393     0.87793   180
max precision                0.983646     1         0
max recall                   0.0139092    1         398
max specificity              0.983646     1         0
max absolute_mcc             0.576393     0.755889  180
max min_per_class_accuracy   0.546211     0.876655  190
max mean_per_class_accuracy  0.576393     0.877853  180
Gains/Lift Table: Avg response rate: 49.55 %, avg score: 50.38 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   0.983151           2.01832    2.01832            1                0.983698   1                           0.983698            0.0203301       0.0203301                  101.832   101.832
    2        0.0200459                   0.981878           1.97795    1.99823            0.98             0.982506   0.99005                     0.983105            0.0197262       0.0400564                  97.7951   99.8234
    3        0.0300189                   0.980611           1.99813    1.9982             0.99             0.981212   0.990033                    0.982476            0.0199275       0.0599839                  99.8134   99.8201
    4        0.0400918                   0.979216           2.01832    2.00326            1                0.979931   0.992537                    0.981837            0.0203301       0.080314                   101.832   100.326
    5        0.0500648                   0.977833           1.99813    2.00224            0.99             0.978547   0.992032                    0.981181            0.0199275       0.100242                   99.8134   100.224
    6        0.10003                     0.970723           2.0022     2.00222            0.992016         0.97417    0.992024                    0.977679            0.10004         0.200282                   100.22    100.222
    7        0.149995                    0.962052           1.94983    1.98477            0.966068         0.966723   0.983378                    0.974029            0.0974235       0.297705                   94.9831   98.4768
    8        0.20006                     0.949309           1.92987    1.97103            0.956175         0.956132   0.97657                     0.969551            0.0966184       0.394324                   92.9865   97.1029
    9        0.29999                     0.906044           1.87933    1.94048            0.931138         0.930445   0.961436                    0.956524            0.187802        0.582126                   87.9331   94.0483
    10       0.40002                     0.796251           1.71446    1.88396            0.849452         0.860479   0.933433                    0.932507            0.171498        0.753623                   71.4463   88.3964
    11       0.50005                     0.534452           1.27176    1.7615             0.63011          0.680947   0.872756                    0.882185            0.127214        0.880837                   27.1761   76.1499
    12       0.59998                     0.234279           0.711044   1.58654            0.352295         0.378838   0.78607                     0.79835             0.0710548       0.951892                   -28.8956  58.654
    13       0.70001                     0.086469           0.301842   1.40296            0.149551         0.146973   0.695113                    0.705269            0.0301932       0.982085                   -69.8158  40.2959
    14       0.79994                     0.0378546          0.130929   1.24405            0.0648703        0.0574691  0.616382                    0.624345            0.0130837       0.995169                   -86.9071  24.4054
    15       0.89997                     0.020546           0.036221   1.10981            0.0179462        0.0279647  0.549867                    0.558058            0.00362319      0.998792                   -96.3779  10.9806
    16       1                           0.0125932          0.0120737  1                  0.00598205       0.0157694  0.495462                    0.503813            0.00120773      1                          -98.7926  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08179411527380057
RMSE: 0.2859967050051461
LogLoss: 0.27246497542392734
Mean Per-Class Error: 0.11068689243632768
AUC: 0.9555843117402965
pr_auc: 0.9341446861450008
Gini: 0.9111686234805929
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.478375589328586: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2725  403   0.1288   (403.0/3128.0)
1      292   2757  0.0958   (292.0/3049.0)
Total  3017  3160  0.1125   (695.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.478376     0.888066  207
max f2                       0.193623     0.921662  296
max f0point5                 0.776937     0.906587  117
max accuracy                 0.574828     0.889429  179
max precision                0.9837       1         0
max recall                   0.0147452    1         397
max specificity              0.9837       1         0
max absolute_mcc             0.574828     0.778868  179
max min_per_class_accuracy   0.546046     0.887176  188
max mean_per_class_accuracy  0.574828     0.889313  179
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.08 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.983162           2.02591     2.02591            1                0.983736   1                           0.983736            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.981662           2.02591     2.02591            1                0.982427   1                           0.983082            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980675           2.02591     2.02591            1                0.981191   1                           0.982451            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.979305           2.02591     2.02591            1                0.980051   1                           0.981851            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.978074           2.02591     2.02591            1                0.978736   1                           0.981236            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.970892           2.00624     2.01608            0.990291         0.974555   0.995146                    0.977895            0.100361        0.201705                   100.624   101.608
    7        0.150073                    0.96279            1.97346     2.00187            0.97411          0.96679    0.988134                    0.974194            0.0987209       0.300426                   97.3459   100.187
    8        0.200097                    0.949685           1.95379     1.98985            0.964401         0.956848   0.982201                    0.969857            0.097737        0.398163                   95.379    98.985
    9        0.299984                    0.906291           1.92741     1.96906            0.951378         0.931422   0.971937                    0.957059            0.192522        0.590685                   92.7406   96.9058
    10       0.400032                    0.797856           1.77021     1.91933            0.873786         0.861313   0.94739                     0.933113            0.177107        0.767793                   77.0213   91.9326
    11       0.500081                    0.521516           1.25226     1.78587            0.618123         0.679484   0.881515                    0.882371            0.125287        0.89308                    25.2262   78.587
    12       0.599968                    0.215814           0.673114    1.60061            0.332253         0.356126   0.79007                     0.794758            0.0672352       0.960315                   -32.6886  60.0611
    13       0.700016                    0.0831309          0.23275     1.40511            0.114887         0.140114   0.693571                    0.701194            0.0232863       0.983601                   -76.725   40.5112
    14       0.799903                    0.0368319          0.114922    1.244              0.0567261        0.0558183  0.614046                    0.620604            0.0114792       0.99508                    -88.5078  24.4001
    15       0.899951                    0.0203192          0.0458944   1.11081            0.0226537        0.0276839  0.5483                      0.554688            0.00459167      0.999672                   -95.4106  11.0807
    16       1                           0.0126734          0.00327817  1                  0.00161812       0.0156156  0.493605                    0.500755            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:45:39  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:45:45  39 min  2.324 sec  4830 obs/sec      1         1             25000      0.308711         0.312944            0.61876        0.940357        0.922421           2.01832          0.128752                         0.296068           0.288567              0.649317         0.94981           0.931926             2.02591            0.119637
    2019-08-03 16:45:51  39 min  9.177 sec  4294 obs/sec      2         2             50000      0.299529         0.295644            0.6411         0.946985        0.921371           2.01832          0.124963                         0.285997           0.272465              0.67277          0.955584          0.934145             2.02591            0.112514
    2019-08-03 16:45:57  39 min 14.779 sec  4444 obs/sec      3         3             75000      0.298426         0.295305            0.643738       0.947933        0.898808           1.99833          0.121173                         0.285509           0.272614              0.673885         0.956159          0.921601             2.02591            0.11219
    2019-08-03 16:46:03  39 min 20.556 sec  4497 obs/sec      4         4             100000     0.299387         0.298645            0.641441       0.947166        0.926963           1.97835          0.120275                         0.285807           0.274137              0.673205         0.955598          0.930252             2.02591            0.109114
    2019-08-03 16:46:08  39 min 26.014 sec  4580 obs/sec      5         5             125000     0.30005          0.301995            0.639851       0.945975        0.799419           2.01832          0.120874                         0.287353           0.280629              0.66966          0.953895          0.824814             2.02591            0.111219
    2019-08-03 16:46:14  39 min 31.375 sec  4648 obs/sec      6         6             150000     0.300869         0.303253            0.637881       0.945696        0.812431           2.01832          0.120774                         0.287531           0.280264              0.669251         0.953935          0.805944             2.02591            0.112028
    2019-08-03 16:46:19  39 min 36.694 sec  4703 obs/sec      7         7             175000     0.301886         0.306766            0.63543        0.944266        0.858194           1.99833          0.122769                         0.288393           0.284326              0.667264         0.953048          0.887391             2.02591            0.111543
    2019-08-03 16:46:24  39 min 42.088 sec  4740 obs/sec      8         8             200000     0.303163         0.30872             0.632338       0.943436        0.732065           2.01832          0.123566                         0.289435           0.284584              0.664856         0.951686          0.72675              2.02591            0.113
    2019-08-03 16:46:29  39 min 47.284 sec  4790 obs/sec      9         9             225000     0.304336         0.311241            0.629487       0.942325        0.690302           2.01832          0.123666                         0.290293           0.286077              0.662864         0.951123          0.686735             2.02591            0.11219
    2019-08-03 16:46:34  39 min 52.204 sec  4856 obs/sec      10        10            250000     0.304514         0.312659            0.629054       0.941411        0.906189           1.97835          0.124564                         0.291347           0.290238              0.660413         0.950333          0.920016             1.99323            0.113647
    2019-08-03 16:46:35  39 min 52.612 sec  4855 obs/sec      10        10            250000     0.299529         0.295644            0.6411         0.946985        0.921371           2.01832          0.124963                         0.285997           0.272465              0.67277          0.955584          0.934145             2.02591            0.112514
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.0064344479158427404
C438        0.6847888827323914     0.6847888827323914   0.004406238399289714
C374        0.6559649109840393     0.6559649109840393   0.0042207720543472205
C88         0.6553534865379333     0.6553534865379333   0.004216837875594279
C79         0.5716544389724731     0.5716544389724731   0.003678280713428681
---         ---                    ---                  ---
C743        0.09134331345558167    0.09134331345558167  0.0005877437928904376
C983        0.09123492985963821    0.09123492985963821  0.0005870464042874077
C657        0.09111359715461731    0.09111359715461731  0.0005862656953164624
C762        0.08392467349767685    0.08392467349767685  0.0005400089404749092
C376        0.08337505906820297    0.08337505906820297  0.000536472475054664

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_117

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight              weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  -----------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.01390415785544974   0.020623207092285156   0.0         -0.00024486180869081237  0.0722629725933075  0.0022237761975670454  0.06929710507392883
    3        2        Softmax                 0.0   0.0   0.002217435435341031  0.0007216446101665497  0.0         0.06146839868506504      0.5067005157470703  0.0017229876846483819  0.06501638889312744


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08590363822926503
RMSE: 0.2930932244683678
LogLoss: 0.28389647429093223
Mean Per-Class Error: 0.1184271467844712
AUC: 0.9513509887639339
pr_auc: 0.928769583642748
Gini: 0.9027019775278677
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4161634336445778: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4272  790   0.1561   (790.0/5062.0)
1      405   4553  0.0817   (405.0/4958.0)
Total  4677  5343  0.1193   (1195.0/10020.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.416163     0.883992  228
max f2                       0.173806     0.91861   306
max f0point5                 0.75416      0.896742  124
max accuracy                 0.569725     0.881637  183
max precision                0.982517     1         0
max recall                   0.0135337    1         399
max specificity              0.982517     1         0
max absolute_mcc             0.416163     0.763897  228
max min_per_class_accuracy   0.545196     0.880284  190
max mean_per_class_accuracy  0.534138     0.881573  193
Gains/Lift Table: Avg response rate: 49.48 %, avg score: 50.12 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100798                   0.982154           2.02098    2.02098            1                0.982534   1                           0.982534            0.0203711       0.0203711                  102.098   102.098
    2        0.0200599                   0.980971           2.02098    2.02098            1                0.981525   1                           0.982032            0.0201694       0.0405405                  102.098   102.098
    3        0.0300399                   0.979945           2.00077    2.01426            0.99             0.980515   0.996678                    0.981528            0.0199677       0.0605083                  100.077   101.426
    4        0.04002                     0.978974           2.02098    2.01594            1                0.979455   0.997506                    0.981011            0.0201694       0.0806777                  102.098   101.594
    5        0.05                        0.977854           2.00077    2.01291            0.99             0.978402   0.996008                    0.98049             0.0199677       0.100645                   100.077   101.291
    6        0.1                         0.972459           2.00081    2.00686            0.99002          0.97527    0.993014                    0.97788             0.10004         0.200686                   100.081   100.686
    7        0.15                        0.964815           1.96047    1.99139            0.97006          0.968807   0.985363                    0.974856            0.0980234       0.298709                   96.0468   99.1394
    8        0.2                         0.954334           1.98064    1.98871            0.98004          0.959868   0.984032                    0.971109            0.0990319       0.397741                   98.0637   98.8705
    9        0.3                         0.911466           1.89794    1.95845            0.939122         0.93578    0.969062                    0.959333            0.189794        0.587535                   89.7943   95.8451
    10       0.4                         0.801078           1.70633    1.89542            0.844311         0.865403   0.937874                    0.93585             0.170633        0.758169                   70.6333   89.5422
    11       0.5                         0.531337           1.27471    1.77128            0.630739         0.679986   0.876447                    0.884677            0.127471        0.885639                   27.4708   77.1279
    12       0.6                         0.217976           0.713998   1.59507            0.353293         0.365524   0.789255                    0.798152            0.0713998       0.957039                   -28.6002  59.5065
    13       0.7                         0.0773692          0.27027    1.40581            0.133733         0.133351   0.695609                    0.70318             0.027027        0.984066                   -72.973   40.5809
    14       0.8                         0.0327734          0.100847   1.24269            0.0499002        0.0498314  0.614895                    0.621512            0.0100847       0.994151                   -89.9153  24.2689
    15       0.9                         0.0186273          0.0463897  1.10977            0.0229541        0.0242813  0.549124                    0.555153            0.00463897      0.99879                    -95.361   10.9766
    16       1                           0.0131433          0.0121017  1                  0.00598802       0.0154871  0.49481                     0.501186            0.00121017      1                          -98.7898  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0820219765551833
RMSE: 0.28639479142467533
LogLoss: 0.2731209662713256
Mean Per-Class Error: 0.11189693446931148
AUC: 0.9551358606528156
pr_auc: 0.9307091865331611
Gini: 0.9102717213056313
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43972949957154944: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2677  451   0.1442   (451.0/3128.0)
1      259   2790  0.0849   (259.0/3049.0)
Total  2936  3241  0.1149   (710.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.439729     0.887122  214
max f2                       0.254045     0.922002  272
max f0point5                 0.747967     0.904793  127
max accuracy                 0.615448     0.888295  166
max precision                0.982447     1         0
max recall                   0.0134629    1         399
max specificity              0.982447     1         0
max absolute_mcc             0.615448     0.776869  166
max min_per_class_accuracy   0.556237     0.88587   183
max mean_per_class_accuracy  0.604956     0.888103  169
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.25 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.982127           2.02591     2.02591            1                0.98252    1                           0.98252             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.981225           2.02591     2.02591            1                0.981616   1                           0.982068            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980384           2.02591     2.02591            1                0.98079    1                           0.981642            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.979241           1.99323     2.01774            0.983871         0.979728   0.995968                    0.981163            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.97817            2.02591     2.01935            1                0.978712   0.996764                    0.980679            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.972984           2.00624     2.0128             0.990291         0.975764   0.993528                    0.978221            0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.96638            1.96035     1.99531            0.967638         0.969657   0.984898                    0.975367            0.0980649       0.299442                   96.0347   99.5314
    8        0.200097                    0.955477           1.98002     1.99149            0.977346         0.961518   0.98301                     0.971905            0.0990489       0.398491                   98.0016   99.1489
    9        0.299984                    0.914369           1.91427     1.96578            0.944895         0.937573   0.970318                    0.960473            0.19121         0.589702                   91.4272   96.5778
    10       0.400032                    0.8103             1.76038     1.91441            0.868932         0.871739   0.944962                    0.93828             0.176123        0.765825                   76.0378   91.4407
    11       0.500081                    0.537456           1.25226     1.78194            0.618123         0.690662   0.879573                    0.888741            0.125287        0.891112                   25.2262   78.1935
    12       0.599968                    0.215457           0.696099    1.60116            0.343598         0.357765   0.79034                     0.80034             0.069531        0.960643                   -30.3901  60.1158
    13       0.700016                    0.0768315          0.239307    1.40652            0.118123         0.132106   0.694265                    0.704834            0.0239423       0.984585                   -76.0693  40.6518
    14       0.799903                    0.0334251          0.105072    1.244              0.0518639        0.0502639  0.614046                    0.623096            0.0104952       0.99508                    -89.4928  24.4001
    15       0.899951                    0.0188372          0.0426162   1.11044            0.0210356        0.0248819  0.54812                     0.556591            0.00426369      0.999344                   -95.7384  11.0442
    16       1                           0.0132578          0.00655634  1                  0.00323625       0.0155734  0.493605                    0.502463            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:19:15  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:19:20  2:12:38.189  4871 obs/sec      1         1             25000      0.303417         0.302321            0.631712       0.944166        0.930378           2.02098          0.123453                         0.297634           0.292287              0.645599         0.948262          0.935399             2.02591            0.119475
    2019-08-03 18:19:26  2:12:43.596  4928 obs/sec      2         2             50000      0.293093         0.283896            0.656348       0.951351        0.92877            2.02098          0.119261                         0.286395           0.273121              0.671858         0.955136          0.930709             2.02591            0.114943
    2019-08-03 18:19:32  2:12:49.308  4845 obs/sec      3         3             75000      0.295128         0.291315            0.651561       0.949214        0.908052           2.02098          0.118064                         0.287638           0.279493              0.669003         0.953459          0.908187             2.02591            0.111057
    2019-08-03 18:19:37  2:12:54.875  4849 obs/sec      4         4             100000     0.293994         0.289109            0.654232       0.95086         0.927944           2.02098          0.118164                         0.286406           0.276295              0.671834         0.955168          0.941065             2.02591            0.113971
    2019-08-03 18:19:43  2:13:00.591  4826 obs/sec      5         5             125000     0.295282         0.293679            0.651196       0.949474        0.939479           2.02098          0.117365                         0.287412           0.280855              0.669523         0.953823          0.948692             1.99323            0.108953
    2019-08-03 18:19:48  2:13:06.263  4817 obs/sec      6         6             150000     0.296976         0.29715             0.647182       0.94766         0.930679           2.02098          0.117665                         0.289265           0.284376              0.665248         0.952106          0.939061             2.02591            0.113647
    2019-08-03 18:19:54  2:13:11.503  4868 obs/sec      7         7             175000     0.299129         0.300975            0.642048       0.94553         0.878016           2.02098          0.123054                         0.290668           0.286927              0.661993         0.950198          0.870896             1.99323            0.113162
    2019-08-03 18:19:59  2:13:16.847  4894 obs/sec      8         8             200000     0.29724          0.29997             0.646556       0.946733        0.839035           2.02098          0.120359                         0.289784           0.288026              0.664046         0.950967          0.821965             1.96056            0.112352
    2019-08-03 18:20:04  2:13:22.047  4930 obs/sec      9         9             225000     0.298882         0.30149             0.64264        0.946112        0.899334           1.98096          0.118762                         0.291135           0.287968              0.660907         0.950467          0.901945             1.96056            0.114781
    2019-08-03 18:20:09  2:13:27.188  4966 obs/sec      10        10            250000     0.298089         0.3017              0.644534       0.945882        0.919276           2.00097          0.117665                         0.290547           0.288951              0.662275         0.95018           0.930388             1.96056            0.114781
    2019-08-03 18:20:10  2:13:27.629  4965 obs/sec      10        10            250000     0.293093         0.283896            0.656348       0.951351        0.92877            2.02098          0.119261                         0.286395           0.273121              0.671858         0.955136          0.930709             2.02591            0.114943
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006152614903103731
C438        0.8325864672660828     0.8325864672660828   0.005122583906623787
C88         0.762887716293335      0.762887716293335    0.004693754332661144
C374        0.7203992009162903     0.7203992009162903   0.004432338859741587
C322        0.6077221035957336     0.6077221035957336   0.0037390800715286603
---         ---                    ---                  ---
C472        0.09516815841197968    0.09516815841197968  0.0005855330297464829
C827        0.09384512901306152    0.09384512901306152  0.0005773929393494547
C545        0.09334710240364075    0.09334710240364075  0.0005743287734101902
C348        0.0908612608909607     0.0908612608909607   0.000559034347872521
C342        0.08941653370857239    0.08941653370857239  0.0005501454978792396

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_154

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.015127188438736994  0.02651725709438324    0.0         -0.0027351742295678894  0.07158279418945312  0.011432545055545872   0.06203511357307434
    3        2        Softmax                 0.0   0.0   0.001863081785813847  0.0004696343094110489  0.0         -0.05399030791159021    0.4696648120880127   0.0035504933170954454  0.06415754556655884


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.087738664580271
RMSE: 0.2962071312110345
LogLoss: 0.28975668096847673
Mean Per-Class Error: 0.1187762922820319
AUC: 0.9490788746335196
pr_auc: 0.9281153326219289
Gini: 0.8981577492670392
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4745809062162434: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4342  701   0.139    (701.0/5043.0)
1      492   4482  0.0989   (492.0/4974.0)
Total  4834  5183  0.1191   (1193.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.474581     0.882544  214
max f2                       0.179294     0.919646  305
max f0point5                 0.777396     0.893882  112
max accuracy                 0.483152     0.881102  211
max precision                0.982268     1         0
max recall                   0.014279     1         398
max specificity              0.982268     1         0
max absolute_mcc             0.480771     0.762774  212
max min_per_class_accuracy   0.537451     0.87904   193
max mean_per_class_accuracy  0.480771     0.881224  212
Gains/Lift Table: Avg response rate: 49.66 %, avg score: 49.89 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   0.981721           2.01387    2.01387            1                0.982255   1                           0.982255            0.0203056       0.0203056                  101.387   101.387
    2        0.0200659                   0.980396           2.01387    2.01387            1                0.981063   1                           0.981662            0.0201045       0.0404101                  101.387   101.387
    3        0.0300489                   0.979078           2.01387    2.01387            1                0.979757   1                           0.981029            0.0201045       0.0605147                  101.387   101.387
    4        0.0400319                   0.977597           2.01387    2.01387            1                0.97833    1                           0.980356            0.0201045       0.0806192                  101.387   101.387
    5        0.050015                    0.976321           1.95346    2.00181            0.97             0.97696    0.994012                    0.979678            0.0195014       0.100121                   95.3456   100.181
    6        0.10003                     0.968848           1.99377    1.99779            0.99002          0.97263    0.992016                    0.976154            0.0997185       0.199839                   99.3774   99.7793
    7        0.150045                    0.961057           1.9576     1.98439            0.972056         0.965314   0.985363                    0.972541            0.0979091       0.297748                   95.7596   98.4394
    8        0.20006                     0.949498           1.92946    1.97066            0.958084         0.955483   0.978543                    0.968276            0.0965018       0.39425                    92.9458   97.066
    9        0.29999                     0.904156           1.87103    1.93747            0.929071         0.930293   0.962063                    0.955624            0.186972        0.581222                   87.103    93.7472
    10       0.40002                     0.789144           1.72043    1.8832             0.854291         0.856054   0.935114                    0.930725            0.172095        0.753317                   72.0434   88.3199
    11       0.50005                     0.525319           1.28832    1.7642             0.639721         0.67332    0.876023                    0.879234            0.12887         0.882187                   28.8315   76.4199
    12       0.59998                     0.214315           0.738353   1.59334            0.366633         0.360616   0.791181                    0.792855            0.0737837       0.955971                   -26.1647  59.3338
    13       0.70001                     0.0792162          0.27736    1.40529            0.137725         0.135062   0.697804                    0.698858            0.0277443       0.983715                   -72.264   40.5288
    14       0.79994                     0.0357027          0.10864    1.24331            0.0539461        0.0530274  0.617372                    0.618179            0.0108565       0.994572                   -89.136   24.3308
    15       0.89997                     0.020898           0.0381872  1.10936            0.0189621        0.0274385  0.55086                     0.552519            0.00381986      0.998392                   -96.1813  10.9361
    16       1                           0.0131369          0.0160788  1                  0.00798403       0.016326   0.496556                    0.498884            0.00160836      1                          -98.3921  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08181206705210206
RMSE: 0.2860280878726809
LogLoss: 0.27328272451279567
Mean Per-Class Error: 0.10992986254350301
AUC: 0.9550293312385344
pr_auc: 0.9380442521442738
Gini: 0.9100586624770688
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.42488552172385274: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2677  451   0.1442   (451.0/3128.0)
1      239   2810  0.0784   (239.0/3049.0)
Total  2916  3261  0.1117   (690.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.424886     0.89065   219
max f2                       0.212446     0.923038  288
max f0point5                 0.738955     0.903486  125
max accuracy                 0.505338     0.889914  197
max precision                0.982406     1         0
max recall                   0.0142498    1         398
max specificity              0.982406     1         0
max absolute_mcc             0.505338     0.780157  197
max min_per_class_accuracy   0.543923     0.888747  185
max mean_per_class_accuracy  0.505338     0.89007   197
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.91 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.981602           2.02591     2.02591            1                0.982255   1                           0.982255            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.980373           2.02591     2.02591            1                0.981055   1                           0.981655            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.978968           2.02591     2.02591            1                0.979781   1                           0.98103             0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.977714           1.99323     2.01774            0.983871         0.978317   0.995968                    0.980352            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.976651           2.02591     2.01935            1                0.977185   0.996764                    0.979727            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.968991           2.0128      2.01608            0.993528         0.972891   0.995146                    0.976309            0.100689        0.201705                   101.28    101.608
    7        0.150073                    0.962027           1.9669      1.99968            0.970874         0.965734   0.987055                    0.972784            0.0983929       0.300098                   96.6903   99.9685
    8        0.200097                    0.952167           1.9669      1.99149            0.970874         0.957257   0.98301                     0.968902            0.0983929       0.398491                   96.6903   99.1489
    9        0.299984                    0.9066             1.888       1.95703            0.931929         0.932255   0.966001                    0.956699            0.188586        0.587078                   88.8004   95.7031
    10       0.400032                    0.797094           1.75382     1.90621            0.865696         0.863562   0.940915                    0.933405            0.175467        0.762545                   75.3822   90.6208
    11       0.500081                    0.530104           1.31455     1.78784            0.648867         0.675883   0.882486                    0.881884            0.131519        0.894064                   31.4547   78.7838
    12       0.599968                    0.212152           0.686248    1.60444            0.338736         0.353665   0.791959                    0.793943            0.0685471       0.962611                   -31.3752  60.4438
    13       0.700016                    0.0775916          0.23275     1.40839            0.114887         0.131909   0.69519                     0.699323            0.0232863       0.985897                   -76.725   40.8392
    14       0.799903                    0.0355594          0.105072    1.24564            0.0518639        0.0518192  0.614855                    0.618467            0.0104952       0.996392                   -89.4928  24.5642
    15       0.899951                    0.0208625          0.0327817   1.11081            0.0161812        0.0273924  0.5483                      0.552756            0.00327976      0.999672                   -96.7218  11.0807
    16       1                           0.0131382          0.00327817  1                  0.00161812       0.0161441  0.493605                    0.499069            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 19:04:21  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 19:04:26  2:57:43.593  5101 obs/sec      1         1             25000      0.306203         0.306115            0.624942       0.942604        0.9233             2.01387          0.129879                         0.29623            0.288816              0.648934         0.949221          0.933687             2.02591            0.119475
    2019-08-03 19:04:32  2:57:49.591  4757 obs/sec      2         2             50000      0.296207         0.289757            0.649029       0.949079        0.928115           2.01387          0.119098                         0.286028           0.273283              0.672698         0.955029          0.938044             2.02591            0.111705
    2019-08-03 19:04:37  2:57:55.142  4788 obs/sec      3         3             75000      0.297983         0.295664            0.644807       0.948423        0.934412           2.01387          0.121693                         0.28716            0.279214              0.670102         0.954425          0.938315             2.02591            0.109924
    2019-08-03 19:04:43  2:58:00.779  4784 obs/sec      4         4             100000     0.298649         0.299036            0.643218       0.947657        0.930607           2.01387          0.12379                          0.286761           0.281054              0.67102          0.954035          0.930712             2.02591            0.11041
    2019-08-03 19:04:48  2:58:06.041  4860 obs/sec      5         5             125000     0.298053         0.297904            0.644642       0.947595        0.799824           2.01387          0.119896                         0.287861           0.281449              0.668489         0.953312          0.828413             2.02591            0.110895
    2019-08-03 19:04:54  2:58:11.497  4881 obs/sec      6         6             150000     0.299586         0.301189            0.640976       0.946241        0.757603           2.01387          0.122991                         0.288772           0.284008              0.666388         0.952349          0.744417             2.02591            0.111219
    2019-08-03 19:04:59  2:58:16.915  4903 obs/sec      7         7             175000     0.300085         0.302803            0.639779       0.945216        0.726672           2.01387          0.121194                         0.289722           0.285687              0.664189         0.951223          0.756801             1.99323            0.112676
    2019-08-03 19:05:04  2:58:22.275  4924 obs/sec      8         8             200000     0.300101         0.304772            0.639741       0.945677        0.724992           2.01387          0.121793                         0.28987            0.288438              0.663847         0.951751          0.719143             2.02591            0.113162
    2019-08-03 19:05:09  2:58:27.281  4978 obs/sec      9         9             225000     0.301464         0.305758            0.63646        0.944087        0.688193           2.01387          0.121493                         0.290743           0.288137              0.661818         0.950162          0.691295             2.02591            0.113647
    2019-08-03 19:05:14  2:58:32.259  5032 obs/sec      10        10            250000     0.302844         0.308435            0.633124       0.943895        0.682213           2.01387          0.121493                         0.292004           0.289867              0.65888          0.949846          0.658646             2.02591            0.113324
    2019-08-03 19:05:15  2:58:32.724  5030 obs/sec      10        10            250000     0.296207         0.289757            0.649029       0.949079        0.928115           2.01387          0.119098                         0.286028           0.273283              0.672698         0.955029          0.938044             2.02591            0.111705
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006194161540252318
C438        0.8063566088676453     0.8063566088676453   0.0049947030943762495
C88         0.7337177991867065     0.7337177991867065   0.0045447665731208715
C374        0.7328174710273743     0.7328174710273743   0.004539189795062729
C322        0.6147841811180115     0.6147841811180115   0.0038080725302367022
---         ---                    ---                  ---
C525        0.0926271602511406     0.0926271602511406   0.0005737475936104033
C802        0.0923914760351181     0.0923914760351181   0.0005722877275038722
C720        0.09227699786424637    0.09227699786424637  0.0005715786312206602
C561        0.09114493429660797    0.09114493429660797  0.0005645664466088735
C885        0.08741652965545654    0.08741652965545654  0.0005414721059741551

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_145

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 125,826 weights/biases, 1.6 MB, 222,278 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight              weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  -----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.035535143060241706   0.056189700961112976   0.0         -0.00016989317024354328  0.10086473822593689  0.010532019598286566   0.10098496079444885
    3        2        Softmax                 0.0   0.0   0.0020876330631836026  0.0008460513781756163  0.0         0.013907204898714554     0.34310710430145264  -0.003613940257353822  0.07928207516670227


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08718886366924973
RMSE: 0.2952776044153192
LogLoss: 0.2910391237982561
Mean Per-Class Error: 0.11600142108422085
AUC: 0.9491758484886947
pr_auc: 0.9411872353017298
Gini: 0.8983516969773895
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4269252967585615: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4249  760   0.1517   (760.0/5009.0)
1      412   4596  0.0823   (412.0/5008.0)
Total  4661  5356  0.117    (1172.0/10017.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.426925     0.886916  228
max f2                       0.193941     0.919406  298
max f0point5                 0.770034     0.895612  122
max accuracy                 0.529628     0.883997  198
max precision                0.978219     1         0
max recall                   0.0168761    1         398
max specificity              0.978219     1         0
max absolute_mcc             0.51873      0.768287  201
max min_per_class_accuracy   0.569021     0.880815  187
max mean_per_class_accuracy  0.51873      0.883999  201
Gains/Lift Table: Avg response rate: 50.00 %, avg score: 50.74 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100829                   0.97578            1.9804     1.9804             0.990099         0.976946   0.990099                    0.976946            0.0199681       0.0199681                  98.0396   98.0396
    2        0.0200659                   0.974359           2.0002     1.99025            1                0.974952   0.995025                    0.975954            0.0199681       0.0399361                  100.02    99.0248
    3        0.0300489                   0.973334           1.9802     1.98691            0.99             0.973863   0.993355                    0.975259            0.0197684       0.0597045                  98.0198   98.6909
    4        0.0400319                   0.97247            1.9802     1.98524            0.99             0.972915   0.992519                    0.974675            0.0197684       0.0794728                  98.0198   98.5236
    5        0.050015                    0.971598           1.94019    1.97625            0.97             0.972049   0.988024                    0.974151            0.019369        0.0988419                  94.0194   97.6245
    6        0.10003                     0.967546           1.97625    1.97625            0.988024         0.969604   0.988024                    0.971877            0.0988419       0.197684                   97.6245   97.6245
    7        0.150045                    0.962497           1.97625    1.97625            0.988024         0.965303   0.988024                    0.969686            0.0988419       0.296526                   97.6245   97.6245
    8        0.20006                     0.955224           1.91636    1.96127            0.958084         0.959056   0.980539                    0.967028            0.0958466       0.392372                   91.6359   96.1274
    9        0.29999                     0.926954           1.87631    1.93297            0.938062         0.943594   0.966389                    0.959222            0.1875          0.579872                   87.6311   93.2972
    10       0.40002                     0.839952           1.6868     1.87141            0.843313         0.89189    0.935613                    0.942385            0.16873         0.748602                   68.6795   87.1412
    11       0.50005                     0.569037           1.32548    1.7622             0.662675         0.726828   0.881014                    0.899265            0.132588        0.88119                    32.5482   76.2204
    12       0.59998                     0.192952           0.751324   1.59384            0.375624         0.368675   0.796839                    0.810892            0.0750799       0.95627                    -24.8676  59.3836
    13       0.70001                     0.0652172          0.269488   1.40459            0.134731         0.114747   0.702225                    0.711414            0.0269569       0.983227                   -73.0512  40.459
    14       0.79994                     0.0328671          0.0979119  1.24136            0.048951         0.0456531  0.620616                    0.628246            0.00978435      0.993011                   -90.2088  24.1357
    15       0.89997                     0.0236197          0.0538976  1.10937            0.0269461        0.0274772  0.554631                    0.561472            0.00539137      0.998403                   -94.6102  10.9373
    16       1                           0.0146198          0.0159697  1                  0.00798403       0.0206773  0.49995                     0.507376            0.00159744      1                          -98.403   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08119431687861639
RMSE: 0.28494616487788776
LogLoss: 0.2733558165064312
Mean Per-Class Error: 0.10676606476149575
AUC: 0.9549011499305042
pr_auc: 0.9464416897164972
Gini: 0.9098022998610085
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47483453953371013: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2723  405   0.1295   (405.0/3128.0)
1      264   2785  0.0866   (264.0/3049.0)
Total  2987  3190  0.1083   (669.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.474835     0.892771  210
max f2                       0.194069     0.922796  294
max f0point5                 0.794987     0.903103  113
max accuracy                 0.529206     0.893152  194
max precision                0.9791       1         0
max recall                   0.0192269    1         395
max specificity              0.9791       1         0
max absolute_mcc             0.529206     0.786407  194
max min_per_class_accuracy   0.558812     0.892263  186
max mean_per_class_accuracy  0.529206     0.893234  194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.07 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.976073           2.02591    2.02591            1                0.977416   1                           0.977416            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.974653           2.02591    2.02591            1                0.975342   1                           0.976379            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.973611           1.99323    2.01502            0.983871         0.974158   0.994624                    0.975639            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.972638           1.96056    2.0014             0.967742         0.973089   0.987903                    0.975001            0.0196786       0.0803542                  96.0558   100.14
    5        0.0500243                   0.971667           1.9927     1.99968            0.983607         0.972177   0.987055                    0.974444            0.0196786       0.100033                   99.2698   99.9685
    6        0.100049                    0.967681           1.99968    1.99968            0.987055         0.969731   0.987055                    0.972087            0.100033        0.200066                   99.9685   99.9685
    7        0.150073                    0.962919           1.97346    1.99094            0.97411          0.965452   0.98274                     0.969875            0.0987209       0.298786                   97.3459   99.0943
    8        0.200097                    0.955355           1.99968    1.99313            0.987055         0.95949    0.983819                    0.967279            0.100033        0.398819                   99.9685   99.3128
    9        0.299984                    0.926869           1.92084    1.96906            0.948136         0.944039   0.971937                    0.959541            0.191866        0.590685                   92.0839   96.9058
    10       0.400032                    0.835354           1.71776    1.90621            0.847896         0.89071    0.940915                    0.942326            0.17186         0.762545                   71.7762   90.6208
    11       0.500081                    0.531097           1.34733    1.7944             0.665049         0.704632   0.885724                    0.894772            0.134798        0.897343                   34.7329   79.4396
    12       0.599968                    0.180657           0.643563   1.6028             0.317666         0.331891   0.791149                    0.80106             0.0642834       0.961627                   -35.6437  60.2798
    13       0.700016                    0.0629861          0.242585   1.40839            0.119741         0.108302   0.69519                     0.702049            0.0242703       0.985897                   -75.7415  40.8392
    14       0.799903                    0.0321311          0.0788036  1.24236            0.0388979        0.0442235  0.613236                    0.619904            0.00787143      0.993768                   -92.1196  24.2361
    15       0.899951                    0.0236751          0.0491726  1.10971            0.0242718        0.0272349  0.54776                     0.554016            0.00491965      0.998688                   -95.0827  10.9713
    16       1                           0.0146198          0.0131127  1                  0.00647249       0.0207082  0.493605                    0.500659            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:46:57  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:47:03  2:40:21.246  2507 obs/sec      0.64052   1             16013      0.316563         0.337092            0.599152       0.93736         0.882142           2.0002           0.135769                         0.308079           0.316266              0.620288         0.943546          0.889213             2.02591            0.130808
    2019-08-03 18:47:10  2:40:28.111  2495 obs/sec      1.27128   2             31782      0.305648         0.304259            0.626318       0.943701        0.933612           2.0002           0.128382                         0.297209           0.288369              0.646609         0.949743          0.937523             2.02591            0.118828
    2019-08-03 18:47:17  2:40:35.084  2479 obs/sec      1.90396   3             47599      0.297089         0.290707            0.646953       0.948443        0.935151           2.0002           0.117999                         0.288852           0.276701              0.666202         0.953634          0.934777             2.02591            0.112514
    2019-08-03 18:47:24  2:40:41.989  2494 obs/sec      2.53848   4             63462      0.29595          0.289045            0.649654       0.949756        0.932866           2.0002           0.120096                         0.288045           0.275895              0.668067         0.954108          0.947888             2.02591            0.114457
    2019-08-03 18:47:31  2:40:48.901  2509 obs/sec      3.17776   5             79444      0.295824         0.290977            0.649952       0.948745        0.946234           1.96059          0.118199                         0.287178           0.276641              0.670062         0.953946          0.949995             2.02591            0.113486
    2019-08-03 18:47:44  2:41:01.852  2530 obs/sec      4.44684   7             111171     0.295278         0.291039            0.651245       0.949176        0.941187           1.9804           0.117001                         0.284946           0.273356              0.67517          0.954901          0.946442             2.02591            0.108305
    2019-08-03 18:47:51  2:41:08.844  2526 obs/sec      5.08084   8             127021     0.296235         0.293194            0.648979       0.948422        0.942252           1.96059          0.118598                         0.28557            0.275068              0.673746         0.954648          0.946855             1.96056            0.108791
    2019-08-03 18:47:58  2:41:15.656  2532 obs/sec      5.71436   9             142859     0.29701          0.294224            0.64714        0.949288        0.940413           1.9804           0.120695                         0.286827           0.276048              0.670868         0.954973          0.944339             1.99323            0.112838
    2019-08-03 18:48:04  2:41:22.579  2532 obs/sec      6.34768   10            158692     0.296404         0.293458            0.648579       0.948791        0.943276           1.96059          0.119896                         0.286672           0.27596               0.671222         0.954503          0.94739              1.99323            0.113971
    2019-08-03 18:48:11  2:41:29.507  2534 obs/sec      6.98744   11            174686     0.296511         0.294934            0.648326       0.948274        0.940888           1.92098          0.118798                         0.286559           0.277473              0.671481         0.953931          0.945301             2.02591            0.111057
    2019-08-03 18:48:18  2:41:36.542  2531 obs/sec      7.6254    12            190635     0.298068         0.297977            0.644621       0.947408        0.940569           1.90118          0.117201                         0.288782           0.282043              0.666365         0.953157          0.9471               1.99323            0.113971
    2019-08-03 18:48:25  2:41:43.357  2535 obs/sec      8.2588    13            206470     0.297669         0.297801            0.645573       0.947215        0.938345           1.90118          0.1179                           0.287636           0.280434              0.669008         0.952785          0.94516              1.96056            0.11219
    2019-08-03 18:48:32  2:41:50.319  2533 obs/sec      8.89112   14            222278     0.299111         0.300733            0.642131       0.947184        0.935876           1.92098          0.116901                         0.288274           0.280944              0.667539         0.953508          0.945554             2.02591            0.111219
    2019-08-03 18:48:33  2:41:50.986  2532 obs/sec      8.89112   14            222278     0.295278         0.291039            0.651245       0.949176        0.941187           1.9804           0.117001                         0.284946           0.273356              0.67517          0.954901          0.946442             2.02591            0.108305
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006636354550914516
C438        0.8943675756454468     0.8943675756454468   0.0059353403308250435
C374        0.7943781614303589     0.7943781614303589   0.005271775126755468
C88         0.6770159006118774     0.6770159006118774   0.004492917553067122
C863        0.6611239314079285     0.6611239314079285   0.0043874528109175024
---         ---                    ---                  ---
C941        0.07690393179655075    0.07690393179655075  0.0005103617577612591
C835        0.07533836364746094    0.07533836364746094  0.0004999720924502801
C843        0.07431277632713318    0.07431277632713318  0.0004931659313696628
C476        0.07374608516693115    0.07374608516693115  0.000489405167909693
C899        0.07326768338680267    0.07326768338680267  0.0004862303240789718

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_229

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 263,594 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.015125456349350854  0.0232168510556221     0.0         -0.0033466350546672735  0.09324926137924194  0.0008620470322047882  0.10339576005935669
    3        2        Softmax                 0.0   0.0   0.001883912977973523  0.0005051163025200367  0.0         0.07202264947318326     0.4443775415420532   -0.018057341378001125  0.059682697057724


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08860365351077608
RMSE: 0.2976636583642284
LogLoss: 0.2949075001049829
Mean Per-Class Error: 0.11962932641529345
AUC: 0.9474174709132825
pr_auc: 0.9141281657110585
Gini: 0.8948349418265651
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.40298900983556596: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4206  812   0.1618   (812.0/5018.0)
1      401   4593  0.0803   (401.0/4994.0)
Total  4607  5405  0.1212   (1213.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.402989     0.883354  228
max f2                       0.179676     0.91617   305
max f0point5                 0.765449     0.892614  118
max accuracy                 0.504841     0.880344  198
max precision                0.970388     0.991722  5
max recall                   0.019448     1         399
max specificity              0.975194     0.999601  0
max absolute_mcc             0.44613      0.761043  217
max min_per_class_accuracy   0.550846     0.879055  186
max mean_per_class_accuracy  0.504841     0.880371  198
Gains/Lift Table: Avg response rate: 49.88 %, avg score: 50.51 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   0.975055           2.00481    2.00481            1                0.975358   1                           0.975358            0.0202243       0.0202243                  100.481   100.481
    2        0.0200759                   0.974091           1.94466    1.97488            0.97             0.974635   0.985075                    0.974998            0.0194233       0.0396476                  94.4662   97.4883
    3        0.0300639                   0.973062           1.98476    1.97816            0.99             0.973571   0.986711                    0.974524            0.0198238       0.0594714                  98.4758   97.8164
    4        0.0400519                   0.972147           2.00481    1.98481            1                0.972589   0.990025                    0.974041            0.020024        0.0794954                  100.481   98.4808
    5        0.05004                     0.970973           1.98476    1.9848             0.99             0.97158    0.99002                     0.97355             0.0198238       0.0993192                  98.4758   98.4798
    6        0.10008                     0.965352           1.97279    1.9788             0.984032         0.968211   0.987026                    0.970881            0.0987185       0.198038                   97.2793   97.8795
    7        0.15002                     0.959128           1.94466    1.96743            0.97             0.962214   0.981358                    0.967996            0.0971165       0.295154                   94.4662   96.7433
    8        0.20006                     0.950505           1.94078    1.96077            0.968064         0.955211   0.978033                    0.964798            0.0971165       0.392271                   94.078    96.0766
    9        0.30004                     0.912311           1.88263    1.93473            0.939061         0.934581   0.965047                    0.954729            0.188226        0.580497                   88.2635   93.4731
    10       0.40002                     0.813766           1.68636    1.87265            0.841159         0.872182   0.934082                    0.934097            0.168602        0.749099                   68.636    87.2654
    11       0.5                         0.539138           1.30983    1.76011            0.653347         0.697005   0.877946                    0.886688            0.130957        0.880056                   30.9833   76.0112
    12       0.59998                     0.224605           0.731023   1.58863            0.364635         0.374077   0.792409                    0.801267            0.0730877       0.953144                   -26.8977  58.8626
    13       0.69996                     0.078344           0.27839    1.40148            0.138861         0.136209   0.699058                    0.706273            0.0278334       0.980977                   -72.161   40.1476
    14       0.79994                     0.0380932          0.128179   1.24233            0.0639361        0.054211   0.619678                    0.624775            0.0128154       0.993793                   -87.1821  24.2334
    15       0.89992                     0.0253168          0.0480673  1.10965            0.023976         0.0310531  0.553496                    0.558813            0.00480577      0.998598                   -95.1933  10.9652
    16       1                           0.0192492          0.0140056  1                  0.00698603       0.021655   0.498801                    0.505055            0.00140168      1                          -98.5994  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08165761566083825
RMSE: 0.28575796692452554
LogLoss: 0.27370340572891255
Mean Per-Class Error: 0.10907353800961117
AUC: 0.9552368329224542
pr_auc: 0.9333232994804386
Gini: 0.9104736658449084
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4041869398477938: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2649  479   0.1531   (479.0/3128.0)
1      231   2818  0.0758   (231.0/3049.0)
Total  2880  3297  0.1149   (710.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.404187     0.888118  229
max f2                       0.199166     0.92226   295
max f0point5                 0.798754     0.905051  107
max accuracy                 0.625045     0.891209  164
max precision                0.975368     1         0
max recall                   0.0194591    1         399
max specificity              0.975368     1         0
max absolute_mcc             0.625045     0.782941  164
max min_per_class_accuracy   0.543705     0.887788  188
max mean_per_class_accuracy  0.625045     0.890926  164
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.12 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.974987           2.02591     2.02591            1                0.975349   1                           0.975349            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.973996           2.02591     2.02591            1                0.974542   1                           0.974945            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.972931           1.99323     2.01502            0.983871         0.973357   0.994624                    0.974416            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.972167           2.02591     2.01774            1                0.972553   0.995968                    0.97395             0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.971148           1.95949     2.00624            0.967213         0.971618   0.990291                    0.973489            0.0193506       0.100361                   95.9487   100.624
    6        0.100049                    0.966008           2.00624     2.00624            0.990291         0.968814   0.990291                    0.971152            0.100361        0.200722                   100.624   100.624
    7        0.150073                    0.959387           1.98002     1.9975             0.977346         0.962558   0.985976                    0.968287            0.0990489       0.29977                    98.0016   99.7499
    8        0.200097                    0.950145           1.95379     1.98657            0.964401         0.955227   0.980583                    0.965022            0.097737        0.397507                   95.379    98.6572
    9        0.299984                    0.914013           1.92741     1.96687            0.951378         0.934708   0.970858                    0.954928            0.192522        0.59003                    92.7406   96.6871
    10       0.400032                    0.814812           1.76366     1.91605            0.87055          0.875189   0.945771                    0.934986            0.176451        0.766481                   76.3656   91.6047
    11       0.500081                    0.52803            1.2621      1.78521            0.622977         0.689386   0.881191                    0.88585             0.126271        0.892752                   26.2096   78.5214
    12       0.599968                    0.201467           0.692815    1.60334            0.341977         0.350229   0.791419                    0.796676            0.069203        0.961955                   -30.7185  60.3344
    13       0.700016                    0.0758044          0.23275     1.40745            0.114887         0.127342   0.694727                    0.701013            0.0232863       0.985241                   -76.725   40.7455
    14       0.799903                    0.0376115          0.105072    1.24482            0.0518639        0.0532028  0.614451                    0.620118            0.0104952       0.995736                   -89.4928  24.4822
    15       0.899951                    0.0250238          0.0327817   1.11008            0.0161812        0.0305535  0.54794                     0.554576            0.00327976      0.999016                   -96.7218  11.0078
    16       1                           0.0193013          0.00983452  1                  0.00485437       0.0214826  0.493605                    0.501241            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:47:36  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:47:41  4:40:58.658  5029 obs/sec      0.95656   1             23914      0.308525         0.315921            0.619247       0.939601        0.920885           1.98496          0.127048                         0.298              0.293813              0.644726         0.947337          0.919268             2.02591            0.120447
    2019-08-03 20:47:46  4:41:03.999  4931 obs/sec      1.91324   2             47831      0.29848          0.295522            0.643637       0.946709        0.933102           1.94526          0.123252                         0.286576           0.274562              0.671443         0.954548          0.942888             2.02591            0.111543
    2019-08-03 20:47:52  4:41:09.413  4910 obs/sec      2.871     3             71775      0.297664         0.294908            0.645583       0.947417        0.914128           2.00481          0.121155                         0.285758           0.273703              0.673316         0.955237          0.933323             2.02591            0.114943
    2019-08-03 20:47:57  4:41:14.803  4898 obs/sec      3.82752   4             95688      0.301066         0.301719            0.637436       0.945399        0.898241           2.00481          0.121155                         0.289689           0.280171              0.664267         0.952909          0.917735             2.02591            0.111543
    2019-08-03 20:48:04  4:41:21.639  4616 obs/sec      4.7882    5             119705     0.298288         0.298545            0.644095       0.946016        0.862432           2.00481          0.120056                         0.287298           0.278675              0.669785         0.953674          0.882953             2.02591            0.113486
    2019-08-03 20:48:09  4:41:27.037  4654 obs/sec      5.74836   6             143709     0.300424         0.303537            0.638979       0.945179        0.935085           1.98496          0.120356                         0.288832           0.281098              0.66625          0.953306          0.94261              2.02591            0.110086
    2019-08-03 20:48:14  4:41:32.220  4707 obs/sec      6.70648   7             167662     0.300825         0.304665            0.638015       0.944117        0.808645           1.96511          0.123252                         0.289209           0.282974              0.665378         0.952437          0.815722             2.02591            0.11219
    2019-08-03 20:48:20  4:41:37.363  4747 obs/sec      7.66784   8             191696     0.300846         0.306309            0.637964       0.94389         0.906389           1.96511          0.121654                         0.289344           0.286121              0.665066         0.95217           0.914842             1.96056            0.112514
    2019-08-03 20:48:25  4:41:42.473  4787 obs/sec      8.6256    9             215640     0.303002         0.31079             0.632756       0.942739        0.915924           1.94526          0.119557                         0.291433           0.287753              0.660212         0.950986          0.941273             1.96056            0.113162
    2019-08-03 20:48:34  4:41:52.002  4874 obs/sec      10.5438   11            263594     0.30328          0.311056            0.632082       0.940249        0.929279           1.94697          0.120555                         0.291508           0.289307              0.660036         0.949044          0.937516             1.96803            0.112352
    2019-08-03 20:48:35  4:41:52.461  4873 obs/sec      10.5438   11            263594     0.297664         0.294908            0.645583       0.947417        0.914128           2.00481          0.121155                         0.285758           0.273703              0.673316         0.955237          0.933323             2.02591            0.114943
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.007098700223176028
C438        0.8267309069633484     0.8267309069633484   0.005868714873767241
C374        0.6696834564208984     0.6696834564208984   0.004753882101552326
C863        0.6423707008361816     0.6423707008361816   0.004559997037387544
C88         0.6419373154640198     0.6419373154640198   0.004556920564549457
---         ---                    ---                  ---
C879        0.06862487643957138    0.06862487643957138  0.00048714742569701275
C668        0.06799335777759552    0.06799335777759552  0.00048266446403030485
C785        0.06706807017326355    0.06706807017326355  0.0004760961247069315
C925        0.06663129478693008    0.06663129478693008  0.0004729955871744883
C888        0.06580846011638641    0.06580846011638641  0.000467154530515063

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_42

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 254,815 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.02023099795498675    0.04320846498012543   0.0         0.0016445035411755294  0.08753511309623718  -0.005186515913629182  0.09612047672271729
    3        2        Softmax                 0.0   0.0   0.0018914817192126065  0.000601982232183218  0.0         -0.033391071666756034  0.46118855476379395  -0.016691274184842328  0.06172196567058563


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.0874887855945815
RMSE: 0.29578503274266854
LogLoss: 0.2889977408695871
Mean Per-Class Error: 0.11974703541583764
AUC: 0.9501391961798646
pr_auc: 0.9241302088592346
Gini: 0.9002783923597293
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43318894551242115: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4241  759   0.1518   (759.0/5000.0)
1      447   4579  0.0889   (447.0/5026.0)
Total  4688  5338  0.1203   (1206.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.433189     0.883636  221
max f2                       0.149094     0.921505  315
max f0point5                 0.789093     0.896184  110
max accuracy                 0.472424     0.880311  210
max precision                0.975948     1         0
max recall                   0.0200897    1         397
max specificity              0.975948     1         0
max absolute_mcc             0.472424     0.76134   210
max min_per_class_accuracy   0.560073     0.878     185
max mean_per_class_accuracy  0.472424     0.880253  210
Gains/Lift Table: Avg response rate: 50.13 %, avg score: 50.85 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.975849           1.99483    1.99483            1                0.97599    1                           0.97599             0.0200955       0.0200955                  99.4827   99.4827
    2        0.0200479                   0.975225           1.97488    1.9849             0.99             0.975522   0.995025                    0.975757            0.0196976       0.0397931                  97.4879   98.4902
    3        0.0300219                   0.974462           1.99483    1.9882             1                0.974843   0.996678                    0.975454            0.0198965       0.0596896                  99.4827   98.82
    4        0.0400958                   0.973652           1.99483    1.98986            1                0.974043   0.997512                    0.975099            0.0200955       0.0797851                  99.4827   98.9865
    5        0.0500698                   0.972874           1.97488    1.98688            0.99             0.973283   0.996016                    0.974737            0.0196976       0.0994827                  97.4879   98.6879
    6        0.10004                     0.968085           1.96297    1.97494            0.984032         0.970566   0.99003                     0.972654            0.0980899       0.197573                   96.2973   97.4938
    7        0.15001                     0.962172           1.95899    1.96963            0.982036         0.965303   0.987367                    0.970205            0.097891        0.295464                   95.8992   96.9626
    8        0.20008                     0.953968           1.93125    1.96002            0.968127         0.95826    0.982552                    0.967216            0.0966972       0.392161                   93.1247   96.0022
    9        0.30002                     0.922094           1.86144    1.92718            0.933134         0.940023   0.96609                     0.958157            0.186033        0.578193                   86.144    92.7183
    10       0.40006                     0.828912           1.71241    1.87348            0.858425         0.883401   0.939167                    0.939464            0.171309        0.749503                   71.2409   87.3476
    11       0.5                         0.561373           1.27812    1.75448            0.640719         0.717463   0.879513                    0.89509             0.127736        0.877238                   27.8123   75.4477
    12       0.60004                     0.216844           0.775656   1.59129            0.388833         0.376274   0.797706                    0.808592            0.0775965       0.954835                   -22.4344  59.1286
    13       0.69998                     0.0761843          0.290663   1.40559            0.145709         0.13391    0.704617                    0.712264            0.0290489       0.983884                   -70.9337  40.5588
    14       0.80002                     0.0355226          0.103421   1.24276            0.0518445        0.0508722  0.62299                     0.629559            0.0103462       0.99423                    -89.6579  24.2757
    15       0.89996                     0.0230724          0.0457894  1.10983            0.0229541        0.0281734  0.556356                    0.562775            0.0045762       0.998806                   -95.4211  10.9834
    16       1                           0.0185216          0.0119332  1                  0.00598205       0.0204484  0.501297                    0.508521            0.00119379      1                          -98.8067  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08208158767793534
RMSE: 0.2864988441127387
LogLoss: 0.2740529652142107
Mean Per-Class Error: 0.11228121626393794
AUC: 0.9554126169411965
pr_auc: 0.9308275238282351
Gini: 0.910825233882393
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.431947373701252: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2682  446   0.1426   (446.0/3128.0)
1      261   2788  0.0856   (261.0/3049.0)
Total  2943  3234  0.1145   (707.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.431947     0.887474  223
max f2                       0.188714     0.922797  299
max f0point5                 0.802488     0.905964  110
max accuracy                 0.564435     0.88781   181
max precision                0.975925     1         0
max recall                   0.0194173    1         398
max specificity              0.975925     1         0
max absolute_mcc             0.685136     0.775732  148
max min_per_class_accuracy   0.540778     0.88555   188
max mean_per_class_accuracy  0.564435     0.887719  181
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.04 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.975768           2.02591     2.02591            1                0.975965   1                           0.975965            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.975215           2.02591     2.02591            1                0.975503   1                           0.975734            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.974189           2.02591     2.02591            1                0.974655   1                           0.975374            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.973292           2.02591     2.02591            1                0.973741   1                           0.974966            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.97246            2.02591     2.02591            1                0.972889   1                           0.974556            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.967877           1.99968     2.0128             0.987055         0.97019    0.993528                    0.972373            0.100033        0.201378                   99.9685   101.28
    7        0.150073                    0.962201           2.00624     2.01061            0.990291         0.965058   0.992449                    0.969935            0.100361        0.301738                   100.624   101.061
    8        0.200097                    0.953807           1.97346     2.00132            0.97411          0.958391   0.987864                    0.967049            0.0987209       0.400459                   97.3459   100.132
    9        0.299984                    0.919088           1.888       1.96359            0.931929         0.939283   0.969239                    0.957804            0.188586        0.589046                   88.8004   96.3591
    10       0.400032                    0.827484           1.78988     1.92015            0.883495         0.881024   0.947794                    0.938601            0.179075        0.768121                   78.9882   92.0146
    11       0.500081                    0.51985            1.22276     1.78062            0.60356          0.692959   0.878925                    0.889457            0.122335        0.890456                   22.2758   78.0624
    12       0.599968                    0.194107           0.7158      1.60334            0.353323         0.341309   0.791419                    0.798197            0.0714989       0.961955                   -28.42    60.3344
    13       0.700016                    0.0706391          0.209803    1.40417            0.10356          0.118875   0.693108                    0.701106            0.0209905       0.982945                   -79.0197  40.4175
    14       0.799903                    0.0342214          0.124772    1.24441            0.0615883        0.048039   0.614248                    0.619556            0.0124631       0.995408                   -87.5228  24.4412
    15       0.899951                    0.0230034          0.0393381   1.11044            0.0194175        0.0279828  0.54812                     0.55379             0.00393572      0.999344                   -96.0662  11.0442
    16       1                           0.0185661          0.00655634  1                  0.00323625       0.0203434  0.493605                    0.500419            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:51:55  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:52:00  45 min 17.530 sec  4752 obs/sec      0.92564   1             23141      0.306581         0.308383            0.624029       0.941861        0.918143           1.99483          0.129164                         0.298026           0.29347               0.644663         0.947444          0.919133             2.02591            0.118018
    2019-08-03 16:52:05  45 min 23.072 sec  4623 obs/sec      1.85212   2             46303      0.298717         0.293425            0.64307        0.948075        0.933555           1.99483          0.123579                         0.289155           0.278322              0.665504         0.953974          0.943574             2.02591            0.112838
    2019-08-03 16:52:11  45 min 28.266 sec  4678 obs/sec      2.77704   3             69426      0.295785         0.288998            0.650043       0.950139        0.92413            1.99483          0.120287                         0.286499           0.274053              0.67162          0.955413          0.930828             2.02591            0.114457
    2019-08-03 16:52:16  45 min 33.609 sec  4687 obs/sec      3.70356   4             92589      0.295509         0.289794            0.650696       0.95034         0.900646           1.99483          0.118791                         0.286231           0.275002              0.672233         0.955521          0.908424             2.02591            0.112352
    2019-08-03 16:52:21  45 min 38.753 sec  4730 obs/sec      4.63048   5             115762     0.296282         0.292825            0.648865       0.949264        0.895061           1.97508          0.119689                         0.287107           0.27865               0.670224         0.954337          0.855726             2.02591            0.113971
    2019-08-03 16:52:26  45 min 44.119 sec  4724 obs/sec      5.55884   6             138971     0.298288         0.296594            0.644094       0.948994        0.774455           1.99483          0.121085                         0.287791           0.28                  0.668651         0.954036          0.781069             2.02591            0.110895
    2019-08-03 16:52:32  45 min 49.367 sec  4731 obs/sec      6.4834    7             162085     0.298953         0.298707            0.642505       0.947473        0.74952            1.99483          0.121883                         0.288734           0.282705              0.666477         0.952535          0.763929             2.02591            0.115104
    2019-08-03 16:52:37  45 min 54.493 sec  4753 obs/sec      7.40912   8             185228     0.299893         0.301423            0.640255       0.94633         0.689869           1.99483          0.122681                         0.28993            0.285976              0.663708         0.951568          0.697398             2.02591            0.110733
    2019-08-03 16:52:46  46 min  3.648 sec  4852 obs/sec      9.26448   10            231612     0.300214         0.304489            0.639483       0.945493        0.629454           1.98088          0.120686                         0.290285           0.289021              0.662884         0.95111           0.629622             2.0012             0.113647
    2019-08-03 16:52:50  46 min  8.244 sec  4905 obs/sec      10.1926   11            254815     0.301491         0.305372            0.636409       0.944556        0.609948           1.98336          0.118791                         0.291124           0.288407              0.660932         0.950072          0.6162               2.02591            0.112028
    2019-08-03 16:52:51  46 min  8.656 sec  4904 obs/sec      10.1926   11            254815     0.295785         0.288998            0.650043       0.950139        0.92413            1.99483          0.120287                         0.286499           0.274053              0.67162          0.955413          0.930828             2.02591            0.114457
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.00659086153189457
C438        0.893431544303894      0.893431544303894    0.0058884835967336945
C374        0.7167218327522278     0.7167218327522278   0.004723814356555632
C322        0.6840711236000061     0.6840711236000061   0.0045086180536151755
C88         0.6773322820663452     0.6773322820663452   0.004464203282181437
---         ---                    ---                  ---
C885        0.08149871975183487    0.08149871975183487  0.0005371467769110246
C612        0.0813499465584755     0.0813499465584755   0.0005361662333939352
C594        0.0802883729338646     0.0802883729338646   0.0005291695486282133
C823        0.07302785664796829    0.07302785664796829  0.00048131649113780536
C776        0.07255250215530396    0.07255250215530396  0.0004781834954980907

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_203

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.015666464457444816  0.03542602062225342    0.0         -0.0009576478684685841  0.09421008825302124  0.0033588351689236248  0.09478449821472168
    3        2        Softmax                 0.0   0.0   0.001804128238291014  0.0005416497588157654  0.0         0.0194120298820053      0.48045945167541504  0.0028655637184805197  0.07555976510047913


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08644267987655813
RMSE: 0.294011360114806
LogLoss: 0.2900077633172074
Mean Per-Class Error: 0.11381211265094138
AUC: 0.9494443510806635
pr_auc: 0.9393097973121544
Gini: 0.898888702161327
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49363115560862614: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4414  659   0.1299   (659.0/5073.0)
1      491   4446  0.0995   (491.0/4937.0)
Total  4905  5105  0.1149   (1150.0/10010.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.493631     0.885481  206
max f2                       0.172794     0.915602  309
max f0point5                 0.766589     0.898241  121
max accuracy                 0.534622     0.886114  194
max precision                0.970768     1         0
max recall                   0.0232448    1         397
max specificity              0.970768     1         0
max absolute_mcc             0.534622     0.772305  194
max min_per_class_accuracy   0.55746      0.884289  189
max mean_per_class_accuracy  0.534622     0.886188  194
Gains/Lift Table: Avg response rate: 49.32 %, avg score: 50.07 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100899                   0.969021           2.02755    2.02755            1                0.970103   1                           0.970103            0.0204578       0.0204578                  102.755   102.755
    2        0.0200799                   0.968002           2.00727    2.01746            0.99             0.96854    0.995025                    0.969325            0.0200527       0.0405104                  100.727   101.746
    3        0.0300699                   0.966823           2.02755    2.02081            1                0.967457   0.996678                    0.968705            0.0202552       0.0607656                  102.755   102.081
    4        0.0400599                   0.965709           2.02755    2.02249            1                0.966266   0.997506                    0.968096            0.0202552       0.0810209                  102.755   102.249
    5        0.05005                     0.964667           2.02755    2.0235             1                0.965199   0.998004                    0.967518            0.0202552       0.101276                   102.755   102.35
    6        0.1                         0.959059           1.99511    2.00932            0.984            0.961914   0.991009                    0.964719            0.0996557       0.200932                   99.5106   100.932
    7        0.15005                     0.952293           1.95875    1.99245            0.966068         0.955956   0.98269                     0.961796            0.0980352       0.298967                   95.8748   99.245
    8        0.2                         0.944381           1.94645    1.98096            0.96             0.94852    0.977023                    0.95848             0.097225        0.396192                   94.6445   98.096
    9        0.3                         0.91046            1.89589    1.9526             0.935065         0.930158   0.963037                    0.949039            0.189589        0.585781                   89.5888   95.2603
    10       0.4                         0.816988           1.74803    1.90146            0.862138         0.871877   0.937812                    0.929749            0.174803        0.760583                   74.8025   90.1458
    11       0.5                         0.533369           1.30849    1.78286            0.645355         0.700753   0.879321                    0.88395             0.130849        0.891432                   30.8487   78.2864
    12       0.6                         0.199022           0.623861   1.5897             0.307692         0.347882   0.784049                    0.794605            0.0623861       0.953818                   -37.6139  58.9697
    13       0.7                         0.077525           0.281547   1.40282            0.138861         0.125445   0.69188                     0.699011            0.0281547       0.981973                   -71.8453  40.2818
    14       0.8                         0.0397457          0.11748    1.24215            0.0579421        0.055189   0.612637                    0.618533            0.011748        0.993721                   -88.252   24.2151
    15       0.9                         0.0284778          0.0405104  1.10864            0.01998          0.0332056  0.546787                    0.553497            0.00405104      0.997772                   -95.949   10.8635
    16       1                           0.0212908          0.0222807  1                  0.010989         0.0252017  0.493207                    0.500667            0.00222807      1                          -97.7719  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08136824678038093
RMSE: 0.2852511994372345
LogLoss: 0.2743091263325468
Mean Per-Class Error: 0.11035556079348474
AUC: 0.955393324212626
pr_auc: 0.9416747361423073
Gini: 0.910786648425252
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4707958079619283: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2730  398   0.1272   (398.0/3128.0)
1      285   2764  0.0935   (285.0/3049.0)
Total  3015  3162  0.1106   (683.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.470796     0.890034  211
max f2                       0.177482     0.924301  306
max f0point5                 0.776028     0.904889  117
max accuracy                 0.612434     0.88959   170
max precision                0.970743     1         0
max recall                   0.0243716    1         397
max specificity              0.970743     1         0
max absolute_mcc             0.612434     0.779589  170
max min_per_class_accuracy   0.545531     0.888747  191
max mean_per_class_accuracy  0.470796     0.889644  211
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.84 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.968923           2.02591     2.02591            1                0.970237   1                           0.970237            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.967745           1.99323     2.00957            0.983871         0.968306   0.991935                    0.969271            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.96657            1.99323     2.00413            0.983871         0.967132   0.989247                    0.968558            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.965784           2.02591     2.00957            1                0.966152   0.991935                    0.967957            0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.964683           2.02591     2.0128             1                0.965284   0.993528                    0.967429            0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.959782           2.00624     2.00952            0.990291         0.962354   0.991909                    0.964892            0.100361        0.20105                    100.624   100.952
    7        0.150073                    0.953739           1.96035     1.99313            0.967638         0.956767   0.983819                    0.962184            0.0980649       0.299114                   96.0347   99.3128
    8        0.200097                    0.945766           2.00624     1.99641            0.990291         0.949916   0.985437                    0.959117            0.100361        0.399475                   100.624   99.6407
    9        0.299984                    0.909547           1.92412     1.97234            0.949757         0.929968   0.973556                    0.949411            0.192194        0.591669                   92.4122   97.2338
    10       0.400032                    0.815445           1.75382     1.91769            0.865696         0.872604   0.94658                     0.930202            0.175467        0.767137                   75.3822   91.7687
    11       0.500081                    0.51451            1.26537     1.78718            0.624595         0.689232   0.882163                    0.881992            0.126599        0.893736                   26.5374   78.7182
    12       0.599968                    0.196872           0.692815    1.60498            0.341977         0.341097   0.792229                    0.79194             0.069203        0.962939                   -30.7185  60.4984
    13       0.700016                    0.0748268          0.199968    1.40417            0.0987055        0.121443   0.693108                    0.696111            0.0200066       0.982945                   -80.0032  40.4175
    14       0.799903                    0.0390116          0.128056    1.24482            0.0632091        0.0537058  0.614451                    0.615891            0.0127911       0.995736                   -87.1944  24.4822
    15       0.899951                    0.0279353          0.0360599   1.11044            0.0177994        0.0327273  0.54812                     0.55106             0.00360774      0.999344                   -96.394   11.0442
    16       1                           0.021292           0.00655634  1                  0.00323625       0.0249558  0.493605                    0.498424            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:15:30  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:15:35  4:08:53.081  4801 obs/sec      1         1             25000      0.30505          0.308801            0.62771        0.942138        0.92405            2.02755          0.124575                         0.298656           0.295348              0.643161         0.946883          0.934669             2.02591            0.122228
    2019-08-03 20:15:41  4:08:58.597  4821 obs/sec      2         2             50000      0.295416         0.290006            0.650853       0.94893         0.937864           2.02755          0.118182                         0.287308           0.275559              0.669763         0.954245          0.940139             2.02591            0.108791
    2019-08-03 20:15:46  4:09:04.193  4832 obs/sec      3         3             75000      0.294011         0.290008            0.654165       0.949444        0.93931            2.02755          0.114885                         0.285251           0.274309              0.674474         0.955393          0.941675             2.02591            0.110571
    2019-08-03 20:15:52  4:09:09.746  4848 obs/sec      4         4             100000     0.29549          0.293304            0.650678       0.94794         0.931097           2.02755          0.117183                         0.286987           0.277666              0.6705           0.953441          0.938086             1.99323            0.110733
    2019-08-03 20:15:58  4:09:15.356  4844 obs/sec      5         5             125000     0.296442         0.296456            0.648423       0.947073        0.930341           2.00747          0.115285                         0.287502           0.279941              0.669317         0.953477          0.931785             1.96056            0.11041
    2019-08-03 20:16:03  4:09:20.787  4871 obs/sec      6         6             150000     0.296291         0.297034            0.648781       0.947329        0.89098            2.02755          0.116384                         0.287918           0.280927              0.668358         0.953643          0.894802             2.02591            0.113971
    2019-08-03 20:16:08  4:09:26.068  4910 obs/sec      7         7             175000     0.298787         0.302664            0.64284        0.944767        0.935              1.9874           0.118781                         0.290452           0.287713              0.662496         0.950897          0.938603             1.92788            0.114295
    2019-08-03 20:16:14  4:09:31.347  4939 obs/sec      8         8             200000     0.299268         0.303301            0.641687       0.944591        0.836225           2.02755          0.116883                         0.290868           0.287095              0.661528         0.950795          0.847312             2.02591            0.112838
    2019-08-03 20:16:19  4:09:36.470  4978 obs/sec      9         9             225000     0.29971          0.30479             0.64063        0.943407        0.819854           1.9874           0.116084                         0.291663           0.289427              0.659676         0.949628          0.816132             1.99323            0.115752
    2019-08-03 20:16:24  4:09:41.474  5017 obs/sec      10        10            250000     0.299315         0.304998            0.641577       0.943359        0.925124           1.94725          0.117083                         0.291119           0.289565              0.660944         0.949924          0.935994             1.99323            0.112676
    2019-08-03 20:16:24  4:09:41.915  5016 obs/sec      10        10            250000     0.294011         0.290008            0.654165       0.949444        0.93931            2.02755          0.114885                         0.285251           0.274309              0.674474         0.955393          0.941675             2.02591            0.110571
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.006902343256976491
C438        0.9178562164306641     0.9178562164306641   0.006335358666354149
C374        0.800429105758667      0.800429105758667    0.005524836440821058
C88         0.6578384041786194     0.6578384041786194   0.004540626473262469
C863        0.6322574615478516     0.6322574615478516   0.004364058026387886
---         ---                    ---                  ---
C949        0.07274124771356583    0.07274124771356583  0.0005020850606597877
C950        0.07184552401304245    0.07184552401304245  0.0004959024682153661
C275        0.07167012989521027    0.07167012989521027  0.0004946918378088338
C963        0.07079396396875381    0.07079396396875381  0.0004886442398343646
C725        0.06820692867040634    0.06820692867040634  0.00047078763418725573

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_65

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  ------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.020487291430029527   0.033482372760772705   0.0         -0.0009791450003185998  0.09464970231056213  0.010630142512000746   0.0840001106262207
    3        2        Softmax                 0.0   0.0   0.0017543154499435332  0.0003678840585052967  0.0         0.008874804552760907    0.5124790668487549   0.0027315052874686413  0.0984703004360199


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08800235066340023
RMSE: 0.2966519014997211
LogLoss: 0.29421745033686775
Mean Per-Class Error: 0.11785090531359188
AUC: 0.9482709131664356
pr_auc: 0.9242298495414859
Gini: 0.8965418263328713
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44671557173655163: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4266  739   0.1477   (739.0/5005.0)
1      462   4563  0.0919   (462.0/5025.0)
Total  4728  5302  0.1197   (1201.0/10030.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.446716     0.883703  220
max f2                       0.150928     0.916935  317
max f0point5                 0.767402     0.897819  119
max accuracy                 0.5497       0.882154  188
max precision                0.967987     1         0
max recall                   0.0224519    1         398
max specificity              0.967987     1         0
max absolute_mcc             0.5497       0.76431   188
max min_per_class_accuracy   0.558306     0.881194  185
max mean_per_class_accuracy  0.5497       0.882149  188
Gains/Lift Table: Avg response rate: 50.10 %, avg score: 50.43 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100698                   0.967723           1.99602    1.99602            1                0.968047   1                           0.968047            0.0200995       0.0200995                  99.602    99.602
    2        0.0200399                   0.967318           1.99602    1.99602            1                0.967489   1                           0.967769            0.0199005       0.04                       99.602    99.602
    3        0.03001                     0.966921           1.99602    1.99602            1                0.967143   1                           0.967561            0.0199005       0.0599005                  99.602    99.602
    4        0.0400798                   0.966403           1.99602    1.99602            1                0.966696   1                           0.967344            0.0200995       0.08                       99.602    99.602
    5        0.0500499                   0.965782           1.9561     1.98807            0.98             0.966086   0.996016                    0.967093            0.0195025       0.0995025                  95.61     98.8068
    6        0.1                         0.961009           1.97212    1.9801             0.988024         0.963606   0.992024                    0.965352            0.0985075       0.19801                    97.2115   98.01
    7        0.15005                     0.953579           1.92843    1.96286            0.966135         0.957309   0.983389                    0.962669            0.0965174       0.294527                   92.8426   96.2863
    8        0.2                         0.944791           1.91235    1.95025            0.958084         0.949022   0.977069                    0.959261            0.0955224       0.39005                    91.2354   95.0249
    9        0.3                         0.916537           1.88259    1.92769            0.94317          0.932855   0.965769                    0.950459            0.188259        0.578308                   88.2587   92.7695
    10       0.4                         0.83467            1.71343    1.87413            0.858425         0.88341    0.938933                    0.933696            0.171343        0.749652                   71.3433   87.4129
    11       0.5                         0.558865           1.30746    1.7608             0.655035         0.715208   0.882154                    0.889999            0.130746        0.880398                   30.7463   76.0796
    12       0.6                         0.208937           0.704478   1.58474            0.352941         0.369296   0.793951                    0.803215            0.0704478       0.950846                   -29.5522  58.4743
    13       0.7                         0.0688853          0.290547   1.39986            0.145563         0.120393   0.701325                    0.705669            0.0290547       0.9799                     -70.9453  39.9858
    14       0.8                         0.0374137          0.125373   1.24055            0.0628116        0.0494386  0.62151                     0.62364             0.0125373       0.992438                   -87.4627  24.0547
    15       0.9                         0.0249455          0.0597015  1.10934            0.0299103        0.03053    0.555777                    0.557739            0.00597015      0.998408                   -94.0299  10.9342
    16       1                           0.021328           0.0159204  1                  0.00797607       0.0228823  0.500997                    0.504253            0.00159204      1                          -98.408   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08177841502298387
RMSE: 0.28596925538068574
LogLoss: 0.27473166358023543
Mean Per-Class Error: 0.11122105985862629
AUC: 0.9553382245992355
pr_auc: 0.9265980627120892
Gini: 0.9106764491984709
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4420507645976411: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2702  426   0.1362   (426.0/3128.0)
1      265   2784  0.0869   (265.0/3049.0)
Total  2967  3210  0.1119   (691.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.442051     0.889599  221
max f2                       0.158873     0.922759  311
max f0point5                 0.819282     0.904904  100
max accuracy                 0.528908     0.888619  195
max precision                0.967979     1         0
max recall                   0.0228378    1         397
max specificity              0.967979     1         0
max absolute_mcc             0.484073     0.777582  208
max min_per_class_accuracy   0.536362     0.887468  192
max mean_per_class_accuracy  0.484073     0.888779  208
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.59 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.967805           2.02591     2.02591            1                0.968066   1                           0.968066            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.967353           2.02591     2.02591            1                0.967556   1                           0.967811            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.967092           2.02591     2.02591            1                0.967246   1                           0.967623            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.966623           2.02591     2.02591            1                0.966876   1                           0.967436            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.966032           2.02591     2.02591            1                0.966304   1                           0.967213            0.0200066       0.101345                   102.591   102.591
    6        0.100049                    0.961106           1.99313     2.00952            0.983819         0.963952   0.991909                    0.965582            0.0997048       0.20105                    99.3128   100.952
    7        0.150073                    0.953995           1.9669      1.99531            0.970874         0.957524   0.984898                    0.962896            0.0983929       0.299442                   96.6903   99.5314
    8        0.200097                    0.944925           1.97346     1.98985            0.97411          0.949221   0.982201                    0.959478            0.0987209       0.398163                   97.3459   98.985
    9        0.299984                    0.914165           1.93397     1.97124            0.954619         0.931894   0.973017                    0.950293            0.193178        0.591341                   93.3973   97.1244
    10       0.400032                    0.82545            1.75054     1.91605            0.864078         0.878999   0.945771                    0.932462            0.175139        0.766481                   75.0544   91.6047
    11       0.500081                    0.515439           1.26865     1.78653            0.626214         0.691636   0.881839                    0.884281            0.126927        0.893408                   26.8652   78.6526
    12       0.599968                    0.178988           0.673114    1.60116            0.332253         0.327806   0.79034                     0.791636            0.0672352       0.960643                   -32.6886  60.1158
    13       0.700016                    0.0643966          0.245863    1.40745            0.121359         0.109469   0.694727                    0.694138            0.0245982       0.985241                   -75.4137  40.7455
    14       0.799903                    0.0366582          0.0886541   1.24277            0.0437601        0.0477023  0.613439                    0.613416            0.00885536      0.994096                   -91.1346  24.2771
    15       0.899951                    0.0245618          0.0524507   1.11044            0.02589          0.029832   0.54812                     0.548538            0.00524762      0.999344                   -94.7549  11.0442
    16       1                           0.0213207          0.00655634  1                  0.00323625       0.0227509  0.493605                    0.495934            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:16:16  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:16:21  1:09:38.725  4959 obs/sec      1         1             25000      0.313367         0.321286            0.607202       0.938023        0.917899           1.97626          0.132502                         0.301382           0.298851              0.636616         0.946438          0.914836             2.02591            0.125142
    2019-08-03 17:16:26  1:09:44.183  4944 obs/sec      2         2             50000      0.297072         0.292903            0.646991       0.948044        0.932875           1.99602          0.121236                         0.287027           0.274962              0.670407         0.95474           0.935095             2.02591            0.113486
    2019-08-03 17:16:32  1:09:49.623  4942 obs/sec      3         3             75000      0.296652         0.294217            0.647989       0.948271        0.92423            1.99602          0.119741                         0.285969           0.274732              0.672833         0.955338          0.926598             2.02591            0.111867
    2019-08-03 17:16:37  1:09:55.163  4917 obs/sec      4         4             100000     0.296591         0.296935            0.648135       0.947667        0.919455           1.99602          0.117647                         0.285551           0.277672              0.673789         0.955087          0.918868             2.02591            0.113162
    2019-08-03 17:16:43  1:10:00.637  4917 obs/sec      5         5             125000     0.297656         0.298918            0.645603       0.9459          0.904637           1.99602          0.118046                         0.28703            0.279903              0.670401         0.952887          0.911371             2.02591            0.112514
    2019-08-03 17:16:48  1:10:06.065  4928 obs/sec      6         6             150000     0.299787         0.30338             0.64051        0.944889        0.8848             1.99602          0.119541                         0.289149           0.283869              0.665518         0.95262           0.887418             2.02591            0.115428
    2019-08-03 17:16:54  1:10:11.464  4944 obs/sec      7         7             175000     0.299232         0.302924            0.641839       0.945062        0.880496           1.97626          0.118445                         0.288774           0.283139              0.666383         0.952432          0.879403             2.02591            0.113971
    2019-08-03 17:16:59  1:10:16.496  4998 obs/sec      8         8             200000     0.300333         0.305009            0.639199       0.943274        0.868788           1.99602          0.12004                          0.290241           0.285989              0.662986         0.950083          0.882095             2.02591            0.114295
    2019-08-03 17:17:04  1:10:21.509  5039 obs/sec      9         9             225000     0.301108         0.306851            0.637335       0.944014        0.817938           1.97626          0.119143                         0.290706           0.286706              0.661904         0.951412          0.828653             2.02591            0.113
    2019-08-03 17:17:09  1:10:26.526  5076 obs/sec      10        10            250000     0.300993         0.306866            0.637611       0.942951        0.923285           1.93673          0.119641                         0.291494           0.288995              0.660069         0.950203          0.929158             1.92788            0.114133
    2019-08-03 17:17:09  1:10:26.944  5075 obs/sec      10        10            250000     0.296652         0.294217            0.647989       0.948271        0.92423            1.99602          0.119741                         0.285969           0.274732              0.672833         0.955338          0.926598             2.02591            0.111867
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.006969420460734494
C438        0.8369196057319641     0.8369196057319641   0.0058328446241781955
C374        0.7281723022460938     0.7281723022460938   0.005074938942214067
C88         0.6893650889396667     0.6893650889396667   0.004804475155772168
C322        0.6107880473136902     0.6107880473136902   0.0042568387141201005
---         ---                    ---                  ---
C497        0.07375482469797134    0.07375482469797134  0.0005140283843279273
C912        0.07259815186262131    0.07259815186262131  0.0005059670450028629
C832        0.07136306166648865    0.07136306166648865  0.0004973591821190833
C980        0.0695892795920372     0.0695892795920372   0.0004849969490365174
C741        0.06920430064201355    0.06920430064201355  0.0004823138688652705

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_15

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 262,692 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.013874128063425629   0.03509017825126648     0.0         0.002212612756381752    0.0713624358177185  -0.011769292677409636  0.07053419947624207
    3        2        Softmax                 0.0   0.0   0.0018330075536141521  0.00047980970703065395  0.0         -0.0007553774303232785  0.4997591972351074  -0.01945659047707502   0.07476875185966492


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08982840032752497
RMSE: 0.2997138640896096
LogLoss: 0.2955541642932531
Mean Per-Class Error: 0.12371399046104936
AUC: 0.9470033585055644
pr_auc: 0.934849867303551
Gini: 0.8940067170111288
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43380130151141344: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4223  809   0.1608   (809.0/5032.0)
1      461   4539  0.0922   (461.0/5000.0)
Total  4684  5348  0.1266   (1270.0/10032.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.433801     0.877271  223
max f2                       0.194338     0.919341  298
max f0point5                 0.76288      0.891554  122
max accuracy                 0.558026     0.876296  188
max precision                0.981908     0.996324  3
max recall                   0.0136217    1         396
max specificity              0.984402     0.999801  0
max absolute_mcc             0.558026     0.752604  188
max min_per_class_accuracy   0.546117     0.875199  192
max mean_per_class_accuracy  0.554264     0.876286  189
Gains/Lift Table: Avg response rate: 49.84 %, avg score: 50.41 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100678                   0.983466           1.98653    1.98653            0.990099         0.984113   0.990099                    0.984113            0.02            0.02                       98.6535   98.6535
    2        0.0200359                   0.982343           2.0064     1.99642            1                0.982854   0.995025                    0.983487            0.02            0.04                       100.64    99.6418
    3        0.030004                    0.980868           1.98634    1.99307            0.99             0.981626   0.993355                    0.982869            0.0198          0.0598                     98.6336   99.3068
    4        0.0400718                   0.979509           2.0064     1.99642            1                0.980201   0.995025                    0.982198            0.0202          0.08                       100.64    99.6418
    5        0.0500399                   0.978179           1.98634    1.99441            0.99             0.978849   0.994024                    0.981531            0.0198          0.0998                     98.6336   99.441
    6        0.10008                     0.97043            1.98242    1.98841            0.988048         0.974456   0.991036                    0.977993            0.0992          0.199                      98.2419   98.8414
    7        0.15002                     0.961569           1.95033    1.97574            0.972056         0.966119   0.984718                    0.974041            0.0974          0.2964                     95.0333   97.5737
    8        0.20006                     0.949488           1.93446    1.96541            0.964143         0.955749   0.979571                    0.969465            0.0968          0.3932                     93.4457   96.5412
    9        0.30004                     0.906664           1.86637    1.93241            0.930209         0.930658   0.963123                    0.956534            0.1866          0.5798                     86.6372   93.241
    10       0.40002                     0.800886           1.69434    1.87291            0.844467         0.861802   0.933466                    0.932857            0.1694          0.7492                     69.4338   87.2907
    11       0.5                         0.538812           1.27025    1.7524             0.633101         0.687692   0.873405                    0.883834            0.127           0.8762                     27.0253   75.24
    12       0.59998                     0.231587           0.790158   1.59205            0.393819         0.377267   0.793487                    0.79942             0.079           0.9552                     -20.9842  59.2053
    13       0.69996                     0.0858962          0.280056   1.40465            0.139581         0.145747   0.700085                    0.706051            0.028           0.9832                     -71.9944  40.4651
    14       0.79994                     0.0380944          0.110022   1.24284            0.0548355        0.0573765  0.619439                    0.624977            0.011           0.9942                     -88.9978  24.2843
    15       0.89992                     0.0192366          0.040008   1.10921            0.0199402        0.0270871  0.552836                    0.558552            0.004           0.9982                     -95.9992  10.9209
    16       1                           0.0106847          0.0179857  1                  0.00896414       0.014564   0.498405                    0.50411             0.0018          1                          -98.2014  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08286018623517741
RMSE: 0.28785445321408076
LogLoss: 0.27581683212186575
Mean Per-Class Error: 0.11307630735497531
AUC: 0.9542319858341044
pr_auc: 0.9459979439737399
Gini: 0.9084639716682088
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4687482100563374: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2705  423   0.1352   (423.0/3128.0)
1      284   2765  0.0931   (284.0/3049.0)
Total  2989  3188  0.1145   (707.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.468748     0.886644  213
max f2                       0.227059     0.921575  283
max f0point5                 0.804463     0.902084  111
max accuracy                 0.551715     0.887     188
max precision                0.984555     1         0
max recall                   0.0114864    1         399
max specificity              0.984555     1         0
max absolute_mcc             0.551715     0.773969  188
max min_per_class_accuracy   0.532056     0.88555   193
max mean_per_class_accuracy  0.551715     0.886924  188
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.02 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.983362           2.02591     2.02591            1                0.984116   1                           0.984116            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.982039           2.02591     2.02591            1                0.982746   1                           0.983431            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.980765           1.99323     2.01502            0.983871         0.981382   0.994624                    0.982748            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.979527           2.02591     2.01774            1                0.980102   0.995968                    0.982086            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.978009           1.9927      2.0128             0.983607         0.978744   0.993528                    0.981427            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.970252           2.0128      2.0128             0.993528         0.974159   0.993528                    0.977793            0.100689        0.201378                   101.28    101.28
    7        0.150073                    0.961447           1.9669      1.9975             0.970874         0.965944   0.985976                    0.973843            0.0983929       0.29977                    96.6903   99.7499
    8        0.200097                    0.950321           1.98657     1.99477            0.980583         0.955935   0.984628                    0.969366            0.0993768       0.399147                   98.6572   99.4768
    9        0.299984                    0.908259           1.91427     1.96796            0.944895         0.93166    0.971398                    0.956811            0.19121         0.590357                   91.4272   96.7965
    10       0.400032                    0.801266           1.74727     1.91277            0.86246          0.863009   0.944152                    0.933351            0.174811        0.765169                   74.7266   91.2767
    11       0.500081                    0.518957           1.25554     1.78128            0.619741         0.675195   0.879249                    0.881703            0.125615        0.890784                   25.554    78.1279
    12       0.599968                    0.216925           0.702666    1.6017             0.34684          0.360077   0.79061                     0.794859            0.0701869       0.960971                   -29.7334  60.1704
    13       0.700016                    0.0809558          0.226194    1.40511            0.11165          0.138252   0.693571                    0.701015            0.0226304       0.983601                   -77.3806  40.5112
    14       0.799903                    0.0354541          0.114922    1.244              0.0567261        0.0543599  0.614046                    0.620265            0.0114792       0.99508                    -88.5078  24.4001
    15       0.899951                    0.0187837          0.0426162   1.11044            0.0210356        0.0257536  0.54812                     0.554172            0.00426369      0.999344                   -95.7384  11.0442
    16       1                           0.0107472          0.00655634  1                  0.00323625       0.014295   0.493605                    0.500158            0.000655953     1                          -99.3444  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:24:55  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:25:00  18 min 17.927 sec  4906 obs/sec      0.95528   1             23882      0.308769         0.312735            0.618642       0.940216        0.916421           2.0064           0.130183                         0.298964           0.294288              0.642424         0.947344          0.928014             2.02591            0.120932
    2019-08-03 16:25:06  18 min 23.312 sec  4843 obs/sec      1.91092   2             47773      0.299714         0.295554            0.640683       0.947003        0.93485            1.98653          0.126595                         0.287854           0.275817              0.668505         0.954232          0.945998             2.02591            0.114457
    2019-08-03 16:25:11  18 min 28.500 sec  4887 obs/sec      2.86548   3             71637      0.298828         0.295508            0.642803       0.947683        0.921354           1.98653          0.123405                         0.287254           0.276743              0.669886         0.954261          0.934302             2.02591            0.114133
    2019-08-03 16:25:16  18 min 33.763 sec  4888 obs/sec      3.8188    4             95470      0.298789         0.296179            0.642897       0.947576        0.905429           1.98653          0.12191                          0.287308           0.277178              0.669763         0.954398          0.911039             2.02591            0.112838
    2019-08-03 16:25:21  18 min 38.971 sec  4905 obs/sec      4.774     5             119350     0.299133         0.298917            0.642075       0.946982        0.8837             2.0064           0.120415                         0.286925           0.27904               0.670641         0.953891          0.875218             1.99323            0.111381
    2019-08-03 16:25:27  18 min 44.445 sec  4866 obs/sec      5.72944   6             143236     0.300803         0.302689            0.638066       0.945731        0.867303           2.0064           0.122109                         0.288849           0.282133              0.666211         0.952596          0.876919             2.02591            0.114295
    2019-08-03 16:25:32  18 min 49.759 sec  4867 obs/sec      6.68576   7             167144     0.302241         0.305807            0.634597       0.943859        0.843107           2.0064           0.12191                          0.290395           0.285406              0.662627         0.950521          0.846021             1.99323            0.114457
    2019-08-03 16:25:37  18 min 54.838 sec  4898 obs/sec      7.64312   8             191078     0.302271         0.307384            0.634525       0.943136        0.926325           2.0064           0.121711                         0.290657           0.287187              0.662018         0.950402          0.937269             1.99323            0.114619
    2019-08-03 16:25:43  19 min  1.011 sec  4798 obs/sec      8.59836   9             214959     0.303039         0.309329            0.632666       0.942444        0.807806           2.0064           0.122408                         0.291085           0.287889              0.661022         0.949801          0.809941             1.99323            0.116076
    2019-08-03 16:25:53  19 min 10.330 sec  4888 obs/sec      10.5077   11            262692     0.30464          0.312805            0.628773       0.940398        0.912408           1.98653          0.123505                         0.292738           0.291664              0.657161         0.947899          0.92521              1.99323            0.116561
    2019-08-03 16:25:53  19 min 10.750 sec  4887 obs/sec      10.5077   11            262692     0.299714         0.295554            0.640683       0.947003        0.93485            1.98653          0.126595                         0.287854           0.275817              0.668505         0.954232          0.945998             2.02591            0.114457
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ---------------------
C250        1.0                    1.0                  0.005866614277266938
C438        0.8005132675170898     0.8005132675170898   0.0046963025643573676
C88         0.7268503308296204     0.7268503308296204   0.004264150528281248
C374        0.6906886100769043     0.6906886100769043   0.004052003661022824
C79         0.6382184624671936     0.6382184624671936   0.0037441815439253913
---         ---                    ---                  ---
C897        0.09890644252300262    0.09890644252300262  0.000580245947819129
C743        0.09876206517219543    0.09876206517219543  0.0005793989415915695
C251        0.09672552347183228    0.09672552347183228  0.0005674513369759695
C507        0.09658211469650269    0.09658211469650269  0.0005666100130071357
C430        0.09478659182786942    0.09478659182786942  0.0005560763729108524

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_218

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias                bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -----------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.018877273684295558  0.03117060661315918    0.0         0.0012859810415287135  0.09496524930000305  -7.371180744687909e-05   0.09651687741279602
    3        2        Softmax                 0.0   0.0   0.002112041380314622  0.0006844971794635057  0.0         -0.07302405497739528   0.5030779838562012   -0.00015977308782288285  0.09845632314682007


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08736783342106935
RMSE: 0.29558050243727063
LogLoss: 0.2908768346353555
Mean Per-Class Error: 0.11717922982724294
AUC: 0.9495951625734399
pr_auc: 0.9376751523123655
Gini: 0.8991903251468798
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5087856342990761: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4361  635   0.1271   (635.0/4996.0)
1      538   4478  0.1073   (538.0/5016.0)
Total  4899  5113  0.1172   (1173.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.508786     0.884194  198
max f2                       0.137018     0.918765  321
max f0point5                 0.800196     0.897542  106
max accuracy                 0.508786     0.882841  198
max precision                0.969106     1         0
max recall                   0.0224589    1         397
max specificity              0.969106     1         0
max absolute_mcc             0.508786     0.765815  198
max min_per_class_accuracy   0.547204     0.880905  187
max mean_per_class_accuracy  0.508786     0.882821  198
Gains/Lift Table: Avg response rate: 50.10 %, avg score: 50.21 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   0.968018           1.99601    1.99601            1                0.968695   1                           0.968695            0.0201356       0.0201356                  99.6013   99.6013
    2        0.0200759                   0.967294           1.99601    1.99601            1                0.967591   1                           0.968146            0.0199362       0.0400718                  99.6013   99.6013
    3        0.0300639                   0.966784           1.93613    1.97612            0.97             0.967045   0.990033                    0.96778             0.0193381       0.0594099                  93.6132   97.6119
    4        0.0400519                   0.966102           1.97605    1.9761             0.99             0.966461   0.990025                    0.967451            0.0197368       0.0791467                  97.6053   97.6102
    5        0.05004                     0.96544            1.99601    1.98008            1                0.965761   0.992016                    0.967114            0.0199362       0.0990829                  99.6013   98.0077
    6        0.10008                     0.96089            1.96414    1.97211            0.984032         0.963258   0.988024                    0.965186            0.0982855       0.197368                   96.414    97.2108
    7        0.15002                     0.955077           1.96008    1.96811            0.982            0.958032   0.986019                    0.962804            0.0978868       0.295255                   96.0085   96.8106
    8        0.20006                     0.946821           1.92032    1.95615            0.962076         0.951368   0.98003                     0.959944            0.0960925       0.391348                   92.0316   95.6152
    9        0.30004                     0.915067           1.89232    1.93488            0.948052         0.933172   0.969374                    0.951023            0.189195        0.580542                   89.2324   93.4883
    10       0.40002                     0.823588           1.69492    1.87491            0.849151         0.878823   0.939326                    0.932977            0.169458        0.75                       69.4916   87.4906
    11       0.5                         0.548479           1.3001     1.75997            0.651349         0.708889   0.881742                    0.888169            0.129984        0.879984                   30.01     75.9968
    12       0.59998                     0.196344           0.727817   1.58797            0.364635         0.357134   0.795572                    0.799678            0.0727671       0.952751                   -27.2183  58.7972
    13       0.69996                     0.0710272          0.307079   1.40501            0.153846         0.120808   0.70391                     0.70271             0.0307018       0.983453                   -69.2921  40.5013
    14       0.79994                     0.0354818          0.101695   1.24212            0.0509491        0.0495788  0.6223                      0.621079            0.0101675       0.99362                    -89.8305  24.2119
    15       0.89992                     0.025419           0.0458624  1.10922            0.022977         0.0296262  0.555716                    0.555369            0.00458533      0.998206                   -95.4138  10.9216
    16       1                           0.0202145          0.0179283  1                  0.00898204       0.0230985  0.500999                    0.5021              0.00179426      1                          -98.2072  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08232435455370805
RMSE: 0.2869222099345188
LogLoss: 0.27600209809702386
Mean Per-Class Error: 0.11042350475062479
AUC: 0.9549689366099656
pr_auc: 0.9388967333947329
Gini: 0.9099378732199312
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5088177789325863: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2769  359   0.1148   (359.0/3128.0)
1      325   2724  0.1066   (325.0/3049.0)
Total  3094  3083  0.1107   (684.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.508818     0.888454  197
max f2                       0.1408       0.920634  313
max f0point5                 0.809939     0.905828  100
max accuracy                 0.52664      0.88959   191
max precision                0.968913     1         0
max recall                   0.0212466    1         399
max specificity              0.968913     1         0
max absolute_mcc             0.52664      0.779147  191
max min_per_class_accuracy   0.525061     0.889386  192
max mean_per_class_accuracy  0.52664      0.889576  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.43 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.968193           2.02591     2.02591            1                0.968763   1                           0.968763            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.967381           2.02591     2.02591            1                0.967754   1                           0.968259            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.967014           2.02591     2.02591            1                0.967189   1                           0.967902            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.966458           1.99323     2.01774            0.983871         0.966747   0.995968                    0.967613            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.965618           2.02591     2.01935            1                0.966057   0.996764                    0.967306            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.960701           2.00624     2.0128             0.990291         0.963226   0.993528                    0.965266            0.100361        0.201378                   100.624   101.28
    7        0.150073                    0.955473           1.97346     1.99968            0.97411          0.95815    0.987055                    0.962894            0.0987209       0.300098                   97.3459   99.9685
    8        0.200097                    0.946951           1.96035     1.98985            0.967638         0.951573   0.982201                    0.960064            0.0980649       0.398163                   96.0347   98.985
    9        0.299984                    0.911671           1.93069     1.97015            0.952998         0.932048   0.972477                    0.950735            0.19285         0.591013                   93.0689   97.0151
    10       0.400032                    0.817782           1.76366     1.91851            0.87055          0.874095   0.946985                    0.931567            0.176451        0.767465                   76.3656   91.8507
    11       0.500081                    0.503411           1.26537     1.78784            0.624595         0.68311    0.882486                    0.88186             0.126599        0.894064                   26.5374   78.7838
    12       0.599968                    0.172354           0.646847    1.59788            0.319287         0.324413   0.788721                    0.789052            0.0646113       0.958675                   -35.3153  59.7878
    13       0.700016                    0.0667773          0.255697    1.40605            0.126214         0.108675   0.694033                    0.691811            0.0255822       0.984257                   -74.4303  40.6049
    14       0.799903                    0.0350227          0.105072    1.24359            0.0518639        0.0478802  0.613843                    0.611401            0.0104952       0.994752                   -89.4928  24.3591
    15       0.899951                    0.0250626          0.0491726   1.11081            0.0242718        0.0293445  0.5483                      0.546693            0.00491965      0.999672                   -95.0827  11.0807
    16       1                           0.0202145          0.00327817  1                  0.00161812       0.0229479  0.493605                    0.494293            0.000327976     1                          -99.6722  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:31:01  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:31:06  4:24:23.817  4862 obs/sec      1         1             25000      0.307451         0.310735            0.621894       0.94133         0.922266           1.97625          0.129944                         0.298207           0.29261               0.644231         0.948163          0.936706             2.02591            0.11899
    2019-08-03 20:31:12  4:24:29.313  4861 obs/sec      2         2             50000      0.297262         0.292301            0.646539       0.948511        0.937905           1.99601          0.119856                         0.287994           0.27682               0.668184         0.954362          0.942416             2.02591            0.113647
    2019-08-03 20:31:17  4:24:34.779  4893 obs/sec      3         3             75000      0.295581         0.290877            0.650527       0.949595        0.937675           1.99601          0.117159                         0.286922           0.276002              0.670649         0.954969          0.938897             2.02591            0.110733
    2019-08-03 20:31:22  4:24:40.210  4922 obs/sec      4         4             100000     0.295132         0.291666            0.651587       0.949336        0.934543           1.99601          0.117659                         0.286052           0.276491              0.672643         0.954729          0.941586             2.02591            0.108791
    2019-08-03 20:31:28  4:24:45.811  4902 obs/sec      5         5             125000     0.295188         0.293336            0.651456       0.948712        0.867655           1.97625          0.114862                         0.28629            0.277939              0.672098         0.954578          0.869414             2.02591            0.109276
    2019-08-03 20:31:33  4:24:51.208  4931 obs/sec      6         6             150000     0.297081         0.296711            0.646969       0.947287        0.925651           1.95649          0.117459                         0.287875           0.280181              0.668458         0.953234          0.937625             2.02591            0.113809
    2019-08-03 20:31:39  4:24:56.693  4939 obs/sec      7         7             175000     0.29768          0.297907            0.645545       0.947437        0.77262            1.99601          0.118857                         0.288437           0.281348              0.667163         0.953421          0.769537             2.02591            0.111381
    2019-08-03 20:31:44  4:25:02.041  4959 obs/sec      8         8             200000     0.29817          0.299575            0.644377       0.946141        0.739492           1.99601          0.117159                         0.289607           0.284049              0.664456         0.952042          0.739156             2.02591            0.116238
    2019-08-03 20:31:49  4:25:07.203  4996 obs/sec      9         9             225000     0.299328         0.302293            0.641609       0.945439        0.707602           1.99601          0.117759                         0.290689           0.286255              0.661943         0.951154          0.712024             2.02591            0.113324
    2019-08-03 20:31:54  4:25:12.163  5046 obs/sec      10        10            250000     0.299288         0.303513            0.641706       0.94514         0.657948           1.91696          0.11706                          0.29034            0.288086              0.662756         0.950962          0.675606             2.02591            0.112352
    2019-08-03 20:31:55  4:25:12.598  5045 obs/sec      10        10            250000     0.295581         0.290877            0.650527       0.949595        0.937675           1.99601          0.117159                         0.286922           0.276002              0.670649         0.954969          0.938897             2.02591            0.110733
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.006947024542098799
C438        0.8655964136123657     0.8655964136123657   0.006013319528917807
C374        0.7465670108795166     0.7465670108795166   0.005186419346901342
C88         0.6920433044433594     0.6920433044433594   0.004807641820163168
C322        0.6283594965934753     0.6283594965934753   0.004365228844095719
---         ---                    ---                  ---
C569        0.07246224582195282    0.07246224582195282  0.0005033970001007024
C404        0.07061401754617691    0.07061401754617691  0.0004905573129094862
C758        0.07053796947002411    0.07053796947002411  0.0004900290050580732
C839        0.06920421868562698    0.06920421868562698  0.0004807634056258229
C631        0.0683140978217125     0.0683140978217125   0.00047457971413877474

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_107

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 62,914 weights/biases, 886.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.014798995096999551  0.022617779672145844   0.0         0.0038851712344383435  0.09611907601356506  -0.013673106229630342  0.09228497743606567
    3        2        Softmax                 0.0   0.0   0.002008271819249785  0.0006150659173727036  0.0         0.07472960253653582    0.521848201751709    -0.014495266873438488  0.06762680411338806


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08696597900946823
RMSE: 0.29489994745585874
LogLoss: 0.29052235514422137
Mean Per-Class Error: 0.11797495948822945
AUC: 0.9501163379207377
pr_auc: 0.9437708877666742
Gini: 0.9002326758414754
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.413382515681976: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4191  783   0.1574   (783.0/4974.0)
1      426   4622  0.0844   (426.0/5048.0)
Total  4617  5405  0.1206   (1209.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.413383     0.884339  233
max f2                       0.157399     0.92003   315
max f0point5                 0.784564     0.900508  112
max accuracy                 0.538524     0.882059  196
max precision                0.964236     1         0
max recall                   0.0282834    1         398
max specificity              0.964236     1         0
max absolute_mcc             0.531901     0.764127  198
max min_per_class_accuracy   0.555742     0.880547  191
max mean_per_class_accuracy  0.538524     0.882025  196
Gains/Lift Table: Avg response rate: 50.37 %, avg score: 50.73 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   0.963065           1.98534    1.98534            1                0.96357    1                           0.96357             0.0200079       0.0200079                  98.5341   98.5341
    2        0.0200559                   0.962361           1.98534    1.98534            1                0.962726   1                           0.96315             0.0198098       0.0398177                  98.5341   98.5341
    3        0.0300339                   0.961668           1.96549    1.97874            0.99             0.962032   0.996678                    0.962779            0.0196117       0.0594295                  96.5487   97.8745
    4        0.040012                    0.960907           1.96549    1.97544            0.99             0.961256   0.995012                    0.962399            0.0196117       0.0790412                  96.5487   97.5439
    5        0.0500898                   0.960135           1.94603    1.96952            0.980198         0.960523   0.992032                    0.962021            0.0196117       0.0986529                  94.6027   96.9521
    6        0.10008                     0.956013           1.96156    1.96555            0.988024         0.958073   0.99003                     0.960049            0.0980586       0.196712                   96.1564   96.5547
    7        0.15007                     0.949804           1.93382    1.95498            0.974052         0.953092   0.984707                    0.957732            0.0966719       0.293384                   93.3825   95.498
    8        0.20006                     0.942167           1.9259     1.94771            0.97006          0.946025   0.981047                    0.954806            0.0962758       0.389659                   92.5899   94.7713
    9        0.30004                     0.912318           1.8942     1.92988            0.954092         0.930186   0.972065                    0.946602            0.189382        0.579041                   89.4197   92.9881
    10       0.40002                     0.826778           1.71191    1.8754             0.862275         0.87733    0.944625                    0.929289            0.171157        0.750198                   71.1911   87.5402
    11       0.5                         0.564551           1.27204    1.75475            0.640719         0.710823   0.883856                    0.885604            0.127179        0.877377                   27.2045   75.4754
    12       0.59998                     0.224456           0.752924   1.58781            0.379242         0.381811   0.799767                    0.801653            0.0752773       0.952655                   -24.7076  58.781
    13       0.69996                     0.0807888          0.2873     1.40205            0.144711         0.136033   0.706201                    0.706578            0.0287242       0.981379                   -71.27    40.205
    14       0.79994                     0.044601           0.122845   1.24217            0.0618762        0.0595459  0.62567                     0.625709            0.0122821       0.993661                   -87.7155  24.2169
    15       0.89992                     0.0326189          0.0435903  1.10901            0.0219561        0.0376462  0.558599                    0.560376            0.00435816      0.998019                   -95.641   10.9008
    16       1                           0.0267107          0.019794   1                  0.00997009       0.0297798  0.503692                    0.507274            0.00198098      1                          -98.0206  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08232973959120143
RMSE: 0.28693159392301404
LogLoss: 0.27778809899685014
Mean Per-Class Error: 0.11123516242380416
AUC: 0.9547022460930128
pr_auc: 0.9472985880557557
Gini: 0.9094044921860256
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.41934931573578516: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2675  453   0.1448   (453.0/3128.0)
1      250   2799  0.082    (250.0/3049.0)
Total  2925  3252  0.1138   (703.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.419349     0.88843   224
max f2                       0.180288     0.922966  301
max f0point5                 0.807437     0.903111  100
max accuracy                 0.559165     0.888781  184
max precision                0.962439     0.993506  2
max recall                   0.0292414    1         396
max specificity              0.964263     0.99968   0
max absolute_mcc             0.559165     0.777526  184
max min_per_class_accuracy   0.556732     0.88816   185
max mean_per_class_accuracy  0.559165     0.888765  184
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.04 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.963018           1.99323     1.99323            0.983871         0.963449   0.983871                    0.963449            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.962437           2.02591     2.00957            1                0.962731   0.991935                    0.96309             0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.961748           1.99323     2.00413            0.983871         0.962089   0.989247                    0.962756            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.960878           2.02591     2.00957            1                0.961251   0.991935                    0.96238             0.0203345       0.0806822                  102.591   100.957
    5        0.0500243                   0.960225           1.9927      2.00624            0.983607         0.960535   0.990291                    0.962016            0.0196786       0.100361                   99.2698   100.624
    6        0.100049                    0.955834           2.0128      2.00952            0.993528         0.958157   0.991909                    0.960087            0.100689        0.20105                    101.28    100.952
    7        0.150073                    0.949459           1.98657     2.00187            0.980583         0.95299    0.988134                    0.957721            0.0993768       0.300426                   98.6572   100.187
    8        0.200097                    0.941769           1.95379     1.98985            0.964401         0.945635   0.982201                    0.954699            0.097737        0.398163                   95.379    98.985
    9        0.299984                    0.90907            1.92741     1.96906            0.951378         0.928227   0.971937                    0.945885            0.192522        0.590685                   92.7406   96.9058
    10       0.400032                    0.820502           1.7276      1.90867            0.852751         0.872686   0.942129                    0.927578            0.172844        0.763529                   72.7597   90.8668
    11       0.500081                    0.526124           1.29816     1.78653            0.640777         0.69635    0.881839                    0.881317            0.129879        0.893408                   29.8156   78.6526
    12       0.599968                    0.199406           0.686248    1.60334            0.338736         0.347701   0.791419                    0.792477            0.0685471       0.961955                   -31.3752  60.3344
    13       0.700016                    0.0792922          0.226194    1.40652            0.11165          0.124263   0.694265                    0.696974            0.0226304       0.984585                   -77.3806  40.6518
    14       0.799903                    0.0440755          0.101788    1.24359            0.0502431        0.0582469  0.613843                    0.617214            0.0101673       0.994752                   -89.8212  24.3591
    15       0.899951                    0.0325092          0.0426162   1.11008            0.0210356        0.0372058  0.54794                     0.552734            0.00426369      0.999016                   -95.7384  11.0078
    16       1                           0.0267502          0.00983452  1                  0.00485437       0.029734   0.493605                    0.500408            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:08:00  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:08:05  2:01:23.152  4907 obs/sec      1         1             25000      0.303757         0.302934            0.630906       0.943769        0.926788           1.98534          0.126222                         0.296864           0.290347              0.647429         0.948685          0.934059             2.02591            0.117533
    2019-08-03 18:08:11  2:01:28.647  4870 obs/sec      2         2             50000      0.296773         0.291635            0.647684       0.949237        0.934275           1.98534          0.123129                         0.289289           0.279716              0.665193         0.95367           0.939951             2.02591            0.114133
    2019-08-03 18:08:16  2:01:34.307  4839 obs/sec      3         3             75000      0.2949           0.290522            0.652117       0.950116        0.943771           1.98534          0.120635                         0.286932           0.277788              0.670627         0.954702          0.947299             1.99323            0.113809
    2019-08-03 18:08:22  2:01:39.748  4874 obs/sec      4         4             100000     0.295967         0.292968            0.649594       0.948521        0.926878           1.96568          0.119537                         0.287829           0.278813              0.668563         0.953331          0.932256             2.02591            0.110086
    2019-08-03 18:08:28  2:01:45.373  4862 obs/sec      5         5             125000     0.296886         0.295582            0.647416       0.948246        0.904301           1.96568          0.117641                         0.288294           0.280444              0.667492         0.953706          0.912212             2.02591            0.112838
    2019-08-03 18:08:33  2:01:50.725  4898 obs/sec      6         6             150000     0.297993         0.298572            0.644781       0.94669         0.906955           1.90671          0.119737                         0.289679           0.283937              0.664289         0.951664          0.912667             2.02591            0.111867
    2019-08-03 18:08:38  2:01:55.974  4930 obs/sec      7         7             175000     0.298411         0.300575            0.643784       0.945838        0.909958           1.88706          0.11824                          0.289973           0.285583              0.663607         0.950896          0.908815             1.99323            0.113
    2019-08-03 18:08:43  2:02:01.260  4957 obs/sec      8         8             200000     0.299632         0.303152            0.640863       0.944442        0.912797           1.92637          0.119437                         0.290734           0.286962              0.661839         0.949782          0.923812             1.96056            0.111381
    2019-08-03 18:08:49  2:02:06.438  4990 obs/sec      9         9             225000     0.300165         0.304382            0.639584       0.944097        0.914689           1.90671          0.120834                         0.291294           0.288875              0.660535         0.949408          0.924915             1.92788            0.111381
    2019-08-03 18:08:53  2:02:11.314  5047 obs/sec      10        10            250000     0.301436         0.306959            0.636527       0.94367         0.929394           1.88706          0.120834                         0.292392           0.290551              0.657971         0.950124          0.939375             1.92788            0.114943
    2019-08-03 18:08:54  2:02:11.741  5045 obs/sec      10        10            250000     0.2949           0.290522            0.652117       0.950116        0.943771           1.98534          0.120635                         0.286932           0.277788              0.670627         0.954702          0.947299             1.99323            0.113809
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.007014899493006407
C438        0.8638466000556946     0.8638466000556946   0.006059797076766
C374        0.7536614537239075     0.7536614537239075   0.00528685934962631
C88         0.6883034706115723     0.6883034706115723   0.004828379667027669
C79         0.661028265953064      0.661028265953064    0.004637046847697053
---         ---                    ---                  ---
C908        0.06773877143859863    0.06773877143859863  0.00047518067342150244
C785        0.06737342476844788    0.06737342476844788  0.00047261780325029033
C974        0.06668214499950409    0.06668214499950409  0.00046776854514960094
C823        0.0645357221364975     0.0645357221364975   0.00045271160449611864
C832        0.0635078027844429     0.0635078027844429   0.00044550085355453937

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_86

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.01055838451741377    0.0221114382147789     0.0         0.002190466208909519  0.10914650559425354  -0.004437460152176269  0.09293478727340698
    3        2        Softmax                 0.0   0.0   0.0018677215412026271  0.0004890644922852516  0.0         0.047465783325606026  0.790313720703125    -0.006160892808757333  0.09535062313079834


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08293905266744847
RMSE: 0.287991410752905
LogLoss: 0.2808150321408437
Mean Per-Class Error: 0.11098164353978301
AUC: 0.9532285614972953
pr_auc: 0.8840041606011225
Gini: 0.9064571229945906
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4726372500462876: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4391  640   0.1272   (640.0/5031.0)
1      476   4519  0.0953   (476.0/4995.0)
Total  4867  5159  0.1113   (1116.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.472637     0.890093  209
max f2                       0.17816      0.92451   303
max f0point5                 0.792029     0.903172  107
max accuracy                 0.503239     0.888989  199
max precision                0.957745     0.99793   1
max recall                   0.0290441    1         399
max specificity              0.958374     0.999801  0
max absolute_mcc             0.503239     0.778105  199
max min_per_class_accuracy   0.54227      0.887487  188
max mean_per_class_accuracy  0.503239     0.889018  199
Gains/Lift Table: Avg response rate: 49.82 %, avg score: 49.98 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.95845            2.00721    2.00721            1                0.958452   1                           0.958452            0.0202202       0.0202202                  100.721   100.721
    2        0.0200479                   0.958408           1.98714    1.99722            0.99             0.958436   0.995025                    0.958444            0.0198198       0.04004                    98.7135   99.7221
    3        0.0300219                   0.95824            2.00721    2.00054            1                0.958348   0.996678                    0.958412            0.02002         0.0600601                  100.721   100.054
    4        0.0400958                   0.957816           2.00721    2.00221            1                0.958045   0.997512                    0.95832             0.0202202       0.0802803                  100.721   100.221
    5        0.0500698                   0.956984           2.00721    2.00321            1                0.957456   0.998008                    0.958148            0.02002         0.1003                     100.721   100.321
    6        0.10004                     0.953285           1.96714    1.98519            0.98004          0.95538    0.989033                    0.956766            0.0982983       0.198599                   96.7143   98.5194
    7        0.15001                     0.946318           1.94711    1.97251            0.97006          0.949851   0.982713                    0.954462            0.0972973       0.295896                   94.7111   97.2508
    8        0.20008                     0.937269           1.95923    1.96918            0.976096         0.941696   0.981057                    0.951267            0.0980981       0.393994                   95.9226   96.9184
    9        0.30002                     0.911815           1.91105    1.94982            0.952096         0.925345   0.97141                     0.942632            0.190991        0.584985                   91.1054   94.982
    10       0.40006                     0.831263           1.73905    1.89711            0.866401         0.882313   0.945151                    0.927549            0.173974        0.758959                   73.9046   89.7114
    11       0.5                         0.532522           1.30208    1.77818            0.648703         0.712709   0.885897                    0.884607            0.13013         0.889089                   30.2081   77.8178
    12       0.60004                     0.187148           0.722434   1.60216            0.35992          0.340986   0.798205                    0.793973            0.0722723       0.961361                   -27.7566  60.2162
    13       0.69998                     0.069603           0.20633    1.40287            0.102794         0.113984   0.698917                    0.696887            0.0206206       0.981982                   -79.367   40.2871
    14       0.80002                     0.0431122          0.102061   1.24021            0.0508475        0.0539488  0.617878                    0.61649             0.0102102       0.992192                   -89.7939  24.0209
    15       0.89996                     0.0313043          0.0620992  1.10938            0.0309381        0.0362796  0.552699                    0.552058            0.00620621      0.998398                   -93.7901  10.9381
    16       1                           0.0290053          0.0160096  1                  0.00797607       0.0295983  0.498205                    0.499791            0.0016016       1                          -98.399   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08318874575236958
RMSE: 0.2884245928355791
LogLoss: 0.2806709151069368
Mean Per-Class Error: 0.11183480978627847
AUC: 0.9536880147698419
pr_auc: 0.8906589094908078
Gini: 0.9073760295396838
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43592269783039894: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2689  439   0.1403   (439.0/3128.0)
1      274   2775  0.0899   (274.0/3049.0)
Total  2963  3214  0.1154   (713.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.435923     0.886157  217
max f2                       0.186164     0.922675  300
max f0point5                 0.79179      0.904939  109
max accuracy                 0.58625      0.888295  175
max precision                0.957377     0.996599  2
max recall                   0.029042     1         399
max specificity              0.958388     0.99968   0
max absolute_mcc             0.58625      0.776623  175
max min_per_class_accuracy   0.541702     0.88488   188
max mean_per_class_accuracy  0.58625      0.888165  175
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.69 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.958445           2.02591     2.02591            1                0.958451   1                           0.958451            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.958385           2.02591     2.02591            1                0.958422   1                           0.958436            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.958145           1.99323     2.01502            0.983871         0.958295   0.994624                    0.958389            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.957678           2.02591     2.01774            1                0.9579     0.995968                    0.958267            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.956876           2.02591     2.01935            1                0.957281   0.996764                    0.958072            0.0200066       0.101017                   102.591   101.935
    6        0.100049                    0.953375           1.98657     2.00296            0.980583         0.955254   0.988673                    0.956663            0.0993768       0.200394                   98.6572   100.296
    7        0.150073                    0.946296           1.98657     1.9975             0.980583         0.949919   0.985976                    0.954415            0.0993768       0.29977                    98.6572   99.7499
    8        0.200097                    0.937419           1.94723     1.98493            0.961165         0.941822   0.979773                    0.951267            0.097409        0.397179                   94.7234   98.4933
    9        0.299984                    0.910361           1.92741     1.96578            0.951378         0.924499   0.970318                    0.942354            0.192522        0.589702                   92.7406   96.5778
    10       0.400032                    0.825372           1.75054     1.91195            0.864078         0.877882   0.943747                    0.926229            0.175139        0.764841                   75.0544   91.1948
    11       0.500081                    0.514734           1.23915     1.77734            0.61165          0.702624   0.877307                    0.881494            0.123975        0.888816                   23.9149   77.7344
    12       0.599968                    0.181062           0.735501    1.60389            0.363047         0.329577   0.791689                    0.789607            0.0734667       0.962283                   -26.4499  60.3891
    13       0.700016                    0.0711196          0.209803    1.40464            0.10356          0.111943   0.69334                     0.692753            0.0209905       0.983273                   -79.0197  40.4644
    14       0.799903                    0.0428696          0.101788    1.24195            0.0502431        0.0543971  0.613034                    0.613039            0.0101673       0.99344                    -89.8212  24.1951
    15       0.899951                    0.0311684          0.0557289   1.11008            0.0275081        0.0361358  0.54794                     0.548904            0.0055756       0.999016                   -94.4271  11.0078
    16       1                           0.0290053          0.00983452  1                  0.00485437       0.029535   0.493605                    0.496942            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:42:47  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:42:50  1:36:07.251  9269 obs/sec      1         1             25000      0.296196         0.291187            0.649068       0.94801         0.931944           2.00721          0.118292                         0.295922           0.28898               0.649664         0.948849          0.934498             2.02591            0.119314
    2019-08-03 17:42:55  1:36:12.920  9253 obs/sec      3         3             75000      0.287991         0.280815            0.66824        0.953229        0.884004           2.00721          0.111311                         0.288425           0.280671              0.667191         0.953688          0.890659             2.02591            0.115428
    2019-08-03 17:43:01  1:36:18.676  9229 obs/sec      5         5             125000     0.289988         0.286225            0.663624       0.950159        0.799              2.00721          0.111909                         0.290606           0.286727              0.662138         0.950314          0.8027               2.02591            0.110571
    2019-08-03 17:43:06  1:36:24.024  9421 obs/sec      7         7             175000     0.292356         0.292554            0.658107       0.94733         0.693385           2.00721          0.110612                         0.292905           0.292414              0.656769         0.948143          0.706747             2.02591            0.114781
    2019-08-03 17:43:11  1:36:29.236  9598 obs/sec      9         9             225000     0.293926         0.295786            0.654425       0.945764        0.645371           1.99859          0.11171                          0.294035           0.295131              0.654117         0.946443          0.637198             2.02591            0.113
    2019-08-03 17:43:14  1:36:31.776  9742 obs/sec      10        10            250000     0.293719         0.295358            0.654912       0.945364        0.619693           1.99977          0.11151                          0.293833           0.294957              0.654592         0.946108          0.620171             2.02591            0.11219
    2019-08-03 17:43:14  1:36:32.088  9739 obs/sec      10        10            250000     0.287991         0.280815            0.66824        0.953229        0.884004           2.00721          0.111311                         0.288425           0.280671              0.667191         0.953688          0.890659             2.02591            0.115428
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ---------------------
C250        1.0                    1.0                   0.008085405761001387
C438        0.8404310941696167     0.8404310941696167    0.006795226410523719
C374        0.7423633337020874     0.7423633337020874    0.006002308775071053
C88         0.7132583856582642     0.7132583856582642    0.005766983460483878
C79         0.6515571475028992     0.6515571475028992    0.005268103914041572
---         ---                    ---                   ---
C792        0.04783647507429123    0.04783647507429123   0.0003867773111516736
C576        0.04768705368041992    0.04768705368041992   0.0003855691785528497
C947        0.04477702081203461    0.04477702081203461   0.0003620403820341037
C594        0.041102517396211624   0.041102517396211624  0.0003323305309469892
C670        0.039009906351566315   0.039009906351566315  0.0003154109215510789

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_92

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.008916486974332508  0.013647407293319702   0.0         0.0036938803362544354  0.11253827810287476  -0.021123597877247862   0.12006354331970215
    3        2        Softmax                 0.0   0.0   0.002264841466967482  0.0007306691259145737  0.0         0.05471958230191376    0.7611618041992188   -0.0023988379928623904  0.07461613416671753


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08872753313056762
RMSE: 0.2978716722526122
LogLoss: 0.297217439042961
Mean Per-Class Error: 0.1198099552765487
AUC: 0.9469996520859383
pr_auc: 0.8653393800279773
Gini: 0.8939993041718766
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4532583395502869: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4291  742   0.1474   (742.0/5033.0)
1      481   4512  0.0963   (481.0/4993.0)
Total  4772  5254  0.122    (1223.0/10026.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.453258     0.880648  218
max f2                       0.179873     0.92075   307
max f0point5                 0.804696     0.893417  99
max accuracy                 0.577139     0.880211  181
max precision                0.956579     0.992405  0
max recall                   0.0325167    1         399
max specificity              0.956579     0.999404  0
max absolute_mcc             0.577139     0.760446  181
max min_per_class_accuracy   0.556978     0.879231  187
max mean_per_class_accuracy  0.577139     0.88019   181
Gains/Lift Table: Avg response rate: 49.80 %, avg score: 50.07 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100738                   0.956619           2.00801    2.00801            1                0.956666   1                           0.956666            0.0202283       0.0202283                  100.801   100.801
    2        0.0200479                   0.956607           1.98793    1.99802            0.99             0.956615   0.995025                    0.956641            0.0198278       0.0400561                  98.7931   99.8021
    3        0.0300219                   0.956551           1.96785    1.988              0.98             0.956585   0.990033                    0.956622            0.0196275       0.0596836                  96.7851   98.7998
    4        0.0400958                   0.956347           2.00801    1.99303            1                0.95646    0.992537                    0.956581            0.0202283       0.0799119                  100.801   99.3026
    5        0.0500698                   0.955678           1.98793    1.99201            0.99             0.956092   0.992032                    0.956484            0.0198278       0.0997396                  98.7931   99.2011
    6        0.10004                     0.94977            1.95591    1.97398            0.974052         0.95295    0.983051                    0.954719            0.0977368       0.197476                   95.5907   97.3977
    7        0.15001                     0.943729           1.96392    1.97063            0.978044         0.946463   0.981383                    0.951969            0.0981374       0.295614                   96.3923   97.0628
    8        0.20008                     0.936614           1.93201    1.96096            0.962151         0.940712   0.97657                     0.949152            0.0967354       0.392349                   93.2011   96.0964
    9        0.30002                     0.908064           1.87976    1.93391            0.936128         0.925037   0.963098                    0.941119            0.187863        0.580212                   87.9755   93.3912
    10       0.40006                     0.819276           1.71772    1.87985            0.855434         0.871794   0.936176                    0.923783            0.171841        0.752053                   71.772    87.9851
    11       0.5                         0.547397           1.28857    1.76167            0.641717         0.703983   0.877319                    0.879849            0.12878         0.880833                   28.8574   76.1666
    12       0.60004                     0.196896           0.75876    1.59446            0.377866         0.356051   0.794049                    0.792521            0.0759063       0.956739                   -24.124   59.446
    13       0.69998                     0.0748042          0.246492   1.402              0.122754         0.121777   0.698205                    0.696755            0.0246345       0.981374                   -75.3508  40.2003
    14       0.80002                     0.0455634          0.104104   1.2397             0.0518445        0.0571091  0.617379                    0.616769            0.0104146       0.991789                   -89.5896  23.9705
    15       0.89996                     0.0351787          0.0521041  1.10782            0.0259481        0.040081   0.551701                    0.552728            0.00520729      0.996996                   -94.7896  10.7822
    16       1                           0.0317748          0.0300301  1                  0.0149551        0.0330392  0.498005                    0.500739            0.00300421      1                          -96.997   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0832999279130159
RMSE: 0.288617268909911
LogLoss: 0.28206120259058093
Mean Per-Class Error: 0.11288086362641225
AUC: 0.9529057155966612
pr_auc: 0.858607579817658
Gini: 0.9058114311933223
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4082239145357782: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2672  456   0.1458   (456.0/3128.0)
1      255   2794  0.0836   (255.0/3049.0)
Total  2927  3250  0.1151   (711.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.408224     0.887125  228
max f2                       0.161683     0.922123  313
max f0point5                 0.787484     0.903209  106
max accuracy                 0.607952     0.887324  168
max precision                0.956518     0.996429  0
max recall                   0.0328246    1         398
max specificity              0.956518     0.99968   0
max absolute_mcc             0.607952     0.774856  168
max min_per_class_accuracy   0.536365     0.88555   188
max mean_per_class_accuracy  0.607952     0.887119  168
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.60 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.956619           2.02591    2.02591            1                0.956664   1                           0.956664            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.956608           2.02591    2.02591            1                0.956615   1                           0.956639            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.956523           2.02591    2.02591            1                0.956575   1                           0.956618            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.956266           1.99323    2.01774            0.983871         0.956414   0.995968                    0.956567            0.0200066       0.0810102                  99.3234   101.774
    5        0.0500243                   0.955434           1.9927     2.0128             0.983607         0.955952   0.993528                    0.956446            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.950398           1.98002    1.99641            0.977346         0.953002   0.985437                    0.954724            0.0990489       0.199738                   98.0016   99.6407
    7        0.150073                    0.944431           1.98657    1.99313            0.980583         0.947223   0.983819                    0.952224            0.0993768       0.299114                   98.6572   99.3128
    8        0.200097                    0.937717           1.98657    1.99149            0.980583         0.94146    0.98301                     0.949533            0.0993768       0.398491                   98.6572   99.1489
    9        0.299984                    0.907596           1.90442    1.9625             0.940032         0.925115   0.968699                    0.941402            0.190226        0.588718                   90.4421   96.2498
    10       0.400032                    0.819253           1.74399    1.90785            0.860841         0.87253    0.941724                    0.924177            0.174483        0.763201                   74.3987   90.7848
    11       0.500081                    0.514975           1.27849    1.78194            0.631068         0.69017    0.879573                    0.877361            0.127911        0.891112                   27.8487   78.1935
    12       0.599968                    0.1815             0.702666   1.60225            0.34684          0.33065    0.79088                     0.78634             0.0701869       0.961299                   -29.7334  60.2251
    13       0.700016                    0.0722096          0.23275    1.40652            0.114887         0.114043   0.694265                    0.690254            0.0232863       0.984585                   -76.725   40.6518
    14       0.799903                    0.0451338          0.0853706  1.24154            0.0421394        0.0559238  0.612831                    0.611043            0.00852739      0.993112                   -91.4629  24.1541
    15       0.899951                    0.0348009          0.0458944  1.10862            0.0226537        0.0395387  0.547221                    0.547508            0.00459167      0.997704                   -95.4106  10.862
    16       1                           0.0318283          0.0229472  1                  0.0113269        0.0329339  0.493605                    0.496025            0.00229583      1                          -97.7053  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:48:23  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:48:25  1:41:43.183  9245 obs/sec      1         1             25000      0.305137         0.306294            0.62756        0.942572        0.927272           1.98813          0.127868                         0.295818           0.289428              0.649911         0.948946          0.937657             2.02591            0.118828
    2019-08-03 17:48:31  1:41:49.002  9106 obs/sec      3         3             75000      0.297872         0.297217            0.645084       0.947           0.865339           2.00801          0.121983                         0.288617           0.282061              0.666746         0.952906          0.858608             2.02591            0.115104
    2019-08-03 17:48:37  1:41:54.325  9416 obs/sec      5         5             125000     0.300963         0.30493             0.63768        0.943173        0.772318           2.00801          0.122083                         0.291019           0.288225              0.661177         0.949628          0.768044             2.02591            0.114295
    2019-08-03 17:48:42  1:41:59.740  9522 obs/sec      7         7             175000     0.302146         0.308371            0.634825       0.941383        0.710063           2.00801          0.121584                         0.292601           0.291351              0.657483         0.948054          0.684152             2.02591            0.116723
    2019-08-03 17:48:49  1:42:06.939  9885 obs/sec      10        10            250000     0.304316         0.312643            0.629562       0.939762        0.634323           1.9904           0.124077                         0.294633           0.296022              0.652709         0.946108          0.616994             2.02591            0.119475
    2019-08-03 17:48:50  1:42:07.243  9882 obs/sec      10        10            250000     0.297872         0.297217            0.645084       0.947           0.865339           2.00801          0.121983                         0.288617           0.282061              0.666746         0.952906          0.858608             2.02591            0.115104
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.00833027261878253
C438        0.8433632254600525     0.8433632254600525    0.007025445584737992
C374        0.6986046433448792     0.6986046433448792    0.005819567131810182
C88         0.6572514772415161     0.6572514772415161    0.005475083984519371
C322        0.624384880065918      0.624384880065918     0.00520129626999493
---         ---                    ---                   ---
C476        0.04753965511918068    0.04753965511918068   0.0003960182873456755
C634        0.04699614644050598    0.04699614644050598   0.000391490711881641
C547        0.04510389268398285    0.04510389268398285   0.000375727722225888
C768        0.044109899550676346   0.044109899550676346  0.000367447488444247
C827        0.04237138107419014    0.04237138107419014   0.00035296515558232643

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_110

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.011375157999191287   0.03105737268924713   0.0         -0.001378733271747078  0.11466559767723083  0.013968299812670518   0.11198872327804565
    3        2        Softmax                 0.0   0.0   0.0022794979940954363  0.000825089868158102  0.0         -0.16779864014824852   0.7416901588439941   -0.017122731098843408  0.09087982773780823


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08919842528062792
RMSE: 0.29866105417450717
LogLoss: 0.2972315656331047
Mean Per-Class Error: 0.12026301970228226
AUC: 0.9470761615667991
pr_auc: 0.8599398920730505
Gini: 0.8941523231335982
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48323452741881995: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4336  721   0.1426   (721.0/5057.0)
1      490   4475  0.0987   (490.0/4965.0)
Total  4826  5196  0.1208   (1211.0/10022.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.483235     0.880819  212
max f2                       0.178153     0.917752  310
max f0point5                 0.803901     0.890888  99
max accuracy                 0.566353     0.879765  184
max precision                0.958482     0.992883  1
max recall                   0.0291842    1         399
max specificity              0.959064     0.999407  0
max absolute_mcc             0.566353     0.759506  184
max min_per_class_accuracy   0.557614     0.878953  187
max mean_per_class_accuracy  0.566353     0.879737  184
Gains/Lift Table: Avg response rate: 49.54 %, avg score: 50.02 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100778                   0.959084           2.01853    2.01853            1                0.959216   1                           0.959216            0.0203424       0.0203424                  101.853   101.853
    2        0.0200559                   0.959078           1.99834    2.00849            0.99             0.959082   0.995025                    0.95915             0.0199396       0.040282                   99.8344   100.849
    3        0.0300339                   0.959032           2.01853    2.01182            1                0.95906    0.996678                    0.95912             0.020141        0.060423                   101.853   101.182
    4        0.040012                    0.958846           1.97816    2.00343            0.98             0.958949   0.992519                    0.959077            0.0197382       0.0801611                  97.8159   100.343
    5        0.0500898                   0.95846            1.99854    2.00245            0.990099         0.958624   0.992032                    0.958986            0.020141        0.100302                   99.8544   100.245
    6        0.10008                     0.953027           1.97018    1.98633            0.976048         0.955975   0.984048                    0.957482            0.0984894       0.198792                   97.0182   98.633
    7        0.15007                     0.947856           1.97421    1.98229            0.978044         0.950188   0.982048                    0.955052            0.0986908       0.297482                   97.4211   98.2293
    8        0.20006                     0.940573           1.95004    1.97423            0.966068         0.944867   0.978055                    0.952507            0.0974824       0.394965                   95.0037   97.4233
    9        0.30004                     0.905953           1.8614     1.93663            0.922156         0.925666   0.959428                    0.943563            0.186103        0.581067                   86.1399   93.6634
    10       0.40002                     0.80628            1.71434    1.88107            0.849301         0.865231   0.931903                    0.923985            0.1714          0.752467                   71.434    88.1074
    11       0.5                         0.541462           1.30338    1.76556            0.645709         0.692704   0.874676                    0.877738            0.130312        0.882779                   30.3382   76.5559
    12       0.60008                     0.210163           0.730535   1.59294            0.361914         0.367875   0.789159                    0.792704            0.0731118       0.955891                   -26.9465  59.294
    13       0.69996                     0.0755371          0.286345   1.4065             0.141858         0.127401   0.696793                    0.697769            0.0286002       0.984491                   -71.3655  40.6497
    14       0.79994                     0.039593           0.0866235  1.24153            0.0429142        0.0536403  0.615068                    0.617263            0.00866062      0.993152                   -91.3376  24.1533
    15       0.89992                     0.0310962          0.0423045  1.1083             0.0209581        0.0352112  0.549063                    0.552598            0.00422961      0.997382                   -95.7695  10.83
    16       1                           0.0282988          0.0261624  1                  0.0129611        0.0295011  0.49541                     0.500247            0.00261833      1                          -97.3838  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08400601105619263
RMSE: 0.2898379047954091
LogLoss: 0.282569832276929
Mean Per-Class Error: 0.11231020778268674
AUC: 0.9529423612957667
pr_auc: 0.8745856856660055
Gini: 0.9058847225915334
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5772031501209366: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2806  322   0.1029   (322.0/3128.0)
1      371   2678  0.1217   (371.0/3049.0)
Total  3177  3000  0.1122   (693.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.577203     0.885436  179
max f2                       0.203164     0.920962  299
max f0point5                 0.794264     0.902541  104
max accuracy                 0.577203     0.88781   179
max precision                0.959062     1         0
max recall                   0.0291912    1         399
max specificity              0.959062     1         0
max absolute_mcc             0.577203     0.775635  179
max min_per_class_accuracy   0.545369     0.88491   189
max mean_per_class_accuracy  0.577203     0.88769   179
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.67 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.959084           2.02591    2.02591            1                0.959195   1                           0.959195            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.959071           2.02591    2.02591            1                0.95908    1                           0.959137            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.95899            2.02591    2.02591            1                0.959048   1                           0.959107            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.958643           2.02591    2.02591            1                0.958843   1                           0.959041            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.958232           1.9927     2.01935            0.983607         0.95844    0.996764                    0.958923            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.953012           1.98002    1.99968            0.977346         0.955776   0.987055                    0.95735             0.0990489       0.200066                   98.0016   99.9685
    7        0.150073                    0.948181           2.00624    2.00187            0.990291         0.950295   0.988134                    0.954998            0.100361        0.300426                   100.624   100.187
    8        0.200097                    0.94149            1.94723    1.98821            0.961165         0.945311   0.981392                    0.952576            0.097409        0.397835                   94.7234   98.8211
    9        0.299984                    0.904485           1.90114    1.95922            0.938412         0.925421   0.96708                     0.943534            0.189898        0.587734                   90.1138   95.9218
    10       0.400032                    0.811292           1.76366    1.91031            0.87055          0.864624   0.942938                    0.923799            0.176451        0.764185                   76.3656   91.0308
    11       0.500081                    0.52565            1.25882    1.77997            0.621359         0.688126   0.878601                    0.876649            0.125943        0.890128                   25.8818   77.9968
    12       0.599968                    0.196475           0.699382   1.60006            0.345219         0.34101    0.7898                      0.787472            0.069859        0.959987                   -30.0618  60.0064
    13       0.700016                    0.075604           0.23275    1.40464            0.114887         0.12391    0.69334                     0.692634            0.0232863       0.983273                   -76.725   40.4644
    14       0.799903                    0.038913           0.105072   1.24236            0.0518639        0.0538264  0.613236                    0.612864            0.0104952       0.993768                   -89.4928  24.2361
    15       0.899951                    0.0307376          0.0491726  1.10971            0.0242718        0.034889   0.54776                     0.54861             0.00491965      0.998688                   -95.0827  10.9713
    16       1                           0.0285312          0.0131127  1                  0.00647249       0.0294395  0.493605                    0.496667            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 18:11:52  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 18:11:55  2:05:12.884  9455 obs/sec      1         1             25000      0.304402         0.304132            0.629325       0.943665        0.92896            1.99854          0.12742                          0.29717            0.292305              0.646703         0.94819           0.934318             2.02591            0.121256
    2019-08-03 18:12:01  2:05:18.787  9119 obs/sec      3         3             75000      0.298661         0.297232            0.643176       0.947076        0.85994            2.01853          0.120834                         0.289838           0.28257               0.663921         0.952942          0.874586             2.02591            0.11219
    2019-08-03 18:12:07  2:05:24.265  9323 obs/sec      5         5             125000     0.299684         0.302035            0.640727       0.944598        0.780299           1.99854          0.119836                         0.290283           0.286483              0.662887         0.951048          0.796258             2.02591            0.112028
    2019-08-03 18:12:12  2:05:29.503  9558 obs/sec      7         7             175000     0.301011         0.305952            0.63754        0.942962        0.712087           2.01853          0.121034                         0.292404           0.29116               0.657944         0.948861          0.715238             2.02591            0.113486
    2019-08-03 18:12:17  2:05:34.547  9789 obs/sec      9         9             225000     0.301914         0.308149            0.635361       0.941506        0.656963           2.00994          0.121333                         0.293749           0.293804              0.654789         0.947465          0.640671             2.02591            0.113162
    2019-08-03 18:12:19  2:05:37.129  9901 obs/sec      10        10            250000     0.303347         0.30989             0.631891       0.940626        0.614848           2.01198          0.121034                         0.29493            0.29479               0.652008         0.946666          0.624704             2.02591            0.115104
    2019-08-03 18:12:20  2:05:37.442  9898 obs/sec      10        10            250000     0.298661         0.297232            0.643176       0.947076        0.85994            2.01853          0.120834                         0.289838           0.28257               0.663921         0.952942          0.874586             2.02591            0.11219
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.00829995812165514
C438        0.872711181640625      0.872711181640625     0.007243466259917359
C374        0.7081345319747925     0.7081345319747925    0.00587748695988864
C88         0.7014459371566772     0.7014459371566772    0.005821971903005564
C79         0.6378323435783386     0.6378323435783386    0.005293981740337363
---         ---                    ---                   ---
C708        0.04566741734743118    0.04566741734743118   0.00037903765150782624
C938        0.045605745166540146   0.045605745166540146  0.0003785257749891595
C670        0.04419614002108574    0.04419614002108574   0.00036682611131381835
C540        0.0434814989566803     0.0434814989566803    0.0003608946204072381
C876        0.04221221059560776    0.04221221059560776   0.00035035958016603176

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_59

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.017474990325292903   0.048893749713897705   0.0         0.002093325148214251   0.11087921261787415  -0.0007309819752191269  0.11248388886451721
    3        2        Softmax                 0.0   0.0   0.0017733262975525577  0.0004122218815609813  0.0         -0.028416034241672605  0.623610258102417    -0.0017750965635069255  0.09945407509803772


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08911262905704619
RMSE: 0.29851738484893336
LogLoss: 0.2993821907552803
Mean Per-Class Error: 0.11903368745319631
AUC: 0.9462939108696491
pr_auc: 0.8694920353454058
Gini: 0.8925878217392982
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4142763945439394: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4269  730   0.146    (730.0/4999.0)
1      472   4558  0.0938   (472.0/5030.0)
Total  4741  5288  0.1199   (1202.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.414276     0.883505  227
max f2                       0.140241     0.916086  321
max f0point5                 0.737574     0.895879  127
max accuracy                 0.546453     0.880945  188
max precision                0.957603     0.99637   2
max recall                   0.0280866    1         399
max specificity              0.958873     0.9996    0
max absolute_mcc             0.546453     0.761977  188
max min_per_class_accuracy   0.519641     0.879722  197
max mean_per_class_accuracy  0.546453     0.880966  188
Gains/Lift Table: Avg response rate: 50.15 %, avg score: 49.47 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   0.958916           1.99384    1.99384            1                0.959011   1                           0.959011            0.0200795       0.0200795                  99.3837   99.3837
    2        0.0200419                   0.9589             1.99384    1.99384            1                0.958911   1                           0.958961            0.0198807       0.0399602                  99.3837   99.3837
    3        0.030013                    0.958814           1.95396    1.98059            0.98             0.958863   0.993355                    0.958929            0.0194831       0.0594433                  95.396    98.0589
    4        0.0400838                   0.958463           1.99384    1.98392            1                0.958665   0.995025                    0.958862            0.0200795       0.0795229                  99.3837   98.3917
    5        0.0500548                   0.957673           1.99384    1.98589            1                0.95811    0.996016                    0.958712            0.0198807       0.0994036                  99.3837   98.5893
    6        0.10001                     0.950627           1.96598    1.97595            0.986028         0.954419   0.991027                    0.956568            0.0982107       0.197614                   96.5979   97.5946
    7        0.150065                    0.94374            1.92234    1.95807            0.964143         0.947058   0.98206                     0.953396            0.0962227       0.293837                   92.2345   95.8067
    8        0.20002                     0.933446           1.91026    1.94613            0.958084         0.939276   0.976072                    0.94987             0.0954274       0.389264                   91.0263   94.6128
    9        0.30003                     0.904286           1.87655    1.92294            0.941176         0.920594   0.96444                     0.940111            0.187674        0.576938                   87.6552   92.2936
    10       0.40004                     0.817001           1.73343    1.87556            0.869392         0.869379   0.940678                    0.922428            0.17336         0.750298                   73.3426   87.5559
    11       0.50005                     0.522807           1.28019    1.75648            0.642074         0.690749   0.880957                    0.876092            0.128032        0.87833                    28.019    75.6485
    12       0.59996                     0.179315           0.726298   1.58493            0.364271         0.334656   0.794914                    0.785928            0.0725646       0.950895                   -27.3702  58.493
    13       0.69997                     0.0683902          0.274327   1.39767            0.137587         0.112152   0.700997                    0.68966             0.0274354       0.97833                    -72.5673  39.7674
    14       0.79998                     0.0431619          0.12126    1.2381             0.0608175        0.0535472  0.620965                    0.610136            0.0121272       0.990457                   -87.874   23.8102
    15       0.89999                     0.0317801          0.0616241  1.10737            0.0309073        0.0368018  0.555396                    0.546425            0.00616302      0.99662                    -93.8376  10.7368
    16       1                           0.0277288          0.0337938  1                  0.0169492        0.0288227  0.501546                    0.49466             0.00337972      1                          -96.6206  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08362400428804209
RMSE: 0.2891781531997915
LogLoss: 0.28291279981518164
Mean Per-Class Error: 0.11239964635589716
AUC: 0.9520911744993746
pr_auc: 0.8873530696750122
Gini: 0.9041823489987493
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4382720807303275: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2712  416   0.133    (416.0/3128.0)
1      283   2766  0.0928   (283.0/3049.0)
Total  2995  3182  0.1132   (699.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.438272     0.887819  224
max f2                       0.1481       0.920806  319
max f0point5                 0.778549     0.903601  119
max accuracy                 0.538835     0.887648  194
max precision                0.958914     1         0
max recall                   0.0281016    1         399
max specificity              0.958914     1         0
max absolute_mcc             0.538835     0.775254  194
max min_per_class_accuracy   0.520377     0.886829  199
max mean_per_class_accuracy  0.538835     0.8876    194
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.15 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.958916           2.02591    2.02591            1                0.958998   1                           0.958998            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.958891           2.02591    2.02591            1                0.958907   1                           0.958953            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.958778           2.02591    2.02591            1                0.958842   1                           0.958916            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.95842            2.02591    2.02591            1                0.958606   1                           0.958838            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.95763            1.9927     2.01935            0.983607         0.958088   0.996764                    0.95869             0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.951047           1.9669     1.99313            0.970874         0.954524   0.983819                    0.956607            0.0983929       0.19941                    96.6903   99.3128
    7        0.150073                    0.943984           1.96035    1.9822             0.967638         0.947279   0.978425                    0.953498            0.0980649       0.297475                   96.0347   98.2201
    8        0.200097                    0.934171           1.94723    1.97346            0.961165         0.939747   0.97411                     0.95006             0.097409        0.394884                   94.7234   97.3459
    9        0.299984                    0.90291            1.92084    1.95594            0.948136         0.920921   0.965461                    0.940357            0.191866        0.58675                    92.0839   95.5938
    10       0.400032                    0.814403           1.77021    1.90949            0.873786         0.867528   0.942533                    0.922143            0.177107        0.763857                   77.0213   90.9488
    11       0.500081                    0.500166           1.28177    1.7839             0.632686         0.684788   0.880544                    0.874656            0.128239        0.892096                   28.1765   78.3903
    12       0.599968                    0.171149           0.666547   1.59788            0.329011         0.317018   0.788721                    0.781817            0.0665792       0.958675                   -33.3453  59.7878
    13       0.700016                    0.0661813          0.262254   1.40699            0.12945          0.107199   0.694496                    0.685398            0.0262381       0.984913                   -73.7746  40.6986
    14       0.799903                    0.0426765          0.0853706  1.24195            0.0421394        0.052745   0.613034                    0.606397            0.00852739      0.99344                    -91.4629  24.1951
    15       0.899951                    0.0307694          0.0491726  1.10935            0.0242718        0.0360409  0.547581                    0.54299             0.00491965      0.99836                    -95.0827  10.9349
    16       1                           0.0277293          0.0163909  1                  0.00809061       0.0285523  0.493605                    0.491521            0.00163988      1                          -98.3609  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:12:44  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:12:47  1:06:04.215  9349 obs/sec      1         1             25000      0.306236         0.310791            0.624874       0.940968        0.922044           1.99384          0.130123                         0.296818           0.293413              0.647539         0.947319          0.924451             2.02591            0.117209
    2019-08-03 17:12:52  1:06:10.014  9130 obs/sec      3         3             75000      0.298517         0.299382            0.643546       0.946294        0.869492           1.99384          0.119852                         0.289178           0.282913              0.665449         0.952091          0.887353             2.02591            0.113162
    2019-08-03 17:12:58  1:06:15.437  9343 obs/sec      5         5             125000     0.300468         0.305753            0.638873       0.942466        0.786206           1.99384          0.119454                         0.291897           0.290663              0.659129         0.948479          0.782457             2.02591            0.111381
    2019-08-03 17:13:03  1:06:20.740  9548 obs/sec      7         7             175000     0.302708         0.310556            0.633467       0.940166        0.685564           1.99384          0.119454                         0.294471           0.29492               0.65309          0.946225          0.683571             2.02591            0.117047
    2019-08-03 17:13:10  1:06:27.812  9980 obs/sec      10        10            250000     0.305889         0.315855            0.625725       0.937853        0.629805           1.9819           0.122744                         0.298513           0.301286              0.643501         0.943842          0.613605             2.02591            0.11818
    2019-08-03 17:13:10  1:06:28.131  9976 obs/sec      10        10            250000     0.298517         0.299382            0.643546       0.946294        0.869492           1.99384          0.119852                         0.289178           0.282913              0.665449         0.952091          0.887353             2.02591            0.113162
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ----------------------
C250        1.0                    1.0                  0.007554363496578422
C438        0.874387264251709      0.874387264251709    0.006605439230936181
C374        0.7792771458625793     0.7792771458625793   0.005886942824422088
C88         0.6886063814163208     0.6886063814163208   0.0052019829112824115
C322        0.6705532073974609     0.6705532073974609   0.0050656026724769584
---         ---                    ---                  ---
C449        0.04879971221089363    0.04879971221089363  0.00036865076456950714
C363        0.04871203377842903    0.04871203377842903  0.00036798840981985934
C521        0.04841024428606033    0.04841024428606033  0.0003657085822950583
C802        0.04785313084721565    0.04785313084721565  0.00036149994486919676
C376        0.04719286412000656    0.04719286412000656  0.00035651205000716314

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_22

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.008164647041138203  0.013560090214014053   0.0         -0.007063641357240274  0.11246585845947266  0.0346413833165445      0.10415154695510864
    3        2        Softmax                 0.0   0.0   0.00205795463261893   0.0006656490731984377  0.0         -0.07151527842506766   0.6476447582244873   -0.0009212199741564925  0.04745122790336609


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08765462875573693
RMSE: 0.2960652440860577
LogLoss: 0.29351062077848944
Mean Per-Class Error: 0.11928474196200911
AUC: 0.9480864247781374
pr_auc: 0.8281809674506028
Gini: 0.8961728495562749
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.40161698009388186: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4234  793   0.1577   (793.0/5027.0)
1      418   4589  0.0835   (418.0/5007.0)
Total  4652  5382  0.1207   (1211.0/10034.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.401617     0.883434  233
max f2                       0.176547     0.922651  307
max f0point5                 0.746371     0.89397   123
max accuracy                 0.540158     0.880706  190
max precision                0.962389     0.994881  0
max recall                   0.031424     1         399
max specificity              0.962389     0.999403  0
max absolute_mcc             0.540158     0.761454  190
max min_per_class_accuracy   0.562953     0.879369  184
max mean_per_class_accuracy  0.540158     0.880715  190
Gains/Lift Table: Avg response rate: 49.90 %, avg score: 50.42 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100658                   0.962489           2.00399    2.00399            1                0.96249    1                           0.96249             0.0201718       0.0201718                  100.399   100.399
    2        0.0200319                   0.962484           2.00399    2.00399            1                0.962487   1                           0.962488            0.019972        0.0401438                  100.399   100.399
    3        0.029998                    0.962462           2.00399    2.00399            1                0.962475   1                           0.962484            0.019972        0.0601158                  100.399   100.399
    4        0.0400638                   0.962387           1.98415    1.99901            0.990099         0.962432   0.997512                    0.962471            0.019972        0.0800879                  98.4153   99.9009
    5        0.0500299                   0.962207           2.00399    2                  1                0.962315   0.998008                    0.96244             0.019972        0.10006                    100.399   100
    6        0.10006                     0.958421           1.96008    1.98004            0.978088         0.960498   0.988048                    0.961469            0.0980627       0.198123                   96.0082   98.0042
    7        0.14999                     0.9524             1.94399    1.96804            0.97006          0.95541    0.98206                     0.959452            0.0970641       0.295187                   94.3995   96.8042
    8        0.20002                     0.943447           1.90819    1.95307            0.952191         0.948155   0.974589                    0.956627            0.0954663       0.390653                   90.8186   95.3071
    9        0.29998                     0.911315           1.86613    1.9241             0.931206         0.93004    0.960133                    0.947767            0.186539        0.577192                   86.6132   92.4101
    10       0.40004                     0.822856           1.7006     1.8682             0.848606         0.874655   0.932237                    0.92948             0.170162        0.747354                   70.0601   86.8198
    11       0.5                         0.556236           1.33466    1.76153            0.666002         0.707296   0.879011                    0.885061            0.133413        0.880767                   33.4664   76.1534
    12       0.59996                     0.205469           0.775224   1.5972             0.386839         0.362056   0.79701                     0.797922            0.0774915       0.958258                   -22.4776  59.7204
    13       0.70002                     0.0771659          0.253493   1.40514            0.126494         0.127105   0.701167                    0.702037            0.0253645       0.983623                   -74.6507  40.5136
    14       0.79998                     0.0446626          0.101898   1.24229            0.0508475        0.0576942  0.619908                    0.621524            0.0101857       0.993809                   -89.8102  24.2292
    15       0.89994                     0.0333352          0.043956   1.10919            0.0219342        0.0379173  0.553488                    0.5567              0.00439385      0.998203                   -95.6044  10.9188
    16       1                           0.0313747          0.0179641  1                  0.00896414       0.0316668  0.499003                    0.504166            0.00179748      1                          -98.2036  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08404251769012126
RMSE: 0.28990087562841416
LogLoss: 0.28322385422893126
Mean Per-Class Error: 0.11224886948804647
AUC: 0.9522837872297235
pr_auc: 0.8500341503283481
Gini: 0.904567574459447
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4497001214145519: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2712  416   0.133    (416.0/3128.0)
1      279   2770  0.0915   (279.0/3049.0)
Total  2991  3186  0.1125   (695.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.4497       0.888532  211
max f2                       0.170853     0.922239  310
max f0point5                 0.779674     0.899695  109
max accuracy                 0.539438     0.887486  186
max precision                0.96244      0.993421  0
max recall                   0.0314057    1         399
max specificity              0.96244      0.999361  0
max absolute_mcc             0.4497       0.775826  211
max min_per_class_accuracy   0.547426     0.887176  183
max mean_per_class_accuracy  0.4497       0.887751  211
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.80 %

    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.962489           2.02591     2.02591            1                0.962489   1                           0.962489            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.962482           2.02591     2.02591            1                0.962487   1                           0.962488            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.962454           1.99323     2.01502            0.983871         0.962471   0.994624                    0.962482            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.962392           1.99323     2.00957            0.983871         0.962426   0.991935                    0.962468            0.0200066       0.0806822                  99.3234   100.957
    5        0.0500243                   0.962252           2.02591     2.0128             1                0.962327   0.993528                    0.96244             0.0200066       0.100689                   102.591   101.28
    6        0.100049                    0.958854           1.98657     1.99968            0.980583         0.960757   0.987055                    0.961599            0.0993768       0.200066                   98.6572   99.9685
    7        0.150073                    0.953342           1.98002     1.99313            0.977346         0.956202   0.983819                    0.9598              0.0990489       0.299114                   98.0016   99.3128
    8        0.200097                    0.944789           1.9669      1.98657            0.970874         0.949503   0.980583                    0.957225            0.0983929       0.397507                   96.6903   98.6572
    9        0.299984                    0.909111           1.91756     1.96359            0.946515         0.92993    0.969239                    0.948137            0.191538        0.589046                   91.7555   96.3591
    10       0.400032                    0.815478           1.70793     1.89965            0.843042         0.868984   0.937677                    0.928341            0.170876        0.759921                   70.7927   89.9649
    11       0.500081                    0.517569           1.3211      1.7839             0.652104         0.688533   0.880544                    0.880364            0.132174        0.892096                   32.1103   78.3903
    12       0.599968                    0.195068           0.686248    1.60116            0.338736         0.332542   0.79034                     0.789159            0.0685471       0.960643                   -31.3752  60.1158
    13       0.700016                    0.0731204          0.23275     1.40558            0.114887         0.119815   0.693802                    0.693494            0.0232863       0.983929                   -76.725   40.5581
    14       0.799903                    0.0438687          0.101788    1.24277            0.0502431        0.056349   0.613439                    0.613931            0.0101673       0.994096                   -89.8212  24.2771
    15       0.899951                    0.0329538          0.0491726   1.11008            0.0242718        0.037284   0.54794                     0.549825            0.00491965      0.999016                   -95.0827  11.0078
    16       1                           0.0313747          0.00983452  1                  0.00485437       0.0315976  0.493605                    0.497977            0.000983929     1                          -99.0165  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:32:46  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:32:49  26 min  6.323 sec  9637 obs/sec      1         1             25000      0.300154         0.296671            0.639628       0.946071        0.92957            2.00399          0.125772                         0.295022           0.286153              0.651791         0.950229          0.934361             2.02591            0.117695
    2019-08-03 16:32:54  26 min 12.096 sec  9259 obs/sec      3         3             75000      0.296065         0.293511            0.64938        0.948086        0.828181           2.00399          0.12069                          0.289901           0.283224              0.663775         0.952284          0.850034             2.02591            0.112514
    2019-08-03 16:33:00  26 min 17.644 sec  9346 obs/sec      5         5             125000     0.298277         0.299772            0.644121       0.945059        0.745926           2.00399          0.118696                         0.292129           0.288641              0.658587         0.949672          0.739471             2.02591            0.113647
    2019-08-03 16:33:05  26 min 23.006 sec  9496 obs/sec      7         7             175000     0.299432         0.303843            0.641361       0.942631        0.679205           2.00399          0.118995                         0.293307           0.292928              0.655829         0.94747           0.661232             2.02591            0.114781
    2019-08-03 16:33:10  26 min 28.049 sec  9712 obs/sec      9         9             225000     0.299235         0.303804            0.641832       0.941639        0.617438           1.99696          0.118796                         0.293905           0.293563              0.654424         0.946663          0.619438             2.02591            0.114457
    2019-08-03 16:33:13  26 min 30.662 sec  9812 obs/sec      10        10            250000     0.299598         0.305855            0.640962       0.941268        0.626748           1.9988           0.116803                         0.294098           0.295982              0.653969         0.946279          0.612781             2.01747            0.113324
    2019-08-03 16:33:13  26 min 30.969 sec  9808 obs/sec      10        10            250000     0.296065         0.293511            0.64938        0.948086        0.828181           2.00399          0.12069                          0.289901           0.283224              0.663775         0.952284          0.850034             2.02591            0.112514
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.008318005299729111
C438        0.8387309908866882     0.8387309908866882    0.006976568827242522
C374        0.7154072523117065     0.7154072523117065    0.005950761316193417
C88         0.6657952666282654     0.6657952666282654    0.005538088556348468
C79         0.6333056092262268     0.6333056092262268    0.005267839413891928
---         ---                    ---                   ---
C540        0.04678697884082794    0.04678697884082794   0.0003891743379563206
C269        0.04576002433896065    0.04576002433896065   0.0003806321249672078
C921        0.045244861394166946   0.045244861394166946  0.0003763469968621897
C743        0.04375080019235611    0.04375080019235611   0.00036391938786740755
C823        0.04252074286341667    0.04252074286341667   0.00035368776448631864

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_60

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  ------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.009578442297645649   0.013281024992465973   0.0         -0.0025674082709635985  0.1107068657875061  0.0005934285028621355  0.11649629473686218
    3        2        Softmax                 0.0   0.0   0.0017243862512259511  0.0003592900466173887  0.0         -0.08614042776753195    0.68851637840271    -0.001228162173284822  0.07722821831703186


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08850375568950444
RMSE: 0.29749580785198376
LogLoss: 0.29776169594202473
Mean Per-Class Error: 0.11896675026002779
AUC: 0.9466448965954765
pr_auc: 0.9258761674552738
Gini: 0.8932897931909529
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4081327127141912: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4191  763   0.154    (763.0/4954.0)
1      431   4644  0.0849   (431.0/5075.0)
Total  4622  5407  0.1191   (1194.0/10029.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.408133     0.88609   232
max f2                       0.198062     0.920045  304
max f0point5                 0.78885      0.895161  108
max accuracy                 0.440315     0.881344  222
max precision                0.955185     0.991786  2
max recall                   0.03268      1         398
max specificity              0.957022     0.999596  0
max absolute_mcc             0.440315     0.76342   222
max min_per_class_accuracy   0.560203     0.878424  187
max mean_per_class_accuracy  0.440315     0.881033  222
Gains/Lift Table: Avg response rate: 50.60 %, avg score: 50.61 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100708                   0.956218           1.93703    1.93703            0.980198         0.956957   0.980198                    0.956957            0.0195074       0.0195074                  93.7026   93.7026
    2        0.0200419                   0.95605            1.97616    1.95649            1                0.956069   0.99005                     0.956515            0.0197044       0.0392118                  97.6158   95.6494
    3        0.030013                    0.955988           1.97616    1.96303            1                0.95603    0.993355                    0.956354            0.0197044       0.0589163                  97.6158   96.3027
    4        0.0400838                   0.955589           1.93703    1.95649            0.980198         0.955835   0.99005                     0.956224            0.0195074       0.0784236                  93.7026   95.6494
    5        0.0500548                   0.954496           1.9564     1.95647            0.99             0.955057   0.99004                     0.955991            0.0195074       0.097931                   95.6396   95.6475
    6        0.10001                     0.947316           1.92882    1.94266            0.976048         0.951007   0.983051                    0.953502            0.0963547       0.194286                   92.8825   94.2663
    7        0.150065                    0.939979           1.9053     1.9302             0.964143         0.943509   0.976744                    0.950169            0.0953695       0.289655                   90.5299   93.02
    8        0.20002                     0.934557           1.93277    1.93084            0.978044         0.937104   0.977069                    0.946906            0.0965517       0.386207                   93.2769   93.0842
    9        0.30003                     0.908513           1.86582    1.90917            0.944167         0.923704   0.966102                    0.939172            0.186601        0.572808                   86.5824   90.9169
    10       0.40004                     0.828238           1.69047    1.85449            0.855434         0.876114   0.938435                    0.923407            0.169064        0.741872                   69.0472   85.4495
    11       0.50005                     0.570424           1.32992    1.74958            0.672981         0.721252   0.885344                    0.882976            0.133005        0.874877                   32.9917   74.9579
    12       0.59996                     0.215278           0.788885   1.5896             0.399202         0.373992   0.804388                    0.798216            0.0788177       0.953695                   -21.1115  58.9597
    13       0.69997                     0.0819422          0.267954   1.40076            0.135593         0.132234   0.708832                    0.703062            0.026798        0.980493                   -73.2046  40.0764
    14       0.79998                     0.0494637          0.100483   1.23821            0.0508475        0.0625141  0.626574                    0.622984            0.0100493       0.990542                   -89.9517  23.8208
    15       0.89999                     0.0370405          0.0669884  1.10806            0.0338983        0.0435329  0.560713                    0.558593            0.00669951      0.997241                   -93.3012  10.8058
    16       1                           0.0315068          0.0275835  1                  0.0139581        0.0335937  0.506033                    0.506088            0.00275862      1                          -97.2417  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.0837320999311671
RMSE: 0.2893649943085153
LogLoss: 0.2835469128041622
Mean Per-Class Error: 0.11291892482462496
AUC: 0.9525593377225688
pr_auc: 0.9340772053910986
Gini: 0.9051186754451377
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.519833040437522: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2755  373   0.1192   (373.0/3128.0)
1      325   2724  0.1066   (325.0/3049.0)
Total  3080  3097  0.113    (698.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.519833     0.88643   190
max f2                       0.199883     0.921874  291
max f0point5                 0.77925      0.903185  109
max accuracy                 0.598599     0.887     167
max precision                0.957007     1         0
max recall                   0.0326607    1         398
max specificity              0.957007     1         0
max absolute_mcc             0.598599     0.774137  167
max min_per_class_accuracy   0.543469     0.88491   184
max mean_per_class_accuracy  0.519833     0.887081  190
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.70 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.956251           1.99323    1.99323            0.983871         0.956845   0.983871                    0.956845            0.0200066       0.0200066                  99.3234   99.3234
    2        0.0200745                   0.956051           2.02591    2.00957            1                0.956083   0.991935                    0.956464            0.0203345       0.0403411                  102.591   100.957
    3        0.0301117                   0.955993           2.02591    2.01502            1                0.956032   0.994624                    0.95632             0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.955622           2.02591    2.01774            1                0.955829   0.995968                    0.956197            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.954412           1.9927     2.0128             0.983607         0.955127   0.993528                    0.955986            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.948038           1.96035    1.98657            0.967638         0.951467   0.980583                    0.953726            0.0980649       0.198754                   96.0347   98.6572
    7        0.150073                    0.940266           1.98002    1.98439            0.977346         0.944167   0.979504                    0.95054             0.0990489       0.297803                   98.0016   98.4387
    8        0.200097                    0.93408            1.97346    1.98165            0.97411          0.937115   0.978155                    0.947184            0.0987209       0.396523                   97.3459   98.1655
    9        0.299984                    0.905251           1.92412    1.9625             0.949757         0.921679   0.968699                    0.938691            0.192194        0.588718                   92.4122   96.2498
    10       0.400032                    0.817947           1.74399    1.90785            0.860841         0.871938   0.941724                    0.921996            0.174483        0.763201                   74.3987   90.7848
    11       0.500081                    0.527828           1.28832    1.7839             0.635922         0.694266   0.880544                    0.876436            0.128895        0.892096                   28.8321   78.3903
    12       0.599968                    0.181578           0.689532   1.6017             0.340357         0.333784   0.79061                     0.786091            0.068875        0.960971                   -31.0468  60.1704
    13       0.700016                    0.0773436          0.216359   1.40371            0.106796         0.117905   0.692877                    0.690592            0.0216464       0.982617                   -78.3641  40.3706
    14       0.799903                    0.0480372          0.105072   1.24154            0.0518639        0.059662   0.612831                    0.611806            0.0104952       0.993112                   -89.4928  24.1541
    15       0.899951                    0.0359678          0.0524507  1.10935            0.02589          0.0424252  0.547581                    0.548507            0.00524762      0.99836                    -94.7549  10.9349
    16       1                           0.0315088          0.0163909  1                  0.00809061       0.0332746  0.493605                    0.496959            0.00163988      1                          -98.3609  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:13:11  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:13:14  1:06:31.383  9641 obs/sec      1         1             25000      0.305687         0.310251            0.626168       0.941705        0.922156           1.97616          0.125835                         0.298863           0.295161              0.642664         0.947371          0.923049             2.02591            0.120932
    2019-08-03 17:13:19  1:06:36.960  9491 obs/sec      3         3             75000      0.297496         0.297762            0.645933       0.946645        0.925876           1.93703          0.119055                         0.289365           0.283547              0.665017         0.952559          0.934077             1.99323            0.113
    2019-08-03 17:13:25  1:06:42.504  9485 obs/sec      5         5             125000     0.301312         0.307198            0.636792       0.942384        0.8191             1.97616          0.121448                         0.293238           0.29274               0.65599          0.948512          0.810784             2.02591            0.114619
    2019-08-03 17:13:30  1:06:47.683  9691 obs/sec      7         7             175000     0.304137         0.313218            0.629949       0.938942        0.75436            1.95659          0.122644                         0.295093           0.296944              0.651623         0.945825          0.744363             2.02591            0.11559
    2019-08-03 17:13:37  1:06:54.897  10003 obs/sec     10        10            250000     0.307273         0.318114            0.622279       0.93714         0.61869            1.96054          0.12414                          0.298015           0.301355              0.64469          0.943968          0.617111             2.0134             0.114457
    2019-08-03 17:13:38  1:06:55.200  10000 obs/sec     10        10            250000     0.297496         0.297762            0.645933       0.946645        0.925876           1.93703          0.119055                         0.289365           0.283547              0.665017         0.952559          0.934077             1.99323            0.113
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.008196921444092512
C438        0.8173249363899231     0.8173249363899231    0.0066995482978861095
C374        0.676929235458374      0.676929235458374     0.005548735766261896
C88         0.6631602644920349     0.6631602644920349    0.005435872592884823
C79         0.6264899969100952     0.6264899969100952    0.005135289290181811
---         ---                    ---                   ---
C841        0.04614507406949997    0.04614507406949997   0.00037824754717952165
C323        0.04558175057172775    0.04558175057172775   0.00037363002872067136
C755        0.044881388545036316   0.044881388545036316  0.00036788921620545625
C921        0.04329485446214676    0.04329485446214676   0.00035488452095963516
C764        0.04220711439847946    0.04220711439847946   0.00034596840110616217

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_237

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.007969747884746947  0.01248953863978386    0.0         -0.007101924312830397  0.11263906955718994  0.008911077633300664    0.11107960343360901
    3        2        Softmax                 0.0   0.0   0.001924211985169677  0.0005670650862157345  0.0         -0.3746242562265252    0.6225650310516357   -0.0014107809625107381  0.06247527897357941


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08894586819708396
RMSE: 0.298237938896251
LogLoss: 0.2971177073093366
Mean Per-Class Error: 0.11902187200852432
AUC: 0.9472510436757402
pr_auc: 0.8798811112351773
Gini: 0.8945020873514804
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5204392354197734: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4368  655   0.1304   (655.0/5023.0)
1      538   4451  0.1078   (538.0/4989.0)
Total  4906  5106  0.1192   (1193.0/10012.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.520439     0.881823  194
max f2                       0.166841     0.919602  312
max f0point5                 0.802915     0.89433   102
max accuracy                 0.532716     0.880943  191
max precision                0.958198     0.984177  0
max recall                   0.0326516    1         399
max specificity              0.958198     0.999005  0
max absolute_mcc             0.525898     0.762078  193
max min_per_class_accuracy   0.563121     0.878957  180
max mean_per_class_accuracy  0.525898     0.880978  193
Gains/Lift Table: Avg response rate: 49.83 %, avg score: 50.35 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100879                   0.958264           1.98695    1.98695            0.990099         0.958267   0.990099                    0.958267            0.0200441       0.0200441                  98.6946   98.6946
    2        0.0200759                   0.958211           1.96668    1.97686            0.98             0.958249   0.985075                    0.958258            0.0196432       0.0396873                  96.6679   97.6863
    3        0.0300639                   0.957981           1.96668    1.97348            0.98             0.958122   0.983389                    0.958213            0.0196432       0.0593305                  96.6679   97.3479
    4        0.0400519                   0.957292           1.96668    1.97178            0.98             0.957702   0.982544                    0.958085            0.0196432       0.0789737                  96.6679   97.1783
    5        0.05004                     0.956436           1.96668    1.97076            0.98             0.956826   0.982036                    0.957834            0.0196432       0.098617                   96.6679   97.0764
    6        0.10008                     0.952761           1.95875    1.96476            0.976048         0.954542   0.979042                    0.956188            0.0980156       0.196633                   95.8748   96.4756
    7        0.15002                     0.948553           1.9426     1.95738            0.968            0.950634   0.975366                    0.954339            0.0970134       0.293646                   94.2597   95.7379
    8        0.20006                     0.943152           1.95474    1.95672            0.974052         0.94585    0.975037                    0.952216            0.0978152       0.391461                   95.4742   95.672
    9        0.30004                     0.910909           1.8765     1.92999            0.935065         0.929883   0.961718                    0.944774            0.187613        0.579074                   87.6502   92.999
    10       0.40002                     0.829497           1.72815    1.87954            0.861139         0.878004   0.936579                    0.928086            0.17278         0.751854                   72.8146   87.9541
    11       0.5                         0.559189           1.28709    1.76107            0.641359         0.715217   0.877547                    0.88552             0.128683        0.880537                   28.7088   76.1074
    12       0.59998                     0.198302           0.743785   1.59155            0.370629         0.358125   0.793075                    0.797636            0.0743636       0.954901                   -25.6215  59.1554
    13       0.69996                     0.0737336          0.282678   1.4046             0.140859         0.121392   0.699914                    0.701043            0.0282622       0.983163                   -71.7322  40.4599
    14       0.79994                     0.0437807          0.10425    1.24208            0.0519481        0.0558787  0.618929                    0.620408            0.0104229       0.993586                   -89.575   24.2075
    15       0.89992                     0.0357766          0.0380914  1.10831            0.018981         0.0392169  0.552275                    0.555838            0.00380838      0.997394                   -96.1909  10.8314
    16       1                           0.0325841          0.0260365  1                  0.0129741        0.0333654  0.498302                    0.503549            0.00260573      1                          -97.3963  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08417360824525585
RMSE: 0.2901268830102717
LogLoss: 0.2837299777554439
Mean Per-Class Error: 0.11378442388976628
AUC: 0.9523181786154363
pr_auc: 0.8807755120551438
Gini: 0.9046363572308727
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4772677132616385: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2714  414   0.1324   (414.0/3128.0)
1      296   2753  0.0971   (296.0/3049.0)
Total  3010  3167  0.1149   (710.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.477268     0.885779  210
max f2                       0.204118     0.921816  297
max f0point5                 0.804042     0.904847  103
max accuracy                 0.545534     0.886191  191
max precision                0.957524     0.988848  1
max recall                   0.0326513    1         399
max specificity              0.958166     0.999041  0
max absolute_mcc             0.545534     0.772382  191
max min_per_class_accuracy   0.552523     0.88523   189
max mean_per_class_accuracy  0.545534     0.886216  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.12 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.958263           2.02591    2.02591            1                0.958267   1                           0.958267            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.958195           1.99323    2.00957            0.983871         0.95824    0.991935                    0.958253            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.957965           1.99323    2.00413            0.983871         0.958106   0.989247                    0.958204            0.0200066       0.0603477                  99.3234   100.413
    4        0.0401489                   0.95742            1.99323    2.0014             0.983871         0.95771    0.987903                    0.958081            0.0200066       0.0803542                  99.3234   100.14
    5        0.0500243                   0.956587           1.9927     1.99968            0.983607         0.956997   0.987055                    0.957867            0.0196786       0.100033                   99.2698   99.9685
    6        0.100049                    0.952984           1.97346    1.98657            0.97411          0.954707   0.980583                    0.956287            0.0987209       0.198754                   97.3459   98.6572
    7        0.150073                    0.948864           1.98002    1.98439            0.977346         0.950991   0.979504                    0.954521            0.0990489       0.297803                   98.0016   98.4387
    8        0.200097                    0.943058           1.96035    1.97838            0.967638         0.945941   0.976537                    0.952376            0.0980649       0.395867                   96.0347   97.8377
    9        0.299984                    0.911809           1.91756    1.95812            0.946515         0.930705   0.966541                    0.94516             0.191538        0.587406                   91.7555   95.8125
    10       0.400032                    0.832939           1.76366    1.90949            0.87055          0.880475   0.942533                    0.928982            0.176451        0.763857                   76.3656   90.9488
    11       0.500081                    0.535499           1.27193    1.78194            0.627832         0.71166    0.879573                    0.885504            0.127255        0.891112                   27.1931   78.1935
    12       0.599968                    0.18869            0.692815   1.60061            0.341977         0.339961   0.79007                     0.794678            0.069203        0.960315                   -30.7185  60.0611
    13       0.700016                    0.0735973          0.226194   1.40417            0.11165          0.116841   0.693108                    0.6978              0.0226304       0.982945                   -77.3806  40.4175
    14       0.799903                    0.0434714          0.111638   1.24277            0.0551053        0.0554513  0.613439                    0.617587            0.0111512       0.994096                   -88.8362  24.2771
    15       0.899951                    0.0352467          0.0426162  1.10935            0.0210356        0.0387324  0.547581                    0.553235            0.00426369      0.99836                    -95.7384  10.9349
    16       1                           0.0325841          0.0163909  1                  0.00809061       0.0332209  0.493605                    0.501209            0.00163988      1                          -98.3609  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:57:46  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:57:49  4:51:06.581  9204 obs/sec      1         1             25000      0.303142         0.301686            0.632415       0.944153        0.929076           2.00681          0.128246                         0.292524           0.284639              0.657662         0.950525          0.938742             2.02591            0.115428
    2019-08-03 20:57:55  4:51:12.410  9101 obs/sec      3         3             75000      0.298238         0.297118            0.644212       0.947251        0.879881           1.98695          0.119157                         0.290127           0.28373               0.66325          0.952318          0.880776             2.02591            0.114943
    2019-08-03 20:58:01  4:51:18.209  9092 obs/sec      5         5             125000     0.301314         0.303842            0.636835       0.944661        0.792604           2.00681          0.120855                         0.293078           0.290359              0.656365         0.949434          0.780413             2.02591            0.11559
    2019-08-03 20:58:06  4:51:24.066  9293 obs/sec      7         7             175000     0.302268         0.308175            0.634532       0.942245        0.715698           2.00681          0.119656                         0.293948           0.29448               0.654322         0.947134          0.706264             2.02591            0.115752
    2019-08-03 20:58:14  4:51:32.170  9401 obs/sec      10        10            250000     0.305002         0.312267            0.62789        0.93942         0.646259           1.98375          0.122253                         0.296995           0.298859              0.647118         0.944159          0.632884             2.0009             0.117695
    2019-08-03 20:58:15  4:51:32.515  9399 obs/sec      10        10            250000     0.298238         0.297118            0.644212       0.947251        0.879881           1.98695          0.119157                         0.290127           0.28373               0.66325          0.952318          0.880776             2.02591            0.114943
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.008386631574167117
C438        0.8076843023300171     0.8076843023300171    0.0067737506718800605
C374        0.7255557179450989     0.7255557179450989    0.006084968492935857
C88         0.6784511208534241     0.6784511208534241    0.005689919591678396
C79         0.6213042140007019     0.6213042140007019    0.00521064953830137
---         ---                    ---                   ---
C577        0.04488872364163399    0.04488872364163399   0.0003764651870169895
C924        0.04468235746026039    0.04468235746026039   0.0003747344698844414
C829        0.04285955801606178    0.04285955801606178   0.00035944732251235107
C674        0.042849499732255936   0.042849499732255936  0.00035936296739180306
C591        0.03955172002315521    0.03955172002315521   0.0003317057039588113

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_79

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.007715681578015299   0.012609880417585373   0.0         0.0007975876957665371  0.11199381947517395  -0.024403908696907423  0.10644635558128357
    3        2        Softmax                 0.0   0.0   0.0019505923246470047  0.0005887667648494244  0.0         -0.2030239479499869    0.7377316951751709   0.0031811507908320324  0.0792134702205658


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08800013888429382
RMSE: 0.29664817357316364
LogLoss: 0.2973662230587327
Mean Per-Class Error: 0.11705399845618436
AUC: 0.9464661525866233
pr_auc: 0.9153318456676653
Gini: 0.8929323051732465
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44561834461114963: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4300  721   0.1436   (721.0/5021.0)
1      456   4550  0.0911   (456.0/5006.0)
Total  4756  5271  0.1174   (1177.0/10027.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.445618     0.885472  223
max f2                       0.168116     0.918682  313
max f0point5                 0.764396     0.897338  118
max accuracy                 0.48939      0.882916  211
max precision                0.955255     0.992647  0
max recall                   0.0329531    1         399
max specificity              0.955255     0.999801  0
max absolute_mcc             0.462456     0.766491  219
max min_per_class_accuracy   0.56014      0.880543  189
max mean_per_class_accuracy  0.475074     0.882946  215
Gains/Lift Table: Avg response rate: 49.93 %, avg score: 50.16 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100728                   0.955115           1.98316    1.98316            0.990099         0.955354   0.990099                    0.955354            0.019976        0.019976                   98.3165   98.3165
    2        0.0200459                   0.954579           1.98297    1.98307            0.99             0.954805   0.99005                     0.955081            0.0197763       0.0397523                  98.2966   98.3066
    3        0.0300189                   0.954568           1.96294    1.97638            0.98             0.954571   0.986711                    0.954912            0.0195765       0.0593288                  96.2936   97.6379
    4        0.0400918                   0.9545             2.003      1.98307            1                0.954546   0.99005                     0.95482             0.0201758       0.0795046                  100.3     98.3066
    5        0.0500648                   0.954237           1.96294    1.97906            0.98             0.954385   0.988048                    0.954733            0.0195765       0.0990811                  96.2936   97.9056
    6        0.10003                     0.947838           1.95902    1.96905            0.978044         0.951165   0.983051                    0.952951            0.0978825       0.196964                   95.9018   96.9047
    7        0.149995                    0.93827            1.95902    1.96571            0.978044         0.943144   0.981383                    0.949684            0.0978825       0.294846                   95.9018   96.5707
    8        0.20006                     0.929047           1.90325    1.95008            0.950199         0.933379   0.973579                    0.945604            0.0952857       0.390132                   90.3246   95.0076
    9        0.29999                     0.895147           1.85507    1.91843            0.926148         0.914603   0.957779                    0.935277            0.185378        0.575509                   85.5071   91.8428
    10       0.40002                     0.812112           1.77534    1.88265            0.886341         0.862066   0.939915                    0.91697             0.177587        0.753096                   77.5338   88.2647
    11       0.50005                     0.555079           1.27609    1.76131            0.637089         0.706358   0.879338                    0.874839            0.127647        0.880743                   27.6086   76.1311
    12       0.59998                     0.211273           0.729634   1.58948            0.364271         0.363834   0.793551                    0.789728            0.0729125       0.953656                   -27.0366  58.9479
    13       0.70001                     0.0851605          0.271593   1.40116            0.135593         0.134011   0.69953                     0.696027            0.0271674       0.980823                   -72.8407  40.1156
    14       0.79994                     0.0519677          0.103948   1.23911            0.0518962        0.0656486  0.618626                    0.617279            0.0103875       0.991211                   -89.6052  23.9106
    15       0.89997                     0.0370705          0.0579132  1.10782            0.0289133        0.0435929  0.553081                    0.553515            0.00579305      0.997004                   -94.2087  10.7819
    16       1                           0.0328018          0.0299551  1                  0.0149551        0.0340466  0.499252                    0.501553            0.0029964       1                          -97.0045  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08396519572168745
RMSE: 0.28976748561853427
LogLoss: 0.28420647422115397
Mean Per-Class Error: 0.1125238957219632
AUC: 0.9526990003011344
pr_auc: 0.920962594144411
Gini: 0.9053980006022688
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47789457498377697: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2720  408   0.1304   (408.0/3128.0)
1      299   2750  0.0981   (299.0/3049.0)
Total  3019  3158  0.1145   (707.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.477895     0.886096  206
max f2                       0.180367     0.922248  306
max f0point5                 0.807869     0.902388  98
max accuracy                 0.609686     0.887648  167
max precision                0.955267     1         0
max recall                   0.0329085    1         399
max specificity              0.955267     1         0
max absolute_mcc             0.609686     0.775445  167
max min_per_class_accuracy   0.546707     0.883896  185
max mean_per_class_accuracy  0.60534      0.887476  168
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.75 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.955131           2.02591    2.02591            1                0.95538    1                           0.95538             0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.954591           2.02591    2.02591            1                0.954831   1                           0.955106            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.954569           2.02591    2.02591            1                0.954573   1                           0.954928            0.0203345       0.0610036                  102.591   102.591
    4        0.0401489                   0.954513           2.02591    2.02591            1                0.95455    1                           0.954834            0.0203345       0.0813381                  102.591   102.591
    5        0.0500243                   0.954228           1.9927     2.01935            0.983607         0.954385   0.996764                    0.954745            0.0196786       0.101017                   99.2698   101.935
    6        0.100049                    0.948653           1.96035    1.98985            0.967638         0.951752   0.982201                    0.953249            0.0980649       0.199082                   96.0347   98.985
    7        0.150073                    0.9394             1.99313    1.99094            0.983819         0.944391   0.98274                     0.950296            0.0997048       0.298786                   99.3128   99.0943
    8        0.200097                    0.929632           1.95379    1.98165            0.964401         0.934221   0.978155                    0.946277            0.097737        0.396523                   95.379    98.1655
    9        0.299984                    0.894483           1.90442    1.95594            0.940032         0.914233   0.965461                    0.935608            0.190226        0.58675                    90.4421   95.5938
    10       0.400032                    0.81319            1.78005    1.91195            0.878641         0.862174   0.943747                    0.917242            0.178091        0.764841                   78.0047   91.1948
    11       0.500081                    0.526108           1.23915    1.77734            0.61165          0.694108   0.877307                    0.872601            0.123975        0.888816                   23.9149   77.7344
    12       0.599968                    0.196666           0.7158     1.60061            0.353323         0.344291   0.79007                     0.784644            0.0714989       0.960315                   -28.42    60.0611
    13       0.700016                    0.0826859          0.249141   1.40745            0.122977         0.126891   0.694727                    0.690636            0.0249262       0.985241                   -75.0859  40.7455
    14       0.799903                    0.0512423          0.0820871  1.24195            0.0405186        0.0645332  0.613034                    0.612452            0.00819941      0.99344                    -91.7913  24.1951
    15       0.899951                    0.0360382          0.0524507  1.10971            0.02589          0.0426145  0.54776                     0.549103            0.00524762      0.998688                   -94.7549  10.9713
    16       1                           0.0328018          0.0131127  1                  0.00647249       0.033812   0.493605                    0.497549            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 17:35:06  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 17:35:08  1:28:26.075  9611 obs/sec      1         1             25000      0.303994         0.306064            0.630349       0.942444        0.928316           1.98316          0.128254                         0.298473           0.293561              0.643596         0.947397          0.931329             2.02591            0.119637
    2019-08-03 17:35:14  1:28:31.673  9468 obs/sec      3         3             75000      0.296648         0.297366            0.647999       0.946466        0.915332           1.98316          0.117383                         0.289767           0.284206              0.664084         0.952699          0.920963             2.02591            0.114457
    2019-08-03 17:35:20  1:28:37.176  9503 obs/sec      5         5             125000     0.298734         0.302012            0.643032       0.943133        0.904963           1.98316          0.118779                         0.291486           0.287544              0.660088         0.949939          0.91168              2.02591            0.114133
    2019-08-03 17:35:27  1:28:44.494  9903 obs/sec      8         8             200000     0.301079         0.307603            0.637406       0.940999        0.678758           2.003            0.11838                          0.293984           0.293674              0.654238         0.947447          0.673884             2.02591            0.114619
    2019-08-03 17:35:31  1:28:49.152  10169 obs/sec     10        10            250000     0.302375         0.311325            0.634276       0.939479        0.647827           1.97847          0.118879                         0.295176           0.297796              0.651428         0.945991          0.632495             2.02591            0.117209
    2019-08-03 17:35:32  1:28:49.431  10166 obs/sec     10        10            250000     0.296648         0.297366            0.647999       0.946466        0.915332           1.98316          0.117383                         0.289767           0.284206              0.664084         0.952699          0.920963             2.02591            0.114457
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.008011935697378202
C438        0.8032163977622986     0.8032163977622986    0.006435318129951288
C374        0.7433650493621826     0.7433650493621826    0.005955792975168179
C88         0.7025892734527588     0.7025892734527588    0.005629100080571173
C322        0.6471562385559082     0.6471562385559082    0.005184974169467084
---         ---                    ---                   ---
C599        0.04776989296078682    0.04776989296078682   0.00038272931067246356
C785        0.04663345217704773    0.04663345217704773   0.0003736242201892679
C671        0.046591613441705704   0.046591613441705704  0.000373289010932048
C968        0.044530436396598816   0.044530436396598816  0.00035677499298573956
C522        0.04265960678458214    0.04265960678458214   0.00034178602643351094

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_226

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ----------------------  -------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.008393222456591187   0.013140447437763214   0.0         0.005294343912422007  0.11694088578224182  -0.005874136786075828   0.10216715931892395
    3        2        Softmax                 0.0   0.0   0.0027763183279603254  0.0005911947228014469  0.0         -0.07939055886527058  0.724217414855957    -9.453895468405221e-05  0.05886119604110718


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.09193852582079058
RMSE: 0.30321366364461644
LogLoss: 0.3069257799049416
Mean Per-Class Error: 0.1227175561782281
AUC: 0.9430216832562194
pr_auc: 0.8091987656362394
Gini: 0.8860433665124388
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4724717133015662: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4315  708   0.141    (708.0/5023.0)
1      529   4459  0.1061   (529.0/4988.0)
Total  4844  5167  0.1236   (1237.0/10011.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.472472     0.878188  213
max f2                       0.137572     0.915614  326
max f0point5                 0.745598     0.889586  123
max accuracy                 0.593102     0.877335  175
max precision                0.961364     0.989362  0
max recall                   0.0306233    1         399
max specificity              0.961364     0.998606  0
max absolute_mcc             0.593102     0.754963  175
max min_per_class_accuracy   0.536548     0.876103  193
max mean_per_class_accuracy  0.593102     0.877282  175
Gains/Lift Table: Avg response rate: 49.83 %, avg score: 49.95 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100889                   0.961467           2.00702    2.00702            1                0.961467   1                           0.961467            0.0202486       0.0202486                  100.702   100.702
    2        0.0200779                   0.961464           1.98695    1.99703            0.99             0.961466   0.995025                    0.961466            0.0198476       0.0400962                  98.6947   99.7032
    3        0.0300669                   0.961452           2.00702    2.00035            1                0.961459   0.996678                    0.961464            0.0200481       0.0601443                  100.702   100.035
    4        0.0400559                   0.961404           1.98695    1.99701            0.99             0.96143    0.995012                    0.961456            0.0198476       0.079992                   98.6947   99.7007
    5        0.050045                    0.9613             1.94681    1.98699            0.97             0.961362   0.99002                     0.961437            0.0194467       0.0994387                  94.6806   98.6987
    6        0.10009                     0.958651           1.97096    1.97897            0.982036         0.960389   0.986028                    0.960913            0.0986367       0.198075                   97.0963   97.8975
    7        0.150035                    0.953537           1.93476    1.96426            0.964            0.956137   0.978695                    0.959323            0.0966319       0.294707                   93.4764   96.4257
    8        0.20008                     0.945975           1.91087    1.9509             0.952096         0.949919   0.972042                    0.956971            0.0956295       0.390337                   91.0872   95.0905
    9        0.30007                     0.909275           1.83459    1.91214            0.914086         0.930934   0.95273                     0.948295            0.18344         0.573777                   83.4586   91.2145
    10       0.40016                     0.814947           1.72459    1.86523            0.859281         0.869704   0.929356                    0.928637            0.172614        0.746391                   72.4592   86.5233
    11       0.50005                     0.531989           1.30657    1.75363            0.651            0.696716   0.873751                    0.882308            0.130513        0.876905                   30.6568   75.3634
    12       0.60004                     0.19166            0.735839   1.58403            0.366633         0.348403   0.789246                    0.793339            0.0735766       0.950481                   -26.4161  58.403
    13       0.70003                     0.0691796          0.294737   1.39987            0.146853         0.117135   0.697489                    0.696752            0.0294707       0.979952                   -70.5263  39.9871
    14       0.80002                     0.0404391          0.126316   1.2407             0.0629371        0.0515131  0.61818                     0.616107            0.0126303       0.992582                   -87.3684  24.0697
    15       0.90001                     0.0313009          0.0541353  1.10887            0.026973         0.0349318  0.552497                    0.55154             0.00541299      0.997995                   -94.5865  10.8871
    16       1                           0.0305976          0.0200501  1                  0.00999001       0.0307048  0.498252                    0.499461            0.00200481      1                          -97.995   0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08448718633708399
RMSE: 0.29066679606911416
LogLoss: 0.2842506302641777
Mean Per-Class Error: 0.11351443054156363
AUC: 0.9518054533833155
pr_auc: 0.8195175917415367
Gini: 0.9036109067666309
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.491284238256144: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2733  395   0.1263   (395.0/3128.0)
1      313   2736  0.1027   (313.0/3049.0)
Total  3046  3131  0.1146   (708.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.491284     0.885437  208
max f2                       0.178362     0.921879  309
max f0point5                 0.741291     0.899702  127
max accuracy                 0.600986     0.886514  175
max precision                0.961391     0.994962  0
max recall                   0.0306231    1         399
max specificity              0.961391     0.999361  0
max absolute_mcc             0.600986     0.773171  175
max min_per_class_accuracy   0.543781     0.886189  193
max mean_per_class_accuracy  0.550027     0.886486  191
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 49.62 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.961467           2.02591    2.02591            1                0.961467   1                           0.961467            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.961464           1.99323    2.00957            0.983871         0.961466   0.991935                    0.961466            0.0200066       0.0403411                  99.3234   100.957
    3        0.0301117                   0.961452           2.02591    2.01502            1                0.961458   0.994624                    0.961464            0.0203345       0.0606756                  102.591   101.502
    4        0.0401489                   0.961421           2.02591    2.01774            1                0.961439   0.995968                    0.961457            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.961322           1.9927     2.0128             0.983607         0.961379   0.993528                    0.961442            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.958976           2.00624    2.00952            0.990291         0.960495   0.991909                    0.960969            0.100361        0.20105                    100.624   100.952
    7        0.150073                    0.954172           1.96035    1.99313            0.967638         0.956591   0.983819                    0.95951             0.0980649       0.299114                   96.0347   99.3128
    8        0.200097                    0.947094           1.96035    1.98493            0.967638         0.950708   0.979773                    0.957309            0.0980649       0.397179                   96.0347   98.4933
    9        0.299984                    0.907686           1.88144    1.95047            0.928687         0.931208   0.962763                    0.948618            0.18793         0.58511                    88.1437   95.0471
    10       0.400032                    0.808038           1.7571     1.90211            0.867314         0.864663   0.938891                    0.927621            0.175795        0.760905                   75.71     90.2109
    11       0.500081                    0.524583           1.29488    1.78062            0.639159         0.687442   0.878925                    0.87957             0.129551        0.890456                   29.4878   78.0624
    12       0.599968                    0.183534           0.705949   1.6017             0.34846          0.332299   0.79061                     0.788456            0.0705149       0.960971                   -29.4051  60.1704
    13       0.700016                    0.0708466          0.219638   1.40417            0.108414         0.114052   0.693108                    0.692068            0.0219744       0.982945                   -78.0362  40.4175
    14       0.799903                    0.0398683          0.114922   1.24318            0.0567261        0.0517901  0.613641                    0.612114            0.0114792       0.994424                   -88.5078  24.3181
    15       0.899951                    0.0311687          0.0393381  1.10935            0.0194175        0.0345659  0.547581                    0.547908            0.00393572      0.99836                    -96.0662  10.9349
    16       1                           0.0305976          0.0163909  1                  0.00809061       0.0306848  0.493605                    0.49616             0.00163988      1                          -98.3609  0

Scoring History: 
    timestamp            duration     training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 20:45:25  0.000 sec                      0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 20:45:28  4:38:45.732  9028 obs/sec      1         1             25000      0.304721         0.306481            0.628575       0.94302         0.922819           2.00702          0.126261                         0.293762           0.287804              0.65476          0.950536          0.928327             2.02591            0.1164
    2019-08-03 20:45:34  4:38:51.431  9156 obs/sec      3         3             75000      0.303214         0.306926            0.632241       0.943022        0.809199           2.00702          0.123564                         0.290667           0.284251              0.661996         0.951805          0.819518             2.02591            0.114619
    2019-08-03 20:45:39  4:38:57.205  9192 obs/sec      5         5             125000     0.304987         0.311288            0.627926       0.941658        0.720587           2.00702          0.123264                         0.292091           0.288733              0.658675         0.949747          0.717712             2.02591            0.113971
    2019-08-03 20:45:45  4:39:02.492  9437 obs/sec      7         7             175000     0.306533         0.315709            0.624146       0.939391        0.637384           2.00702          0.124463                         0.29401            0.293364              0.654175         0.947965          0.628676             2.02591            0.114619
    2019-08-03 20:45:50  4:39:07.526  9685 obs/sec      9         9             225000     0.306502         0.316216            0.624221       0.93882         0.588113           1.99972          0.124863                         0.293668           0.292977              0.65498          0.947307          0.57766              2.02591            0.113162
    2019-08-03 20:45:52  4:39:10.203  9776 obs/sec      10        10            250000     0.307119         0.317337            0.622708       0.938066        0.570367           2.00206          0.124263                         0.294184           0.293889              0.653767         0.947287          0.57489              2.02591            0.114295
    2019-08-03 20:45:53  4:39:10.483  9774 obs/sec      10        10            250000     0.303214         0.306926            0.632241       0.943022        0.809199           2.00702          0.123564                         0.290667           0.284251              0.661996         0.951805          0.819518             2.02591            0.114619
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.008341571781210859
C438        0.8349707126617432     0.8349707126617432    0.006964968134876718
C374        0.7322563529014587     0.7322563529014587    0.006108168929975189
C88         0.6809965968132019     0.6809965968132019    0.005680581995077634
C79         0.6408048272132874     0.6408048272132874    0.005345319463946058
---         ---                    ---                   ---
C981        0.04539966955780983    0.04539966955780983   0.00037870460245972414
C619        0.045265842229127884   0.045265842229127884  0.000377588272191236
C720        0.044853366911411285   0.044853366911411285  0.00037414757972052524
C690        0.04111173003911972    0.04111173003911972   0.00034293644717107985
C493        0.0398109070956707     0.0398109070956707    0.0003320855392136539

See the whole table with table.as_data_frame()
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_19

Status of Neuron Layers: predicting C1001, 2-class classification, bernoulli distribution, CrossEntropy loss, 31,458 weights/biases, 517.7 KB, 250,000 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  --------------------
    1        980      Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.012818107245326543   0.027232445776462555   0.0         0.0019610078490810098  0.11530917882919312  -0.009451690456415892  0.1222819983959198
    3        2        Softmax                 0.0   0.0   0.0016708051753084874  0.0002353667514398694  0.0         0.092941759248788      0.7785453796386719   -0.003194120526193951  0.047336965799331665


ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.08744450574370595
RMSE: 0.2957101718637794
LogLoss: 0.2937927447258612
Mean Per-Class Error: 0.11641307808082901
AUC: 0.9483677437226492
pr_auc: 0.9334348737366407
Gini: 0.8967354874452984
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4375119243632284: 
       0     1     Error    Rate
-----  ----  ----  -------  ----------------
0      4205  750   0.1514   (750.0/4955.0)
1      431   4647  0.0849   (431.0/5078.0)
Total  4636  5397  0.1177   (1181.0/10033.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.437512     0.887255  222
max f2                       0.162595     0.919411  318
max f0point5                 0.801205     0.897342  101
max accuracy                 0.529351     0.883684  193
max precision                0.961499     1         0
max recall                   0.0330832    1         398
max specificity              0.961499     1         0
max absolute_mcc             0.529351     0.76736   193
max min_per_class_accuracy   0.557738     0.882745  184
max mean_per_class_accuracy  0.529351     0.883587  193
Gains/Lift Table: Avg response rate: 50.61 %, avg score: 51.29 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100668                   0.960644           1.95622    1.95622            0.990099         0.961252   0.990099                    0.961252            0.0196928       0.0196928                  95.6216   95.6216
    2        0.0200339                   0.960539           1.97578    1.96595            1                0.96055    0.995025                    0.960903            0.0196928       0.0393856                  97.5778   96.5948
    3        0.030001                    0.960496           1.95602    1.96265            0.99             0.960525   0.993355                    0.960777            0.0194959       0.0588814                  95.602    96.265
    4        0.0400678                   0.960216           1.93665    1.95612            0.980198         0.960389   0.99005                     0.96068             0.0194959       0.0783773                  93.6654   95.6118
    5        0.0500349                   0.95959            1.97578    1.96003            1                0.959913   0.992032                    0.960527            0.0196928       0.0980701                  97.5778   96.0035
    6        0.10007                     0.955076           1.92068    1.94036            0.972112         0.957542   0.982072                    0.959034            0.0961008       0.194171                   92.0676   94.0356
    7        0.150005                    0.948837           1.94028    1.94033            0.982036         0.952053   0.98206                     0.95671             0.0968885       0.291059                   94.0285   94.0332
    8        0.20004                     0.940496           1.901      1.93049            0.962151         0.944679   0.97708                     0.953701            0.0951162       0.386176                   90.0997   93.0493
    9        0.30001                     0.912606           1.86153    1.90751            0.942173         0.928932   0.965449                    0.945448            0.186097        0.572273                   86.1526   90.7512
    10       0.39998                     0.831699           1.71773    1.86008            0.869392         0.879572   0.94144                     0.928983            0.171721        0.743994                   71.7725   86.0077
    11       0.50005                     0.577297           1.3244     1.75288            0.670319         0.724921   0.887184                    0.888146            0.132532        0.876526                   32.4401   75.2878
    12       0.60002                     0.239397           0.758399   1.58719            0.383848         0.398273   0.803322                    0.806528            0.0758173       0.952343                   -24.1601  58.7186
    13       0.69999                     0.0902213          0.283661   1.40102            0.143569         0.147886   0.709099                    0.712463            0.0283576       0.980701                   -71.6339  40.1021
    14       0.79996                     0.0507144          0.128041   1.24194            0.0648056        0.0656213  0.628582                    0.631628            0.0128003       0.993501                   -87.1959  24.1939
    15       0.89993                     0.0364286          0.0492467  1.10945            0.0249252        0.0427808  0.561524                    0.566215            0.0049232       0.998425                   -95.0753  10.9447
    16       1                           0.0319342          0.0157432  1                  0.00796813       0.0336807  0.50613                     0.512924            0.00157542      1                          -98.4257  0


ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.08468336483980521
RMSE: 0.2910040632702664
LogLoss: 0.2855459148552675
Mean Per-Class Error: 0.11534640094148518
AUC: 0.951454095049402
pr_auc: 0.9308062917574783
Gini: 0.9029081900988041
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4344619028389965: 
       0     1     Error    Rate
-----  ----  ----  -------  --------------
0      2668  460   0.1471   (460.0/3128.0)
1      255   2794  0.0836   (255.0/3049.0)
Total  2923  3254  0.1158   (715.0/6177.0)
Maximum Metrics: Maximum metrics at their respective thresholds

metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.434462     0.886562  220
max f2                       0.221104     0.920431  290
max f0point5                 0.780152     0.902773  110
max accuracy                 0.599066     0.884734  169
max precision                0.961329     1         0
max recall                   0.0330492    1         398
max specificity              0.961329     1         0
max absolute_mcc             0.434462     0.770351  220
max min_per_class_accuracy   0.55369      0.882992  184
max mean_per_class_accuracy  0.434462     0.884654  220
Gains/Lift Table: Avg response rate: 49.36 %, avg score: 50.35 %

    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain
--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------
    1        0.0100372                   0.960658           2.02591    2.02591            1                0.961235   1                           0.961235            0.0203345       0.0203345                  102.591   102.591
    2        0.0200745                   0.960539           2.02591    2.02591            1                0.96056    1                           0.960897            0.0203345       0.0406691                  102.591   102.591
    3        0.0301117                   0.96047            1.99323    2.01502            0.983871         0.960517   0.994624                    0.960771            0.0200066       0.0606756                  99.3234   101.502
    4        0.0401489                   0.960244           2.02591    2.01774            1                0.960382   0.995968                    0.960673            0.0203345       0.0810102                  102.591   101.774
    5        0.0500243                   0.959618           1.9927     2.0128             0.983607         0.959914   0.993528                    0.960524            0.0196786       0.100689                   99.2698   101.28
    6        0.100049                    0.955243           1.98002    1.99641            0.977346         0.957588   0.985437                    0.959056            0.0990489       0.199738                   98.0016   99.6407
    7        0.150073                    0.948852           1.96035    1.98439            0.967638         0.952063   0.979504                    0.956725            0.0980649       0.297803                   96.0347   98.4387
    8        0.200097                    0.940413           1.94723    1.9751             0.961165         0.944562   0.974919                    0.953684            0.097409        0.395212                   94.7234   97.5098
    9        0.299984                    0.907872           1.93069    1.96031            0.952998         0.926915   0.96762                     0.94477             0.19285         0.588062                   93.0689   96.0311
    10       0.400032                    0.816604           1.76366    1.91113            0.87055          0.871286   0.943343                    0.926392            0.176451        0.764513                   76.3656   91.1128
    11       0.500081                    0.534446           1.23915    1.77669            0.61165          0.696131   0.876983                    0.880325            0.123975        0.888488                   23.9149   77.6688
    12       0.599968                    0.207802           0.709233   1.59897            0.350081         0.358921   0.789261                    0.793518            0.0708429       0.959331                   -29.0767  59.8971
    13       0.700016                    0.085718           0.245863   1.40558            0.121359         0.135979   0.693802                    0.69954             0.0245982       0.983929                   -75.4137  40.5581
    14       0.799903                    0.049536           0.0919376  1.24154            0.0453809        0.0633986  0.612831                    0.620103            0.00918334      0.993112                   -90.8062  24.1541
    15       0.899951                    0.0354966          0.0557289  1.10971            0.0275081        0.0413398  0.54776                     0.555761            0.0055756       0.998688                   -94.4271  10.9713
    16       1                           0.0319426          0.0131127  1                  0.00647249       0.0334806  0.493605                    0.503508            0.00131191      1                          -98.6887  0

Scoring History: 
    timestamp            duration           training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  -----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2019-08-03 16:29:59  0.000 sec                            0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2019-08-03 16:30:02  23 min 19.299 sec  9304 obs/sec      1         1             25000      0.303861         0.30605             0.630619       0.942514        0.922606           1.97578          0.12429                          0.301473           0.301248              0.636398         0.944413          0.922012             2.02591            0.120932
    2019-08-03 16:30:07  23 min 24.881 sec  9373 obs/sec      3         3             75000      0.29571          0.293793            0.650169       0.948368        0.933435           1.95622          0.117712                         0.291004           0.285546              0.661211         0.951454          0.930806             2.02591            0.115752
    2019-08-03 16:30:13  23 min 30.411 sec  9420 obs/sec      5         5             125000     0.298492         0.300904            0.643557       0.945444        0.931957           1.87797          0.118908                         0.292553           0.29046               0.657594         0.949198          0.93137              1.99323            0.118666
    2019-08-03 16:30:18  23 min 35.463 sec  9689 obs/sec      7         7             175000     0.299365         0.303879            0.641468       0.94374         0.701084           1.97578          0.116615                         0.293721           0.294063              0.654855         0.947677          0.714705             2.02591            0.113809
    2019-08-03 16:30:25  23 min 42.709 sec  9996 obs/sec      10        10            250000     0.302004         0.308395            0.63512        0.941102        0.621564           1.93665          0.117313                         0.296564           0.298857              0.648141         0.944471          0.932812             1.99323            0.114619
    2019-08-03 16:30:25  23 min 43.022 sec  9993 obs/sec      10        10            250000     0.29571          0.293793            0.650169       0.948368        0.933435           1.95622          0.117712                         0.291004           0.285546              0.661211         0.951454          0.930806             2.02591            0.115752
Variable Importances: 
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  ----------------------
C250        1.0                    1.0                   0.007645055933651123
C438        0.887424886226654      0.887424886226654     0.006784412892116755
C88         0.7468006014823914     0.7468006014823914    0.005709332369617183
C374        0.7330727577209473     0.7330727577209473    0.00560438223621252
C79         0.6635144948959351     0.6635144948959351    0.0050726054262676965
---         ---                    ---                   ---
C334        0.05188126862049103    0.05188126862049103   0.0003966352005124328
C961        0.050828300416469574   0.050828300416469574  0.00038858519969633254
C917        0.05058089643716812    0.05058089643716812   0.0003866937824363651
C936        0.048721905797719955   0.048721905797719955  0.00037248169501765
C243        0.04839831590652466    0.04839831590652466   0.00037000783219989786

See the whole table with table.as_data_frame()
[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ]
                  activation  ...                 model_ids              logloss
0       RectifierWithDropout  ...   DL_random_grid_model_41  0.06377824730859294
1       RectifierWithDropout  ...  DL_random_grid_model_197  0.06589692409775776
2       RectifierWithDropout  ...    DL_random_grid_model_4  0.06608252056628768
3       RectifierWithDropout  ...  DL_random_grid_model_169  0.06609029688119879
4       RectifierWithDropout  ...  DL_random_grid_model_158  0.06756562145186505
5       RectifierWithDropout  ...   DL_random_grid_model_82  0.06880190470230817
6       RectifierWithDropout  ...   DL_random_grid_model_17  0.07066338659248987
7       RectifierWithDropout  ...   DL_random_grid_model_21  0.07199418811701501
8       RectifierWithDropout  ...  DL_random_grid_model_160  0.07299621084518722
9       RectifierWithDropout  ...  DL_random_grid_model_219  0.07367294935271426
10      RectifierWithDropout  ...  DL_random_grid_model_112  0.07599334562436388
11      RectifierWithDropout  ...   DL_random_grid_model_27  0.07629833773657306
12      RectifierWithDropout  ...   DL_random_grid_model_33  0.07635534594979104
13      RectifierWithDropout  ...   DL_random_grid_model_78   0.0785769805363295
14      RectifierWithDropout  ...  DL_random_grid_model_220   0.0794384963792225
15      RectifierWithDropout  ...   DL_random_grid_model_70  0.08032767045404529
16      RectifierWithDropout  ...  DL_random_grid_model_185  0.08060539995176194
17      RectifierWithDropout  ...  DL_random_grid_model_228  0.08093552648726834
18      RectifierWithDropout  ...  DL_random_grid_model_193  0.08164623027973766
19      RectifierWithDropout  ...  DL_random_grid_model_134  0.08403741319804647
20      RectifierWithDropout  ...  DL_random_grid_model_129  0.08431769438184723
21      RectifierWithDropout  ...   DL_random_grid_model_29  0.08473939723662756
22      RectifierWithDropout  ...    DL_random_grid_model_1  0.08663394204477438
23      RectifierWithDropout  ...  DL_random_grid_model_232   0.0903890046479914
24      RectifierWithDropout  ...  DL_random_grid_model_142   0.0911671814333971
25      RectifierWithDropout  ...   DL_random_grid_model_97  0.09279041872802628
26      RectifierWithDropout  ...  DL_random_grid_model_211  0.09358449911765505
27           TanhWithDropout  ...  DL_random_grid_model_121  0.09487170112555726
28      RectifierWithDropout  ...   DL_random_grid_model_36  0.09538252030086732
29      RectifierWithDropout  ...   DL_random_grid_model_88   0.0959054402758432
..  ..                   ...  ...                       ...                  ...
210          TanhWithDropout  ...   DL_random_grid_model_46   0.2707297719909951
211          TanhWithDropout  ...  DL_random_grid_model_156  0.27076809889867093
212          TanhWithDropout  ...   DL_random_grid_model_72   0.2710115718115974
213          TanhWithDropout  ...  DL_random_grid_model_222  0.27106251734284553
214          TanhWithDropout  ...   DL_random_grid_model_30   0.2711556760019886
215          TanhWithDropout  ...  DL_random_grid_model_207   0.2711817101025214
216          TanhWithDropout  ...  DL_random_grid_model_147   0.2713339736781258
217          TanhWithDropout  ...   DL_random_grid_model_47   0.2720473848600641
218          TanhWithDropout  ...   DL_random_grid_model_68  0.27236622648685516
219          TanhWithDropout  ...   DL_random_grid_model_35  0.27246497542392734
220          TanhWithDropout  ...  DL_random_grid_model_117   0.2731209662713256
221          TanhWithDropout  ...  DL_random_grid_model_154  0.27328272451279567
222          TanhWithDropout  ...  DL_random_grid_model_145   0.2733558165064312
223          TanhWithDropout  ...  DL_random_grid_model_229  0.27370340572891255
224          TanhWithDropout  ...   DL_random_grid_model_42   0.2740529652142107
225          TanhWithDropout  ...  DL_random_grid_model_203   0.2743091263325468
226          TanhWithDropout  ...   DL_random_grid_model_65  0.27473166358023543
227          TanhWithDropout  ...   DL_random_grid_model_15  0.27581683212186575
228          TanhWithDropout  ...  DL_random_grid_model_218  0.27600209809702386
229          TanhWithDropout  ...  DL_random_grid_model_107  0.27778809899685014
230          TanhWithDropout  ...   DL_random_grid_model_86   0.2806709151069368
231          TanhWithDropout  ...   DL_random_grid_model_92  0.28206120259058093
232          TanhWithDropout  ...  DL_random_grid_model_110    0.282569832276929
233          TanhWithDropout  ...   DL_random_grid_model_59  0.28291279981518164
234          TanhWithDropout  ...   DL_random_grid_model_22  0.28322385422893126
235          TanhWithDropout  ...   DL_random_grid_model_60   0.2835469128041622
236          TanhWithDropout  ...  DL_random_grid_model_237   0.2837299777554439
237          TanhWithDropout  ...   DL_random_grid_model_79  0.28420647422115397
238          TanhWithDropout  ...  DL_random_grid_model_226   0.2842506302641777
239          TanhWithDropout  ...   DL_random_grid_model_19   0.2855459148552675

[240 rows x 7 columns]

--- 17616.91354250908 seconds ---
Evalutation of best performing model:
Final acc, selected model:  84.00800000000001
Time consumed:  4.89362144112587  hours
H2O session _sid_937a closed.
