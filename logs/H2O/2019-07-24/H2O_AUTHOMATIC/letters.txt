Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmpg2obzliu
  JVM stdout: /tmp/tmpg2obzliu/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmpg2obzliu/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    8 days
H2O cluster name:           H2O_from_python_davidserranogemes_6zcyi8
H2O cluster total nodes:    1
H2O cluster free memory:    3.900 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Authomatic  mode.

AutoML progress: |
13:54:17.549: Project: automl_py_3_sid_a8ca
13:54:17.549: AutoML job created: 2019.07.24 13:54:17.547
13:54:17.549: Disabling Algo: GLM as requested by the user.
13:54:17.550: Disabling Algo: DRF as requested by the user.
13:54:17.550: Disabling Algo: XGBoost as requested by the user.
13:54:17.550: Disabling Algo: StackedEnsemble as requested by the user.
13:54:17.550: Disabling Algo: GBM as requested by the user.
13:54:17.550: Build control seed: 1
13:54:17.566: training frame: Frame key: automl_training_py_3_sid_a8ca    cols: 17    rows: 7517  chunks: 1    size: 131113  checksum: -9457487542503
13:54:17.574: validation frame: Frame key: py_4_sid_a8ca    cols: 17    rows: 2490  chunks: 1    size: 45654  checksum: -8175476536668
13:54:17.574: leaderboard frame: NULL
13:54:17.574: response column: C17
13:54:17.574: fold column: null
13:54:17.574: weights column: null
13:54:17.608: Setting stopping tolerance adaptively based on the training frame: 0.011533940982981885
13:54:17.614: AutoML build started: 2019.07.24 13:54:17.614

██████
13:54:25.701: New leader: DeepLearning_1_AutoML_20190724_135417, mean_per_class_error: 0.40281228369195526
13:54:25.702: AutoML: starting DeepLearning hyperparameter search

██████████████
13:54:49.728: New leader: DeepLearning_grid_1_AutoML_20190724_135417_model_1, mean_per_class_error: 0.16397182873472418

███████
13:55:09.731: AutoML: starting DeepLearning hyperparameter search

████████
13:55:32.741: New leader: DeepLearning_grid_1_AutoML_20190724_135417_model_4, mean_per_class_error: 0.15922915733311768

██████
13:55:46.743: AutoML: starting DeepLearning hyperparameter search

██████████████
13:56:18.753: StackedEnsemble builds skipped due to the exclude_algos option.
13:56:18.753: AutoML build stopped: 2019.07.24 13:56:18.753
13:56:18.753: AutoML build done: built 7 models
13:56:18.753: AutoML duration:  2 min  1.139 sec

█| 100%
--- 121.8888430595398 seconds ---
Evalutation of best performing model:
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DeepLearning_grid_1_AutoML_20190724_135417_model_4

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 4,726 weights/biases, 62.4 KB, 661,726 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             15.0
    2        50       RectifierDropout  20.0       0.0   0.0   0.0012908150507428217  0.0004032701253890991  0.0         -0.02026338053889049  0.3317021131515503  -0.5125527013895481  0.3465256690979004
    3        50       RectifierDropout  20.0       0.0   0.0   0.001890862734010443   0.0008860428351908922  0.0         -0.08026098699636204  0.2890889644622803  0.09995856950037561  0.37914061546325684
    4        26       Softmax                      0.0   0.0   0.041093312054872516   0.10935479402542114    0.0         -2.454759647732493    1.8346128463745117  -11.416305008302967  0.7864820957183838


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13731683033649558
RMSE: 0.3705628561209226
LogLoss: 0.4251791637374803
Mean Per-Class Error: 0.11973337593958511
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  -----------
292.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    7.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0457516339869281   14 / 306
0.0    244.0  0.0    5.0    1.0    4.0    0.0    5.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    8.0    0.0    4.0    1.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.11913357400722022  33 / 277
0.0    0.0    251.0  0.0    10.0   0.0    7.0    1.0    0.0    0.0    9.0    3.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    0.12237762237762238  35 / 286
1.0    9.0    0.0    261.0  0.0    2.0    0.0    3.0    0.0    3.0    0.0    0.0    2.0    3.0    1.0    2.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.10309278350515463  30 / 291
0.0    1.0    3.0    0.0    244.0  2.0    11.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    5.0    2.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    12.0   0.14982578397212543  43 / 287
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    272.0  0.0    0.0    0.0    0.04225352112676056  12 / 284
0.0    1.0    0.0    2.0    5.0    0.0    0.0    0.0    0.0    2.0    7.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    0.0    265.0  2.0    1.0    0.09863945578231292  29 / 294
0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    6.0    0.0    3.0    6.0    1.0    8.0    0.0    0.0    253.0  0.0    0.11538461538461539  33 / 286
9.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    39.0   0.0    0.0    0.0    0.0    0.0    0.0    226.0  0.19285714285714287  54 / 280
329.0  296.0  258.0  308.0  284.0  307.0  305.0  240.0  261.0  249.0  305.0  258.0  333.0  274.0  312.0  330.0  284.0  277.0  326.0  276.0  301.0  266.0  337.0  272.0  279.0  250.0  0.11906345616602368  895 / 7,517

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.880937
2    0.945457
3    0.967407
4    0.978981
5    0.984435
6    0.988559
7    0.991486
8    0.993215
9    0.994945
10   0.996142

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16291605760168337
RMSE: 0.4036286134575736
LogLoss: 0.5154795038754886
Mean Per-Class Error: 0.1498448762034377
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6      7     8     9      10     11    12    13     14    15     16     17    18     19    20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0    0.0   3.0   0.0    0.0   0.0    0.0    0.0   1.0    1.0   0.0    1.0   2.0    0.0   0.0    0.0   0.10112359550561797  9 / 89
0.0    83.0   0.0   0.0    0.0   3.0   3.0    3.0   0.0   0.0    1.0    0.0   0.0   0.0    1.0   5.0    0.0    2.0   0.0    0.0   1.0    3.0   1.0    0.0   0.0    0.0   0.2169811320754717   23 / 106
0.0    0.0    69.0  0.0    4.0   0.0   3.0    0.0   0.0   0.0    1.0    0.0   0.0   0.0    3.0   0.0    1.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.15853658536585366  13 / 82
2.0    3.0    0.0   96.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0    0.0   0.0   1.0    2.0   0.0    0.0    1.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.14285714285714285  16 / 112
0.0    0.0    0.0   0.0    77.0  2.0   6.0    0.0   0.0   0.0    2.0    1.0   0.0   0.0    0.0   1.0    1.0    1.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    4.0   0.20618556701030927  20 / 97
---    ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    0.0   89.0   0.0   0.0    0.0   0.03260869565217391  3 / 92
0.0    1.0    0.0   4.0    2.0   0.0   0.0    1.0   1.0   2.0    5.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0   4.0    0.0   0.0    0.0   0.0    78.0  1.0    1.0   0.22                 22 / 100
1.0    0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   4.0    4.0    0.0   0.0    3.0   0.0    4.0   1.0    0.0   89.0   0.0   0.16822429906542055  18 / 107
4.0    0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   12.0   0.0   0.0    0.0   0.0    0.0   0.0    68.0  0.21839080459770116  19 / 87
104.0  106.0  70.0  116.0  89.0  87.0  102.0  74.0  76.0  110.0  102.0  89.0  93.0  102.0  86.0  134.0  103.0  94.0  105.0  85.0  104.0  80.0  116.0  80.0  101.0  82.0  0.1493975903614458   372 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850602
2    0.923293
3    0.951406
4    0.965863
5    0.973494
6    0.981124
7    0.984739
8    0.990763
9    0.991968
10   0.993574

ModelMetricsMultinomial: deeplearning
** Reported on cross-validation data. **

MSE: 0.16338863965107642
RMSE: 0.4042136064645479
LogLoss: 0.522765266521197
Mean Per-Class Error: 0.15922915733311768
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  -------------
288.0  0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    4.0    1.0    1.0    1.0    0.0    1.0    0.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.058823529411764705  18 / 306
0.0    224.0  1.0    7.0    1.0    1.0    0.0    5.0    1.0    0.0    1.0    0.0    1.0    1.0    0.0    10.0   0.0    7.0    13.0   0.0    0.0    1.0    1.0    1.0    1.0    0.0    0.19133574007220217   53 / 277
0.0    0.0    244.0  0.0    13.0   2.0    6.0    0.0    0.0    0.0    7.0    4.0    1.0    0.0    3.0    0.0    1.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.14685314685314685   42 / 286
1.0    12.0   0.0    246.0  0.0    1.0    0.0    5.0    0.0    5.0    0.0    0.0    3.0    3.0    0.0    2.0    0.0    6.0    5.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.15463917525773196   45 / 291
0.0    2.0    6.0    0.0    232.0  0.0    8.0    2.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    4.0    4.0    5.0    1.0    0.0    0.0    0.0    7.0    0.0    11.0   0.1916376306620209    55 / 287
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    2.0    0.0    11.0   1.0    2.0    2.0    0.0    1.0    0.0    1.0    3.0    0.0    256.0  0.0    0.0    0.0    0.09859154929577464   28 / 284
0.0    2.0    0.0    3.0    7.0    1.0    0.0    0.0    0.0    2.0    7.0    3.0    0.0    0.0    3.0    0.0    0.0    1.0    3.0    1.0    1.0    0.0    0.0    255.0  0.0    5.0    0.1326530612244898    39 / 294
1.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    4.0    0.0    0.0    24.0   4.0    7.0    1.0    0.0    236.0  0.0    0.17482517482517482   50 / 286
5.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    32.0   0.0    0.0    0.0    0.0    1.0    2.0    229.0  0.18214285714285713   51 / 280
327.0  292.0  266.0  328.0  285.0  291.0  286.0  226.0  250.0  269.0  280.0  264.0  335.0  285.0  283.0  327.0  281.0  335.0  304.0  328.0  293.0  259.0  318.0  280.0  257.0  268.0  0.1584408673673008    1,191 / 7,517

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.841559
2    0.918318
3    0.947719
4    0.963416
5    0.971132
6    0.978981
7    0.984036
8    0.98816
9    0.992018
10   0.993348
Cross-Validation Metrics Summary: 
                         mean      sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------------------  --------  -----------  ------------  ------------  ------------  ------------  ------------
accuracy                 0.834908  0.0108777    0.854388      0.80984       0.842981      0.826347      0.840985
err                      0.165092  0.0108777    0.145612      0.19016       0.157019      0.173653      0.159015
err_count                248.2     16.367       219           286           236           261           239
logloss                  0.537797  0.0263525    0.479774      0.589728      0.516773      0.557328      0.54538
max_per_class_error      0.380532  0.0569484    0.366667      0.472727      0.272727      0.318841      0.471698
mean_per_class_accuracy  0.835856  0.0110039    0.855275      0.810539      0.845979      0.827363      0.840124
mean_per_class_error     0.164144  0.0110039    0.144725      0.189461      0.154021      0.172637      0.159876
mse                      0.169709  0.00692185   0.15424       0.182019      0.163666      0.176483      0.172135
r2                       0.996986  0.000108292  0.997232      0.996802      0.997082      0.996881      0.996932
rmse                     0.411784  0.00845307   0.392734      0.426637      0.404557      0.420098      0.414892
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:55:27  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:55:28  18.629 sec  133866 obs/sec    8.79739   1             66130      0.491393         0.750396            0.995712       0.223759                         0.50751            0.801259              0.995411         0.240562
    2019-07-24 13:55:32  22.363 sec  157441 obs/sec    88.0306   10            661726     0.370563         0.425179            0.997562       0.119063                         0.403629           0.51548               0.997097         0.149398
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.101834
C15         0.998954               0.998954             0.101728
C8          0.843845               0.843845             0.0859324
C9          0.784824               0.784824             0.0799221
C11         0.724788               0.724788             0.0738084
C12         0.722943               0.722943             0.0736205
C7          0.721608               0.721608             0.0734845
C6          0.640039               0.640039             0.0651779
C10         0.604144               0.604144             0.0615227
C14         0.589474               0.589474             0.0600287
C16         0.561679               0.561679             0.0571982
C5          0.433161               0.433161             0.0441107
C3          0.327389               0.327389             0.0333394
C4          0.314053               0.314053             0.0319814
C1          0.313257               0.313257             0.0319003
C2          0.239709               0.239709             0.0244106

model_id                                              mean_per_class_error    logloss      rmse       mse
--------------------------------------------------  ----------------------  ---------  --------  --------
DeepLearning_grid_1_AutoML_20190724_135417_model_4                0.159229   0.522765  0.404214  0.163389
DeepLearning_grid_1_AutoML_20190724_135417_model_1                0.163972   0.561353  0.408409  0.166798
DeepLearning_grid_1_AutoML_20190724_135417_model_6                0.17721    0.588191  0.429721  0.18466
DeepLearning_grid_1_AutoML_20190724_135417_model_3                0.182453   0.593052  0.405626  0.164533
DeepLearning_grid_1_AutoML_20190724_135417_model_2                0.184536   0.639166  0.403649  0.162933
DeepLearning_grid_1_AutoML_20190724_135417_model_5                0.189122   0.617215  0.413104  0.170655
DeepLearning_1_AutoML_20190724_135417                             0.402812   1.33206   0.639162  0.408528

[7 rows x 5 columns]

deeplearning prediction progress: |███████████████████████████████████████| 100%
Final acc, selected model:  84.77934554187931
Time consumed:  0.03398070600297716  hours
H2O session _sid_a8ca closed.
