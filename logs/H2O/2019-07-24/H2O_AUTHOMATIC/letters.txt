Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmpjyscbhkl
  JVM stdout: /tmp/tmpjyscbhkl/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmpjyscbhkl/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    8 days
H2O cluster name:           H2O_from_python_davidserranogemes_y2mkfh
H2O cluster total nodes:    1
H2O cluster free memory:    3.900 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Authomatic  mode.

AutoML progress: |
15:23:19.319: Project: automl_py_3_sid_829e
15:23:19.319: AutoML job created: 2019.07.24 15:23:19.316
15:23:19.319: Disabling Algo: GBM as requested by the user.
15:23:19.319: Disabling Algo: GLM as requested by the user.
15:23:19.320: Disabling Algo: DRF as requested by the user.
15:23:19.320: Disabling Algo: XGBoost as requested by the user.
15:23:19.320: Disabling Algo: StackedEnsemble as requested by the user.
15:23:19.320: Build control seed: 1
15:23:19.336: training frame: Frame key: automl_training_py_3_sid_829e    cols: 17    rows: 7517  chunks: 1    size: 131113  checksum: -9457487542503
15:23:19.337: validation frame: Frame key: py_4_sid_829e    cols: 17    rows: 2490  chunks: 1    size: 45654  checksum: -8175476536668
15:23:19.337: leaderboard frame: NULL
15:23:19.337: response column: C17
15:23:19.337: fold column: null
15:23:19.337: weights column: null
15:23:19.373: Setting stopping tolerance adaptively based on the training frame: 0.011533940982981885
15:23:19.379: AutoML build started: 2019.07.24 15:23:19.378

██████
15:23:27.534: New leader: DeepLearning_1_AutoML_20190724_152319, mean_per_class_error: 0.3844422152386102
15:23:27.538: AutoML: starting DeepLearning hyperparameter search

██████████████
15:23:52.746: New leader: DeepLearning_grid_1_AutoML_20190724_152319_model_1, mean_per_class_error: 0.16586469360881037

███████
15:24:13.749: AutoML: starting DeepLearning hyperparameter search

████████
15:24:34.762: New leader: DeepLearning_grid_1_AutoML_20190724_152319_model_4, mean_per_class_error: 0.15770333742071904

██████
15:24:47.765: AutoML: starting DeepLearning hyperparameter search

██████████████
15:25:20.782: StackedEnsemble builds skipped due to the exclude_algos option.
15:25:20.782: AutoML build stopped: 2019.07.24 15:25:20.782
15:25:20.782: AutoML build done: built 7 models
15:25:20.782: AutoML duration:  2 min  1.404 sec

█| 100%
--- 122.14849710464478 seconds ---
Evalutation of best performing model:
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DeepLearning_grid_1_AutoML_20190724_152319_model_4

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 4,726 weights/biases, 62.4 KB, 469,394 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             15.0
    2        50       RectifierDropout  20.0       0.0   0.0   0.001461368529489846   0.00038538745138794184  0.0         -0.021589843964538887  0.3395637273788452   -0.4505424576920967  0.28671538829803467
    3        50       RectifierDropout  20.0       0.0   0.0   0.0020552435341873207  0.000894252210855484    0.0         -0.07000224901257607   0.26937782764434814  0.11994124376816873  0.39367032051086426
    4        26       Softmax                      0.0   0.0   0.04194010613781687    0.1235380470752716      0.0         -1.9054449217444143    1.5586881637573242   -8.115630680726888   0.9013192653656006


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14988556270240977
RMSE: 0.38715056851619084
LogLoss: 0.4618187534000122
Mean Per-Class Error: 0.14007464096258265
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  -------------
288.0  0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    2.0    8.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.058823529411764705  18 / 306
0.0    254.0  0.0    2.0    0.0    3.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    0.0    0.08303249097472924   23 / 277
0.0    0.0    261.0  0.0    5.0    0.0    3.0    0.0    0.0    0.0    7.0    2.0    0.0    0.0    1.0    0.0    1.0    3.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0    0.0    0.08741258741258741   25 / 286
0.0    10.0   0.0    261.0  0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    3.0    2.0    0.0    5.0    0.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.10309278350515463   30 / 291
0.0    4.0    5.0    0.0    236.0  3.0    6.0    0.0    0.0    0.0    2.0    9.0    0.0    0.0    0.0    2.0    2.0    2.0    9.0    0.0    0.0    0.0    0.0    2.0    0.0    5.0    0.17770034843205576   51 / 287
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    4.0    0.0    3.0    0.0    0.0    0.0    11.0   253.0  0.0    2.0    0.0    0.10915492957746478   31 / 284
0.0    2.0    0.0    5.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    269.0  1.0    0.0    0.08503401360544217   25 / 294
0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    50.0   1.0    20.0   0.0    0.0    205.0  0.0    0.28321678321678323   81 / 286
3.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    31.0   0.0    0.0    0.0    0.0    3.0    0.0    225.0  0.19642857142857142   55 / 280
298.0  353.0  276.0  332.0  267.0  331.0  250.0  204.0  235.0  278.0  270.0  289.0  349.0  270.0  279.0  330.0  288.0  326.0  290.0  351.0  299.0  321.0  282.0  286.0  225.0  238.0  0.13915125715045895   1,046 / 7,517

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.860849
2    0.933617
3    0.958228
4    0.972994
5    0.980577
6    0.986564
7    0.988958
8    0.992018
9    0.994147
10   0.995477

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17422848325360663
RMSE: 0.41740685578174996
LogLoss: 0.5534137591575771
Mean Per-Class Error: 0.16613919721696252
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11     12     13    14    15     16     17     18    19     20     21    22    23    24    25    Error                 Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  ----  -----  -----  -----  ----  -----  -----  ----  ----  ----  ----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0    1.0   0.0   0.0   2.0   0.0   0.06741573033707865   6 / 89
0.0   86.0   0.0   0.0    0.0   3.0    1.0   0.0   0.0   0.0    1.0   0.0    1.0    0.0   0.0   4.0    0.0    3.0    0.0   0.0    0.0    5.0   0.0   0.0   2.0   0.0   0.18867924528301888   20 / 106
0.0   0.0    76.0  0.0    2.0   0.0    1.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0   1.0   0.0    0.0    0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.07317073170731707   6 / 82
1.0   2.0    0.0   96.0   0.0   0.0    0.0   3.0   0.0   4.0    0.0   0.0    2.0    1.0   1.0   0.0    0.0    0.0    1.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0   0.14285714285714285   16 / 112
0.0   0.0    1.0   0.0    70.0  0.0    5.0   0.0   0.0   0.0    1.0   5.0    0.0    0.0   0.0   1.0    0.0    1.0    7.0   1.0    0.0    0.0   0.0   1.0   0.0   4.0   0.27835051546391754   27 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---   ---    ---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0    0.0   0.0   1.0    0.0    0.0    0.0   0.0    0.0    1.0   88.0  0.0   0.0   0.0   0.043478260869565216  4 / 92
0.0   1.0    0.0   4.0    1.0   2.0    0.0   0.0   1.0   0.0    4.0   1.0    0.0    0.0   0.0   0.0    0.0    0.0    2.0   0.0    0.0    0.0   0.0   83.0  0.0   1.0   0.17                  17 / 100
0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   4.0    5.0    0.0    0.0   13.0   0.0    6.0   1.0   0.0   77.0  0.0   0.2803738317757009    30 / 107
0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0   0.0   5.0    0.0   0.0    0.0    0.0   0.0   0.0    1.0    0.0    9.0   0.0    0.0    0.0   0.0   0.0   0.0   70.0  0.19540229885057472   17 / 87
88.0  131.0  78.0  120.0  78.0  101.0  81.0  64.0  71.0  129.0  95.0  100.0  100.0  98.0  68.0  124.0  110.0  105.0  88.0  103.0  105.0  93.0  99.0  88.0  92.0  81.0  0.16626506024096385   414 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.833735
2    0.914458
3    0.942972
4    0.964257
5    0.971486
6    0.981526
7    0.984739
8    0.989558
9    0.991566
10   0.992369

ModelMetricsMultinomial: deeplearning
** Reported on cross-validation data. **

MSE: 0.16615635749019392
RMSE: 0.40762281276959206
LogLoss: 0.5303957088472929
Mean Per-Class Error: 0.15770333742071904
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  -------------
281.0  0.0    0.0    2.0    0.0    1.0    0.0    1.0    0.0    1.0    3.0    3.0    5.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    2.0    0.08169934640522876  25 / 306
0.0    241.0  0.0    10.0   0.0    4.0    0.0    1.0    1.0    0.0    1.0    0.0    1.0    1.0    0.0    2.0    0.0    9.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.1299638989169675   36 / 277
0.0    0.0    246.0  1.0    16.0   0.0    3.0    0.0    0.0    0.0    8.0    6.0    1.0    0.0    3.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.13986013986013987  40 / 286
0.0    19.0   0.0    247.0  0.0    1.0    0.0    2.0    0.0    5.0    0.0    0.0    4.0    2.0    0.0    6.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.15120274914089346  44 / 291
1.0    4.0    7.0    0.0    227.0  2.0    4.0    0.0    0.0    0.0    4.0    9.0    0.0    1.0    0.0    1.0    6.0    1.0    7.0    0.0    1.0    0.0    0.0    4.0    0.0    8.0    0.20905923344947736  60 / 287
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    2.0    1.0    5.0    0.0    2.0    0.0    1.0    0.0    4.0    257.0  0.0    0.0    0.0    0.09507042253521127  27 / 284
0.0    2.0    0.0    6.0    5.0    0.0    0.0    1.0    0.0    4.0    9.0    5.0    0.0    0.0    2.0    0.0    0.0    0.0    8.0    2.0    1.0    0.0    0.0    245.0  1.0    3.0    0.16666666666666666  49 / 294
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    1.0    0.0    0.0    23.0   1.0    6.0    0.0    0.0    245.0  0.0    0.14335664335664336  41 / 286
3.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    25.0   0.0    0.0    0.0    0.0    4.0    1.0    228.0  0.18571428571428572  52 / 280
312.0  346.0  272.0  332.0  268.0  311.0  256.0  210.0  251.0  269.0  299.0  288.0  351.0  283.0  305.0  309.0  251.0  328.0  304.0  325.0  277.0  270.0  304.0  267.0  275.0  254.0  0.1571105494213117   1,181 / 7,517

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842889
2    0.917919
3    0.945989
4    0.965013
5    0.972728
6    0.978183
7    0.982972
8    0.986431
9    0.98949
10   0.992018
Cross-Validation Metrics Summary: 
                         mean      sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------------------  --------  -----------  ------------  ------------  ------------  ------------  ------------
accuracy                 0.81588   0.0245935    0.833777      0.831117      0.830339      0.746507      0.837658
err                      0.18412   0.0245935    0.166223      0.168883      0.169661      0.253493      0.162342
err_count                276.8     36.9416      250           254           255           381           244
logloss                  0.60904   0.0834299    0.51604       0.562102      0.56635       0.842225      0.558485
max_per_class_error      0.43012   0.0985672    0.383333      0.296875      0.307692      0.672131      0.490566
mean_per_class_accuracy  0.814826  0.0253816    0.833008      0.830866      0.830965      0.743139      0.836153
mean_per_class_error     0.185174  0.0253816    0.166992      0.169134      0.169035      0.256862      0.163847
mse                      0.191126  0.0268744    0.166077      0.171546      0.174504      0.266803      0.1767
r2                       0.996606  0.000469254  0.997019      0.996986      0.996889      0.995284      0.996851
rmse                     0.435266  0.0288921    0.407525      0.414182      0.417737      0.51653       0.420357
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:24:31  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:24:31  17.722 sec  118128 obs/sec    6.23879   1             46897      0.50644          0.79559             0.995446       0.229081                         0.519269           0.847452              0.995195         0.243775
    2019-07-24 15:24:34  20.717 sec  139575 obs/sec    62.4443   10            469394     0.387151         0.461819            0.997339       0.139151                         0.417407           0.553414              0.996895         0.166265
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0986273
C15         0.986106               0.986106             0.0972569
C9          0.867596               0.867596             0.0855687
C12         0.80229                0.80229              0.0791277
C8          0.777125               0.777125             0.0766457
C14         0.725522               0.725522             0.0715562
C11         0.72448                0.72448              0.0714535
C7          0.699163               0.699163             0.0689566
C6          0.61038                0.61038              0.0602001
C16         0.581196               0.581196             0.0573218
C10         0.57208                0.57208              0.0564227
C5          0.523783               0.523783             0.0516593
C3          0.361074               0.361074             0.0356118
C1          0.338523               0.338523             0.0333876
C4          0.303877               0.303877             0.0299706
C2          0.265986               0.265986             0.0262335

model_id                                              mean_per_class_error    logloss      rmse       mse
--------------------------------------------------  ----------------------  ---------  --------  --------
DeepLearning_grid_1_AutoML_20190724_152319_model_4                0.157703   0.530396  0.407623  0.166156
DeepLearning_grid_1_AutoML_20190724_152319_model_1                0.165865   0.568422  0.409771  0.167912
DeepLearning_grid_1_AutoML_20190724_152319_model_3                0.169125   0.562617  0.394322  0.15549
DeepLearning_grid_1_AutoML_20190724_152319_model_6                0.179787   0.588491  0.429214  0.184224
DeepLearning_grid_1_AutoML_20190724_152319_model_2                0.195206   0.700804  0.421667  0.177803
DeepLearning_grid_1_AutoML_20190724_152319_model_5                0.218945   0.701936  0.443008  0.196256
DeepLearning_1_AutoML_20190724_152319                             0.384442   1.32085   0.634301  0.402338

[7 rows x 5 columns]

deeplearning prediction progress: |███████████████████████████████████████| 100%
Final acc, selected model:  83.11818272790954
Time consumed:  0.034052694572342765  hours
H2O session _sid_829e closed.
