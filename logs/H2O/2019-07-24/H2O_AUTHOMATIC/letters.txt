Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmp5afncfy_
  JVM stdout: /tmp/tmp5afncfy_/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmp5afncfy_/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    8 days
H2O cluster name:           H2O_from_python_davidserranogemes_g5tu09
H2O cluster total nodes:    1
H2O cluster free memory:    1.922 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Authomatic  mode.

AutoML progress: |
13:00:33.945: Project: automl_py_3_sid_bd2b
13:00:33.945: AutoML job created: 2019.07.24 13:00:33.942
13:00:33.946: Disabling Algo: StackedEnsemble as requested by the user.
13:00:33.946: Disabling Algo: XGBoost as requested by the user.
13:00:33.946: Disabling Algo: GBM as requested by the user.
13:00:33.946: Disabling Algo: DRF as requested by the user.
13:00:33.946: Disabling Algo: GLM as requested by the user.
13:00:33.946: Build control seed: 1
13:00:33.967: training frame: Frame key: automl_training_py_3_sid_bd2b    cols: 17    rows: 7517  chunks: 1    size: 131113  checksum: -9457487542503
13:00:33.974: validation frame: Frame key: py_4_sid_bd2b    cols: 17    rows: 2490  chunks: 1    size: 45654  checksum: -8175476536668
13:00:33.974: leaderboard frame: NULL
13:00:33.975: response column: C17
13:00:33.975: fold column: null
13:00:33.975: weights column: null
13:00:34.38: Setting stopping tolerance adaptively based on the training frame: 0.011533940982981885
13:00:34.49: AutoML build started: 2019.07.24 13:00:34.49

█████
13:00:45.69: New leader: DeepLearning_1_AutoML_20190724_130033, mean_per_class_error: 0.40096074661261577
13:00:45.70: AutoML: starting DeepLearning hyperparameter search

███████████████
13:01:09.115: New leader: DeepLearning_grid_1_AutoML_20190724_130033_model_1, mean_per_class_error: 0.17807206901412853

█████████
13:01:37.121: New leader: DeepLearning_grid_1_AutoML_20190724_130033_model_3, mean_per_class_error: 0.1780363664333781
13:01:37.121: AutoML: starting DeepLearning hyperparameter search

██████████████████
13:02:15.152: AutoML: starting DeepLearning hyperparameter search

█████████| 100%

13:02:35.167: StackedEnsemble builds skipped due to the exclude_algos option.
13:02:35.168: AutoML build stopped: 2019.07.24 13:02:35.167
13:02:35.168: AutoML build done: built 7 models
13:02:35.168: AutoML duration:  2 min  1.118 sec

--- 122.48260879516602 seconds ---
Evalutation of best performing model:
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DeepLearning_grid_1_AutoML_20190724_130033_model_3

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 21,526 weights/biases, 263.3 KB, 60,385 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             5.0
    2        500      RectifierDropout  50.0       0.0   0.0   0.014593799408263294  0.007406631484627724  0.0         -0.01041157196591942  0.21887272596359253  -0.1432666303051243  0.19610708951950073
    3        26       Softmax                      0.0   0.0   0.18553806362580508   0.2629430294036865    0.0         -0.937964911439297    0.462239146232605    -11.412533328099062  1.0693097114562988


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.10298026927307197
RMSE: 0.32090538990966166
LogLoss: 0.3485888513496099
Mean Per-Class Error: 0.10309366477785893
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  -----------
285.0  1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    1.0    2.0    0.0    0.06862745098039216   21 / 306
0.0    262.0  0.0    5.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.05415162454873646   15 / 277
0.0    0.0    262.0  0.0    10.0   1.0    4.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.08391608391608392   24 / 286
1.0    16.0   0.0    255.0  0.0    0.0    0.0    1.0    0.0    4.0    1.0    0.0    4.0    2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.12371134020618557   36 / 291
0.0    0.0    0.0    0.0    258.0  4.0    10.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    4.0    0.10104529616724739   29 / 287
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    2.0    262.0  0.0    0.0    0.0    0.07746478873239436   22 / 284
0.0    1.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    3.0    4.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    276.0  1.0    2.0    0.061224489795918366  18 / 294
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    2.0    1.0    0.0    0.0    270.0  0.0    0.055944055944055944  16 / 286
1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    3.0    1.0    0.0    0.0    0.0    3.0    0.0    256.0  0.08571428571428572   24 / 280
301.0  329.0  268.0  289.0  322.0  343.0  276.0  221.0  253.0  281.0  277.0  274.0  338.0  282.0  286.0  272.0  263.0  339.0  260.0  283.0  294.0  296.0  282.0  317.0  289.0  282.0  0.10256751363575894   771 / 7,517

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.897432
2    0.951044
3    0.971664
4    0.981243
5    0.986564
6    0.990688
7    0.993082
8    0.994413
9    0.995743
10   0.996807

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.12313255303331597
RMSE: 0.3509024836522477
LogLoss: 0.44588166567918314
Mean Per-Class Error: 0.12487600787770367
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10     11    12     13    14    15     16    17     18    19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   1.0   0.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   89.0   0.0   1.0    2.0   1.0    1.0   1.0   0.0   0.0    1.0    0.0   1.0    0.0   0.0   0.0    2.0   4.0    1.0   0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.16037735849056603  17 / 106
0.0   0.0    73.0  0.0    3.0   0.0    2.0   0.0   0.0   0.0    2.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.10975609756097561  9 / 82
3.0   4.0    0.0   92.0   0.0   0.0    0.0   1.0   0.0   4.0    1.0    0.0   2.0    1.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.17857142857142858  20 / 112
0.0   0.0    1.0   0.0    77.0  2.0    5.0   0.0   0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    2.0   1.0   0.0   0.0   0.0   2.0    0.0    4.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   3.0    0.0   0.0   0.0    1.0   2.0    0.0   0.0   0.0   0.0   86.0  0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    2.0   1.0    0.0   0.0   0.0   1.0    5.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   89.0   0.0    1.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0   0.0   2.0   1.0   0.0    100.0  0.0   0.06542056074766354  7 / 107
0.0   0.0    0.0   0.0    5.0   0.0    0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0    75.0  0.13793103448275862  12 / 87
90.0  117.0  76.0  103.0  96.0  101.0  93.0  72.0  75.0  127.0  103.0  93.0  103.0  97.0  76.0  103.0  91.0  112.0  89.0  89.0  96.0  86.0  95.0  103.0  116.0  88.0  0.12570281124497992  313 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.874297
2    0.940964
3    0.959036
4    0.96747
5    0.977912
6    0.983534
7    0.988353
8    0.991566
9    0.991968
10   0.994779

ModelMetricsMultinomial: deeplearning
** Reported on cross-validation data. **

MSE: 0.16264762278606745
RMSE: 0.40329594937969243
LogLoss: 0.5960979472463357
Mean Per-Class Error: 0.1780363664333781
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  -------------
278.0  0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    6.0    5.0    1.0    2.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    1.0    1.0    1.0    0.0    3.0    0.0    0.0915032679738562   28 / 306
0.0    233.0  0.0    4.0    2.0    2.0    3.0    5.0    1.0    0.0    1.0    0.0    1.0    0.0    0.0    4.0    2.0    8.0    8.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.1588447653429603   44 / 277
0.0    0.0    241.0  0.0    13.0   0.0    15.0   0.0    0.0    0.0    4.0    2.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    2.0    4.0    0.0    2.0    0.0    0.0    0.0    0.15734265734265734  45 / 286
2.0    15.0   0.0    250.0  0.0    1.0    0.0    3.0    0.0    2.0    0.0    0.0    3.0    1.0    0.0    2.0    1.0    7.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    1.0    0.140893470790378    41 / 291
0.0    2.0    1.0    0.0    246.0  3.0    13.0   1.0    0.0    0.0    2.0    3.0    0.0    0.0    0.0    1.0    2.0    2.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    7.0    0.14285714285714285  41 / 287
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    18.0   1.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    252.0  0.0    0.0    0.0    0.11267605633802817  32 / 284
1.0    2.0    0.0    2.0    8.0    3.0    2.0    0.0    1.0    1.0    10.0   2.0    0.0    0.0    2.0    0.0    0.0    1.0    3.0    1.0    1.0    0.0    0.0    248.0  2.0    4.0    0.1564625850340136   46 / 294
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    2.0    0.0    2.0    12.0   2.0    44.0   0.0    0.0    214.0  0.0    0.2517482517482518   72 / 286
3.0    0.0    0.0    0.0    23.0   0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    22.0   1.0    0.0    0.0    0.0    1.0    0.0    217.0  0.225                63 / 280
311.0  311.0  274.0  317.0  355.0  313.0  283.0  270.0  254.0  267.0  263.0  276.0  335.0  272.0  329.0  290.0  217.0  313.0  262.0  294.0  301.0  335.0  295.0  277.0  247.0  256.0  0.17706531861114808  1,331 / 7,517

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822935
2    0.910071
3    0.940668
4    0.958627
5    0.970467
6    0.97632
7    0.980843
8    0.984701
9    0.988692
10   0.990821
Cross-Validation Metrics Summary: 
                         mean      sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------------------  --------  -----------  ------------  ------------  ------------  ------------  ------------
accuracy                 0.822934  0.0104542    0.835106      0.815824      0.797738      0.827678      0.838323
err                      0.177066  0.0104542    0.164894      0.184176      0.202262      0.172322      0.161677
err_count                266.2     15.706       248           277           304           259           243
logloss                  0.596099  0.0330227    0.537969      0.646535      0.656047      0.573365      0.566579
max_per_class_error      0.40424   0.027569     0.393939      0.4           0.44          0.338983      0.448276
mean_per_class_accuracy  0.822721  0.00966592   0.834117      0.816709      0.799321      0.826325      0.837135
mean_per_class_error     0.177279  0.00966592   0.165883      0.183291      0.200679      0.173675      0.162865
mse                      0.162648  0.00661152   0.152492      0.171252      0.174965      0.162278      0.152251
r2                       0.997111  0.000110399  0.997263      0.996991      0.996881      0.997132      0.997287
rmse                     0.40313   0.00819196   0.390503      0.413826      0.418289      0.402837      0.390194
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:01:33  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:01:33  48.897 sec  17818 obs/sec     0.808301  1             6076       0.506473         0.905833            0.995445       0.257417                         0.516164           0.955808              0.995253         0.273494
    2019-07-24 13:01:36  51.578 sec  21091 obs/sec     8.03312   10            60385      0.320905         0.348589            0.998171       0.102568                         0.350902           0.445882              0.997806         0.125703
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0791364
C9          0.989789               0.989789             0.0783283
C15         0.974354               0.974354             0.0771069
C8          0.961309               0.961309             0.0760746
C12         0.892791               0.892791             0.0706523
C10         0.825004               0.825004             0.0652879
C6          0.821593               0.821593             0.065018
C14         0.808005               0.808005             0.0639426
C7          0.795172               0.795172             0.0629271
C11         0.783952               0.783952             0.0620392
C5          0.750306               0.750306             0.0593765
C16         0.702714               0.702714             0.0556102
C4          0.630567               0.630567             0.0499008
C1          0.576285               0.576285             0.0456051
C3          0.563445               0.563445             0.044589
C2          0.56112                0.56112              0.044405

model_id                                              mean_per_class_error    logloss      rmse       mse
--------------------------------------------------  ----------------------  ---------  --------  --------
DeepLearning_grid_1_AutoML_20190724_130033_model_3                0.178036   0.596098  0.403296  0.162648
DeepLearning_grid_1_AutoML_20190724_130033_model_1                0.178072   0.599088  0.423868  0.179664
DeepLearning_grid_1_AutoML_20190724_130033_model_4                0.18144    0.585337  0.429004  0.184044
DeepLearning_grid_1_AutoML_20190724_130033_model_2                0.208741   0.733345  0.435093  0.189306
DeepLearning_grid_1_AutoML_20190724_130033_model_5                0.214946   0.702897  0.44347   0.196666
DeepLearning_grid_1_AutoML_20190724_130033_model_6                0.215928   0.705334  0.467263  0.218335
DeepLearning_1_AutoML_20190724_130033                             0.400961   1.36557   0.645876  0.417156

[7 rows x 5 columns]

deeplearning prediction progress: |███████████████████████████████████████| 100%
Final acc, selected model:  86.64064845391775
Time consumed:  0.03422025687164731  hours
H2O session _sid_bd2b closed.
