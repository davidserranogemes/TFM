Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmpaho7zbaz
  JVM stdout: /tmp/tmpaho7zbaz/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmpaho7zbaz/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    8 days
H2O cluster name:           H2O_from_python_davidserranogemes_p0haeh
H2O cluster total nodes:    1
H2O cluster free memory:    1.922 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Guided  mode.

deeplearning Grid Build progress: |███████████████████████████████████████| 100%
deeplearning prediction progress: |███████████████████████████████████████| 100%
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_41

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.001889591907811905  0.00046081794425845146  0.0         -0.00785018983234842  0.17283445596694946  0.27817759413572674   0.11740243434906006
    3        26       Softmax                      0.0   0.0   0.009462477669199661  0.04731166362762451     0.0         -0.2149836659789885   0.39230239391326904  -0.49082284961015726  0.0941024124622345


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11197776230034058
RMSE: 0.33463078504575844
LogLoss: 0.36855499258651436
Mean Per-Class Error: 0.11004164151388363
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    1.0    1.0    0.0    0.0    0.0    1.0    0.0    2.0    4.0    2.0    4.0    0.0    0.0    1.0    0.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    3.0    3.0    0.07341772151898734  29 / 395
0.0    341.0  0.0    5.0    3.0    0.0    1.0    6.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    8.0    6.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.10966057441253264  42 / 383
0.0    0.0    334.0  0.0    6.0    0.0    9.0    1.0    0.0    0.0    5.0    2.0    0.0    0.0    4.0    0.0    1.0    1.0    2.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.09239130434782608  34 / 368
0.0    9.0    0.0    364.0  0.0    2.0    1.0    2.0    0.0    1.0    0.0    0.0    6.0    6.0    1.0    2.0    0.0    4.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.0967741935483871   39 / 403
0.0    0.0    2.0    0.0    337.0  4.0    18.0   1.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    1.0    2.0    2.0    1.0    2.0    0.0    0.0    0.0    3.0    0.0    5.0    0.12239583333333333  47 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    361.0  0.0    0.0    0.0    0.0398936170212766   15 / 376
0.0    0.0    0.0    5.0    3.0    1.0    0.0    1.0    2.0    4.0    3.0    5.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    359.0  2.0    3.0    0.08418367346938775  33 / 392
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    0.0    1.0    9.0    0.0    33.0   1.0    0.0    335.0  0.0    0.1475826972010178   58 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    5.0    0.0    3.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    0.0    341.0  0.07084468664850137  26 / 367
387.0  432.0  345.0  424.0  389.0  388.0  399.0  323.0  352.0  371.0  353.0  396.0  398.0  380.0  395.0  404.0  369.0  400.0  348.0  377.0  399.0  402.0  409.0  415.0  369.0  379.0  0.10966709987003899  1,097 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.890333
2    0.951215
3    0.971209
4    0.980606
5    0.986304
6    0.991003
7    0.993302
8    0.994901
9    0.996301
10   0.997601

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11260077895025243
RMSE: 0.3355603953839792
LogLoss: 0.3750451488227456
Mean Per-Class Error: 0.10916174255186786
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0    0.0    2.0    1.0   0.07865168539325842   7 / 89
0.0   88.0   0.0   1.0    2.0   0.0   1.0    2.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   5.0    2.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    71.0  0.0    2.0   0.0   4.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    2.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0    0.0    0.0   0.13414634146341464   11 / 82
0.0   1.0    0.0   102.0  0.0   1.0   0.0    1.0   0.0   0.0    0.0   0.0    2.0   1.0    0.0   1.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    1.0    0.0    1.0   0.08928571428571429   10 / 112
0.0   0.0    0.0   0.0    85.0  2.0   6.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0   0.12371134020618557   12 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   90.0   0.0    0.0    0.0   0.021739130434782608  2 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0    1.0   0.0   1.0    1.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    89.0   0.0    1.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   1.0    2.0   0.0    0.0   2.0   0.0    11.0  1.0    0.0    88.0   0.0   0.17757009345794392   19 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   1.0    0.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    80.0  0.08045977011494253   7 / 87
85.0  110.0  72.0  116.0  98.0  91.0  101.0  78.0  86.0  106.0  85.0  104.0  89.0  101.0  83.0  115.0  99.0  100.0  91.0  87.0  104.0  92.0  103.0  100.0  102.0  92.0  0.10963855421686747   273 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.890361
2    0.954618
3    0.969478
4    0.977108
5    0.983133
6    0.990763
7    0.99237
8    0.994779
9    0.995582
10   0.997189
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:10  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:10  1 min 47.933 sec  16458 obs/sec     1         1             10007      0.512036         0.875306            0.99534        0.252524                         0.512034           0.873442              0.995328         0.251406
    2019-07-24 13:11:15  1 min 52.344 sec  20310 obs/sec     10        10            100070     0.334631         0.368555            0.99801        0.109667                         0.33556            0.375045              0.997994         0.109639
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0826872
C13         0.944419               0.944419             0.0780913
C9          0.89255                0.89255              0.0738025
C8          0.882166               0.882166             0.0729438
C12         0.860944               0.860944             0.071189
C7          0.790852               0.790852             0.0653933
C10         0.770626               0.770626             0.0637209
C5          0.769574               0.769574             0.0636339
C11         0.748834               0.748834             0.0619189
C6          0.722088               0.722088             0.0597074
C14         0.69792                0.69792              0.057709
C16         0.654508               0.654508             0.0541195
C3          0.618817               0.618817             0.0511682
C4          0.616697               0.616697             0.050993
C1          0.587966               0.587966             0.0486173
C2          0.535812               0.535812             0.0443048
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_17

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019179426245727882  0.0004894074518233538  0.0         -0.00873727899403054  0.17285269498825073  0.2749425540274145    0.11057406663894653
    3        26       Softmax                      0.0   0.0   0.009753201588453591   0.046757444739341736   0.0         -0.22092963883529557  0.3926123380661011   -0.48240330613990984  0.07869243621826172


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.10882978515181455
RMSE: 0.32989359671235596
LogLoss: 0.3672939549724554
Mean Per-Class Error: 0.10448994775442132
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
370.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    3.0    2.0    3.0    0.0    0.0    0.0    0.0    2.0    2.0    1.0    0.0    1.0    1.0    1.0    3.0    2.0    0.06329113924050633  25 / 395
0.0    340.0  0.0    7.0    3.0    2.0    1.0    8.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    8.0    7.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    341.0  0.0    3.0    0.0    5.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    3.0    0.0    1.0    1.0    0.0    1.0    2.0    0.0    2.0    0.0    0.0    0.0    0.07336956521739131  27 / 368
0.0    9.0    0.0    361.0  0.0    0.0    1.0    3.0    0.0    2.0    2.0    0.0    5.0    4.0    0.0    2.0    0.0    7.0    2.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.10421836228287841  42 / 403
0.0    2.0    2.0    0.0    341.0  4.0    11.0   1.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    1.0    1.0    3.0    2.0    2.0    0.0    0.0    0.0    4.0    0.0    5.0    0.11197916666666667  43 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    359.0  0.0    0.0    0.0    0.04521276595744681  17 / 376
0.0    1.0    0.0    4.0    4.0    0.0    0.0    0.0    2.0    3.0    8.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    0.0    356.0  2.0    6.0    0.09644670050761421  38 / 394
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    10.0   1.0    10.0   1.0    3.0    354.0  0.0    0.09923664122137404  39 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    7.0    1.0    0.0    0.0    0.0    3.0    0.0    334.0  0.08991825613079019  33 / 367
389.0  419.0  372.0  417.0  405.0  398.0  349.0  345.0  337.0  379.0  387.0  359.0  398.0  380.0  387.0  399.0  376.0  408.0  396.0  388.0  396.0  370.0  406.0  408.0  372.0  363.0  0.10416874937518744  1,042 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.895831
2    0.949115
3    0.969109
4    0.979106
5    0.984505
6    0.988603
7    0.992102
8    0.993902
9    0.995301
10   0.997001

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11041896813168024
RMSE: 0.33229349697470795
LogLoss: 0.37620957414916395
Mean Per-Class Error: 0.10222031683933454
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
85.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0    2.0    1.0   0.0449438202247191    4 / 89
0.0   89.0   0.0   0.0    2.0    0.0   1.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    6.0    2.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.16037735849056603   17 / 106
0.0   0.0    76.0  0.0    1.0    0.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   1.0    0.0    0.0    0.0   0.07317073170731707   6 / 82
0.0   1.0    0.0   100.0  0.0    0.0   0.0   2.0   0.0   1.0    1.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   0.0    2.0    0.0    1.0   0.10714285714285714   12 / 112
0.0   0.0    0.0   0.0    86.0   3.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    2.0   0.1134020618556701    11 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   90.0   0.0    0.0    0.0   0.021739130434782608  2 / 92
0.0   0.0    0.0   2.0    2.0    0.0   0.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    89.0   0.0    3.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    1.0    0.0    0.0   2.0   0.0    2.0   1.0    1.0    96.0   0.0   0.102803738317757     11 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    80.0  0.08045977011494253   7 / 87
89.0  105.0  82.0  114.0  102.0  95.0  87.0  86.0  80.0  107.0  95.0  92.0  85.0  98.0  79.0  114.0  102.0  107.0  96.0  90.0  102.0  83.0  100.0  105.0  104.0  91.0  0.10240963855421686   255 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.89759
2    0.954618
3    0.96988
4    0.979518
5    0.982731
6    0.988353
7    0.991566
8    0.991968
9    0.993976
10   0.996386
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:12  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:13  50.554 sec  19776 obs/sec     1         1             10007      0.500924         0.854778            0.995541       0.238229                         0.503573           0.859536              0.995481         0.240964
    2019-07-24 13:10:17  55.031 sec  20422 obs/sec     10        10            100070     0.329894         0.367294            0.998066       0.104169                         0.332293           0.37621               0.998032         0.10241
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0853645
C13         0.932429               0.932429             0.0795964
C9          0.87837                0.87837              0.0749816
C8          0.866818               0.866818             0.0739955
C12         0.820143               0.820143             0.0700111
C10         0.786859               0.786859             0.0671698
C7          0.753203               0.753203             0.0642968
C5          0.7395                 0.7395               0.063127
C6          0.722766               0.722766             0.0616985
C11         0.669                  0.669                0.0571089
C14         0.64354                0.64354              0.0549354
C16         0.628788               0.628788             0.0536761
C3          0.588524               0.588524             0.050239
C4          0.584715               0.584715             0.0499139
C1          0.564139               0.564139             0.0481574
C2          0.535678               0.535678             0.0457279
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_21

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018552538976592814  0.0004847478121519089  0.0         -0.007249435111935876  0.16853857040405273  0.2717705555610748   0.12091779708862305
    3        26       Softmax                      0.0   0.0   0.008679995758720556   0.04213756322860718    0.0         -0.22175115998267905   0.3942854404449463   -0.4868448265856277  0.09761744737625122


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1113690093851907
RMSE: 0.3337199565282105
LogLoss: 0.371405465882287
Mean Per-Class Error: 0.1097177547600669
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
377.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    2.0    1.0    0.0    5.0    2.0    0.04556962025316456  18 / 395
1.0    340.0  1.0    4.0    2.0    0.0    1.0    9.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    7.0    0.0    0.0    3.0    0.0    2.0    2.0    1.0    0.1122715404699739   43 / 383
0.0    0.0    325.0  1.0    5.0    0.0    13.0   2.0    0.0    0.0    10.0   1.0    0.0    0.0    1.0    0.0    0.0    1.0    3.0    2.0    3.0    0.0    1.0    0.0    0.0    0.0    0.11684782608695653  43 / 368
1.0    12.0   0.0    356.0  0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    4.0    9.0    0.0    2.0    1.0    3.0    2.0    1.0    1.0    0.0    0.0    3.0    0.0    2.0    0.11662531017369727  47 / 403
0.0    0.0    4.0    0.0    324.0  4.0    19.0   4.0    0.0    0.0    3.0    3.0    0.0    0.0    0.0    0.0    3.0    1.0    1.0    3.0    0.0    0.0    0.0    3.0    0.0    12.0   0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    12.0   0.0    3.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    347.0  0.0    0.0    0.0    0.07466666666666667  28 / 375
0.0    1.0    0.0    4.0    2.0    0.0    0.0    1.0    2.0    4.0    11.0   1.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    4.0    1.0    0.0    0.0    350.0  2.0    5.0    0.1116751269035533   44 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0    1.0    1.0    2.0    3.0    1.0    0.0    380.0  0.0    0.03307888040712468  13 / 393
2.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    342.0  0.0681198910081744   25 / 367
408.0  433.0  346.0  395.0  364.0  365.0  412.0  359.0  348.0  373.0  391.0  359.0  407.0  391.0  359.0  382.0  400.0  352.0  375.0  379.0  428.0  375.0  378.0  391.0  448.0  385.0  0.10916724982505248  1,092 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.890833
2    0.948515
3    0.970909
4    0.979806
5    0.986304
6    0.989403
7    0.992602
8    0.994402
9    0.996001
10   0.997101

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11313483418030751
RMSE: 0.33635522023644515
LogLoss: 0.38074088635300674
Mean Per-Class Error: 0.11165648601717534
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16     17    18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    1.0   0.0   0.0    2.0    1.0   0.0449438202247191    4 / 89
0.0   88.0   0.0   0.0    2.0   0.0   1.0    3.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    1.0    1.0   1.0   0.0   0.0    3.0   0.0   1.0    1.0    1.0   0.16981132075471697   18 / 106
0.0   0.0    69.0  0.0    2.0   0.0   2.0    1.0   0.0   0.0    2.0   0.0   0.0   0.0    1.0   0.0    0.0    0.0   2.0   2.0   0.0    0.0   1.0   0.0    0.0    0.0   0.15853658536585366   13 / 82
1.0   1.0    0.0   99.0   0.0   0.0   0.0    1.0   0.0   0.0    1.0   0.0   2.0   2.0    0.0   2.0    0.0    0.0   1.0   0.0   0.0    0.0   0.0   1.0    0.0    1.0   0.11607142857142858   13 / 112
0.0   0.0    1.0   0.0    80.0  2.0   6.0    1.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0   1.0   0.0    0.0   0.0   1.0    0.0    3.0   0.17525773195876287   17 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   2.0    0.0   88.0  0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0    0.0   0.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   90.0   0.0    2.0   0.1                   10 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   0.0    1.0   1.0   0.0    102.0  0.0   0.04672897196261682   5 / 107
2.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    81.0  0.06896551724137931   6 / 87
93.0  105.0  73.0  108.0  92.0  84.0  103.0  93.0  86.0  107.0  96.0  93.0  88.0  102.0  76.0  112.0  100.0  85.0  92.0  87.0  108.0  85.0  95.0  102.0  131.0  94.0  0.1108433734939759    276 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.889157
2    0.949398
3    0.971084
4    0.980321
5    0.985542
6    0.988353
7    0.991968
8    0.993574
9    0.995582
10   0.99759
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:22  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:22  59.952 sec        19207 obs/sec     1         1             10007      0.499585         0.842367            0.995565       0.23293                          0.501634           0.849251              0.995516         0.239759
    2019-07-24 13:10:27  1 min  4.463 sec  20212 obs/sec     10        10            100070     0.33372          0.371405            0.998021       0.109167                         0.336355           0.380741              0.997984         0.110843
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0859662
C13         0.935342               0.935342             0.0804078
C8          0.850422               0.850422             0.0731076
C12         0.833505               0.833505             0.0716533
C9          0.821736               0.821736             0.0706415
C5          0.749081               0.749081             0.0643957
C7          0.743374               0.743374             0.0639051
C10         0.739444               0.739444             0.0635672
C11         0.709307               0.709307             0.0609765
C14         0.656602               0.656602             0.0564456
C6          0.642136               0.642136             0.055202
C16         0.636217               0.636217             0.0546931
C4          0.629715               0.629715             0.0541342
C3          0.601139               0.601139             0.0516776
C1          0.560567               0.560567             0.0481898
C2          0.52389                0.52389              0.0450369
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_4

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019357138252047434  0.0004711635410785675  0.0         -0.009039273302773099  0.16988933086395264  0.275357414543512    0.12371721863746643
    3        26       Softmax                      0.0   0.0   0.00860209104491962    0.04020339250564575    0.0         -0.21433882449000144   0.3919028043746948   -0.4782596781659168  0.09309709072113037


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11466292178786515
RMSE: 0.33861913972465457
LogLoss: 0.38165834972714785
Mean Per-Class Error: 0.11483038642523778
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    3.0    1.0    6.0    0.0    1.0    0.0    0.0    1.0    4.0    3.0    1.0    4.0    1.0    1.0    3.0    1.0    0.08607594936708861  34 / 395
0.0    331.0  2.0    7.0    1.0    4.0    1.0    13.0   1.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    7.0    10.0   0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.13577023498694518  52 / 383
0.0    0.0    332.0  0.0    6.0    0.0    2.0    2.0    0.0    0.0    12.0   1.0    2.0    0.0    3.0    0.0    0.0    1.0    4.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.09782608695652174  36 / 368
0.0    10.0   0.0    365.0  0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    7.0    5.0    2.0    0.0    0.0    5.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.09429280397022333  38 / 403
0.0    0.0    4.0    0.0    331.0  6.0    13.0   1.0    0.0    0.0    5.0    5.0    0.0    0.0    0.0    1.0    2.0    3.0    5.0    1.0    0.0    0.0    0.0    3.0    0.0    4.0    0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    18.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    345.0  0.0    0.0    0.0    0.08                 30 / 375
0.0    1.0    0.0    4.0    1.0    0.0    0.0    1.0    2.0    3.0    9.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    360.0  1.0    5.0    0.08629441624365482  34 / 394
0.0    0.0    0.0    2.0    0.0    12.0   0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    14.0   1.0    36.0   1.0    1.0    316.0  0.0    0.19592875318066158  77 / 393
0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    13.0   1.0    0.0    0.0    0.0    3.0    0.0    322.0  0.1226158038147139   45 / 367
372.0  390.0  382.0  421.0  380.0  428.0  340.0  379.0  340.0  373.0  400.0  368.0  438.0  386.0  379.0  388.0  398.0  376.0  451.0  364.0  393.0  398.0  370.0  410.0  331.0  348.0  0.11456563031090673  1,146 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.885434
2    0.947316
3    0.970409
4    0.979306
5    0.985204
6    0.989503
7    0.993502
8    0.994502
9    0.995801
10   0.997301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11716029527889393
RMSE: 0.3422868610959146
LogLoss: 0.3917098822545203
Mean Per-Class Error: 0.11435732122477742
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5      6     7     8     9      10     11    12    13    14    15     16     17    18     19    20     21    22    23    24    25    Error                Rate
----  ----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -------------------  -----------
82.0  0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0    0.0   1.0    0.0   0.0    1.0   0.0   0.0   2.0   0.0   0.07865168539325842  7 / 89
0.0   85.0  1.0   2.0    1.0   2.0    1.0   3.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0    4.0   3.0    0.0   0.0    1.0   0.0   1.0   0.0   0.0   0.19811320754716982  21 / 106
0.0   0.0   71.0  0.0    2.0   0.0    0.0   1.0   0.0   0.0    3.0    0.0   0.0   0.0   1.0   0.0    0.0    0.0   3.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.13414634146341464  11 / 82
0.0   0.0   0.0   103.0  0.0   0.0    0.0   1.0   0.0   1.0    0.0    0.0   3.0   1.0   0.0   0.0    0.0    0.0   1.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.08035714285714286  9 / 112
0.0   0.0   1.0   0.0    79.0  4.0    4.0   0.0   0.0   0.0    2.0    2.0   0.0   0.0   0.0   0.0    0.0    1.0   3.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0   0.18556701030927836  18 / 97
---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0    0.0   4.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0    0.0   87.0  0.0   0.0   0.0   0.05434782608695652  5 / 92
0.0   0.0   0.0   2.0    1.0   0.0    0.0   0.0   0.0   1.0    5.0    1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0    0.0   0.0   88.0  0.0   2.0   0.12                 12 / 100
0.0   0.0   0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   2.0    1.0    0.0   0.0    3.0   0.0    11.0  1.0   0.0   86.0  0.0   0.19626168224299065  21 / 107
0.0   0.0   0.0   0.0    5.0   0.0    0.0   0.0   0.0   2.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0    0.0   0.0    0.0   0.0   1.0   0.0   75.0  0.13793103448275862  12 / 87
85.0  92.0  81.0  121.0  92.0  106.0  91.0  94.0  84.0  108.0  106.0  95.0  97.0  98.0  81.0  116.0  102.0  92.0  115.0  80.0  101.0  88.0  93.0  98.0  92.0  82.0  0.11485943775100402  286 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.885141
2    0.950602
3    0.970281
4    0.978715
5    0.984337
6    0.987952
7    0.993574
8    0.994779
9    0.995984
10   0.997189
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:37  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:37  15.158 sec  15808 obs/sec     1         1             10007      0.500283         0.855329            0.995552       0.235329                         0.499918           0.854556              0.995547         0.240161
    2019-07-24 13:09:42  19.749 sec  19594 obs/sec     10        10            100070     0.338619         0.381658            0.997962       0.114566                         0.342287           0.39171               0.997912         0.114859
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0866459
C13         0.91046                0.91046              0.0788876
C9          0.852961               0.852961             0.0739055
C8          0.826529               0.826529             0.0716153
C12         0.7928                 0.7928               0.0686929
C10         0.767091               0.767091             0.0664653
C7          0.741615               0.741615             0.0642579
C5          0.713746               0.713746             0.0618432
C11         0.684096               0.684096             0.0592741
C6          0.662041               0.662041             0.0573631
C14         0.661797               0.661797             0.057342
C16         0.661766               0.661766             0.0573393
C4          0.590373               0.590373             0.0511534
C3          0.587778               0.587778             0.0509286
C2          0.560119               0.560119             0.048532
C1          0.528056               0.528056             0.0457539
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_26

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0019196688874814072  0.0005278207827359438  0.0         -0.01089772379501075  0.1694275140762329   0.1894029398663771   0.11564996838569641
    3        26       Softmax                      0.0   0.0   0.012160934174071021   0.05091962218284607    0.0         -0.20030548035903778  0.39667022228240967  -0.6370244007343319  0.1842171549797058


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12926668887013718
RMSE: 0.35953676984438904
LogLoss: 0.42465265926493784
Mean Per-Class Error: 0.11992715349013755
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    2.0    0.0    2.0    1.0    4.0    5.0    0.06852791878172589  27 / 394
0.0    338.0  0.0    2.0    3.0    0.0    0.0    6.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    21.0   6.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    324.0  0.0    8.0    0.0    7.0    1.0    0.0    0.0    13.0   2.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    4.0    1.0    0.0    0.0    0.11956521739130435  44 / 368
1.0    17.0   0.0    345.0  0.0    1.0    0.0    6.0    0.0    1.0    2.0    0.0    4.0    7.0    1.0    1.0    0.0    8.0    1.0    2.0    0.0    0.0    0.0    4.0    0.0    2.0    0.14392059553349876  58 / 403
0.0    4.0    2.0    0.0    322.0  2.0    20.0   0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    0.0    3.0    6.0    5.0    0.0    0.0    0.0    5.0    0.0    11.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    1.0    0.0    4.0    4.0    0.0    0.0    0.0    2.0    3.0    4.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    1.0    3.0    1.0    0.0    0.0    361.0  2.0    5.0    0.08375634517766498  33 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    10.0   3.0    7.0    1.0    0.0    363.0  0.0    0.07633587786259542  30 / 393
2.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    11.0   3.0    0.0    0.0    0.0    4.0    0.0    331.0  0.09562841530054644  35 / 366
392.0  439.0  347.0  397.0  392.0  347.0  403.0  332.0  342.0  345.0  370.0  354.0  390.0  392.0  390.0  391.0  365.0  447.0  401.0  402.0  410.0  361.0  397.0  427.0  389.0  381.0  0.11936419074277717  1,194 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.880636
2    0.939118
3    0.962711
4    0.973108
5    0.980806
6    0.985904
7    0.989203
8    0.992802
9    0.994302
10   0.995901

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1295990710798768
RMSE: 0.35999870983085036
LogLoss: 0.4288129556278478
Mean Per-Class Error: 0.11612019590702825
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0   0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   90.0   0.0   0.0    2.0   0.0   0.0    3.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   7.0    1.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0   0.1509433962264151    16 / 106
0.0   0.0    69.0  0.0    1.0   0.0   2.0    0.0   0.0   0.0    3.0   1.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   2.0   0.0    0.0   1.0   0.0    0.0    0.0   0.15853658536585366   13 / 82
1.0   2.0    0.0   98.0   0.0   1.0   0.0    2.0   0.0   0.0    1.0   0.0   1.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.125                 14 / 112
0.0   0.0    0.0   0.0    79.0  1.0   5.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0   2.0   0.0    0.0   0.0   2.0    0.0    4.0   0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   88.0  0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   90.0   0.0    3.0   0.1                   10 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   3.0   0.0    2.0   1.0   0.0    99.0   0.0   0.07476635514018691   8 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0   1.0    0.0    79.0  0.09195402298850575   8 / 87
89.0  106.0  73.0  113.0  95.0  77.0  101.0  82.0  84.0  100.0  92.0  94.0  82.0  105.0  86.0  112.0  99.0  112.0  95.0  99.0  104.0  79.0  98.0  103.0  111.0  99.0  0.11566265060240964   288 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.884337
2    0.941767
3    0.963052
4    0.973494
5    0.981526
6    0.985944
7    0.989558
8    0.991566
9    0.993574
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:36  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:37  1 min 14.372 sec  22387 obs/sec     1         1             10007      0.525865         0.917319            0.995084       0.248226                         0.526613           0.916271              0.995059         0.254618
    2019-07-24 13:10:40  1 min 18.097 sec  24557 obs/sec     10        10            100070     0.359537         0.424653            0.997702       0.119364                         0.359999           0.428813              0.997691         0.115663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0866919
C13         0.935158               0.935158             0.0810706
C8          0.833181               0.833181             0.07223
C7          0.828358               0.828358             0.0718119
C9          0.825558               0.825558             0.0715692
C12         0.782035               0.782035             0.0677961
C11         0.723912               0.723912             0.0627573
C5          0.723813               0.723813             0.0627487
C10         0.692512               0.692512             0.0600352
C6          0.686867               0.686867             0.0595458
C14         0.646443               0.646443             0.0560414
C16         0.63241                0.63241              0.0548248
C3          0.611206               0.611206             0.0529866
C4          0.587379               0.587379             0.050921
C2          0.514564               0.514564             0.0446085
C1          0.511708               0.511708             0.0443609
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_13

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.002640354008747181   0.0007439234759658575  0.0         -0.0018758064134547503  0.24669712781906128  0.007845479228960419  0.2795051336288452
    3        26       Softmax                 0.0   0.0   0.0037589994481620056  0.0017442191019654274  0.0         -0.0031772079468317736  0.35263240337371826  -0.591950366658328    0.0961047112941742


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12758912592933722
RMSE: 0.35719620088872334
LogLoss: 0.42577120508765254
Mean Per-Class Error: 0.12485662487445817
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
371.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    0.0    1.0    0.0    3.0    4.0    0.060759493670886074  24 / 395
0.0    307.0  0.0    15.0   3.0    4.0    2.0    14.0   0.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    2.0    14.0   10.0   0.0    0.0    1.0    0.0    3.0    1.0    2.0    0.19843342036553524   76 / 383
0.0    0.0    313.0  1.0    5.0    1.0    9.0    1.0    0.0    0.0    16.0   3.0    0.0    0.0    6.0    0.0    0.0    0.0    4.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.14945652173913043   55 / 368
1.0    5.0    0.0    366.0  0.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    6.0    5.0    1.0    0.0    0.0    5.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    3.0    0.08955223880597014   36 / 402
0.0    2.0    3.0    0.0    328.0  7.0    6.0    2.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    1.0    10.0   3.0    3.0    2.0    1.0    0.0    0.0    3.0    0.0    6.0    0.14583333333333334   56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    11.0   0.0    7.0    0.0    0.0    0.0    0.0    1.0    7.0    1.0    343.0  0.0    0.0    0.0    0.08533333333333333   32 / 375
0.0    0.0    0.0    5.0    4.0    3.0    0.0    1.0    2.0    1.0    13.0   3.0    0.0    0.0    0.0    0.0    6.0    0.0    4.0    2.0    1.0    0.0    0.0    338.0  3.0    7.0    0.13994910941475827   55 / 393
0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    5.0    2.0    8.0    1.0    1.0    364.0  0.0    0.0737913486005089    29 / 393
3.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    1.0    16.0   2.0    0.0    0.0    0.0    0.0    0.0    326.0  0.11171662125340599   41 / 367
405.0  355.0  329.0  456.0  381.0  431.0  333.0  359.0  336.0  362.0  420.0  356.0  404.0  364.0  407.0  362.0  405.0  402.0  457.0  358.0  435.0  365.0  371.0  381.0  397.0  372.0  0.1243626911926422    1,244 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875637
2    0.938119
3    0.962511
4    0.974708
5    0.982005
6    0.986104
7    0.989303
8    0.991703
9    0.993902
10   0.995601

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13107197178759078
RMSE: 0.3620386330042566
LogLoss: 0.4380486418351201
Mean Per-Class Error: 0.1261826156077731
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5      6     7     8     9      10     11    12    13    14    15     16     17     18     19    20     21    22    23    24     25    Error                Rate
----  ----  ----  -----  ----  -----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  -----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
85.0  0.0   0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.0449438202247191   4 / 89
0.0   78.0  0.0   7.0    2.0   1.0    2.0   4.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    5.0    4.0    0.0   0.0    1.0   0.0   1.0   1.0    0.0   0.2641509433962264   28 / 106
0.0   0.0   66.0  0.0    2.0   0.0    2.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   4.0   0.0    0.0    0.0    3.0    0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.1951219512195122   16 / 82
1.0   1.0   0.0   101.0  0.0   0.0    0.0   0.0   0.0   0.0    1.0    0.0   2.0   2.0   1.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   2.0   0.0    1.0   0.09821428571428571  11 / 112
0.0   0.0   1.0   0.0    81.0  5.0    2.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    3.0    1.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0    1.0   0.16494845360824742  16 / 97
---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---    ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    1.0    0.0   1.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   4.0    1.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0   0.0   2.0    1.0   0.0    0.0   0.0   0.0   0.0    6.0    2.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   85.0  0.0    4.0   0.15                 15 / 100
0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    3.0    0.0    0.0    1.0   0.0    5.0   1.0   0.0   97.0   0.0   0.09345794392523364  10 / 107
1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   0.0   1.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0    79.0  0.09195402298850575  8 / 87
94.0  85.0  70.0  128.0  93.0  102.0  86.0  89.0  83.0  105.0  106.0  96.0  87.0  97.0  87.0  101.0  100.0  101.0  105.0  82.0  111.0  85.0  93.0  94.0  115.0  95.0  0.12690763052208837  316 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873092
2    0.942169
3    0.963454
4    0.9751
5    0.981124
6    0.985542
7    0.989558
8    0.991968
9    0.993976
10   0.995984
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:59  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:00  37.797 sec  14523 obs/sec     1         1             10007      0.514161         0.891813            0.995301       0.245626                         0.512506           0.884271              0.99532          0.249799
    2019-07-24 13:10:05  43.076 sec  15342 obs/sec     9         9             90063      0.367604         0.450346            0.997598       0.129661                         0.370832           0.461449              0.99755          0.132129
    2019-07-24 13:10:06  43.840 sec  15338 obs/sec     10        10            100070     0.357196         0.425771            0.997732       0.124363                         0.362039           0.438049              0.997664         0.126908
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0882893
C15         0.991194               0.991194             0.0875119
C9          0.886189               0.886189             0.078241
C12         0.865065               0.865065             0.076376
C8          0.83092                0.83092              0.0733613
C10         0.752708               0.752708             0.0664561
C7          0.730586               0.730586             0.0645029
C11         0.706991               0.706991             0.0624197
C16         0.684641               0.684641             0.0604465
C5          0.65697                0.65697              0.0580034
C6          0.64019                0.64019              0.0565219
C14         0.621222               0.621222             0.0548473
C3          0.534053               0.534053             0.0471511
C4          0.529482               0.529482             0.0467476
C1          0.458785               0.458785             0.0405058
C2          0.437403               0.437403             0.038618
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_1

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018627201449561426  0.0004522089147940278  0.0         -0.010653331065826777  0.16945600509643555  0.1690299062783709   0.1247667670249939
    3        26       Softmax                      0.0   0.0   0.010960069846506625   0.04517702758312225    0.0         -0.19757753004430284   0.39776432514190674  -0.6594913055229529  0.1650504469871521


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1295549194037659
RMSE: 0.35993738261504027
LogLoss: 0.42723313061079016
Mean Per-Class Error: 0.12196441225265722
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    1.0    6.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    3.0    2.0    1.0    0.0    6.0    1.0    0.07848101265822785  31 / 395
0.0    338.0  0.0    5.0    1.0    0.0    0.0    3.0    1.0    0.0    2.0    1.0    0.0    0.0    0.0    2.0    4.0    12.0   9.0    0.0    0.0    1.0    0.0    1.0    3.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    325.0  0.0    9.0    0.0    4.0    1.0    0.0    0.0    8.0    1.0    0.0    0.0    3.0    0.0    0.0    1.0    2.0    4.0    8.0    0.0    2.0    0.0    0.0    0.0    0.11684782608695653  43 / 368
1.0    7.0    0.0    364.0  0.0    1.0    0.0    0.0    0.0    1.0    2.0    0.0    6.0    6.0    0.0    0.0    0.0    8.0    1.0    1.0    0.0    0.0    0.0    1.0    0.0    3.0    0.0945273631840796   38 / 402
0.0    5.0    3.0    0.0    324.0  3.0    17.0   0.0    0.0    0.0    7.0    5.0    0.0    0.0    0.0    1.0    3.0    3.0    3.0    1.0    0.0    0.0    0.0    3.0    0.0    6.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    0.0    0.0    4.0    5.0    0.0    0.0    1.0    2.0    4.0    6.0    1.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    1.0    1.0    0.0    0.0    356.0  2.0    5.0    0.09644670050761421  38 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    3.0    2.0    8.0    1.0    0.0    363.0  0.0    0.07397959183673469  29 / 392
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    15.0   1.0    0.0    0.0    0.0    1.0    0.0    326.0  0.11171662125340599  41 / 367
391.0  414.0  366.0  441.0  384.0  404.0  335.0  282.0  344.0  375.0  390.0  372.0  415.0  380.0  374.0  376.0  377.0  443.0  418.0  364.0  421.0  376.0  405.0  392.0  405.0  359.0  0.12136359092272318  1,214 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.878636
2    0.940218
3    0.963311
4    0.974408
5    0.981406
6    0.986104
7    0.989203
8    0.992402
9    0.994502
10   0.996101

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13178105960701803
RMSE: 0.3630166106489041
LogLoss: 0.4391544752598762
Mean Per-Class Error: 0.12410142646420323
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   89.0   0.0   0.0    1.0   0.0   0.0   1.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   1.0    2.0   5.0    3.0    0.0   0.0    1.0   0.0    1.0   1.0    0.0   0.16037735849056603  17 / 106
0.0   0.0    69.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0    3.0   1.0    0.0   1.0    0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   1.0    0.0   102.0  0.0   1.0   0.0   0.0   0.0   0.0    1.0    0.0   2.0   2.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.08928571428571429  10 / 112
0.0   0.0    1.0   0.0    79.0  2.0   5.0   0.0   0.0   0.0    2.0    1.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0    0.0   0.0    0.0   0.0    1.0   0.0    3.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   1.0    3.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    89.0  0.0    2.0   0.11                 11 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.0   0.0    2.0   1.0    0.0   100.0  0.0   0.06542056074766354  7 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0    0.0   0.0    0.0   0.0    0.0   0.0    77.0  0.11494252873563218  10 / 87
91.0  102.0  77.0  122.0  93.0  96.0  85.0  67.0  84.0  108.0  102.0  95.0  95.0  102.0  78.0  110.0  97.0  108.0  105.0  84.0  101.0  83.0  101.0  99.0  117.0  88.0  0.12329317269076305  307 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876707
2    0.939357
3    0.963052
4    0.973092
5    0.978715
6    0.983936
7    0.987952
8    0.99237
9    0.994378
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:23  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:24  1.933 sec   17373 obs/sec     1         1             10007      0.521538         0.902871            0.995166       0.249925                         0.522063           0.91234               0.995144         0.25261
    2019-07-24 13:09:29  7.037 sec   19126 obs/sec     10        10            100070     0.359937         0.427233            0.997697       0.121364                         0.363017           0.439154              0.997652         0.123293
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0846377
C13         0.952928               0.952928             0.0806536
C8          0.879144               0.879144             0.0744087
C9          0.83881                0.83881              0.070995
C12         0.832427               0.832427             0.0704547
C7          0.798966               0.798966             0.0676227
C5          0.759215               0.759215             0.0642582
C11         0.751984               0.751984             0.0636462
C10         0.742318               0.742318             0.0628281
C6          0.679669               0.679669             0.0575256
C16         0.650307               0.650307             0.0550405
C14         0.641603               0.641603             0.0543038
C4          0.613819               0.613819             0.0519522
C3          0.612265               0.612265             0.0518207
C1          0.532579               0.532579             0.0450762
C2          0.529034               0.529034             0.0447762
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_27

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0014418299592762196  0.000365671468898654  0.0         -0.009878148358016148  0.2054229974746704  0.23183976982148616  0.1579403281211853
    3        26       Softmax                      0.0   0.0   0.008583419341553404   0.03662675619125366   0.0         -0.2596449305881991    0.5118827819824219  -0.4953394560199049  0.1887737512588501


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13421114560653002
RMSE: 0.36634839375453804
LogLoss: 0.43965517873866305
Mean Per-Class Error: 0.1267817852679511
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    2.0    4.0    3.0    2.0    1.0    0.0    0.0    4.0    2.0    1.0    1.0    2.0    3.0    5.0    0.0    0.09620253164556962  38 / 395
0.0    337.0  0.0    5.0    3.0    1.0    0.0    7.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    8.0    1.0    7.0    10.0   1.0    0.0    1.0    0.0    1.0    0.0    0.0    0.12010443864229765  46 / 383
0.0    0.0    339.0  1.0    6.0    0.0    2.0    1.0    0.0    0.0    8.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    4.0    0.0    0.0    0.0    0.07629427792915532  28 / 367
1.0    11.0   0.0    355.0  0.0    2.0    0.0    2.0    0.0    1.0    2.0    0.0    7.0    5.0    1.0    7.0    0.0    3.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.11910669975186104  48 / 403
0.0    4.0    0.0    0.0    315.0  8.0    13.0   2.0    0.0    0.0    7.0    5.0    0.0    0.0    0.0    1.0    6.0    3.0    7.0    3.0    0.0    0.0    0.0    4.0    0.0    6.0    0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    20.0   1.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    1.0    0.0    4.0    4.0    1.0    0.0    1.0    3.0    4.0    13.0   5.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    2.0    1.0    0.0    0.0    345.0  2.0    3.0    0.12436548223350254  49 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    13.0   3.0    11.0   1.0    0.0    351.0  0.0    0.10687022900763359  42 / 393
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    13.0   2.0    0.0    0.0    0.0    1.0    0.0    323.0  0.11748633879781421  43 / 366
373.0  426.0  384.0  420.0  390.0  397.0  359.0  339.0  349.0  381.0  379.0  368.0  438.0  383.0  396.0  434.0  361.0  392.0  396.0  376.0  399.0  363.0  388.0  390.0  374.0  348.0  0.12646206138158553  1,265 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873538
2    0.937019
3    0.959712
4    0.971808
5    0.980606
6    0.985904
7    0.989103
8    0.992202
9    0.994202
10   0.996501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13561129505345298
RMSE: 0.3682543890484579
LogLoss: 0.4465018410103051
Mean Per-Class Error: 0.1254746459538214
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17    18    19    20    21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   1.0   2.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   88.0   0.0   1.0    2.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0   4.0   4.0   0.0   0.0   1.0   0.0   1.0   0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    76.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   2.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0    0.0   0.07317073170731707  6 / 82
1.0   2.0    0.0   96.0   0.0   1.0   0.0   1.0   0.0   0.0    1.0   0.0   3.0    1.0   1.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    76.0  5.0   4.0   0.0   0.0   0.0    1.0   1.0   0.0    0.0   0.0   0.0    2.0   1.0   4.0   1.0   0.0   0.0   0.0   1.0   0.0    1.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0   1.0   0.0   1.0   0.0   1.0    3.0   3.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   85.0  0.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0   3.0   0.0   4.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0   1.0   0.0    78.0  0.10344827586206896  9 / 87
87.0  111.0  83.0  108.0  93.0  98.0  96.0  84.0  84.0  111.0  92.0  97.0  100.0  99.0  88.0  121.0  94.0  99.0  99.0  84.0  99.0  81.0  96.0  96.0  105.0  85.0  0.12650602409638553  315 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873494
2    0.935743
3    0.959036
4    0.969478
5    0.97992
6    0.983936
7    0.986747
8    0.990763
9    0.993173
10   0.996386
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:41  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:41  1 min 18.519 sec  30696 obs/sec     1         1             10007      0.531112         0.913472            0.994986       0.246226                         0.52998            0.905605              0.994995         0.251004
    2019-07-24 13:10:43  1 min 20.781 sec  39459 obs/sec     10        10            100070     0.366348         0.439655            0.997614       0.126462                         0.368254           0.446502              0.997584         0.126506
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0805951
C8          0.962441               0.962441             0.0775681
C15         0.942081               0.942081             0.0759271
C12         0.916594               0.916594             0.073873
C9          0.903669               0.903669             0.0728313
C7          0.842008               0.842008             0.0678617
C11         0.801142               0.801142             0.0645682
C5          0.797027               0.797027             0.0642365
C10         0.791043               0.791043             0.0637542
C6          0.712844               0.712844             0.0574518
C4          0.67627                0.67627              0.0545041
C14         0.662545               0.662545             0.0533979
C16         0.645013               0.645013             0.0519849
C3          0.610011               0.610011             0.0491639
C1          0.582651               0.582651             0.0469588
C2          0.562361               0.562361             0.0453235
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_33

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0012712470854125968  0.0003463132306933403  0.0         -0.0054390897775604685  0.20094865560531616  0.2484026312358089   0.14559799432754517
    3        26       Softmax                      0.0   0.0   0.007893620030524918   0.038396626710891724   0.0         -0.2482852377272593     0.5166802406311035   -0.4860755184652354  0.13798218965530396


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13594734301414046
RMSE: 0.36871037822949937
LogLoss: 0.4488766190074128
Mean Per-Class Error: 0.1285127918362024
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
365.0  0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    3.0    0.0    1.0    0.0    0.0    1.0    2.0    1.0    2.0    2.0    2.0    2.0    4.0    1.0    0.0759493670886076    30 / 395
0.0    340.0  0.0    9.0    1.0    1.0    3.0    5.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    1.0    0.0    3.0    10.0   0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.1099476439790576    42 / 382
0.0    0.0    317.0  0.0    15.0   0.0    8.0    1.0    0.0    0.0    6.0    2.0    0.0    0.0    6.0    0.0    0.0    1.0    2.0    2.0    4.0    0.0    3.0    0.0    0.0    0.0    0.1362397820163488    50 / 367
1.0    14.0   0.0    360.0  0.0    2.0    1.0    3.0    0.0    1.0    2.0    0.0    5.0    5.0    2.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.10669975186104218   43 / 403
0.0    5.0    2.0    0.0    324.0  3.0    18.0   1.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    1.0    2.0    3.0    2.0    7.0    0.0    0.0    0.0    3.0    0.0    7.0    0.15625               60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    1.0    0.0    0.0    2.0    0.0    1.0    4.0    3.0    352.0  0.0    0.0    0.0    0.06382978723404255   24 / 376
0.0    0.0    0.0    4.0    5.0    1.0    0.0    1.0    3.0    3.0    6.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    358.0  1.0    5.0    0.09137055837563451   36 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    10.0   0.0    2.0    1.0    0.0    369.0  0.0    0.058673469387755105  23 / 392
2.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    5.0    0.0    0.0    0.0    1.0    0.0    335.0  0.08719346049046321   32 / 367
395.0  457.0  348.0  438.0  397.0  395.0  384.0  313.0  351.0  368.0  358.0  371.0  400.0  377.0  415.0  361.0  336.0  379.0  362.0  397.0  414.0  371.0  400.0  408.0  422.0  386.0  0.12796161151654503   1,280 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.872038
2    0.936719
3    0.959912
4    0.972808
5    0.979506
6    0.985204
7    0.989703
8    0.993302
9    0.995001
10   0.996301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13746518137890304
RMSE: 0.37076297196309
LogLoss: 0.4562249351776383
Mean Per-Class Error: 0.12416161467722656
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17    18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   89.0   0.0   2.0    1.0   0.0   1.0   2.0   1.0   0.0    1.0   0.0   0.0   0.0    1.0   0.0    0.0   2.0   3.0   0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.16037735849056603   17 / 106
0.0   0.0    68.0  0.0    4.0   0.0   3.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   1.0   1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.17073170731707318   14 / 82
1.0   2.0    0.0   98.0   0.0   1.0   0.0   2.0   0.0   0.0    1.0   0.0   1.0   2.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.125                 14 / 112
0.0   0.0    0.0   0.0    80.0  2.0   6.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   1.0   1.0   3.0   0.0    0.0   0.0   1.0    0.0    1.0   0.17525773195876287   17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652   5 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   90.0   0.0    3.0   0.1                   10 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0    2.0   1.0   0.0    101.0  0.0   0.056074766355140186  6 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0   1.0    0.0    76.0  0.12643678160919541   11 / 87
91.0  117.0  71.0  122.0  97.0  92.0  95.0  80.0  86.0  105.0  94.0  97.0  87.0  100.0  89.0  100.0  89.0  96.0  96.0  95.0  103.0  82.0  97.0  102.0  119.0  88.0  0.12449799196787148   310 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.875502
2    0.939357
3    0.956225
4    0.972691
5    0.978715
6    0.98514
7    0.988353
8    0.991968
9    0.993574
10   0.995181
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:54  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:54  1 min 31.856 sec  34388 obs/sec     1         1             10007      0.532677         0.920829            0.994956       0.248425                         0.532541           0.924476              0.994947         0.246586
    2019-07-24 13:10:57  1 min 34.231 sec  38223 obs/sec     10        10            100070     0.36871          0.448877            0.997583       0.127962                         0.370763           0.456225              0.997551         0.124498
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0856605
C15         0.961125               0.961125             0.0823304
C8          0.86722                0.86722              0.0742865
C12         0.840926               0.840926             0.0720341
C9          0.802992               0.802992             0.0687847
C7          0.787524               0.787524             0.0674597
C11         0.736372               0.736372             0.0630779
C10         0.728726               0.728726             0.062423
C5          0.724188               0.724188             0.0620343
C14         0.674331               0.674331             0.0577635
C6          0.637108               0.637108             0.054575
C16         0.630998               0.630998             0.0540516
C4          0.61512                0.61512              0.0526915
C3          0.601852               0.601852             0.0515549
C1          0.551239               0.551239             0.0472194
C2          0.514274               0.514274             0.044053
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_29

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.001353038112398508  0.0003528118832036853  0.0         -0.011563701387728997  0.20192503929138184  0.2507208303413765    0.1454734206199646
    3        26       Softmax                      0.0   0.0   0.00829106322570484   0.0462317168712616     0.0         -0.24382565928590338   0.514533519744873    -0.49394324110416277  0.15457093715667725


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13829154311649222
RMSE: 0.37187570923158214
LogLoss: 0.4542656900072636
Mean Per-Class Error: 0.13196387191742506
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    1.0    3.0    4.0    1.0    0.0    0.0    0.0    2.0    1.0    0.0    1.0    1.0    1.0    2.0    3.0    2.0    0.0759493670886076   30 / 395
0.0    332.0  1.0    8.0    1.0    5.0    2.0    5.0    3.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    2.0    10.0   5.0    0.0    0.0    2.0    0.0    3.0    1.0    0.0    0.13315926892950392  51 / 383
0.0    0.0    328.0  0.0    10.0   0.0    6.0    1.0    0.0    0.0    2.0    5.0    0.0    0.0    7.0    0.0    1.0    1.0    0.0    3.0    4.0    0.0    0.0    0.0    0.0    0.0    0.10869565217391304  40 / 368
0.0    11.0   0.0    355.0  0.0    1.0    0.0    3.0    0.0    5.0    1.0    1.0    4.0    3.0    2.0    0.0    0.0    6.0    1.0    0.0    2.0    0.0    0.0    2.0    0.0    6.0    0.11910669975186104  48 / 403
0.0    3.0    1.0    0.0    324.0  4.0    19.0   0.0    0.0    0.0    3.0    8.0    0.0    0.0    0.0    1.0    3.0    3.0    2.0    2.0    0.0    0.0    0.0    3.0    0.0    8.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    14.0   1.0    4.0    0.0    0.0    3.0    0.0    0.0    2.0    5.0    341.0  0.0    0.0    0.0    0.09066666666666667  34 / 375
0.0    1.0    0.0    4.0    2.0    0.0    0.0    3.0    2.0    2.0    5.0    5.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    354.0  3.0    5.0    0.09923664122137404  39 / 393
0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    3.0    1.0    0.0    1.0    15.0   1.0    12.0   1.0    0.0    352.0  0.0    0.10432569974554708  41 / 393
2.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    5.0    3.0    0.0    0.0    0.0    3.0    0.0    325.0  0.11444141689373297  42 / 367
395.0  457.0  353.0  419.0  391.0  390.0  361.0  330.0  358.0  378.0  339.0  412.0  407.0  383.0  402.0  371.0  351.0  427.0  338.0  395.0  405.0  385.0  372.0  407.0  390.0  387.0  0.13136059182245327  1,314 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.868639
2    0.93442
3    0.957913
4    0.970509
5    0.979906
6    0.985704
7    0.989903
8    0.992502
9    0.994302
10   0.996201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14048763321385652
RMSE: 0.37481679953526165
LogLoss: 0.46571078247838327
Mean Per-Class Error: 0.1277738906079968
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   86.0   0.0   2.0    1.0   1.0   1.0   2.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0    0.0   4.0    2.0   0.0   0.0    2.0   0.0   1.0    1.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    73.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0   0.0    0.0    0.0   0.10975609756097561   9 / 82
0.0   2.0    0.0   99.0   0.0   0.0   0.0   1.0   0.0   2.0    0.0   1.0    1.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.11607142857142858   13 / 112
0.0   0.0    0.0   0.0    79.0  3.0   7.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0   1.0    0.0    2.0   0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    3.0   84.0  0.0    0.0    0.0   0.08695652173913043   8 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   2.0   0.0   0.0    2.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   89.0   1.0    1.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   1.0    1.0   0.0    0.0   4.0   0.0    6.0   1.0   0.0    93.0   0.0   0.1308411214953271    14 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0    77.0  0.11494252873563218   10 / 87
90.0  121.0  78.0  115.0  91.0  94.0  92.0  79.0  91.0  107.0  86.0  106.0  87.0  103.0  87.0  104.0  91.0  108.0  85.0  94.0  100.0  90.0  91.0  101.0  106.0  93.0  0.1285140562248996    320 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871486
2    0.932129
3    0.95502
4    0.966667
5    0.976707
6    0.983534
7    0.987952
8    0.991165
9    0.993173
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:46  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:46  1 min 23.577 sec  27416 obs/sec     1         1             10007      0.532389         0.93929             0.994963       0.247326                         0.532767           0.939381              0.994942         0.250602
    2019-07-24 13:10:48  1 min 25.874 sec  38666 obs/sec     10        10            100070     0.371876         0.454266            0.997542       0.131361                         0.374817           0.465711              0.997497         0.128514
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0861553
C13         0.926027               0.926027             0.0797822
C9          0.858103               0.858103             0.0739301
C8          0.831051               0.831051             0.0715994
C7          0.817318               0.817318             0.0704162
C12         0.781647               0.781647             0.067343
C10         0.75079                0.75079              0.0646846
C5          0.746624               0.746624             0.0643256
C11         0.735376               0.735376             0.0633565
C14         0.658874               0.658874             0.0567655
C6          0.646985               0.646985             0.0557412
C4          0.613388               0.613388             0.0528466
C16         0.611759               0.611759             0.0527062
C3          0.578023               0.578023             0.0497998
C2          0.540435               0.540435             0.0465614
C1          0.510546               0.510546             0.0439862
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_25

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0020027496448449256  0.0006213674787431955  0.0         0.0003188430282534682  0.3416208028793335   0.04878456829050887  0.37158286571502686
    3        26       Softmax                 0.0   0.0   0.002976833690074552   0.0012423493899405003  0.0         -0.01555586149568346   0.44081640243530273  -0.5324147409394518  0.1850910782814026


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13636923042948623
RMSE: 0.3692820472612854
LogLoss: 0.46348173505567986
Mean Per-Class Error: 0.13112946278574655
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    2.0    1.0    4.0    0.0    1.0    0.0    0.0    2.0    6.0    0.0    2.0    0.0    1.0    2.0    5.0    0.0    0.08860759493670886  35 / 395
0.0    344.0  0.0    9.0    4.0    0.0    1.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    6.0    5.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    0.10182767624020887  39 / 383
0.0    0.0    327.0  1.0    8.0    0.0    3.0    0.0    0.0    0.0    12.0   1.0    0.0    0.0    4.0    0.0    2.0    1.0    3.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.10899182561307902  40 / 367
0.0    15.0   0.0    367.0  0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    5.0    3.0    0.0    1.0    0.0    2.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    2.0    0.08933002481389578  36 / 403
0.0    3.0    0.0    0.0    334.0  7.0    10.0   1.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    7.0    2.0    6.0    2.0    0.0    0.0    0.0    3.0    0.0    7.0    0.13020833333333334  50 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    10.0   0.0    3.0    0.0    0.0    2.0    0.0    0.0    8.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    0.0    0.0    6.0    9.0    1.0    0.0    2.0    4.0    3.0    2.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    355.0  3.0    3.0    0.09898477157360407  39 / 394
0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    18.0   1.0    9.0    1.0    1.0    353.0  0.0    0.10178117048346055  40 / 393
0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    20.0   3.0    0.0    0.0    0.0    0.0    0.0    327.0  0.10899182561307902  40 / 367
387.0  490.0  353.0  458.0  416.0  373.0  319.0  303.0  340.0  369.0  360.0  364.0  392.0  391.0  381.0  404.0  378.0  408.0  379.0  386.0  429.0  365.0  378.0  417.0  391.0  372.0  0.13036089173248025  1,304 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869639
2    0.93282
3    0.954913
4    0.969109
5    0.977207
6    0.982505
7    0.986404
8    0.989603
9    0.991603
10   0.993402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13810737358946767
RMSE: 0.371628004312737
LogLoss: 0.4660015804285876
Mean Per-Class Error: 0.13099478399487544
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0   0.0   3.0    0.0   0.06741573033707865  6 / 89
0.0   92.0   0.0   3.0    3.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   3.0    1.0   0.0   0.0    0.0   1.0   1.0   0.0    0.0   0.1320754716981132   14 / 106
0.0   0.0    73.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.10975609756097561  9 / 82
0.0   1.0    0.0   103.0  0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   1.0    0.0   1.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0   1.0   0.0    1.0   0.08035714285714286  9 / 112
0.0   0.0    0.0   0.0    81.0  4.0   3.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    3.0   0.0   0.0    0.0   0.0   1.0   0.0    2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0   3.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    3.0   0.0   0.0   1.0   0.0   1.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   88.0  1.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   5.0   0.0    5.0   1.0   0.0   93.0   0.0   0.1308411214953271   14 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    79.0  0.09195402298850575  8 / 87
87.0  131.0  76.0  131.0  99.0  87.0  74.0  72.0  81.0  106.0  93.0  97.0  81.0  105.0  81.0  115.0  97.0  101.0  98.0  90.0  112.0  83.0  95.0  99.0  109.0  90.0  0.13012048192771083  324 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86988
2    0.938153
3    0.958635
4    0.971084
5    0.978715
6    0.982731
7    0.987149
8    0.98996
9    0.991566
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:32  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:33  1 min 10.388 sec  29346 obs/sec     1         1             10007      0.537367         0.94861             0.994869       0.258722                         0.536925           0.941659              0.994863         0.267871
    2019-07-24 13:10:36  1 min 13.821 sec  26973 obs/sec     10        10            100070     0.369282         0.463482            0.997577       0.130361                         0.371628           0.466002              0.997539         0.13012
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.09342
C13         0.911227               0.911227             0.0851268
C9          0.837805               0.837805             0.0782678
C8          0.829074               0.829074             0.0774521
C12         0.768863               0.768863             0.0718272
C7          0.738317               0.738317             0.0689736
C10         0.696762               0.696762             0.0650915
C11         0.680737               0.680737             0.0635944
C16         0.634356               0.634356             0.0592616
C14         0.60744                0.60744              0.056747
C5          0.581575               0.581575             0.0543307
C6          0.572074               0.572074             0.0534431
C2          0.472784               0.472784             0.0441675
C4          0.472543               0.472543             0.0441449
C3          0.460543               0.460543             0.0430239
C1          0.440249               0.440249             0.041128
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_24

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.001917002240901411  0.0005343102384358644  0.0         0.014492132390586221    0.3371185064315796   0.00502582897143817  0.37575745582580566
    3        26       Softmax                 0.0   0.0   0.003161917202515514  0.001117104198783636   0.0         -0.0002869639569535838  0.45015108585357666  -0.5419611455000641  0.1479364037513733


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14080843011862917
RMSE: 0.3752444937885554
LogLoss: 0.470231366276394
Mean Per-Class Error: 0.13684038895659476
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    8.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    2.0    0.0    0.0    2.0    4.0    3.0    0.09620253164556962  38 / 395
0.0    315.0  0.0    7.0    3.0    2.0    1.0    5.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    32.0   6.0    0.0    0.0    2.0    0.0    3.0    2.0    0.0    0.17539267015706805  67 / 382
0.0    0.0    318.0  1.0    11.0   1.0    9.0    1.0    0.0    0.0    9.0    1.0    0.0    0.0    7.0    0.0    0.0    1.0    3.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.1358695652173913   50 / 368
1.0    9.0    0.0    350.0  0.0    0.0    0.0    4.0    0.0    6.0    0.0    0.0    6.0    4.0    3.0    0.0    0.0    14.0   3.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.1315136476426799   53 / 403
0.0    1.0    3.0    0.0    335.0  2.0    11.0   0.0    0.0    0.0    4.0    3.0    0.0    0.0    0.0    1.0    5.0    6.0    4.0    0.0    1.0    0.0    0.0    3.0    0.0    5.0    0.12760416666666666  49 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    9.0    0.0    5.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    354.0  0.0    0.0    0.0    0.05851063829787234  22 / 376
0.0    0.0    0.0    4.0    5.0    0.0    0.0    2.0    4.0    2.0    6.0    1.0    0.0    0.0    2.0    0.0    0.0    1.0    1.0    1.0    1.0    0.0    0.0    358.0  3.0    3.0    0.09137055837563451  36 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    6.0    0.0    1.0    20.0   1.0    33.0   2.0    4.0    315.0  1.0    0.1984732824427481   78 / 393
0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    22.0   2.0    0.0    0.0    0.0    0.0    0.0    310.0  0.1553133514986376   57 / 367
382.0  407.0  337.0  413.0  420.0  398.0  347.0  304.0  331.0  397.0  361.0  360.0  426.0  369.0  392.0  377.0  375.0  508.0  399.0  386.0  409.0  377.0  407.0  422.0  350.0  349.0  0.13625912226332101  1,363 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.863741
2    0.931321
3    0.958113
4    0.970009
5    0.978207
6    0.984305
7    0.988104
8    0.990203
9    0.992302
10   0.994602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1444279271038279
RMSE: 0.3800367444127316
LogLoss: 0.4813785696713536
Mean Per-Class Error: 0.1412338700891215
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18     19    20     21    22     23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  ----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   2.0    2.0   0.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0   9.0    1.0    0.0   0.0    2.0   0.0    1.0    0.0   0.0   0.19811320754716982  21 / 106
0.0   0.0    69.0  0.0    2.0   1.0   3.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    2.0    0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.15853658536585366  13 / 82
1.0   1.0    0.0   97.0   0.0   0.0   0.0   2.0   0.0   2.0    0.0   0.0   3.0   1.0   0.0   0.0    0.0   1.0    2.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0   0.13392857142857142  15 / 112
0.0   0.0    1.0   0.0    81.0  1.0   3.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0   0.0   0.0    1.0   1.0    3.0    0.0   0.0    0.0   0.0    1.0    0.0   2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   89.0   0.0    0.0   0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   1.0    3.0   0.0   0.0   1.0   1.0   1.0    2.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    88.0   1.0   1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0    0.0    6.0   0.0    10.0  1.0    0.0    85.0  0.0   0.205607476635514    22 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    0.0   0.0    0.0   0.0    0.0    0.0   75.0  0.13793103448275862  12 / 87
87.0  102.0  74.0  113.0  99.0  93.0  86.0  80.0  82.0  115.0  88.0  95.0  98.0  95.0  80.0  108.0  98.0  124.0  102.0  90.0  102.0  86.0  104.0  108.0  97.0  84.0  0.14096385542168674  351 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.859036
2    0.931727
3    0.95743
4    0.96988
5    0.978313
6    0.983936
7    0.988353
8    0.990763
9    0.99237
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:29  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:29  1 min  6.718 sec  23997 obs/sec     1         1             10007      0.535015         0.944573            0.994913       0.255223                         0.536223           0.949059              0.994877         0.256627
    2019-07-24 13:10:32  1 min  9.963 sec  27743 obs/sec     10        10            100070     0.375244         0.470231            0.997497       0.136259                         0.380037           0.481379              0.997427         0.140964
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0928073
C15         0.960984               0.960984             0.0891863
C9          0.832332               0.832332             0.0772465
C12         0.800293               0.800293             0.074273
C8          0.797468               0.797468             0.0740109
C7          0.731315               0.731315             0.0678713
C11         0.711512               0.711512             0.0660335
C10         0.69418                0.69418              0.0644249
C16         0.643476               0.643476             0.0597193
C14         0.602359               0.602359             0.0559033
C6          0.587876               0.587876             0.0545591
C5          0.569757               0.569757             0.0528776
C3          0.527692               0.527692             0.0489736
C4          0.49409                0.49409              0.0458551
C2          0.432005               0.432005             0.0400932
C1          0.38968                0.38968              0.0361652
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_11

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013050856255176768  0.0003623192897066474  0.0         -0.009375244182812992  0.2023717761039734  0.13216871298033658  0.15201044082641602
    3        26       Softmax                      0.0   0.0   0.008511931439023521   0.032127365469932556   0.0         -0.23071164009161294   0.524071455001831   -0.6303398949520999  0.2656431198120117


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16171492185669945
RMSE: 0.4021379388427551
LogLoss: 0.5198132791729055
Mean Per-Class Error: 0.14977594522662557
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    5.0    1.0    5.0    0.0    2.0    0.0    0.0    1.0    6.0    0.0    2.0    2.0    2.0    3.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    346.0  0.0    4.0    1.0    1.0    1.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    12.0   7.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.09660574412532637  37 / 383
0.0    0.0    302.0  0.0    15.0   1.0    9.0    1.0    0.0    0.0    22.0   0.0    0.0    0.0    4.0    0.0    3.0    0.0    2.0    3.0    2.0    0.0    3.0    0.0    0.0    0.0    0.1771117166212534   65 / 367
1.0    25.0   0.0    343.0  0.0    1.0    0.0    3.0    1.0    4.0    0.0    0.0    6.0    5.0    1.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.1488833746898263   60 / 403
0.0    7.0    1.0    0.0    323.0  4.0    15.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    4.0    4.0    6.0    1.0    1.0    0.0    0.0    4.0    0.0    11.0   0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    11.0   1.0    2.0    0.0    0.0    3.0    0.0    0.0    6.0    1.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    2.0    0.0    4.0    2.0    1.0    0.0    2.0    2.0    3.0    8.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    2.0    3.0    1.0    0.0    0.0    351.0  3.0    3.0    0.10913705583756345  43 / 394
1.0    0.0    0.0    2.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    2.0    13.0   0.0    27.0   1.0    0.0    331.0  0.0    0.15776081424936386  62 / 393
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    16.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    23.0   1.0    0.0    0.0    0.0    0.0    0.0    308.0  0.16076294277929154  59 / 367
389.0  497.0  324.0  415.0  406.0  405.0  380.0  321.0  338.0  380.0  398.0  357.0  419.0  388.0  392.0  378.0  357.0  402.0  376.0  368.0  395.0  383.0  402.0  418.0  366.0  349.0  0.1490552834149755   1,491 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850945
2    0.921324
3    0.952414
4    0.964111
5    0.974508
6    0.980906
7    0.985704
8    0.989603
9    0.992802
10   0.994302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16376426381750966
RMSE: 0.40467797545395234
LogLoss: 0.5252408728527576
Mean Per-Class Error: 0.1506880587046126
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11    12    13     14    15     16    17    18    19    20    21    22    23     24    25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   1.0   1.0   0.0    3.0   0.0   0.10112359550561797  9 / 89
0.0   90.0   0.0   0.0    1.0   1.0    1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0   6.0   1.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.1509433962264151   16 / 106
0.0   0.0    64.0  0.0    4.0   0.0    3.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   1.0   2.0   0.0   0.0   1.0   0.0    0.0   0.0   0.21951219512195122  18 / 82
1.0   2.0    0.0   98.0   0.0   1.0    0.0   2.0   1.0   1.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.125                14 / 112
0.0   0.0    0.0   0.0    80.0  3.0    4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   2.0   1.0   0.0   0.0   0.0   2.0    0.0   3.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   2.0   1.0   85.0  0.0    0.0   0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   1.0    0.0   1.0   0.0   1.0    1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0   0.0   0.0   0.0   0.0   89.0   0.0   1.0   0.11                 11 / 100
0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0   0.0   2.0   0.0   10.0  1.0   0.0    87.0  0.0   0.18691588785046728  20 / 107
1.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   75.0  0.13793103448275862  12 / 87
90.0  114.0  67.0  123.0  98.0  103.0  98.0  83.0  81.0  107.0  98.0  95.0  93.0  100.0  85.0  107.0  92.0  98.0  84.0  87.0  99.0  92.0  98.0  107.0  98.0  93.0  0.15060240963855423  375 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.849398
2    0.924096
3    0.95261
4    0.965863
5    0.975904
6    0.981124
7    0.984739
8    0.988755
9    0.991566
10   0.992771
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:56  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:56  33.550 sec  42764 obs/sec     1         1             10007      0.562917         1.0009              0.994369       0.273418                         0.560595           0.991507              0.9944           0.269076
    2019-07-24 13:09:58  35.556 sec  45735 obs/sec     10        10            100070     0.402138         0.519813            0.997126       0.149055                         0.404678           0.525241              0.997082         0.150602
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0852994
C15         0.991322               0.991322             0.0845592
C8          0.883068               0.883068             0.0753252
C9          0.847527               0.847527             0.0722936
C7          0.844734               0.844734             0.0720553
C12         0.81742                0.81742              0.0697255
C11         0.744595               0.744595             0.0635136
C5          0.734024               0.734024             0.0626119
C10         0.694193               0.694193             0.0592143
C6          0.688661               0.688661             0.0587424
C14         0.67951                0.67951              0.0579618
C3          0.62662                0.62662              0.0534503
C16         0.582094               0.582094             0.0496523
C4          0.580398               0.580398             0.0495077
C1          0.520656               0.520656             0.0444117
C2          0.488585               0.488585             0.041676
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_28

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013302403564807719  0.00036775146145373583  0.0         -0.013567202332870565  0.19960010051727295  0.1460433287379014   0.1450137495994568
    3        26       Softmax                      0.0   0.0   0.009751215485126662   0.042181044816970825    0.0         -0.26311258827339457   0.5277652740478516   -0.6384128274647595  0.24578309059143066


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16342513778395865
RMSE: 0.40425875102953385
LogLoss: 0.5291584906095859
Mean Per-Class Error: 0.15136505237820552
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    4.0    0.0    2.0    0.0    0.0    3.0    5.0    4.0    3.0    1.0    1.0    0.0    4.0    0.0    0.0810126582278481   32 / 395
0.0    330.0  0.0    5.0    3.0    0.0    1.0    5.0    1.0    0.0    2.0    0.0    0.0    0.0    1.0    4.0    3.0    16.0   8.0    0.0    0.0    1.0    1.0    2.0    0.0    0.0    0.13838120104438642  53 / 383
0.0    0.0    308.0  1.0    13.0   1.0    10.0   0.0    0.0    0.0    18.0   1.0    1.0    0.0    3.0    0.0    0.0    0.0    5.0    3.0    1.0    0.0    3.0    0.0    0.0    0.0    0.16304347826086957  60 / 368
1.0    8.0    0.0    356.0  0.0    2.0    0.0    4.0    0.0    7.0    2.0    0.0    7.0    3.0    2.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.11662531017369727  47 / 403
0.0    4.0    2.0    0.0    328.0  1.0    14.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    7.0    4.0    8.0    3.0    0.0    0.0    0.0    2.0    0.0    9.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    1.0    0.0    7.0    0.0    1.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    3.0    10.0   1.0    0.0    2.0    2.0    3.0    5.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    1.0    3.0    2.0    0.0    0.0    351.0  1.0    6.0    0.10913705583756345  43 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    11.0   2.0    9.0    1.0    0.0    355.0  0.0    0.09669211195928754  38 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    26.0   3.0    0.0    0.0    0.0    1.0    0.0    314.0  0.1444141689373297   53 / 367
390.0  441.0  348.0  446.0  431.0  370.0  354.0  329.0  327.0  365.0  373.0  354.0  399.0  387.0  388.0  403.0  356.0  426.0  383.0  386.0  408.0  356.0  409.0  416.0  391.0  367.0  0.1504548635409377   1,505 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.849545
2    0.917725
3    0.947716
4    0.963111
5    0.972208
6    0.978806
7    0.983205
8    0.987604
9    0.990103
10   0.992902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1653531421901166
RMSE: 0.4066363758815935
LogLoss: 0.5320012993691337
Mean Per-Class Error: 0.15382212298617925
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   1.0    0.0   1.0   0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   87.0   0.0   0.0    2.0    0.0   1.0   1.0   0.0   0.0    2.0   0.0   0.0   0.0    1.0   1.0    1.0   5.0    2.0   0.0   0.0    1.0   1.0   1.0    0.0    0.0   0.1792452830188679   19 / 106
0.0   0.0    66.0  0.0    3.0    0.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
1.0   0.0    0.0   98.0   0.0    1.0   0.0   2.0   0.0   3.0    1.0   0.0   3.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.125                14 / 112
0.0   0.0    0.0   0.0    78.0   1.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    4.0   2.0   0.0    0.0   0.0   2.0    0.0    3.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    5.0    0.0   0.0   1.0   0.0   1.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   86.0   0.0    2.0   0.14                 14 / 100
0.0   0.0    0.0   2.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   2.0   0.0    2.0   1.0   0.0    96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0   1.0   0.0    0.0   0.0   1.0    0.0    74.0  0.14942528735632185  13 / 87
90.0  108.0  74.0  127.0  100.0  83.0  88.0  80.0  75.0  112.0  97.0  94.0  90.0  103.0  77.0  115.0  96.0  105.0  96.0  91.0  104.0  77.0  99.0  102.0  112.0  95.0  0.15261044176706828  380 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.84739
2    0.921285
3    0.950201
4    0.966265
5    0.974297
6    0.979116
7    0.982731
8    0.986747
9    0.990763
10   0.993976
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:43  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:44  1 min 21.171 sec  32490 obs/sec     1         1             10007      0.574113         1.03661             0.994143       0.275817                         0.574045           1.03505               0.994128         0.278313
    2019-07-24 13:10:45  1 min 23.124 sec  45301 obs/sec     10        10            100070     0.404259         0.529158            0.997096       0.150455                         0.406636           0.532001              0.997054         0.15261
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0883142
C15         0.974333               0.974333             0.0860474
C9          0.845742               0.845742             0.074691
C8          0.84238                0.84238              0.0743941
C7          0.810476               0.810476             0.0715765
C12         0.765939               0.765939             0.0676432
C11         0.728729               0.728729             0.0643571
C5          0.719538               0.719538             0.0635454
C10         0.665431               0.665431             0.058767
C3          0.632431               0.632431             0.0558526
C6          0.630542               0.630542             0.0556858
C4          0.609713               0.609713             0.0538463
C14         0.577648               0.577648             0.0510145
C16         0.571995               0.571995             0.0505153
C1          0.475887               0.475887             0.0420276
C2          0.472428               0.472428             0.0417221
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_16

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0016930991758954406  0.000407762941904366   0.0         -0.004458848149610617   0.45563805103302    0.03447598499642679   0.48871147632598877
    3        26       Softmax                 0.0   0.0   0.0023067441760968696  0.0007679294794797897  0.0         -0.0010239890452357241  0.4136151075363159  -0.49210006488119534  0.21705108880996704


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16121660758256545
RMSE: 0.40151787953037094
LogLoss: 0.5506829259682893
Mean Per-Class Error: 0.1610138259418739
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    3.0    2.0    5.0    1.0    1.0    0.0    0.0    3.0    3.0    0.0    1.0    1.0    1.0    2.0    4.0    3.0    0.09113924050632911  36 / 395
0.0    318.0  0.0    8.0    5.0    1.0    1.0    10.0   1.0    0.0    1.0    0.0    1.0    0.0    1.0    2.0    0.0    16.0   8.0    0.0    0.0    6.0    0.0    1.0    1.0    2.0    0.16971279373368145  65 / 383
0.0    0.0    311.0  1.0    13.0   0.0    8.0    1.0    0.0    0.0    16.0   1.0    1.0    0.0    5.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
1.0    11.0   0.0    352.0  0.0    0.0    0.0    14.0   0.0    2.0    0.0    0.0    6.0    2.0    3.0    2.0    0.0    3.0    2.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    0.12655086848635236  51 / 403
0.0    3.0    0.0    0.0    325.0  5.0    12.0   1.0    1.0    0.0    3.0    6.0    0.0    0.0    0.0    0.0    7.0    3.0    5.0    4.0    0.0    0.0    0.0    0.0    0.0    9.0    0.15364583333333334  59 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    21.0   0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    2.0    0.0    7.0    11.0   0.0    0.0    7.0    2.0    2.0    8.0    2.0    0.0    0.0    0.0    0.0    6.0    1.0    2.0    4.0    1.0    0.0    0.0    329.0  4.0    5.0    0.1628498727735369   64 / 393
0.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    3.0    0.0    1.0    13.0   2.0    9.0    1.0    1.0    351.0  0.0    0.10459183673469388  41 / 392
0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    22.0   3.0    0.0    0.0    0.0    0.0    0.0    308.0  0.16076294277929154  59 / 367
383.0  452.0  347.0  424.0  409.0  375.0  340.0  384.0  335.0  371.0  376.0  363.0  459.0  376.0  430.0  387.0  369.0  401.0  374.0  383.0  385.0  358.0  385.0  378.0  386.0  373.0  0.1602519244226732   1,603 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.839748
2    0.912126
3    0.942517
4    0.958912
5    0.969409
6    0.977807
7    0.983505
8    0.986604
9    0.989103
10   0.991003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16376424794989308
RMSE: 0.4046779558487132
LogLoss: 0.5598517918004047
Mean Per-Class Error: 0.1619395692656021
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7      8     9      10    11    12     13     14    15     16    17    18    19    20    21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    1.0   0.06741573033707865  6 / 89
0.0   82.0   0.0   4.0    3.0   0.0   1.0   5.0    0.0   0.0    0.0   0.0   0.0    0.0    1.0   0.0    0.0   4.0   1.0   0.0   0.0   4.0   0.0   1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    67.0  0.0    2.0   0.0   3.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0    2.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.18292682926829268  15 / 82
1.0   1.0    0.0   93.0   0.0   0.0   0.0   7.0    0.0   1.0    0.0   0.0   2.0    0.0    2.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    2.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    76.0  3.0   4.0   0.0    1.0   0.0    0.0   3.0   0.0    0.0    0.0   0.0    1.0   1.0   2.0   2.0   0.0   0.0   0.0   0.0   0.0    3.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   4.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   3.0    0.0   0.0    4.0   0.0   0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   81.0  3.0    2.0   0.19                 19 / 100
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0    2.0   2.0    1.0   0.0   0.0   3.0   0.0   2.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0    0.0   4.0    0.0   1.0   0.0    0.0    0.0   0.0    0.0   0.0   4.0   1.0   0.0   0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
91.0  108.0  72.0  114.0  93.0  88.0  89.0  101.0  82.0  108.0  94.0  96.0  103.0  100.0  91.0  111.0  97.0  98.0  89.0  90.0  98.0  81.0  98.0  92.0  111.0  95.0  0.16184738955823294  403 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838153
2    0.908835
3    0.945783
4    0.963454
5    0.970281
6    0.978313
7    0.983132
8    0.98514
9    0.989558
10   0.990763
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:09  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:09  46.775 sec  28030 obs/sec     1         1             10007      0.540915         0.95676             0.994799       0.26662                          0.540231           0.95163               0.9948           0.274297
    2019-07-24 13:10:12  49.941 sec  28880 obs/sec     10        10            100070     0.401518         0.550683            0.997134       0.160252                         0.404678           0.559852              0.997082         0.161847
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.087456
C15         0.985096               0.985096             0.0861526
C9          0.864179               0.864179             0.0755776
C12         0.851564               0.851564             0.0744744
C7          0.844741               0.844741             0.0738777
C8          0.805827               0.805827             0.0704744
C11         0.757904               0.757904             0.0662833
C14         0.656821               0.656821             0.0574429
C10         0.644588               0.644588             0.056373
C6          0.643824               0.643824             0.0563062
C5          0.621598               0.621598             0.0543625
C16         0.619231               0.619231             0.0541554
C3          0.594988               0.594988             0.0520353
C4          0.554214               0.554214             0.0484693
C1          0.501815               0.501815             0.0438868
C2          0.487933               0.487933             0.0426727
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_7

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017808979641813494  0.00044781260658055544  0.0         -0.014308312716707405  0.4483433961868286   -0.0959606134077149   0.48222315311431885
    3        26       Softmax                 0.0   0.0   0.0022944952158398405  0.0008106101304292679   0.0         0.00431517111810273    0.41379809379577637  -0.48504762931555434  0.18545830249786377


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16434028984961493
RMSE: 0.4053890598543761
LogLoss: 0.558757861039282
Mean Per-Class Error: 0.16579155372329432
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    1.0    0.0    1.0    2.0    8.0    1.0    0.08860759493670886  35 / 395
0.0    324.0  0.0    8.0    4.0    1.0    1.0    6.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    16.0   9.0    0.0    0.0    4.0    0.0    1.0    4.0    0.0    0.15404699738903394  59 / 383
0.0    0.0    309.0  1.0    10.0   1.0    5.0    1.0    0.0    0.0    21.0   1.0    0.0    0.0    8.0    0.0    3.0    0.0    1.0    1.0    4.0    0.0    2.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
1.0    24.0   0.0    347.0  0.0    1.0    0.0    8.0    1.0    2.0    0.0    0.0    4.0    1.0    3.0    0.0    0.0    4.0    0.0    1.0    1.0    0.0    0.0    3.0    0.0    2.0    0.13895781637717122  56 / 403
0.0    3.0    1.0    0.0    317.0  2.0    4.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    12.0   5.0    10.0   1.0    0.0    0.0    0.0    3.0    0.0    18.0   0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    2.0    0.0    16.0   0.0    4.0    0.0    1.0    6.0    0.0    0.0    3.0    0.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    1.0    0.0    4.0    4.0    0.0    0.0    4.0    2.0    1.0    8.0    1.0    0.0    0.0    2.0    0.0    4.0    2.0    8.0    1.0    2.0    2.0    0.0    343.0  2.0    3.0    0.12944162436548223  51 / 394
0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    0.0    1.0    16.0   2.0    4.0    1.0    3.0    355.0  0.0    0.09669211195928754  38 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    33.0   3.0    0.0    0.0    0.0    5.0    0.0    301.0  0.17759562841530055  65 / 366
389.0  477.0  359.0  433.0  394.0  344.0  284.0  293.0  329.0  349.0  413.0  340.0  429.0  379.0  399.0  388.0  415.0  451.0  430.0  376.0  411.0  351.0  384.0  405.0  425.0  356.0  0.16485054483654904  1,649 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835149
2    0.910727
3    0.942617
4    0.957913
5    0.968609
6    0.975607
7    0.981506
8    0.985204
9    0.988304
10   0.991403

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16691530373556482
RMSE: 0.40855269395215693
LogLoss: 0.5689644764004004
Mean Per-Class Error: 0.16889301150431604
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16     17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  -----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0    1.0    1.0    0.0   0.0    0.0   0.0   0.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   1.0    2.0   0.0   1.0   2.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0    6.0    2.0    0.0   0.0    3.0   0.0   1.0    1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    67.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   3.0   0.0    0.0    0.0    1.0    1.0   1.0    0.0   1.0   0.0    0.0    0.0   0.18292682926829268  15 / 82
1.0   4.0    0.0   95.0   0.0   0.0   0.0   5.0   1.0   0.0    0.0    0.0   2.0   1.0   1.0   0.0    0.0    1.0    0.0    0.0   0.0    0.0   0.0   1.0    0.0    0.0   0.15178571428571427  17 / 112
0.0   1.0    1.0   0.0    74.0  1.0   1.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    3.0    1.0    3.0    0.0   0.0    0.0   0.0   2.0    0.0    8.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---    ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   3.0   0.0   0.0   0.0    1.0    0.0    0.0    0.0   1.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   0.0    4.0    1.0   0.0   0.0   0.0   0.0    0.0    1.0    1.0    0.0   0.0    0.0   0.0   86.0   0.0    2.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0    3.0   0.0    1.0   1.0   0.0    99.0   0.0   0.07476635514018691  8 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    8.0    1.0   0.0    0.0   0.0   2.0    0.0    71.0  0.1839080459770115   16 / 87
91.0  116.0  78.0  119.0  91.0  75.0  72.0  77.0  77.0  102.0  102.0  92.0  94.0  99.0  82.0  115.0  105.0  116.0  107.0  88.0  102.0  77.0  96.0  102.0  125.0  90.0  0.1670682730923695   416 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.832932
2    0.909237
3    0.944578
4    0.959839
5    0.968273
6    0.976707
7    0.981928
8    0.987149
9    0.988353
10   0.991165
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:44  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:45  22.577 sec  24347 obs/sec     1         1             10007      0.552445         0.993774            0.994576       0.26562                          0.552487           0.990536              0.994561         0.268675
    2019-07-24 13:09:48  25.693 sec  28822 obs/sec     10        10            100070     0.405389         0.558758            0.997079       0.164851                         0.408553           0.568964              0.997026         0.167068
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.088697
C15         0.985322               0.985322             0.0873951
C12         0.88769                0.88769              0.0787355
C9          0.863176               0.863176             0.0765612
C8          0.786161               0.786161             0.0697301
C7          0.748215               0.748215             0.0663644
C11         0.733489               0.733489             0.0650583
C10         0.687339               0.687339             0.0609649
C14         0.66969                0.66969              0.0593995
C5          0.647353               0.647353             0.0574183
C16         0.639547               0.639547             0.0567259
C6          0.630454               0.630454             0.0559194
C3          0.589247               0.589247             0.0522644
C4          0.522862               0.522862             0.0463763
C1          0.442044               0.442044             0.039208
C2          0.441747               0.441747             0.0391816
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_9

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.001737025775284451  0.00042686983942985535  0.0         -0.010293008675851034  0.17725145816802979  0.13425508191767313  0.11368533968925476
    3        26       Softmax                      0.0   0.0   0.008812932446316014  0.03326775133609772     0.0         -0.17463924697938504   0.4028130769729614   -0.9079065435108143  0.38575613498687744


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17776381721961568
RMSE: 0.4216204658453094
LogLoss: 0.5686827151595388
Mean Per-Class Error: 0.1577081469838736
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    7.0    0.0    2.0    0.0    0.0    0.0    7.0    1.0    1.0    3.0    2.0    2.0    4.0    0.0    0.08607594936708861  34 / 395
0.0    325.0  0.0    3.0    1.0    1.0    3.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    1.0    19.0   7.0    0.0    0.0    7.0    0.0    2.0    2.0    1.0    0.1514360313315927   58 / 383
0.0    0.0    304.0  0.0    10.0   0.0    7.0    1.0    0.0    0.0    21.0   2.0    0.0    0.0    5.0    0.0    2.0    0.0    4.0    4.0    2.0    0.0    5.0    0.0    0.0    0.0    0.17166212534059946  63 / 367
4.0    12.0   0.0    349.0  0.0    2.0    1.0    3.0    0.0    5.0    0.0    0.0    6.0    4.0    1.0    0.0    0.0    10.0   0.0    0.0    2.0    0.0    0.0    4.0    0.0    0.0    0.13399503722084366  54 / 403
0.0    6.0    2.0    0.0    310.0  2.0    17.0   0.0    0.0    0.0    4.0    2.0    0.0    0.0    0.0    0.0    4.0    5.0    9.0    6.0    0.0    0.0    0.0    4.0    0.0    13.0   0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    14.0   1.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    2.0    0.0    5.0    5.0    0.0    0.0    2.0    2.0    2.0    6.0    4.0    0.0    0.0    0.0    0.0    7.0    2.0    1.0    3.0    2.0    0.0    0.0    344.0  2.0    5.0    0.12690355329949238  50 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    2.0    11.0   2.0    10.0   1.0    0.0    358.0  0.0    0.089058524173028    35 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    19.0   2.0    0.0    0.0    0.0    0.0    0.0    318.0  0.13114754098360656  48 / 366
395.0  444.0  335.0  423.0  375.0  382.0  359.0  301.0  350.0  351.0  367.0  374.0  419.0  385.0  405.0  379.0  362.0  454.0  346.0  382.0  410.0  374.0  420.0  397.0  420.0  394.0  0.15685294411676498  1,569 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.843147
2    0.912126
3    0.942717
4    0.959312
5    0.971808
6    0.978306
7    0.983105
8    0.986504
9    0.990303
10   0.992602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18081722364343392
RMSE: 0.42522608532806866
LogLoss: 0.5804364606054686
Mean Per-Class Error: 0.1645947574613166
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   1.0    1.0   2.0    0.0    0.0898876404494382   8 / 89
0.0   82.0   0.0   1.0    1.0   0.0   1.0   2.0   1.0   0.0    0.0   0.0    0.0   0.0    2.0   1.0    0.0   6.0    2.0   0.0   0.0    5.0   0.0    1.0   1.0    0.0    0.22641509433962265  24 / 106
0.0   0.0    64.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    5.0   0.0    0.0   0.0    3.0   0.0    1.0   0.0    1.0   2.0   1.0    0.0   1.0    0.0   0.0    0.0    0.21951219512195122  18 / 82
3.0   2.0    0.0   95.0   0.0   1.0   1.0   2.0   0.0   2.0    0.0   0.0    3.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0    0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    72.0  1.0   4.0   0.0   0.0   0.0    2.0   1.0    0.0   0.0    0.0   0.0    2.0   1.0    3.0   3.0   0.0    0.0   0.0    2.0   0.0    6.0    0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   87.0   0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   1.0   0.0   0.0    3.0   3.0    0.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0    82.0  0.0    3.0    0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   2.0   0.0    3.0   1.0    0.0   100.0  0.0    0.06542056074766354  7 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    77.0   0.11494252873563218  10 / 87
91.0  103.0  68.0  117.0  87.0  92.0  92.0  76.0  87.0  102.0  94.0  101.0  96.0  101.0  83.0  104.0  96.0  115.0  81.0  90.0  100.0  89.0  102.0  96.0  122.0  105.0  0.1642570281124498   409 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835743
2    0.914458
3    0.946988
4    0.961847
5    0.972691
6    0.979116
7    0.981526
8    0.984337
9    0.989558
10   0.992771
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:50  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:51  28.262 sec  30696 obs/sec     1         1             10007      0.592948         1.07579             0.99375        0.285514                         0.594517           1.08185               0.993702         0.295582
    2019-07-24 13:09:53  31.038 sec  33190 obs/sec     10        10            100070     0.42162          0.568683            0.99684        0.156853                         0.425226           0.580436              0.996778         0.164257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0847194
C13         0.985286               0.985286             0.0834728
C8          0.913973               0.913973             0.0774312
C9          0.89135                0.89135              0.0755146
C12         0.887097               0.887097             0.0751543
C7          0.841427               0.841427             0.0712851
C11         0.762958               0.762958             0.0646373
C5          0.732635               0.732635             0.0620683
C10         0.699783               0.699783             0.0592852
C6          0.689517               0.689517             0.0584155
C14         0.668704               0.668704             0.0566522
C3          0.631252               0.631252             0.0534793
C4          0.621335               0.621335             0.0526391
C16         0.588088               0.588088             0.0498224
C2          0.458403               0.458403             0.0388356
C1          0.43187                0.43187              0.0365878
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_38

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0014220078710422968  0.0003677651984617114  0.0         0.004165127192464979   0.4343651533126831  -0.004798193991141402  0.5114521980285645
    3        26       Softmax                 0.0   0.0   0.0024283001946689463  0.000687283230945468   0.0         -0.025652590410502923  0.57077956199646    -0.5260109612427969    0.17617130279541016


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17272350743548723
RMSE: 0.4156001773766311
LogLoss: 0.5700203122831178
Mean Per-Class Error: 0.16708301439490725
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    4.0    1.0    2.0    2.0    0.0    0.0    0.0    3.0    2.0    2.0    0.0    3.0    1.0    3.0    0.0    5.0    1.0    0.07848101265822785  31 / 395
0.0    319.0  0.0    7.0    5.0    5.0    1.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    5.0    18.0   3.0    1.0    1.0    7.0    0.0    3.0    0.0    0.0    0.1671018276762402   64 / 383
0.0    0.0    307.0  0.0    21.0   1.0    8.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    3.0    0.0    0.0    3.0    5.0    2.0    6.0    0.0    2.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
1.0    7.0    0.0    348.0  0.0    2.0    0.0    5.0    0.0    10.0   0.0    2.0    2.0    2.0    4.0    4.0    0.0    8.0    1.0    0.0    3.0    0.0    0.0    2.0    0.0    1.0    0.13432835820895522  54 / 402
0.0    6.0    2.0    0.0    314.0  4.0    24.0   2.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    3.0    1.0    1.0    0.0    7.0    0.0    11.0   0.18229166666666666  70 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    5.0    4.0    6.0    0.0    0.0    2.0    0.0    0.0    6.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    2.0    0.0    4.0    6.0    2.0    0.0    2.0    3.0    1.0    6.0    1.0    0.0    0.0    2.0    0.0    2.0    2.0    0.0    3.0    2.0    0.0    0.0    348.0  3.0    4.0    0.11450381679389313  45 / 393
0.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    0.0    1.0    11.0   4.0    28.0   0.0    0.0    337.0  0.0    0.14249363867684478  56 / 393
2.0    0.0    0.0    0.0    15.0   1.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    24.0   5.0    0.0    0.0    0.0    3.0    0.0    303.0  0.17438692098092642  64 / 367
389.0  463.0  344.0  422.0  438.0  384.0  347.0  297.0  337.0  385.0  326.0  370.0  375.0  378.0  413.0  391.0  348.0  476.0  294.0  382.0  438.0  393.0  403.0  430.0  391.0  389.0  0.16605018494451665  1,661 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83395
2    0.906728
3    0.941917
4    0.957013
5    0.96761
6    0.975907
7    0.981206
8    0.985804
9    0.988204
10   0.991103

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17720449756511997
RMSE: 0.42095664570727465
LogLoss: 0.5824028963756966
Mean Per-Class Error: 0.17168836965701023
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.0   0.0    0.0   1.0   0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   81.0   0.0   2.0    2.0    0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    2.0   7.0    1.0   0.0   1.0    4.0   0.0   1.0    0.0    0.0   0.2358490566037736    25 / 106
0.0   0.0    68.0  0.0    4.0    1.0   1.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   1.0   1.0    0.0   1.0   0.0    0.0    0.0   0.17073170731707318   14 / 82
0.0   1.0    0.0   96.0   0.0    1.0   0.0   2.0   0.0   3.0    0.0   2.0   0.0   2.0    0.0   2.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   1.0    0.0    1.0   0.14285714285714285   16 / 112
0.0   0.0    1.0   0.0    77.0   2.0   6.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0   2.0    0.0    4.0   0.20618556701030927   20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   88.0  0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    3.0    1.0   0.0   1.0   0.0   1.0    3.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    0.0   1.0   1.0    0.0   0.0   83.0   1.0    1.0   0.17                  17 / 100
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0   0.0    0.0   2.0   2.0    11.0  0.0   0.0    87.0   0.0   0.18691588785046728   20 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0   2.0   0.0    0.0   0.0   1.0    0.0    70.0  0.19540229885057472   17 / 87
92.0  111.0  76.0  117.0  101.0  89.0  84.0  79.0  82.0  112.0  85.0  97.0  83.0  103.0  84.0  116.0  91.0  117.0  76.0  88.0  111.0  96.0  99.0  100.0  107.0  94.0  0.172289156626506     429 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827711
2    0.905622
3    0.940562
4    0.955823
5    0.968273
6    0.974297
7    0.981124
8    0.985944
9    0.988755
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:05  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:06  1 min 43.184 sec  42402 obs/sec     1         1             10007      0.585334         1.09102             0.99391        0.289713                         0.584938           1.09008               0.993903         0.292369
    2019-07-24 13:11:07  1 min 44.991 sec  49885 obs/sec     10        10            100070     0.4156           0.57002             0.99693        0.16605                          0.420957           0.582403              0.996842         0.172289
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0921022
C15         0.998343               0.998343             0.0919496
C12         0.952671               0.952671             0.0877431
C9          0.820198               0.820198             0.075542
C8          0.803132               0.803132             0.0739702
C11         0.724448               0.724448             0.0667233
C10         0.715902               0.715902             0.0659361
C7          0.664248               0.664248             0.0611787
C14         0.636796               0.636796             0.0586503
C6          0.636723               0.636723             0.0586436
C16         0.634916               0.634916             0.0584771
C5          0.581866               0.581866             0.0535911
C4          0.487443               0.487443             0.0448945
C3          0.457037               0.457037             0.0420941
C1          0.393601               0.393601             0.0362515
C2          0.350185               0.350185             0.0322528
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_10

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0015545665200420444  0.0004249928751960397  0.0         -0.014984579171823498  0.4435354471206665  0.056732361674108236  0.4399385452270508
    3        26       Softmax                 0.0   0.0   0.002546374128262239   0.0007910034619271755  0.0         -0.015103437928333872  0.566697359085083   -0.5112617197583338   0.17317134141921997


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17311566889204064
RMSE: 0.41607171123742676
LogLoss: 0.5802527115240825
Mean Per-Class Error: 0.16632481345525005
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    5.0    0.0    0.0    0.0    2.0    0.0    3.0    3.0    1.0    4.0    0.0    0.0    0.0    1.0    2.0    2.0    0.0    2.0    1.0    1.0    2.0    4.0    1.0    0.08607594936708861  34 / 395
0.0    336.0  3.0    6.0    3.0    2.0    2.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    3.0    14.0   3.0    1.0    0.0    1.0    0.0    3.0    0.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    308.0  0.0    8.0    1.0    9.0    0.0    0.0    0.0    21.0   2.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    2.0    3.0    0.0    2.0    0.0    0.0    0.0    0.16304347826086957  60 / 368
2.0    13.0   0.0    336.0  0.0    1.0    0.0    1.0    0.0    7.0    1.0    0.0    5.0    5.0    3.0    3.0    0.0    14.0   1.0    0.0    4.0    0.0    0.0    4.0    0.0    2.0    0.16417910447761194  66 / 402
0.0    6.0    6.0    0.0    303.0  8.0    16.0   1.0    1.0    0.0    2.0    5.0    0.0    0.0    0.0    1.0    5.0    5.0    8.0    6.0    0.0    0.0    0.0    3.0    0.0    8.0    0.2109375            81 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    13.0   0.0    0.0    1.0    0.0    1.0    1.0    1.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    0.0    0.0    5.0    9.0    1.0    0.0    0.0    2.0    3.0    5.0    4.0    0.0    0.0    2.0    0.0    5.0    2.0    2.0    3.0    1.0    0.0    0.0    341.0  6.0    3.0    0.13451776649746192  53 / 394
0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    2.0    12.0   4.0    18.0   1.0    1.0    349.0  0.0    0.11195928753180662  44 / 393
1.0    1.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    24.0   2.0    0.0    0.0    0.0    0.0    0.0    314.0  0.1444141689373297   53 / 367
400.0  480.0  342.0  429.0  386.0  372.0  357.0  274.0  338.0  365.0  358.0  359.0  392.0  370.0  428.0  383.0  374.0  434.0  332.0  406.0  425.0  381.0  418.0  420.0  418.0  362.0  0.16545036489053283  1,655 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83455
2    0.908527
3    0.938319
4    0.956313
5    0.968509
6    0.975807
7    0.980806
8    0.984505
9    0.987804
10   0.990303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17379210086308633
RMSE: 0.4168837977939252
LogLoss: 0.5837354343479656
Mean Per-Class Error: 0.16447180732102376
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0   1.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   86.0   1.0   3.0    2.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   6.0    1.0   1.0   0.0    1.0   0.0   2.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    67.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    5.0   0.0    0.0   0.0    5.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.18292682926829268  15 / 82
1.0   2.0    0.0   92.0   0.0   1.0   0.0   0.0   0.0   3.0    1.0   0.0    1.0   2.0    0.0   3.0    0.0   2.0    0.0   0.0   2.0    0.0   0.0   2.0    0.0    0.0   0.17857142857142858  20 / 112
0.0   0.0    1.0   0.0    69.0  5.0   4.0   0.0   0.0   0.0    2.0   2.0    0.0   0.0    0.0   0.0    2.0   1.0    3.0   3.0   0.0    0.0   0.0   2.0    0.0    3.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    3.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   0.0   0.0   1.0    2.0   3.0    0.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0   82.0   2.0    1.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   2.0   1.0    5.0   1.0   0.0    96.0   0.0   0.102803738317757    11 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    5.0   0.0   0.0    0.0   0.0   0.0    0.0    75.0  0.13793103448275862  12 / 87
96.0  121.0  72.0  113.0  90.0  90.0  81.0  74.0  81.0  102.0  87.0  101.0  86.0  100.0  94.0  109.0  98.0  107.0  85.0  97.0  111.0  86.0  99.0  103.0  119.0  88.0  0.1642570281124498   409 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835743
2    0.911245
3    0.939357
4    0.956225
5    0.967068
6    0.974297
7    0.980723
8    0.983534
9    0.987149
10   0.990362
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:53  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:54  31.299 sec  49295 obs/sec     1         1             10007      0.583264         1.07747             0.993955       0.283615                         0.583557           1.07551               0.993932         0.291566
    2019-07-24 13:09:56  33.238 sec  47471 obs/sec     10        10            100070     0.416072         0.580253            0.996924       0.16545                          0.416884           0.583735              0.996903         0.164257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0931813
C13         0.957078               0.957078             0.0891818
C9          0.829247               0.829247             0.0772703
C8          0.796998               0.796998             0.0742653
C12         0.786574               0.786574             0.073294
C11         0.764296               0.764296             0.0712181
C7          0.729628               0.729628             0.0679877
C6          0.656489               0.656489             0.0611725
C10         0.640657               0.640657             0.0596973
C14         0.634669               0.634669             0.0591393
C16         0.602144               0.602144             0.0561085
C5          0.539163               0.539163             0.05024
C3          0.501795               0.501795             0.046758
C4          0.477387               0.477387             0.0444835
C2          0.427455               0.427455             0.0398308
C1          0.388184               0.388184             0.0361715
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_32

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.000976695583460696   0.0002771615982055664  0.0         -0.002298894930650164  0.23126637935638428  0.25094608304227783  0.19961100816726685
    3        26       Softmax                      0.0   0.0   0.0062627082349990815  0.023369967937469482   0.0         -0.28796040352888386   0.7127373218536377   -0.4950654522626365  0.22180062532424927


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17722726310251108
RMSE: 0.420983685078782
LogLoss: 0.5823185908415969
Mean Per-Class Error: 0.16868850011441816
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    4.0    5.0    2.0    5.0    0.0    0.0    0.0    0.0    1.0    3.0    3.0    2.0    1.0    3.0    6.0    4.0    2.0    0.10886075949367088  43 / 395
0.0    334.0  0.0    4.0    3.0    1.0    0.0    5.0    2.0    0.0    3.0    1.0    0.0    0.0    1.0    5.0    1.0    7.0    10.0   0.0    0.0    2.0    0.0    2.0    1.0    0.0    0.1256544502617801   48 / 382
0.0    0.0    302.0  0.0    12.0   1.0    12.0   1.0    0.0    0.0    16.0   2.0    1.0    0.0    6.0    0.0    2.0    0.0    0.0    5.0    2.0    0.0    5.0    0.0    0.0    0.0    0.1771117166212534   65 / 367
3.0    13.0   0.0    341.0  0.0    0.0    0.0    2.0    0.0    9.0    1.0    0.0    7.0    2.0    3.0    3.0    0.0    8.0    2.0    3.0    0.0    0.0    0.0    4.0    0.0    2.0    0.15384615384615385  62 / 403
0.0    6.0    3.0    0.0    300.0  4.0    16.0   0.0    0.0    0.0    2.0    12.0   0.0    0.0    0.0    1.0    4.0    3.0    9.0    2.0    0.0    0.0    0.0    6.0    0.0    16.0   0.21875              84 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    12.0   0.0    4.0    0.0    2.0    2.0    0.0    1.0    2.0    1.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    4.0    3.0    0.0    0.0    2.0    2.0    2.0    7.0    6.0    0.0    0.0    2.0    0.0    0.0    0.0    6.0    1.0    1.0    0.0    0.0    348.0  3.0    6.0    0.116751269035533    46 / 394
2.0    0.0    0.0    1.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    8.0    0.0    25.0   1.0    1.0    340.0  0.0    0.13486005089058525  53 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    15.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    19.0   3.0    0.0    0.0    0.0    0.0    0.0    311.0  0.15258855585831063  56 / 367
404.0  455.0  352.0  420.0  383.0  388.0  335.0  306.0  344.0  387.0  382.0  388.0  416.0  375.0  398.0  378.0  316.0  413.0  372.0  384.0  412.0  396.0  399.0  432.0  396.0  372.0  0.16804958512446266  1,681 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83195
2    0.907428
3    0.938618
4    0.956713
5    0.969009
6    0.977007
7    0.983105
8    0.987604
9    0.991103
10   0.992902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1797097219975335
RMSE: 0.4239218347732675
LogLoss: 0.5902865240150295
Mean Per-Class Error: 0.17416227226347986
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   1.0    0.0   1.0   3.0    2.0    0.0   0.11235955056179775  10 / 89
0.0   88.0   0.0   0.0    2.0   0.0   0.0   1.0   1.0   0.0    1.0   0.0    0.0   0.0    1.0   1.0    0.0   4.0    4.0    0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    62.0  0.0    3.0   0.0   6.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   0.0    1.0   0.0    0.0    2.0   1.0    0.0   2.0   0.0    0.0    0.0   0.24390243902439024  20 / 82
2.0   2.0    0.0   94.0   0.0   0.0   0.0   1.0   0.0   2.0    1.0   0.0    3.0   1.0    0.0   2.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    69.0  3.0   4.0   0.0   0.0   0.0    1.0   4.0    0.0   0.0    0.0   0.0    1.0   1.0    3.0    1.0   0.0    0.0   0.0   2.0    0.0    8.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0    1.0   1.0    0.0    0.0   0.0    0.0   86.0  0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   1.0   0.0   0.0    3.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   87.0   1.0    1.0   0.13                 13 / 100
1.0   0.0    0.0   0.0    0.0   4.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0    1.0   0.0    8.0   1.0   0.0    91.0   0.0   0.14953271028037382  16 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   6.0    0.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0    2.0    1.0   0.0    0.0   0.0   0.0    0.0    72.0  0.1724137931034483   15 / 87
94.0  112.0  72.0  116.0  89.0  90.0  82.0  73.0  83.0  112.0  95.0  107.0  94.0  101.0  82.0  109.0  83.0  107.0  102.0  88.0  105.0  93.0  96.0  104.0  113.0  88.0  0.17349397590361446  432 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826506
2    0.906827
3    0.938554
4    0.955823
5    0.969076
6    0.976305
7    0.97992
8    0.985141
9    0.988353
10   0.990763
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:52  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:52  1 min 30.079 sec  59565 obs/sec     1         1             10007      0.599006         1.13933             0.993623       0.303709                         0.597139           1.12988               0.993646         0.30241
    2019-07-24 13:10:54  1 min 31.498 sec  64353 obs/sec     10        10            100070     0.420984         0.582319            0.99685        0.16805                          0.423922           0.590287              0.996798         0.173494
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0923143
C13         0.915483               0.915483             0.0845122
C7          0.808359               0.808359             0.0746231
C8          0.803099               0.803099             0.0741375
C9          0.801961               0.801961             0.0740324
C12         0.746869               0.746869             0.0689466
C11         0.737134               0.737134             0.068048
C5          0.66671                0.66671              0.0615469
C3          0.629611               0.629611             0.0581221
C16         0.592862               0.592862             0.0547296
C6          0.583014               0.583014             0.0538205
C14         0.56101                0.56101              0.0517892
C10         0.542886               0.542886             0.0501162
C4          0.512567               0.512567             0.0473173
C1          0.468637               0.468637             0.0432619
C2          0.462359               0.462359             0.0426823
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_36

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009803538258097433  0.000267532654106617  0.0         -0.015051709723138629  0.23673111200332642  0.2628501516053807    0.19835901260375977
    3        26       Softmax                      0.0   0.0   0.005996638753073897   0.015310082584619522  0.0         -0.31624629437988006   0.7243976593017578   -0.48405569136490845  0.22533148527145386


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17218023879940933
RMSE: 0.41494606733816547
LogLoss: 0.5738694513090505
Mean Per-Class Error: 0.15935810511994794
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    2.0    1.0    3.0    2.0    4.0    0.0    1.0    1.0    2.0    1.0    3.0    1.0    2.0    4.0    3.0    2.0    0.08607594936708861  34 / 395
0.0    346.0  0.0    2.0    1.0    0.0    1.0    2.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0    13.0   7.0    0.0    0.0    1.0    0.0    2.0    3.0    0.0    0.09660574412532637  37 / 383
0.0    0.0    311.0  0.0    12.0   0.0    4.0    0.0    0.0    0.0    18.0   5.0    0.0    0.0    7.0    0.0    1.0    0.0    2.0    1.0    1.0    0.0    6.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
2.0    16.0   0.0    342.0  0.0    0.0    0.0    1.0    0.0    4.0    3.0    1.0    6.0    5.0    3.0    2.0    0.0    6.0    2.0    1.0    0.0    0.0    0.0    6.0    0.0    3.0    0.1513647642679901   61 / 403
0.0    8.0    4.0    0.0    309.0  9.0    16.0   0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    5.0    4.0    6.0    5.0    0.0    0.0    0.0    3.0    0.0    8.0    0.1953125            75 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    4.0    0.0    1.0    0.0    0.0    8.0    0.0    0.0    8.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    4.0    9.0    0.0    0.0    4.0    2.0    2.0    5.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    13.0   2.0    3.0    0.0    0.0    338.0  3.0    2.0    0.13994910941475827  55 / 393
0.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    3.0    8.0    2.0    11.0   1.0    0.0    361.0  0.0    0.08142493638676845  32 / 393
4.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    5.0    0.0    3.0    0.0    0.0    0.0    0.0    5.0    0.0    30.0   2.0    0.0    0.0    0.0    0.0    0.0    308.0  0.16076294277929154  59 / 367
415.0  482.0  351.0  402.0  406.0  322.0  346.0  317.0  337.0  370.0  362.0  373.0  388.0  419.0  377.0  415.0  355.0  430.0  392.0  378.0  407.0  363.0  415.0  404.0  418.0  359.0  0.15865240427871638  1,587 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.841348
2    0.914226
3    0.942717
4    0.958013
5    0.96771
6    0.973808
7    0.980506
8    0.984605
9    0.987404
10   0.989203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17727807321994848
RMSE: 0.4210440276502547
LogLoss: 0.5904498106494139
Mean Per-Class Error: 0.1744007432134519
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   1.0    1.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   88.0   0.0   0.0    1.0   0.0   1.0   1.0   1.0   0.0    1.0   0.0   0.0   0.0    1.0   1.0    0.0   5.0    3.0    0.0   0.0    1.0   0.0    1.0   1.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    65.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    4.0   1.0   0.0   0.0    4.0   0.0    1.0   0.0    1.0    1.0   0.0    0.0   2.0    0.0   0.0    0.0   0.2073170731707317   17 / 82
2.0   2.0    0.0   96.0   0.0   0.0   0.0   1.0   0.0   1.0    1.0   1.0   2.0   2.0    1.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.14285714285714285  16 / 112
0.0   1.0    0.0   0.0    70.0  5.0   4.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0    3.0   0.0    0.0   0.0    2.0   0.0    4.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   3.0    0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   3.0   0.0   1.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    5.0    0.0   2.0    0.0   0.0    79.0  0.0    1.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0    2.0   0.0    2.0   1.0    0.0   100.0  0.0   0.06542056074766354  7 / 107
2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0    1.0   0.0    0.0   0.0    0.0   0.0    71.0  0.1839080459770115   16 / 87
99.0  118.0  72.0  114.0  93.0  73.0  87.0  81.0  77.0  107.0  92.0  97.0  84.0  106.0  81.0  120.0  97.0  103.0  101.0  94.0  104.0  80.0  102.0  96.0  124.0  88.0  0.1714859437751004   427 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.828514
2    0.911245
3    0.942169
4    0.956225
5    0.965863
6    0.973494
7    0.978313
8    0.981928
9    0.985542
10   0.987952
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:01  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:01  1 min 38.427 sec  61392 obs/sec     1         1             10007      0.590191         1.1027              0.99381        0.288613                         0.587954           1.09678               0.99384          0.284739
    2019-07-24 13:11:02  1 min 39.708 sec  70670 obs/sec     10        10            100070     0.414946         0.573869            0.99694        0.158652                         0.421044           0.59045               0.996841         0.171486
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0865221
C13         0.916242               0.916242             0.0792752
C12         0.876899               0.876899             0.0758712
C8          0.8113                 0.8113               0.0701954
C7          0.798245               0.798245             0.0690658
C9          0.756114               0.756114             0.0654206
C11         0.75331                0.75331              0.065178
C5          0.738569               0.738569             0.0639026
C6          0.706952               0.706952             0.061167
C14         0.674975               0.674975             0.0584003
C10         0.653399               0.653399             0.0565334
C3          0.610125               0.610125             0.0527893
C16         0.606533               0.606533             0.0524785
C4          0.569902               0.569902             0.0493091
C1          0.554349               0.554349             0.0479635
C2          0.530822               0.530822             0.0459279
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_2

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0020227155683159026  0.0005074236541986465  0.0         0.0012776877667093345  0.41805243492126465  -0.004445432408418213  0.4937537908554077
    3        26       Softmax                 0.0   0.0   0.002194711865181139   0.0006055196281522512  0.0         0.002215584234821659   0.28875863552093506  -0.6206294802943458    0.2474879026412964


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17603286883166958
RMSE: 0.4195627114409353
LogLoss: 0.6175403220704774
Mean Per-Class Error: 0.17959258600904157
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    4.0    0.0    2.0    0.0    1.0    0.0    0.0    1.0    4.0    3.0    4.0    0.0    1.0    2.0    5.0    2.0    0.0759493670886076   30 / 395
0.0    328.0  0.0    3.0    7.0    0.0    1.0    4.0    4.0    0.0    0.0    1.0    0.0    0.0    1.0    2.0    0.0    20.0   5.0    0.0    0.0    2.0    0.0    2.0    2.0    1.0    0.14360313315926893  55 / 383
0.0    0.0    296.0  0.0    19.0   0.0    12.0   0.0    0.0    0.0    16.0   0.0    0.0    0.0    8.0    0.0    2.0    0.0    2.0    2.0    8.0    0.0    2.0    0.0    0.0    0.0    0.19346049046321526  71 / 367
4.0    29.0   0.0    319.0  0.0    0.0    0.0    6.0    1.0    4.0    2.0    1.0    6.0    5.0    5.0    2.0    0.0    9.0    1.0    0.0    2.0    0.0    0.0    7.0    0.0    0.0    0.20843672456575682  84 / 403
0.0    5.0    0.0    0.0    332.0  2.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    4.0    4.0    7.0    0.0    0.0    0.0    4.0    0.0    8.0    0.13541666666666666  52 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    5.0    0.0    0.0    2.0    0.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    1.0    0.0    3.0    11.0   0.0    0.0    3.0    5.0    4.0    4.0    2.0    0.0    0.0    0.0    0.0    7.0    2.0    1.0    3.0    1.0    0.0    0.0    342.0  2.0    3.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    3.0    10.0   4.0    10.0   1.0    1.0    351.0  0.0    0.10687022900763359  42 / 393
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    13.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    16.0   4.0    0.0    0.0    0.0    0.0    0.0    314.0  0.1444141689373297   53 / 367
412.0  487.0  334.0  388.0  499.0  326.0  347.0  309.0  342.0  375.0  349.0  353.0  410.0  398.0  391.0  385.0  372.0  439.0  261.0  408.0  427.0  365.0  394.0  429.0  413.0  390.0  0.17844646606018194  1,785 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.821554
2    0.895431
3    0.93182
4    0.949415
5    0.961711
6    0.972208
7    0.979006
8    0.983305
9    0.986104
10   0.988303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18015867248053874
RMSE: 0.42445102483153313
LogLoss: 0.6296970703726318
Mean Per-Class Error: 0.18235123450596744
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   0.0   1.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   85.0   0.0   0.0    3.0    0.0   1.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    0.0   7.0    1.0   0.0   0.0    2.0   0.0   1.0   1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    63.0  0.0    3.0    0.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   1.0   2.0    0.0   1.0   0.0   0.0    0.0   0.23170731707317074  19 / 82
3.0   4.0    0.0   90.0   0.0    0.0   0.0   3.0   1.0   1.0    1.0   0.0   2.0   1.0    0.0   2.0    0.0   2.0    0.0   0.0   1.0    0.0   0.0   1.0   0.0    0.0   0.19642857142857142  22 / 112
0.0   0.0    0.0   0.0    83.0   1.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   3.0   0.0    0.0   0.0   1.0   0.0    2.0   0.14432989690721648  14 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   1.0    5.0    0.0   0.0   1.0   1.0   1.0    1.0   2.0   0.0   0.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0   84.0  0.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    4.0   0.0    0.0   3.0   0.0    3.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
94.0  117.0  67.0  109.0  118.0  77.0  90.0  80.0  81.0  113.0  85.0  98.0  91.0  104.0  84.0  110.0  95.0  115.0  65.0  99.0  105.0  82.0  99.0  99.0  117.0  96.0  0.18112449799196786  451 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818875
2    0.891165
3    0.933333
4    0.949398
5    0.960241
6    0.969478
7    0.979518
8    0.983133
9    0.985542
10   0.98755
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:30  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:30  8.016 sec   15070 obs/sec     1         1             10007      0.544054         0.985196            0.99474        0.263921                         0.544023           0.982625              0.994726         0.267068
    2019-07-24 13:09:35  13.011 sec  18059 obs/sec     10        10            100070     0.419563         0.61754             0.996872       0.178446                         0.424451           0.629697              0.99679          0.181124
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0894564
C13         0.997782               0.997782             0.089258
C9          0.880847               0.880847             0.0787975
C12         0.84549                0.84549              0.0756346
C8          0.795957               0.795957             0.0712035
C7          0.775721               0.775721             0.0693933
C11         0.756148               0.756148             0.0676423
C10         0.680457               0.680457             0.0608712
C14         0.634976               0.634976             0.0568027
C6          0.62331                0.62331              0.0557591
C5          0.601398               0.601398             0.0537989
C3          0.5813                 0.5813               0.052001
C16         0.567318               0.567318             0.0507503
C4          0.566489               0.566489             0.0506761
C2          0.43876                0.43876              0.0392499
C1          0.432673               0.432673             0.0387053
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_44

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009680137975749403  0.00023605942260473967  0.0         -0.009801619837560338  0.2398233413696289  0.12344994328024862  0.20183849334716797
    3        26       Softmax                      0.0   0.0   0.0068904111729772505  0.024767853319644928    0.0         -0.27576227714255835   0.7226545810699463  -0.5918930435281117  0.37643682956695557


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20192011683712727
RMSE: 0.4493552234448013
LogLoss: 0.6466906879582421
Mean Per-Class Error: 0.178805136076223
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    6.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    3.0    1.0    2.0    0.0    3.0    2.0    4.0    2.0    0.09898477157360407  39 / 394
0.0    322.0  0.0    4.0    1.0    1.0    9.0    5.0    2.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    11.0   14.0   0.0    0.0    6.0    1.0    3.0    0.0    0.0    0.15926892950391644  61 / 383
0.0    0.0    296.0  0.0    18.0   0.0    12.0   1.0    0.0    0.0    18.0   0.0    0.0    0.0    6.0    0.0    3.0    0.0    3.0    4.0    3.0    0.0    4.0    0.0    0.0    0.0    0.1956521739130435   72 / 368
2.0    29.0   0.0    333.0  1.0    0.0    2.0    4.0    0.0    1.0    0.0    0.0    5.0    3.0    2.0    0.0    0.0    11.0   1.0    2.0    1.0    0.0    0.0    5.0    0.0    0.0    0.17164179104477612  69 / 402
0.0    14.0   0.0    0.0    309.0  3.0    22.0   1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    5.0    5.0    1.0    0.0    0.0    5.0    0.0    11.0   0.1953125            75 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    1.0    0.0    18.0   0.0    8.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    4.0    0.0    4.0    11.0   1.0    0.0    2.0    1.0    1.0    8.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    5.0    3.0    2.0    0.0    0.0    339.0  2.0    4.0    0.13959390862944163  55 / 394
1.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    7.0    0.0    3.0    14.0   0.0    10.0   2.0    0.0    342.0  0.0    0.12755102040816327  50 / 392
0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    24.0   4.0    0.0    0.0    0.0    2.0    0.0    309.0  0.15803814713896458  58 / 367
396.0  519.0  323.0  399.0  406.0  408.0  396.0  323.0  329.0  353.0  409.0  336.0  425.0  379.0  409.0  355.0  351.0  405.0  354.0  371.0  399.0  369.0  421.0  402.0  391.0  375.0  0.17804658602419274  1,781 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.821953
2    0.898031
3    0.929321
4    0.948815
5    0.962211
6    0.972208
7    0.978606
8    0.982405
9    0.986504
10   0.990103

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20346143490419086
RMSE: 0.4510669960263008
LogLoss: 0.6490965882690374
Mean Per-Class Error: 0.17510479393847378
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   83.0   0.0   1.0    1.0   0.0   2.0    4.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0   2.0    4.0   0.0   0.0    4.0   1.0    2.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    60.0  0.0    4.0   0.0   3.0    0.0   0.0   0.0    4.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    2.0   2.0   1.0    0.0   2.0    0.0    0.0    0.0   0.2682926829268293   22 / 82
2.0   4.0    0.0   95.0   0.0   0.0   2.0    1.0   0.0   0.0    0.0   0.0   1.0   2.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    0.0   0.15178571428571427  17 / 112
0.0   2.0    0.0   0.0    73.0  1.0   6.0    1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    2.0   3.0   0.0    0.0   0.0    2.0    0.0    5.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   4.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   2.0    4.0   0.0   0.0    1.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   0.0   0.0    0.0   0.0    83.0   1.0    1.0   0.17                 17 / 100
1.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    4.0   0.0    0.0   4.0   0.0    3.0   2.0    0.0    90.0   0.0   0.1588785046728972   17 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   5.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   1.0   0.0    0.0   0.0    0.0    0.0    76.0  0.12643678160919541  11 / 87
94.0  121.0  64.0  112.0  93.0  97.0  101.0  88.0  77.0  103.0  99.0  91.0  95.0  100.0  85.0  103.0  92.0  100.0  91.0  90.0  103.0  88.0  103.0  101.0  103.0  96.0  0.1751004016064257   436 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.8249
2    0.899197
3    0.93012
4    0.947791
5    0.961044
6    0.971888
7    0.978715
8    0.981526
9    0.986345
10   0.98996
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:18  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:18  1 min 55.423 sec  54983 obs/sec     1         1             10007      0.653618         1.28244             0.992405       0.330701                         0.652467           1.27452               0.992414         0.331325
    2019-07-24 13:11:19  1 min 56.530 sec  79483 obs/sec     10        10            100070     0.449355         0.646691            0.99641        0.178047                         0.451067           0.649097              0.996375         0.1751
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0938099
C13         0.913969               0.913969             0.0857393
C8          0.804353               0.804353             0.0754562
C7          0.788198               0.788198             0.0739407
C12         0.771162               0.771162             0.0723426
C9          0.768762               0.768762             0.0721175
C5          0.749842               0.749842             0.0703425
C11         0.664446               0.664446             0.0623316
C10         0.632982               0.632982             0.05938
C14         0.61384                0.61384              0.0575842
C3          0.556303               0.556303             0.0521867
C4          0.548069               0.548069             0.0514143
C6          0.517611               0.517611             0.048557
C16         0.50608                0.50608              0.0474753
C2          0.412605               0.412605             0.0387064
C1          0.411637               0.411637             0.0386157
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_3

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009404668011825379  0.00023863965179771185  0.0         -0.015423448180527544  0.2378649115562439  0.10662190187329165  0.19042718410491943
    3        26       Softmax                      0.0   0.0   0.006475283855567026   0.016705714166164398    0.0         -0.28680157127050515   0.7401986122131348  -0.6057259470892947  0.37575602531433105


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20574778109810374
RMSE: 0.4535942912979657
LogLoss: 0.6563231566734083
Mean Per-Class Error: 0.1825698880971595
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    1.0    4.0    0.0    3.0    0.0    1.0    0.0    11.0   0.0    1.0    2.0    2.0    1.0    5.0    0.0    0.09873417721518987  39 / 395
0.0    320.0  0.0    13.0   2.0    3.0    5.0    9.0    1.0    0.0    2.0    0.0    0.0    0.0    6.0    4.0    0.0    8.0    7.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    0.16449086161879894  63 / 383
0.0    0.0    298.0  1.0    4.0    0.0    14.0   2.0    0.0    0.0    26.0   0.0    0.0    0.0    2.0    0.0    4.0    0.0    11.0   0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
1.0    15.0   0.0    341.0  0.0    2.0    0.0    6.0    0.0    3.0    0.0    0.0    6.0    4.0    4.0    0.0    0.0    8.0    5.0    0.0    0.0    0.0    0.0    2.0    0.0    6.0    0.15384615384615385  62 / 403
0.0    5.0    1.0    0.0    314.0  5.0    18.0   0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    0.0    4.0    12.0   5.0    0.0    0.0    0.0    2.0    0.0    10.0   0.1801566579634465   69 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    1.0    3.0    12.0   0.0    0.0    0.0    0.0    8.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    4.0    0.0    4.0    5.0    1.0    0.0    2.0    2.0    1.0    10.0   0.0    0.0    0.0    0.0    0.0    5.0    0.0    4.0    2.0    1.0    1.0    0.0    337.0  9.0    6.0    0.1446700507614213   57 / 394
0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    5.0    5.0    0.0    3.0    9.0    1.0    13.0   2.0    0.0    343.0  0.0    0.1272264631043257   50 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    34.0   3.0    0.0    0.0    0.0    0.0    0.0    307.0  0.16348773841961853  60 / 367
394.0  484.0  332.0  427.0  400.0  399.0  379.0  315.0  327.0  354.0  404.0  324.0  407.0  392.0  409.0  366.0  340.0  405.0  388.0  377.0  386.0  366.0  428.0  394.0  412.0  394.0  0.18174547635709287  1,818 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818255
2    0.893732
3    0.927622
4    0.948216
5    0.963411
6    0.970409
7    0.976507
8    0.981106
9    0.986404
10   0.990303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20869848701474697
RMSE: 0.45683529528129385
LogLoss: 0.6666629983427547
Mean Per-Class Error: 0.18643009838847743
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20    21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  -----  -----  -----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   1.0   1.0    0.0    2.0    0.0   0.07865168539325842   7 / 89
0.0   79.0   0.0   4.0    1.0   2.0   1.0   3.0   0.0   0.0    1.0    0.0   0.0   0.0    3.0   1.0    0.0   5.0    3.0    0.0   0.0   1.0   1.0    1.0    0.0    0.0   0.25471698113207547   27 / 106
0.0   0.0    63.0  0.0    2.0   0.0   5.0   1.0   0.0   0.0    4.0    0.0   0.0   0.0    1.0   0.0    1.0   0.0    3.0    0.0   1.0   0.0   1.0    0.0    0.0    0.0   0.23170731707317074   19 / 82
1.0   2.0    0.0   95.0   0.0   1.0   0.0   2.0   0.0   2.0    0.0    0.0   3.0   1.0    1.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   0.0    1.0    0.0    1.0   0.15178571428571427   17 / 112
0.0   0.0    0.0   0.0    72.0  4.0   6.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0    3.0   0.0   0.0   0.0    2.0    0.0    3.0   0.25773195876288657   25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   1.0    0.0   2.0    2.0   1.0   0.0   1.0   0.0   0.0    5.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0   0.0   0.0    83.0   2.0    1.0   0.17                  17 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    1.0   3.0    2.0   0.0    0.0    2.0   0.0   3.0   2.0    0.0    93.0   0.0   0.1308411214953271    14 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    7.0    2.0   0.0   0.0   0.0    0.0    0.0    72.0  0.1724137931034483    15 / 87
92.0  113.0  67.0  122.0  91.0  98.0  96.0  78.0  75.0  103.0  104.0  84.0  91.0  100.0  90.0  103.0  85.0  103.0  102.0  91.0  98.0  83.0  107.0  101.0  116.0  97.0  0.18634538152610441   464 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.813655
2    0.897992
3    0.926104
4    0.94739
5    0.961446
6    0.969478
7    0.975502
8    0.981526
9    0.985141
10   0.990362
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:35  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:36  13.268 sec  66271 obs/sec     1         1             10007      0.647962         1.25232             0.99254        0.330001                         0.650584           1.26239               0.992458         0.330924
    2019-07-24 13:09:37  14.333 sec  84590 obs/sec     10        10            100070     0.453594         0.656323            0.996344       0.181745                         0.456835           0.666663              0.996281         0.186345
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0875528
C15         0.963303               0.963303             0.0843398
C8          0.888555               0.888555             0.0777955
C9          0.884272               0.884272             0.0774205
C12         0.833297               0.833297             0.0729575
C11         0.785278               0.785278             0.0687532
C7          0.767705               0.767705             0.0672147
C5          0.760413               0.760413             0.0665763
C6          0.633431               0.633431             0.0554586
C3          0.633358               0.633358             0.0554523
C10         0.630325               0.630325             0.0551868
C14         0.627022               0.627022             0.0548976
C4          0.603953               0.603953             0.0528777
C16         0.556633               0.556633             0.0487348
C1          0.47887                0.47887              0.0419264
C2          0.375264               0.375264             0.0328554
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_20

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.001235046292890729  0.00035619258414953947  0.0         -0.013547348803685688  0.20901238918304443  0.10249504357575182  0.13082951307296753
    3        26       Softmax                      0.0   0.0   0.006038914587931616  0.013935931026935577    0.0         -0.20508775953047229   0.5261754989624023   -0.9096113552401981  0.38863813877105713


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22233506216122725
RMSE: 0.4715241904305942
LogLoss: 0.6954726444974064
Mean Per-Class Error: 0.19002490545691947
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    4.0    5.0    1.0    4.0    0.0    4.0    0.0    0.0    0.0    6.0    0.0    4.0    0.0    2.0    3.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    325.0  0.0    4.0    2.0    1.0    4.0    2.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    2.0    1.0    21.0   5.0    0.0    0.0    3.0    1.0    3.0    3.0    0.0    0.1514360313315927   58 / 383
0.0    0.0    303.0  1.0    16.0   0.0    9.0    0.0    0.0    0.0    18.0   0.0    1.0    0.0    4.0    0.0    3.0    0.0    5.0    1.0    0.0    0.0    7.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
2.0    22.0   0.0    330.0  0.0    0.0    2.0    4.0    0.0    2.0    0.0    0.0    7.0    3.0    4.0    0.0    0.0    10.0   2.0    2.0    0.0    0.0    0.0    7.0    0.0    6.0    0.18114143920595532  73 / 403
0.0    6.0    0.0    0.0    312.0  1.0    12.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    2.0    6.0    5.0    12.0   2.0    0.0    0.0    0.0    6.0    0.0    16.0   0.1875               72 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    13.0   4.0    1.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    3.0    0.0    4.0    11.0   0.0    0.0    1.0    2.0    2.0    7.0    0.0    0.0    0.0    2.0    0.0    5.0    3.0    6.0    3.0    2.0    0.0    0.0    335.0  6.0    2.0    0.14974619289340102  59 / 394
1.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    9.0    9.0    0.0    19.0   1.0    0.0    341.0  0.0    0.13010204081632654  51 / 392
1.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    30.0   1.0    0.0    0.0    0.0    1.0    0.0    312.0  0.14986376021798364  55 / 367
399.0  478.0  359.0  417.0  428.0  355.0  330.0  296.0  342.0  350.0  399.0  335.0  434.0  378.0  391.0  368.0  358.0  443.0  356.0  376.0  382.0  369.0  439.0  404.0  418.0  399.0  0.18934319704088773  1,894 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.810657
2    0.891533
3    0.927322
4    0.948016
5    0.962111
6    0.971808
7    0.977307
8    0.980906
9    0.985004
10   0.988603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22444763459419176
RMSE: 0.4737590469787271
LogLoss: 0.7005819937706235
Mean Per-Class Error: 0.19298507289699823
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12    13    14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0   0.0   1.0    1.0   2.0    0.0    0.0898876404494382   8 / 89
0.0   83.0   0.0   1.0    1.0    0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   3.0   1.0    0.0   9.0    1.0   0.0   0.0   2.0   1.0    1.0   1.0    0.0    0.2169811320754717   23 / 106
0.0   0.0    63.0  0.0    3.0    0.0   3.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   2.0   0.0    1.0   0.0    3.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.23170731707317074  19 / 82
2.0   3.0    0.0   94.0   0.0    0.0   1.0   2.0   0.0   1.0   0.0   0.0   3.0   1.0   1.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    1.0    0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    76.0   1.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    4.0   0.0   0.0   0.0   0.0    2.0   0.0    7.0    0.21649484536082475  21 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0   1.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   1.0    0.0   2.0    6.0    0.0   0.0   1.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0    1.0   2.0    1.0   0.0   1.0   0.0   0.0    79.0  2.0    1.0    0.21                 21 / 100
0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0    0.0   1.0   0.0   7.0   1.0    0.0   94.0   0.0    0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    2.0    0.0   0.0   0.0   0.0   2.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0    0.0   0.0    76.0   0.12643678160919541  11 / 87
95.0  112.0  77.0  114.0  102.0  85.0  85.0  78.0  83.0  99.0  98.0  90.0  97.0  99.0  83.0  103.0  92.0  115.0  86.0  85.0  95.0  84.0  112.0  97.0  118.0  106.0  0.1927710843373494   480 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.807229
2    0.89237
3    0.927309
4    0.948193
5    0.959839
6    0.971888
7    0.977109
8    0.980723
9    0.984337
10   0.988353
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:20  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:20  57.700 sec  57182 obs/sec     1         1             10007      0.663956         1.29612             0.992166       0.338798                         0.664015           1.29079               0.992144         0.345382
    2019-07-24 13:10:22  59.328 sec  57215 obs/sec     10        10            100070     0.471524         0.695473            0.996049       0.189343                         0.473759           0.700582              0.996001         0.192771
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0890378
C13         0.959245               0.959245             0.085409
C8          0.841593               0.841593             0.0749336
C9          0.801904               0.801904             0.0713997
C11         0.798358               0.798358             0.071084
C12         0.797178               0.797178             0.070979
C7          0.77804                0.77804              0.069275
C14         0.681312               0.681312             0.0606626
C10         0.664447               0.664447             0.0591609
C6          0.661855               0.661855             0.0589302
C5          0.657918               0.657918             0.0585796
C3          0.600653               0.600653             0.0534808
C4          0.573176               0.573176             0.0510343
C16         0.566271               0.566271             0.0504196
C2          0.443396               0.443396             0.039479
C1          0.405838               0.405838             0.0361349
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_34

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  ------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013275968217385525  0.0003724447451531887   0.0         0.008082329746230243    0.7203054428100586  -0.035521647039925774  0.7597193717956543
    3        26       Softmax                 0.0   0.0   0.0019001745472800953  0.00034018547739833593  0.0         -0.0018384720476835635  0.5008997917175293  -0.45600129090184605   0.21637403964996338


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2150547097488352
RMSE: 0.4637399160616166
LogLoss: 0.7195175404841033
Mean Per-Class Error: 0.2142095909000464
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    3.0    4.0    0.0    4.0    0.0    2.0    1.0    1.0    0.0    2.0    0.0    3.0    2.0    5.0    1.0    0.09620253164556962  38 / 395
0.0    333.0  0.0    6.0    2.0    1.0    2.0    9.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    3.0    3.0    11.0   4.0    0.0    0.0    2.0    1.0    1.0    0.0    1.0    0.13054830287206268  50 / 383
0.0    0.0    292.0  0.0    15.0   4.0    17.0   0.0    0.0    0.0    15.0   1.0    0.0    0.0    10.0   1.0    3.0    0.0    1.0    2.0    5.0    0.0    1.0    0.0    1.0    0.0    0.20652173913043478  76 / 368
5.0    17.0   0.0    328.0  0.0    2.0    0.0    4.0    0.0    3.0    0.0    0.0    7.0    4.0    4.0    3.0    1.0    7.0    7.0    1.0    2.0    0.0    0.0    7.0    0.0    1.0    0.18610421836228289  75 / 403
0.0    13.0   1.0    0.0    288.0  1.0    24.0   1.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    6.0    3.0    7.0    7.0    0.0    0.0    0.0    11.0   5.0    12.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    10.0   3.0    1.0    0.0    3.0    0.0    0.0    0.0    2.0    8.0    330.0  0.0    0.0    0.0    0.12234042553191489  46 / 376
0.0    5.0    0.0    14.0   12.0   0.0    0.0    1.0    3.0    0.0    5.0    4.0    0.0    0.0    2.0    1.0    4.0    4.0    5.0    5.0    2.0    0.0    0.0    316.0  5.0    4.0    0.19387755102040816  76 / 392
0.0    2.0    0.0    3.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    7.0    0.0    2.0    11.0   2.0    12.0   1.0    0.0    336.0  0.0    0.1450381679389313   57 / 393
3.0    0.0    0.0    1.0    24.0   1.0    0.0    0.0    0.0    19.0   0.0    3.0    0.0    0.0    0.0    0.0    8.0    2.0    32.0   6.0    0.0    0.0    0.0    4.0    0.0    264.0  0.28065395095367845  103 / 367
415.0  525.0  356.0  450.0  414.0  355.0  343.0  298.0  318.0  362.0  385.0  341.0  455.0  339.0  426.0  392.0  394.0  389.0  317.0  385.0  395.0  372.0  404.0  402.0  420.0  351.0  0.21283614915525342  2,129 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787164
2    0.880236
3    0.918324
4    0.939118
5    0.952314
6    0.963011
7    0.970709
8    0.976107
9    0.980806
10   0.984105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21914770490793392
RMSE: 0.4681321447069555
LogLoss: 0.728258506744848
Mean Per-Class Error: 0.21836539731842908
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0    0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   1.0   1.0   3.0    0.0   0.07865168539325842  7 / 89
0.0    88.0   0.0   1.0    1.0   0.0   1.0   4.0   0.0   0.0    0.0    0.0   0.0    0.0   2.0   0.0    1.0    5.0    0.0   0.0   0.0    1.0   1.0   1.0   0.0    0.0   0.16981132075471697  18 / 106
0.0    0.0    63.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   4.0   0.0    1.0    0.0    0.0   1.0   0.0    0.0   0.0   0.0   1.0    0.0   0.23170731707317074  19 / 82
3.0    1.0    0.0   92.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0    0.0   3.0    0.0   1.0   2.0    0.0    0.0    2.0   0.0   1.0    0.0   0.0   3.0   0.0    1.0   0.17857142857142858  20 / 112
0.0    3.0    0.0   0.0    69.0  1.0   6.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0   0.0   0.0    1.0    1.0    3.0   3.0   0.0    0.0   0.0   1.0   1.0    7.0   0.28865979381443296  28 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   3.0    1.0   0.0   0.0    1.0    0.0    0.0   0.0   1.0    2.0   82.0  0.0   0.0    0.0   0.10869565217391304  10 / 92
0.0    2.0    0.0   5.0    4.0   0.0   0.0   0.0   0.0   0.0    2.0    3.0   0.0    0.0   0.0   0.0    0.0    1.0    1.0   1.0   1.0    0.0   0.0   78.0  2.0    0.0   0.22                 22 / 100
0.0    1.0    0.0   1.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   1.0   1.0    3.0    0.0    0.0   4.0   0.0    3.0   1.0   0.0   89.0   0.0   0.16822429906542055  18 / 107
1.0    0.0    0.0   1.0    9.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0    1.0    5.0   2.0   0.0    0.0   0.0   0.0   0.0    63.0  0.27586206896551724  24 / 87
100.0  137.0  74.0  127.0  93.0  81.0  84.0  72.0  69.0  104.0  100.0  91.0  103.0  94.0  88.0  110.0  104.0  100.0  81.0  89.0  101.0  89.0  96.0  96.0  119.0  88.0  0.21686746987951808  540 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783133
2    0.881124
3    0.923293
4    0.944578
5    0.956225
6    0.96506
7    0.971887
8    0.975502
9    0.979518
10   0.982731
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:57  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:57  1 min 34.465 sec  54091 obs/sec     1         1             10007      0.607928         1.15781             0.993431       0.321304                         0.608175           1.14459               0.993409         0.32249
    2019-07-24 13:10:59  1 min 36.345 sec  49222 obs/sec     10        10            100070     0.46374          0.719518            0.996178       0.212836                         0.468132           0.728259              0.996095         0.216867
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0903372
C9          0.932894               0.932894             0.084275
C13         0.874844               0.874844             0.0790309
C11         0.837096               0.837096             0.0756209
C12         0.835107               0.835107             0.0754412
C8          0.797239               0.797239             0.0720203
C7          0.76499                0.76499              0.069107
C10         0.696421               0.696421             0.0629127
C14         0.683695               0.683695             0.061763
C16         0.680228               0.680228             0.0614499
C6          0.649387               0.649387             0.0586637
C5          0.572699               0.572699             0.051736
C4          0.463095               0.463095             0.0418347
C3          0.444638               0.444638             0.0401673
C1          0.438189               0.438189             0.0395847
C2          0.39912                0.39912              0.0360554
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_31

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007583407050333335  0.00017002708045765758  0.0         -0.027456177999141573  0.28864002227783203  0.1893237143225965    0.26461076736450195
    3        26       Softmax                      0.0   0.0   0.004874812748102368   0.011303119361400604    0.0         -0.39878728521608325   0.8620989322662354   -0.45911060000677445  0.3734409809112549


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22394806274187107
RMSE: 0.4732315107237377
LogLoss: 0.7213247113845692
Mean Per-Class Error: 0.20619311238830684
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    5.0    5.0    0.0    3.0    0.0    2.0    0.0    4.0    1.0    6.0    0.0    1.0    4.0    2.0    1.0    4.0    0.0    0.10632911392405063  42 / 395
0.0    328.0  0.0    3.0    2.0    1.0    5.0    9.0    2.0    1.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0    15.0   6.0    0.0    2.0    1.0    0.0    4.0    0.0    0.0    0.14136125654450263  54 / 382
0.0    0.0    293.0  0.0    12.0   0.0    15.0   2.0    0.0    0.0    25.0   0.0    1.0    0.0    2.0    0.0    3.0    2.0    7.0    3.0    1.0    0.0    2.0    0.0    0.0    0.0    0.20380434782608695  75 / 368
1.0    16.0   0.0    328.0  0.0    2.0    0.0    9.0    0.0    5.0    0.0    0.0    5.0    6.0    4.0    2.0    0.0    8.0    3.0    0.0    0.0    0.0    0.0    8.0    0.0    6.0    0.18610421836228289  75 / 403
0.0    7.0    2.0    0.0    298.0  1.0    15.0   3.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    2.0    5.0    4.0    2.0    6.0    0.0    0.0    0.0    8.0    1.0    23.0   0.22395833333333334  86 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    4.0    0.0    9.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    4.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    2.0    0.0    12.0   3.0    0.0    0.0    1.0    7.0    2.0    9.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    3.0    13.0   2.0    1.0    0.0    325.0  7.0    4.0    0.17302798982188294  68 / 393
0.0    0.0    0.0    0.0    0.0    6.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    3.0    11.0   6.0    32.0   0.0    0.0    317.0  1.0    0.19338422391857507  76 / 393
1.0    0.0    0.0    0.0    14.0   1.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    1.0    16.0   3.0    0.0    0.0    0.0    3.0    0.0    309.0  0.1557377049180328   57 / 366
411.0  490.0  350.0  428.0  382.0  373.0  339.0  340.0  363.0  359.0  407.0  325.0  419.0  348.0  378.0  380.0  367.0  438.0  273.0  374.0  398.0  393.0  435.0  391.0  407.0  435.0  0.20533839848045587  2,054 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.794662
2    0.884035
3    0.919624
4    0.941518
5    0.956313
6    0.96511
7    0.972408
8    0.978106
9    0.983105
10   0.985904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22802874899577283
RMSE: 0.47752355857671863
LogLoss: 0.7364662384574785
Mean Per-Class Error: 0.2070879220835024
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    2.0   1.0    1.0   2.0    0.0    0.10112359550561797  9 / 89
0.0   83.0   0.0   0.0    1.0   0.0   2.0   4.0   1.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0    6.0    2.0   0.0   2.0    1.0   0.0    2.0   0.0    0.0    0.2169811320754717   23 / 106
0.0   0.0    63.0  0.0    2.0   0.0   4.0   1.0   0.0   0.0    6.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    3.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0    0.23170731707317074  19 / 82
1.0   2.0    0.0   93.0   0.0   0.0   0.0   5.0   0.0   1.0    0.0    0.0   2.0   2.0   0.0   2.0    0.0    1.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0    0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    73.0  1.0   3.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   0.0   0.0    2.0    1.0    0.0   3.0   0.0    0.0   0.0    2.0   0.0    8.0    0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   4.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   0.0    0.0   4.0    1.0   0.0   0.0   1.0   3.0   0.0    4.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   3.0   0.0    0.0   0.0    80.0  3.0    0.0    0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    6.0    0.0    0.0   3.0   3.0    10.0  0.0    0.0   83.0   0.0    0.22429906542056074  24 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    73.0   0.16091954022988506  14 / 87
96.0  112.0  74.0  121.0  94.0  81.0  81.0  90.0  90.0  101.0  105.0  87.0  91.0  97.0  71.0  108.0  101.0  111.0  71.0  91.0  105.0  94.0  106.0  92.0  112.0  108.0  0.20682730923694778  515 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793173
2    0.883133
3    0.918876
4    0.937349
5    0.954619
6    0.965462
7    0.970281
8    0.975101
9    0.97992
10   0.983534
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:51  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:52  1 min 29.130 sec  116360 obs/sec    1         1             10007      0.701983         1.47837             0.99124        0.386184                         0.704163           1.48426               0.991165         0.393173
    2019-07-24 13:10:52  1 min 29.864 sec  124931 obs/sec    10        10            100070     0.473232         0.721325            0.996019       0.205338                         0.477524           0.736466              0.995937         0.206827
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0957044
C13         0.883683               0.883683             0.0845723
C7          0.847875               0.847875             0.0811453
C12         0.809709               0.809709             0.0774927
C8          0.804487               0.804487             0.0769929
C9          0.748178               0.748178             0.0716039
C14         0.690872               0.690872             0.0661195
C11         0.687083               0.687083             0.0657569
C5          0.608838               0.608838             0.0582685
C16         0.598943               0.598943             0.0573215
C10         0.545113               0.545113             0.0521697
C6          0.539737               0.539737             0.0516552
C3          0.537124               0.537124             0.0514051
C4          0.484423               0.484423             0.0463614
C1          0.353453               0.353453             0.033827
C2          0.309325               0.309325             0.0296038
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_5

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.000783170045224324  0.00018446502508595586  0.0         -0.008561980863646568  0.28810644149780273  0.21589368710178997  0.25483405590057373
    3        26       Softmax                      0.0   0.0   0.00559198718845157   0.021637894213199615    0.0         -0.39174953754678216   0.8629434108734131   -0.4507273271734     0.3272644281387329


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22362979510341577
RMSE: 0.4728951206170516
LogLoss: 0.7310831665043279
Mean Per-Class Error: 0.20400486492724967
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    3.0    4.0    6.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    1.0    0.0    6.0    1.0    5.0    3.0    0.11139240506329114  44 / 395
0.0    297.0  0.0    13.0   2.0    1.0    5.0    9.0    2.0    1.0    1.0    1.0    2.0    0.0    2.0    14.0   5.0    13.0   7.0    0.0    0.0    0.0    2.0    6.0    0.0    0.0    0.2245430809399478   86 / 383
0.0    0.0    301.0  0.0    9.0    0.0    32.0   0.0    0.0    0.0    8.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    1.0    4.0    2.0    0.0    2.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
2.0    8.0    0.0    327.0  2.0    1.0    5.0    5.0    1.0    6.0    0.0    2.0    4.0    6.0    4.0    6.0    1.0    10.0   3.0    0.0    1.0    0.0    0.0    2.0    1.0    5.0    0.1865671641791045   75 / 402
0.0    10.0   1.0    0.0    292.0  1.0    18.0   3.0    0.0    0.0    8.0    3.0    0.0    0.0    0.0    1.0    3.0    7.0    4.0    5.0    0.0    0.0    0.0    9.0    0.0    19.0   0.23958333333333334  92 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    3.0    0.0    0.0    3.0    6.0    0.0    0.0    1.0    0.0    13.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    0.0    0.0    5.0    7.0    1.0    0.0    5.0    1.0    2.0    8.0    0.0    0.0    0.0    1.0    0.0    6.0    0.0    18.0   3.0    2.0    0.0    0.0    333.0  1.0    1.0    0.1548223350253807   61 / 394
0.0    0.0    0.0    0.0    0.0    9.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    4.0    16.0   2.0    36.0   1.0    0.0    318.0  0.0    0.19083969465648856  75 / 393
1.0    0.0    0.0    1.0    12.0   0.0    0.0    0.0    0.0    16.0   0.0    2.0    0.0    0.0    0.0    0.0    7.0    0.0    33.0   2.0    0.0    0.0    0.0    2.0    0.0    291.0  0.20708446866485014  76 / 367
387.0  427.0  370.0  437.0  365.0  378.0  395.0  299.0  336.0  382.0  405.0  375.0  414.0  379.0  413.0  387.0  338.0  378.0  380.0  390.0  395.0  381.0  441.0  423.0  362.0  366.0  0.20323902829151255  2,033 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796761
2    0.879436
3    0.915126
4    0.936519
5    0.951515
6    0.961712
7    0.969909
8    0.976207
9    0.981106
10   0.985604

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22772260142443224
RMSE: 0.4772028933529555
LogLoss: 0.7383946274380824
Mean Per-Class Error: 0.20948546886138975
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17    18    19    20     21    22     23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    0.0   3.0    0.0    2.0   0.0   0.07865168539325842  7 / 89
0.0   76.0   0.0   4.0    2.0   0.0   0.0   2.0   1.0   0.0    1.0   0.0    0.0   0.0    1.0   6.0    2.0   6.0   2.0   0.0   0.0    0.0   1.0    2.0    0.0   0.0   0.2830188679245283   30 / 106
0.0   0.0    60.0  0.0    2.0   0.0   9.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0   1.0   2.0   0.0    0.0   1.0    0.0    0.0   0.0   0.2682926829268293   22 / 82
1.0   1.0    0.0   92.0   0.0   1.0   2.0   3.0   0.0   2.0    0.0   1.0    2.0   2.0    1.0   1.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.17857142857142858  20 / 112
0.0   2.0    0.0   0.0    70.0  1.0   5.0   0.0   0.0   0.0    3.0   1.0    0.0   0.0    0.0   0.0    2.0   2.0   1.0   2.0   0.0    0.0   0.0    3.0    0.0   5.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    1.0   0.0    0.0   0.0   0.0   0.0   2.0    0.0   85.0   0.0    0.0   0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   4.0    3.0   0.0   0.0   2.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   4.0   0.0   0.0    0.0   0.0    82.0   0.0   1.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0   5.0   0.0    11.0  1.0    0.0    84.0  0.0   0.21495327102803738  23 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   5.0   1.0   0.0    0.0   0.0    0.0    0.0   71.0  0.1839080459770115   16 / 87
91.0  105.0  75.0  127.0  88.0  87.0  95.0  79.0  82.0  105.0  99.0  101.0  89.0  100.0  85.0  113.0  91.0  99.0  91.0  95.0  102.0  86.0  112.0  103.0  97.0  93.0  0.20883534136546184  520 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791165
2    0.879518
3    0.922891
4    0.940161
5    0.954217
6    0.963855
7    0.971887
8    0.977108
9    0.982329
10   0.987148
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:42  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:42  19.964 sec  80056 obs/sec     1         1             10007      0.704626         1.52644             0.991178       0.410277                         0.705561           1.53649               0.99113          0.421285
    2019-07-24 13:09:43  20.759 sec  111560 obs/sec    10        10            100070     0.472895         0.731083            0.996026       0.203239                         0.477203           0.738395              0.995942         0.208835
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0872142
C13         0.932823               0.932823             0.0813554
C7          0.873464               0.873464             0.0761784
C9          0.855336               0.855336             0.0745975
C8          0.792951               0.792951             0.0691566
C12         0.792216               0.792216             0.0690925
C10         0.777645               0.777645             0.0678217
C11         0.690564               0.690564             0.0602269
C5          0.662191               0.662191             0.0577525
C6          0.655963               0.655963             0.0572093
C4          0.653965               0.653965             0.057035
C14         0.648975               0.648975             0.0565998
C3          0.626758               0.626758             0.0546622
C16         0.587794               0.587794             0.0512639
C2          0.464707               0.464707             0.0405291
C1          0.450672               0.450672             0.039305
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_8

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight             weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ----------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.001342268140717806  0.000360312988050282    0.0         0.01584967338817478     0.7339844703674316  0.11148499820791476  0.8200893402099609
    3        26       Softmax                 0.0   0.0   0.00187889944411906   0.00030130427330732346  0.0         -0.0012764523434480696  0.5003933906555176  -0.4468053413339272  0.20233356952667236


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22026111371342927
RMSE: 0.46931984159358664
LogLoss: 0.7373988556668991
Mean Per-Class Error: 0.21708762923048158
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    4.0    2.0    1.0    10.0   0.0    1.0    0.0    0.0    0.0    6.0    2.0    1.0    1.0    3.0    1.0    5.0    0.0    0.10152284263959391  40 / 394
0.0    296.0  0.0    5.0    2.0    3.0    0.0    11.0   3.0    0.0    4.0    0.0    1.0    0.0    2.0    1.0    2.0    32.0   9.0    0.0    1.0    4.0    0.0    3.0    3.0    0.0    0.225130890052356    86 / 382
0.0    0.0    287.0  1.0    23.0   3.0    12.0   6.0    0.0    0.0    20.0   0.0    0.0    0.0    5.0    0.0    1.0    0.0    4.0    0.0    2.0    1.0    3.0    0.0    0.0    0.0    0.22010869565217392  81 / 368
1.0    20.0   0.0    312.0  0.0    5.0    0.0    7.0    0.0    9.0    0.0    1.0    7.0    4.0    3.0    3.0    0.0    11.0   3.0    2.0    0.0    0.0    0.0    11.0   0.0    4.0    0.22580645161290322  91 / 403
0.0    5.0    1.0    0.0    294.0  5.0    11.0   2.0    2.0    0.0    6.0    3.0    0.0    0.0    0.0    3.0    12.0   6.0    3.0    5.0    2.0    0.0    0.0    11.0   0.0    13.0   0.234375             90 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    11.0   4.0    6.0    0.0    0.0    1.0    0.0    0.0    5.0    2.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    1.0    0.0    10.0   9.0    1.0    4.0    4.0    2.0    1.0    6.0    0.0    0.0    2.0    0.0    0.0    7.0    2.0    7.0    2.0    1.0    0.0    0.0    316.0  14.0   5.0    0.19796954314720813  78 / 394
0.0    0.0    0.0    1.0    0.0    8.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    9.0    0.0    2.0    13.0   3.0    8.0    1.0    1.0    343.0  1.0    0.1272264631043257   50 / 393
0.0    0.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    21.0   6.0    0.0    0.0    0.0    6.0    0.0    295.0  0.19618528610354224  72 / 367
418.0  478.0  331.0  396.0  393.0  394.0  344.0  371.0  329.0  394.0  378.0  348.0  436.0  367.0  386.0  361.0  383.0  436.0  282.0  367.0  385.0  353.0  438.0  410.0  441.0  384.0  0.21613515945216435  2,162 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783865
2    0.873838
3    0.915625
4    0.938718
5    0.953014
6    0.963711
7    0.971209
8    0.977507
9    0.981905
10   0.985704

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22305321434709077
RMSE: 0.4722850985867443
LogLoss: 0.7418268346794655
Mean Per-Class Error: 0.21866569015950482
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20    21    22     23    24     25     Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  --------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   2.0    1.0   2.0    0.0    0.10112359550561797   9 / 89
0.0   77.0   0.0   2.0    1.0   0.0   0.0   2.0   1.0   0.0    1.0   0.0   0.0   0.0   1.0   1.0    2.0   11.0   2.0   0.0   1.0   3.0   0.0    1.0   0.0    0.0    0.27358490566037735   29 / 106
0.0   0.0    58.0  0.0    5.0   2.0   3.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0   0.0   1.0   1.0   1.0    0.0   0.0    0.0    0.2926829268292683    24 / 82
1.0   2.0    0.0   88.0   0.0   1.0   0.0   4.0   0.0   2.0    0.0   1.0   3.0   1.0   1.0   2.0    0.0   3.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    2.0    0.21428571428571427   24 / 112
0.0   2.0    0.0   0.0    70.0  3.0   4.0   0.0   1.0   0.0    2.0   1.0   0.0   0.0   0.0   1.0    2.0   1.0    1.0   2.0   0.0   0.0   0.0    2.0   0.0    5.0    0.27835051546391754   27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   88.0   0.0   0.0    0.0    0.043478260869565216  4 / 92
0.0   0.0    0.0   3.0    3.0   0.0   1.0   1.0   1.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0    2.0   2.0    2.0   0.0   0.0   0.0   0.0    76.0  5.0    1.0    0.24                  24 / 100
0.0   0.0    0.0   0.0    0.0   2.0   1.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0   2.0   0.0   3.0   1.0    0.0   95.0   0.0    0.11214953271028037   12 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    2.0   2.0   0.0   0.0   0.0    1.0   0.0    72.0   0.1724137931034483    15 / 87
96.0  113.0  68.0  113.0  90.0  93.0  80.0  91.0  76.0  119.0  92.0  93.0  99.0  93.0  78.0  105.0  98.0  119.0  76.0  81.0  98.0  81.0  115.0  96.0  127.0  100.0  0.21807228915662652   543 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781928
2    0.871486
3    0.919277
4    0.940161
5    0.95502
6    0.964257
7    0.973092
8    0.978715
9    0.980723
10   0.985542
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:48  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:48  25.934 sec  54683 obs/sec     1         1             10007      0.604266         1.16492             0.99351        0.317505                         0.600556           1.1481                0.993573         0.316466
    2019-07-24 13:09:50  27.822 sec  49102 obs/sec     10        10            100070     0.46932          0.737399            0.996085       0.216135                         0.472285           0.741827              0.996026         0.218072
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0890693
C15         0.920107               0.920107             0.0819533
C12         0.914195               0.914195             0.0814267
C9          0.838224               0.838224             0.07466
C8          0.798814               0.798814             0.0711498
C7          0.757973               0.757973             0.0675121
C11         0.748149               0.748149             0.0666371
C14         0.693379               0.693379             0.0617588
C16         0.668025               0.668025             0.0595005
C10         0.666751               0.666751             0.059387
C6          0.661201               0.661201             0.0588927
C5          0.60145                0.60145              0.0535707
C3          0.577898               0.577898             0.0514729
C4          0.555282               0.555282             0.0494585
C1          0.441526               0.441526             0.0393264
C2          0.384244               0.384244             0.0342243
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_12

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.001135265391781104   0.0003169436240568757  0.0         -0.004038426860631716  0.554347038269043   0.039918080718446346  0.624575138092041
    3        26       Softmax                 0.0   0.0   0.0023069186155715636  0.0005009425804018974  0.0         -0.039034296666404074  0.7328486442565918  -0.5251550773640399   0.27544736862182617


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22127870771399272
RMSE: 0.47040270802153417
LogLoss: 0.7483658573553748
Mean Per-Class Error: 0.2086688094493816
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    1.0    5.0    1.0    4.0    0.0    8.0    0.0    0.0    1.0    3.0    0.0    3.0    0.0    2.0    1.0    4.0    0.0    0.08860759493670886  35 / 395
0.0    285.0  0.0    8.0    3.0    7.0    4.0    5.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    1.0    0.0    34.0   26.0   1.0    0.0    2.0    0.0    4.0    0.0    0.0    0.2558746736292428   98 / 383
0.0    0.0    293.0  1.0    13.0   1.0    15.0   3.0    0.0    0.0    23.0   2.0    0.0    0.0    8.0    0.0    3.0    0.0    1.0    2.0    0.0    0.0    2.0    1.0    0.0    0.0    0.20380434782608695  75 / 368
1.0    9.0    0.0    347.0  0.0    0.0    0.0    4.0    0.0    4.0    1.0    0.0    5.0    5.0    3.0    7.0    0.0    11.0   2.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.13895781637717122  56 / 403
0.0    6.0    2.0    0.0    287.0  8.0    6.0    2.0    0.0    0.0    14.0   3.0    0.0    0.0    0.0    1.0    10.0   6.0    9.0    1.0    1.0    0.0    0.0    5.0    0.0    22.0   0.2506527415143603   96 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    25.0   11.0   3.0    0.0    0.0    3.0    0.0    0.0    1.0    5.0    324.0  0.0    0.0    0.0    0.13829787234042554  52 / 376
0.0    2.0    0.0    7.0    3.0    5.0    0.0    0.0    2.0    1.0    8.0    2.0    0.0    0.0    2.0    0.0    6.0    2.0    4.0    3.0    2.0    0.0    0.0    338.0  1.0    6.0    0.14213197969543148  56 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    2.0    0.0    11.0   0.0    1.0    14.0   0.0    29.0   1.0    0.0    326.0  0.0    0.17048346055979643  67 / 393
1.0    0.0    0.0    1.0    14.0   1.0    0.0    0.0    0.0    10.0   0.0    3.0    0.0    0.0    0.0    0.0    1.0    3.0    47.0   3.0    0.0    0.0    0.0    3.0    0.0    280.0  0.23705722070844687  87 / 367
411.0  416.0  374.0  457.0  361.0  396.0  301.0  306.0  323.0  361.0  394.0  353.0  444.0  394.0  375.0  395.0  365.0  470.0  399.0  379.0  392.0  371.0  381.0  429.0  387.0  369.0  0.20743776866939917  2,075 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792562
2    0.884535
3    0.916625
4    0.936819
5    0.951015
6    0.960512
7    0.96781
8    0.973608
9    0.979906
10   0.984505

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22238947627620054
RMSE: 0.47158188713753685
LogLoss: 0.7436758764229251
Mean Per-Class Error: 0.21016241820092232
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1     2     3      4     5     6     7     8     9      10     11    12     13     14    15     16    17     18    19    20    21    22    23     24     25    Error                Rate
-----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
83.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0   2.0   0.0   0.0   0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0    76.0  0.0   2.0    2.0   2.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   11.0   6.0   1.0   0.0   1.0   0.0   3.0    0.0    0.0   0.2830188679245283   30 / 106
0.0    0.0   62.0  0.0    2.0   0.0   4.0   2.0   0.0   0.0    5.0    0.0   0.0    0.0    3.0   0.0    2.0   0.0    0.0   1.0   0.0   0.0   1.0   0.0    0.0    0.0   0.24390243902439024  20 / 82
1.0    0.0   0.0   96.0   0.0   0.0   0.0   1.0   0.0   1.0    1.0    0.0   2.0    2.0    2.0   2.0    0.0   2.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.14285714285714285  16 / 112
0.0    2.0   1.0   0.0    68.0  4.0   1.0   0.0   0.0   0.0    5.0    2.0   0.0    0.0    0.0   1.0    3.0   2.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0    6.0   0.29896907216494845  29 / 97
---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   6.0    3.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   82.0  0.0    0.0    0.0   0.10869565217391304  10 / 92
0.0    0.0   0.0   2.0    1.0   1.0   0.0   0.0   1.0   0.0    3.0    2.0   0.0    0.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0   0.0   0.0   85.0   0.0    2.0   0.15                 15 / 100
0.0    0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    1.0    1.0   0.0    5.0   0.0    0.0   5.0   0.0   7.0   1.0   0.0    85.0   0.0   0.205607476635514    22 / 107
0.0    0.0   0.0   1.0    3.0   1.0   0.0   0.0   0.0   0.0    0.0    2.0   0.0    0.0    0.0   0.0    0.0   1.0    9.0   1.0   0.0   0.0   0.0   1.0    0.0    68.0  0.21839080459770116  19 / 87
101.0  99.0  82.0  124.0  80.0  92.0  69.0  76.0  74.0  103.0  101.0  95.0  100.0  104.0  81.0  113.0  97.0  122.0  95.0  92.0  98.0  80.0  95.0  113.0  107.0  97.0  0.20963855421686747  522 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790361
2    0.88755
3    0.917269
4    0.933735
5    0.948996
6    0.959036
7    0.967871
8    0.974297
9    0.981928
10   0.985944
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:58  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:58  35.743 sec  78179 obs/sec     1         1             10007      0.663385         1.38025             0.992181       0.378586                         0.659551           1.36297               0.992249         0.375502
    2019-07-24 13:09:59  36.956 sec  76564 obs/sec     10        10            100070     0.470403         0.748366            0.996068       0.207438                         0.471582           0.743676              0.996037         0.209639
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0935265
C13         0.944972               0.944972             0.0883799
C8          0.887273               0.887273             0.0829836
C12         0.8636                 0.8636               0.0807695
C9          0.858509               0.858509             0.0802934
C7          0.846568               0.846568             0.0791766
C11         0.781707               0.781707             0.0731103
C14         0.679843               0.679843             0.0635833
C16         0.649698               0.649698             0.060764
C10         0.635141               0.635141             0.0594025
C6          0.596406               0.596406             0.0557798
C5          0.478756               0.478756             0.0447764
C4          0.43503                0.43503              0.0406868
C3          0.420908               0.420908             0.0393661
C2          0.30949                0.30949              0.0289455
C1          0.304254               0.304254             0.0284558
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_39

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011643483112493414  0.00037812069058418274  0.0         -0.009373370554556004  0.5816423892974854  -0.05368015935669093  0.6927509307861328
    3        26       Softmax                 0.0   0.0   0.002228448707543206   0.0005012326873838902   0.0         -0.042199879096957514  0.7363252639770508  -0.5049266351883105   0.21132421493530273


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2222172661354522
RMSE: 0.47139926403787713
LogLoss: 0.743908220677938
Mean Per-Class Error: 0.2101497225957552
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
347.0  0.0    0.0    3.0    0.0    0.0    1.0    0.0    1.0    9.0    4.0    1.0    8.0    0.0    0.0    0.0    2.0    3.0    2.0    0.0    1.0    0.0    6.0    2.0    5.0    0.0    0.12151898734177215  48 / 395
1.0    312.0  0.0    8.0    2.0    0.0    1.0    8.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    3.0    2.0    26.0   6.0    0.0    0.0    4.0    1.0    2.0    1.0    1.0    0.185378590078329    71 / 383
0.0    0.0    310.0  0.0    14.0   0.0    16.0   1.0    0.0    0.0    12.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    4.0    0.0    5.0    0.0    2.0    0.0    1.0    0.0    0.15760869565217392  58 / 368
3.0    13.0   0.0    319.0  0.0    1.0    0.0    8.0    0.0    3.0    1.0    0.0    7.0    4.0    8.0    4.0    2.0    12.0   1.0    1.0    3.0    0.0    0.0    5.0    1.0    7.0    0.20843672456575682  84 / 403
0.0    5.0    3.0    0.0    288.0  4.0    19.0   0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    17.0   3.0    0.0    0.0    0.0    7.0    0.0    22.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    10.0   0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    13.0   4.0    3.0    0.0    1.0    1.0    0.0    0.0    4.0    1.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
1.0    2.0    0.0    2.0    8.0    2.0    0.0    3.0    1.0    1.0    10.0   1.0    0.0    0.0    0.0    0.0    10.0   2.0    4.0    9.0    1.0    0.0    0.0    326.0  3.0    8.0    0.17258883248730963  68 / 394
0.0    0.0    1.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    6.0    14.0   0.0    0.0    33.0   3.0    28.0   0.0    0.0    296.0  2.0    0.24489795918367346  96 / 392
2.0    2.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    27.0   6.0    0.0    0.0    0.0    0.0    4.0    298.0  0.1880108991825613   69 / 367
421.0  475.0  367.0  409.0  370.0  337.0  375.0  329.0  332.0  378.0  373.0  333.0  421.0  363.0  389.0  385.0  363.0  466.0  345.0  402.0  392.0  382.0  419.0  393.0  372.0  412.0  0.2095371388583425   2,096 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790463
2    0.878836
3    0.916225
4    0.937819
5    0.954114
6    0.964111
7    0.971009
8    0.976507
9    0.980906
10   0.985204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22315954588616913
RMSE: 0.47239765652061516
LogLoss: 0.7506885701115511
Mean Per-Class Error: 0.21146701181992592
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
76.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   2.0   0.0    0.0   0.0    1.0   2.0    1.0   0.0   0.0    0.0   2.0    2.0   2.0    0.0   0.14606741573033707  13 / 89
0.0   81.0   0.0   2.0    1.0   0.0   1.0   3.0   1.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   9.0    2.0   0.0   0.0    2.0   1.0    1.0   1.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    68.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    0.0   1.0    0.0   0.17073170731707318  14 / 82
3.0   2.0    0.0   88.0   0.0   1.0   0.0   3.0   0.0   1.0    1.0   0.0   3.0   0.0    3.0   2.0    1.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.21428571428571427  24 / 112
0.0   2.0    0.0   0.0    69.0  1.0   7.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0   1.0   0.0    0.0   0.0    1.0   0.0    7.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   1.0    1.0   0.0    1.0   0.0    0.0   0.0   1.0    0.0   83.0   0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0   0.0    0.0   2.0    3.0   1.0   0.0   1.0   0.0   0.0    4.0   1.0   0.0   0.0    0.0   0.0    2.0   2.0    2.0   0.0   0.0    0.0   0.0    78.0  1.0    3.0   0.22                 22 / 100
0.0   0.0    1.0   1.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    4.0   0.0    0.0   6.0   1.0    8.0   0.0    0.0   82.0   0.0   0.2336448598130841   25 / 107
0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0   2.0   0.0    0.0   0.0    0.0   0.0    70.0  0.19540229885057472  17 / 87
92.0  117.0  80.0  115.0  84.0  84.0  97.0  83.0  80.0  105.0  95.0  92.0  90.0  100.0  84.0  105.0  89.0  124.0  89.0  92.0  101.0  88.0  104.0  93.0  108.0  99.0  0.21244979919678714  529 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.78755
2    0.877912
3    0.915663
4    0.936546
5    0.951406
6    0.964659
7    0.970683
8    0.975502
9    0.980321
10   0.984337
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:07  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:08  1 min 45.199 sec  65835 obs/sec     1         1             10007      0.670056         1.38228             0.992022       0.374488                         0.667559           1.36746               0.992059         0.377912
    2019-07-24 13:11:09  1 min 46.418 sec  74125 obs/sec     10        10            100070     0.471399         0.743908            0.996051       0.209537                         0.472398           0.750689              0.996024         0.21245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.102146
C13         0.890545               0.890545             0.0909659
C12         0.818065               0.818065             0.0835623
C8          0.740224               0.740224             0.0756112
C11         0.731525               0.731525             0.0747227
C7          0.713156               0.713156             0.0728463
C9          0.674253               0.674253             0.0688725
C10         0.652405               0.652405             0.0666408
C16         0.609786               0.609786             0.0622874
C14         0.581594               0.581594             0.0594077
C6          0.558261               0.558261             0.0570244
C5          0.515963               0.515963             0.0527037
C4          0.414363               0.414363             0.0423257
C3          0.400186               0.400186             0.0408776
C1          0.257989               0.257989             0.0263527
C2          0.23156                0.23156              0.023653
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_18

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011061277546104975  0.0003028302453458309  0.0         -0.06023858723358444  0.5769755840301514  -0.07691397238781665  0.5776355266571045
    3        26       Softmax                 0.0   0.0   0.0021279115448683463  0.0004607735900208354  0.0         0.027223549243129898  0.7377386093139648  -0.5429401775818896   0.2391648292541504


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2222698171390118
RMSE: 0.47145500012091485
LogLoss: 0.7494392738203144
Mean Per-Class Error: 0.20667780210283787
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    8.0    2.0    2.0    3.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    0.0    7.0    1.0    5.0    0.0    0.09367088607594937  37 / 395
1.0    311.0  0.0    12.0   1.0    1.0    2.0    8.0    1.0    0.0    5.0    0.0    0.0    0.0    1.0    2.0    1.0    23.0   3.0    0.0    0.0    1.0    0.0    5.0    3.0    1.0    0.18586387434554974  71 / 382
0.0    0.0    292.0  0.0    13.0   2.0    17.0   2.0    1.0    0.0    18.0   0.0    0.0    0.0    8.0    0.0    1.0    0.0    1.0    2.0    7.0    0.0    4.0    0.0    0.0    0.0    0.20652173913043478  76 / 368
1.0    15.0   0.0    316.0  1.0    1.0    0.0    11.0   0.0    8.0    1.0    0.0    3.0    6.0    4.0    2.0    0.0    22.0   3.0    0.0    1.0    0.0    0.0    4.0    0.0    4.0    0.21588089330024815  87 / 403
0.0    4.0    0.0    1.0    281.0  0.0    41.0   1.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    4.0    5.0    6.0    10.0   0.0    0.0    0.0    0.0    0.0    18.0   0.26631853785900783  102 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    8.0    3.0    0.0    0.0    0.0    10.0   0.0    0.0    6.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    3.0    0.0    3.0    11.0   1.0    1.0    1.0    1.0    4.0    10.0   0.0    0.0    0.0    0.0    0.0    10.0   3.0    14.0   5.0    1.0    1.0    0.0    313.0  6.0    6.0    0.20558375634517767  81 / 394
0.0    0.0    0.0    1.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    4.0    7.0    0.0    3.0    11.0   0.0    10.0   0.0    3.0    340.0  0.0    0.13486005089058525  53 / 393
3.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    20.0   0.0    2.0    0.0    0.0    0.0    0.0    7.0    1.0    17.0   7.0    0.0    0.0    0.0    1.0    1.0    293.0  0.2016348773841962   74 / 367
393.0  480.0  326.0  397.0  386.0  359.0  416.0  328.0  332.0  378.0  430.0  329.0  388.0  394.0  375.0  396.0  381.0  448.0  284.0  401.0  400.0  346.0  427.0  392.0  417.0  400.0  0.20573827851644508  2,058 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.794262
2    0.877737
3    0.913726
4    0.93342
5    0.948016
6    0.956613
7    0.96591
8    0.972208
9    0.977407
10   0.981406

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22861952632034938
RMSE: 0.47814174291767225
LogLoss: 0.7600920664808973
Mean Per-Class Error: 0.21721821915438927
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10     11    12    13     14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0   1.0    0.0    1.0   0.0   1.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   3.0    0.0    0.11235955056179775  10 / 89
0.0   81.0   0.0   3.0    1.0   1.0   2.0    3.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   1.0    1.0   6.0    2.0   0.0   0.0   1.0   0.0    1.0   2.0    0.0    0.2358490566037736   25 / 106
0.0   0.0    59.0  0.0    5.0   1.0   5.0    1.0   0.0   0.0    5.0    0.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.2804878048780488   23 / 82
1.0   3.0    0.0   90.0   0.0   0.0   0.0    5.0   0.0   2.0    0.0    0.0   1.0   3.0    0.0   0.0    0.0   5.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0    0.19642857142857142  22 / 112
0.0   0.0    0.0   0.0    67.0  0.0   11.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0   4.0   0.0   0.0   0.0    0.0   0.0    7.0    0.30927835051546393  30 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   3.0   0.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0   1.0    0.0   1.0    4.0   0.0   1.0    1.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0    5.0   0.0   0.0   0.0   0.0    73.0  3.0    4.0    0.27                 27 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0   1.0    0.0   1.0    2.0   0.0    0.0   3.0   0.0   4.0   0.0    1.0   92.0   0.0    0.14018691588785046  15 / 107
0.0   0.0    0.0   0.0    2.0   0.0   1.0    0.0   0.0   6.0    0.0    2.0   0.0   0.0    0.0   0.0    2.0   0.0    5.0   2.0   0.0   0.0   0.0    1.0   1.0    65.0   0.25287356321839083  22 / 87
88.0  117.0  62.0  109.0  91.0  88.0  109.0  89.0  76.0  108.0  111.0  89.0  82.0  107.0  74.0  116.0  99.0  115.0  73.0  89.0  98.0  76.0  109.0  91.0  122.0  102.0  0.21646586345381527  539 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783534
2    0.872691
3    0.911245
4    0.931325
5    0.946988
6    0.955823
7    0.969076
8    0.973896
9    0.978313
10   0.983936
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:17  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:18  55.201 sec  78179 obs/sec     1         1             10007      0.678322         1.41817             0.991822       0.384685                         0.676609           1.40456               0.991843         0.382731
    2019-07-24 13:10:19  56.320 sec  81890 obs/sec     10        10            100070     0.471455         0.749439            0.99605        0.205738                         0.478142           0.760092              0.995926         0.216466
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0995721
C15         0.932523               0.932523             0.0928533
C9          0.778337               0.778337             0.0775007
C12         0.777453               0.777453             0.0774127
C8          0.77205                0.77205              0.0768746
C11         0.699255               0.699255             0.0696263
C14         0.69754                0.69754              0.0694556
C7          0.638631               0.638631             0.0635898
C6          0.636041               0.636041             0.063332
C10         0.635856               0.635856             0.0633135
C16         0.512019               0.512019             0.0509828
C5          0.449665               0.449665             0.0447741
C4          0.425232               0.425232             0.0423413
C3          0.401408               0.401408             0.039969
C2          0.374874               0.374874             0.037327
C1          0.312089               0.312089             0.0310754
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_30

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015572622920672075  0.00036148622166365385  0.0         0.029897675667371004  0.7637426853179932  0.056892926652113485  0.7481520175933838
    3        26       Softmax                 0.0   0.0   0.0018381307766923362  0.0003086054930463433   0.0         0.006709123630046703  0.3852180242538452  -0.5329309569967038   0.2937253713607788


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2161488702076212
RMSE: 0.4649181328014871
LogLoss: 0.7427938299108583
Mean Per-Class Error: 0.20706771681887068
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    5.0    0.0    1.0    0.0    1.0    1.0    6.0    3.0    3.0    0.0    2.0    4.0    6.0    0.0    0.09113924050632911  36 / 395
0.0    325.0  0.0    5.0    3.0    0.0    2.0    1.0    5.0    0.0    1.0    0.0    1.0    0.0    2.0    2.0    1.0    27.0   3.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.1514360313315927   58 / 383
0.0    1.0    279.0  0.0    16.0   0.0    32.0   1.0    0.0    0.0    13.0   0.0    0.0    0.0    4.0    0.0    1.0    0.0    10.0   3.0    2.0    0.0    6.0    0.0    0.0    0.0    0.2418478260869565   89 / 368
4.0    30.0   0.0    325.0  1.0    1.0    0.0    2.0    0.0    6.0    1.0    0.0    7.0    3.0    1.0    3.0    0.0    11.0   1.0    0.0    1.0    0.0    0.0    6.0    0.0    0.0    0.1935483870967742   78 / 403
0.0    4.0    1.0    0.0    286.0  3.0    24.0   0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    6.0    9.0    10.0   0.0    0.0    0.0    13.0   1.0    16.0   0.2552083333333333   98 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    7.0    0.0    2.0    0.0    0.0    11.0   0.0    0.0    1.0    1.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
6.0    5.0    0.0    5.0    8.0    1.0    3.0    2.0    3.0    0.0    6.0    1.0    0.0    0.0    2.0    0.0    8.0    4.0    3.0    9.0    1.0    0.0    0.0    318.0  5.0    4.0    0.19289340101522842  76 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    2.0    9.0    0.0    4.0    30.0   2.0    24.0   1.0    0.0    311.0  0.0    0.20865139949109415  82 / 393
2.0    1.0    0.0    1.0    10.0   0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    23.0   8.0    0.0    0.0    0.0    3.0    0.0    307.0  0.16348773841961853  60 / 367
431.0  559.0  305.0  446.0  378.0  349.0  396.0  250.0  336.0  335.0  366.0  328.0  423.0  364.0  379.0  382.0  386.0  463.0  311.0  425.0  390.0  362.0  456.0  418.0  396.0  369.0  0.20603818854343697  2,061 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793962
2    0.877337
3    0.915026
4    0.936919
5    0.950715
6    0.961911
7    0.970109
8    0.976507
9    0.981206
10   0.985304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22160322661512485
RMSE: 0.4707475189686344
LogLoss: 0.7630716439137823
Mean Per-Class Error: 0.21101113990145406
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6      7     8     9     10    11    12    13     14    15     16    17     18    19     20    21    22     23    24     25    Error                 Rate
-----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  --------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   1.0    2.0   3.0    0.0   0.07865168539325842   7 / 89
0.0    85.0   0.0   1.0    2.0   0.0   2.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0   9.0    0.0   0.0    0.0   2.0   0.0    2.0   0.0    0.0   0.19811320754716982   21 / 106
0.0    0.0    56.0  0.0    4.0   0.0   9.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    4.0   2.0    1.0   0.0   2.0    0.0   0.0    0.0   0.3170731707317073    26 / 82
2.0    5.0    0.0   93.0   0.0   1.0   0.0    1.0   0.0   0.0   1.0   0.0   2.0   2.0    0.0   1.0    0.0   3.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0    0.0   0.16964285714285715   19 / 112
0.0    2.0    0.0   0.0    71.0  2.0   6.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   2.0    3.0   5.0    0.0   0.0   0.0    3.0   0.0    2.0   0.26804123711340205   26 / 97
---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---                   ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0    0.0   0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
1.0    2.0    0.0   2.0    4.0   0.0   1.0    2.0   1.0   0.0   4.0   1.0   0.0   0.0    0.0   0.0    2.0   1.0    1.0   1.0    0.0   0.0   0.0    73.0  3.0    1.0   0.27                  27 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   10.0   2.0   7.0   1.0    0.0   83.0   0.0   0.22429906542056074   24 / 107
0.0    0.0    0.0   1.0    4.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    6.0   3.0    0.0   0.0   0.0    0.0   0.0    71.0  0.1839080459770115    16 / 87
101.0  139.0  61.0  126.0  94.0  81.0  101.0  65.0  78.0  95.0  91.0  89.0  94.0  100.0  77.0  111.0  97.0  114.0  77.0  103.0  99.0  86.0  114.0  98.0  111.0  88.0  0.21004016064257028   523 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.78996
2    0.877108
3    0.912851
4    0.934137
5    0.949398
6    0.959438
7    0.968273
8    0.975502
9    0.981124
10   0.985944
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:49  1 min 26.278 sec  30696 obs/sec     1         1             10007      0.585041         1.10005             0.993919       0.297711                         0.585517           1.10043               0.993891         0.30241
    2019-07-24 13:10:51  1 min 29.004 sec  33490 obs/sec     10        10            100070     0.464918         0.742794            0.99616        0.206038                         0.470748           0.763072              0.996051         0.21004
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0847203
C9          0.99505                0.99505              0.0843009
C13         0.990097               0.990097             0.0838813
C12         0.907639               0.907639             0.0768954
C11         0.887801               0.887801             0.0752148
C7          0.856849               0.856849             0.0725925
C8          0.837645               0.837645             0.0709655
C14         0.726087               0.726087             0.0615143
C10         0.675104               0.675104             0.057195
C6          0.663739               0.663739             0.0562322
C3          0.617414               0.617414             0.0523075
C5          0.585865               0.585865             0.0496347
C16         0.579849               0.579849             0.049125
C4          0.576033               0.576033             0.0488017
C2          0.50017                0.50017              0.0423746
C1          0.404206               0.404206             0.0342445
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_37

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015822095747637377  0.0003633954329416156  0.0         -0.019260871223082177  0.7685704231262207  0.060032423216380866  0.7502908706665039
    3        26       Softmax                 0.0   0.0   0.0018906664262291228  0.0003719213418662548  0.0         0.0035528854779180653  0.3832993507385254  -0.5487049745229526   0.2482277750968933


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21912276562978125
RMSE: 0.46810550694237857
LogLoss: 0.7451475006877273
Mean Per-Class Error: 0.2179527282082945
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    6.0    0.0    0.0    0.0    2.0    2.0    7.0    2.0    2.0    0.0    3.0    2.0    7.0    0.0    0.09873417721518987  39 / 395
0.0    330.0  0.0    1.0    2.0    0.0    2.0    3.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    25.0   2.0    1.0    0.0    2.0    1.0    1.0    5.0    1.0    0.13838120104438642  53 / 383
0.0    0.0    290.0  0.0    15.0   2.0    12.0   0.0    0.0    0.0    22.0   0.0    0.0    0.0    4.0    0.0    4.0    0.0    7.0    4.0    6.0    0.0    2.0    0.0    0.0    0.0    0.21195652173913043  78 / 368
5.0    30.0   0.0    321.0  0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    6.0    6.0    2.0    5.0    0.0    14.0   3.0    1.0    0.0    0.0    0.0    2.0    0.0    3.0    0.20347394540942929  82 / 403
0.0    4.0    1.0    0.0    301.0  6.0    21.0   0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    9.0    5.0    10.0   7.0    0.0    0.0    0.0    2.0    1.0    13.0   0.21409921671018275  82 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    2.0    0.0    17.0   0.0    1.0    0.0    0.0    6.0    0.0    0.0    1.0    3.0    338.0  0.0    1.0    0.0    0.10106382978723404  38 / 376
0.0    6.0    0.0    12.0   11.0   0.0    1.0    3.0    5.0    0.0    9.0    3.0    0.0    0.0    2.0    0.0    17.0   0.0    8.0    7.0    1.0    0.0    0.0    295.0  9.0    5.0    0.2512690355329949   99 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    1.0    7.0    0.0    1.0    29.0   0.0    14.0   2.0    0.0    329.0  0.0    0.1628498727735369   64 / 393
1.0    2.0    0.0    0.0    17.0   1.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    1.0    35.0   5.0    0.0    0.0    0.0    2.0    0.0    292.0  0.20435967302452315  75 / 367
415.0  568.0  363.0  427.0  411.0  362.0  319.0  279.0  348.0  336.0  360.0  327.0  444.0  356.0  373.0  376.0  394.0  471.0  328.0  415.0  403.0  356.0  420.0  347.0  429.0  376.0  0.21693491952414276  2,170 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783065
2    0.875537
3    0.914126
4    0.937119
5    0.953114
6    0.963511
7    0.970309
8    0.976707
9    0.980906
10   0.985204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22479402175707897
RMSE: 0.4741244791793385
LogLoss: 0.7657542894451504
Mean Per-Class Error: 0.2245210959380287
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18    19     20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    0.0   1.0    2.0   3.0    0.0   0.10112359550561797  9 / 89
0.0   83.0   0.0   0.0    2.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   11.0   1.0   0.0    0.0    1.0   1.0    1.0   2.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    61.0  0.0    2.0   1.0   4.0   0.0   0.0   0.0   6.0   0.0   0.0    0.0   2.0   0.0    1.0   0.0    2.0   1.0    1.0    0.0   1.0    0.0   0.0    0.0   0.25609756097560976  21 / 82
3.0   7.0    0.0   92.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   2.0    2.0   1.0   1.0    0.0   1.0    1.0   0.0    0.0    0.0   0.0    0.0   0.0    0.0   0.17857142857142858  20 / 112
0.0   1.0    1.0   0.0    72.0  4.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    3.0   3.0    0.0    0.0   0.0    1.0   0.0    4.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   4.0    4.0   0.0   0.0   2.0   2.0   0.0   4.0   2.0   0.0    0.0   0.0   0.0    3.0   0.0    3.0   0.0    0.0    0.0   0.0    71.0  1.0    2.0   0.29                 29 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   1.0    2.0   0.0    0.0   6.0    0.0    6.0   1.0    0.0   88.0   0.0   0.17757009345794392  19 / 107
0.0   1.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0    2.0   0.0    7.0   2.0    0.0    0.0   0.0    1.0   0.0    66.0  0.2413793103448276   21 / 87
98.0  135.0  78.0  125.0  98.0  87.0  78.0  71.0  81.0  95.0  88.0  91.0  100.0  95.0  78.0  104.0  97.0  118.0  84.0  101.0  101.0  81.0  109.0  88.0  116.0  93.0  0.22369477911646587  557 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.776305
2    0.867871
3    0.911245
4    0.933735
5    0.948193
6    0.960241
7    0.967871
8    0.974699
9    0.97751
10   0.983936
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:02  1 min 40.102 sec  32385 obs/sec     1         1             10007      0.588635         1.11121             0.993842       0.302109                         0.590548           1.11848               0.993786         0.304819
    2019-07-24 13:11:05  1 min 42.891 sec  33245 obs/sec     10        10            100070     0.468106         0.745148            0.996106       0.216935                         0.474124           0.765754              0.995994         0.223695
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.084643
C13         0.974053               0.974053             0.0824467
C12         0.962978               0.962978             0.0815093
C9          0.950192               0.950192             0.080427
C7          0.847097               0.847097             0.0717008
C11         0.835251               0.835251             0.0706981
C8          0.821448               0.821448             0.0695298
C10         0.75743                0.75743              0.0641111
C14         0.753643               0.753643             0.0637906
C6          0.62633                0.62633              0.0530145
C16         0.60996                0.60996              0.0516288
C4          0.598012               0.598012             0.0506175
C3          0.588619               0.588619             0.0498224
C5          0.587538               0.587538             0.049731
C2          0.471285               0.471285             0.0398909
C1          0.430495               0.430495             0.0364384
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_40

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007611437193304482  0.0001839936594478786  0.0         -0.016603892901457584  0.2748706340789795  0.12684646519889353  0.202120840549469
    3        26       Softmax                      0.0   0.0   0.004923897990360833   0.010653413832187653   0.0         -0.368038345662521     0.9070184230804443  -0.5943824596793741  0.4564923048019409


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2715635748377724
RMSE: 0.5211176209242712
LogLoss: 0.8500838691201505
Mean Per-Class Error: 0.2292575447796157
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    5.0    0.0    6.0    0.0    1.0    0.0    1.0    0.0    2.0    0.0    0.0    5.0    2.0    0.0    3.0    4.0    0.09367088607594937  37 / 395
0.0    299.0  0.0    6.0    1.0    0.0    7.0    2.0    2.0    0.0    1.0    0.0    1.0    0.0    8.0    6.0    0.0    28.0   8.0    0.0    1.0    6.0    1.0    5.0    1.0    0.0    0.2193211488250653   84 / 383
0.0    0.0    292.0  0.0    25.0   1.0    8.0    1.0    0.0    0.0    21.0   0.0    1.0    0.0    2.0    1.0    5.0    0.0    0.0    8.0    0.0    0.0    3.0    0.0    0.0    0.0    0.20652173913043478  76 / 368
6.0    20.0   0.0    318.0  0.0    1.0    0.0    2.0    2.0    5.0    3.0    0.0    5.0    2.0    1.0    4.0    0.0    13.0   5.0    0.0    2.0    0.0    0.0    9.0    3.0    1.0    0.208955223880597    84 / 402
0.0    17.0   3.0    0.0    282.0  2.0    10.0   0.0    1.0    0.0    7.0    1.0    0.0    0.0    3.0    0.0    10.0   4.0    7.0    2.0    1.0    2.0    0.0    10.0   1.0    21.0   0.265625             102 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    4.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    3.0    0.0    4.0    9.0    0.0    1.0    2.0    4.0    1.0    5.0    2.0    1.0    0.0    0.0    0.0    5.0    0.0    7.0    3.0    2.0    2.0    0.0    332.0  9.0    2.0    0.15736040609137056  62 / 394
0.0    1.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    8.0    0.0    7.0    30.0   3.0    42.0   1.0    0.0    290.0  0.0    0.26208651399491095  103 / 393
0.0    1.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    37.0   0.0    0.0    0.0    0.0    2.0    0.0    308.0  0.16076294277929154  59 / 367
396.0  481.0  371.0  429.0  389.0  346.0  334.0  245.0  345.0  362.0  404.0  342.0  441.0  348.0  386.0  385.0  332.0  426.0  364.0  401.0  386.0  413.0  453.0  431.0  371.0  422.0  0.22823153054083775  2,283 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.771768
2    0.863541
3    0.903429
4    0.927622
5    0.942617
6    0.954514
7    0.964211
8    0.971409
9    0.977807
10   0.982705

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2750532490000756
RMSE: 0.5244551925570722
LogLoss: 0.8554856707251272
Mean Per-Class Error: 0.2344871549131748
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17     18    19    20    21    22     23     24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  ----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   1.0    0.0    2.0   1.0    0.0898876404494382   8 / 89
0.0   73.0   0.0   1.0    1.0   0.0   3.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   6.0   2.0    0.0   11.0   3.0   0.0   1.0   2.0   1.0    1.0    0.0   0.0    0.3113207547169811   33 / 106
0.0   0.0    61.0  0.0    4.0   0.0   2.0   1.0   0.0   0.0   5.0    0.0   0.0    0.0   0.0   1.0    2.0   0.0    0.0   5.0   0.0   0.0   1.0    0.0    0.0   0.0    0.25609756097560976  21 / 82
3.0   4.0    0.0   89.0   0.0   0.0   0.0   2.0   1.0   1.0   1.0    0.0   2.0    1.0   0.0   2.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0    2.0    0.0   0.0    0.20535714285714285  23 / 112
0.0   3.0    0.0   0.0    69.0  1.0   2.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   1.0   0.0    2.0   2.0    1.0   1.0   0.0   1.0   0.0    3.0    0.0   9.0    0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   89.0   0.0    0.0   0.0    0.03260869565217391  3 / 92
0.0   1.0    0.0   1.0    4.0   0.0   1.0   1.0   1.0   0.0   2.0    1.0   1.0    0.0   0.0   0.0    1.0   0.0    2.0   0.0   0.0   0.0   0.0    83.0   1.0   0.0    0.17                 17 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0    1.0   0.0    1.0   7.0   0.0   13.0  1.0    0.0    81.0  0.0    0.24299065420560748  26 / 107
0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0    0.0    0.0   73.0   0.16091954022988506  14 / 87
92.0  111.0  78.0  117.0  93.0  77.0  80.0  71.0  83.0  98.0  104.0  92.0  101.0  89.0  83.0  118.0  85.0  109.0  97.0  98.0  96.0  97.0  111.0  104.0  97.0  109.0  0.23413654618473895  583 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.765864
2    0.861847
3    0.906827
4    0.930522
5    0.942972
6    0.95502
7    0.964257
8    0.96988
9    0.97751
10   0.983534
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:09  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:09  1 min 46.532 sec  123543 obs/sec    1         1             10007      0.751492         1.71175             0.989964       0.447466                         0.752113           1.7151                0.989921         0.448594
    2019-07-24 13:11:10  1 min 47.173 sec  142347 obs/sec    10        10            100070     0.521118         0.850084            0.995174       0.228232                         0.524455           0.855486              0.995099         0.234137
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.101205
C13         0.85282                0.85282              0.0863099
C12         0.778057               0.778057             0.0787435
C8          0.735577               0.735577             0.0744443
C9          0.734047               0.734047             0.0742894
C11         0.684837               0.684837             0.0693092
C7          0.677298               0.677298             0.0685461
C6          0.624055               0.624055             0.0631577
C10         0.549776               0.549776             0.0556402
C3          0.513081               0.513081             0.0519266
C4          0.512169               0.512169             0.0518342
C14         0.506632               0.506632             0.0512738
C5          0.496162               0.496162             0.0502143
C16         0.437702               0.437702             0.0442978
C1          0.404983               0.404983             0.0409865
C2          0.37371                0.37371              0.0378214
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_43

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009541141167517253  0.0002651235554367304  0.0         -0.01408126551184985  0.24338412284851074  0.08012150655945356  0.16894692182540894
    3        26       Softmax                      0.0   0.0   0.0051135303187598204  0.00971672311425209    0.0         -0.25879326130050756  0.7289719581604004   -0.8549751395902674  0.41436338424682617


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.28612183073856406
RMSE: 0.5349035714393428
LogLoss: 0.8749668429828472
Mean Per-Class Error: 0.23309584075839734
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    8.0    1.0    0.0    8.0    0.0    3.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    4.0    1.0    8.0    0.0    0.10379746835443038  41 / 395
0.0    311.0  0.0    7.0    3.0    0.0    2.0    2.0    5.0    0.0    2.0    0.0    0.0    0.0    4.0    2.0    0.0    26.0   3.0    0.0    0.0    1.0    0.0    10.0   5.0    0.0    0.18798955613577023  72 / 383
0.0    0.0    301.0  0.0    19.0   0.0    9.0    2.0    0.0    0.0    22.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    5.0    2.0    0.0    0.0    5.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
4.0    18.0   0.0    318.0  0.0    0.0    1.0    4.0    1.0    3.0    0.0    0.0    3.0    6.0    8.0    4.0    0.0    9.0    4.0    0.0    0.0    0.0    0.0    19.0   0.0    0.0    0.208955223880597    84 / 402
0.0    8.0    3.0    0.0    303.0  1.0    16.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    15.0   2.0    1.0    0.0    0.0    3.0    0.0    21.0   0.2109375            81 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    12.0   0.0    0.0    0.0    0.0    7.0    0.0    0.0    2.0    0.0    345.0  0.0    1.0    0.0    0.08244680851063829  31 / 376
2.0    1.0    0.0    9.0    8.0    0.0    2.0    0.0    5.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    9.0    2.0    11.0   3.0    4.0    1.0    0.0    326.0  4.0    3.0    0.17258883248730963  68 / 394
0.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    9.0    33.0   3.0    84.0   2.0    0.0    242.0  1.0    0.3842239185750636   151 / 393
2.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    42.0   2.0    0.0    0.0    0.0    7.0    0.0    294.0  0.1989100817438692   73 / 367
411.0  487.0  366.0  416.0  397.0  345.0  364.0  229.0  358.0  330.0  442.0  326.0  421.0  352.0  418.0  366.0  312.0  433.0  384.0  387.0  380.0  460.0  462.0  454.0  309.0  394.0  0.2323303009097271   2,324 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.76767
2    0.864041
3    0.904329
4    0.929121
5    0.945216
6    0.955713
7    0.96531
8    0.973608
9    0.980106
10   0.984105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.28703800942525654
RMSE: 0.5357592830976021
LogLoss: 0.8727321764883789
Mean Per-Class Error: 0.2350323731244022
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16    17     18    19    20     21     22     23     24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  -----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0    2.0    1.0    3.0   0.0    0.10112359550561797  9 / 89
0.0   81.0   0.0   3.0    3.0   0.0   1.0   1.0   1.0   0.0   1.0    0.0   0.0   0.0   2.0   1.0    0.0   5.0    1.0   0.0   0.0    1.0    0.0    3.0    2.0   0.0    0.2358490566037736   25 / 106
0.0   0.0    61.0  0.0    4.0   0.0   4.0   1.0   0.0   0.0   5.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0    3.0   1.0   0.0    0.0    2.0    0.0    0.0   0.0    0.25609756097560976  21 / 82
3.0   4.0    0.0   89.0   0.0   0.0   1.0   2.0   1.0   1.0   0.0    0.0   1.0   3.0   2.0   0.0    0.0   1.0    2.0   0.0   0.0    0.0    0.0    2.0    0.0   0.0    0.20535714285714285  23 / 112
0.0   1.0    0.0   0.0    71.0  1.0   3.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0    2.0   1.0    4.0   0.0   0.0    0.0    0.0    1.0    0.0   11.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0    87.0   0.0    0.0   0.0    0.05434782608695652  5 / 92
2.0   0.0    0.0   2.0    3.0   0.0   1.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    1.0   2.0    3.0   1.0   1.0    0.0    0.0    80.0   0.0   2.0    0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    3.0   0.0    1.0   9.0   2.0    26.0   2.0    0.0    62.0  0.0    0.4205607476635514   45 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    8.0   1.0   0.0    0.0    0.0    3.0    0.0   70.0   0.19540229885057472  17 / 87
96.0  115.0  76.0  117.0  90.0  81.0  94.0  59.0  91.0  90.0  108.0  89.0  93.0  96.0  84.0  103.0  85.0  111.0  92.0  92.0  101.0  109.0  114.0  112.0  84.0  108.0  0.2357429718875502   587 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.764257
2    0.863855
3    0.905221
4    0.928514
5    0.94257
6    0.954217
7    0.966265
8    0.974297
9    0.981526
10   0.984337
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:17  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:17  1 min 54.284 sec  99079 obs/sec     1         1             10007      0.757768         1.65995             0.989797       0.386984                         0.757979           1.65182               0.989763         0.38996
    2019-07-24 13:11:18  1 min 55.180 sec  106006 obs/sec    10        10            100070     0.534904         0.874967            0.994916       0.23233                          0.535759           0.872732              0.994885         0.235743
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0963585
C13         0.932918               0.932918             0.0898945
C8          0.817596               0.817596             0.0787823
C12         0.782506               0.782506             0.0754011
C7          0.743836               0.743836             0.0716749
C9          0.739748               0.739748             0.071281
C11         0.684871               0.684871             0.0659931
C14         0.65893                0.65893              0.0634935
C10         0.618321               0.618321             0.0595805
C6          0.592904               0.592904             0.0571313
C5          0.528529               0.528529             0.0509283
C3          0.514225               0.514225             0.04955
C16         0.502618               0.502618             0.0484316
C4          0.48674                0.48674              0.0469015
C2          0.414673               0.414673             0.0399572
C1          0.3595                 0.3595               0.0346409
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_45

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 10,007 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0018906751983820413  0.0004983332473784685  0.0         0.0007982818581666606  0.12182605266571045  0.003419993521533724  0.0878375768661499
    3        26       Softmax                 0.0   0.0   0.0045830730131316295  0.0017553754150867462  0.0         0.005916606750474784   0.3361690044403076   -0.14736790301474162  0.10645592212677002


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.27495485501001743
RMSE: 0.5243613782593236
LogLoss: 0.9370360711842269
Mean Per-Class Error: 0.26056242632496185
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    7.0    5.0    0.0    6.0    0.0    2.0    0.0    0.0    2.0    6.0    0.0    1.0    0.0    2.0    2.0    7.0    0.0    0.10632911392405063  42 / 395
0.0    244.0  0.0    7.0    4.0    4.0    0.0    7.0    9.0    3.0    1.0    1.0    1.0    0.0    2.0    7.0    0.0    43.0   42.0   0.0    0.0    0.0    2.0    5.0    0.0    0.0    0.3612565445026178   138 / 382
0.0    0.0    294.0  0.0    10.0   1.0    11.0   1.0    0.0    0.0    21.0   4.0    0.0    0.0    3.0    0.0    2.0    0.0    8.0    6.0    1.0    0.0    6.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
4.0    13.0   0.0    311.0  0.0    2.0    0.0    6.0    0.0    12.0   0.0    0.0    7.0    3.0    7.0    4.0    0.0    16.0   10.0   2.0    1.0    0.0    0.0    5.0    0.0    0.0    0.228287841191067    92 / 403
0.0    11.0   0.0    0.0    287.0  10.0   7.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    3.0    11.0   7.0    21.0   5.0    0.0    0.0    0.0    5.0    2.0    13.0   0.2526041666666667   97 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    18.0   0.0    0.0    1.0    0.0    12.0   0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    1.0    0.0    10.0   7.0    1.0    0.0    0.0    2.0    3.0    2.0    1.0    0.0    0.0    4.0    0.0    5.0    6.0    19.0   7.0    5.0    0.0    0.0    312.0  9.0    0.0    0.20812182741116753  82 / 394
0.0    0.0    0.0    2.0    0.0    22.0   0.0    5.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    2.0    8.0    0.0    9.0    37.0   3.0    54.0   4.0    2.0    243.0  0.0    0.3816793893129771   150 / 393
0.0    0.0    0.0    0.0    23.0   4.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    77.0   4.0    0.0    0.0    0.0    1.0    0.0    249.0  0.3215258855585831   118 / 367
411.0  371.0  376.0  436.0  372.0  465.0  241.0  279.0  334.0  359.0  346.0  347.0  443.0  309.0  453.0  369.0  299.0  546.0  562.0  395.0  400.0  387.0  496.0  409.0  309.0  289.0  0.2594221733479956   2,595 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.740578
2    0.851045
3    0.893732
4    0.921524
5    0.939118
6    0.949415
7    0.959212
8    0.96651
9    0.972108
10   0.977007

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2763469394264233
RMSE: 0.5256871117180097
LogLoss: 0.9417669355152002
Mean Per-Class Error: 0.2654069010927685
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10    11    12     13    14    15     16    17     18     19    20     21    22     23    24    25    Error                Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  ----  ----  -------------------  -----------
80.0  0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   1.0    1.0   3.0   0.0   0.10112359550561797  9 / 89
0.0   68.0  0.0   2.0    2.0   0.0   0.0   4.0   2.0   0.0    0.0   0.0   0.0    0.0   2.0   2.0    0.0   11.0   10.0   0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.3584905660377358   38 / 106
0.0   0.0   60.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    6.0   0.0   0.0    0.0   2.0   0.0    1.0   0.0    2.0    2.0   0.0    0.0   2.0    0.0   0.0   0.0   0.2682926829268293   22 / 82
3.0   2.0   0.0   86.0   0.0   0.0   0.0   2.0   0.0   5.0    0.0   0.0   3.0    1.0   2.0   1.0    0.0   4.0    1.0    0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.23214285714285715  26 / 112
0.0   2.0   0.0   0.0    70.0  2.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0    3.0   1.0    6.0    2.0   0.0    0.0   0.0    1.0   0.0   6.0   0.27835051546391754  27 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---   ---   ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   85.0   0.0   0.0   0.0   0.07608695652173914  7 / 92
0.0   0.0   0.0   4.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0    0.0   1.0   0.0    1.0   5.0    6.0    0.0   1.0    0.0   0.0    74.0  3.0   0.0   0.26                 26 / 100
0.0   0.0   0.0   0.0    0.0   6.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    4.0   0.0    2.0    9.0   1.0    17.0  2.0    0.0   62.0  0.0   0.4205607476635514   45 / 107
0.0   0.0   0.0   0.0    6.0   1.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    18.0   1.0   0.0    0.0   0.0    1.0   0.0   58.0  0.3333333333333333   29 / 87
96.0  94.0  77.0  124.0  91.0  99.0  58.0  83.0  79.0  100.0  88.0  92.0  102.0  82.0  91.0  107.0  86.0  140.0  136.0  92.0  102.0  89.0  124.0  99.0  83.0  76.0  0.26666666666666666  664 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.733333
2    0.852209
3    0.893574
4    0.925703
5    0.941365
6    0.949799
7    0.960241
8    0.965462
9    0.969076
10   0.975502
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:19  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:20  1 min 57.229 sec  17742 obs/sec     1         1             10007      0.524361         0.937036            0.995114       0.259422                         0.525687           0.941767              0.995076         0.266667
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0779939
C13         0.98814                0.98814              0.0770689
C12         0.911583               0.911583             0.0710979
C9          0.9071                 0.9071               0.0707483
C8          0.885426               0.885426             0.0690578
C7          0.826732               0.826732             0.0644801
C11         0.819054               0.819054             0.0638812
C10         0.787345               0.787345             0.0614081
C14         0.783834               0.783834             0.0611343
C16         0.761308               0.761308             0.0593774
C5          0.726931               0.726931             0.0566962
C6          0.720524               0.720524             0.0561965
C4          0.717624               0.717624             0.0559703
C3          0.702244               0.702244             0.0547708
C2          0.643422               0.643422             0.050183
C1          0.640244               0.640244             0.0499352
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_42

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012810624033363638  0.00033931806683540344  0.0         0.011981843218567434  1.246251106262207   -0.11555444576054938  0.922480583190918
    3        26       Softmax                 0.0   0.0   0.001728343676824387   0.00016104435781016946  0.0         0.02778158705044776   0.4495478868484497  -0.549839956424142    0.3747144937515259


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2955209047263441
RMSE: 0.5436183447294104
LogLoss: 0.9606068822863829
Mean Per-Class Error: 0.27640325244796404
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    5.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    5.0    0.0    4.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    5.0    2.0    8.0    0.0    0.09873417721518987  39 / 395
0.0    286.0  0.0    5.0    3.0    1.0    3.0    13.0   5.0    1.0    2.0    0.0    2.0    0.0    1.0    7.0    4.0    27.0   14.0   0.0    0.0    1.0    2.0    1.0    3.0    2.0    0.25326370757180156  97 / 383
0.0    0.0    273.0  0.0    24.0   2.0    32.0   1.0    0.0    0.0    12.0   0.0    0.0    0.0    3.0    0.0    2.0    0.0    3.0    7.0    1.0    0.0    7.0    0.0    0.0    0.0    0.2561307901907357   94 / 367
6.0    22.0   0.0    289.0  0.0    0.0    0.0    7.0    0.0    14.0   0.0    1.0    6.0    6.0    11.0   12.0   0.0    14.0   5.0    1.0    1.0    0.0    0.0    8.0    0.0    0.0    0.28287841191067     114 / 403
0.0    4.0    2.0    0.0    288.0  6.0    19.0   1.0    2.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    15.0   5.0    8.0    9.0    1.0    1.0    0.0    12.0   0.0    7.0    0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    26.0   4.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    4.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
2.0    16.0   0.0    9.0    22.0   1.0    7.0    2.0    12.0   0.0    4.0    3.0    0.0    0.0    2.0    0.0    16.0   3.0    12.0   11.0   4.0    1.0    0.0    253.0  4.0    10.0   0.35786802030456855  141 / 394
0.0    0.0    0.0    1.0    0.0    9.0    1.0    5.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    1.0    6.0    0.0    8.0    26.0   4.0    37.0   0.0    0.0    291.0  0.0    0.2595419847328244   102 / 393
4.0    1.0    0.0    2.0    27.0   5.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    45.0   5.0    0.0    0.0    0.0    3.0    0.0    269.0  0.2670299727520436   98 / 367
445.0  521.0  357.0  399.0  442.0  361.0  345.0  282.0  338.0  333.0  323.0  341.0  469.0  371.0  397.0  387.0  370.0  434.0  320.0  379.0  392.0  401.0  472.0  342.0  422.0  360.0  0.2752174347695691   2,753 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.724783
2    0.836449
3    0.884335
4    0.912626
5    0.93222
6    0.945416
7    0.957013
8    0.963411
9    0.971309
10   0.976407

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2992888427745738
RMSE: 0.5470729775583636
LogLoss: 0.9673187726508254
Mean Per-Class Error: 0.2869569051775191
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10    11    12     13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   2.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0    73.0   0.0   0.0    2.0    0.0   1.0   4.0   2.0   0.0   2.0   0.0   1.0    0.0   1.0   2.0    3.0   10.0   1.0   0.0   0.0    1.0   0.0    1.0   1.0    1.0   0.3113207547169811   33 / 106
0.0    0.0    57.0  0.0    5.0    0.0   8.0   0.0   0.0   0.0   4.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    2.0   3.0   1.0    0.0   1.0    0.0   0.0    0.0   0.3048780487804878   25 / 82
4.0    3.0    0.0   80.0   0.0    0.0   0.0   3.0   0.0   1.0   0.0   1.0   3.0    1.0   5.0   4.0    0.0   4.0    2.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.2857142857142857   32 / 112
0.0    1.0    1.0   0.0    65.0   4.0   5.0   0.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    5.0   1.0    2.0   4.0   0.0    0.0   0.0    3.0   0.0    3.0   0.32989690721649484  32 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   7.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   83.0   0.0   0.0    0.0   0.09782608695652174  9 / 92
1.0    3.0    0.0   3.0    7.0    0.0   1.0   1.0   3.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    2.0   1.0    6.0   2.0   1.0    0.0   0.0    65.0  1.0    2.0   0.35                 35 / 100
0.0    0.0    0.0   0.0    0.0    2.0   1.0   3.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   0.0    0.0   5.0   2.0    11.0  0.0    0.0   80.0   0.0   0.2523364485981308   27 / 107
0.0    0.0    0.0   1.0    6.0    1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    11.0  3.0   0.0    0.0   0.0    1.0   0.0    63.0  0.27586206896551724  24 / 87
104.0  132.0  73.0  113.0  100.0  76.0  84.0  75.0  78.0  91.0  91.0  93.0  105.0  98.0  79.0  110.0  96.0  105.0  86.0  90.0  103.0  95.0  114.0  90.0  121.0  88.0  0.2859437751004016   712 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.714056
2    0.836546
3    0.886345
4    0.913655
5    0.933333
6    0.94739
7    0.959036
8    0.964659
9    0.971486
10   0.975502
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:11:15  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:11:15  1 min 52.581 sec  56857 obs/sec     1         1             10007      0.655709         1.33101             0.992359       0.371089                         0.65225            1.32078               0.992419         0.369076
    2019-07-24 13:11:17  1 min 54.136 sec  58934 obs/sec     10        10            100070     0.543618         0.960607            0.994748       0.275217                         0.547073           0.967319              0.994667         0.285944
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0869353
C15         0.996571               0.996571             0.0866372
C12         0.996158               0.996158             0.0866013
C13         0.963951               0.963951             0.0838014
C11         0.884403               0.884403             0.0768858
C7          0.84968                0.84968              0.0738672
C14         0.771679               0.771679             0.0670862
C8          0.748383               0.748383             0.0650609
C10         0.683626               0.683626             0.0594313
C6          0.638449               0.638449             0.0555038
C16         0.613102               0.613102             0.0533002
C3          0.574669               0.574669             0.049959
C4          0.484444               0.484444             0.0421153
C5          0.475286               0.475286             0.0413191
C1          0.41321                0.41321              0.0359225
C2          0.409195               0.409195             0.0355735
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_15

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012799460681094388  0.00032361503690481186  0.0         0.06620111801726125   1.2583494186401367   0.2686993243967618   1.0002245903015137
    3        26       Softmax                 0.0   0.0   0.0017376442064442716  0.00019423774210736156  0.0         -0.01798481292210524  0.45308685302734375  -0.5603380605114832  0.34349489212036133


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.30630478556851165
RMSE: 0.5534480875100316
LogLoss: 0.9898328163290342
Mean Per-Class Error: 0.2790108515168019
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    5.0    3.0    4.0    0.0    0.0    1.0    6.0    1.0    0.0    0.0    6.0    0.0    5.0    0.0    0.09620253164556962  38 / 395
0.0    251.0  0.0    8.0    2.0    3.0    0.0    13.0   3.0    2.0    1.0    0.0    2.0    0.0    0.0    4.0    14.0   43.0   30.0   0.0    0.0    1.0    0.0    1.0    5.0    0.0    0.34464751958224543  132 / 383
0.0    0.0    282.0  0.0    15.0   5.0    15.0   1.0    1.0    0.0    25.0   2.0    2.0    0.0    1.0    0.0    3.0    0.0    3.0    1.0    3.0    0.0    3.0    0.0    1.0    4.0    0.23160762942779292  85 / 367
7.0    11.0   0.0    324.0  0.0    2.0    0.0    3.0    0.0    10.0   0.0    0.0    11.0   2.0    1.0    7.0    2.0    8.0    2.0    2.0    0.0    0.0    0.0    10.0   1.0    0.0    0.19602977667493796  79 / 403
0.0    4.0    2.0    0.0    261.0  2.0    19.0   2.0    3.0    0.0    8.0    0.0    0.0    0.0    0.0    1.0    13.0   9.0    16.0   6.0    1.0    0.0    0.0    9.0    5.0    23.0   0.3203125            123 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    36.0   9.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    315.0  0.0    0.0    0.0    0.1622340425531915   61 / 376
3.0    8.0    0.0    14.0   4.0    0.0    0.0    1.0    6.0    3.0    13.0   3.0    0.0    2.0    3.0    0.0    21.0   3.0    12.0   6.0    4.0    0.0    0.0    276.0  10.0   1.0    0.29770992366412213  117 / 393
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    1.0    13.0   0.0    6.0    84.0   2.0    61.0   2.0    1.0    215.0  0.0    0.4529262086513995   178 / 393
0.0    1.0    0.0    0.0    23.0   1.0    0.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    1.0    6.0    1.0    47.0   5.0    0.0    0.0    0.0    8.0    1.0    266.0  0.27520435967302453  101 / 367
424.0  406.0  380.0  449.0  365.0  345.0  335.0  324.0  327.0  373.0  347.0  329.0  540.0  350.0  358.0  379.0  411.0  456.0  361.0  470.0  377.0  429.0  419.0  356.0  329.0  364.0  0.27781665500349895  2,779 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.722183
2    0.83415
3    0.884135
4    0.914126
5    0.93172
6    0.944717
7    0.956313
8    0.963811
9    0.971508
10   0.977507

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.30814598474561505
RMSE: 0.5551089845657473
LogLoss: 0.9958171506754403
Mean Per-Class Error: 0.2885679161365161
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1     2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19     20    21     22     23    24    25    Error                Rate
-----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  -----  -----  ----  ----  ----  -------------------  -----------
83.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0   0.0    2.0    0.0   2.0   0.0   0.06741573033707865  6 / 89
0.0    68.0  0.0   1.0    2.0   1.0   0.0   5.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    6.0    12.0   6.0   0.0    0.0   1.0    0.0    1.0   1.0   0.0   0.3584905660377358   38 / 106
0.0    0.0   59.0  0.0    2.0   0.0   5.0   0.0   1.0   0.0    7.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0    1.0   0.0    1.0   0.0    1.0    0.0   1.0   2.0   0.2804878048780488   23 / 82
4.0    2.0   0.0   88.0   0.0   0.0   0.0   3.0   0.0   2.0    0.0   0.0   4.0    1.0   0.0   4.0    0.0    1.0    1.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.21428571428571427  24 / 112
0.0    0.0   0.0   0.0    63.0  1.0   3.0   1.0   1.0   0.0    3.0   0.0   0.0    0.0   0.0   0.0    3.0    5.0    4.0   3.0    0.0   0.0    0.0    1.0   1.0   8.0   0.35051546391752575  34 / 97
---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---    ---    ---   ---   ---   ---                  ---
0.0    0.0   0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   7.0    2.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0    81.0   0.0   0.0   0.0   0.11956521739130435  11 / 92
2.0    1.0   0.0   2.0    2.0   0.0   0.0   1.0   3.0   0.0    5.0   2.0   0.0    0.0   0.0   0.0    3.0    2.0    3.0   2.0    2.0   0.0    0.0    66.0  3.0   1.0   0.34                 34 / 100
0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0    5.0    0.0    0.0   22.0   1.0   20.0   2.0    0.0   56.0  0.0   0.4766355140186916   51 / 107
0.0    0.0   0.0   0.0    6.0   1.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0    9.0   2.0    0.0   0.0    0.0    4.0   0.0   61.0  0.2988505747126437   26 / 87
101.0  99.0  77.0  118.0  85.0  74.0  78.0  85.0  77.0  103.0  91.0  94.0  122.0  92.0  74.0  109.0  104.0  121.0  93.0  113.0  99.0  104.0  111.0  84.0  90.0  92.0  0.2891566265060241   720 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.710843
2    0.829317
3    0.881526
4    0.916064
5    0.932932
6    0.943373
7    0.953414
8    0.963052
9    0.970281
10   0.977108
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:07  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:07  44.798 sec  52119 obs/sec     1         1             10007      0.649962         1.32105             0.992492       0.362891                         0.648417           1.31248               0.992508         0.360643
    2019-07-24 13:10:09  46.293 sec  60465 obs/sec     10        10            100070     0.553448         0.989833            0.994556       0.277817                         0.555109           0.995817              0.994509         0.289157
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0877025
C9          0.962734               0.962734             0.0844342
C15         0.938184               0.938184             0.0822811
C13         0.918319               0.918319             0.0805389
C11         0.846301               0.846301             0.0742228
C7          0.795147               0.795147             0.0697364
C14         0.790454               0.790454             0.0693248
C8          0.759017               0.759017             0.0665677
C10         0.744359               0.744359             0.0652821
C16         0.604912               0.604912             0.0530523
C6          0.593923               0.593923             0.0520885
C3          0.58139                0.58139              0.0509894
C4          0.517832               0.517832             0.0454152
C5          0.48644                0.48644              0.042662
C1          0.441311               0.441311             0.0387041
C2          0.421858               0.421858             0.036998
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_35

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012831270831838992  0.00033326877746731043  0.0         0.02961722964676028   1.2694177627563477   -0.20439206292990966  1.0257196426391602
    3        26       Softmax                 0.0   0.0   0.0017337649100786971  0.00014746823580935597  0.0         0.016616132999143492  0.45586633682250977  -0.535471915890715    0.2980661392211914


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3152177490831162
RMSE: 0.5614425608048575
LogLoss: 1.0054669770179472
Mean Per-Class Error: 0.2865990728090951
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    9.0    0.0    0.0    0.0    2.0    3.0    10.0   0.0    1.0    1.0    6.0    0.0    5.0    0.0    0.10632911392405063  42 / 395
0.0    262.0  0.0    10.0   5.0    2.0    1.0    15.0   1.0    1.0    1.0    0.0    4.0    0.0    1.0    3.0    5.0    34.0   23.0   0.0    0.0    0.0    4.0    8.0    2.0    0.0    0.31413612565445026  120 / 382
0.0    0.0    260.0  0.0    37.0   2.0    26.0   1.0    1.0    0.0    16.0   0.0    1.0    0.0    2.0    0.0    1.0    0.0    6.0    5.0    4.0    0.0    5.0    0.0    0.0    1.0    0.29347826086956524  108 / 368
5.0    12.0   0.0    294.0  0.0    0.0    0.0    10.0   0.0    15.0   0.0    0.0    6.0    2.0    13.0   10.0   0.0    14.0   1.0    0.0    0.0    0.0    0.0    21.0   0.0    0.0    0.2704714640198511   109 / 403
0.0    3.0    8.0    0.0    235.0  3.0    28.0   2.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    15.0   6.0    16.0   18.0   0.0    0.0    0.0    23.0   0.0    18.0   0.3880208333333333   149 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    27.0   6.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    7.0    325.0  0.0    0.0    0.0    0.1356382978723404   51 / 376
1.0    2.0    2.0    5.0    14.0   0.0    9.0    1.0    12.0   1.0    7.0    0.0    0.0    0.0    3.0    0.0    8.0    6.0    20.0   9.0    1.0    1.0    0.0    282.0  7.0    3.0    0.28426395939086296  112 / 394
0.0    0.0    0.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    11.0   0.0    5.0    68.0   0.0    37.0   8.0    1.0    252.0  2.0    0.35877862595419846  141 / 393
0.0    4.0    0.0    2.0    11.0   3.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    47.0   5.0    0.0    0.0    0.0    13.0   0.0    275.0  0.2506811989100817   92 / 367
407.0  427.0  373.0  439.0  369.0  310.0  345.0  280.0  326.0  359.0  338.0  304.0  514.0  327.0  404.0  402.0  359.0  484.0  387.0  455.0  380.0  382.0  498.0  430.0  350.0  354.0  0.28551434569629114  2,856 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.714486
2    0.835649
3    0.885534
4    0.913426
5    0.93202
6    0.944117
7    0.955013
8    0.963511
9    0.970209
10   0.976107

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3208526462081368
RMSE: 0.5664385634895781
LogLoss: 1.0310668133149576
Mean Per-Class Error: 0.2917434418193522
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18    19     20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   0.0   3.0    0.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   66.0   0.0   5.0    2.0   0.0   1.0   6.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    3.0   12.0   5.0   0.0    0.0   0.0   3.0    2.0   0.0    0.0   0.37735849056603776  40 / 106
0.0   0.0    54.0  0.0    7.0   0.0   8.0   0.0   1.0   0.0   4.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    2.0   2.0    1.0   0.0   2.0    0.0   0.0    0.0   0.34146341463414637  28 / 82
3.0   3.0    0.0   87.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   2.0    0.0   5.0   3.0    0.0   2.0    1.0   0.0    0.0   0.0   0.0    3.0   0.0    0.0   0.22321428571428573  25 / 112
0.0   2.0    3.0   0.0    52.0  1.0   9.0   0.0   0.0   0.0   5.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    3.0   6.0    0.0   0.0   0.0    6.0   0.0    6.0   0.4639175257731959   45 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   6.0    3.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   1.0   80.0   0.0   0.0    0.0   0.13043478260869565  12 / 92
0.0   1.0    1.0   3.0    3.0   0.0   2.0   1.0   5.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    2.0   3.0    6.0   5.0    0.0   0.0   0.0    62.0  3.0    0.0   0.38                 38 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   1.0    4.0   0.0    1.0   12.0   0.0   8.0   3.0    0.0   75.0   0.0   0.29906542056074764  32 / 107
0.0   0.0    0.0   1.0    3.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    10.0  2.0    0.0   0.0   0.0    4.0   0.0    66.0  0.2413793103448276   21 / 87
96.0  100.0  78.0  129.0  85.0  69.0  88.0  79.0  78.0  94.0  84.0  82.0  115.0  83.0  82.0  120.0  99.0  127.0  99.0  111.0  95.0  83.0  123.0  99.0  104.0  88.0  0.29036144578313255  723 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.709639
2    0.820883
3    0.877108
4    0.908434
5    0.927711
6    0.941767
7    0.953012
8    0.961446
9    0.967068
10   0.974699
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:59  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:59  1 min 36.565 sec  59565 obs/sec     1         1             10007      0.649903         1.31007             0.992494       0.36649                          0.644895           1.29323               0.992589         0.36506
    2019-07-24 13:11:01  1 min 38.219 sec  56124 obs/sec     10        10            100070     0.561443         1.00547             0.994398       0.285514                         0.566439           1.03107               0.994283         0.290361
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0868902
C13         0.999717               0.999717             0.0868657
C12         0.917829               0.917829             0.0797504
C9          0.88094                0.88094              0.0765451
C8          0.866278               0.866278             0.0752711
C11         0.823193               0.823193             0.0715275
C7          0.814972               0.814972             0.0708131
C14         0.797851               0.797851             0.0693255
C10         0.687798               0.687798             0.0597629
C16         0.645456               0.645456             0.0560838
C6          0.595398               0.595398             0.0517343
C3          0.570259               0.570259             0.0495499
C4          0.50486                0.50486              0.0438674
C5          0.494522               0.494522             0.0429692
C1          0.464227               0.464227             0.0403368
C2          0.445471               0.445471             0.0387071
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_14

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008048256894994665  0.00022883544443175197  0.0         -0.028542254120054622  0.2888338565826416  0.026593580519296566  0.19982749223709106
    3        26       Softmax                      0.0   0.0   0.004310717789429383   0.007315227761864662    0.0         -0.3505974147857999    0.8855643272399902  -0.8016230190979036   0.5895123481750488


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3677580502098625
RMSE: 0.6064305815259176
LogLoss: 1.0830602715764375
Mean Per-Class Error: 0.26672693757428356
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  2.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    2.0    3.0    0.0    8.0    0.0    4.0    0.0    4.0    0.0    0.0    0.0    3.0    4.0    4.0    0.0    2.0    2.0    0.11139240506329114  44 / 395
0.0    322.0  0.0    15.0   0.0    0.0    3.0    2.0    3.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    2.0    18.0   8.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.15926892950391644  61 / 383
0.0    0.0    280.0  0.0    15.0   7.0    17.0   0.0    0.0    0.0    21.0   1.0    2.0    0.0    4.0    0.0    7.0    0.0    5.0    1.0    6.0    0.0    2.0    0.0    0.0    0.0    0.2391304347826087   88 / 368
6.0    29.0   0.0    320.0  0.0    0.0    1.0    6.0    2.0    1.0    0.0    1.0    4.0    6.0    3.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    18.0   0.0    1.0    0.20595533498759305  83 / 403
0.0    8.0    3.0    0.0    277.0  3.0    10.0   0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    13.0   5.0    11.0   5.0    0.0    0.0    0.0    14.0   0.0    24.0   0.2786458333333333   107 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    40.0   9.0    0.0    0.0    2.0    4.0    0.0    0.0    0.0    1.0    316.0  0.0    0.0    0.0    0.1595744680851064   60 / 376
0.0    10.0   0.0    9.0    13.0   0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    2.0    0.0    48.0   1.0    18.0   6.0    4.0    0.0    0.0    266.0  2.0    8.0    0.3248730964467005   128 / 394
0.0    1.0    0.0    1.0    0.0    4.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    21.0   0.0    8.0    35.0   0.0    62.0   0.0    0.0    257.0  0.0    0.3460559796437659   136 / 393
1.0    7.0    0.0    0.0    14.0   2.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    11.0   0.0    39.0   2.0    0.0    0.0    0.0    5.0    0.0    279.0  0.23978201634877383  88 / 367
417.0  607.0  335.0  467.0  356.0  310.0  318.0  244.0  334.0  307.0  404.0  309.0  500.0  376.0  412.0  406.0  470.0  336.0  350.0  364.0  397.0  430.0  414.0  398.0  347.0  395.0  0.26552034389683093  2,656 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.73448
2    0.841747
3    0.883735
4    0.913226
5    0.93252
6    0.947916
7    0.958213
8    0.96631
9    0.972008
10   0.978106

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.37010676127860814
RMSE: 0.6083640039307127
LogLoss: 1.0936199064843242
Mean Per-Class Error: 0.27152684982241254
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13     14    15     16     17    18    19    20     21     22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  -----  ----  ----  ----  -----  -----  -----  ----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0    1.0   0.0    1.0    0.0   0.0   0.0   1.0    2.0    1.0    0.0   1.0   0.0   0.10112359550561797  9 / 89
0.0   84.0   0.0   4.0    0.0   0.0   0.0   1.0   1.0   0.0   1.0    0.0   0.0    0.0    3.0   0.0    2.0    7.0   1.0   0.0   0.0    1.0    0.0    1.0   0.0   0.0   0.20754716981132076  22 / 106
0.0   0.0    58.0  0.0    3.0   1.0   3.0   0.0   0.0   0.0   5.0    0.0   0.0    0.0    2.0   0.0    4.0    0.0   3.0   1.0   1.0    0.0    1.0    0.0   0.0   0.0   0.2926829268292683   24 / 82
3.0   7.0    0.0   92.0   0.0   0.0   0.0   2.0   1.0   0.0   0.0    1.0   1.0    4.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.17857142857142858  20 / 112
0.0   1.0    0.0   0.0    67.0  2.0   4.0   0.0   0.0   0.0   4.0    0.0   0.0    0.0    0.0   0.0    3.0    1.0   3.0   2.0   0.0    0.0    0.0    3.0   0.0   7.0   0.30927835051546393  30 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---    ---   ---   ---   ---    ---    ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   7.0    2.0    0.0   0.0    1.0    1.0   0.0   0.0   0.0    1.0    80.0   0.0   0.0   0.0   0.13043478260869565  12 / 92
0.0   3.0    0.0   2.0    7.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0    0.0   0.0    9.0    0.0   5.0   0.0   2.0    0.0    0.0    67.0  1.0   2.0   0.33                 33 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    10.0   0.0   0.0   8.0   0.0    16.0   0.0    0.0   70.0  0.0   0.34579439252336447  37 / 107
0.0   2.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   2.0    3.0    0.0   8.0   1.0   0.0    0.0    0.0    2.0   0.0   65.0  0.25287356321839083  22 / 87
98.0  143.0  70.0  133.0  89.0  63.0  75.0  65.0  81.0  83.0  110.0  87.0  106.0  100.0  81.0  123.0  132.0  80.0  93.0  87.0  103.0  102.0  105.0  97.0  93.0  91.0  0.26987951807228916  672 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.73012
2    0.840161
3    0.883132
4    0.912048
5    0.930924
6    0.94498
7    0.955422
8    0.963052
9    0.969076
10   0.976305
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:06  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:06  43.949 sec  161403 obs/sec    1         1             10007      0.84123          2.09213             0.987427       0.504249                         0.840996           2.08628               0.987397         0.5
    2019-07-24 13:10:07  44.550 sec  157590 obs/sec    10        10            100070     0.606431         1.08306             0.993466       0.26552                          0.608364           1.09362               0.993405         0.26988
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.101448
C13         0.99999                0.99999              0.101447
C12         0.861378               0.861378             0.0873851
C9          0.739612               0.739612             0.0750321
C11         0.68538                0.68538              0.0695304
C7          0.652208               0.652208             0.0661652
C8          0.640885               0.640885             0.0650165
C14         0.614827               0.614827             0.0623729
C10         0.586809               0.586809             0.0595306
C6          0.578861               0.578861             0.0587243
C4          0.482258               0.482258             0.0489241
C16         0.473053               0.473053             0.0479902
C3          0.436926               0.436926             0.0443252
C5          0.416465               0.416465             0.0422496
C1          0.401085               0.401085             0.0406892
C2          0.28753                0.28753              0.0291694
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_6

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011459749601385738  0.00030710618011653423  0.0         -0.02041593633566663   1.1058306694030762  -0.109917444950055    1.0812597274780273
    3        26       Softmax                 0.0   0.0   0.0017589545020130642  0.00017023744294419885  0.0         -0.018310094978635158  0.5813777446746826  -0.47816182284548225  0.24275141954421997


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3466353761397773
RMSE: 0.5887574849968171
LogLoss: 1.1075444667566208
Mean Per-Class Error: 0.31885832197414715
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  2.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    12.0   1.0    1.0    0.0    2.0    0.0    3.0    0.0    1.0    0.0    6.0    1.0    5.0    0.0    0.10379746835443038  41 / 395
2.0    266.0  1.0    7.0    3.0    1.0    3.0    2.0    9.0    0.0    10.0   0.0    4.0    0.0    16.0   1.0    7.0    31.0   12.0   0.0    0.0    1.0    0.0    1.0    6.0    0.0    0.30548302872062666  117 / 383
0.0    0.0    264.0  0.0    17.0   2.0    26.0   0.0    0.0    0.0    18.0   1.0    2.0    0.0    4.0    0.0    7.0    0.0    12.0   3.0    6.0    0.0    4.0    1.0    0.0    0.0    0.28065395095367845  103 / 367
3.0    10.0   0.0    295.0  1.0    2.0    0.0    21.0   1.0    4.0    2.0    1.0    8.0    1.0    15.0   2.0    0.0    22.0   4.0    1.0    1.0    0.0    0.0    7.0    1.0    1.0    0.2679900744416873   108 / 403
0.0    16.0   24.0   0.0    180.0  4.0    31.0   0.0    9.0    0.0    13.0   3.0    0.0    0.0    1.0    2.0    16.0   8.0    10.0   5.0    2.0    0.0    0.0    31.0   0.0    29.0   0.53125              204 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    24.0   7.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    1.0    331.0  0.0    0.0    0.0    0.1196808510638298   45 / 376
0.0    11.0   0.0    1.0    31.0   0.0    1.0    4.0    12.0   7.0    11.0   0.0    0.0    0.0    4.0    2.0    21.0   4.0    21.0   8.0    1.0    0.0    0.0    201.0  14.0   40.0   0.48984771573604063  193 / 394
1.0    0.0    0.0    0.0    0.0    18.0   0.0    1.0    0.0    0.0    0.0    0.0    4.0    4.0    0.0    7.0    5.0    0.0    10.0   59.0   1.0    35.0   3.0    0.0    245.0  0.0    0.37659033078880405  148 / 393
0.0    8.0    0.0    3.0    8.0    11.0   4.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    2.0    35.0   0.0    0.0    0.0    0.0    13.0   2.0    274.0  0.25340599455040874  93 / 367
439.0  522.0  380.0  406.0  298.0  380.0  370.0  261.0  346.0  317.0  328.0  320.0  514.0  346.0  467.0  405.0  393.0  465.0  295.0  430.0  379.0  326.0  458.0  334.0  397.0  427.0  0.317704688593422    3,178 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.682295
2    0.807858
3    0.863341
4    0.893632
5    0.914026
6    0.929021
7    0.941018
8    0.951415
9    0.960312
10   0.96701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.34709941627755864
RMSE: 0.5891514374738965
LogLoss: 1.1016526495015884
Mean Per-Class Error: 0.32273054015331376
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13    14     15     16     17     18    19    20    21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   2.0    1.0   0.0    0.0    0.0    0.0    1.0   0.0   0.0   0.0   2.0    1.0   2.0    0.0    0.11235955056179775  10 / 89
0.0    71.0   1.0   1.0    1.0   0.0   1.0   1.0   3.0   0.0   2.0   0.0   1.0    0.0   7.0    1.0    2.0    9.0    0.0   0.0   0.0   1.0   0.0    1.0   3.0    0.0    0.330188679245283    35 / 106
0.0    0.0    55.0  0.0    3.0   0.0   9.0   0.0   0.0   0.0   4.0   0.0   0.0    0.0   1.0    0.0    2.0    0.0    3.0   0.0   2.0   0.0   2.0    1.0   0.0    0.0    0.32926829268292684  27 / 82
2.0    1.0    0.0   86.0   0.0   1.0   0.0   3.0   0.0   1.0   0.0   1.0   3.0    0.0   5.0    0.0    0.0    6.0    2.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    0.23214285714285715  26 / 112
0.0    6.0    6.0   0.0    44.0  1.0   8.0   0.0   1.0   0.0   4.0   0.0   0.0    0.0   0.0    0.0    3.0    2.0    2.0   3.0   0.0   0.0   0.0    8.0   0.0    9.0    0.5463917525773195   53 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0    1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   6.0    1.0   0.0    0.0    0.0    1.0    0.0   0.0   0.0   0.0   83.0   0.0   0.0    0.0    0.09782608695652174  9 / 92
0.0    1.0    0.0   0.0    9.0   0.0   0.0   1.0   5.0   1.0   6.0   0.0   0.0    0.0   1.0    0.0    4.0    1.0    6.0   1.0   0.0   0.0   0.0    46.0  6.0    12.0   0.54                 54 / 100
1.0    0.0    0.0   0.0    0.0   4.0   0.0   1.0   0.0   0.0   0.0   0.0   2.0    1.0   0.0    1.0    2.0    0.0    1.0   14.0  0.0   11.0  1.0    0.0   68.0   0.0    0.3644859813084112   39 / 107
0.0    1.0    0.0   2.0    3.0   3.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0    0.0    8.0   0.0   0.0   0.0   0.0    6.0   1.0    61.0   0.2988505747126437   26 / 87
102.0  124.0  83.0  113.0  67.0  93.0  92.0  75.0  78.0  89.0  83.0  86.0  125.0  89.0  100.0  116.0  106.0  110.0  80.0  97.0  97.0  78.0  110.0  81.0  113.0  103.0  0.3220883534136546   802 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.677912
2    0.804016
3    0.867068
4    0.89759
5    0.916867
6    0.931727
7    0.943373
8    0.95261
9    0.961044
10   0.967871
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:09:43  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:09:43  20.937 sec  80701 obs/sec     1         1             10007      0.695216         1.53004             0.991411       0.430571                         0.693487           1.51003               0.991431         0.431727
    2019-07-24 13:09:44  22.038 sec  83461 obs/sec     10        10            100070     0.588757         1.10754             0.99384        0.317705                         0.589151           1.10165               0.993815         0.322088
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0888581
C13         0.961752               0.961752             0.0854595
C12         0.881218               0.881218             0.0783033
C9          0.855412               0.855412             0.0760102
C11         0.818085               0.818085             0.0726934
C14         0.785361               0.785361             0.0697857
C7          0.762904               0.762904             0.0677902
C8          0.737601               0.737601             0.0655418
C16         0.635319               0.635319             0.0564532
C6          0.624099               0.624099             0.0554562
C3          0.592798               0.592798             0.0526749
C5          0.580966               0.580966             0.0516235
C10         0.54003                0.54003              0.047986
C4          0.524681               0.524681             0.0466222
C1          0.518957               0.518957             0.0461135
C2          0.43472                0.43472              0.0386283
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_23

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008309436703939355  0.0002416160423308611  0.0         -0.01459232314118708  0.2905149459838867  0.01608426950327444  0.1905335783958435
    3        26       Softmax                      0.0   0.0   0.004247514792670979   0.006683342158794403   0.0         -0.31453466271803054  0.8698370456695557  -0.8423981436814832  0.5360300540924072


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.37943351052097835
RMSE: 0.6159817452822595
LogLoss: 1.1141632050945254
Mean Per-Class Error: 0.272330894867864
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    5.0    2.0    0.0    10.0   0.0    1.0    0.0    1.0    0.0    12.0   0.0    1.0    2.0    7.0    0.0    2.0    0.0    0.11645569620253164  46 / 395
0.0    289.0  0.0    9.0    0.0    0.0    1.0    0.0    4.0    1.0    4.0    0.0    6.0    0.0    3.0    1.0    1.0    32.0   15.0   0.0    0.0    0.0    1.0    16.0   0.0    0.0    0.2454308093994778   94 / 383
0.0    0.0    300.0  0.0    10.0   1.0    9.0    2.0    0.0    0.0    32.0   0.0    0.0    0.0    2.0    2.0    1.0    0.0    2.0    3.0    1.0    0.0    3.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
2.0    15.0   0.0    315.0  0.0    0.0    1.0    0.0    1.0    8.0    0.0    0.0    3.0    5.0    3.0    1.0    2.0    10.0   5.0    1.0    0.0    0.0    0.0    31.0   0.0    0.0    0.21836228287841192  88 / 403
0.0    9.0    8.0    0.0    257.0  0.0    19.0   0.0    2.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    11.0   8.0    0.0    3.0    4.0    0.0    1.0    20.0   4.0    31.0   0.3307291666666667   127 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    14.0   6.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    1.0    347.0  0.0    0.0    0.0    0.07466666666666667  28 / 375
1.0    4.0    2.0    4.0    4.0    0.0    1.0    3.0    7.0    2.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    8.0    9.0    5.0    7.0    0.0    0.0    317.0  15.0   2.0    0.19543147208121828  77 / 394
0.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    1.0    13.0   0.0    11.0   56.0   1.0    60.0   3.0    2.0    238.0  1.0    0.3944020356234097   155 / 393
6.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    38.0   3.0    0.0    0.0    0.0    9.0    0.0    292.0  0.20435967302452315  75 / 367
388.0  496.0  381.0  453.0  336.0  297.0  261.0  202.0  357.0  341.0  423.0  312.0  483.0  385.0  343.0  389.0  373.0  460.0  318.0  409.0  386.0  382.0  502.0  553.0  337.0  436.0  0.2712186344096771   2,713 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.728781
2    0.838149
3    0.880436
4    0.910027
5    0.926522
6    0.942317
7    0.954114
8    0.962911
9    0.969909
10   0.975007

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.38169645340458297
RMSE: 0.6178158733834725
LogLoss: 1.1195051539713736
Mean Per-Class Error: 0.28159365424328187
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16     17     18    19    20    21    22     23     24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   1.0   3.0    0.0    1.0   0.0    0.10112359550561797  9 / 89
0.0   72.0   0.0   4.0    0.0   0.0   0.0   0.0   1.0   0.0    1.0    0.0   1.0    0.0   3.0   0.0    0.0    12.0   5.0   0.0   0.0   0.0   1.0    6.0    0.0   0.0    0.32075471698113206  34 / 106
0.0   0.0    61.0  0.0    2.0   0.0   4.0   2.0   0.0   0.0    8.0    0.0   0.0    0.0   0.0   1.0    0.0    0.0    1.0   2.0   0.0   0.0   1.0    0.0    0.0   0.0    0.25609756097560976  21 / 82
1.0   2.0    0.0   93.0   0.0   0.0   1.0   0.0   1.0   1.0    0.0    0.0   1.0    2.0   1.0   0.0    1.0    2.0    2.0   0.0   0.0   0.0   0.0    4.0    0.0   0.0    0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    59.0  0.0   4.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   0.0   0.0    3.0    3.0    0.0   2.0   0.0   0.0   1.0    5.0    0.0   14.0   0.3917525773195876   38 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0    1.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0   1.0   85.0   0.0    0.0   0.0    0.07608695652173914  7 / 92
0.0   3.0    0.0   0.0    2.0   0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0    3.0    2.0   0.0   1.0   0.0   0.0    77.0   8.0   2.0    0.23                 23 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0    0.0   1.0   0.0    6.0    0.0    2.0   11.0  0.0   18.0  1.0    1.0    66.0  0.0    0.38317757009345793  41 / 107
2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0    0.0    10.0  1.0   0.0   0.0   0.0    4.0    0.0   65.0   0.25287356321839083  22 / 87
88.0  117.0  79.0  133.0  78.0  61.0  59.0  51.0  79.0  103.0  111.0  90.0  108.0  96.0  71.0  111.0  104.0  118.0  84.0  98.0  93.0  91.0  124.0  132.0  97.0  114.0  0.27951807228915665  696 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.720482
2    0.833735
3    0.884337
4    0.913655
5    0.929317
6    0.94498
7    0.956627
8    0.962249
9    0.969478
10   0.974699
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:28  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:28  1 min  5.629 sec  153953 obs/sec    1         1             10007      0.840429         2.11347             0.987449       0.543337                         0.839548           2.109                 0.987441         0.535743
    2019-07-24 13:10:29  1 min  6.210 sec  160884 obs/sec    10        10            100070     0.615982         1.11416             0.993258       0.271219                         0.617816           1.11951               0.993199         0.279518
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.10149
C15         0.852345               0.852345             0.0865048
C8          0.7866                 0.7866               0.0798324
C9          0.745934               0.745934             0.0757052
C12         0.728872               0.728872             0.0739735
C7          0.708113               0.708113             0.0718667
C11         0.651028               0.651028             0.0660731
C14         0.63664                0.63664              0.0646129
C6          0.580467               0.580467             0.0589119
C10         0.551354               0.551354             0.0559571
C4          0.540901               0.540901             0.0548963
C5          0.483626               0.483626             0.0490834
C16         0.474117               0.474117             0.0481184
C3          0.451206               0.451206             0.0457931
C1          0.355079               0.355079             0.0360372
C2          0.306863               0.306863             0.0311437
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_22

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011586517944124353  0.0003246632404625416   0.0         0.10693790062123298    2.1338024139404297  -0.20349130873344548  1.2341384887695312
    3        26       Softmax                 0.0   0.0   0.0016756238879819508  0.00010228078463114798  0.0         0.0056877482896267725  0.5053212642669678  -0.5930947568771017   0.381891131401062


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.48607299751844707
RMSE: 0.697189355568806
LogLoss: 1.4465688277833133
Mean Per-Class Error: 0.3920621121473952
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
330.0  1.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    2.0    9.0    8.0    0.0    0.0    0.0    3.0    15.0   5.0    1.0    1.0    0.0    5.0    2.0    6.0    0.0    0.16455696202531644  65 / 395
1.0    239.0  0.0    9.0    0.0    0.0    2.0    9.0    11.0   21.0   1.0    0.0    11.0   0.0    1.0    3.0    6.0    38.0   24.0   0.0    0.0    1.0    0.0    2.0    2.0    2.0    0.37597911227154046  144 / 383
0.0    1.0    237.0  0.0    12.0   5.0    35.0   1.0    4.0    0.0    31.0   0.0    8.0    0.0    1.0    0.0    8.0    0.0    9.0    6.0    7.0    0.0    3.0    0.0    0.0    0.0    0.35597826086956524  131 / 368
4.0    19.0   0.0    219.0  1.0    4.0    0.0    12.0   7.0    34.0   4.0    0.0    12.0   1.0    23.0   11.0   0.0    30.0   2.0    2.0    2.0    0.0    0.0    6.0    3.0    7.0    0.456575682382134    184 / 403
0.0    14.0   10.0   0.0    217.0  5.0    35.0   0.0    3.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    21.0   5.0    15.0   14.0   0.0    0.0    0.0    10.0   1.0    29.0   0.4348958333333333   167 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    1.0    0.0    35.0   13.0   1.0    0.0    1.0    0.0    0.0    0.0    1.0    32.0   289.0  0.0    0.0    0.0    0.23138297872340424  87 / 376
32.0   17.0   0.0    1.0    15.0   1.0    2.0    6.0    13.0   15.0   12.0   0.0    0.0    0.0    3.0    2.0    27.0   3.0    26.0   28.0   3.0    0.0    0.0    118.0  8.0    62.0   0.700507614213198    276 / 394
0.0    0.0    0.0    0.0    1.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    7.0    6.0    0.0    3.0    76.0   1.0    76.0   4.0    0.0    201.0  2.0    0.48854961832061067  192 / 393
2.0    8.0    0.0    2.0    20.0   2.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    2.0    41.0   5.0    0.0    0.0    0.0    9.0    1.0    264.0  0.28065395095367845  103 / 367
423.0  526.0  355.0  337.0  308.0  317.0  350.0  211.0  363.0  397.0  348.0  323.0  588.0  357.0  374.0  430.0  404.0  444.0  335.0  493.0  400.0  442.0  466.0  215.0  334.0  463.0  0.3910826751974408   3,912 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.608917
2    0.755573
3    0.824553
4    0.86754
5    0.893932
6    0.913926
7    0.930421
8    0.941817
9    0.951115
10   0.959812

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4832275589779742
RMSE: 0.6951457106089156
LogLoss: 1.445566213813593
Mean Per-Class Error: 0.39507793545922476
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19     20     21     22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -----  -----  ----  ----  -----  -------------------  -----------
74.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0   1.0    0.0   0.0   0.0    1.0    5.0    1.0   0.0    0.0    0.0    1.0    1.0   3.0   0.0    0.16853932584269662  15 / 89
0.0   63.0   0.0   2.0    0.0   0.0   2.0   3.0   6.0   5.0    1.0   0.0   4.0    0.0   0.0   1.0    5.0    11.0   2.0   0.0    0.0    1.0    0.0    0.0   0.0   0.0    0.4056603773584906   43 / 106
0.0   0.0    56.0  0.0    0.0   1.0   7.0   0.0   1.0   0.0    3.0   0.0   0.0    0.0   1.0   0.0    6.0    0.0    4.0   1.0    1.0    0.0    1.0    0.0   0.0   0.0    0.3170731707317073   26 / 82
1.0   4.0    0.0   70.0   0.0   1.0   0.0   4.0   1.0   5.0    0.0   0.0   4.0    0.0   7.0   1.0    0.0    9.0    1.0   0.0    1.0    0.0    0.0    1.0   0.0   2.0    0.375                42 / 112
0.0   5.0    1.0   0.0    53.0  1.0   9.0   0.0   1.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    6.0    1.0    3.0   5.0    0.0    0.0    0.0    3.0   0.0   8.0    0.4536082474226804   44 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---    ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   8.0    2.0   1.0   0.0    1.0    0.0    0.0   0.0    0.0    3.0    77.0   0.0   0.0   0.0    0.16304347826086957  15 / 92
5.0   6.0    0.0   0.0    7.0   0.0   1.0   3.0   3.0   2.0    4.0   0.0   0.0    0.0   0.0   0.0    4.0    0.0    10.0  11.0   1.0    0.0    0.0    24.0  1.0   18.0   0.76                 76 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   4.0    2.0    0.0    0.0   20.0   0.0    24.0   2.0    0.0   50.0  0.0    0.5327102803738317   57 / 107
1.0   1.0    0.0   1.0    7.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0    9.0   2.0    0.0    0.0    0.0    3.0   0.0   61.0   0.2988505747126437   26 / 87
94.0  134.0  84.0  104.0  77.0  71.0  87.0  58.0  81.0  108.0  75.0  84.0  134.0  91.0  75.0  122.0  113.0  110.0  83.0  117.0  103.0  101.0  124.0  52.0  91.0  117.0  0.39397590361445783  981 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.606024
2    0.751004
3    0.816064
4    0.863855
5    0.889558
6    0.910442
7    0.924096
8    0.937751
9    0.951807
10   0.959839
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:27  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:27  1 min  4.600 sec  103164 obs/sec    1         1             10007      0.748837         1.67797             0.990036       0.454864                         0.747384           1.67729               0.990047         0.445783
    2019-07-24 13:10:28  1 min  5.514 sec  101080 obs/sec    10        10            100070     0.697189         1.44657             0.991363       0.391083                         0.695146           1.44557               0.99139          0.393976
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0899365
C15         0.983971               0.983971             0.0884949
C12         0.87481                0.87481              0.0786774
C9          0.872687               0.872687             0.0784864
C11         0.835503               0.835503             0.0751422
C7          0.823224               0.823224             0.0740379
C8          0.81079                0.81079              0.0729197
C14         0.766674               0.766674             0.0689519
C10         0.6414                 0.6414               0.0576853
C3          0.605475               0.605475             0.0544543
C16         0.562586               0.562586             0.050597
C6          0.502521               0.502521             0.045195
C5          0.493151               0.493151             0.0443523
C1          0.492113               0.492113             0.044259
C4          0.468389               0.468389             0.0421253
C2          0.385659               0.385659             0.0346849
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_19

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight          weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  -------------------  ------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.001111208520683249   0.00030728860292583704  0.0         -0.2314382385643512  2.015072822570801   -0.009919372461658969  0.9663419723510742
    3        26       Softmax                 0.0   0.0   0.0016632254077054453  9.095165296457708e-05   0.0         -0.0382267538170009  0.5068156719207764  -0.5853991807078334    0.39284980297088623


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4875536773109005
RMSE: 0.6982504402511326
LogLoss: 1.453791692909116
Mean Per-Class Error: 0.4091773780654159
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
339.0  0.0    0.0    11.0   0.0    0.0    2.0    1.0    0.0    2.0    1.0    8.0    8.0    1.0    0.0    0.0    3.0    4.0    0.0    0.0    3.0    3.0    2.0    0.0    6.0    0.0    0.13959390862944163  55 / 394
2.0    199.0  0.0    7.0    5.0    2.0    1.0    6.0    13.0   0.0    0.0    1.0    6.0    1.0    0.0    5.0    7.0    64.0   52.0   0.0    0.0    1.0    1.0    0.0    0.0    10.0   0.4804177545691906   184 / 383
0.0    2.0    228.0  0.0    47.0   0.0    35.0   1.0    0.0    0.0    19.0   1.0    5.0    2.0    0.0    1.0    3.0    1.0    4.0    5.0    9.0    0.0    0.0    0.0    0.0    5.0    0.3804347826086957   140 / 368
3.0    26.0   0.0    263.0  1.0    1.0    0.0    5.0    7.0    7.0    0.0    13.0   3.0    14.0   14.0   9.0    0.0    18.0   1.0    4.0    1.0    0.0    0.0    10.0   0.0    3.0    0.34739454094292804  140 / 403
0.0    7.0    36.0   0.0    164.0  1.0    34.0   0.0    18.0   0.0    0.0    1.0    0.0    0.0    0.0    0.0    11.0   13.0   28.0   3.0    6.0    0.0    0.0    16.0   1.0    45.0   0.5729166666666666   220 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    20.0   9.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    15.0   315.0  0.0    0.0    0.0    0.1622340425531915   61 / 376
35.0   6.0    12.0   12.0   23.0   2.0    2.0    0.0    30.0   0.0    2.0    16.0   0.0    0.0    2.0    0.0    20.0   2.0    17.0   9.0    10.0   0.0    0.0    120.0  8.0    66.0   0.6954314720812182   274 / 394
0.0    1.0    0.0    4.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    2.0    15.0   13.0   1.0    7.0    77.0   7.0    85.0   0.0    0.0    161.0  0.0    0.5903307888040712   232 / 393
2.0    13.0   1.0    5.0    19.0   0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    7.0    1.0    32.0   5.0    0.0    0.0    0.0    5.0    0.0    274.0  0.25340599455040874  93 / 367
451.0  396.0  383.0  452.0  393.0  312.0  371.0  135.0  405.0  306.0  217.0  385.0  445.0  399.0  364.0  425.0  386.0  623.0  332.0  445.0  379.0  452.0  450.0  243.0  310.0  544.0  0.4078776367089873   4,080 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.592122
2    0.743477
3    0.815355
4    0.857243
5    0.885734
6    0.906528
7    0.922323
8    0.936819
9    0.948215
10   0.957213

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.48827980001587123
RMSE: 0.698770205443729
LogLoss: 1.4494088596467767
Mean Per-Class Error: 0.4078457594033911
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1     2     3      4     5     6     7     8     9     10    11     12     13     14    15     16     17     18    19    20    21     22     23    24    25     Error                Rate
-----  ----  ----  -----  ----  ----  ----  ----  ----  ----  ----  -----  -----  -----  ----  -----  -----  -----  ----  ----  ----  -----  -----  ----  ----  -----  -------------------  -------------
78.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    1.0    0.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0   0.0    2.0    0.0   3.0   0.0    0.12359550561797752  11 / 89
0.0    44.0  0.0   0.0    1.0   0.0   0.0   0.0   5.0   0.0   0.0   1.0    2.0    1.0    0.0   1.0    6.0    24.0   15.0  0.0   0.0   1.0    1.0    0.0   0.0   4.0    0.5849056603773585   62 / 106
0.0    1.0   49.0  0.0    8.0   0.0   12.0  0.0   0.0   0.0   3.0   0.0    0.0    1.0    0.0   1.0    1.0    1.0    2.0   2.0   0.0   0.0    0.0    0.0   0.0   1.0    0.4024390243902439   33 / 82
1.0    6.0   0.0   84.0   0.0   0.0   0.0   2.0   0.0   1.0   0.0   3.0    2.0    3.0    4.0   1.0    0.0    3.0    1.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0    0.25                 28 / 112
0.0    0.0   13.0  0.0    38.0  1.0   10.0  0.0   3.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    3.0    4.0    8.0   2.0   2.0   0.0    0.0    4.0   0.0   9.0    0.6082474226804123   59 / 97
---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---   ---    ---    ---    ---   ---    ---    ---    ---   ---   ---   ---    ---    ---   ---   ---    ---                  ---
0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    4.0    4.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0   3.0    79.0   0.0   0.0   0.0    0.14130434782608695  13 / 92
7.0    3.0   3.0   2.0    8.0   0.0   0.0   0.0   8.0   0.0   2.0   3.0    0.0    0.0    0.0   0.0    3.0    0.0    5.0   1.0   3.0   0.0    0.0    36.0  2.0   14.0   0.64                 64 / 100
0.0    1.0   0.0   1.0    0.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0    2.0    0.0   6.0    5.0    1.0    0.0   12.0  2.0   22.0   0.0    0.0   50.0  0.0    0.5327102803738317   57 / 107
0.0    2.0   0.0   2.0    5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    2.0    0.0    7.0   2.0   0.0   0.0    0.0    3.0   0.0   64.0   0.26436781609195403  23 / 87
105.0  92.0  85.0  127.0  89.0  66.0  89.0  28.0  97.0  80.0  57.0  108.0  102.0  104.0  70.0  123.0  105.0  165.0  93.0  95.0  95.0  107.0  120.0  67.0  91.0  130.0  0.40642570281124496  1,012 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.593574
2    0.748193
3    0.822892
4    0.85743
5    0.888755
6    0.91004
7    0.926506
8    0.936948
9    0.948594
10   0.959438
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 13:10:19  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 13:10:19  56.506 sec  78795 obs/sec     1         1             10007      0.759644         1.72492             0.989744       0.482755                         0.756503           1.70639               0.989803         0.473092
    2019-07-24 13:10:20  57.460 sec  94405 obs/sec     10        10            100070     0.69825          1.45379             0.991335       0.407878                         0.69877            1.44941               0.9913           0.406426
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0971014
C13         0.900704               0.900704             0.0874596
C12         0.900547               0.900547             0.0874444
C9          0.888069               0.888069             0.0862328
C11         0.745749               0.745749             0.0724133
C7          0.725985               0.725985             0.0704941
C8          0.707866               0.707866             0.0687348
C14         0.659568               0.659568             0.064045
C10         0.614427               0.614427             0.0596617
C16         0.566187               0.566187             0.0549775
C6          0.536589               0.536589             0.0521035
C3          0.484174               0.484174             0.047014
C5          0.468865               0.468865             0.0455274
C4          0.376732               0.376732             0.0365812
C1          0.372063               0.372063             0.0361278
C2          0.35099                0.35099              0.0340816
[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ]
                activation  ...                model_ids              logloss
0     RectifierWithDropout  ...  DL_random_grid_model_41   0.3750451488227456
1     RectifierWithDropout  ...  DL_random_grid_model_17  0.37620957414916395
2     RectifierWithDropout  ...  DL_random_grid_model_21  0.38074088635300674
3     RectifierWithDropout  ...   DL_random_grid_model_4   0.3917098822545203
4     RectifierWithDropout  ...  DL_random_grid_model_26   0.4288129556278478
5          TanhWithDropout  ...  DL_random_grid_model_13   0.4380486418351201
6     RectifierWithDropout  ...   DL_random_grid_model_1   0.4391544752598762
7     RectifierWithDropout  ...  DL_random_grid_model_27   0.4465018410103051
8     RectifierWithDropout  ...  DL_random_grid_model_33   0.4562249351776383
9     RectifierWithDropout  ...  DL_random_grid_model_29  0.46571078247838327
10         TanhWithDropout  ...  DL_random_grid_model_25   0.4660015804285876
11         TanhWithDropout  ...  DL_random_grid_model_24   0.4813785696713536
12    RectifierWithDropout  ...  DL_random_grid_model_11   0.5252408728527576
13    RectifierWithDropout  ...  DL_random_grid_model_28   0.5320012993691337
14         TanhWithDropout  ...  DL_random_grid_model_16   0.5598517918004047
15         TanhWithDropout  ...   DL_random_grid_model_7   0.5689644764004004
16    RectifierWithDropout  ...   DL_random_grid_model_9   0.5804364606054686
17         TanhWithDropout  ...  DL_random_grid_model_38   0.5824028963756966
18         TanhWithDropout  ...  DL_random_grid_model_10   0.5837354343479656
19    RectifierWithDropout  ...  DL_random_grid_model_32   0.5902865240150295
20    RectifierWithDropout  ...  DL_random_grid_model_36   0.5904498106494139
21         TanhWithDropout  ...   DL_random_grid_model_2   0.6296970703726318
22    RectifierWithDropout  ...  DL_random_grid_model_44   0.6490965882690374
23    RectifierWithDropout  ...   DL_random_grid_model_3   0.6666629983427547
24    RectifierWithDropout  ...  DL_random_grid_model_20   0.7005819937706235
25         TanhWithDropout  ...  DL_random_grid_model_34    0.728258506744848
26    RectifierWithDropout  ...  DL_random_grid_model_31   0.7364662384574785
27    RectifierWithDropout  ...   DL_random_grid_model_5   0.7383946274380824
28         TanhWithDropout  ...   DL_random_grid_model_8   0.7418268346794655
29         TanhWithDropout  ...  DL_random_grid_model_12   0.7436758764229251
30         TanhWithDropout  ...  DL_random_grid_model_39   0.7506885701115511
31         TanhWithDropout  ...  DL_random_grid_model_18   0.7600920664808973
32         TanhWithDropout  ...  DL_random_grid_model_30   0.7630716439137823
33         TanhWithDropout  ...  DL_random_grid_model_37   0.7657542894451504
34    RectifierWithDropout  ...  DL_random_grid_model_40   0.8554856707251272
35    RectifierWithDropout  ...  DL_random_grid_model_43   0.8727321764883789
36         TanhWithDropout  ...  DL_random_grid_model_45   0.9417669355152002
37         TanhWithDropout  ...  DL_random_grid_model_42   0.9673187726508254
38         TanhWithDropout  ...  DL_random_grid_model_15   0.9958171506754403
39         TanhWithDropout  ...  DL_random_grid_model_35   1.0310668133149576
40    RectifierWithDropout  ...  DL_random_grid_model_14   1.0936199064843242
41         TanhWithDropout  ...   DL_random_grid_model_6   1.1016526495015884
42    RectifierWithDropout  ...  DL_random_grid_model_23   1.1195051539713736
43         TanhWithDropout  ...  DL_random_grid_model_22    1.445566213813593
44         TanhWithDropout  ...  DL_random_grid_model_19   1.4494088596467767

[45 rows x 7 columns]

--- 123.27730226516724 seconds ---
Evalutation of best performing model:
Final acc, selected model:  86.47052937055939
Time consumed:  0.0342838411198722  hours
H2O session _sid_87b2 closed.
