Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmp73qu5ndb
  JVM stdout: /tmp/tmp73qu5ndb/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmp73qu5ndb/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    8 days
H2O cluster name:           H2O_from_python_davidserranogemes_udcyqe
H2O cluster total nodes:    1
H2O cluster free memory:    3.900 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Guided  mode.

deeplearning Grid Build progress: |███████████████████████████████████████| 100%
deeplearning prediction progress: |███████████████████████████████████████| 100%
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_41

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019274532715058967  0.0004733059322461486  0.0         -0.008677033058493322  0.17409390211105347  0.26929267305540244   0.1266460418701172
    3        26       Softmax                      0.0   0.0   0.010008936154200945   0.05077701807022095    0.0         -0.21176201456437235   0.3941497802734375   -0.49040574806500703  0.09567239880561829


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.10990960622900041
RMSE: 0.33152617729072376
LogLoss: 0.3642081168043636
Mean Per-Class Error: 0.10521948883769142
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
368.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    2.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    1.0    4.0    2.0    1.0    3.0    2.0    0.06835443037974684  27 / 395
0.0    336.0  0.0    7.0    2.0    0.0    1.0    8.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    8.0    8.0    0.0    0.0    3.0    0.0    2.0    1.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    333.0  0.0    7.0    0.0    5.0    1.0    0.0    0.0    8.0    2.0    0.0    0.0    5.0    0.0    1.0    1.0    1.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.09510869565217392  35 / 368
0.0    7.0    0.0    370.0  0.0    0.0    0.0    3.0    0.0    1.0    1.0    0.0    6.0    4.0    0.0    0.0    0.0    3.0    2.0    0.0    1.0    0.0    0.0    2.0    0.0    3.0    0.08188585607940446  33 / 403
0.0    2.0    2.0    0.0    330.0  4.0    16.0   2.0    0.0    0.0    2.0    8.0    0.0    0.0    0.0    1.0    2.0    2.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    9.0    0.140625             54 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    361.0  0.0    0.0    0.0    0.0398936170212766   15 / 376
0.0    1.0    0.0    5.0    4.0    1.0    0.0    0.0    3.0    4.0    6.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    358.0  1.0    1.0    0.08673469387755102  34 / 392
0.0    0.0    0.0    2.0    0.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    7.0    0.0    19.0   1.0    0.0    347.0  0.0    0.11704834605597965  46 / 393
2.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   1.0    0.0    0.0    0.0    0.0    0.0    330.0  0.1008174386920981   37 / 367
389.0  401.0  352.0  424.0  380.0  436.0  375.0  320.0  347.0  389.0  371.0  385.0  400.0  379.0  376.0  367.0  352.0  438.0  399.0  371.0  404.0  391.0  420.0  401.0  370.0  366.0  0.10486853943816855  1,049 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.895131
2    0.951815
3    0.971209
4    0.981006
5    0.986904
6    0.991403
7    0.993502
8    0.995101
9    0.996401
10   0.997501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.10992277048292944
RMSE: 0.33154603071508704
LogLoss: 0.3707619238473035
Mean Per-Class Error: 0.1015725901283205
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11    12    13    14    15     16    17     18     19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    1.0   0.0    0.0   2.0    0.0   0.0449438202247191    4 / 89
0.0   88.0   0.0   2.0    1.0   0.0    1.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   5.0    2.0    0.0   0.0    2.0   0.0    1.0   0.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    73.0  0.0    2.0   0.0    2.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.10975609756097561   9 / 82
0.0   1.0    0.0   102.0  0.0   0.0    0.0   2.0   0.0   0.0    0.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   0.0    1.0   0.0    2.0   0.08928571428571429   10 / 112
0.0   0.0    0.0   0.0    82.0  3.0    6.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0    1.0   0.0    2.0   0.15463917525773196   15 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   91.0   0.0   0.0    0.0   0.010869565217391304  1 / 92
0.0   0.0    0.0   2.0    3.0   1.0    0.0   0.0   0.0   1.0    4.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    88.0  0.0    0.0   0.12                  12 / 100
0.0   0.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    2.0   0.0    7.0   1.0    0.0   93.0   0.0   0.1308411214953271    14 / 107
1.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0    0.0   0.0    79.0  0.09195402298850575   8 / 87
89.0  100.0  77.0  115.0  95.0  103.0  98.0  79.0  83.0  113.0  90.0  97.0  85.0  99.0  79.0  103.0  95.0  111.0  100.0  87.0  103.0  90.0  108.0  97.0  105.0  89.0  0.10240963855421686   255 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.89759
2    0.953815
3    0.969076
4    0.979518
5    0.983133
6    0.991165
7    0.993574
8    0.995181
9    0.996787
10   0.99759
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:34  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:34  1 min 11.017 sec  27341 obs/sec     1         1             10007      0.500231         0.839185            0.995553       0.23273                          0.502222           0.850215              0.995506         0.24257
    2019-07-24 15:36:37  1 min 14.020 sec  30168 obs/sec     10        10            100070     0.331526         0.364208            0.998047       0.104869                         0.331546           0.370762              0.998041         0.10241
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.084529
C13         0.939511               0.939511             0.079416
C9          0.891867               0.891867             0.0753887
C8          0.873781               0.873781             0.0738599
C12         0.842521               0.842521             0.0712175
C7          0.770252               0.770252             0.0651087
C10         0.769765               0.769765             0.0650675
C5          0.731479               0.731479             0.0618312
C11         0.705201               0.705201             0.0596099
C6          0.690806               0.690806             0.0583932
C14         0.686469               0.686469             0.0580266
C16         0.651455               0.651455             0.0550668
C4          0.614643               0.614643             0.0519552
C3          0.597928               0.597928             0.0505423
C1          0.558531               0.558531             0.0472121
C2          0.506046               0.506046             0.0427756
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_17

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018910489902168592  0.0005043796263635159  0.0         -0.0093569919308365   0.1727510690689087  0.2684575929369565    0.11442163586616516
    3        26       Softmax                      0.0   0.0   0.009356977053200283   0.04031127691268921    0.0         -0.22052017383819916  0.393407940864563   -0.48707072331683254  0.08381053805351257


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.10936448068045147
RMSE: 0.33070300978438566
LogLoss: 0.369500078700599
Mean Per-Class Error: 0.10672378786156402
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
372.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    4.0    0.0    0.0    0.0    0.0    3.0    1.0    1.0    0.0    1.0    1.0    0.0    4.0    3.0    0.05822784810126582  23 / 395
0.0    342.0  0.0    1.0    3.0    0.0    1.0    7.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    12.0   6.0    1.0    0.0    1.0    0.0    3.0    1.0    0.0    0.10704960835509138  41 / 383
0.0    0.0    336.0  0.0    3.0    0.0    10.0   1.0    0.0    0.0    7.0    1.0    0.0    0.0    4.0    0.0    1.0    1.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.08695652173913043  32 / 368
0.0    16.0   0.0    345.0  0.0    0.0    3.0    5.0    0.0    3.0    1.0    0.0    6.0    4.0    2.0    0.0    0.0    8.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    4.0    0.14392059553349876  58 / 403
0.0    4.0    3.0    0.0    325.0  2.0    17.0   0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    1.0    3.0    3.0    2.0    3.0    0.0    0.0    0.0    6.0    0.0    10.0   0.15364583333333334  59 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    13.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    355.0  0.0    0.0    0.0    0.05585106382978723  21 / 376
0.0    0.0    0.0    4.0    2.0    0.0    0.0    1.0    2.0    4.0    10.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    357.0  3.0    3.0    0.09390862944162437  37 / 394
0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    1.0    3.0    1.0    2.0    1.0    0.0    380.0  0.0    0.03307888040712468  13 / 393
2.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    6.0    1.0    0.0    0.0    0.0    3.0    0.0    343.0  0.0653950953678474   24 / 367
388.0  436.0  358.0  388.0  377.0  378.0  410.0  332.0  331.0  372.0  370.0  367.0  412.0  374.0  390.0  358.0  374.0  428.0  376.0  390.0  405.0  359.0  397.0  421.0  425.0  387.0  0.10636808957312806  1,064 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.893632
2    0.950015
3    0.969209
4    0.978706
5    0.984105
6    0.989003
7    0.992402
8    0.994102
9    0.995201
10   0.996601

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11153082133434779
RMSE: 0.3339623052596622
LogLoss: 0.38064600984023134
Mean Per-Class Error: 0.10587066496739077
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0    2.0    1.0   0.056179775280898875  5 / 89
0.0   88.0   0.0   0.0    2.0   0.0   1.0    3.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   6.0    2.0   0.0   0.0    1.0   0.0   1.0    1.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    77.0  0.0    1.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0    0.0    0.0   0.06097560975609756   5 / 82
0.0   1.0    0.0   98.0   0.0   0.0   1.0    2.0   0.0   2.0    0.0   0.0   2.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    2.0   0.125                 14 / 112
0.0   0.0    1.0   0.0    82.0  1.0   6.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0   2.0    0.0    3.0   0.15463917525773196   15 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   89.0  0.0    0.0    0.0   0.03260869565217391   3 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0    0.0   0.0   1.0    5.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   89.0   0.0    1.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   0.0   0.0    1.0   1.0   0.0    103.0  0.0   0.037383177570093455  4 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0    82.0  0.05747126436781609   5 / 87
88.0  104.0  83.0  109.0  95.0  85.0  102.0  84.0  81.0  109.0  93.0  94.0  90.0  98.0  82.0  101.0  99.0  107.0  92.0  89.0  105.0  79.0  99.0  106.0  121.0  95.0  0.10642570281124498   265 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.893574
2    0.951807
3    0.969478
4    0.979518
5    0.983936
6    0.988353
7    0.991968
8    0.992771
9    0.993574
10   0.996787
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:57  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:57  34.101 sec  24407 obs/sec     1         1             10007      0.502149         0.860473            0.995519       0.238329                         0.505332           0.870971              0.99545          0.244578
    2019-07-24 15:36:00  37.043 sec  30518 obs/sec     10        10            100070     0.330703         0.3695              0.998057       0.106368                         0.333962           0.380646              0.998013         0.106426
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0843484
C13         0.923469               0.923469             0.0778931
C9          0.896469               0.896469             0.0756157
C8          0.889999               0.889999             0.07507
C12         0.812603               0.812603             0.0685417
C10         0.788259               0.788259             0.0664884
C7          0.752593               0.752593             0.06348
C5          0.74795                0.74795              0.0630884
C6          0.731323               0.731323             0.0616859
C11         0.70524                0.70524              0.0594858
C14         0.634407               0.634407             0.0535112
C16         0.629222               0.629222             0.0530739
C4          0.613329               0.613329             0.0517333
C3          0.596502               0.596502             0.050314
C1          0.585064               0.585064             0.0493492
C2          0.549165               0.549165             0.0463212
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_21

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019042455189932639  0.000496499240398407  0.0         -0.006488900739767267  0.17019188404083252  0.27507763417556824   0.1200844943523407
    3        26       Softmax                      0.0   0.0   0.009592758129376587   0.037887513637542725  0.0         -0.21636889623851538   0.3935680389404297   -0.47120297044988935  0.09667855501174927


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11026554563741789
RMSE: 0.33206256283630936
LogLoss: 0.3704308167221075
Mean Per-Class Error: 0.10848932728534702
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
366.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0    1.0    3.0    0.0    0.0    1.0    0.0    3.0    2.0    1.0    1.0    1.0    2.0    1.0    2.0    3.0    0.07341772151898734   29 / 395
0.0    335.0  0.0    7.0    3.0    2.0    1.0    12.0   1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    8.0    5.0    0.0    0.0    3.0    0.0    1.0    1.0    0.0    0.12532637075718014   48 / 383
0.0    0.0    334.0  1.0    8.0    0.0    5.0    2.0    0.0    0.0    6.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    1.0    3.0    0.0    2.0    0.0    0.0    0.0    0.09239130434782608   34 / 368
0.0    5.0    0.0    378.0  0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    8.0    0.0    1.0    0.0    2.0    1.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    0.062034739454094295  25 / 403
0.0    0.0    1.0    0.0    345.0  3.0    9.0    1.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    5.0    4.0    1.0    3.0    0.0    0.0    0.0    2.0    0.0    6.0    0.1015625             39 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    3.0    0.0    0.0    4.0    0.0    0.0    3.0    0.0    354.0  0.0    0.0    0.0    0.056                 21 / 375
0.0    1.0    0.0    4.0    2.0    2.0    0.0    1.0    2.0    4.0    8.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    359.0  1.0    4.0    0.08883248730964467   35 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0    2.0    6.0    1.0    3.0    1.0    0.0    372.0  0.0    0.05343511450381679   21 / 393
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    8.0    1.0    0.0    0.0    0.0    1.0    0.0    336.0  0.08446866485013624   31 / 367
378.0  401.0  381.0  458.0  406.0  370.0  329.0  347.0  342.0  379.0  372.0  352.0  388.0  381.0  370.0  402.0  378.0  457.0  391.0  385.0  416.0  347.0  403.0  393.0  409.0  368.0  0.10796760971708487   1,080 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.892032
2    0.951914
3    0.970209
4    0.978906
5    0.985604
6    0.989503
7    0.992402
8    0.994502
9    0.995701
10   0.996301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11276968756313065
RMSE: 0.3358119824591294
LogLoss: 0.38252103262376946
Mean Per-Class Error: 0.10875639544057651
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
83.0  0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   1.0    0.0   2.0    1.0   0.06741573033707865   6 / 89
0.0   87.0  0.0   0.0    2.0    1.0   1.0   3.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0   4.0    1.0   0.0   0.0    3.0   0.0    1.0   1.0    0.0   0.1792452830188679    19 / 106
0.0   0.0   74.0  0.0    2.0    0.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0975609756097561    8 / 82
0.0   0.0   0.0   104.0  0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   3.0   0.0   1.0    0.0   0.0    1.0   0.0   1.0    0.0   0.0    1.0   0.0    0.0   0.07142857142857142   8 / 112
0.0   0.0   0.0   0.0    87.0   1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0    1.0   0.0    1.0   0.10309278350515463   10 / 97
---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   90.0   0.0   0.0    0.0   0.021739130434782608  2 / 92
0.0   0.0   0.0   2.0    1.0    0.0   0.0   0.0   0.0   1.0    5.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    89.0  0.0    2.0   0.11                  11 / 100
0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0   2.0   0.0    1.0   1.0    0.0   100.0  0.0   0.06542056074766354   7 / 107
1.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    80.0  0.08045977011494253   7 / 87
87.0  98.0  82.0  123.0  100.0  83.0  87.0  88.0  81.0  108.0  91.0  91.0  82.0  99.0  78.0  114.0  99.0  118.0  97.0  92.0  106.0  76.0  104.0  99.0  118.0  89.0  0.10803212851405622   269 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.891968
2    0.948996
3    0.96747
4    0.977912
5    0.984739
6    0.989558
7    0.991968
8    0.994378
9    0.995582
10   0.995582
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:03  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:03  40.166 sec  22437 obs/sec     1         1             10007      0.499584         0.853452            0.995565       0.239628                         0.500222           0.850765              0.995541         0.244578
    2019-07-24 15:36:06  43.172 sec  29432 obs/sec     10        10            100070     0.332063         0.370431            0.998041       0.107968                         0.335812           0.382521              0.997991         0.108032
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0874991
C13         0.912367               0.912367             0.0798313
C8          0.85804                0.85804              0.0750778
C12         0.810444               0.810444             0.0709131
C9          0.787867               0.787867             0.0689376
C7          0.738027               0.738027             0.0645767
C10         0.729553               0.729553             0.0638352
C5          0.714163               0.714163             0.0624886
C11         0.691097               0.691097             0.0604703
C14         0.654101               0.654101             0.0572333
C6          0.650873               0.650873             0.0569508
C16         0.636424               0.636424             0.0556865
C4          0.600238               0.600238             0.0525203
C3          0.581786               0.581786             0.0509057
C1          0.561712               0.561712             0.0491493
C2          0.502                  0.502                0.0439245
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_4

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.001863678873789354  0.0004869893891736865  0.0         -0.009119499263381181  0.16906064748764038  0.2788014663264844   0.1213742196559906
    3        26       Softmax                      0.0   0.0   0.008268120584331812  0.03452305495738983    0.0         -0.21549771437126544   0.391049861907959    -0.4879155938411989  0.095784991979599


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11576471371880259
RMSE: 0.34024213983397555
LogLoss: 0.3839871154780446
Mean Per-Class Error: 0.11369183695328415
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
368.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    3.0    1.0    0.0    2.0    0.0    0.0    2.0    2.0    3.0    0.0    2.0    2.0    1.0    4.0    2.0    0.06835443037974684   27 / 395
0.0    321.0  0.0    7.0    5.0    4.0    2.0    10.0   2.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    14.0   10.0   0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.1618798955613577    62 / 383
0.0    0.0    317.0  0.0    16.0   0.0    7.0    1.0    0.0    0.0    4.0    4.0    0.0    0.0    8.0    0.0    0.0    1.0    0.0    2.0    4.0    0.0    3.0    1.0    0.0    0.0    0.13858695652173914   51 / 368
1.0    11.0   0.0    357.0  0.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    2.0    6.0    4.0    1.0    0.0    6.0    1.0    0.0    1.0    0.0    0.0    4.0    0.0    5.0    0.1141439205955335    46 / 403
0.0    0.0    2.0    0.0    333.0  4.0    14.0   1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    1.0    0.0    3.0    1.0    2.0    0.0    0.0    0.0    4.0    0.0    13.0   0.1328125             51 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    362.0  0.0    0.0    0.0    0.034666666666666665  13 / 375
0.0    0.0    0.0    4.0    1.0    0.0    0.0    2.0    2.0    4.0    2.0    5.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    364.0  1.0    5.0    0.07614213197969544   30 / 394
1.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    15.0   1.0    27.0   1.0    0.0    343.0  0.0    0.1272264631043257    50 / 393
1.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    5.0    1.0    0.0    0.0    0.0    1.0    0.0    347.0  0.05449591280653951   20 / 367
402.0  380.0  332.0  407.0  405.0  406.0  377.0  362.0  350.0  374.0  319.0  407.0  369.0  382.0  432.0  378.0  332.0  427.0  353.0  384.0  411.0  382.0  412.0  432.0  371.0  417.0  0.11336599020293912   1,134 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.886634
2    0.946416
3    0.96761
4    0.978906
5    0.986104
6    0.990003
7    0.992702
8    0.994402
9    0.996501
10   0.997501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11856844253006162
RMSE: 0.344337686769923
LogLoss: 0.3973996485540035
Mean Per-Class Error: 0.1147303058341483
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22     23     24     25     Error                 Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  --------------------  -----------
84.0  0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0    0.0    2.0    1.0    0.056179775280898875  5 / 89
0.0   83.0  0.0   2.0    2.0   2.0   1.0   2.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0    0.0   6.0    3.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0    0.2169811320754717    23 / 106
0.0   0.0   69.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    1.0   2.0    0.0   0.0    4.0   0.0    0.0   0.0    0.0   2.0   0.0    0.0   1.0    0.0    0.0    0.0    0.15853658536585366   13 / 82
1.0   2.0   0.0   99.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   3.0    1.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    2.0    0.11607142857142858   13 / 112
0.0   0.0   0.0   0.0    81.0  2.0   4.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    5.0    0.16494845360824742   16 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                   ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   91.0   0.0    0.0    0.0    0.010869565217391304  1 / 92
0.0   0.0   0.0   2.0    1.0   0.0   0.0   1.0   0.0   1.0    0.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    91.0   0.0    2.0    0.09                  9 / 100
1.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   3.0   0.0    9.0   1.0    0.0    92.0   0.0    0.14018691588785046   15 / 107
1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    83.0   0.04597701149425287   4 / 87
92.0  94.0  73.0  115.0  97.0  95.0  92.0  90.0  86.0  111.0  80.0  105.0  78.0  101.0  95.0  107.0  89.0  106.0  86.0  90.0  105.0  88.0  101.0  105.0  104.0  105.0  0.11566265060240964   288 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.884337
2    0.948594
3    0.966265
4    0.975904
5    0.983133
6    0.988755
7    0.991566
8    0.994378
9    0.996386
10   0.99759
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:34  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:35  11.434 sec  27952 obs/sec     1         1             10007      0.505821         0.85781             0.995453       0.239028                         0.506075           0.866444              0.995436         0.241767
    2019-07-24 15:35:38  14.397 sec  30639 obs/sec     10        10            100070     0.340242         0.383987            0.997943       0.113366                         0.344338           0.3974                0.997887         0.115663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.087973
C13         0.870282               0.870282             0.0765613
C8          0.855138               0.855138             0.0752291
C9          0.851366               0.851366             0.0748972
C12         0.763759               0.763759             0.0671902
C7          0.748341               0.748341             0.0658338
C10         0.731082               0.731082             0.0643155
C5          0.70901                0.70901              0.0623737
C11         0.690098               0.690098             0.06071
C6          0.659503               0.659503             0.0580185
C14         0.639407               0.639407             0.0562505
C16         0.637851               0.637851             0.0561137
C4          0.57604                0.57604              0.050676
C3          0.563425               0.563425             0.0495662
C2          0.538206               0.538206             0.0473476
C1          0.533614               0.533614             0.0469436
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_26

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018691806082102858  0.00047551782336086035  0.0         -0.009919824891165607  0.17063653469085693  0.1703075338392024   0.12360683083534241
    3        26       Softmax                      0.0   0.0   0.011419066359368256   0.0485515296459198      0.0         -0.20233264680074442   0.3997225761413574   -0.6778879333390703  0.19274884462356567


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12643050899747324
RMSE: 0.3555706807337653
LogLoss: 0.41336532142959065
Mean Per-Class Error: 0.11399846217293234
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    5.0    0.0    1.0    0.0    0.0    2.0    3.0    0.0    1.0    2.0    3.0    1.0    3.0    2.0    0.06852791878172589   27 / 394
0.0    354.0  0.0    4.0    3.0    1.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    9.0    3.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.07571801566579635   29 / 383
0.0    0.0    325.0  0.0    10.0   1.0    9.0    1.0    0.0    0.0    7.0    2.0    0.0    0.0    3.0    0.0    0.0    0.0    2.0    2.0    1.0    0.0    4.0    1.0    0.0    0.0    0.11684782608695653   43 / 368
0.0    21.0   0.0    353.0  0.0    1.0    0.0    6.0    0.0    4.0    0.0    0.0    5.0    5.0    1.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0    0.12406947890818859   50 / 403
0.0    5.0    1.0    0.0    326.0  7.0    16.0   2.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    1.0    3.0    3.0    3.0    0.0    0.0    0.0    3.0    0.0    10.0   0.15104166666666666   58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    5.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    13.0   1.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    350.0  0.0    0.0    0.0    0.06914893617021277   26 / 376
0.0    1.0    0.0    5.0    4.0    0.0    0.0    1.0    1.0    4.0    7.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    357.0  4.0    3.0    0.09390862944162437   37 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    3.0    1.0    3.0    1.0    0.0    376.0  0.0    0.043256997455470736  17 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    10.0   1.0    0.0    0.0    0.0    0.0    0.0    329.0  0.10109289617486339   37 / 366
386.0  487.0  343.0  408.0  400.0  416.0  372.0  333.0  340.0  386.0  353.0  367.0  410.0  381.0  386.0  365.0  371.0  404.0  365.0  378.0  403.0  368.0  396.0  412.0  409.0  364.0  0.11346596021193642   1,135 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.886534
2    0.942717
3    0.963811
4    0.975507
5    0.982405
6    0.987704
7    0.990703
8    0.993402
9    0.994702
10   0.996401

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.12699597691850398
RMSE: 0.3563649490599545
LogLoss: 0.4196552081299318
Mean Per-Class Error: 0.10975749621979942
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11    12    13     14    15     16     17     18    19    20    21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  ----  ----  -----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0   0.0   0.0   1.0   0.0   2.0    0.0   0.07865168539325842   7 / 89
0.0   91.0   0.0   1.0    2.0   1.0    0.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    0.0    4.0    1.0   0.0   0.0   1.0   0.0   1.0   0.0    0.0   0.14150943396226415   15 / 106
0.0   0.0    70.0  0.0    2.0   0.0    1.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    3.0   0.0    0.0    0.0    1.0   2.0   0.0   0.0   1.0   0.0   0.0    0.0   0.14634146341463414   12 / 82
0.0   2.0    0.0   100.0  0.0   1.0    0.0   2.0   0.0   1.0    0.0   0.0   1.0   3.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.10714285714285714   12 / 112
0.0   0.0    0.0   0.0    79.0  4.0    4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    1.0    2.0   1.0   0.0   0.0   0.0   2.0   0.0    3.0   0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---   ---   ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   88.0  0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   3.0    2.0   0.0    0.0   0.0   0.0   1.0    5.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   87.0  1.0    1.0   0.13                  13 / 100
0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0    0.0   0.0   0.0   2.0   1.0   0.0   102.0  0.0   0.04672897196261682   5 / 107
1.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    78.0  0.10344827586206896   9 / 87
88.0  120.0  73.0  113.0  96.0  100.0  91.0  78.0  84.0  112.0  90.0  95.0  92.0  103.0  85.0  106.0  100.0  102.0  91.0  90.0  98.0  83.0  98.0  99.0  114.0  89.0  0.10963855421686747   273 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.890361
2    0.943373
3    0.962651
4    0.974297
5    0.981124
6    0.986345
7    0.988755
8    0.991566
9    0.994378
10   0.996386
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:12  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:13  49.567 sec  32385 obs/sec     1         1             10007      0.520469         0.889876            0.995185       0.240428                         0.52117            0.896032              0.99516          0.244177
    2019-07-24 15:36:15  52.072 sec  36257 obs/sec     10        10            100070     0.355571         0.413365            0.997753       0.113466                         0.356365           0.419655              0.997737         0.109639
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0867777
C13         0.913647               0.913647             0.0792841
C8          0.838197               0.838197             0.0727368
C9          0.83446                0.83446              0.0724125
C7          0.824224               0.824224             0.0715242
C12         0.774663               0.774663             0.0672234
C11         0.73151                0.73151              0.0634788
C5          0.728538               0.728538             0.0632208
C10         0.715332               0.715332             0.0620749
C6          0.676362               0.676362             0.0586931
C14         0.646239               0.646239             0.0560791
C16         0.616857               0.616857             0.0535294
C3          0.613611               0.613611             0.0532477
C4          0.592536               0.592536             0.0514189
C2          0.514203               0.514203             0.0446213
C1          0.503324               0.503324             0.0436773
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_49

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018583658016382287  0.00047520315274596214  0.0         -0.009322699033969872  0.16686230897903442  0.18460687487166372  0.11799058318138123
    3        26       Softmax                      0.0   0.0   0.01038761520148385    0.0465860515832901      0.0         -0.19753284575062496   0.39884912967681885  -0.6454904693914614  0.19178467988967896


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1304482186031571
RMSE: 0.36117616007034176
LogLoss: 0.42961973811303267
Mean Per-Class Error: 0.12307838619588939
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    2.0    4.0    0.0    0.0    0.0    0.0    3.0    5.0    1.0    2.0    1.0    2.0    0.0    4.0    0.0    0.07088607594936709  28 / 395
0.0    349.0  0.0    8.0    2.0    0.0    1.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    9.0    5.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.08877284595300261  34 / 383
0.0    0.0    311.0  1.0    14.0   0.0    7.0    0.0    0.0    0.0    11.0   4.0    0.0    0.0    4.0    0.0    1.0    0.0    7.0    1.0    4.0    0.0    3.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
0.0    12.0   0.0    363.0  0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    3.0    6.0    1.0    0.0    0.0    5.0    2.0    0.0    1.0    0.0    0.0    3.0    0.0    2.0    0.09925558312655088  40 / 403
0.0    2.0    2.0    0.0    328.0  3.0    16.0   0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    2.0    4.0    8.0    3.0    0.0    0.0    0.0    3.0    0.0    6.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    3.0    0.0    355.0  0.0    0.0    0.0    0.05585106382978723  21 / 376
0.0    1.0    0.0    4.0    4.0    0.0    0.0    2.0    3.0    1.0    6.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    2.0    1.0    0.0    0.0    358.0  2.0    4.0    0.09137055837563451  36 / 394
0.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    7.0    1.0    7.0    1.0    0.0    365.0  0.0    0.07124681933842239  28 / 393
2.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    2.0    18.0   1.0    0.0    0.0    0.0    0.0    0.0    318.0  0.1335149863760218   49 / 367
385.0  468.0  338.0  451.0  401.0  378.0  365.0  289.0  342.0  365.0  348.0  391.0  379.0  382.0  408.0  371.0  362.0  432.0  415.0  379.0  412.0  371.0  418.0  406.0  401.0  346.0  0.12236329101269619  1,224 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877637
2    0.939218
3    0.963411
4    0.973708
5    0.981006
6    0.986504
7    0.990203
8    0.992302
9    0.994002
10   0.996201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1326200211007144
RMSE: 0.36417031880799183
LogLoss: 0.44105858483589444
Mean Per-Class Error: 0.12312907668602646
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   1.0    0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   90.0   0.0   2.0    1.0   0.0   1.0   1.0   1.0   0.0    1.0   0.0   0.0   0.0    1.0   0.0    0.0   3.0    2.0    0.0   0.0    2.0   0.0    1.0   0.0    0.0   0.1509433962264151    16 / 106
0.0   0.0    66.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    3.0    1.0   0.0    0.0   1.0    0.0   0.0    0.0   0.1951219512195122    16 / 82
0.0   1.0    0.0   102.0  0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   3.0    0.0   0.0    0.0   0.0    1.0    0.0   1.0    0.0   0.0    2.0   0.0    1.0   0.08928571428571429   10 / 112
0.0   0.0    0.0   0.0    83.0  1.0   5.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0    4.0    1.0   0.0    0.0   0.0    1.0   0.0    0.0   0.14432989690721648   14 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   1.0    0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   1.0   0.0   0.0    4.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0    89.0  0.0    1.0   0.11                  11 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    2.0   0.0    2.0   1.0    0.0   99.0   0.0   0.07476635514018691   8 / 107
2.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0    0.0   0.0    0.0   0.0    0.0   0.0    75.0  0.13793103448275862   12 / 87
90.0  116.0  70.0  126.0  97.0  89.0  99.0  70.0  84.0  103.0  89.0  97.0  81.0  102.0  85.0  106.0  95.0  110.0  107.0  86.0  106.0  82.0  102.0  99.0  115.0  84.0  0.12208835341365462   304 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877912
2    0.938554
3    0.961847
4    0.972691
5    0.978715
6    0.985944
7    0.990763
8    0.992771
9    0.993574
10   0.995984
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:49  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:49  1 min 26.283 sec  27952 obs/sec     1         1             10007      0.522553         0.913632            0.995148       0.246126                         0.523855           0.917563              0.99511          0.253012
    2019-07-24 15:36:52  1 min 28.843 sec  34952 obs/sec     10        10            100070     0.361176         0.42962             0.997682       0.122363                         0.36417            0.441059              0.997637         0.122088
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.087249
C13         0.939703               0.939703             0.0819881
C8          0.841573               0.841573             0.0734264
C9          0.814484               0.814484             0.0710629
C12         0.803979               0.803979             0.0701463
C10         0.762578               0.762578             0.0665341
C7          0.750356               0.750356             0.0654678
C5          0.739276               0.739276             0.064501
C11         0.692166               0.692166             0.0603908
C6          0.656904               0.656904             0.0573142
C14         0.647098               0.647098             0.0564587
C3          0.620262               0.620262             0.0541172
C4          0.608392               0.608392             0.0530815
C16         0.594761               0.594761             0.0518923
C2          0.496966               0.496966             0.0433598
C1          0.492957               0.492957             0.04301
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_1

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018034005937153097  0.0004369518719613552  0.0         -0.01126377132429468  0.16675293445587158  0.18075887963958404  0.1245904266834259
    3        26       Softmax                      0.0   0.0   0.010179857237858414   0.042875662446022034   0.0         -0.19719276018977894  0.39626944065093994  -0.6394943078666581  0.1588941216468811


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13130765113079612
RMSE: 0.36236397603900433
LogLoss: 0.4306090742585689
Mean Per-Class Error: 0.11914002723127576
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    6.0    0.0    0.0    0.0    0.0    2.0    7.0    1.0    2.0    2.0    2.0    0.0    4.0    0.0    0.07848101265822785  31 / 395
0.0    338.0  0.0    6.0    2.0    1.0    0.0    5.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    4.0    13.0   5.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    326.0  0.0    5.0    0.0    3.0    1.0    0.0    0.0    12.0   2.0    1.0    0.0    5.0    0.0    1.0    1.0    0.0    3.0    5.0    1.0    2.0    0.0    0.0    0.0    0.11413043478260869  42 / 368
1.0    5.0    0.0    366.0  0.0    1.0    1.0    2.0    0.0    0.0    2.0    0.0    7.0    4.0    0.0    0.0    1.0    9.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.08955223880597014  36 / 402
0.0    4.0    2.0    0.0    328.0  3.0    16.0   0.0    0.0    0.0    6.0    3.0    0.0    0.0    0.0    1.0    3.0    3.0    4.0    3.0    0.0    0.0    0.0    3.0    0.0    5.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    15.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    0.0    0.0    4.0    2.0    1.0    0.0    1.0    2.0    4.0    8.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    363.0  1.0    2.0    0.07868020304568528  31 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    5.0    1.0    11.0   1.0    0.0    359.0  0.0    0.08418367346938775  33 / 392
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    11.0   3.0    0.0    0.0    0.0    1.0    0.0    322.0  0.1226158038147139   45 / 367
385.0  403.0  361.0  439.0  394.0  408.0  344.0  321.0  348.0  368.0  383.0  367.0  433.0  364.0  371.0  381.0  378.0  452.0  401.0  374.0  404.0  379.0  406.0  409.0  387.0  343.0  0.11856443067079876  1,186 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.881436
2    0.937619
3    0.962111
4    0.972508
5    0.981006
6    0.986104
7    0.990203
8    0.992802
9    0.994402
10   0.996001

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13360617128456773
RMSE: 0.3655217794941469
LogLoss: 0.4441029563325956
Mean Per-Class Error: 0.1191089221524761
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20    21    22    23     24     25    Error                Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
80.0  0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0   0.0   1.0   0.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   88.0  0.0   2.0    1.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    2.0   4.0    1.0   0.0   0.0   2.0   0.0   1.0    1.0    0.0   0.16981132075471697  18 / 106
0.0   0.0   71.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0   3.0   0.0    1.0   0.0    0.0   3.0   0.0   0.0   1.0   0.0    0.0    0.0   0.13414634146341464  11 / 82
1.0   1.0   0.0   103.0  0.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.08035714285714286  9 / 112
0.0   0.0   0.0   0.0    81.0  2.0   4.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    3.0   2.0   0.0   0.0   0.0   1.0    0.0    1.0   0.16494845360824742  16 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0   0.0   2.0    1.0   1.0   0.0   0.0   0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   91.0   0.0    0.0   0.09                 9 / 100
0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    2.0   0.0    0.0   0.0   0.0   4.0   1.0   0.0    97.0   0.0   0.09345794392523364  10 / 107
1.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    0.0    77.0  0.11494252873563218  10 / 87
88.0  98.0  78.0  124.0  95.0  99.0  87.0  76.0  87.0  105.0  95.0  95.0  99.0  98.0  80.0  111.0  99.0  114.0  97.0  91.0  99.0  85.0  99.0  100.0  109.0  82.0  0.11887550200803212  296 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.881124
2    0.935743
3    0.959438
4    0.971084
5    0.97992
6    0.984337
7    0.989157
8    0.991566
9    0.993574
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:23  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:25  1.702 sec   18531 obs/sec     1         1             10007      0.528797         0.919043            0.99503        0.255323                         0.530347           0.929147              0.994988         0.257831
    2019-07-24 15:35:27  4.367 sec   32073 obs/sec     10        10            100070     0.362364         0.430609            0.997666       0.118564                         0.365522           0.444103              0.997619         0.118876
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0847425
C13         0.958008               0.958008             0.081184
C8          0.872163               0.872163             0.0739093
C9          0.862357               0.862357             0.0730783
C12         0.82671                0.82671              0.0700575
C7          0.820221               0.820221             0.0695076
C5          0.758597               0.758597             0.0642854
C11         0.752445               0.752445             0.0637641
C10         0.727897               0.727897             0.0616838
C6          0.666187               0.666187             0.0564543
C16         0.651821               0.651821             0.055237
C14         0.629627               0.629627             0.0533562
C4          0.619014               0.619014             0.0524568
C3          0.606868               0.606868             0.0514275
C2          0.528807               0.528807             0.0448124
C1          0.519731               0.519731             0.0440433
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_70

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.001344376429329941  0.00036949978675693274  0.0         -0.011023216738440311  0.20314329862594604  0.24516799286249036  0.16280996799468994
    3        26       Softmax                      0.0   0.0   0.007268993926992642  0.02849964052438736     0.0         -0.25350014149849953   0.5194790363311768   -0.4964090628858134  0.14267784357070923


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13459796912687266
RMSE: 0.36687595877472357
LogLoss: 0.446773238343603
Mean Per-Class Error: 0.12888439917233138
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    1.0    5.0    0.0    3.0    0.0    0.0    3.0    1.0    3.0    1.0    1.0    1.0    1.0    5.0    2.0    0.08121827411167512  32 / 394
0.0    346.0  0.0    5.0    2.0    0.0    1.0    3.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   4.0    0.0    0.0    5.0    0.0    1.0    1.0    1.0    0.09660574412532637  37 / 383
0.0    0.0    306.0  0.0    13.0   0.0    10.0   0.0    0.0    0.0    12.0   3.0    0.0    0.0    5.0    0.0    1.0    1.0    3.0    5.0    7.0    0.0    1.0    0.0    0.0    0.0    0.16621253405994552  61 / 367
0.0    14.0   0.0    355.0  0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    7.0    4.0    2.0    0.0    0.0    10.0   2.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.11910669975186104  48 / 403
0.0    0.0    0.0    0.0    334.0  4.0    13.0   0.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    1.0    1.0    4.0    1.0    2.0    0.0    0.0    0.0    4.0    0.0    13.0   0.13020833333333334  50 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    354.0  0.0    0.0    0.0    0.056                21 / 375
0.0    0.0    0.0    4.0    2.0    0.0    0.0    0.0    2.0    1.0    4.0    4.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    1.0    1.0    0.0    0.0    366.0  3.0    2.0    0.07106598984771574  28 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    12.0   1.0    20.0   1.0    0.0    349.0  0.0    0.1096938775510204   43 / 392
2.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    7.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    0.0    10.0   2.0    0.0    0.0    0.0    0.0    0.0    335.0  0.08719346049046321  32 / 367
386.0  460.0  328.0  411.0  428.0  400.0  359.0  301.0  345.0  370.0  351.0  390.0  392.0  382.0  427.0  349.0  345.0  438.0  354.0  379.0  408.0  395.0  402.0  429.0  394.0  380.0  0.12836149155253423  1,284 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871639
2    0.936919
3    0.960012
4    0.971309
5    0.979906
6    0.984905
7    0.988304
8    0.991303
9    0.993502
10   0.995301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1367886650112015
RMSE: 0.36984951671078536
LogLoss: 0.4501992138741178
Mean Per-Class Error: 0.13159338428669834
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13    14    15    16    17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0    3.0    0.0   0.07865168539325842   7 / 89
0.0   87.0   0.0   0.0    1.0   0.0   1.0   2.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   7.0    1.0   0.0   0.0    4.0   0.0    1.0    0.0    1.0   0.1792452830188679    19 / 106
0.0   0.0    66.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    1.0   2.0   1.0    0.0   1.0    0.0    0.0    0.0   0.1951219512195122    16 / 82
0.0   2.0    0.0   99.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0   1.0    2.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0   0.11607142857142858   13 / 112
0.0   0.0    0.0   0.0    81.0  2.0   4.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   1.0   0.0    0.0   0.0    2.0    0.0    3.0   0.16494845360824742   16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0   90.0   0.0    0.0    0.0   0.021739130434782608  2 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0   0.0   0.0    2.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    90.0   1.0    1.0   0.1                   10 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0   0.0    8.0   1.0    0.0    95.0   0.0   0.11214953271028037   12 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0    0.0    79.0  0.09195402298850575   8 / 87
88.0  114.0  70.0  111.0  97.0  93.0  92.0  76.0  85.0  107.0  93.0  103.0  89.0  97.0  90.0  99.0  90.0  117.0  87.0  85.0  101.0  90.0  104.0  104.0  113.0  95.0  0.1321285140562249    329 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.867871
2    0.940161
3    0.960241
4    0.971486
5    0.980321
6    0.986747
7    0.98996
8    0.991566
9    0.994377
10   0.995582
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:20  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:21  1 min 57.390 sec  54683 obs/sec     1         1             10007      0.539668         0.952236            0.994822       0.254024                         0.539485           0.952372              0.994814         0.254217
    2019-07-24 15:37:22  1 min 59.008 sec  56472 obs/sec     10        10            100070     0.366876         0.446773            0.997607       0.128361                         0.36985            0.450199              0.997563         0.132129
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0864682
C13         0.897739               0.897739             0.0776259
C8          0.884809               0.884809             0.0765079
C9          0.813205               0.813205             0.0703164
C7          0.799221               0.799221             0.0691072
C12         0.783483               0.783483             0.0677463
C10         0.760738               0.760738             0.0657796
C11         0.723843               0.723843             0.0625895
C5          0.71365                0.71365              0.061708
C6          0.665124               0.665124             0.0575121
C14         0.62896                0.62896              0.054385
C3          0.614324               0.614324             0.0531195
C4          0.604803               0.604803             0.0522963
C1          0.589474               0.589474             0.0509708
C16         0.578154               0.578154             0.049992
C2          0.507415               0.507415             0.0438753
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_13

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0026286480785131516  0.0006991915870457888  0.0         -0.0004955726840751851  0.24613386392593384  0.011190967121114533  0.26757752895355225
    3        26       Softmax                 0.0   0.0   0.0036226082539682325  0.0014934120699763298  0.0         -0.0045002629154383775  0.3533778190612793   -0.6026779185977555   0.11370480060577393


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13339044331407962
RMSE: 0.3652265643598226
LogLoss: 0.43804797628955056
Mean Per-Class Error: 0.13289714154898324
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    4.0    3.0    4.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    2.0    1.0    1.0    2.0    3.0    0.08607594936708861  34 / 395
0.0    316.0  1.0    8.0    2.0    1.0    2.0    13.0   1.0    1.0    2.0    1.0    0.0    0.0    0.0    3.0    3.0    3.0    22.0   0.0    0.0    1.0    0.0    2.0    0.0    1.0    0.17493472584856398  67 / 383
0.0    0.0    312.0  1.0    3.0    1.0    13.0   2.0    0.0    0.0    12.0   8.0    0.0    0.0    4.0    0.0    2.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.15217391304347827  56 / 368
1.0    15.0   0.0    351.0  0.0    0.0    0.0    6.0    2.0    0.0    2.0    0.0    6.0    5.0    0.0    3.0    0.0    3.0    4.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.12686567164179105  51 / 402
0.0    1.0    5.0    0.0    321.0  6.0    15.0   1.0    0.0    0.0    3.0    7.0    0.0    0.0    0.0    1.0    5.0    1.0    6.0    6.0    0.0    0.0    0.0    2.0    0.0    4.0    0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    20.0   0.0    2.0    1.0    0.0    0.0    0.0    1.0    2.0    5.0    338.0  0.0    0.0    0.0    0.09866666666666667  37 / 375
0.0    1.0    0.0    4.0    4.0    1.0    0.0    2.0    2.0    3.0    15.0   3.0    0.0    0.0    0.0    0.0    6.0    0.0    5.0    3.0    1.0    0.0    0.0    340.0  1.0    2.0    0.13486005089058525  53 / 393
0.0    0.0    0.0    2.0    0.0    14.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    2.0    14.0   1.0    26.0   1.0    2.0    321.0  0.0    0.183206106870229    72 / 393
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    5.0    0.0    29.0   2.0    0.0    0.0    0.0    0.0    0.0    303.0  0.17438692098092642  64 / 367
378.0  388.0  330.0  420.0  375.0  433.0  380.0  361.0  353.0  380.0  398.0  392.0  454.0  376.0  384.0  374.0  403.0  341.0  512.0  390.0  388.0  394.0  357.0  383.0  337.0  322.0  0.13246026192142357  1,325 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86754
2    0.939118
3    0.964911
4    0.976607
5    0.983405
6    0.987304
7    0.990503
8    0.992702
9    0.994302
10   0.995701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13550670312809535
RMSE: 0.36811235123002234
LogLoss: 0.45094235488782747
Mean Per-Class Error: 0.13405465490078575
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5      6      7     8     9      10     11     12     13     14    15     16     17    18     19    20    21    22    23    24    25    Error                Rate
----  ----  ----  -----  ----  -----  -----  ----  ----  -----  -----  -----  -----  -----  ----  -----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  -------------------  -----------
83.0  0.0   0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0    0.0    0.0    2.0    0.0    0.0   0.0    0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.06741573033707865  6 / 89
0.0   81.0  0.0   4.0    2.0   0.0    2.0    5.0   0.0   0.0    0.0    0.0    0.0    0.0    0.0   1.0    0.0    2.0   7.0    0.0   0.0   1.0   0.0   1.0   0.0   0.0   0.2358490566037736   25 / 106
0.0   0.0   66.0  0.0    2.0   0.0    3.0    1.0   0.0   0.0    2.0    1.0    0.0    0.0    3.0   0.0    0.0    0.0   4.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.1951219512195122   16 / 82
1.0   1.0   0.0   95.0   0.0   0.0    0.0    3.0   1.0   0.0    1.0    0.0    2.0    2.0    0.0   3.0    0.0    0.0   1.0    0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.15178571428571427  17 / 112
0.0   0.0   1.0   0.0    77.0  4.0    5.0    0.0   0.0   0.0    1.0    2.0    0.0    0.0    0.0   0.0    1.0    0.0   3.0    1.0   0.0   0.0   0.0   1.0   0.0   1.0   0.20618556701030927  20 / 97
---   ---   ---   ---    ---   ---    ---    ---   ---   ---    ---    ---    ---    ---    ---   ---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0    0.0    0.0    5.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   3.0   83.0  0.0   0.0   0.0   0.09782608695652174  9 / 92
0.0   0.0   0.0   2.0    2.0   0.0    0.0    1.0   0.0   1.0    7.0    3.0    0.0    0.0    0.0   0.0    0.0    0.0   1.0    0.0   0.0   0.0   0.0   82.0  0.0   1.0   0.18                 18 / 100
0.0   0.0   0.0   0.0    0.0   3.0    0.0    0.0   0.0   0.0    0.0    0.0    0.0    0.0    0.0   1.0    3.0    0.0   0.0    4.0   0.0   9.0   1.0   0.0   86.0  0.0   0.19626168224299065  21 / 107
1.0   0.0   0.0   0.0    4.0   0.0    0.0    0.0   0.0   3.0    0.0    2.0    0.0    0.0    0.0   0.0    0.0    0.0   6.0    0.0   0.0   0.0   0.0   0.0   0.0   71.0  0.1839080459770115   16 / 87
89.0  94.0  68.0  113.0  90.0  102.0  100.0  93.0  85.0  112.0  100.0  104.0  105.0  100.0  82.0  109.0  103.0  87.0  121.0  93.0  99.0  92.0  86.0  91.0  96.0  76.0  0.13453815261044177  335 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.865462
2    0.941365
3    0.966265
4    0.976707
5    0.983534
6    0.987149
7    0.988353
8    0.990361
9    0.991165
10   0.994378
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:49  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:49  25.883 sec  21945 obs/sec     1         1             10007      0.521494         0.910755            0.995166       0.254624                         0.52198            0.914049              0.995145         0.263052
    2019-07-24 15:35:53  29.807 sec  23196 obs/sec     10        10            100070     0.365227         0.438048            0.997629       0.13246                          0.368112           0.450942              0.997585         0.134538
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0868612
C15         0.999952               0.999952             0.086857
C12         0.924385               0.924385             0.0802932
C9          0.922231               0.922231             0.0801061
C8          0.84901                0.84901              0.0737461
C10         0.754326               0.754326             0.0655217
C7          0.740459               0.740459             0.0643172
C11         0.715582               0.715582             0.0621563
C16         0.689397               0.689397             0.0598818
C5          0.655501               0.655501             0.0569376
C6          0.655463               0.655463             0.0569343
C14         0.635447               0.635447             0.0551957
C3          0.549505               0.549505             0.0477307
C4          0.526722               0.526722             0.0457517
C1          0.448373               0.448373             0.0389462
C2          0.446268               0.446268             0.0387634
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_27

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0014653765369700977  0.0003659093054011464  0.0         -0.008762706171978607  0.20471572875976562  0.23907940351065649   0.14538705348968506
    3        26       Softmax                      0.0   0.0   0.008241021573772182   0.03539085388183594    0.0         -0.26322113927403407   0.5087292194366455   -0.49664394330092876  0.1782926321029663


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1344903497180804
RMSE: 0.3667292594245521
LogLoss: 0.4485645482193134
Mean Per-Class Error: 0.13010462106015988
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    3.0    0.0    1.0    0.0    0.0    2.0    3.0    2.0    2.0    3.0    1.0    2.0    4.0    0.0    0.0759493670886076   30 / 395
0.0    354.0  0.0    4.0    2.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    9.0    5.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.07571801566579635  29 / 383
0.0    0.0    330.0  1.0    11.0   0.0    6.0    1.0    0.0    0.0    6.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    4.0    0.0    0.0    0.0    0.1008174386920981   37 / 367
2.0    24.0   0.0    346.0  0.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    5.0    6.0    0.0    3.0    0.0    7.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.141439205955335    57 / 403
0.0    4.0    0.0    0.0    335.0  2.0    12.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    1.0    6.0    4.0    6.0    3.0    0.0    0.0    0.0    3.0    0.0    5.0    0.12760416666666666  49 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    8.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    6.0    1.0    1.0    1.0    0.0    2.0    0.0    0.0    4.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    2.0    0.0    4.0    6.0    0.0    0.0    1.0    2.0    3.0    10.0   4.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.0    351.0  2.0    4.0    0.10913705583756345  43 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    1.0    19.0   2.0    7.0    1.0    0.0    352.0  0.0    0.10432569974554708  41 / 393
2.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    10.0   2.0    0.0    0.0    0.0    2.0    0.0    322.0  0.12021857923497267  44 / 366
390.0  499.0  361.0  413.0  436.0  349.0  387.0  325.0  338.0  373.0  346.0  366.0  388.0  387.0  381.0  439.0  347.0  433.0  356.0  405.0  409.0  348.0  405.0  400.0  376.0  346.0  0.12956113166050184  1,296 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.870439
2    0.936419
3    0.959612
4    0.971009
5    0.979606
6    0.985105
7    0.987904
8    0.990603
9    0.992302
10   0.994902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1351164870153838
RMSE: 0.36758194598671984
LogLoss: 0.45459146551001495
Mean Per-Class Error: 0.13034738919799302
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0    1.0   2.0    0.0   0.07865168539325842   7 / 89
0.0   92.0   0.0   1.0    1.0    0.0   1.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   5.0    1.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0   0.1320754716981132    14 / 106
0.0   0.0    75.0  0.0    1.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    0.0   2.0   0.0    0.0   1.0    0.0   0.0    0.0   0.08536585365853659   7 / 82
1.0   4.0    0.0   96.0   0.0    0.0   0.0    2.0   0.0   0.0    1.0   0.0   2.0   2.0    0.0   2.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.14285714285714285   16 / 112
0.0   0.0    0.0   0.0    83.0   1.0   4.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.14432989690721648   14 / 97
---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   1.0    0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    2.0    0.0   0.0    1.0   0.0   1.0    4.0   3.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    84.0  1.0    1.0   0.16                  16 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0   6.0   0.0    3.0   1.0    0.0   94.0   0.0   0.12149532710280374   13 / 107
2.0   0.0    0.0   0.0    5.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    77.0  0.11494252873563218   10 / 87
90.0  128.0  80.0  111.0  104.0  82.0  103.0  81.0  81.0  110.0  88.0  94.0  84.0  101.0  81.0  121.0  89.0  112.0  88.0  97.0  105.0  76.0  101.0  95.0  105.0  83.0  0.13012048192771083   324 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86988
2    0.937751
3    0.959036
4    0.970281
5    0.979116
6    0.983534
7    0.98514
8    0.98755
9    0.990361
10   0.993976
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:15  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:15  52.305 sec  54091 obs/sec     1         1             10007      0.536234         0.927317            0.994889       0.252924                         0.536716           0.926003              0.994867         0.260241
    2019-07-24 15:36:17  53.813 sec  60319 obs/sec     10        10            100070     0.366729         0.448565            0.997609       0.129561                         0.367582           0.454591              0.997592         0.13012
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0802148
C15         0.983652               0.983652             0.0789035
C8          0.95744                0.95744              0.0768009
C12         0.910667               0.910667             0.073049
C9          0.908935               0.908935             0.0729101
C7          0.870248               0.870248             0.0698068
C5          0.803978               0.803978             0.0644909
C11         0.788539               0.788539             0.0632525
C10         0.765658               0.765658             0.0614171
C6          0.701752               0.701752             0.0562909
C4          0.692472               0.692472             0.0555465
C14         0.659341               0.659341             0.0528889
C16         0.649554               0.649554             0.0521038
C3          0.630076               0.630076             0.0505414
C1          0.596661               0.596661             0.0478611
C2          0.547553               0.547553             0.0439219
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_33

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013662521130584082  0.00036514666862785816  0.0         -0.00620015912838312  0.20154565572738647  0.2546905564735068    0.15265560150146484
    3        26       Softmax                      0.0   0.0   0.008067963997990982   0.032784879207611084    0.0         -0.24642918529690844  0.5150918960571289   -0.48611366708767323  0.1450481414794922


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13585147469857814
RMSE: 0.36858035039673254
LogLoss: 0.4484275635455465
Mean Per-Class Error: 0.1288298090757571
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    3.0    2.0    2.0    0.0    1.0    0.0    0.0    2.0    6.0    1.0    1.0    3.0    2.0    1.0    3.0    0.0    0.07848101265822785  31 / 395
0.0    343.0  0.0    6.0    1.0    0.0    1.0    8.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    0.0    6.0    7.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.10209424083769633  39 / 382
0.0    0.0    317.0  0.0    13.0   0.0    4.0    1.0    0.0    0.0    10.0   2.0    0.0    0.0    5.0    0.0    0.0    1.0    5.0    1.0    4.0    0.0    4.0    0.0    0.0    0.0    0.1362397820163488   50 / 367
2.0    14.0   0.0    350.0  0.0    1.0    1.0    5.0    0.0    2.0    2.0    0.0    6.0    4.0    1.0    3.0    0.0    7.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.1315136476426799   53 / 403
0.0    5.0    2.0    0.0    331.0  3.0    14.0   1.0    1.0    0.0    3.0    4.0    0.0    0.0    0.0    1.0    3.0    4.0    3.0    3.0    0.0    0.0    0.0    1.0    0.0    5.0    0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    9.0    1.0    0.0    1.0    0.0    1.0    0.0    0.0    4.0    1.0    355.0  0.0    0.0    0.0    0.05585106382978723  21 / 376
0.0    0.0    0.0    4.0    10.0   1.0    0.0    2.0    3.0    4.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    355.0  1.0    2.0    0.09898477157360407  39 / 394
1.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    6.0    1.0    9.0    1.0    0.0    357.0  0.0    0.08928571428571429  35 / 392
0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    20.0   3.0    0.0    0.0    0.0    1.0    0.0    318.0  0.1335149863760218   49 / 367
388.0  443.0  359.0  416.0  405.0  393.0  350.0  351.0  345.0  376.0  391.0  359.0  413.0  365.0  393.0  397.0  357.0  397.0  406.0  386.0  396.0  378.0  412.0  398.0  387.0  342.0  0.12836149155253423  1,284 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871639
2    0.936919
3    0.960512
4    0.972708
5    0.979506
6    0.984905
7    0.989003
8    0.992602
9    0.995102
10   0.996301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13840187459292877
RMSE: 0.37202402421473907
LogLoss: 0.4572076181793416
Mean Per-Class Error: 0.13045363222598155
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17    18     19    20    21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0   0.0   1.0   0.0   0.0   2.0    0.0   0.06741573033707865   6 / 89
0.0   90.0   0.0   1.0    1.0   0.0   1.0   4.0   1.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   2.0    0.0   0.0   2.0   0.0   1.0   0.0    0.0   0.1509433962264151    16 / 106
0.0   0.0    68.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    3.0    1.0   0.0   0.0   2.0   0.0    0.0   0.0   3.0    1.0   0.0   0.0   1.0   0.0   0.0    0.0   0.17073170731707318   14 / 82
1.0   2.0    0.0   96.0   0.0   1.0   0.0   3.0   0.0   1.0    1.0    0.0   2.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0   2.0   0.0    0.0   0.14285714285714285   16 / 112
0.0   0.0    0.0   0.0    81.0  2.0   5.0   0.0   0.0   0.0    1.0    2.0   0.0   0.0   0.0   0.0    1.0   1.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0    1.0   0.16494845360824742   16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0   0.0   88.0  0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    3.0   1.0   0.0   1.0   0.0   1.0    4.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   88.0  0.0    0.0   0.12                  12 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0   0.0   1.0    1.0   0.0   0.0    1.0   0.0   2.0   1.0   0.0   99.0   0.0   0.07476635514018691   8 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0    1.0   0.0   0.0   0.0   1.0   0.0    73.0  0.16091954022988506   14 / 87
88.0  113.0  76.0  113.0  96.0  97.0  89.0  89.0  82.0  110.0  101.0  93.0  90.0  98.0  85.0  112.0  95.0  95.0  103.0  93.0  99.0  83.0  99.0  99.0  114.0  78.0  0.13012048192771083   324 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86988
2    0.939357
3    0.961044
4    0.972691
5    0.977108
6    0.983133
7    0.98755
8    0.991165
9    0.993173
10   0.994779
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:24  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:24  1 min  1.011 sec  56219 obs/sec     1         1             10007      0.536356         0.92555             0.994886       0.251525                         0.534605           0.925794              0.994907         0.248193
    2019-07-24 15:36:26  1 min  2.492 sec  61392 obs/sec     10        10            100070     0.36858          0.448428            0.997585       0.128361                         0.372024           0.457208              0.997534         0.13012
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0846299
C15         0.964179               0.964179             0.0815984
C8          0.888777               0.888777             0.0752171
C9          0.868979               0.868979             0.0735416
C12         0.834067               0.834067             0.070587
C7          0.764038               0.764038             0.0646605
C11         0.74013                0.74013              0.0626371
C10         0.726851               0.726851             0.0615134
C5          0.719117               0.719117             0.0608588
C14         0.699528               0.699528             0.059201
C6          0.682618               0.682618             0.0577699
C16         0.630931               0.630931             0.0533956
C3          0.628648               0.628648             0.0532024
C4          0.615433               0.615433             0.0520841
C1          0.5365                 0.5365               0.045404
C2          0.516356               0.516356             0.0436992
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_29

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.001331350641123663  0.0003609590930864215  0.0         -0.01141582563400867  0.20311999320983887  0.25210709501361045  0.14332365989685059
    3        26       Softmax                      0.0   0.0   0.007543229562490803  0.036490947008132935   0.0         -0.24381787711530917  0.514448881149292    -0.4874252326278744  0.14936870336532593


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13565815841987638
RMSE: 0.3683180126193618
LogLoss: 0.4476207633449984
Mean Per-Class Error: 0.1293165608943688
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    2.0    2.0    7.0    1.0    0.0    0.0    0.0    2.0    2.0    1.0    2.0    1.0    1.0    1.0    3.0    0.0    0.0759493670886076   30 / 395
0.0    326.0  1.0    5.0    2.0    4.0    2.0    4.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    4.0    16.0   7.0    0.0    0.0    3.0    0.0    2.0    2.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    318.0  1.0    8.0    0.0    7.0    1.0    0.0    0.0    8.0    2.0    0.0    0.0    5.0    0.0    1.0    1.0    5.0    2.0    5.0    0.0    4.0    0.0    0.0    0.0    0.1358695652173913   50 / 368
0.0    6.0    0.0    362.0  0.0    0.0    0.0    4.0    0.0    1.0    0.0    1.0    7.0    2.0    2.0    0.0    0.0    10.0   1.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    0.10173697270471464  41 / 403
0.0    6.0    0.0    1.0    324.0  3.0    12.0   1.0    0.0    0.0    7.0    7.0    0.0    0.0    0.0    0.0    7.0    2.0    3.0    0.0    0.0    0.0    0.0    1.0    1.0    9.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    12.0   1.0    1.0    0.0    0.0    2.0    0.0    0.0    4.0    4.0    348.0  0.0    0.0    0.0    0.072                27 / 375
0.0    1.0    0.0    5.0    6.0    0.0    0.0    0.0    2.0    0.0    14.0   3.0    0.0    0.0    2.0    0.0    0.0    0.0    5.0    2.0    1.0    0.0    0.0    346.0  1.0    5.0    0.11959287531806616  47 / 393
0.0    0.0    0.0    2.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    0.0    1.0    7.0    1.0    15.0   1.0    0.0    349.0  0.0    0.11195928753180662  44 / 393
3.0    1.0    0.0    0.0    21.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    13.0   1.0    0.0    0.0    0.0    0.0    0.0    315.0  0.14168937329700274  52 / 367
391.0  430.0  338.0  422.0  399.0  419.0  357.0  314.0  335.0  366.0  407.0  376.0  423.0  379.0  407.0  372.0  367.0  434.0  394.0  368.0  399.0  393.0  390.0  389.0  379.0  355.0  0.12876137158852344  1,288 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871239
2    0.93362
3    0.960112
4    0.972308
5    0.981706
6    0.986304
7    0.990403
8    0.992702
9    0.994902
10   0.996301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13750331397466103
RMSE: 0.37081439289037993
LogLoss: 0.45799163527356973
Mean Per-Class Error: 0.1289166116565198
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   1.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   0.0    2.0   0.0   1.0   1.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   1.0    2.0   5.0    3.0    0.0   0.0    3.0   0.0   1.0   1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    66.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0    1.0   2.0    0.0   1.0   0.0   0.0    0.0   0.1951219512195122   16 / 82
0.0   2.0    0.0   100.0  0.0   0.0   0.0   2.0   0.0   0.0    0.0    1.0   3.0   1.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   2.0   0.0    1.0   0.10714285714285714  12 / 112
0.0   1.0    0.0   0.0    81.0  1.0   3.0   0.0   0.0   0.0    1.0    1.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0    0.0   0.0    0.0   0.0   1.0   0.0    3.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   2.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   0.0   0.0   0.0    5.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   85.0  0.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    1.0   0.0    4.0   1.0   0.0   96.0   0.0   0.102803738317757    11 / 107
2.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   2.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0   0.0    74.0  0.14942528735632185  13 / 87
87.0  114.0  70.0  115.0  97.0  99.0  93.0  78.0  78.0  108.0  100.0  97.0  98.0  101.0  84.0  103.0  99.0  108.0  100.0  85.0  100.0  90.0  95.0  99.0  106.0  86.0  0.12891566265060242  321 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871084
2    0.935743
3    0.960241
4    0.970281
5    0.980321
6    0.983534
7    0.989558
8    0.991968
9    0.993976
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:19  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:19  55.605 sec  54683 obs/sec     1         1             10007      0.527193         0.916044            0.995061       0.240228                         0.528351           0.917368              0.995026         0.237751
    2019-07-24 15:36:20  57.138 sec  59886 obs/sec     10        10            100070     0.368318         0.447621            0.997589       0.128761                         0.370814           0.457992              0.99755          0.128916
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0886672
C13         0.89471                0.89471              0.0793314
C9          0.839582               0.839582             0.0744434
C8          0.818604               0.818604             0.0725833
C7          0.795141               0.795141             0.0705029
C12         0.750241               0.750241             0.0665218
C10         0.730148               0.730148             0.0647402
C5          0.710121               0.710121             0.0629644
C11         0.679641               0.679641             0.0602618
C6          0.655715               0.655715             0.0581404
C14         0.648092               0.648092             0.0574645
C16         0.599196               0.599196             0.053129
C4          0.581096               0.581096             0.0515241
C3          0.538843               0.538843             0.0477777
C2          0.528331               0.528331             0.0468456
C1          0.508668               0.508668             0.0451022
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_25

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0021687968911692224  0.0006136558949947357  0.0         -0.0006325918736891367  0.3412036895751953   0.04548210346704472  0.38002467155456543
    3        26       Softmax                 0.0   0.0   0.0031565556775533946  0.0011928067542612553  0.0         -0.013443031109781546   0.44213175773620605  -0.5444825856826759  0.186659038066864


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13794131107319413
RMSE: 0.37140451137970054
LogLoss: 0.4615059365237366
Mean Per-Class Error: 0.13461938136883228
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    2.0    1.0    6.0    0.0    0.0    0.0    0.0    2.0    4.0    1.0    2.0    1.0    1.0    2.0    4.0    2.0    0.09113924050632911  36 / 395
0.0    331.0  0.0    9.0    4.0    0.0    1.0    9.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    2.0    0.0    10.0   4.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    0.13577023498694518  52 / 383
0.0    0.0    319.0  1.0    6.0    1.0    4.0    0.0    0.0    0.0    18.0   1.0    1.0    0.0    3.0    0.0    2.0    1.0    5.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.1307901907356948   48 / 367
0.0    8.0    0.0    355.0  0.0    1.0    0.0    7.0    1.0    5.0    0.0    0.0    7.0    2.0    1.0    0.0    0.0    7.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    3.0    0.11910669975186104  48 / 403
0.0    0.0    0.0    0.0    329.0  5.0    9.0    1.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    11.0   2.0    9.0    1.0    1.0    0.0    0.0    4.0    0.0    4.0    0.14322916666666666  55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    11.0   0.0    0.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    0.0    0.0    4.0    6.0    1.0    0.0    2.0    6.0    4.0    11.0   2.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    2.0    1.0    0.0    0.0    343.0  2.0    4.0    0.12944162436548223  51 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    9.0    1.0    27.0   1.0    1.0    340.0  0.0    0.13486005089058525  53 / 393
0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    20.0   3.0    0.0    0.0    0.0    0.0    0.0    323.0  0.11989100817438691  44 / 367
382.0  426.0  341.0  427.0  399.0  418.0  337.0  332.0  352.0  375.0  419.0  365.0  412.0  370.0  379.0  373.0  369.0  415.0  391.0  382.0  415.0  390.0  394.0  412.0  367.0  361.0  0.13405978206538038  1,341 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86594
2    0.93162
3    0.957613
4    0.969209
5    0.977507
6    0.983005
7    0.986904
8    0.989403
9    0.992202
10   0.993702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14042232653156922
RMSE: 0.3747296712719307
LogLoss: 0.4666247039105046
Mean Per-Class Error: 0.13220786876719495
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   86.0   0.0   5.0    3.0   0.0   1.0   2.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   0.0    0.0   4.0    1.0   0.0   0.0    0.0   1.0   1.0   0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    70.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.14634146341463414  12 / 82
0.0   1.0    0.0   97.0   0.0   0.0   0.0   3.0   1.0   3.0    0.0    0.0   3.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    78.0  3.0   2.0   0.0   1.0   0.0    3.0    0.0   0.0   0.0    0.0   0.0    4.0   0.0    4.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    5.0    2.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   84.0  0.0    2.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   3.0   0.0    8.0   1.0   0.0   92.0   0.0   0.14018691588785046  15 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0   0.0   0.0    80.0  0.08045977011494253  7 / 87
87.0  110.0  71.0  119.0  95.0  96.0  83.0  85.0  85.0  105.0  106.0  97.0  90.0  100.0  81.0  103.0  97.0  105.0  99.0  93.0  106.0  88.0  97.0  97.0  105.0  90.0  0.13333333333333333  332 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.866667
2    0.93494
3    0.961847
4    0.969478
5    0.978313
6    0.98514
7    0.98755
8    0.990763
9    0.991566
10   0.993173
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:10  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:10  47.000 sec  42948 obs/sec     1         1             10007      0.537047         0.949405            0.994875       0.257623                         0.536291           0.940769              0.994875         0.262651
    2019-07-24 15:36:12  49.191 sec  41940 obs/sec     10        10            100070     0.371405         0.461506            0.997549       0.13406                          0.37473            0.466625              0.997498         0.133333
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0919565
C13         0.925998               0.925998             0.0851515
C9          0.844731               0.844731             0.0776785
C8          0.837891               0.837891             0.0770496
C12         0.797931               0.797931             0.0733749
C7          0.73665                0.73665              0.0677398
C10         0.734648               0.734648             0.0675556
C11         0.679648               0.679648             0.0624981
C16         0.6535                 0.6535               0.0600936
C14         0.628012               0.628012             0.0577498
C6          0.588609               0.588609             0.0541264
C5          0.588411               0.588411             0.0541082
C2          0.479708               0.479708             0.0441123
C3          0.472712               0.472712             0.043469
C4          0.469551               0.469551             0.0431783
C1          0.436706               0.436706             0.0401579
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_24

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.001975646879984083  0.0005742434877902269  0.0         0.014973075964071825   0.3357166051864624  0.002987631885565851  0.37651383876800537
    3        26       Softmax                 0.0   0.0   0.003100814684960194  0.001444770023226738   0.0         0.0002987816795977457  0.448980450630188   -0.5373943600678973   0.17736470699310303


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1395318599499931
RMSE: 0.37353963638413673
LogLoss: 0.4690975943270559
Mean Per-Class Error: 0.13304540611894555
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    3.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    1.0    3.0    3.0    3.0    0.0    0.0    1.0    3.0    3.0    0.0810126582278481   32 / 395
0.0    331.0  0.0    5.0    5.0    2.0    1.0    8.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    9.0    7.0    0.0    0.0    4.0    0.0    3.0    2.0    0.0    0.13350785340314136  51 / 382
0.0    0.0    324.0  1.0    12.0   1.0    6.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    7.0    0.0    0.0    1.0    3.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.11956521739130435  44 / 368
1.0    13.0   0.0    350.0  0.0    1.0    0.0    5.0    1.0    2.0    0.0    0.0    4.0    3.0    6.0    0.0    0.0    7.0    4.0    0.0    2.0    0.0    0.0    4.0    0.0    0.0    0.1315136476426799   53 / 403
0.0    1.0    3.0    0.0    342.0  3.0    11.0   0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    1.0    4.0    4.0    1.0    1.0    1.0    0.0    0.0    2.0    0.0    5.0    0.109375             42 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    2.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    8.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    0.0    0.0    4.0    8.0    1.0    0.0    2.0    5.0    2.0    3.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    3.0    1.0    0.0    0.0    352.0  4.0    4.0    0.1065989847715736   42 / 394
0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    3.0    3.0    8.0    1.0    1.0    364.0  0.0    0.0737913486005089   29 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    13.0   2.0    0.0    0.0    0.0    0.0    0.0    324.0  0.11716621253405994  43 / 367
384.0  470.0  360.0  418.0  443.0  390.0  350.0  304.0  346.0  365.0  323.0  360.0  401.0  367.0  427.0  363.0  383.0  422.0  355.0  381.0  411.0  350.0  412.0  417.0  424.0  377.0  0.13236029191242626  1,324 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86764
2    0.929621
3    0.955513
4    0.96821
5    0.977807
6    0.983505
7    0.986804
8    0.990003
9    0.991802
10   0.993402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1432627011120905
RMSE: 0.3785005959203902
LogLoss: 0.480978253043427
Mean Per-Class Error: 0.13497815993194814
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0898876404494382    8 / 89
0.0   86.0   0.0   2.0    3.0    0.0   1.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    0.0   4.0    2.0   0.0   0.0    3.0   0.0    1.0    0.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    71.0  0.0    2.0    1.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    2.0   0.0   1.0    0.0   0.0    0.0    0.0    0.0   0.13414634146341464   11 / 82
1.0   1.0    0.0   94.0   0.0    1.0   0.0   2.0   1.0   1.0    0.0   0.0   2.0   1.0   1.0   0.0    0.0   1.0    3.0   0.0   1.0    0.0   0.0    2.0    0.0    0.0   0.16071428571428573   18 / 112
0.0   0.0    1.0   0.0    85.0   1.0   3.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0   1.0   0.0    0.0   0.0    1.0    0.0    1.0   0.12371134020618557   12 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    1.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   1.0    4.0    0.0   0.0   1.0   0.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    89.0   0.0    2.0   0.11                  11 / 100
0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   0.0    1.0   1.0    0.0    101.0  0.0   0.056074766355140186  6 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0    0.0    0.0    76.0  0.12643678160919541   11 / 87
86.0  113.0  78.0  112.0  107.0  90.0  89.0  82.0  87.0  108.0  79.0  95.0  90.0  96.0  91.0  101.0  97.0  104.0  97.0  88.0  101.0  77.0  107.0  107.0  120.0  88.0  0.13493975903614458   336 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86506
2    0.928916
3    0.95502
4    0.968273
5    0.980321
6    0.985944
7    0.987952
8    0.990763
9    0.99237
10   0.993976
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:07  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:08  44.451 sec  42948 obs/sec     1         1             10007      0.534724         0.952596            0.994918       0.252124                         0.536454           0.959385              0.994872         0.259839
    2019-07-24 15:36:10  46.719 sec  40579 obs/sec     10        10            100070     0.37354          0.469098            0.99752        0.13236                          0.378501           0.480978              0.997447         0.13494
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0921415
C13         0.987596               0.987596             0.0909986
C9          0.865334               0.865334             0.0797331
C12         0.792783               0.792783             0.0730482
C8          0.77198                0.77198              0.0711314
C7          0.723509               0.723509             0.0666652
C10         0.719778               0.719778             0.0663214
C11         0.679227               0.679227             0.062585
C16         0.651229               0.651229             0.0600052
C5          0.59649                0.59649              0.0549615
C6          0.590558               0.590558             0.0544149
C14         0.583438               0.583438             0.0537589
C3          0.555177               0.555177             0.0511549
C4          0.487261               0.487261             0.0448969
C2          0.441077               0.441077             0.0406415
C1          0.407436               0.407436             0.0375417
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_51

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0023728926777835113  0.0006155737210065126  0.0         -0.002436654179422626  0.3118189573287964   -0.046799407551288384  0.3909482955932617
    3        26       Softmax                 0.0   0.0   0.002831533033748621   0.0013158158399164677  0.0         0.0024202695245820064  0.31116414070129395  -0.5729722338156086    0.15259528160095215


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14222063310384636
RMSE: 0.3771215097337281
LogLoss: 0.481486092485417
Mean Per-Class Error: 0.14599350644208287
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    7.0    2.0    1.0    10.0   0.0    0.0    0.0    0.0    1.0    3.0    0.0    1.0    0.0    1.0    1.0    5.0    3.0    0.09620253164556962  38 / 395
0.0    322.0  0.0    9.0    3.0    0.0    1.0    10.0   2.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    16.0   12.0   0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.15926892950391644  61 / 383
0.0    0.0    314.0  1.0    2.0    0.0    5.0    2.0    0.0    0.0    25.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    8.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.14673913043478262  54 / 368
1.0    14.0   0.0    347.0  0.0    1.0    0.0    9.0    2.0    3.0    0.0    0.0    7.0    4.0    1.0    2.0    0.0    7.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    2.0    0.13681592039800994  55 / 402
0.0    5.0    2.0    0.0    310.0  8.0    14.0   0.0    0.0    0.0    10.0   1.0    0.0    0.0    0.0    0.0    8.0    4.0    11.0   5.0    0.0    0.0    0.0    1.0    0.0    4.0    0.1906005221932115   73 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    1.0    0.0    21.0   0.0    5.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    337.0  0.0    0.0    0.0    0.10133333333333333  38 / 375
0.0    1.0    0.0    3.0    4.0    0.0    0.0    2.0    3.0    4.0    16.0   1.0    0.0    0.0    2.0    0.0    4.0    2.0    2.0    2.0    1.0    0.0    0.0    339.0  5.0    3.0    0.13959390862944163  55 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    6.0    0.0    2.0    11.0   1.0    10.0   1.0    1.0    347.0  1.0    0.11704834605597965  46 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    33.0   3.0    0.0    0.0    0.0    0.0    0.0    305.0  0.16893732970027248  62 / 367
384.0  418.0  353.0  416.0  363.0  391.0  320.0  337.0  344.0  376.0  434.0  363.0  463.0  375.0  380.0  417.0  389.0  408.0  447.0  385.0  402.0  362.0  372.0  389.0  377.0  338.0  0.14525642307307807  1,453 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.854744
2    0.927922
3    0.953614
4    0.964611
5    0.976107
6    0.983005
7    0.986504
8    0.988803
9    0.991603
10   0.993702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14527545816527074
RMSE: 0.3811501779683052
LogLoss: 0.4928387874791506
Mean Per-Class Error: 0.14736162549396611
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   0.0   3.0    0.0   0.10112359550561797  9 / 89
0.0   84.0   0.0   3.0    2.0   0.0   1.0   4.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   7.0    2.0    0.0   0.0    0.0   1.0   1.0   1.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    69.0  0.0    0.0   0.0   1.0   1.0   0.0   0.0    5.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0    3.0    0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.15853658536585366  13 / 82
1.0   1.0    0.0   96.0   0.0   0.0   0.0   3.0   1.0   1.0    0.0    0.0   3.0    1.0   0.0   2.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    74.0  5.0   5.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0   0.0   0.0    2.0   1.0    3.0    3.0   0.0    0.0   0.0   0.0   0.0    1.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   4.0    0.0   1.0   0.0    0.0   0.0    0.0    0.0   0.0    1.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    6.0    1.0   0.0    0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   0.0   83.0  1.0    1.0   0.17                 17 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   2.0    2.0   0.0    0.0    3.0   0.0    4.0   1.0   0.0   95.0   0.0   0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   3.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    5.0    0.0   0.0    0.0   0.0   0.0   0.0    73.0  0.16091954022988506  14 / 87
89.0  102.0  74.0  114.0  86.0  94.0  79.0  85.0  82.0  111.0  110.0  96.0  104.0  99.0  85.0  120.0  98.0  107.0  107.0  92.0  100.0  81.0  93.0  92.0  109.0  81.0  0.14698795180722893  366 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853012
2    0.925301
3    0.953414
4    0.965863
5    0.976707
6    0.983133
7    0.98755
8    0.98996
9    0.991566
10   0.993574
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:53  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:54  1 min 30.582 sec  25857 obs/sec     1         1             10007      0.521869         0.920088            0.99516        0.254424                         0.522478           0.922089              0.995136         0.258635
    2019-07-24 15:36:57  1 min 34.210 sec  25321 obs/sec     10        10            100070     0.377122         0.481486            0.997472       0.145256                         0.38115            0.492839              0.997411         0.146988
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0837135
C15         0.983577               0.983577             0.0823387
C12         0.894819               0.894819             0.0749084
C9          0.88781                0.88781              0.0743217
C8          0.874803               0.874803             0.0732328
C7          0.797351               0.797351             0.066749
C10         0.790171               0.790171             0.066148
C11         0.775536               0.775536             0.0649229
C5          0.709582               0.709582             0.0594016
C14         0.703903               0.703903             0.0589262
C16         0.691093               0.691093             0.0578538
C6          0.642435               0.642435             0.0537805
C3          0.624444               0.624444             0.0522744
C4          0.57369                0.57369              0.0480256
C1          0.501351               0.501351             0.0419698
C2          0.494938               0.494938             0.041433
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_45

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0023581204639242515  0.0006742810364812613  0.0         0.0015474699458941643  0.3033318519592285   0.01590382832901812  0.37252235412597656
    3        26       Softmax                 0.0   0.0   0.002899863012159515   0.0011307294480502605  0.0         0.00813652728135959    0.31374895572662354  -0.5629998500155101  0.1445198655128479


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1433510201478117
RMSE: 0.3786172475572286
LogLoss: 0.4910436718334913
Mean Per-Class Error: 0.14430826847278586
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    6.0    1.0    4.0    1.0    0.0    0.0    0.0    1.0    3.0    2.0    1.0    0.0    1.0    1.0    3.0    3.0    0.08607594936708861  34 / 395
0.0    334.0  1.0    11.0   2.0    0.0    1.0    10.0   1.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    2.0    6.0    8.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.1256544502617801   48 / 382
0.0    0.0    319.0  1.0    6.0    0.0    2.0    1.0    0.0    0.0    19.0   0.0    0.0    0.0    2.0    0.0    2.0    0.0    7.0    2.0    5.0    0.0    2.0    0.0    0.0    0.0    0.1331521739130435   49 / 368
1.0    8.0    0.0    360.0  0.0    0.0    0.0    3.0    0.0    5.0    1.0    0.0    7.0    4.0    1.0    2.0    0.0    5.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    0.10669975186104218  43 / 403
0.0    6.0    3.0    0.0    324.0  4.0    11.0   1.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    2.0    7.0    3.0    6.0    2.0    1.0    0.0    0.0    4.0    0.0    6.0    0.15625              60 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    21.0   0.0    5.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    0.0    0.0    11.0   4.0    0.0    0.0    2.0    2.0    3.0    16.0   2.0    0.0    0.0    2.0    1.0    5.0    0.0    4.0    1.0    1.0    0.0    0.0    333.0  4.0    3.0    0.1548223350253807   61 / 394
0.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    8.0    0.0    1.0    13.0   1.0    14.0   1.0    1.0    346.0  0.0    0.11959287531806616  47 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    24.0   2.0    0.0    0.0    0.0    0.0    0.0    305.0  0.16893732970027248  62 / 367
382.0  439.0  363.0  463.0  402.0  344.0  314.0  333.0  338.0  385.0  400.0  355.0  455.0  369.0  392.0  416.0  398.0  407.0  426.0  379.0  409.0  371.0  369.0  379.0  375.0  340.0  0.14355693292012398  1,436 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.856443
2    0.923423
3    0.952914
4    0.96631
5    0.974008
6    0.981106
7    0.985604
8    0.988104
9    0.991003
10   0.993402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1478750773546927
RMSE: 0.38454528648091985
LogLoss: 0.5036677617546912
Mean Per-Class Error: 0.15179144500751734
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10     11    12     13     14    15     16    17    18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   2.0   0.0   0.0    0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   89.0   0.0   3.0    2.0    0.0   1.0   3.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   4.0   1.0    0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.16037735849056603  17 / 106
0.0   0.0    70.0  0.0    2.0    0.0   0.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0    2.0   0.0    0.0   0.0   3.0    1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.14634146341463414  12 / 82
1.0   1.0    0.0   98.0   0.0    0.0   0.0   1.0   0.0   1.0    1.0    0.0   3.0    1.0    0.0   2.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.125                14 / 112
0.0   0.0    0.0   0.0    79.0   3.0   4.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0    0.0   0.0    2.0   1.0   2.0    1.0   0.0    0.0   0.0   1.0   0.0    3.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   6.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   5.0    2.0    0.0   0.0   1.0   0.0   0.0    7.0    2.0   0.0    0.0    0.0   0.0    1.0   0.0   1.0    0.0   0.0    0.0   0.0   78.0  1.0    2.0   0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   2.0    3.0   0.0   0.0    4.0   0.0    4.0   1.0   0.0   93.0   0.0   0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0    0.0    0.0   0.0    0.0   0.0   3.0    0.0   0.0    0.0   0.0   0.0   0.0    75.0  0.13793103448275862  12 / 87
88.0  110.0  77.0  132.0  100.0  82.0  82.0  86.0  80.0  107.0  100.0  93.0  106.0  100.0  81.0  115.0  99.0  99.0  103.0  91.0  101.0  86.0  90.0  88.0  108.0  86.0  0.15100401606425704  376 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.848996
2    0.924096
3    0.953012
4    0.969076
5    0.977108
6    0.983133
7    0.986345
8    0.988755
9    0.990763
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:40  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:40  1 min 17.084 sec  23545 obs/sec     1         1             10007      0.521274         0.91826             0.995171       0.249125                         0.521836           0.919204              0.995148         0.254618
    2019-07-24 15:36:44  1 min 20.877 sec  24084 obs/sec     10        10            100070     0.378617         0.491044            0.997452       0.143557                         0.384545           0.503668              0.997365         0.151004
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0882865
C13         0.992442               0.992442             0.0876192
C9          0.870771               0.870771             0.0768773
C8          0.835082               0.835082             0.0737264
C12         0.828851               0.828851             0.0731763
C11         0.740605               0.740605             0.0653854
C10         0.720962               0.720962             0.0636512
C7          0.705324               0.705324             0.0622705
C14         0.661453               0.661453             0.0583973
C5          0.644357               0.644357             0.056888
C16         0.631061               0.631061             0.0557141
C6          0.610212               0.610212             0.0538734
C3          0.584599               0.584599             0.0516122
C4          0.571307               0.571307             0.0504387
C2          0.467122               0.467122             0.0412406
C1          0.462617               0.462617             0.0408428
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_28

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0012954885197018484  0.0003604833036661148  0.0         -0.013884444147169717  0.20247340202331543  0.13197031654270544  0.1315147876739502
    3        26       Softmax                      0.0   0.0   0.009495496551415692   0.04377298057079315    0.0         -0.26176812356153023   0.5272078514099121   -0.6515068400487015  0.2641277313232422


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16250448345899612
RMSE: 0.40311844842303624
LogLoss: 0.5234852798420095
Mean Per-Class Error: 0.1507202142327859
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    4.0    0.0    2.0    0.0    0.0    1.0    8.0    1.0    4.0    0.0    1.0    0.0    4.0    0.0    0.07341772151898734  29 / 395
0.0    344.0  0.0    5.0    2.0    3.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    5.0    3.0    7.0    8.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.10182767624020887  39 / 383
0.0    0.0    311.0  0.0    16.0   0.0    5.0    0.0    0.0    0.0    14.0   1.0    1.0    0.0    5.0    0.0    0.0    0.0    4.0    2.0    5.0    0.0    4.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
2.0    10.0   0.0    361.0  0.0    2.0    0.0    3.0    0.0    4.0    2.0    0.0    7.0    2.0    1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    0.10421836228287841  42 / 403
0.0    10.0   1.0    0.0    326.0  3.0    10.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    8.0    5.0    4.0    2.0    0.0    0.0    0.0    2.0    0.0    11.0   0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    14.0   0.0    1.0    0.0    0.0    3.0    0.0    0.0    4.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    1.0    0.0    4.0    9.0    0.0    0.0    2.0    2.0    3.0    7.0    0.0    0.0    0.0    2.0    0.0    3.0    2.0    1.0    2.0    1.0    0.0    0.0    347.0  2.0    6.0    0.11928934010152284  47 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    0.0    2.0    12.0   1.0    8.0    1.0    0.0    361.0  0.0    0.08142493638676845  32 / 393
0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    26.0   3.0    0.0    0.0    0.0    1.0    0.0    316.0  0.13896457765667575  51 / 367
400.0  490.0  351.0  452.0  418.0  355.0  331.0  286.0  337.0  363.0  376.0  362.0  409.0  390.0  409.0  407.0  369.0  402.0  359.0  384.0  418.0  354.0  401.0  400.0  404.0  376.0  0.1497550734779566   1,498 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850245
2    0.921124
3    0.949315
4    0.962411
5    0.972208
6    0.978606
7    0.983105
8    0.987704
9    0.990903
10   0.993802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1641560865937875
RMSE: 0.4051618029797324
LogLoss: 0.5266093473098682
Mean Per-Class Error: 0.15489715351254846
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17    18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   1.0    0.0   1.0    0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   88.0   0.0   0.0    1.0   3.0   0.0   0.0   1.0   0.0    1.0   0.0   0.0   0.0    1.0   2.0    1.0   3.0   3.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    67.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0   2.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0   0.18292682926829268   15 / 82
2.0   1.0    0.0   99.0   0.0   1.0   0.0   1.0   0.0   1.0    1.0   0.0   3.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.11607142857142858   13 / 112
0.0   2.0    0.0   0.0    75.0  2.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0   3.0   1.0   0.0    0.0   0.0    2.0   0.0    5.0   0.2268041237113402    22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   3.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   1.0    0.0   86.0   0.0   0.0    0.0   0.06521739130434782   6 / 92
0.0   0.0    0.0   2.0    4.0   0.0   0.0   1.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    85.0  1.0    2.0   0.15                  15 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    2.0   0.0   0.0   2.0   0.0    2.0   1.0    0.0   99.0   0.0   0.07476635514018691   8 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   5.0   1.0   0.0    0.0   0.0    0.0   0.0    76.0  0.12643678160919541   11 / 87
93.0  122.0  74.0  121.0  93.0  83.0  81.0  74.0  78.0  107.0  96.0  94.0  89.0  104.0  85.0  116.0  96.0  99.0  95.0  92.0  105.0  80.0  100.0  96.0  119.0  98.0  0.1534136546184739    382 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.846586
2    0.925703
3    0.95261
4    0.963855
5    0.973092
6    0.97992
7    0.983534
8    0.986345
9    0.98996
10   0.993976
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:17  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:17  54.028 sec  58864 obs/sec     1         1             10007      0.572211         1.03132             0.994182       0.273118                         0.574333           1.03804               0.994122         0.276305
    2019-07-24 15:36:19  55.380 sec  67116 obs/sec     10        10            100070     0.403118         0.523485            0.997112       0.149755                         0.405162           0.526609              0.997075         0.153414
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0879581
C13         0.963035               0.963035             0.0847068
C9          0.867649               0.867649             0.0763168
C8          0.825231               0.825231             0.0725858
C7          0.807182               0.807182             0.0709982
C12         0.785377               0.785377             0.0690803
C11         0.719983               0.719983             0.0633283
C5          0.713341               0.713341             0.0627442
C10         0.690004               0.690004             0.0606914
C6          0.663821               0.663821             0.0583884
C3          0.61837                0.61837              0.0543907
C14         0.614669               0.614669             0.0540651
C4          0.589663               0.589663             0.0518657
C16         0.564137               0.564137             0.0496204
C1          0.477203               0.477203             0.0419739
C2          0.469381               0.469381             0.0412859
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_11

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013402904014583328  0.00035678118001669645  0.0         -0.007565197478530905  0.20024186372756958  0.14881594786745042  0.14951711893081665
    3        26       Softmax                      0.0   0.0   0.008932072614260714   0.028896436095237732    0.0         -0.23052107038217157   0.5199182033538818   -0.6106189452298231  0.2702988386154175


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1628543833642888
RMSE: 0.40355220649166174
LogLoss: 0.5280930529458163
Mean Per-Class Error: 0.15097471589602526
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    5.0    7.0    1.0    2.0    0.0    1.0    0.0    1.0    1.0    6.0    0.0    3.0    2.0    2.0    2.0    3.0    0.0    0.09367088607594937  37 / 395
0.0    346.0  0.0    3.0    3.0    0.0    1.0    6.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    10.0   4.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.09660574412532637  37 / 383
0.0    0.0    312.0  0.0    12.0   0.0    8.0    1.0    0.0    0.0    18.0   0.0    0.0    0.0    3.0    0.0    2.0    0.0    2.0    4.0    1.0    0.0    4.0    0.0    0.0    0.0    0.14986376021798364  55 / 367
1.0    22.0   0.0    351.0  0.0    1.0    0.0    4.0    0.0    1.0    1.0    0.0    6.0    5.0    1.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    5.0    0.0    0.0    0.12903225806451613  52 / 403
0.0    12.0   1.0    0.0    318.0  2.0    12.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    8.0    4.0    5.0    4.0    0.0    0.0    0.0    5.0    0.0    10.0   0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    6.0    1.0    1.0    0.0    0.0    10.0   0.0    0.0    5.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    2.0    0.0    4.0    2.0    1.0    0.0    2.0    2.0    3.0    5.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    361.0  2.0    3.0    0.08375634517766498  33 / 394
0.0    0.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    2.0    17.0   0.0    14.0   1.0    0.0    344.0  0.0    0.12468193384223919  49 / 393
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    17.0   2.0    0.0    0.0    0.0    3.0    1.0    316.0  0.13896457765667575  51 / 367
390.0  494.0  348.0  438.0  401.0  358.0  375.0  358.0  340.0  363.0  377.0  357.0  393.0  386.0  366.0  377.0  376.0  419.0  329.0  397.0  402.0  364.0  403.0  446.0  382.0  364.0  0.1501549535139458   1,502 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.849845
2    0.923223
3    0.949515
4    0.962311
5    0.971608
6    0.979206
7    0.984005
8    0.987604
9    0.991103
10   0.992802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16502092020518092
RMSE: 0.40622767040808644
LogLoss: 0.5334057637383038
Mean Per-Class Error: 0.14964678176154347
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0    1.0   1.0   0.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   89.0   0.0   0.0    2.0   0.0   0.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0   2.0   1.0    0.0   5.0    2.0   0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.16037735849056603  17 / 106
0.0   0.0    68.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    1.0   2.0   0.0    0.0   1.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
1.0   1.0    0.0   100.0  0.0   1.0   0.0   2.0   0.0   0.0    1.0   0.0   2.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.10714285714285714  12 / 112
0.0   2.0    0.0   0.0    78.0  1.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    2.0   3.0   0.0    0.0   0.0   2.0    0.0    3.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   86.0  0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    1.0   1.0   0.0   1.0   0.0   1.0    2.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   90.0   0.0    1.0   0.1                  10 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    3.0   0.0    0.0   4.0   0.0    5.0   1.0   0.0    92.0   0.0   0.14018691588785046  15 / 107
1.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0   1.0    1.0    74.0  0.14942528735632185  13 / 87
90.0  117.0  74.0  128.0  97.0  83.0  93.0  87.0  82.0  102.0  96.0  96.0  88.0  99.0  80.0  107.0  95.0  105.0  80.0  96.0  103.0  85.0  98.0  111.0  105.0  93.0  0.14859437751004015  370 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.851406
2    0.924498
3    0.951406
4    0.961044
5    0.970281
6    0.980321
7    0.984337
8    0.987148
9    0.98996
10   0.992369
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:46  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:46  23.190 sec  63738 obs/sec     1         1             10007      0.56537          1.01626             0.994319       0.26772                          0.564851           1.01247               0.994315         0.26988
    2019-07-24 15:35:48  24.454 sec  72096 obs/sec     10        10            100070     0.403552         0.528093            0.997106       0.150155                         0.406228           0.533406              0.99706          0.148594
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0855433
C15         0.98794                0.98794              0.0845117
C8          0.868124               0.868124             0.0742622
C7          0.860133               0.860133             0.0735786
C9          0.842003               0.842003             0.0720277
C12         0.826291               0.826291             0.0706837
C11         0.753409               0.753409             0.0644491
C5          0.749709               0.749709             0.0641326
C10         0.697873               0.697873             0.0596984
C6          0.684534               0.684534             0.0585573
C14         0.659893               0.659893             0.0564495
C3          0.647311               0.647311             0.0553731
C16         0.581069               0.581069             0.0497065
C4          0.562909               0.562909             0.0481531
C1          0.498321               0.498321             0.042628
C2          0.470466               0.470466             0.0402453
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_66

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias           bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009825723158201072  0.0002743862569332123  0.0         -0.01917713798314935  0.24764806032180786  0.2701429840067124  0.19212108850479126
    3        26       Softmax                      0.0   0.0   0.006172793037037012   0.0297161266207695     0.0         -0.29947883829193134  0.7080216407775879   -0.488163965734252  0.22523266077041626


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16721101903156815
RMSE: 0.408914439744512
LogLoss: 0.5462794984286082
Mean Per-Class Error: 0.15548776759087574
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    7.0    2.0    1.0    5.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    1.0    1.0    1.0    6.0    6.0    0.0    0.10126582278481013  40 / 395
1.0    349.0  0.0    6.0    2.0    1.0    0.0    2.0    0.0    1.0    1.0    0.0    0.0    0.0    2.0    2.0    0.0    6.0    5.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    0.08877284595300261  34 / 383
0.0    0.0    309.0  0.0    13.0   0.0    10.0   1.0    0.0    0.0    18.0   1.0    0.0    0.0    8.0    0.0    0.0    0.0    2.0    3.0    1.0    0.0    2.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
1.0    23.0   0.0    347.0  0.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    5.0    6.0    3.0    0.0    1.0    6.0    1.0    0.0    1.0    0.0    0.0    5.0    0.0    0.0    0.13895781637717122  56 / 403
0.0    3.0    2.0    0.0    321.0  5.0    14.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    7.0    1.0    1.0    0.0    0.0    4.0    0.0    12.0   0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    11.0   0.0    4.0    0.0    0.0    5.0    0.0    0.0    3.0    5.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    2.0    0.0    3.0    3.0    0.0    0.0    4.0    3.0    3.0    6.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    3.0    1.0    0.0    0.0    355.0  4.0    4.0    0.09898477157360407  39 / 394
0.0    0.0    0.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    2.0    18.0   0.0    8.0    0.0    0.0    351.0  0.0    0.10687022900763359  42 / 393
2.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    2.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    1.0    0.0    0.0    0.0    2.0    0.0    336.0  0.08446866485013624  31 / 367
387.0  517.0  333.0  437.0  396.0  352.0  377.0  311.0  341.0  376.0  359.0  364.0  407.0  380.0  390.0  377.0  352.0  442.0  305.0  394.0  395.0  365.0  409.0  443.0  405.0  389.0  0.15475357392782166  1,548 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.845246
2    0.913526
3    0.942917
4    0.959912
5    0.971009
6    0.978606
7    0.983605
8    0.987604
9    0.990703
10   0.993402

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17146750105916475
RMSE: 0.4140863449320259
LogLoss: 0.5556113794203216
Mean Per-Class Error: 0.16285590272830225
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   0.0   1.0    3.0    0.0   0.07865168539325842  7 / 89
1.0   90.0   0.0   2.0    2.0   1.0   0.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    1.0   1.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    66.0  0.0    3.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0   2.0   1.0   0.0   0.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
1.0   4.0    0.0   97.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   2.0    1.0   0.0    1.0   1.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.13392857142857142  15 / 112
0.0   1.0    0.0   0.0    76.0  3.0   3.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    4.0   1.0   0.0   0.0   0.0   1.0    0.0    4.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0   2.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   1.0    1.0   0.0   0.0   2.0   1.0   1.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   89.0   0.0    1.0   0.11                 11 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    2.0   0.0    0.0   4.0   0.0   2.0   0.0   0.0    96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    78.0  0.10344827586206896  9 / 87
91.0  127.0  71.0  126.0  92.0  83.0  93.0  79.0  81.0  106.0  93.0  95.0  88.0  101.0  81.0  110.0  95.0  110.0  79.0  94.0  98.0  84.0  96.0  107.0  115.0  95.0  0.1614457831325301   402 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838554
2    0.913655
3    0.946185
4    0.960241
5    0.970281
6    0.979116
7    0.984337
8    0.987149
9    0.989558
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:12  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:12  1 min 48.671 sec  96221 obs/sec     1         1             10007      0.594713         1.09715             0.993715       0.288613                         0.596874           1.09262               0.993652         0.290763
    2019-07-24 15:37:13  1 min 49.575 sec  101593 obs/sec    10        10            100070     0.408914         0.546279            0.997029       0.154754                         0.414086           0.555611              0.996945         0.161446
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0822931
C15         0.997189               0.997189             0.0820618
C8          0.980463               0.980463             0.0806853
C9          0.883569               0.883569             0.0727117
C12         0.861361               0.861361             0.0708841
C11         0.792404               0.792404             0.0652094
C7          0.780761               0.780761             0.0642512
C5          0.776274               0.776274             0.063882
C14         0.755843               0.755843             0.0622007
C10         0.734563               0.734563             0.0604495
C6          0.716486               0.716486             0.0589619
C4          0.691567               0.691567             0.0569113
C16         0.643288               0.643288             0.0529382
C3          0.547384               0.547384             0.045046
C2          0.501848               0.501848             0.0412987
C1          0.488682               0.488682             0.0402152
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_16

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017432220191437864  0.0004718793788924813  0.0         -0.0033489603795295864  0.46133625507354736  0.01093060784472071   0.496929407119751
    3        26       Softmax                 0.0   0.0   0.0022694852074122396  0.0005618899594992399  0.0         0.0012358329160913574   0.412778377532959    -0.49335200825806896  0.20543092489242554


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16083802153234453
RMSE: 0.4010461588549933
LogLoss: 0.5487488045815563
Mean Per-Class Error: 0.1591223725962388
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    2.0    5.0    1.0    1.0    0.0    1.0    4.0    2.0    0.0    1.0    1.0    1.0    2.0    5.0    2.0    0.09113924050632911  36 / 395
0.0    320.0  0.0    8.0    4.0    0.0    1.0    1.0    2.0    0.0    1.0    1.0    1.0    0.0    1.0    2.0    2.0    24.0   10.0   0.0    0.0    0.0    1.0    2.0    1.0    1.0    0.16449086161879894  63 / 383
0.0    0.0    312.0  1.0    12.0   0.0    8.0    0.0    0.0    0.0    13.0   4.0    0.0    0.0    4.0    0.0    2.0    0.0    6.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.15217391304347827  56 / 368
1.0    15.0   0.0    349.0  0.0    0.0    0.0    5.0    2.0    2.0    0.0    1.0    5.0    2.0    2.0    2.0    0.0    5.0    3.0    0.0    1.0    0.0    1.0    4.0    0.0    3.0    0.13399503722084366  54 / 403
0.0    1.0    0.0    0.0    318.0  4.0    10.0   0.0    1.0    0.0    4.0    6.0    0.0    0.0    0.0    0.0    8.0    6.0    8.0    3.0    0.0    0.0    0.0    4.0    0.0    11.0   0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.0    1.0    0.0    11.0   1.0    2.0    0.0    0.0    4.0    0.0    0.0    1.0    2.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    2.0    0.0    8.0    5.0    1.0    0.0    0.0    5.0    1.0    11.0   5.0    0.0    0.0    2.0    0.0    3.0    0.0    2.0    2.0    1.0    0.0    0.0    336.0  4.0    5.0    0.1450381679389313   57 / 393
0.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    1.0    9.0    1.0    5.0    1.0    1.0    358.0  0.0    0.08673469387755102  34 / 392
0.0    0.0    0.0    0.0    16.0   1.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    1.0    20.0   4.0    0.0    0.0    0.0    1.0    1.0    307.0  0.16348773841961853  60 / 367
391.0  470.0  348.0  427.0  392.0  413.0  337.0  278.0  364.0  366.0  380.0  364.0  428.0  372.0  401.0  351.0  386.0  452.0  381.0  359.0  406.0  352.0  409.0  396.0  412.0  368.0  0.1584524642607218   1,585 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.841548
2    0.912026
3    0.942817
4    0.959112
5    0.970909
6    0.978606
7    0.983305
8    0.986604
9    0.989503
10   0.992302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16151239811972523
RMSE: 0.40188605116341775
LogLoss: 0.5562871003000159
Mean Per-Class Error: 0.15771810444612314
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0    1.0   0.06741573033707865   6 / 89
0.0   85.0   0.0   3.0    3.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0   1.0    0.0    7.0    2.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   0.19811320754716982   21 / 106
0.0   0.0    68.0  0.0    2.0   0.0    2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    3.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0   0.17073170731707318   14 / 82
1.0   2.0    0.0   94.0   0.0   0.0    0.0   3.0   1.0   0.0    0.0   0.0   1.0   0.0   2.0   2.0    0.0    2.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0    2.0   0.16071428571428573   18 / 112
0.0   0.0    0.0   0.0    72.0  3.0    2.0   0.0   1.0   0.0    2.0   2.0   0.0   0.0   0.0   0.0    3.0    2.0    3.0   2.0   0.0    0.0   0.0    0.0   0.0    5.0   0.25773195876288657   25 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    1.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   3.0    3.0   0.0    0.0   0.0   1.0   0.0    5.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    83.0  2.0    1.0   0.17                  17 / 100
0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0    0.0   3.0   0.0    2.0   1.0    0.0   97.0   0.0   0.09345794392523364   10 / 107
0.0   0.0    0.0   0.0    5.0   1.0    0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0    5.0   1.0   0.0    0.0   0.0    0.0   1.0    70.0  0.19540229885057472   17 / 87
91.0  115.0  71.0  119.0  89.0  100.0  84.0  72.0  92.0  106.0  97.0  96.0  96.0  97.0  82.0  102.0  103.0  106.0  96.0  87.0  106.0  76.0  107.0  95.0  117.0  88.0  0.1578313253012048    393 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842169
2    0.911647
3    0.945783
4    0.962249
5    0.971888
6    0.979116
7    0.981526
8    0.986345
9    0.989157
10   0.992771
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:55  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:55  31.687 sec  44874 obs/sec     1         1             10007      0.539487         0.95914             0.994826       0.258123                         0.537982           0.951325              0.994843         0.263855
    2019-07-24 15:35:57  33.613 sec  47336 obs/sec     10        10            100070     0.401046         0.548749            0.997141       0.158452                         0.401886           0.556287              0.997122         0.157831
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0867562
C15         0.992487               0.992487             0.0861044
C9          0.885703               0.885703             0.0768403
C12         0.864068               0.864068             0.0749632
C7          0.836236               0.836236             0.0725486
C8          0.816814               0.816814             0.0708637
C11         0.737208               0.737208             0.0639573
C10         0.702656               0.702656             0.0609597
C6          0.664204               0.664204             0.0576238
C14         0.656645               0.656645             0.0569681
C5          0.632446               0.632446             0.0548686
C16         0.614963               0.614963             0.0533518
C3          0.594581               0.594581             0.0515836
C4          0.550835               0.550835             0.0477883
C1          0.502771               0.502771             0.0436185
C2          0.474939               0.474939             0.0412039
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_55

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017830467042188047  0.00046646432019770145  0.0         0.012692676270948056   0.45086514949798584  -0.023113941418974628  0.48400235176086426
    3        26       Softmax                 0.0   0.0   0.0023506351778730906  0.0007654407527297735   0.0         -0.004807704202343862  0.4158283472061157   -0.4780714331996693    0.15515786409378052


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1603774996624429
RMSE: 0.40047159657389303
LogLoss: 0.5446462104624624
Mean Per-Class Error: 0.16057774433770994
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    4.0    1.0    4.0    1.0    0.0    0.0    2.0    2.0    0.0    1.0    3.0    1.0    1.0    1.0    4.0    3.0    0.0810126582278481   32 / 395
0.0    340.0  0.0    3.0    3.0    0.0    1.0    3.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    7.0    14.0   0.0    0.0    2.0    0.0    3.0    2.0    1.0    0.1122715404699739   43 / 383
0.0    0.0    307.0  1.0    13.0   1.0    9.0    1.0    0.0    0.0    13.0   0.0    1.0    0.0    11.0   0.0    1.0    0.0    4.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
1.0    28.0   0.0    332.0  0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    7.0    4.0    0.0    0.0    7.0    2.0    0.0    4.0    0.0    0.0    6.0    0.0    2.0    0.1761786600496278   71 / 403
0.0    7.0    1.0    0.0    320.0  5.0    15.0   0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    3.0    3.0    2.0    1.0    0.0    0.0    5.0    0.0    10.0   0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    5.0    0.0    0.0    2.0    0.0    0.0    3.0    1.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    5.0    7.0    0.0    1.0    4.0    4.0    1.0    5.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    5.0    3.0    2.0    0.0    0.0    339.0  7.0    2.0    0.13959390862944163  55 / 394
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    0.0    2.0    11.0   3.0    12.0   1.0    1.0    350.0  0.0    0.10941475826972011  43 / 393
2.0    0.0    0.0    0.0    24.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    21.0   4.0    0.0    0.0    0.0    2.0    0.0    301.0  0.17983651226158037  66 / 367
410.0  495.0  329.0  391.0  426.0  372.0  391.0  335.0  340.0  352.0  353.0  341.0  387.0  401.0  384.0  384.0  382.0  408.0  394.0  380.0  411.0  362.0  402.0  426.0  401.0  346.0  0.15975207437768668  1,598 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840248
2    0.916225
3    0.945716
4    0.961212
5    0.972808
6    0.977907
7    0.983305
8    0.986104
9    0.988603
10   0.991003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16428780105651145
RMSE: 0.4053243158959396
LogLoss: 0.5572656652640022
Mean Per-Class Error: 0.16417687547291446
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17    18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   2.0    1.0   0.056179775280898875  5 / 89
0.0   90.0   0.0   0.0    2.0   0.0   1.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    0.0   2.0   3.0   0.0   0.0    2.0   0.0   1.0   1.0    0.0   0.1509433962264151    16 / 106
0.0   0.0    69.0  0.0    2.0   0.0   1.0    0.0   0.0   0.0    2.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0   2.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.15853658536585366   13 / 82
1.0   4.0    0.0   94.0   0.0   0.0   0.0    4.0   0.0   0.0    0.0   0.0   0.0   3.0    0.0   0.0    0.0   1.0   1.0   0.0   1.0    0.0   0.0   2.0   0.0    1.0   0.16071428571428573   18 / 112
0.0   0.0    0.0   0.0    77.0  4.0   6.0    0.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   1.0   1.0   0.0    0.0   0.0   1.0   0.0    4.0   0.20618556701030927   20 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   87.0  0.0   0.0    0.0   0.05434782608695652   5 / 92
0.0   0.0    0.0   3.0    3.0   0.0   0.0    2.0   1.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   2.0   0.0   1.0    0.0   0.0   78.0  3.0    1.0   0.22                  22 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   3.0    1.0   0.0   0.0   2.0   0.0    4.0   1.0   0.0   96.0   0.0   0.102803738317757     11 / 107
1.0   0.0    0.0   0.0    7.0   0.0   0.0    0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0    71.0  0.1839080459770115    16 / 87
99.0  122.0  71.0  111.0  98.0  88.0  101.0  85.0  84.0  102.0  88.0  88.0  86.0  110.0  79.0  110.0  93.0  99.0  97.0  88.0  108.0  82.0  99.0  97.0  118.0  87.0  0.1634538152610442    407 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836546
2    0.918072
3    0.947791
4    0.960643
5    0.969478
6    0.975502
7    0.982329
8    0.985141
9    0.98755
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:00  1 min 36.689 sec  45694 obs/sec     1         1             10007      0.552405         0.998244            0.994579       0.270719                         0.552055           0.996883              0.99457          0.27751
    2019-07-24 15:37:02  1 min 38.745 sec  44674 obs/sec     10        10            100070     0.400472         0.544646            0.997151       0.159752                         0.405324           0.557266              0.997073         0.163454
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0908543
C13         0.895364               0.895364             0.0813476
C9          0.826513               0.826513             0.0750923
C12         0.821856               0.821856             0.0746692
C8          0.782659               0.782659             0.0711079
C11         0.780748               0.780748             0.0709343
C7          0.772775               0.772775             0.07021
C10         0.718947               0.718947             0.0653194
C14         0.697859               0.697859             0.0634035
C16         0.676745               0.676745             0.0614852
C6          0.636533               0.636533             0.0578317
C5          0.5773                 0.5773               0.0524502
C4          0.507846               0.507846             0.04614
C3          0.49763                0.49763              0.0452118
C2          0.411083               0.411083             0.0373487
C1          0.402775               0.402775             0.0365939
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_7

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017114532869868526  0.0004131424939259887   0.0         -0.011125718776458626  0.4579702615737915   -0.07132528613407234  0.4794774055480957
    3        26       Softmax                 0.0   0.0   0.002180088959133942   0.00048186059575527906  0.0         0.0001233553748883983  0.41280555725097656  -0.4757881725070451   0.18300777673721313


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16383319498122978
RMSE: 0.40476313441472134
LogLoss: 0.5589552244440285
Mean Per-Class Error: 0.1628554803119719
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    2.0    0.0    5.0    0.0    2.0    0.0    0.0    2.0    3.0    0.0    5.0    1.0    0.0    2.0    5.0    1.0    0.0810126582278481   32 / 395
0.0    337.0  0.0    6.0    5.0    1.0    1.0    9.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    10.0   4.0    0.0    0.0    3.0    0.0    1.0    4.0    0.0    0.12010443864229765  46 / 383
0.0    0.0    302.0  1.0    9.0    1.0    22.0   1.0    0.0    0.0    12.0   0.0    0.0    0.0    8.0    0.0    2.0    0.0    1.0    2.0    6.0    0.0    1.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
1.0    25.0   0.0    332.0  0.0    1.0    0.0    9.0    1.0    4.0    1.0    1.0    4.0    6.0    6.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    6.0    0.0    2.0    0.1761786600496278   71 / 403
0.0    3.0    3.0    0.0    319.0  2.0    11.0   1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    7.0    3.0    4.0    3.0    1.0    0.0    0.0    4.0    0.0    18.0   0.16927083333333334  65 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    7.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    14.0   1.0    6.0    0.0    1.0    4.0    0.0    0.0    3.0    0.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    5.0    0.0    5.0    6.0    1.0    0.0    2.0    3.0    1.0    4.0    1.0    0.0    0.0    2.0    0.0    4.0    1.0    2.0    1.0    2.0    2.0    0.0    345.0  4.0    3.0    0.12436548223350254  49 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    1.0    7.0    2.0    10.0   1.0    1.0    359.0  0.0    0.08651399491094147  34 / 393
2.0    1.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    1.0    17.0   5.0    0.0    0.0    0.0    2.0    0.0    311.0  0.15027322404371585  55 / 366
399.0  529.0  321.0  396.0  411.0  357.0  393.0  316.0  339.0  352.0  351.0  359.0  408.0  390.0  418.0  374.0  392.0  406.0  303.0  381.0  423.0  362.0  381.0  423.0  441.0  378.0  0.16185144456663     1,619 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838149
2    0.907128
3    0.940518
4    0.957613
5    0.968209
6    0.976607
7    0.981705
8    0.986004
9    0.988703
10   0.991502

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.165627095076706
RMSE: 0.40697308888513256
LogLoss: 0.5664591586331545
Mean Per-Class Error: 0.1643795143134724
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   1.0    0.0   0.0   1.0    2.0    0.0   0.10112359550561797  9 / 89
0.0   86.0   0.0   2.0    2.0   0.0   1.0   4.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   5.0    1.0   0.0   0.0    3.0   0.0   1.0    1.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    64.0  0.0    2.0   0.0   7.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   2.0   1.0    0.0   1.0   0.0    0.0    0.0   0.21951219512195122  18 / 82
1.0   5.0    0.0   91.0   0.0   0.0   0.0   6.0   1.0   1.0    0.0   0.0   1.0   2.0    1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.1875               21 / 112
0.0   0.0    1.0   0.0    75.0  1.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   3.0   0.0    0.0   0.0   2.0    0.0    6.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    1.0   1.0    0.0   0.0   0.0    0.0   86.0  0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   88.0   1.0    2.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   1.0   0.0    5.0   1.0   0.0    96.0   0.0   0.102803738317757    11 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   2.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   1.0   0.0    0.0   0.0   0.0    0.0    75.0  0.13793103448275862  12 / 87
88.0  130.0  66.0  110.0  94.0  78.0  98.0  86.0  80.0  107.0  89.0  93.0  89.0  104.0  81.0  111.0  98.0  107.0  81.0  94.0  106.0  86.0  95.0  105.0  119.0  95.0  0.16305220883534136  406 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836948
2    0.906827
3    0.942169
4    0.957831
5    0.969478
6    0.974699
7    0.979518
8    0.985141
9    0.988755
10   0.991165
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:39  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:39  15.995 sec  44083 obs/sec     1         1             10007      0.552709         0.994051            0.99457        0.273318                         0.551548           0.98822               0.99458          0.273494
    2019-07-24 15:35:41  18.075 sec  44200 obs/sec     10        10            100070     0.404763         0.558955            0.997088       0.161851                         0.406973           0.566459              0.997049         0.163052
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0888703
C15         0.985621               0.985621             0.0875924
C12         0.852739               0.852739             0.0757831
C9          0.84478                0.84478              0.0750758
C8          0.783547               0.783547             0.069634
C7          0.762403               0.762403             0.067755
C11         0.745087               0.745087             0.0662161
C5          0.663869               0.663869             0.0589982
C10         0.663392               0.663392             0.0589558
C14         0.655454               0.655454             0.0582504
C6          0.620415               0.620415             0.0551364
C16         0.617959               0.617959             0.0549182
C3          0.594696               0.594696             0.0528508
C4          0.545702               0.545702             0.0484967
C2          0.464886               0.464886             0.0413146
C1          0.451807               0.451807             0.0401522
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_10

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001554140066104992   0.0004031728021800518  0.0         -0.012309586787253579  0.4424957036972046  0.05173680783939758  0.4640927314758301
    3        26       Softmax                 0.0   0.0   0.0026827425081836945  0.0010983208194375038  0.0         -0.0195837549937848    0.5691032409667969  -0.5201594378550244  0.18580037355422974


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16875874149789435
RMSE: 0.4108025578034956
LogLoss: 0.5651469587297211
Mean Per-Class Error: 0.1653635219943649
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    5.0    0.0    0.0    0.0    3.0    0.0    6.0    2.0    1.0    5.0    1.0    0.0    0.0    1.0    3.0    1.0    1.0    1.0    1.0    1.0    1.0    3.0    0.0    0.09113924050632911  36 / 395
0.0    332.0  2.0    4.0    4.0    0.0    2.0    3.0    3.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    1.0    17.0   4.0    0.0    0.0    1.0    0.0    3.0    3.0    0.0    0.13315926892950392  51 / 383
0.0    0.0    308.0  0.0    17.0   0.0    6.0    0.0    0.0    0.0    19.0   1.0    0.0    0.0    9.0    0.0    2.0    0.0    2.0    1.0    1.0    0.0    2.0    0.0    0.0    0.0    0.16304347826086957  60 / 368
2.0    19.0   0.0    331.0  0.0    1.0    0.0    2.0    0.0    6.0    1.0    0.0    6.0    2.0    4.0    2.0    1.0    12.0   1.0    0.0    5.0    0.0    1.0    5.0    0.0    1.0    0.17661691542288557  71 / 402
0.0    8.0    2.0    1.0    310.0  6.0    15.0   1.0    1.0    0.0    2.0    5.0    0.0    0.0    0.0    1.0    9.0    4.0    7.0    5.0    0.0    0.0    0.0    1.0    0.0    6.0    0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    9.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    3.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    1.0    0.0    2.0    7.0    3.0    1.0    0.0    2.0    5.0    10.0   5.0    0.0    0.0    2.0    0.0    4.0    3.0    4.0    0.0    1.0    0.0    0.0    340.0  3.0    1.0    0.13705583756345177  54 / 394
0.0    1.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    2.0    0.0    2.0    10.0   3.0    10.0   1.0    1.0    355.0  0.0    0.09669211195928754  38 / 393
2.0    1.0    0.0    1.0    11.0   0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    21.0   2.0    0.0    0.0    0.0    1.0    1.0    315.0  0.14168937329700274  52 / 367
390.0  509.0  345.0  409.0  408.0  367.0  330.0  289.0  343.0  370.0  372.0  359.0  396.0  381.0  448.0  378.0  378.0  433.0  325.0  383.0  410.0  365.0  404.0  423.0  435.0  353.0  0.16465060481855442  1,647 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835349
2    0.910127
3    0.940818
4    0.957013
5    0.968909
6    0.974808
7    0.980406
8    0.984305
9    0.987804
10   0.991802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1698074298856758
RMSE: 0.4120769708266597
LogLoss: 0.5672729142024786
Mean Per-Class Error: 0.16461932792532202
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   88.0   1.0   1.0    2.0   0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   8.0    0.0   0.0   0.0    1.0   0.0    2.0    0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    69.0  0.0    4.0   0.0   0.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   1.0    0.0    0.0    0.0   0.15853658536585366  13 / 82
1.0   2.0    0.0   92.0   0.0   1.0   0.0   1.0   0.0   3.0    0.0   0.0   2.0   0.0   2.0   2.0    0.0   2.0    0.0   0.0   2.0    0.0   0.0    2.0    0.0    0.0   0.17857142857142858  20 / 112
0.0   2.0    1.0   0.0    71.0  4.0   3.0   0.0   0.0   0.0    1.0   2.0   0.0   0.0   0.0   0.0    3.0   1.0    3.0   2.0   0.0    0.0   0.0    1.0    0.0    3.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   89.0   0.0    0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   1.0    3.0   3.0   0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0   0.0    0.0   0.0    82.0   2.0    1.0   0.18                 18 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   3.0   0.0    3.0   1.0    0.0    98.0   0.0   0.08411214953271028  9 / 107
0.0   0.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   1.0   0.0    0.0   0.0    0.0    1.0    74.0  0.14942528735632185  13 / 87
90.0  126.0  78.0  114.0  93.0  84.0  75.0  75.0  80.0  106.0  91.0  96.0  85.0  99.0  96.0  107.0  99.0  111.0  83.0  96.0  104.0  81.0  101.0  104.0  129.0  87.0  0.1642570281124498   409 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835743
2    0.913655
3    0.941365
4    0.955422
5    0.967871
6    0.974699
7    0.980723
8    0.984337
9    0.989157
10   0.991566
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:45  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:45  21.710 sec  71478 obs/sec     1         1             10007      0.586278         1.08631             0.993893       0.286814                         0.586193           1.0838                0.993877         0.295181
    2019-07-24 15:35:46  22.983 sec  71992 obs/sec     10        10            100070     0.410803         0.565147            0.997001       0.164651                         0.412077           0.567273              0.996974         0.164257
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0959736
C13         0.947574               0.947574             0.0909421
C9          0.818116               0.818116             0.0785176
C12         0.798902               0.798902             0.0766736
C8          0.798253               0.798253             0.0766113
C11         0.728727               0.728727             0.0699386
C7          0.683556               0.683556             0.0656034
C10         0.650747               0.650747             0.0624545
C6          0.634546               0.634546             0.0608997
C16         0.612234               0.612234             0.0587584
C14         0.592085               0.592085             0.0568246
C5          0.52795                0.52795              0.0506693
C3          0.464802               0.464802             0.0446087
C4          0.426292               0.426292             0.0409128
C2          0.377298               0.377298             0.0362107
C1          0.358443               0.358443             0.0344011
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_48

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0010088406043564646  0.00026400969363749027  0.0         -0.01154356392896183  0.23633140325546265  0.26444112122953983  0.19896972179412842
    3        26       Softmax                      0.0   0.0   0.006927397747124185   0.02991102635860443     0.0         -0.27014206607768404  0.7213420867919922   -0.4740361405976689  0.195795476436615


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17359635878739624
RMSE: 0.4166489635021264
LogLoss: 0.5746967226772463
Mean Per-Class Error: 0.16267124509370814
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    1.0    3.0    0.0    1.0    0.0    0.0    2.0    6.0    1.0    4.0    1.0    1.0    1.0    4.0    0.0    0.08860759493670886  35 / 395
0.0    338.0  0.0    6.0    3.0    0.0    0.0    2.0    2.0    0.0    1.0    1.0    0.0    0.0    2.0    0.0    3.0    17.0   5.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    311.0  0.0    13.0   0.0    9.0    1.0    0.0    0.0    16.0   0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    3.0    4.0    0.0    2.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
1.0    15.0   0.0    350.0  0.0    0.0    0.0    1.0    0.0    3.0    0.0    1.0    5.0    4.0    2.0    3.0    2.0    8.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    2.0    0.1315136476426799   53 / 403
0.0    6.0    7.0    0.0    327.0  1.0    10.0   0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    6.0    5.0    4.0    0.0    1.0    0.0    0.0    4.0    0.0    8.0    0.1484375            57 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    10.0   1.0    1.0    0.0    0.0    5.0    0.0    0.0    3.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    2.0    0.0    3.0    5.0    0.0    0.0    1.0    2.0    3.0    7.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    2.0    3.0    1.0    0.0    0.0    355.0  2.0    3.0    0.09898477157360407  39 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    1.0    14.0   0.0    3.0    1.0    0.0    360.0  0.0    0.08163265306122448  32 / 392
0.0    0.0    0.0    1.0    11.0   0.0    0.0    0.0    1.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    22.0   2.0    0.0    0.0    0.0    3.0    0.0    315.0  0.14168937329700274  52 / 367
396.0  513.0  377.0  424.0  448.0  340.0  304.0  279.0  339.0  363.0  359.0  365.0  396.0  381.0  408.0  386.0  369.0  443.0  328.0  381.0  420.0  349.0  407.0  433.0  434.0  361.0  0.16175147455763272  1,618 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838249
2    0.913826
3    0.940218
4    0.955013
5    0.96741
6    0.974308
7    0.980406
8    0.984205
9    0.988403
10   0.991303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17411227844883712
RMSE: 0.41726763407774287
LogLoss: 0.5797799024067584
Mean Per-Class Error: 0.16262704918695914
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   1.0    1.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   89.0   0.0   1.0    1.0    0.0   0.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    1.0    8.0    1.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.16037735849056603  17 / 106
0.0   0.0    68.0  0.0    2.0    0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   4.0   0.0    0.0    0.0    0.0   2.0   0.0    0.0   1.0    0.0    0.0    0.0   0.17073170731707318  14 / 82
0.0   2.0    0.0   96.0   0.0    0.0   0.0   1.0   0.0   2.0    0.0   0.0   2.0   2.0   0.0   2.0    1.0    1.0    0.0   0.0   1.0    0.0   0.0    1.0    0.0    1.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    84.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    4.0    1.0    3.0   0.0   0.0    0.0   0.0    1.0    0.0    2.0   0.13402061855670103  13 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0    0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    0.0    2.0    1.0   0.0   0.0    0.0   0.0    87.0   0.0    2.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0   2.0   0.0    1.0   1.0    0.0    100.0  0.0   0.06542056074766354  7 / 107
0.0   0.0    0.0   1.0    3.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    2.0   0.0   0.0    0.0   0.0    0.0    0.0    79.0  0.09195402298850575  8 / 87
93.0  127.0  82.0  116.0  106.0  82.0  72.0  70.0  82.0  106.0  87.0  98.0  92.0  97.0  84.0  109.0  105.0  112.0  81.0  85.0  103.0  76.0  102.0  102.0  122.0  99.0  0.1614457831325301   402 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838554
2    0.916466
3    0.941365
4    0.953815
5    0.969076
6    0.974699
7    0.97992
8    0.981928
9    0.987149
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:48  1 min 24.984 sec  98107 obs/sec     1         1             10007      0.605526         1.1543              0.993484       0.307308                         0.606009           1.15532               0.993456         0.31004
    2019-07-24 15:36:49  1 min 25.840 sec  106570 obs/sec    10        10            100070     0.416649         0.574697            0.996915       0.161751                         0.417268           0.57978               0.996898         0.161446
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0877222
C13         0.956431               0.956431             0.0839003
C9          0.881613               0.881613             0.0773371
C8          0.828455               0.828455             0.0726739
C12         0.810322               0.810322             0.0710833
C7          0.809585               0.809585             0.0710186
C5          0.757584               0.757584             0.0664569
C11         0.717612               0.717612             0.0629505
C10         0.679832               0.679832             0.0596364
C4          0.635359               0.635359             0.0557351
C14         0.621339               0.621339             0.0545052
C6          0.616864               0.616864             0.0541126
C16         0.591853               0.591853             0.0519187
C3          0.578236               0.578236             0.0507242
C1          0.490567               0.490567             0.0430336
C2          0.423967               0.423967             0.0371913
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_38

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms         mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -----------------  ----------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0015678029388368486  0.0004238005494698882  0.0         0.0038890689473589646  0.432828426361084  -0.0025642249104393423  0.5155189037322998
    3        26       Softmax                 0.0   0.0   0.002655203651906609   0.0008240754250437021  0.0         -0.025001154426578208  0.566964864730835  -0.5231197337015959     0.19379031658172607


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1718906290580379
RMSE: 0.4145969477191528
LogLoss: 0.5682702594473336
Mean Per-Class Error: 0.1633259289957533
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    2.0    1.0    2.0    4.0    0.0    0.0    0.0    4.0    1.0    2.0    0.0    4.0    0.0    0.0    0.0    6.0    1.0    0.0759493670886076   30 / 395
0.0    314.0  0.0    5.0    3.0    5.0    2.0    5.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    3.0    21.0   9.0    0.0    0.0    5.0    0.0    1.0    1.0    0.0    0.1801566579634465   69 / 383
0.0    2.0    308.0  0.0    11.0   0.0    15.0   1.0    0.0    0.0    12.0   0.0    0.0    0.0    3.0    0.0    2.0    2.0    5.0    2.0    3.0    0.0    1.0    1.0    0.0    0.0    0.16304347826086957  60 / 368
1.0    12.0   0.0    349.0  0.0    1.0    0.0    6.0    0.0    5.0    1.0    0.0    3.0    2.0    3.0    4.0    0.0    7.0    2.0    0.0    1.0    0.0    0.0    3.0    0.0    2.0    0.1318407960199005   53 / 402
0.0    3.0    3.0    0.0    313.0  4.0    14.0   2.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    1.0    6.0    2.0    6.0    2.0    1.0    0.0    0.0    8.0    0.0    13.0   0.18489583333333334  71 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
3.0    6.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    7.0    2.0    6.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    5.0    0.0    5.0    7.0    2.0    0.0    1.0    4.0    0.0    9.0    0.0    0.0    0.0    2.0    0.0    2.0    0.0    3.0    3.0    5.0    0.0    0.0    340.0  2.0    3.0    0.13486005089058525  53 / 393
1.0    1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    0.0    1.0    10.0   1.0    14.0   0.0    0.0    351.0  0.0    0.10687022900763359  42 / 393
3.0    0.0    0.0    0.0    12.0   1.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    36.0   6.0    0.0    0.0    0.0    2.0    1.0    296.0  0.19346049046321526  71 / 367
396.0  457.0  353.0  421.0  396.0  373.0  358.0  321.0  343.0  352.0  350.0  358.0  396.0  386.0  408.0  417.0  347.0  478.0  397.0  373.0  405.0  370.0  382.0  407.0  411.0  348.0  0.16245126462061382  1,625 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837549
2    0.908827
3    0.939418
4    0.956713
5    0.96781
6    0.974608
7    0.981206
8    0.986304
9    0.989003
10   0.991103

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17714723124930568
RMSE: 0.420888620954886
LogLoss: 0.5815513539675672
Mean Per-Class Error: 0.17255630014962964
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.0   1.0    0.0   0.0   0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   78.0   0.0   2.0    2.0   1.0   1.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0   6.0    4.0   0.0   0.0    3.0   0.0   1.0    1.0    0.0   0.2641509433962264   28 / 106
0.0   1.0    68.0  0.0    3.0   0.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    1.0   0.0    1.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
0.0   3.0    0.0   95.0   0.0   0.0   0.0   1.0   0.0   2.0    1.0   0.0   1.0   2.0    0.0   3.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   2.0    0.0    1.0   0.15178571428571427  17 / 112
0.0   0.0    1.0   0.0    74.0  2.0   5.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   2.0   0.0    0.0   0.0   3.0    0.0    4.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
1.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   1.0    1.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   2.0    3.0   1.0   0.0   1.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   1.0   1.0    0.0   0.0   82.0   1.0    1.0   0.18                 18 / 100
0.0   1.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   3.0    1.0   0.0    0.0   2.0   0.0    5.0   0.0   0.0    93.0   0.0   0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0   2.0   0.0    0.0   0.0   2.0    1.0    69.0  0.20689655172413793  18 / 87
92.0  112.0  77.0  116.0  92.0  89.0  86.0  82.0  82.0  103.0  92.0  90.0  87.0  106.0  79.0  122.0  93.0  125.0  97.0  85.0  103.0  88.0  90.0  100.0  117.0  85.0  0.17269076305220885  430 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827309
2    0.908434
3    0.941767
4    0.956627
5    0.968273
6    0.976707
7    0.984337
8    0.986747
9    0.988755
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:31  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:31  1 min  8.069 sec  74679 obs/sec     1         1             10007      0.590434         1.11073             0.993803       0.293612                         0.589117           1.10261               0.993816         0.3
    2019-07-24 15:36:32  1 min  9.347 sec  72148 obs/sec     10        10            100070     0.414597         0.56827             0.996945       0.162451                         0.420889           0.581551              0.996843         0.172691
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0972213
C13         0.935397               0.935397             0.0909406
C12         0.910473               0.910473             0.0885174
C9          0.796693               0.796693             0.0774556
C8          0.765626               0.765626             0.0744352
C11         0.673624               0.673624             0.0654906
C10         0.654627               0.654627             0.0636437
C7          0.652282               0.652282             0.0634158
C16         0.622068               0.622068             0.0604783
C14         0.602431               0.602431             0.0585691
C6          0.583241               0.583241             0.0567035
C5          0.531443               0.531443             0.0516676
C4          0.451293               0.451293             0.0438753
C3          0.439861               0.439861             0.0427639
C1          0.349283               0.349283             0.0339578
C2          0.317465               0.317465             0.0308643
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_9

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.0017568850362010835  0.00043620355427265167  0.0         -0.010021882099064072  0.17642748355865479  0.13894912587763467  0.1144261360168457
    3        26       Softmax                      0.0   0.0   0.008553793167904517   0.025280393660068512    0.0         -0.17466995112888      0.4022955894470215   -0.9072140795462447  0.3845548629760742


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.18073533659178764
RMSE: 0.4251297879375046
LogLoss: 0.5744776543880561
Mean Per-Class Error: 0.16488191743779015
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    4.0    2.0    3.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    1.0    1.0    2.0    2.0    5.0    2.0    0.0810126582278481   32 / 395
0.0    343.0  0.0    5.0    2.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    1.0    15.0   4.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.10443864229765012  40 / 383
0.0    0.0    309.0  0.0    14.0   0.0    3.0    1.0    0.0    0.0    20.0   1.0    0.0    0.0    5.0    0.0    2.0    0.0    4.0    2.0    1.0    0.0    5.0    0.0    0.0    0.0    0.15803814713896458  58 / 367
2.0    20.0   0.0    351.0  0.0    0.0    1.0    3.0    0.0    2.0    1.0    0.0    7.0    4.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.12903225806451613  52 / 403
0.0    7.0    2.0    0.0    309.0  4.0    15.0   1.0    0.0    0.0    4.0    2.0    0.0    0.0    0.0    1.0    4.0    4.0    8.0    6.0    0.0    0.0    0.0    5.0    0.0    12.0   0.1953125            75 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    0.0    12.0   1.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    2.0    0.0    5.0    6.0    0.0    0.0    2.0    2.0    2.0    4.0    2.0    0.0    0.0    0.0    0.0    6.0    2.0    0.0    2.0    1.0    0.0    0.0    351.0  3.0    4.0    0.10913705583756345  43 / 394
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    0.0    3.0    24.0   2.0    16.0   1.0    0.0    339.0  0.0    0.13740458015267176  54 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    25.0   3.0    0.0    0.0    0.0    1.0    0.0    306.0  0.16393442622950818  60 / 366
396.0  515.0  376.0  427.0  395.0  360.0  333.0  301.0  341.0  355.0  381.0  364.0  408.0  389.0  385.0  403.0  355.0  405.0  362.0  399.0  402.0  362.0  416.0  419.0  386.0  368.0  0.16395081475557333  1,640 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836049
2    0.914626
3    0.945316
4    0.959912
5    0.971709
6    0.979006
7    0.983805
8    0.986904
9    0.990003
10   0.992802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18304682967085134
RMSE: 0.42783972427867345
LogLoss: 0.5842550586397437
Mean Per-Class Error: 0.16870429006992232
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0    3.0    0.0   0.06741573033707865  6 / 89
0.0   94.0   0.0   0.0    1.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    1.0   2.0    0.0   5.0    0.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.11320754716981132  12 / 106
0.0   0.0    66.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    2.0   1.0   1.0    0.0   1.0    0.0    0.0    0.0   0.1951219512195122   16 / 82
2.0   4.0    0.0   96.0   0.0   0.0   1.0   1.0   0.0   1.0    0.0   0.0   3.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   1.0    0.0   0.0    71.0  3.0   4.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   3.0   0.0    0.0   0.0    2.0    0.0    6.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    2.0   2.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    86.0   1.0    1.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0   6.0   0.0    6.0   1.0    0.0    91.0   0.0   0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
93.0  129.0  81.0  116.0  87.0  83.0  87.0  72.0  81.0  104.0  93.0  97.0  90.0  104.0  80.0  117.0  95.0  105.0  88.0  97.0  100.0  84.0  101.0  100.0  110.0  96.0  0.1670682730923695   416 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.832932
2    0.918072
3    0.948594
4    0.959839
5    0.970281
6    0.978313
7    0.981928
8    0.985542
9    0.988755
10   0.991968
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:43  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:43  19.734 sec  35739 obs/sec     1         1             10007      0.591881         1.08282             0.993773       0.278416                         0.590361           1.07521               0.99379          0.276305
    2019-07-24 15:35:45  21.520 sec  50009 obs/sec     10        10            100070     0.42513          0.574478            0.996787       0.163951                         0.42784            0.584255              0.996738         0.167068
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0871562
C13         0.931359               0.931359             0.0811737
C8          0.880942               0.880942             0.0767796
C9          0.86173                0.86173              0.0751052
C12         0.857931               0.857931             0.074774
C7          0.808384               0.808384             0.0704557
C11         0.720288               0.720288             0.0627776
C5          0.697744               0.697744             0.0608128
C6          0.675299               0.675299             0.0588566
C10         0.67448                0.67448              0.0587851
C14         0.643476               0.643476             0.056083
C4          0.637845               0.637845             0.0555922
C3          0.60976                0.60976              0.0531444
C16         0.590842               0.590842             0.0514956
C2          0.464217               0.464217             0.0404594
C1          0.419349               0.419349             0.0365489
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_32

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.001001272281570209  0.00027411547489464283  0.0         -0.004912009645295257  0.23263543844223022  0.2482555730085338   0.19748425483703613
    3        26       Softmax                      0.0   0.0   0.005740313481930151  0.017435774207115173    0.0         -0.28703038064895736   0.7125518321990967   -0.4793091815583853  0.2210802435874939


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17756221840704273
RMSE: 0.4213813218535472
LogLoss: 0.5805197458197079
Mean Per-Class Error: 0.16827571447570644
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    5.0    2.0    5.0    0.0    1.0    0.0    0.0    1.0    3.0    4.0    1.0    3.0    2.0    4.0    5.0    1.0    0.10379746835443038  41 / 395
0.0    317.0  0.0    4.0    1.0    0.0    4.0    5.0    3.0    0.0    4.0    0.0    0.0    0.0    3.0    3.0    0.0    10.0   19.0   0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.17015706806282724  65 / 382
0.0    0.0    306.0  0.0    13.0   1.0    13.0   1.0    0.0    0.0    12.0   3.0    0.0    0.0    3.0    0.0    1.0    1.0    1.0    5.0    3.0    0.0    4.0    0.0    0.0    0.0    0.16621253405994552  61 / 367
1.0    16.0   0.0    345.0  0.0    0.0    0.0    2.0    0.0    2.0    1.0    0.0    7.0    2.0    2.0    1.0    0.0    13.0   3.0    2.0    0.0    0.0    1.0    4.0    0.0    1.0    0.14392059553349876  58 / 403
0.0    0.0    3.0    0.0    309.0  5.0    18.0   0.0    0.0    0.0    3.0    9.0    0.0    0.0    0.0    0.0    2.0    3.0    11.0   4.0    0.0    0.0    0.0    4.0    0.0    13.0   0.1953125            75 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    1.0    3.0    0.0    0.0    2.0    0.0    356.0  0.0    0.0    0.0    0.05319148936170213  20 / 376
0.0    0.0    0.0    4.0    5.0    0.0    0.0    2.0    2.0    2.0    5.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    7.0    1.0    1.0    0.0    0.0    352.0  3.0    5.0    0.1065989847715736   42 / 394
2.0    0.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    12.0   0.0    19.0   1.0    1.0    343.0  0.0    0.1272264631043257   50 / 393
0.0    0.0    0.0    0.0    13.0   1.0    0.0    0.0    0.0    8.0    0.0    4.0    0.0    0.0    0.0    0.0    4.0    1.0    25.0   3.0    0.0    0.0    0.0    1.0    0.0    307.0  0.16348773841961853  60 / 367
404.0  422.0  357.0  408.0  405.0  372.0  356.0  317.0  341.0  357.0  358.0  389.0  397.0  381.0  400.0  367.0  323.0  451.0  396.0  401.0  405.0  377.0  418.0  439.0  397.0  365.0  0.16754973507947615  1,676 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83245
2    0.909727
3    0.940018
4    0.958512
5    0.970009
6    0.976407
7    0.982505
8    0.987704
9    0.991203
10   0.993702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18022397455429598
RMSE: 0.42452794319608217
LogLoss: 0.5884470626154495
Mean Per-Class Error: 0.17694656946821238
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18     19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    1.0   1.0    1.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   82.0   0.0   0.0    1.0   0.0   2.0   1.0   1.0   0.0    1.0   0.0    0.0   0.0    2.0   1.0    0.0   6.0    6.0    0.0   0.0    2.0   0.0    1.0    0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    64.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    1.0    2.0   1.0    0.0   1.0    0.0    0.0    0.0   0.21951219512195122  18 / 82
1.0   3.0    0.0   96.0   0.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0    3.0   1.0    0.0   1.0    0.0   2.0    1.0    0.0   0.0    0.0   0.0    2.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    71.0  3.0   5.0   0.0   0.0   0.0    1.0   2.0    0.0   0.0    0.0   0.0    0.0   1.0    4.0    1.0   0.0    0.0   0.0    2.0    0.0    7.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   89.0   0.0    0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0    2.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0    85.0   1.0    1.0   0.15                 15 / 100
1.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0    2.0   0.0    7.0   1.0    0.0    92.0   0.0   0.14018691588785046  15 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0    4.0    1.0   0.0    0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
95.0  105.0  76.0  113.0  91.0  83.0  89.0  84.0  82.0  108.0  92.0  105.0  86.0  100.0  84.0  106.0  84.0  117.0  103.0  95.0  102.0  86.0  100.0  101.0  112.0  91.0  0.17630522088353415  439 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.823695
2    0.909639
3    0.941767
4    0.956225
5    0.969478
6    0.976305
7    0.981124
8    0.986747
9    0.989558
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:23  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:23  59.875 sec        84092 obs/sec     1         1             10007      0.599015         1.13095             0.993623       0.296611                         0.598245           1.124                 0.993623         0.295984
    2019-07-24 15:36:24  1 min  0.788 sec  98688 obs/sec     10        10            100070     0.421381         0.58052             0.996844       0.16755                          0.424528           0.588447              0.996789         0.176305
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0949305
C13         0.884398               0.884398             0.0839564
C9          0.767223               0.767223             0.0728329
C7          0.761515               0.761515             0.072291
C8          0.756602               0.756602             0.0718247
C12         0.739788               0.739788             0.0702285
C11         0.714703               0.714703             0.0678472
C5          0.648721               0.648721             0.0615834
C16         0.588                  0.588                0.0558192
C6          0.5856                 0.5856               0.0555914
C3          0.585164               0.585164             0.0555499
C10         0.559226               0.559226             0.0530876
C14         0.542068               0.542068             0.0514588
C4          0.489866               0.489866             0.0465033
C2          0.456828               0.456828             0.0433669
C1          0.454315               0.454315             0.0431284
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_61

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017400245938858916  0.00043359550181776285  0.0         0.009094699579378585    0.47943317890167236  -0.04512628633722665  0.5122203826904297
    3        26       Softmax                 0.0   0.0   0.002194280300920162   0.0006009228527545929   0.0         -0.0020200984854454873  0.40937650203704834  -0.4877513929906741   0.1748342514038086


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16733732685876235
RMSE: 0.40906885344494553
LogLoss: 0.5693603293071031
Mean Per-Class Error: 0.1701810435684573
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    6.0    4.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    0.0    1.0    1.0    5.0    2.0    0.08354430379746836  33 / 395
0.0    332.0  0.0    2.0    3.0    1.0    3.0    12.0   1.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    17.0   4.0    0.0    0.0    0.0    2.0    2.0    1.0    1.0    0.13315926892950392  51 / 383
0.0    0.0    309.0  0.0    9.0    0.0    13.0   1.0    0.0    0.0    9.0    3.0    0.0    0.0    7.0    0.0    1.0    1.0    1.0    6.0    2.0    0.0    5.0    0.0    0.0    1.0    0.16032608695652173  59 / 368
2.0    22.0   0.0    337.0  0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    7.0    5.0    2.0    0.0    0.0    4.0    1.0    2.0    1.0    0.0    0.0    6.0    0.0    2.0    0.16169154228855723  65 / 402
0.0    7.0    0.0    0.0    310.0  3.0    9.0    2.0    1.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    11.0   2.0    1.0    3.0    0.0    0.0    0.0    3.0    0.0    24.0   0.19270833333333334  74 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    19.0   1.0    4.0    0.0    0.0    2.0    0.0    0.0    4.0    0.0    341.0  0.0    1.0    0.0    0.09308510638297872  35 / 376
0.0    2.0    0.0    5.0    6.0    0.0    0.0    4.0    5.0    0.0    8.0    3.0    0.0    0.0    2.0    0.0    5.0    2.0    1.0    1.0    2.0    0.0    0.0    335.0  7.0    6.0    0.14974619289340102  59 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    3.0    8.0    0.0    1.0    6.0    1.0    17.0   2.0    1.0    347.0  0.0    0.11704834605597965  46 / 393
1.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    17.0   3.0    0.0    0.0    0.0    0.0    0.0    320.0  0.12806539509536785  47 / 367
402.0  499.0  348.0  405.0  399.0  339.0  366.0  348.0  334.0  358.0  365.0  328.0  425.0  387.0  397.0  390.0  401.0  405.0  291.0  389.0  407.0  361.0  407.0  402.0  415.0  435.0  0.16924922523243027  1,693 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830751
2    0.909527
3    0.941817
4    0.958512
5    0.970009
6    0.976307
7    0.979606
8    0.982805
9    0.986604
10   0.989403

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17162135972832634
RMSE: 0.414272084176965
LogLoss: 0.5898143363139626
Mean Per-Class Error: 0.17258883211368098
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   0.0   1.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   0.0    0.0   2.0    0.0    0.07865168539325842  7 / 89
0.0   84.0   0.0   0.0    2.0   1.0   2.0   5.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0    6.0    2.0   0.0   0.0    0.0   1.0    1.0   1.0    0.0    0.20754716981132076  22 / 106
0.0   0.0    66.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    4.0   0.0    1.0    0.0    1.0   3.0   0.0    0.0   2.0    0.0   0.0    0.0    0.1951219512195122   16 / 82
1.0   3.0    0.0   95.0   0.0   0.0   0.0   5.0   0.0   0.0    0.0   0.0   3.0   1.0    0.0   0.0    0.0    1.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0    0.15178571428571427  17 / 112
0.0   2.0    0.0   0.0    72.0  1.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    4.0    1.0    1.0   1.0   0.0    0.0   0.0    1.0   0.0    10.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   1.0    0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   2.0   1.0   0.0    3.0   2.0   0.0   0.0    0.0   0.0    1.0    2.0    0.0   0.0   1.0    0.0   0.0    79.0  3.0    2.0    0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0    0.0    0.0   1.0   1.0    4.0   2.0    0.0   93.0   0.0    0.1308411214953271   14 / 107
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0    79.0   0.09195402298850575  8 / 87
92.0  122.0  70.0  114.0  88.0  76.0  90.0  93.0  82.0  102.0  90.0  89.0  92.0  104.0  81.0  115.0  106.0  105.0  74.0  94.0  106.0  79.0  100.0  94.0  117.0  115.0  0.1714859437751004   427 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.828514
2    0.908032
3    0.937349
4    0.955823
5    0.968675
6    0.975904
7    0.977912
8    0.981928
9    0.986747
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:07  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:07  1 min 43.855 sec  40188 obs/sec     1         1             10007      0.549035         0.982108            0.994644       0.26782                          0.547223           0.973286              0.994664         0.26988
    2019-07-24 15:37:09  1 min 45.769 sec  47180 obs/sec     10        10            100070     0.409069         0.56936             0.997026       0.169249                         0.414272           0.589814              0.996942         0.171486
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0862622
C15         0.972855               0.972855             0.0839207
C12         0.88512                0.88512              0.0763524
C9          0.869781               0.869781             0.0750293
C8          0.850885               0.850885             0.0733992
C7          0.80272                0.80272              0.0692444
C11         0.74981                0.74981              0.0646803
C14         0.692425               0.692425             0.0597301
C10         0.671562               0.671562             0.0579304
C5          0.666643               0.666643             0.0575061
C6          0.651349               0.651349             0.0561869
C3          0.639694               0.639694             0.0551814
C16         0.624542               0.624542             0.0538744
C4          0.551125               0.551125             0.0475412
C2          0.483434               0.483434             0.0417021
C1          0.480614               0.480614             0.0414588
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_36

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009441126022409208  0.000248586293309927  0.0         -0.016127310572329634  0.2350190281867981  0.24679734416043905   0.1955127716064453
    3        26       Softmax                      0.0   0.0   0.006616898835755609   0.020021699368953705  0.0         -0.31646196642360824   0.7267050743103027  -0.48385910429215667  0.23999083042144775


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17445809111574848
RMSE: 0.4176818060626396
LogLoss: 0.5773937927936743
Mean Per-Class Error: 0.16400599643900693
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    2.0    1.0    5.0    3.0    5.0    0.0    2.0    2.0    4.0    1.0    2.0    0.0    1.0    3.0    4.0    0.0    0.10379746835443038  41 / 395
0.0    338.0  0.0    3.0    1.0    0.0    1.0    6.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    0.0    10.0   9.0    0.0    0.0    2.0    0.0    2.0    3.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    318.0  1.0    9.0    0.0    2.0    0.0    0.0    0.0    16.0   4.0    0.0    0.0    4.0    0.0    1.0    0.0    6.0    1.0    0.0    0.0    6.0    0.0    0.0    0.0    0.1358695652173913   50 / 368
1.0    18.0   0.0    354.0  0.0    0.0    0.0    4.0    0.0    1.0    2.0    0.0    7.0    4.0    2.0    0.0    0.0    4.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.12158808933002481  49 / 403
0.0    9.0    4.0    0.0    311.0  11.0   15.0   0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    8.0    4.0    9.0    4.0    0.0    0.0    0.0    2.0    0.0    5.0    0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    6.0    0.0    4.0    0.0    0.0    7.0    0.0    0.0    8.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    2.0    0.0    4.0    11.0   1.0    0.0    2.0    4.0    1.0    4.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    350.0  2.0    2.0    0.10941475826972011  43 / 393
0.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    0.0    2.0    21.0   2.0    10.0   1.0    0.0    347.0  0.0    0.11704834605597965  46 / 393
2.0    1.0    0.0    0.0    19.0   0.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    34.0   3.0    0.0    0.0    0.0    2.0    0.0    289.0  0.2125340599455041   78 / 367
394.0  489.0  383.0  429.0  412.0  337.0  307.0  331.0  351.0  360.0  369.0  359.0  394.0  411.0  383.0  421.0  357.0  405.0  421.0  384.0  404.0  350.0  413.0  417.0  398.0  324.0  0.16315105468359492  1,632 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836849
2    0.914026
3    0.941817
4    0.957113
5    0.969009
6    0.975507
7    0.980806
8    0.985005
9    0.987704
10   0.990203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1791143381321549
RMSE: 0.4232190191049487
LogLoss: 0.5919725885649424
Mean Per-Class Error: 0.17466504141361658
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0    0.0    2.0    0.0   0.10112359550561797  9 / 89
0.0   86.0   0.0   0.0    1.0   0.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0   3.0    4.0    0.0   0.0    2.0   0.0    1.0    1.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    68.0  0.0    3.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0   2.0    0.0    0.0    0.0   0.17073170731707318  14 / 82
1.0   2.0    0.0   96.0   0.0   0.0   0.0   3.0   0.0   0.0    1.0   0.0   3.0   1.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0    2.0    0.0    1.0   0.14285714285714285  16 / 112
0.0   1.0    0.0   0.0    73.0  5.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    4.0    2.0   0.0    0.0   0.0    1.0    0.0    3.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   3.0    0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   2.0    5.0   1.0   0.0   1.0   0.0   1.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0    86.0   0.0    0.0   0.14                 14 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   5.0    0.0   0.0    0.0    3.0   0.0    2.0   1.0    0.0    96.0   0.0   0.102803738317757    11 / 107
2.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    5.0    1.0   0.0    0.0   0.0    1.0    0.0    69.0  0.20689655172413793  18 / 87
92.0  120.0  80.0  120.0  95.0  77.0  81.0  85.0  79.0  104.0  93.0  94.0  88.0  103.0  78.0  124.0  95.0  100.0  105.0  89.0  105.0  76.0  103.0  103.0  116.0  85.0  0.172289156626506    429 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.827711
2    0.91245
3    0.940161
4    0.956627
5    0.967068
6    0.972289
7    0.979518
8    0.983936
9    0.986345
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:28  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:28  1 min  5.043 sec  101080 obs/sec    1         1             10007      0.598674         1.13267             0.993631       0.294712                         0.59805            1.13664               0.993627         0.296787
    2019-07-24 15:36:29  1 min  5.907 sec  106684 obs/sec    10        10            100070     0.417682         0.577394            0.9969         0.163151                         0.423219           0.591973              0.996808         0.172289
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0865675
C13         0.889862               0.889862             0.0770332
C12         0.867271               0.867271             0.0750775
C8          0.84333                0.84333              0.073005
C7          0.83637                0.83637              0.0724025
C11         0.765541               0.765541             0.066271
C9          0.761007               0.761007             0.0658785
C5          0.736234               0.736234             0.063734
C6          0.699452               0.699452             0.0605498
C10         0.681417               0.681417             0.0589886
C14         0.668268               0.668268             0.0578503
C3          0.620969               0.620969             0.0537557
C16         0.60008                0.60008              0.0519474
C4          0.55117                0.55117              0.0477134
C1          0.532925               0.532925             0.046134
C2          0.497778               0.497778             0.0430914
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_56

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0014334319482713909  0.00039882666897028685  0.0         0.014817697628586757   0.4369192123413086  0.051261318118514254  0.4824904203414917
    3        26       Softmax                 0.0   0.0   0.0024437489243539926  0.0008400359656661749   0.0         -0.013293669968124259  0.5709636211395264  -0.5241524610983075   0.21798396110534668


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1701876998041059
RMSE: 0.41253811921337147
LogLoss: 0.5853887151331819
Mean Per-Class Error: 0.16566217270829334
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    5.0    0.0    3.0    0.0    4.0    1.0    0.0    1.0    4.0    0.0    2.0    0.0    4.0    4.0    0.08860759493670886  35 / 395
0.0    328.0  0.0    7.0    4.0    3.0    1.0    5.0    2.0    1.0    0.0    0.0    0.0    0.0    5.0    2.0    1.0    13.0   1.0    0.0    0.0    5.0    0.0    4.0    1.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    299.0  1.0    16.0   1.0    16.0   1.0    0.0    0.0    6.0    2.0    0.0    0.0    4.0    0.0    2.0    0.0    7.0    2.0    8.0    0.0    3.0    0.0    0.0    0.0    0.1875               69 / 368
0.0    21.0   0.0    339.0  0.0    0.0    0.0    8.0    0.0    1.0    2.0    0.0    4.0    6.0    5.0    2.0    0.0    6.0    4.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.1588089330024814   64 / 403
0.0    7.0    2.0    0.0    306.0  7.0    14.0   0.0    1.0    0.0    2.0    1.0    0.0    0.0    0.0    1.0    8.0    4.0    9.0    3.0    0.0    0.0    0.0    4.0    0.0    14.0   0.2010443864229765   77 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0    0.0    5.0    1.0    0.0    0.0    0.0    13.0   0.0    0.0    1.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    4.0    0.0    3.0    8.0    0.0    2.0    5.0    2.0    0.0    11.0   2.0    0.0    0.0    0.0    0.0    5.0    5.0    14.0   9.0    1.0    0.0    0.0    313.0  7.0    3.0    0.20558375634517767  81 / 394
1.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    1.0    12.0   0.0    14.0   1.0    0.0    357.0  1.0    0.0916030534351145   36 / 393
1.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    16.0   6.0    0.0    0.0    0.0    0.0    0.0    318.0  0.13114754098360656  48 / 366
390.0  529.0  322.0  413.0  423.0  363.0  410.0  331.0  326.0  366.0  331.0  345.0  386.0  375.0  403.0  370.0  371.0  441.0  328.0  393.0  413.0  372.0  423.0  374.0  421.0  384.0  0.16495051484554635  1,650 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83505
2    0.908727
3    0.939718
4    0.954014
5    0.964411
6    0.971808
7    0.977607
8    0.980906
9    0.984505
10   0.987804

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17433414990035626
RMSE: 0.4175334117173813
LogLoss: 0.6001968405285861
Mean Per-Class Error: 0.16764840398858594
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   2.0    0.0   0.0    0.0   2.0    1.0   0.06741573033707865   6 / 89
0.0   88.0   0.0   0.0    2.0   1.0   1.0    2.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    0.0   4.0    0.0   0.0   0.0    2.0   0.0    1.0   1.0    0.0   0.16981132075471697   18 / 106
0.0   0.0    67.0  0.0    1.0   0.0   4.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   1.0   2.0    0.0   1.0    0.0   0.0    0.0   0.18292682926829268   15 / 82
0.0   2.0    0.0   93.0   0.0   0.0   0.0    5.0   0.0   0.0    1.0   0.0   2.0   1.0    2.0   2.0    0.0   1.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0    1.0   0.16964285714285715   19 / 112
0.0   1.0    0.0   0.0    74.0  5.0   5.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    5.0   0.23711340206185566   23 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   2.0    0.0   1.0    3.0   0.0   1.0    3.0   0.0   0.0    5.0   1.0   0.0   0.0    0.0   0.0    0.0   2.0    3.0   2.0   0.0    0.0   0.0    73.0  3.0    1.0   0.27                  27 / 100
0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   2.0   0.0    4.0   1.0    0.0   98.0   0.0   0.08411214953271028   9 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   2.0   0.0    0.0   0.0    0.0   0.0    76.0  0.12643678160919541   11 / 87
91.0  138.0  72.0  112.0  90.0  84.0  104.0  90.0  76.0  106.0  84.0  90.0  84.0  101.0  82.0  112.0  87.0  111.0  85.0  93.0  106.0  80.0  109.0  87.0  121.0  95.0  0.16666666666666666   415 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.833333
2    0.905622
3    0.935341
4    0.951004
5    0.963454
6    0.970683
7    0.977108
8    0.980321
9    0.984739
10   0.98755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:02  1 min 38.909 sec  76389 obs/sec     1         1             10007      0.583569         1.09834             0.993947       0.289213                         0.581115           1.08682               0.993983         0.291566
    2019-07-24 15:37:03  1 min 40.090 sec  77573 obs/sec     10        10            100070     0.412538         0.585389            0.996975       0.164951                         0.417533           0.600197              0.996894         0.166667
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0908814
C12         0.910821               0.910821             0.0827767
C13         0.904438               0.904438             0.0821966
C9          0.828399               0.828399             0.075286
C8          0.817148               0.817148             0.0742635
C7          0.786183               0.786183             0.0714494
C11         0.738833               0.738833             0.0671461
C10         0.723256               0.723256             0.0657305
C14         0.680428               0.680428             0.0618382
C6          0.636692               0.636692             0.0578634
C16         0.629035               0.629035             0.0571675
C5          0.590427               0.590427             0.0536588
C3          0.531386               0.531386             0.0482931
C1          0.444908               0.444908             0.0404338
C4          0.429392               0.429392             0.0390237
C2          0.352013               0.352013             0.0319914
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_69

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.001960303935376828  0.00047542620450258255  0.0         0.011388764726754541    0.42182326316833496  0.06520557959345673  0.492928147315979
    3        26       Softmax                 0.0   0.0   0.002185940805475184  0.000584976514801383    0.0         -0.0007376880871878309  0.2914849519729614   -0.607086261396586   0.21777600049972534


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17426167136003015
RMSE: 0.41744660899333
LogLoss: 0.6050768169560372
Mean Per-Class Error: 0.17793446390842996
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    1.0    6.0    0.0    2.0    0.0    0.0    3.0    3.0    0.0    1.0    1.0    2.0    1.0    5.0    3.0    0.09113924050632911  36 / 395
0.0    325.0  0.0    1.0    3.0    0.0    1.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    38.0   2.0    0.0    0.0    1.0    1.0    1.0    1.0    1.0    0.1514360313315927   58 / 383
0.0    1.0    301.0  0.0    13.0   0.0    12.0   1.0    0.0    0.0    18.0   1.0    0.0    0.0    3.0    0.0    2.0    0.0    3.0    7.0    2.0    0.0    4.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
2.0    13.0   0.0    335.0  0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    5.0    5.0    3.0    2.0    2.0    12.0   1.0    2.0    1.0    0.0    0.0    7.0    0.0    3.0    0.1687344913151365   68 / 403
0.0    8.0    1.0    0.0    307.0  4.0    11.0   0.0    1.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    9.0    5.0    8.0    9.0    0.0    0.0    0.0    2.0    0.0    13.0   0.19843342036553524  76 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0    11.0   0.0    5.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    3.0    0.0    2.0    7.0    1.0    1.0    3.0    2.0    1.0    12.0   2.0    0.0    0.0    0.0    0.0    8.0    2.0    3.0    7.0    1.0    0.0    0.0    331.0  5.0    3.0    0.1598984771573604   63 / 394
0.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    2.0    15.0   3.0    7.0    1.0    1.0    347.0  0.0    0.11704834605597965  46 / 393
2.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    19.0   4.0    0.0    0.0    0.0    1.0    0.0    318.0  0.13114754098360656  48 / 366
399.0  470.0  340.0  399.0  397.0  320.0  347.0  322.0  325.0  367.0  379.0  351.0  414.0  365.0  367.0  385.0  431.0  517.0  289.0  430.0  391.0  352.0  441.0  396.0  404.0  405.0  0.17704688593421974  1,771 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822953
2    0.902729
3    0.936619
4    0.952514
5    0.964911
6    0.972208
7    0.978706
8    0.982705
9    0.986604
10   0.990003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18000078653079468
RMSE: 0.4242649956463468
LogLoss: 0.6256733655565685
Mean Per-Class Error: 0.1852907772161896
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19     20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0    0.0   0.0   1.0    0.0   3.0    0.0    0.0898876404494382   8 / 89
0.0   86.0   0.0   0.0    2.0   0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0    11.0   0.0   0.0    0.0   1.0   1.0    1.0   0.0    0.0    0.18867924528301888  20 / 106
0.0   0.0    65.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0    2.0   3.0    0.0   0.0   2.0    0.0   0.0    0.0    0.2073170731707317   17 / 82
1.0   2.0    0.0   92.0   0.0   0.0   0.0   5.0   0.0   0.0    0.0   0.0   2.0   2.0    0.0   2.0    2.0    1.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0    1.0    0.17857142857142858  20 / 112
0.0   2.0    0.0   0.0    72.0  2.0   2.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    3.0    1.0    3.0   4.0    0.0   0.0   0.0    0.0   0.0    6.0    0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0    1.0   0.0    0.0    1.0    0.0   0.0    0.0   0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   1.0    0.0   2.0    3.0   1.0   0.0   1.0   0.0   0.0    6.0   2.0   0.0   0.0    0.0   0.0    1.0    1.0    0.0   1.0    0.0   0.0   0.0    79.0  1.0    1.0    0.21                 21 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    4.0    0.0    0.0   3.0    1.0   3.0   1.0    0.0   93.0   0.0    0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0    2.0   1.0    0.0   0.0   0.0    0.0   0.0    78.0   0.10344827586206896  9 / 87
94.0  113.0  71.0  113.0  91.0  71.0  83.0  86.0  76.0  100.0  96.0  95.0  95.0  101.0  77.0  112.0  110.0  132.0  71.0  102.0  98.0  78.0  108.0  92.0  115.0  110.0  0.18393574297188756  458 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816064
2    0.901205
3    0.938554
4    0.953012
5    0.962651
6    0.970281
7    0.97992
8    0.984337
9    0.987149
10   0.990361
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:17  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:17  1 min 53.941 sec  29871 obs/sec     1         1             10007      0.540776         0.972273            0.994802       0.26552                          0.54084            0.967701              0.994788         0.26747
    2019-07-24 15:37:20  1 min 57.166 sec  28615 obs/sec     10        10            100070     0.417447         0.605077            0.996903       0.177047                         0.424265           0.625673              0.996793         0.183936
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0895692
C15         0.992671               0.992671             0.0889128
C9          0.874765               0.874765             0.078352
C12         0.860468               0.860468             0.0770714
C8          0.786198               0.786198             0.0704191
C7          0.785227               0.785227             0.0703321
C11         0.753133               0.753133             0.0674575
C14         0.68071                0.68071              0.0609706
C10         0.652795               0.652795             0.0584704
C6          0.618835               0.618835             0.0554285
C16         0.595014               0.595014             0.053295
C5          0.585318               0.585318             0.0524265
C3          0.574402               0.574402             0.0514487
C4          0.555493               0.555493             0.049755
C2          0.436806               0.436806             0.0391244
C1          0.412716               0.412716             0.0369667
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_2

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.002044208235389533  0.00045528810005635023  0.0         0.006009810301595905   0.4236745834350586   0.00915691950783915  0.5002546310424805
    3        26       Softmax                 0.0   0.0   0.002190157757782939  0.000549377640709281    0.0         0.0008964298525750809  0.28908777236938477  -0.5836700609502692  0.2204897403717041


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17544020393177606
RMSE: 0.41885582714315445
LogLoss: 0.6089995578331029
Mean Per-Class Error: 0.17773730672151697
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    6.0    5.0    1.0    5.0    0.0    1.0    0.0    0.0    1.0    5.0    0.0    1.0    1.0    1.0    3.0    6.0    0.0    0.09367088607594937  37 / 395
0.0    331.0  0.0    6.0    4.0    0.0    2.0    11.0   2.0    0.0    0.0    1.0    0.0    0.0    1.0    3.0    0.0    12.0   5.0    0.0    0.0    2.0    0.0    2.0    1.0    0.0    0.13577023498694518  52 / 383
0.0    0.0    302.0  0.0    15.0   2.0    9.0    2.0    0.0    0.0    20.0   0.0    0.0    0.0    2.0    0.0    2.0    0.0    7.0    2.0    3.0    0.0    1.0    0.0    0.0    0.0    0.1771117166212534   65 / 367
1.0    23.0   0.0    341.0  0.0    1.0    0.0    6.0    0.0    5.0    1.0    0.0    6.0    5.0    2.0    3.0    0.0    4.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.15384615384615385  62 / 403
0.0    6.0    1.0    0.0    314.0  6.0    11.0   1.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    0.0    6.0    3.0    14.0   5.0    0.0    0.0    0.0    3.0    0.0    10.0   0.18229166666666666  70 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    17.0   0.0    0.0    0.0    0.0    13.0   0.0    1.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    4.0    0.0    6.0    6.0    1.0    0.0    2.0    3.0    2.0    8.0    4.0    0.0    0.0    3.0    0.0    5.0    2.0    4.0    0.0    1.0    0.0    0.0    339.0  2.0    2.0    0.13959390862944163  55 / 394
0.0    0.0    0.0    3.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    2.0    15.0   2.0    11.0   1.0    1.0    343.0  0.0    0.1272264631043257   50 / 393
0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    24.0   4.0    0.0    0.0    0.0    0.0    0.0    303.0  0.17438692098092642  64 / 367
384.0  508.0  355.0  440.0  425.0  381.0  316.0  377.0  335.0  376.0  403.0  375.0  423.0  397.0  374.0  393.0  360.0  371.0  356.0  370.0  387.0  375.0  374.0  402.0  407.0  339.0  0.17684694591622513  1,769 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.823153
2    0.89913
3    0.93292
4    0.953014
5    0.964811
6    0.972008
7    0.978806
8    0.983305
9    0.987004
10   0.989503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18128742892096222
RMSE: 0.4257786149173796
LogLoss: 0.6289624611595639
Mean Per-Class Error: 0.18267010531506825
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11     12    13     14    15     16    17    18    19    20    21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   1.0   0.0   2.0   3.0    0.0   0.10112359550561797  9 / 89
0.0   85.0   0.0   1.0    3.0    0.0   0.0   6.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0    0.0   3.0   2.0   0.0   0.0   2.0   0.0   1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    66.0  0.0    3.0    0.0   3.0   1.0   0.0   0.0    3.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0   3.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.1951219512195122   16 / 82
1.0   3.0    0.0   93.0   0.0    0.0   0.0   4.0   0.0   1.0    1.0   0.0    2.0   1.0    0.0   3.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    1.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    75.0   4.0   4.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   4.0   2.0   0.0   0.0   0.0   0.0   0.0    5.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   3.0   0.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0   83.0  0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0   0.0    0.0   3.0    4.0    0.0   0.0   1.0   0.0   1.0    3.0   2.0    0.0   0.0    1.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0   0.0   81.0  1.0    1.0   0.19                 19 / 100
0.0   0.0    0.0   1.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    3.0   0.0   0.0   4.0   0.0   3.0   1.0   0.0   93.0   0.0   0.1308411214953271   14 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   5.0    0.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   4.0   1.0   0.0   0.0   0.0   0.0   0.0    71.0  0.1839080459770115   16 / 87
85.0  121.0  76.0  123.0  104.0  91.0  75.0  99.0  80.0  107.0  96.0  102.0  98.0  101.0  78.0  114.0  92.0  95.0  94.0  87.0  98.0  86.0  90.0  93.0  119.0  86.0  0.1823293172690763   454 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.817671
2    0.898394
3    0.928916
4    0.948996
5    0.960241
6    0.969076
7    0.978313
8    0.982731
9    0.986747
10   0.989157
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:28  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:29  5.569 sec   27267 obs/sec     1         1             10007      0.543311         0.984477            0.994754       0.26812                          0.544188           0.986487              0.994723         0.274699
    2019-07-24 15:35:33  9.952 sec   21364 obs/sec     10        10            100070     0.418856         0.609               0.996882       0.176847                         0.425779           0.628962              0.99677          0.182329
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.088238
C15         0.995406               0.995406             0.0878327
C9          0.899226               0.899226             0.0793459
C12         0.867131               0.867131             0.076514
C8          0.799622               0.799622             0.0705571
C7          0.787586               0.787586             0.069495
C11         0.768711               0.768711             0.0678295
C10         0.699506               0.699506             0.0617231
C14         0.648005               0.648005             0.0571787
C6          0.640083               0.640083             0.0564797
C5          0.601528               0.601528             0.0530777
C3          0.596423               0.596423             0.0526272
C4          0.577714               0.577714             0.0509763
C16         0.562072               0.562072             0.0495961
C2          0.46058                0.46058              0.0406407
C1          0.429388               0.429388             0.0378884
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_52

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009071854415196867  0.00022074359003454447  0.0         -0.013136817154844493  0.23574864864349365  0.11905792592804565  0.1905636191368103
    3        26       Softmax                      0.0   0.0   0.006180515483160539   0.01922646164894104     0.0         -0.2953000717858721    0.7456502914428711   -0.5977192012603246  0.33147716522216797


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.19929571100391394
RMSE: 0.4464254820279796
LogLoss: 0.6375218039229076
Mean Per-Class Error: 0.17667914756529854
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    2.0    1.0    5.0    3.0    1.0    0.0    0.0    1.0    8.0    1.0    1.0    0.0    2.0    0.0    8.0    1.0    0.09873417721518987  39 / 395
1.0    327.0  0.0    5.0    8.0    7.0    1.0    3.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    17.0   2.0    0.0    0.0    2.0    0.0    2.0    2.0    0.0    0.1462140992167102   56 / 383
0.0    0.0    306.0  0.0    17.0   0.0    7.0    0.0    0.0    0.0    16.0   0.0    2.0    0.0    4.0    0.0    1.0    0.0    6.0    1.0    1.0    0.0    7.0    0.0    0.0    0.0    0.16847826086956522  62 / 368
2.0    17.0   0.0    328.0  0.0    0.0    2.0    5.0    0.0    2.0    0.0    0.0    3.0    5.0    5.0    2.0    0.0    14.0   5.0    0.0    1.0    0.0    0.0    8.0    0.0    3.0    0.18407960199004975  74 / 402
0.0    7.0    2.0    0.0    322.0  4.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    7.0    5.0    6.0    4.0    0.0    0.0    0.0    5.0    0.0    11.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    10.0   2.0    1.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    349.0  0.0    0.0    0.0    0.06933333333333333  26 / 375
0.0    2.0    0.0    2.0    8.0    0.0    0.0    0.0    2.0    2.0    9.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    5.0    6.0    1.0    0.0    0.0    346.0  5.0    3.0    0.1218274111675127   48 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    10.0   0.0    2.0    10.0   2.0    16.0   1.0    0.0    342.0  0.0    0.1297709923664122   51 / 393
1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    13.0   0.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    29.0   3.0    0.0    0.0    0.0    0.0    0.0    300.0  0.18032786885245902  66 / 366
399.0  485.0  355.0  387.0  432.0  359.0  323.0  310.0  349.0  362.0  378.0  364.0  409.0  402.0  397.0  370.0  355.0  458.0  345.0  383.0  382.0  363.0  437.0  411.0  426.0  362.0  0.17594721583524942  1,760 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.824053
2    0.90163
3    0.931321
4    0.950815
5    0.964511
6    0.973408
7    0.979106
8    0.983805
9    0.987204
10   0.990203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20082366533988932
RMSE: 0.4481335351654564
LogLoss: 0.6386586922474632
Mean Per-Class Error: 0.1786371533764018
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    0.0    4.0    0.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   1.0    3.0    2.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   7.0    0.0   0.0   0.0   2.0   0.0    1.0    2.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    67.0  0.0    4.0    0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   2.0    0.0    0.0    0.0   0.18292682926829268  15 / 82
2.0   0.0    0.0   93.0   0.0    0.0   1.0   2.0   0.0   1.0    0.0   0.0   1.0   3.0    1.0   1.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    78.0   3.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    2.0   1.0   0.0   0.0   0.0    2.0    0.0    4.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    3.0    0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0   0.0   0.0    88.0   2.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    5.0   0.0    0.0   2.0   0.0   5.0   1.0    0.0    92.0   0.0   0.14018691588785046  15 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    4.0   1.0   0.0   0.0   0.0    0.0    0.0    71.0  0.1839080459770115   16 / 87
97.0  116.0  74.0  108.0  101.0  88.0  78.0  78.0  85.0  103.0  93.0  96.0  90.0  109.0  85.0  107.0  94.0  113.0  83.0  89.0  95.0  83.0  104.0  105.0  124.0  92.0  0.1783132530120482   444 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.821687
2    0.903213
3    0.932129
4    0.95261
5    0.966265
6    0.972289
7    0.979116
8    0.984337
9    0.987149
10   0.990361
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:57  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:57  1 min 34.357 sec  95304 obs/sec     1         1             10007      0.650962         1.2697              0.992468       0.333                            0.649552           1.26262               0.992482         0.332932
    2019-07-24 15:36:58  1 min 35.172 sec  111935 obs/sec    10        10            100070     0.446425         0.637522            0.996457       0.175947                         0.448134           0.638659              0.996422         0.178313
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0869572
C13         0.960281               0.960281             0.0835033
C9          0.879481               0.879481             0.0764772
C7          0.838311               0.838311             0.0728971
C8          0.82021                0.82021              0.0713232
C11         0.814029               0.814029             0.0707857
C12         0.77511                0.77511              0.0674014
C6          0.686042               0.686042             0.0596563
C10         0.665034               0.665034             0.0578295
C5          0.663937               0.663937             0.0577341
C14         0.649438               0.649438             0.0564733
C3          0.601876               0.601876             0.0523375
C4          0.576394               0.576394             0.0501216
C16         0.573087               0.573087             0.049834
C2          0.510243               0.510243             0.0443693
C1          0.48644                0.48644              0.0422994
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_58

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009354634024703046  0.00023229210637509823  0.0         -0.010561852357653834  0.23593062162399292  0.11812270981565591  0.21334165334701538
    3        26       Softmax                      0.0   0.0   0.007243841904570358   0.024773485958576202    0.0         -0.3121450058604471    0.7371578216552734   -0.6125065908728246  0.37015295028686523


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20287362443989776
RMSE: 0.4504149469543587
LogLoss: 0.6479045618125608
Mean Per-Class Error: 0.1784318243807054
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    3.0    2.0    6.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    4.0    1.0    1.0    0.0    5.0    0.0    0.09367088607594937  37 / 395
0.0    330.0  0.0    4.0    4.0    0.0    4.0    12.0   2.0    1.0    2.0    1.0    0.0    0.0    3.0    2.0    1.0    11.0   2.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.13612565445026178  52 / 382
0.0    0.0    295.0  0.0    11.0   1.0    23.0   1.0    0.0    0.0    18.0   0.0    0.0    0.0    6.0    0.0    5.0    0.0    2.0    2.0    4.0    0.0    0.0    0.0    0.0    0.0    0.1983695652173913   73 / 368
0.0    20.0   0.0    343.0  0.0    0.0    0.0    6.0    0.0    6.0    1.0    0.0    4.0    6.0    4.0    0.0    0.0    1.0    2.0    1.0    2.0    0.0    0.0    6.0    0.0    1.0    0.1488833746898263   60 / 403
0.0    12.0   1.0    0.0    302.0  1.0    25.0   0.0    0.0    0.0    7.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    8.0    1.0    0.0    0.0    0.0    1.0    0.0    18.0   0.21148825065274152  81 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    13.0   0.0    0.0    0.0    0.0    11.0   0.0    3.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    3.0    1.0    2.0    9.0    0.0    0.0    0.0    2.0    2.0    8.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    4.0    4.0    0.0    0.0    343.0  6.0    3.0    0.12944162436548223  51 / 394
1.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    2.0    0.0    0.0    5.0    0.0    4.0    10.0   4.0    5.0    1.0    1.0    348.0  0.0    0.11224489795918367  44 / 392
1.0    0.0    0.0    1.0    6.0    0.0    1.0    0.0    0.0    22.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    17.0   1.0    0.0    0.0    0.0    2.0    0.0    313.0  0.14713896457765668  54 / 367
406.0  509.0  325.0  408.0  404.0  349.0  419.0  360.0  343.0  382.0  376.0  354.0  412.0  389.0  415.0  373.0  336.0  384.0  322.0  371.0  412.0  359.0  405.0  400.0  400.0  390.0  0.17744676597020895  1,775 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822553
2    0.895531
3    0.929521
4    0.948215
5    0.962111
6    0.971409
7    0.978206
8    0.982805
9    0.986404
10   0.990203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20398238486473075
RMSE: 0.45164409092196783
LogLoss: 0.6509524267669605
Mean Per-Class Error: 0.17852299667332097
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   1.0    0.0   3.0    0.0    0.07865168539325842  7 / 89
0.0   83.0   0.0   1.0    3.0   0.0   4.0    4.0   1.0   0.0    1.0   0.0   0.0   0.0    2.0   0.0    1.0   3.0    1.0   0.0   0.0    1.0   0.0    1.0   0.0    0.0    0.2169811320754717   23 / 106
0.0   0.0    61.0  0.0    2.0   0.0   6.0    0.0   0.0   0.0    4.0   0.0   0.0   0.0    3.0   0.0    2.0   0.0    2.0   1.0   1.0    0.0   0.0    0.0   0.0    0.0    0.25609756097560976  21 / 82
0.0   4.0    0.0   98.0   0.0   0.0   0.0    1.0   0.0   3.0    0.0   0.0   2.0   2.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.125                14 / 112
0.0   2.0    0.0   0.0    72.0  1.0   6.0    0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0   0.0   0.0    0.0   0.0    0.0   0.0    9.0    0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    4.0   0.0   0.0    0.0   0.0   0.0    4.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    86.0  2.0    1.0    0.14                 14 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    3.0   0.0    0.0   3.0   1.0    2.0   1.0    0.0   95.0   0.0    0.11214953271028037  12 / 107
1.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   6.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    77.0   0.11494252873563218  10 / 87
95.0  117.0  67.0  117.0  95.0  78.0  112.0  92.0  79.0  112.0  95.0  93.0  90.0  101.0  82.0  108.0  91.0  101.0  82.0  86.0  102.0  79.0  101.0  95.0  116.0  104.0  0.17710843373493976  441 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822892
2    0.892771
3    0.929317
4    0.950602
5    0.962651
6    0.971888
7    0.976305
8    0.97992
9    0.985542
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:05  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:05  1 min 41.582 sec  120566 obs/sec    1         1             10007      0.657854         1.31877             0.992307       0.357593                         0.656556           1.31622               0.992319         0.359438
    2019-07-24 15:37:05  1 min 42.248 sec  136707 obs/sec    10        10            100070     0.450415         0.647905            0.996394       0.177447                         0.451644           0.650952              0.996365         0.177108
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0958071
C13         0.906719               0.906719             0.0868701
C9          0.790125               0.790125             0.0756996
C7          0.770029               0.770029             0.0737742
C12         0.732014               0.732014             0.0701321
C8          0.716257               0.716257             0.0686225
C11         0.701186               0.701186             0.0671786
C5          0.650158               0.650158             0.0622897
C6          0.622203               0.622203             0.0596115
C10         0.586896               0.586896             0.0562288
C14         0.584559               0.584559             0.0560049
C4          0.531089               0.531089             0.0508821
C3          0.527802               0.527802             0.0505671
C16         0.486859               0.486859             0.0466446
C2          0.44126                0.44126              0.0422758
C1          0.390485               0.390485             0.0374112
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_44

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -----------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009670227463516312  0.00023896194761618972  0.0         -0.012800799718178268  0.23912584781646729  0.1321524020173599   0.193071186542511
    3        26       Softmax                      0.0   0.0   0.006717624606083588   0.02585894614458084     0.0         -0.2771714095672975    0.7221274375915527   -0.5821234624259138  0.395635724067688


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20436870491807582
RMSE: 0.45207157057049696
LogLoss: 0.6533168418316704
Mean Per-Class Error: 0.18257522727029687
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    6.0    3.0    4.0    0.0    2.0    0.0    0.0    0.0    5.0    0.0    3.0    1.0    2.0    4.0    3.0    0.0    0.10406091370558376  41 / 394
0.0    332.0  0.0    5.0    3.0    0.0    9.0    3.0    1.0    0.0    1.0    0.0    1.0    0.0    1.0    3.0    0.0    8.0    10.0   0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.13315926892950392  51 / 383
0.0    0.0    306.0  0.0    23.0   0.0    6.0    0.0    0.0    0.0    15.0   0.0    2.0    0.0    3.0    0.0    1.0    0.0    3.0    3.0    3.0    0.0    3.0    0.0    0.0    0.0    0.16847826086956522  62 / 368
3.0    31.0   0.0    329.0  0.0    0.0    1.0    7.0    0.0    2.0    0.0    0.0    6.0    3.0    2.0    1.0    1.0    5.0    3.0    2.0    0.0    0.0    0.0    6.0    0.0    0.0    0.18159203980099503  73 / 402
0.0    14.0   2.0    0.0    311.0  1.0    18.0   2.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    5.0    6.0    0.0    0.0    0.0    7.0    0.0    7.0    0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    1.0    0.0    26.0   0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    340.0  0.0    0.0    0.0    0.09574468085106383  36 / 376
0.0    4.0    0.0    6.0    9.0    0.0    0.0    3.0    2.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    6.0    3.0    2.0    0.0    0.0    338.0  5.0    0.0    0.14213197969543148  56 / 394
1.0    0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    9.0    0.0    3.0    17.0   2.0    14.0   2.0    0.0    337.0  0.0    0.14030612244897958  55 / 392
2.0    0.0    0.0    0.0    15.0   0.0    1.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    32.0   5.0    0.0    0.0    0.0    4.0    0.0    292.0  0.20435967302452315  75 / 367
390.0  547.0  347.0  410.0  410.0  329.0  374.0  340.0  346.0  343.0  394.0  343.0  460.0  373.0  363.0  407.0  338.0  397.0  398.0  383.0  389.0  380.0  409.0  417.0  393.0  323.0  0.18184544636609018  1,819 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.818155
2    0.896331
3    0.928022
4    0.948915
5    0.961012
6    0.969209
7    0.977507
8    0.982105
9    0.986604
10   0.989303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20616662493006863
RMSE: 0.4540557509051819
LogLoss: 0.6565097016964122
Mean Per-Class Error: 0.18068151757314024
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12     13     14    15     16    17    18     19    20    21    22    23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0    0.0   0.0    0.0   0.0   1.0    0.0   1.0   0.0   1.0   1.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   1.0    3.0    0.0   2.0   1.0   0.0   0.0   1.0   0.0   1.0    0.0    1.0   1.0    0.0   2.0   4.0    0.0   0.0   4.0   0.0   1.0   0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    64.0  0.0    4.0    0.0   3.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0    2.0   0.0    1.0   0.0   2.0    2.0   1.0   0.0   1.0   0.0   0.0    0.0   0.21951219512195122  18 / 82
2.0   5.0    0.0   95.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0   2.0    2.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.15178571428571427  17 / 112
0.0   2.0    0.0   0.0    77.0   1.0   4.0   1.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0    0.0   1.0   1.0    3.0   0.0   0.0   0.0   2.0   0.0    3.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   3.0   0.0   0.0   0.0   0.0   5.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   84.0  0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   2.0    0.0   2.0    4.0    0.0   0.0   2.0   0.0   0.0   4.0   0.0   0.0    0.0    0.0   0.0    2.0   0.0   1.0    0.0   0.0   0.0   0.0   81.0  2.0    0.0   0.19                 19 / 100
1.0   0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    4.0   0.0   0.0    4.0   1.0   4.0   2.0   0.0   90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   3.0   0.0   1.0   0.0    0.0    0.0   0.0    0.0   0.0   6.0    2.0   0.0   0.0   0.0   0.0   0.0    70.0  0.19540229885057472  17 / 87
93.0  128.0  73.0  117.0  100.0  79.0  92.0  90.0  83.0  96.0  94.0  91.0  105.0  101.0  76.0  114.0  91.0  97.0  104.0  94.0  98.0  91.0  99.0  97.0  105.0  82.0  0.17951807228915662  447 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.820482
2    0.895181
3    0.930121
4    0.950201
5    0.962249
6    0.96988
7    0.97751
8    0.981526
9    0.985542
10   0.988755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:39  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:39  1 min 15.878 sec  117729 obs/sec    1         1             10007      0.647455         1.26165             0.992547       0.325802                         0.647534           1.25782               0.992529         0.331727
    2019-07-24 15:36:40  1 min 16.581 sec  130130 obs/sec    10        10            100070     0.452072         0.653317            0.996367       0.181845                         0.454056           0.65651               0.996326         0.179518
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0889279
C15         0.985033               0.985033             0.087597
C7          0.865617               0.865617             0.0769776
C8          0.843216               0.843216             0.0749854
C9          0.804939               0.804939             0.0715815
C5          0.801958               0.801958             0.0713165
C12         0.782863               0.782863             0.0696184
C11         0.743965               0.743965             0.0661592
C10         0.681865               0.681865             0.0606368
C14         0.644167               0.644167             0.0572844
C4          0.571464               0.571464             0.0508191
C3          0.56613                0.56613              0.0503447
C6          0.563409               0.563409             0.0501028
C16         0.539151               0.539151             0.0479456
C2          0.431005               0.431005             0.0383284
C1          0.420279               0.420279             0.0373746
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_3

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.000932209989173316  0.00022468145471066236  0.0         -0.01621685063459921  0.23543626070022583  0.1170330526176327   0.1715739369392395
    3        26       Softmax                      0.0   0.0   0.006326711484549518  0.01836509257555008     0.0         -0.2899541676568053   0.7408356666564941   -0.5970353563309208  0.38954830169677734


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20594387930763192
RMSE: 0.45381040017570323
LogLoss: 0.6607112205923505
Mean Per-Class Error: 0.18683739136872538
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    6.0    2.0    3.0    0.0    5.0    0.0    1.0    0.0    6.0    0.0    1.0    2.0    2.0    3.0    4.0    0.0    0.09620253164556962  38 / 395
0.0    328.0  0.0    7.0    1.0    7.0    1.0    3.0    2.0    0.0    2.0    1.0    1.0    0.0    5.0    3.0    0.0    10.0   8.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    302.0  1.0    13.0   0.0    6.0    1.0    0.0    0.0    25.0   0.0    0.0    0.0    3.0    0.0    3.0    0.0    5.0    4.0    2.0    0.0    3.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
2.0    23.0   0.0    344.0  0.0    0.0    1.0    3.0    0.0    2.0    0.0    0.0    6.0    4.0    5.0    0.0    0.0    5.0    3.0    0.0    1.0    0.0    0.0    3.0    0.0    1.0    0.14640198511166252  59 / 403
0.0    6.0    0.0    0.0    311.0  2.0    13.0   1.0    0.0    0.0    5.0    1.0    0.0    0.0    0.0    3.0    4.0    4.0    13.0   7.0    0.0    0.0    0.0    3.0    0.0    10.0   0.18798955613577023  72 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    3.0    11.0   0.0    0.0    0.0    0.0    15.0   2.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    3.0    0.0    8.0    5.0    1.0    0.0    3.0    2.0    1.0    7.0    0.0    0.0    0.0    3.0    0.0    3.0    0.0    5.0    2.0    1.0    1.0    0.0    342.0  3.0    4.0    0.1319796954314721   52 / 394
0.0    1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    11.0   8.0    0.0    3.0    18.0   1.0    21.0   0.0    0.0    313.0  0.0    0.2035623409669211   80 / 393
0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    39.0   2.0    0.0    0.0    0.0    1.0    0.0    302.0  0.1771117166212534   65 / 367
393.0  537.0  358.0  437.0  396.0  364.0  330.0  306.0  328.0  344.0  420.0  341.0  437.0  379.0  426.0  414.0  314.0  415.0  423.0  387.0  380.0  372.0  400.0  400.0  352.0  350.0  0.1861441567529741   1,862 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.813856
2    0.891932
3    0.926922
4    0.948515
5    0.962211
6    0.971009
7    0.977207
8    0.982005
9    0.985904
10   0.989303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20846178894174897
RMSE: 0.4565761589721357
LogLoss: 0.6681938130868065
Mean Per-Class Error: 0.1900923441359686
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13     14    15     16    17     18     19    20    21    22    23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   1.0   1.0   1.0    2.0   0.0   0.07865168539325842  7 / 89
0.0   84.0   0.0   1.0    1.0   3.0   0.0   2.0   1.0   0.0    2.0    0.0   0.0    0.0    2.0   1.0    0.0   4.0    2.0    0.0   0.0   2.0   0.0   1.0    0.0   0.0   0.20754716981132076  22 / 106
0.0   0.0    62.0  0.0    3.0   0.0   3.0   1.0   0.0   0.0    5.0    0.0   0.0    0.0    1.0   0.0    1.0   0.0    3.0    1.0   1.0   0.0   1.0   0.0    0.0   0.0   0.24390243902439024  20 / 82
2.0   4.0    0.0   93.0   0.0   0.0   1.0   1.0   0.0   1.0    0.0    0.0   3.0    1.0    2.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    74.0  2.0   2.0   0.0   0.0   0.0    2.0    0.0   0.0    0.0    0.0   1.0    3.0   1.0    4.0    4.0   0.0   0.0   0.0   2.0    0.0   2.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0   5.0    0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   85.0  0.0    0.0   0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    1.0   1.0   0.0   2.0   0.0   0.0    4.0    0.0   0.0    0.0    1.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   85.0   0.0   1.0   0.15                 15 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0    3.0   5.0    3.0   0.0    0.0    4.0   0.0   6.0   0.0   0.0    84.0  0.0   0.21495327102803738  23 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    8.0    1.0   0.0   0.0   0.0   1.0    0.0   72.0  0.1724137931034483   15 / 87
94.0  129.0  72.0  120.0  87.0  87.0  82.0  78.0  77.0  100.0  112.0  88.0  100.0  100.0  90.0  117.0  83.0  103.0  113.0  93.0  96.0  86.0  98.0  102.0  97.0  86.0  0.18995983935742972  473 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.81004
2    0.891968
3    0.925703
4    0.948594
5    0.959438
6    0.969076
7    0.977109
8    0.983936
9    0.985542
10   0.989157
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:33  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:33  10.141 sec  83391 obs/sec     1         1             10007      0.648251         1.25714             0.992534       0.331401                         0.651109           1.26898               0.992446         0.337349
    2019-07-24 15:35:34  10.988 sec  105782 obs/sec    10        10            100070     0.45381          0.660711            0.996341       0.186144                         0.456576           0.668194              0.996286         0.18996
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0893593
C15         0.954809               0.954809             0.0853211
C8          0.868698               0.868698             0.0776263
C9          0.85148                0.85148              0.0760877
C12         0.800054               0.800054             0.0714923
C5          0.760697               0.760697             0.0679754
C7          0.754408               0.754408             0.0674134
C11         0.730658               0.730658             0.0652911
C10         0.661527               0.661527             0.0591136
C6          0.616991               0.616991             0.0551339
C14         0.616618               0.616618             0.0551006
C3          0.616514               0.616514             0.0550913
C4          0.568244               0.568244             0.0507779
C16         0.544271               0.544271             0.0486357
C1          0.460315               0.460315             0.0411334
C2          0.385487               0.385487             0.0344469
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_20

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012586119331672307  0.00036667485255748034  0.0         -0.012383343266261448  0.2093830108642578  0.09971319650302476  0.13979274034500122
    3        26       Softmax                      0.0   0.0   0.006137623149173193   0.013553932309150696    0.0         -0.19791542590532282   0.5247228145599365  -0.8723017642332375  0.3975483179092407


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22007647272735567
RMSE: 0.4691230891006705
LogLoss: 0.6916232389656496
Mean Per-Class Error: 0.18761253755635718
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    6.0    3.0    1.0    6.0    1.0    3.0    0.0    0.0    0.0    6.0    0.0    3.0    0.0    1.0    4.0    5.0    0.0    0.10379746835443038  41 / 395
0.0    326.0  0.0    6.0    3.0    0.0    6.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    19.0   5.0    0.0    0.0    4.0    0.0    4.0    2.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    297.0  1.0    17.0   0.0    12.0   0.0    0.0    0.0    17.0   0.0    1.0    0.0    5.0    0.0    2.0    0.0    6.0    1.0    3.0    0.0    6.0    0.0    0.0    0.0    0.19293478260869565  71 / 368
2.0    22.0   0.0    338.0  0.0    0.0    1.0    6.0    0.0    3.0    0.0    0.0    7.0    2.0    1.0    1.0    0.0    4.0    4.0    1.0    1.0    0.0    0.0    5.0    0.0    5.0    0.16129032258064516  65 / 403
0.0    6.0    1.0    0.0    318.0  2.0    12.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    7.0    5.0    8.0    2.0    0.0    0.0    0.0    7.0    0.0    13.0   0.171875             66 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    1.0    0.0    15.0   1.0    0.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    4.0    0.0    3.0    7.0    0.0    0.0    1.0    2.0    1.0    7.0    1.0    0.0    0.0    2.0    0.0    5.0    1.0    8.0    4.0    3.0    0.0    0.0    338.0  6.0    1.0    0.14213197969543148  56 / 394
1.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    10.0   21.0   1.0    35.0   1.0    0.0    309.0  0.0    0.21173469387755103  83 / 392
0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    31.0   1.0    0.0    0.0    0.0    1.0    0.0    305.0  0.16893732970027248  62 / 367
395.0  491.0  345.0  425.0  419.0  366.0  342.0  296.0  337.0  348.0  387.0  336.0  442.0  373.0  387.0  365.0  357.0  429.0  425.0  379.0  394.0  393.0  414.0  424.0  377.0  357.0  0.1869439168249525   1,870 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.813056
2    0.893932
3    0.927922
4    0.947716
5    0.962511
6    0.972408
7    0.977907
8    0.983405
9    0.986404
10   0.988903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2226549815206709
RMSE: 0.471863308088975
LogLoss: 0.6975183591980215
Mean Per-Class Error: 0.19076564594842602
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16    17     18     19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0    1.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   84.0   0.0   1.0    2.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   3.0   1.0    0.0   7.0    1.0    0.0   0.0   3.0   0.0    2.0    0.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    62.0  0.0    3.0   0.0   5.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0    1.0   1.0   0.0   2.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
2.0   4.0    0.0   96.0   0.0   0.0   1.0   2.0   0.0   1.0   0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    80.0  1.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    3.0   1.0    2.0    0.0   0.0   0.0   0.0    2.0    0.0    6.0   0.17525773195876287  17 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   2.0    0.0   2.0    3.0   0.0   0.0   1.0   0.0   0.0   3.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0    2.0    0.0   1.0   0.0   0.0    82.0   2.0    0.0   0.18                 18 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0    1.0    5.0   1.0   10.0  1.0    0.0    84.0   0.0   0.21495327102803738  23 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0    0.0    0.0    72.0  0.1724137931034483   15 / 87
95.0  118.0  73.0  120.0  98.0  88.0  83.0  76.0  82.0  99.0  95.0  93.0  98.0  99.0  82.0  103.0  95.0  108.0  105.0  87.0  97.0  93.0  102.0  103.0  107.0  91.0  0.19076305220883535  475 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.809237
2    0.893976
3    0.931727
4    0.949799
5    0.963855
6    0.9751
7    0.977912
8    0.981928
9    0.984739
10   0.987149
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:02  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:02  38.623 sec  82024 obs/sec     1         1             10007      0.657354         1.2803              0.992321       0.329701                         0.657837           1.27982               0.992289         0.329317
    2019-07-24 15:36:03  39.623 sec  91976 obs/sec     10        10            100070     0.469123         0.691623            0.996089       0.186944                         0.471863           0.697518              0.996033         0.190763
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0892347
C13         0.961698               0.961698             0.0858169
C8          0.864352               0.864352             0.0771302
C9          0.824831               0.824831             0.0736036
C12         0.79353                0.79353              0.0708105
C7          0.771469               0.771469             0.0688418
C11         0.765046               0.765046             0.0682686
C6          0.670846               0.670846             0.0598628
C5          0.664808               0.664808             0.059324
C14         0.654132               0.654132             0.0583713
C10         0.64304                0.64304              0.0573815
C3          0.594837               0.594837             0.0530802
C16         0.591656               0.591656             0.0527962
C4          0.564781               0.564781             0.050398
C2          0.432692               0.432692             0.0386112
C1          0.408681               0.408681             0.0364685
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_67

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015770467581432968  0.00035700108855962753  0.0         -0.012235472235680334  0.7490477561950684   -0.06693725514842122  0.7573084831237793
    3        26       Softmax                 0.0   0.0   0.0018667693976357651  0.00027380965184420347  0.0         -0.017430291576212873  0.38558638095855713  -0.5529862880672256   0.27176976203918457


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21356687604685798
RMSE: 0.4621329636012324
LogLoss: 0.7187123460634315
Mean Per-Class Error: 0.20728963994295918
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    2.0    0.0    0.0    0.0    5.0    0.0    3.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    2.0    0.0    2.0    2.0    8.0    0.0    0.08860759493670886  35 / 395
0.0    310.0  0.0    10.0   3.0    0.0    1.0    5.0    2.0    1.0    0.0    0.0    3.0    0.0    0.0    1.0    4.0    19.0   9.0    0.0    0.0    4.0    1.0    5.0    4.0    0.0    0.18848167539267016  72 / 382
0.0    0.0    302.0  0.0    14.0   1.0    5.0    1.0    0.0    0.0    18.0   1.0    0.0    0.0    3.0    0.0    2.0    0.0    8.0    2.0    3.0    0.0    8.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
4.0    17.0   0.0    329.0  0.0    1.0    0.0    6.0    0.0    4.0    0.0    1.0    2.0    7.0    6.0    4.0    0.0    10.0   3.0    1.0    1.0    0.0    0.0    6.0    0.0    1.0    0.18362282878411912  74 / 403
0.0    5.0    0.0    0.0    294.0  5.0    11.0   0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    14.0   5.0    11.0   7.0    0.0    0.0    0.0    7.0    0.0    21.0   0.234375             90 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    2.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    2.0    0.0    6.0    7.0    1.0    0.0    5.0    6.0    0.0    7.0    3.0    0.0    0.0    2.0    0.0    8.0    0.0    10.0   3.0    2.0    0.0    0.0    326.0  5.0    1.0    0.17258883248730963  68 / 394
0.0    0.0    0.0    1.0    0.0    11.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    6.0    0.0    3.0    24.0   5.0    19.0   2.0    2.0    318.0  0.0    0.19083969465648856  75 / 393
1.0    0.0    0.0    1.0    10.0   1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    27.0   5.0    0.0    0.0    0.0    4.0    0.0    301.0  0.17983651226158037  66 / 367
417.0  501.0  357.0  445.0  395.0  374.0  312.0  338.0  343.0  354.0  362.0  337.0  441.0  358.0  369.0  377.0  371.0  398.0  335.0  395.0  405.0  370.0  479.0  405.0  389.0  376.0  0.20633809857042887  2,064 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793662
2    0.882935
3    0.917925
4    0.939118
5    0.953314
6    0.964511
7    0.973108
8    0.978706
9    0.982205
10   0.986204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21456565809551778
RMSE: 0.46321232506866417
LogLoss: 0.7233849703180365
Mean Per-Class Error: 0.2081553308440681
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   1.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0    79.0   0.0   4.0    2.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0    9.0    3.0   0.0   0.0    3.0   1.0    2.0    0.0    0.0   0.25471698113207547  27 / 106
0.0    0.0    64.0  0.0    3.0   0.0   1.0   0.0   0.0   0.0   5.0   0.0   0.0   0.0   2.0   0.0    1.0    0.0    3.0   1.0   0.0    0.0   2.0    0.0    0.0    0.0   0.21951219512195122  18 / 82
2.0    2.0    0.0   93.0   0.0   1.0   0.0   3.0   0.0   0.0   0.0   0.0   1.0   2.0   1.0   1.0    0.0    4.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.16964285714285715  19 / 112
0.0    2.0    0.0   0.0    70.0  3.0   2.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    4.0    1.0    3.0   3.0   0.0    0.0   0.0    2.0    0.0    6.0   0.27835051546391754  27 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    1.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0    0.0    0.0   3.0    3.0   0.0   0.0   1.0   1.0   0.0   2.0   1.0   0.0   0.0   0.0   0.0    2.0    0.0    4.0   0.0   1.0    0.0   0.0    81.0   1.0    0.0   0.19                 19 / 100
0.0    0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   4.0   3.0    4.0   2.0    0.0    90.0   0.0   0.1588785046728972   17 / 107
0.0    0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0    2.0    0.0    6.0   2.0   0.0    0.0   0.0    1.0    0.0    72.0  0.1724137931034483   15 / 87
102.0  122.0  74.0  129.0  90.0  84.0  74.0  86.0  83.0  97.0  93.0  91.0  98.0  94.0  70.0  107.0  100.0  100.0  88.0  94.0  107.0  87.0  120.0  100.0  108.0  92.0  0.20722891566265061  516 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792771
2    0.883133
3    0.92008
4    0.939357
5    0.952209
6    0.960241
7    0.96988
8    0.976305
9    0.981526
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:13  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:13  1 min 49.835 sec  46544 obs/sec     1         1             10007      0.581313         1.09296             0.993994       0.304209                         0.579138           1.07923               0.994024         0.312851
    2019-07-24 15:37:15  1 min 51.506 sec  54209 obs/sec     10        10            100070     0.462133         0.718712            0.996205       0.206338                         0.463212           0.723385              0.996177         0.207229
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0884951
C13         0.95518                0.95518              0.0845288
C9          0.937279               0.937279             0.0829446
C12         0.900212               0.900212             0.0796644
C11         0.820947               0.820947             0.0726498
C8          0.812752               0.812752             0.0719246
C7          0.810955               0.810955             0.0717655
C14         0.716955               0.716955             0.063447
C10         0.663592               0.663592             0.0587247
C6          0.623503               0.623503             0.055177
C16         0.602408               0.602408             0.0533101
C3          0.572512               0.572512             0.0506645
C4          0.534025               0.534025             0.0472586
C5          0.525553               0.525553             0.0465089
C2          0.426219               0.426219             0.0377183
C1          0.39797                0.39797              0.0352184
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_31

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007597701870167839  0.00017050246242433786  0.0         -0.025965980380846077  0.2906229496002197  0.2008791146823666    0.24876022338867188
    3        26       Softmax                      0.0   0.0   0.004689860267297683   0.010672114789485931    0.0         -0.39896156028754165   0.8667869567871094  -0.45356981863373413  0.37344300746917725


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2212241886941238
RMSE: 0.47034475514682184
LogLoss: 0.7156242913966079
Mean Per-Class Error: 0.2048515502544439
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    8.0    5.0    0.0    3.0    0.0    0.0    1.0    5.0    2.0    6.0    0.0    2.0    4.0    2.0    1.0    4.0    0.0    0.11139240506329114  44 / 395
0.0    334.0  0.0    0.0    3.0    1.0    5.0    7.0    2.0    2.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    12.0   8.0    0.0    1.0    1.0    0.0    2.0    0.0    0.0    0.1256544502617801   48 / 382
0.0    0.0    298.0  0.0    10.0   0.0    12.0   1.0    0.0    0.0    24.0   0.0    0.0    0.0    3.0    0.0    3.0    2.0    7.0    3.0    1.0    0.0    4.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
0.0    17.0   0.0    319.0  0.0    1.0    0.0    13.0   0.0    8.0    0.0    1.0    5.0    4.0    4.0    2.0    0.0    8.0    2.0    0.0    0.0    0.0    0.0    9.0    0.0    10.0   0.20843672456575682  84 / 403
0.0    7.0    2.0    0.0    304.0  2.0    20.0   2.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    11.0   4.0    0.0    0.0    0.0    4.0    2.0    11.0   0.20833333333333334  80 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    12.0   0.0    0.0    3.0    0.0    7.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    8.0    4.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    3.0    1.0    9.0    8.0    0.0    1.0    0.0    8.0    2.0    8.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    6.0    10.0   2.0    2.0    0.0    318.0  9.0    4.0    0.19083969465648856  75 / 393
0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    11.0   0.0    3.0    23.0   7.0    32.0   0.0    0.0    308.0  0.0    0.21628498727735368  85 / 393
1.0    0.0    0.0    0.0    22.0   1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    9.0    1.0    22.0   1.0    0.0    0.0    0.0    4.0    0.0    295.0  0.19398907103825136  71 / 366
411.0  502.0  366.0  401.0  394.0  376.0  345.0  314.0  355.0  361.0  399.0  323.0  421.0  353.0  387.0  393.0  337.0  450.0  355.0  365.0  407.0  411.0  416.0  378.0  392.0  391.0  0.20413875837248827  2,042 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.795861
2    0.887034
3    0.922423
4    0.941717
5    0.956213
6    0.96521
7    0.972008
8    0.977607
9    0.982605
10   0.986904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2233965189524547
RMSE: 0.472648409446657
LogLoss: 0.7244401920975011
Mean Per-Class Error: 0.2061300313978659
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    2.0   1.0    1.0   2.0    0.0   0.11235955056179775  10 / 89
0.0   86.0   0.0   0.0    2.0   0.0   2.0   3.0   1.0   0.0    0.0    0.0   0.0   0.0   1.0   1.0    0.0   4.0    3.0   0.0   1.0    1.0   0.0    1.0   0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    64.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    6.0    0.0   0.0   0.0   1.0   0.0    1.0   0.0    3.0   1.0   0.0    0.0   1.0    0.0   0.0    0.0   0.21951219512195122  18 / 82
0.0   2.0    0.0   91.0   0.0   0.0   0.0   5.0   0.0   3.0    0.0    1.0   2.0   2.0   0.0   2.0    0.0   1.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.1875               21 / 112
0.0   0.0    0.0   0.0    71.0  2.0   6.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0    3.0   2.0   0.0    0.0   0.0    2.0   0.0    5.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0    0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    2.0   0.0   1.0   0.0   2.0   0.0    4.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0   3.0   0.0    0.0   0.0    78.0  3.0    0.0   0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    4.0   0.0    0.0   7.0   3.0    10.0  0.0    0.0   81.0   0.0   0.24299065420560748  26 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    5.0   0.0   0.0    0.0   0.0    1.0   0.0    69.0  0.20689655172413793  18 / 87
96.0  118.0  79.0  116.0  92.0  86.0  81.0  85.0  85.0  100.0  105.0  88.0  94.0  97.0  74.0  115.0  91.0  112.0  96.0  89.0  105.0  94.0  101.0  88.0  106.0  97.0  0.20602409638554217  513 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793976
2    0.88755
3    0.922892
4    0.940562
5    0.953414
6    0.966265
7    0.971888
8    0.975502
9    0.981125
10   0.985141
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:22  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:22  59.248 sec  181945 obs/sec    1         1             10007      0.695083         1.45168             0.991411       0.376587                         0.698221           1.46089               0.991313         0.385542
    2019-07-24 15:36:23  59.721 sec  194688 obs/sec    10        10            100070     0.470345         0.715624            0.996067       0.204139                         0.472648           0.72444               0.996019         0.206024
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0971538
C13         0.879012               0.879012             0.0853994
C8          0.798325               0.798325             0.0775604
C12         0.798285               0.798285             0.0775565
C7          0.761762               0.761762             0.0740081
C9          0.735979               0.735979             0.0715032
C14         0.709358               0.709358             0.0689169
C11         0.64632                0.64632              0.0627925
C5          0.610569               0.610569             0.0593191
C10         0.566727               0.566727             0.0550597
C16         0.561128               0.561128             0.0545157
C6          0.536439               0.536439             0.0521171
C4          0.499581               0.499581             0.0485362
C3          0.485905               0.485905             0.0472076
C1          0.359349               0.359349             0.0349122
C2          0.344212               0.344212             0.0334416
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_34

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  ------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.001372877988046639   0.00036098738200962543  0.0         -0.0016323892351692848  0.7357027530670166  -0.048088742271961235  0.7420156002044678
    3        26       Softmax                 0.0   0.0   0.0019610499504359234  0.00036448228638619184  0.0         -0.0005019866741716983  0.5001406669616699  -0.4571140039192984    0.20965206623077393


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21352059431538167
RMSE: 0.46208288684540316
LogLoss: 0.716222656765996
Mean Per-Class Error: 0.2133923909825754
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    5.0    4.0    3.0    3.0    0.0    2.0    0.0    1.0    2.0    1.0    0.0    3.0    0.0    2.0    5.0    5.0    1.0    0.10126582278481013  40 / 395
0.0    304.0  0.0    7.0    2.0    6.0    3.0    18.0   2.0    1.0    5.0    0.0    0.0    0.0    0.0    2.0    4.0    18.0   3.0    0.0    0.0    1.0    3.0    1.0    1.0    2.0    0.206266318537859    79 / 383
0.0    0.0    290.0  0.0    15.0   6.0    14.0   1.0    0.0    0.0    14.0   3.0    0.0    0.0    14.0   1.0    3.0    0.0    0.0    0.0    5.0    0.0    1.0    1.0    0.0    0.0    0.21195652173913043  78 / 368
4.0    15.0   0.0    332.0  0.0    4.0    0.0    8.0    0.0    4.0    0.0    0.0    6.0    9.0    4.0    2.0    0.0    7.0    1.0    0.0    1.0    0.0    0.0    5.0    0.0    1.0    0.1761786600496278   71 / 403
0.0    5.0    3.0    0.0    292.0  2.0    10.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    10.0   4.0    7.0    9.0    0.0    0.0    0.0    17.0   4.0    18.0   0.23958333333333334  92 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    1.0    0.0    14.0   4.0    6.0    1.0    1.0    2.0    0.0    0.0    1.0    0.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    5.0    0.0    17.0   14.0   1.0    0.0    4.0    4.0    0.0    6.0    2.0    0.0    0.0    0.0    1.0    6.0    2.0    5.0    11.0   0.0    0.0    0.0    305.0  6.0    3.0    0.22193877551020408  87 / 392
0.0    1.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    11.0   0.0    2.0    25.0   2.0    17.0   2.0    0.0    324.0  0.0    0.17557251908396945  69 / 393
5.0    0.0    0.0    0.0    22.0   0.0    0.0    0.0    3.0    17.0   0.0    2.0    0.0    0.0    0.0    0.0    7.0    1.0    19.0   4.0    0.0    0.0    0.0    1.0    0.0    286.0  0.22070844686648503  81 / 367
410.0  437.0  363.0  457.0  431.0  374.0  304.0  330.0  334.0  364.0  372.0  339.0  430.0  362.0  392.0  391.0  420.0  430.0  273.0  411.0  407.0  367.0  421.0  395.0  392.0  397.0  0.21213635909227233  2,122 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787864
2    0.882335
3    0.920224
4    0.940618
5    0.953714
6    0.964211
7    0.970809
8    0.976707
9    0.980606
10   0.984805

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21743560959438643
RMSE: 0.4662999137833787
LogLoss: 0.7250679398299272
Mean Per-Class Error: 0.22113429347501182
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   1.0    3.0   3.0    0.0    0.10112359550561797  9 / 89
0.0   76.0   0.0   2.0    2.0   2.0   2.0   5.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0    8.0    2.0   0.0   0.0    1.0   2.0    1.0   0.0    0.0    0.2830188679245283   30 / 106
0.0   0.0    61.0  0.0    3.0   1.0   5.0   1.0   0.0   0.0    4.0   0.0   0.0   0.0   6.0   0.0    0.0    0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0    0.0    0.25609756097560976  21 / 82
3.0   2.0    0.0   93.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   2.0   2.0   1.0   2.0    0.0    0.0    1.0   0.0   0.0    0.0   0.0    2.0   0.0    1.0    0.16964285714285715  19 / 112
0.0   2.0    0.0   0.0    70.0  2.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    2.0    1.0    2.0   3.0   0.0    0.0   0.0    2.0   0.0    8.0    0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   3.0   1.0   1.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   2.0    0.0   6.0    5.0   0.0   0.0   1.0   0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    1.0    2.0    3.0   1.0   0.0    0.0   0.0    71.0  3.0    1.0    0.29                 29 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    4.0    0.0    1.0   7.0   0.0    6.0   1.0    0.0   85.0   0.0    0.205607476635514    22 / 107
1.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0   0.0   0.0    1.0    0.0    5.0   2.0   0.0    0.0   0.0    0.0   0.0    67.0   0.22988505747126436  20 / 87
98.0  111.0  75.0  132.0  98.0  87.0  80.0  87.0  75.0  103.0  95.0  85.0  93.0  95.0  78.0  110.0  105.0  115.0  72.0  94.0  102.0  87.0  105.0  93.0  111.0  104.0  0.22008032128514057  548 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.77992
2    0.882329
3    0.919277
4    0.938956
5    0.954619
6    0.963855
7    0.970683
8    0.975904
9    0.980723
10   0.984739
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:26  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:26  1 min  2.659 sec  77573 obs/sec     1         1             10007      0.606433         1.1535              0.993464       0.318704                         0.606385           1.14186               0.993448         0.321285
    2019-07-24 15:36:27  1 min  3.835 sec  77996 obs/sec     10        10            100070     0.462083         0.716223            0.996205       0.212136                         0.4663             0.725068              0.996126         0.22008
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0900746
C13         0.898291               0.898291             0.0809132
C9          0.892608               0.892608             0.0804013
C12         0.834479               0.834479             0.0751653
C11         0.81615                0.81615              0.0735144
C8          0.780384               0.780384             0.0702927
C7          0.750753               0.750753             0.0676237
C14         0.723496               0.723496             0.0651686
C10         0.684597               0.684597             0.0616648
C16         0.665915               0.665915             0.059982
C6          0.639654               0.639654             0.0576166
C5          0.586622               0.586622             0.0528398
C3          0.501566               0.501566             0.0451784
C1          0.468015               0.468015             0.0421562
C4          0.461621               0.461621             0.0415803
C2          0.397761               0.397761             0.0358282
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_50

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias               bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ----------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.001332395086848237   0.0003464682959020138   0.0         -0.010985271695062693  0.7203042507171631  -0.0027691170329213646  0.7708375453948975
    3        26       Softmax                 0.0   0.0   0.0019597096830833694  0.00039547018241137266  0.0         0.010582248192594516   0.5012607574462891  -0.47212678764848454    0.2498469352722168


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21473559308091886
RMSE: 0.4633957197481639
LogLoss: 0.7203421819632443
Mean Per-Class Error: 0.20923353714022114
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  2.0    0.0    2.0    0.0    0.0    0.0    5.0    0.0    3.0    2.0    2.0    6.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    2.0    0.0    9.0    2.0    0.10126582278481013  40 / 395
0.0    308.0  0.0    8.0    4.0    2.0    3.0    7.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    23.0   9.0    0.0    0.0    1.0    1.0    5.0    5.0    0.0    0.195822454308094    75 / 383
0.0    0.0    301.0  1.0    14.0   0.0    10.0   1.0    1.0    0.0    18.0   0.0    0.0    0.0    3.0    0.0    2.0    1.0    6.0    0.0    4.0    0.0    6.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
3.0    33.0   0.0    316.0  0.0    0.0    0.0    5.0    0.0    2.0    1.0    0.0    4.0    2.0    9.0    3.0    0.0    14.0   2.0    0.0    1.0    0.0    0.0    6.0    0.0    2.0    0.21588089330024815  87 / 403
0.0    9.0    2.0    0.0    292.0  7.0    10.0   1.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    1.0    9.0    6.0    12.0   5.0    1.0    0.0    0.0    6.0    0.0    15.0   0.23958333333333334  92 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    2.0    10.0   0.0    0.0    2.0    0.0    10.0   2.0    1.0    0.0    2.0    2.0    0.0    0.0    4.0    6.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    1.0    0.0    5.0    10.0   1.0    0.0    4.0    3.0    0.0    12.0   0.0    0.0    0.0    0.0    1.0    8.0    2.0    2.0    4.0    3.0    0.0    0.0    325.0  9.0    4.0    0.1751269035532995   69 / 394
0.0    1.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    6.0    9.0    0.0    3.0    23.0   1.0    32.0   1.0    0.0    308.0  0.0    0.21628498727735368  85 / 393
2.0    2.0    0.0    0.0    11.0   5.0    0.0    0.0    2.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    24.0   1.0    0.0    0.0    0.0    4.0    1.0    302.0  0.17486338797814208  64 / 366
391.0  514.0  345.0  402.0  398.0  346.0  305.0  310.0  340.0  344.0  359.0  344.0  417.0  360.0  393.0  408.0  405.0  482.0  291.0  408.0  412.0  388.0  419.0  423.0  389.0  410.0  0.2081375587323803   2,082 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791862
2    0.880836
3    0.918324
4    0.939218
5    0.952514
6    0.962111
7    0.970209
8    0.976807
9    0.981605
10   0.986104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21722518237580757
RMSE: 0.4660742241057829
LogLoss: 0.726194045375923
Mean Per-Class Error: 0.21175155182577549
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    0.0   3.0    0.0    0.10112359550561797  9 / 89
0.0   81.0   0.0   5.0    0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0    7.0    4.0   0.0   0.0    1.0   1.0    2.0   2.0    0.0    0.2358490566037736   25 / 106
0.0   0.0    63.0  0.0    4.0   0.0   2.0   0.0   1.0   0.0   4.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    3.0   0.0   0.0    0.0   2.0    0.0   0.0    0.0    0.23170731707317074  19 / 82
2.0   6.0    0.0   89.0   0.0   0.0   0.0   3.0   0.0   0.0   1.0   0.0   2.0   1.0    3.0   1.0    0.0    2.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0    0.20535714285714285  23 / 112
0.0   2.0    0.0   0.0    68.0  6.0   2.0   0.0   1.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    3.0    2.0    4.0   1.0   0.0    0.0   0.0    2.0   0.0    4.0    0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   4.0   1.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0    1.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0   0.0    0.0   3.0    5.0   0.0   0.0   1.0   2.0   0.0   5.0   0.0   0.0   0.0    0.0   0.0    2.0    2.0    0.0   0.0   1.0    0.0   0.0    73.0  5.0    1.0    0.27                 27 / 100
0.0   1.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   5.0    2.0    0.0    0.0   7.0   0.0    7.0   1.0    0.0   83.0   0.0    0.22429906542056074  24 / 107
1.0   1.0    0.0   0.0    3.0   2.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    2.0   0.0   0.0    0.0   0.0    1.0   1.0    73.0   0.16091954022988506  14 / 87
91.0  123.0  69.0  117.0  91.0  86.0  77.0  78.0  82.0  98.0  92.0  93.0  92.0  101.0  81.0  116.0  105.0  121.0  70.0  97.0  105.0  92.0  100.0  99.0  111.0  103.0  0.21124497991967872  526 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788755
2    0.881124
3    0.919277
4    0.938956
5    0.951406
6    0.962249
7    0.971084
8    0.976305
9    0.982329
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:52  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:52  1 min 29.040 sec  70471 obs/sec     1         1             10007      0.597977         1.13639             0.993645       0.312606                         0.597502           1.12569               0.993639         0.311647
    2019-07-24 15:36:53  1 min 30.119 sec  83600 obs/sec     10        10            100070     0.463396         0.720342            0.996184       0.208138                         0.466074           0.726194              0.996129         0.211245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0884954
C13         0.972129               0.972129             0.0860289
C9          0.92891                0.92891              0.0822043
C12         0.926744               0.926744             0.0820125
C11         0.820939               0.820939             0.0726493
C8          0.788854               0.788854             0.0698099
C7          0.784943               0.784943             0.0694638
C14         0.716681               0.716681             0.0634229
C6          0.674978               0.674978             0.0597324
C10         0.653091               0.653091             0.0577955
C16         0.586535               0.586535             0.0519056
C5          0.570576               0.570576             0.0504933
C3          0.565966               0.565966             0.0500854
C4          0.495705               0.495705             0.0438676
C2          0.408568               0.408568             0.0361564
C1          0.405408               0.405408             0.0358767
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_12

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0012050640179950278  0.0003598090261220932  0.0         -0.020536647623885074  0.5655214786529541  -0.05542471632301122  0.5981748104095459
    3        26       Softmax                 0.0   0.0   0.0022232907463498684  0.0005073812790215015  0.0         -0.01833020321926317   0.7345290184020996  -0.5307041157088952   0.27017152309417725


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.220166190529893
RMSE: 0.4692187022379788
LogLoss: 0.7420724196660029
Mean Per-Class Error: 0.20985953273168206
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    4.0    5.0    0.0    3.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    3.0    5.0    3.0    0.09873417721518987  39 / 395
0.0    307.0  0.0    8.0    5.0    3.0    2.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    24.0   12.0   0.0    0.0    4.0    2.0    7.0    1.0    0.0    0.19843342036553524  76 / 383
0.0    1.0    285.0  1.0    14.0   0.0    25.0   0.0    0.0    0.0    20.0   2.0    0.0    0.0    13.0   0.0    0.0    1.0    1.0    2.0    1.0    0.0    2.0    0.0    0.0    0.0    0.22554347826086957  83 / 368
2.0    13.0   0.0    336.0  0.0    1.0    0.0    5.0    0.0    5.0    1.0    1.0    2.0    9.0    9.0    2.0    0.0    12.0   1.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.1662531017369727   67 / 403
0.0    3.0    5.0    0.0    304.0  6.0    17.0   1.0    0.0    0.0    5.0    2.0    0.0    0.0    1.0    0.0    4.0    4.0    8.0    1.0    1.0    0.0    0.0    2.0    0.0    19.0   0.206266318537859    79 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    23.0   2.0    2.0    1.0    0.0    2.0    0.0    0.0    4.0    7.0    317.0  0.0    0.0    0.0    0.15691489361702127  59 / 376
0.0    2.0    0.0    1.0    9.0    0.0    0.0    1.0    1.0    1.0    5.0    7.0    0.0    0.0    2.0    0.0    8.0    2.0    1.0    7.0    9.0    0.0    0.0    324.0  5.0    9.0    0.17766497461928935  70 / 394
0.0    0.0    0.0    1.0    0.0    12.0   1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    3.0    0.0    2.0    30.0   1.0    29.0   3.0    0.0    307.0  0.0    0.21882951653944022  86 / 393
2.0    0.0    0.0    2.0    19.0   0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    31.0   5.0    0.0    0.0    0.0    3.0    0.0    289.0  0.2125340599455041   78 / 367
391.0  480.0  339.0  438.0  407.0  401.0  366.0  297.0  324.0  371.0  365.0  365.0  413.0  376.0  430.0  376.0  331.0  436.0  301.0  400.0  399.0  389.0  407.0  412.0  371.0  418.0  0.20863740877736678  2,087 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791363
2    0.879936
3    0.918025
4    0.938418
5    0.953114
6    0.961811
7    0.96801
8    0.975607
9    0.980506
10   0.983905

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22179771318470173
RMSE: 0.47095404572495364
LogLoss: 0.7452971958216307
Mean Per-Class Error: 0.20899070938662917
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   1.0    1.0    3.0    0.0    0.0898876404494382   8 / 89
0.0   81.0   0.0   1.0    3.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   9.0    3.0   0.0   0.0    3.0   1.0    2.0    0.0    0.0    0.2358490566037736   25 / 106
0.0   1.0    60.0  0.0    2.0   0.0   8.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0    0.0   1.0   1.0    0.0   1.0    0.0    0.0    0.0    0.2682926829268293   22 / 82
2.0   0.0    0.0   94.0   0.0   0.0   0.0   1.0   0.0   2.0    0.0   0.0   1.0   3.0    3.0   1.0    0.0   3.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0    0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    74.0  3.0   4.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    1.0   0.0    2.0   1.0    1.0   0.0   0.0    0.0   0.0    0.0    0.0    8.0    0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   3.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   1.0    2.0   81.0   0.0    0.0    0.0    0.11956521739130435  11 / 92
0.0   0.0    0.0   1.0    3.0   0.0   0.0   1.0   0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    2.0   2.0    0.0   1.0   2.0    0.0   0.0    79.0   1.0    5.0    0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   9.0   1.0    8.0   2.0    0.0    82.0   0.0    0.2336448598130841   25 / 107
0.0   0.0    0.0   2.0    5.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    5.0   2.0   0.0    0.0   0.0    1.0    0.0    69.0   0.20689655172413793  18 / 87
91.0  113.0  69.0  121.0  97.0  89.0  77.0  79.0  73.0  108.0  93.0  93.0  87.0  103.0  87.0  111.0  92.0  118.0  81.0  92.0  102.0  89.0  102.0  104.0  109.0  110.0  0.20843373493975903  519 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791566
2    0.879518
3    0.917671
4    0.938554
5    0.954217
6    0.963454
7    0.966667
8    0.974297
9    0.980321
10   0.983133
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:48  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:48  24.575 sec  116360 obs/sec    1         1             10007      0.666877         1.40526             0.992098       0.384085                         0.662241           1.38256               0.992185         0.380723
    2019-07-24 15:35:48  25.336 sec  120857 obs/sec    10        10            100070     0.469219         0.742072            0.996088       0.208637                         0.470954           0.745297              0.996048         0.208434
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0974809
C9          0.885797               0.885797             0.0863483
C13         0.856873               0.856873             0.0835288
C8          0.854694               0.854694             0.0833164
C7          0.797865               0.797865             0.0777766
C12         0.783762               0.783762             0.0764018
C11         0.772276               0.772276             0.0752822
C14         0.64823                0.64823              0.06319
C6          0.627035               0.627035             0.061124
C10         0.596901               0.596901             0.0581865
C16         0.573233               0.573233             0.0558793
C5          0.443854               0.443854             0.0432673
C4          0.427047               0.427047             0.041629
C3          0.389544               0.389544             0.0379731
C1          0.306707               0.306707             0.0298981
C2          0.294599               0.294599             0.0287178
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_47

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0016102311221857235  0.00032457057386636734  0.0         0.020368962547287595  0.7567973136901855   -0.06580502154935343  0.7546472549438477
    3        26       Softmax                 0.0   0.0   0.0018783933757661614  0.0002817477798089385   0.0         0.013294374871124913  0.38194143772125244  -0.5667073765196554   0.2717888355255127


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2152249991789811
RMSE: 0.46392348418568025
LogLoss: 0.7398700597193922
Mean Per-Class Error: 0.21418288286031148
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    5.0    2.0    3.0    6.0    0.0    4.0    0.0    1.0    1.0    5.0    0.0    1.0    0.0    4.0    0.0    7.0    2.0    0.11139240506329114  44 / 395
0.0    323.0  0.0    8.0    2.0    2.0    3.0    3.0    2.0    0.0    2.0    0.0    1.0    0.0    0.0    5.0    0.0    21.0   6.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    0.1566579634464752   60 / 383
0.0    0.0    288.0  0.0    19.0   0.0    10.0   1.0    0.0    0.0    25.0   1.0    0.0    0.0    2.0    0.0    2.0    0.0    8.0    3.0    4.0    0.0    5.0    0.0    0.0    0.0    0.21739130434782608  80 / 368
4.0    16.0   0.0    334.0  0.0    0.0    0.0    8.0    0.0    4.0    0.0    1.0    3.0    7.0    2.0    5.0    0.0    7.0    3.0    1.0    1.0    0.0    0.0    6.0    0.0    1.0    0.17121588089330025  69 / 403
0.0    14.0   2.0    0.0    302.0  5.0    10.0   0.0    0.0    0.0    5.0    3.0    0.0    0.0    0.0    2.0    7.0    3.0    1.0    2.0    0.0    0.0    0.0    7.0    0.0    21.0   0.21354166666666666  82 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    3.0    0.0    16.0   0.0    1.0    1.0    0.0    4.0    0.0    0.0    1.0    3.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    8.0    0.0    10.0   13.0   1.0    0.0    2.0    3.0    0.0    9.0    0.0    0.0    0.0    2.0    1.0    8.0    1.0    10.0   6.0    1.0    2.0    0.0    310.0  4.0    3.0    0.2131979695431472   84 / 394
0.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    9.0    0.0    6.0    22.0   2.0    18.0   2.0    1.0    317.0  0.0    0.1913265306122449   75 / 392
2.0    0.0    0.0    1.0    15.0   0.0    0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    28.0   7.0    0.0    0.0    0.0    2.0    0.0    300.0  0.18256130790190736  67 / 367
398.0  534.0  343.0  469.0  399.0  397.0  313.0  283.0  333.0  351.0  421.0  347.0  448.0  343.0  382.0  382.0  351.0  442.0  311.0  380.0  393.0  374.0  436.0  382.0  381.0  410.0  0.21313605918224532  2,132 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.786864
2    0.878936
3    0.916925
4    0.935419
5    0.951115
6    0.961311
7    0.969509
8    0.975407
9    0.980906
10   0.985104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2182713227605155
RMSE: 0.4671951656005395
LogLoss: 0.7465944322705939
Mean Per-Class Error: 0.22112755835377917
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    1.0   0.0    1.0   0.0   0.0   0.0   2.0    0.0   3.0    0.0    0.0898876404494382   8 / 89
0.0   84.0   0.0   2.0    1.0   0.0   1.0   1.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   10.0   1.0   0.0   0.0   3.0   0.0    1.0   0.0    0.0    0.20754716981132076  22 / 106
0.0   0.0    61.0  0.0    3.0   0.0   3.0   0.0   0.0   0.0   6.0    0.0   0.0    0.0   2.0   0.0    1.0   0.0    3.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.25609756097560976  21 / 82
3.0   3.0    0.0   93.0   0.0   0.0   0.0   5.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0   1.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    0.16964285714285715  19 / 112
0.0   4.0    1.0   0.0    68.0  4.0   3.0   0.0   0.0   0.0   1.0    3.0   0.0    0.0   0.0   0.0    2.0   1.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    9.0    0.29896907216494845  29 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0    0.0   1.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   1.0    0.0   4.0    5.0   1.0   0.0   1.0   0.0   0.0   5.0    0.0   0.0    0.0   0.0   0.0    2.0   1.0    3.0   0.0   0.0   0.0   0.0    75.0  1.0    1.0    0.25                 25 / 100
0.0   0.0    0.0   1.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   3.0    5.0   0.0    1.0   4.0   1.0   6.0   1.0    0.0   83.0   0.0    0.22429906542056074  24 / 107
0.0   0.0    0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    5.0   3.0   0.0   0.0   0.0    1.0   0.0    73.0   0.16091954022988506  14 / 87
94.0  130.0  72.0  128.0  86.0  89.0  78.0  75.0  81.0  96.0  103.0  92.0  100.0  95.0  77.0  113.0  94.0  111.0  80.0  86.0  99.0  89.0  111.0  94.0  107.0  110.0  0.22048192771084338  549 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779518
2    0.880321
3    0.918072
4    0.936948
5    0.952209
6    0.961044
7    0.96747
8    0.972289
9    0.977912
10   0.984337
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:46  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:46  1 min 23.122 sec  50286 obs/sec     1         1             10007      0.586586         1.11005             0.993885       0.303509                         0.587106           1.10451               0.993858         0.313253
    2019-07-24 15:36:48  1 min 24.850 sec  52919 obs/sec     10        10            100070     0.463923         0.73987             0.996175       0.213136                         0.467195           0.746594              0.996111         0.220482
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0913152
C13         0.942163               0.942163             0.0860338
C12         0.8674                 0.8674               0.0792069
C9          0.86046                0.86046              0.0785731
C11         0.801235               0.801235             0.073165
C7          0.799795               0.799795             0.0730334
C8          0.761465               0.761465             0.0695333
C14         0.681084               0.681084             0.0621934
C10         0.67447                0.67447              0.0615894
C6          0.60229                0.60229              0.0549982
C16         0.566957               0.566957             0.0517718
C3          0.561074               0.561074             0.0512346
C5          0.515221               0.515221             0.0470476
C4          0.48661                0.48661              0.0444349
C2          0.430094               0.430094             0.0392742
C1          0.40076                0.40076              0.0365954
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_5

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007888172736443266  0.0001728231436572969  0.0         -0.010920697494384513  0.28568708896636963  0.2257431414423323   0.24916261434555054
    3        26       Softmax                      0.0   0.0   0.004768452100891479   0.009560037404298782   0.0         -0.3943464908054291    0.8666880130767822   -0.4602200200961063  0.332861065864563


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22354136371961514
RMSE: 0.4728016113758657
LogLoss: 0.7338943147795612
Mean Per-Class Error: 0.20455887949951707
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    7.0    3.0    1.0    6.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    1.0    0.0    6.0    2.0    5.0    3.0    0.10886075949367088  43 / 395
0.0    314.0  0.0    11.0   0.0    1.0    2.0    7.0    2.0    0.0    1.0    0.0    0.0    0.0    8.0    12.0   0.0    13.0   5.0    0.0    0.0    0.0    1.0    4.0    0.0    2.0    0.1801566579634465   69 / 383
0.0    0.0    309.0  0.0    13.0   0.0    19.0   0.0    0.0    0.0    12.0   0.0    0.0    0.0    6.0    0.0    1.0    0.0    1.0    4.0    1.0    1.0    1.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
1.0    14.0   0.0    323.0  0.0    0.0    2.0    11.0   1.0    5.0    0.0    1.0    4.0    6.0    6.0    3.0    0.0    14.0   3.0    2.0    0.0    0.0    0.0    2.0    0.0    4.0    0.19651741293532338  79 / 402
0.0    11.0   6.0    0.0    286.0  1.0    12.0   2.0    0.0    0.0    10.0   2.0    0.0    0.0    0.0    1.0    8.0    7.0    7.0    6.0    0.0    0.0    0.0    7.0    0.0    18.0   0.2552083333333333   98 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    2.0    0.0    23.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    3.0    0.0    4.0    4.0    0.0    1.0    3.0    1.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    8.0    3.0    19.0   5.0    2.0    0.0    0.0    330.0  1.0    1.0    0.16243654822335024  64 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    21.0   2.0    26.0   0.0    0.0    329.0  0.0    0.1628498727735369   64 / 393
1.0    0.0    0.0    1.0    13.0   0.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    41.0   2.0    0.0    0.0    0.0    3.0    1.0    288.0  0.21525885558583105  79 / 367
384.0  505.0  381.0  420.0  349.0  340.0  336.0  343.0  326.0  364.0  414.0  354.0  443.0  362.0  394.0  415.0  354.0  409.0  390.0  395.0  388.0  376.0  416.0  407.0  376.0  362.0  0.20373887833649906  2,038 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796261
2    0.878836
3    0.914126
4    0.93472
5    0.951515
6    0.960912
7    0.969209
8    0.975008
9    0.980906
10   0.985904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22890202960196693
RMSE: 0.478437069636088
LogLoss: 0.7472492952628547
Mean Per-Class Error: 0.2128134220732066
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   3.0    0.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   80.0   0.0   4.0    0.0   0.0   0.0   2.0   1.0   0.0   1.0    0.0   0.0   0.0   4.0   5.0    0.0   4.0    2.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0   0.24528301886792453  26 / 106
0.0   0.0    64.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0   2.0   0.0   1.0   0.0    0.0    0.0    0.0   0.21951219512195122  18 / 82
1.0   2.0    0.0   93.0   0.0   0.0   1.0   4.0   0.0   2.0   0.0    1.0   2.0   2.0   1.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   3.0    2.0   0.0    65.0  1.0   2.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0    3.0   2.0    3.0   3.0   0.0   0.0   0.0    3.0    0.0    6.0   0.32989690721649484  32 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   7.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   1.0    0.0   3.0    1.0   0.0   1.0   2.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0    1.0   1.0    6.0   1.0   0.0   0.0   0.0    79.0   0.0    1.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   6.0   0.0   8.0   0.0    0.0    87.0   0.0   0.18691588785046728  20 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    11.0  1.0   0.0   0.0   0.0    1.0    0.0    67.0  0.22988505747126436  20 / 87
90.0  130.0  80.0  123.0  78.0  83.0  82.0  85.0  78.0  99.0  104.0  94.0  98.0  98.0  85.0  114.0  92.0  104.0  99.0  95.0  97.0  86.0  102.0  101.0  104.0  89.0  0.21244979919678714  529 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.78755
2    0.877912
3    0.915663
4    0.938956
5    0.952611
6    0.961446
7    0.970683
8    0.9751
9    0.982731
10   0.987149
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:38  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:38  14.506 sec  158841 obs/sec    1         1             10007      0.705805         1.53134             0.991148       0.39878                          0.707905           1.53877               0.991071         0.413253
    2019-07-24 15:35:38  14.969 sec  195831 obs/sec    10        10            100070     0.472802         0.733894            0.996028       0.203739                         0.478437           0.747249              0.995921         0.21245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0845984
C13         0.987221               0.987221             0.0835173
C7          0.925994               0.925994             0.0783376
C9          0.891029               0.891029             0.0753797
C12         0.88357                0.88357              0.0747486
C8          0.78739                0.78739              0.066612
C10         0.734108               0.734108             0.0621044
C11         0.731337               0.731337             0.0618699
C5          0.718682               0.718682             0.0607994
C14         0.6924                 0.6924               0.0585759
C4          0.671067               0.671067             0.0567712
C6          0.619944               0.619944             0.0524463
C3          0.608109               0.608109             0.0514451
C16         0.572468               0.572468             0.0484299
C2          0.511478               0.511478             0.0432703
C1          0.485755               0.485755             0.0410941
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_8

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.001308470859441968   0.00037608121056109667  0.0         0.0194437900193698     0.743494987487793   0.1507436987305659    0.8124091625213623
    3        26       Softmax                 0.0   0.0   0.0019045565950364107  0.0004242901923134923   0.0         -0.006501851507961804  0.4985170364379883  -0.45304331552063765  0.22678130865097046


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22239898011011786
RMSE: 0.47159196357668975
LogLoss: 0.7453837773561665
Mean Per-Class Error: 0.2185166366458754
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    12.0   0.0    1.0    0.0    3.0    0.0    3.0    0.0    2.0    2.0    2.0    2.0    4.0    2.0    0.09898477157360407  39 / 394
0.0    298.0  0.0    6.0    1.0    2.0    2.0    14.0   3.0    0.0    2.0    0.0    1.0    0.0    0.0    2.0    0.0    24.0   14.0   0.0    1.0    8.0    0.0    3.0    1.0    0.0    0.2198952879581152   84 / 382
0.0    0.0    286.0  1.0    20.0   3.0    13.0   3.0    0.0    0.0    19.0   1.0    2.0    0.0    4.0    0.0    5.0    0.0    3.0    1.0    4.0    0.0    2.0    1.0    0.0    0.0    0.22282608695652173  82 / 368
2.0    17.0   0.0    304.0  0.0    2.0    0.0    13.0   1.0    7.0    0.0    0.0    4.0    8.0    3.0    4.0    0.0    21.0   2.0    2.0    0.0    0.0    0.0    9.0    0.0    4.0    0.2456575682382134   99 / 403
0.0    8.0    0.0    0.0    284.0  2.0    14.0   0.0    2.0    0.0    9.0    2.0    0.0    0.0    0.0    1.0    7.0    3.0    5.0    14.0   1.0    0.0    0.0    13.0   0.0    19.0   0.2604166666666667   100 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    1.0    0.0    0.0    0.0    1.0    15.0   0.0    0.0    0.0    0.0    8.0    9.0    8.0    0.0    0.0    1.0    0.0    0.0    4.0    2.0    327.0  0.0    0.0    0.0    0.13031914893617022  49 / 376
0.0    2.0    1.0    8.0    9.0    1.0    1.0    3.0    2.0    0.0    6.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    9.0    3.0    1.0    1.0    0.0    328.0  7.0    5.0    0.16751269035532995  66 / 394
2.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    6.0    0.0    3.0    26.0   2.0    14.0   1.0    0.0    328.0  1.0    0.16539440203562342  65 / 393
0.0    0.0    0.0    0.0    12.0   1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    32.0   8.0    0.0    0.0    0.0    5.0    0.0    291.0  0.20708446866485014  76 / 367
417.0  485.0  343.0  384.0  376.0  383.0  345.0  392.0  343.0  381.0  358.0  335.0  454.0  361.0  417.0  365.0  384.0  409.0  305.0  377.0  383.0  385.0  395.0  429.0  420.0  377.0  0.21763470958712386  2,177 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782365
2    0.873038
3    0.916425
4    0.937319
5    0.952414
6    0.964411
7    0.971708
8    0.977807
9    0.981905
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22375740214628428
RMSE: 0.4730300224576494
LogLoss: 0.74789558197885
Mean Per-Class Error: 0.2218653486903331
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7      8     9      10    11    12    13    14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   2.0    1.0    2.0    1.0   0.10112359550561797  9 / 89
0.0    77.0   0.0   2.0    0.0   0.0   2.0   6.0    1.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0   8.0    2.0   0.0   1.0   4.0   0.0    1.0    0.0    0.0   0.27358490566037735  29 / 106
0.0    0.0    58.0  0.0    4.0   2.0   4.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   2.0   0.0    1.0   0.0    2.0   1.0   1.0   0.0   1.0    0.0    0.0    0.0   0.2926829268292683   24 / 82
1.0    2.0    0.0   84.0   0.0   1.0   0.0   7.0    0.0   2.0    0.0   0.0   1.0   2.0   2.0   2.0    0.0   5.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    2.0   0.25                 28 / 112
0.0    3.0    0.0   0.0    67.0  1.0   5.0   0.0    1.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    1.0   6.0   0.0   0.0   0.0    4.0    0.0    6.0   0.30927835051546393  30 / 97
---    ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   2.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0    1.0    0.0   2.0    3.0   0.0   0.0   1.0    1.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    2.0   1.0   0.0   0.0   0.0    81.0   3.0    1.0   0.19                 19 / 100
2.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0   1.0    2.0   0.0    0.0   7.0   0.0   5.0   1.0    0.0    87.0   0.0   0.18691588785046728  20 / 107
0.0    0.0    0.0   0.0    2.0   0.0   0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    4.0   2.0   0.0   0.0   0.0    2.0    0.0    72.0  0.1724137931034483   15 / 87
100.0  120.0  72.0  107.0  82.0  85.0  88.0  106.0  81.0  114.0  89.0  90.0  95.0  94.0  87.0  104.0  94.0  100.0  80.0  96.0  99.0  90.0  102.0  103.0  114.0  98.0  0.2216867469879518   552 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.778313
2    0.870281
3    0.918072
4    0.935743
5    0.95502
6    0.966265
7    0.971888
8    0.97751
9    0.981526
10   0.984337
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:41  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:41  18.236 sec  82024 obs/sec     1         1             10007      0.602057         1.15571             0.993557       0.316905                         0.598741           1.14188               0.993612         0.312048
    2019-07-24 15:35:43  19.373 sec  81225 obs/sec     10        10            100070     0.471592         0.745384            0.996047       0.217635                         0.47303            0.747896              0.996013         0.221687
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0887239
C15         0.908192               0.908192             0.0805784
C12         0.898105               0.898105             0.0796834
C9          0.870352               0.870352             0.0772211
C8          0.795746               0.795746             0.0706017
C11         0.774842               0.774842             0.068747
C7          0.70554                0.70554              0.0625983
C14         0.683214               0.683214             0.0606174
C16         0.672302               0.672302             0.0596493
C6          0.669251               0.669251             0.0593786
C10         0.656333               0.656333             0.0582325
C5          0.628116               0.628116             0.0557289
C3          0.589225               0.589225             0.0522783
C4          0.583049               0.583049             0.0517304
C1          0.442349               0.442349             0.039247
C2          0.3943                 0.3943               0.0349838
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_68

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.001572049543653975   0.00035149091854691505  0.0         -0.02810804204770534  0.752403736114502   0.004689542768591445  0.7452688217163086
    3        26       Softmax                 0.0   0.0   0.0019076926419424685  0.0003105386858806014   0.0         0.00582725472413979   0.3888833522796631  -0.5520496035566386   0.25726866722106934


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21480226848146722
RMSE: 0.46346765634881926
LogLoss: 0.7337163380464495
Mean Per-Class Error: 0.21001037691456198
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    8.0    0.0    0.0    0.0    0.0    1.0    6.0    3.0    1.0    0.0    2.0    5.0    6.0    2.0    0.09873417721518987  39 / 395
0.0    315.0  0.0    4.0    2.0    2.0    0.0    9.0    3.0    0.0    1.0    0.0    1.0    0.0    1.0    2.0    2.0    19.0   13.0   0.0    1.0    4.0    0.0    2.0    1.0    1.0    0.17754569190600522  68 / 383
0.0    0.0    298.0  0.0    14.0   0.0    14.0   0.0    0.0    0.0    22.0   0.0    0.0    0.0    4.0    0.0    3.0    0.0    4.0    2.0    2.0    0.0    5.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
4.0    25.0   0.0    319.0  0.0    3.0    0.0    7.0    0.0    5.0    2.0    0.0    8.0    4.0    4.0    1.0    0.0    8.0    3.0    1.0    1.0    0.0    0.0    4.0    0.0    4.0    0.20843672456575682  84 / 403
0.0    14.0   1.0    0.0    300.0  8.0    9.0    1.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    12.0   3.0    11.0   6.0    0.0    0.0    0.0    4.0    0.0    8.0    0.21875              84 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    13.0   0.0    3.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    5.0    0.0    3.0    6.0    1.0    1.0    1.0    5.0    3.0    14.0   1.0    0.0    0.0    2.0    1.0    8.0    1.0    6.0    3.0    1.0    0.0    0.0    325.0  5.0    2.0    0.1751269035532995   69 / 394
0.0    0.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    9.0    0.0    4.0    34.0   0.0    42.0   3.0    1.0    291.0  0.0    0.2595419847328244   102 / 393
0.0    1.0    0.0    1.0    17.0   1.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    0.0    0.0    3.0    1.0    29.0   8.0    0.0    0.0    0.0    0.0    0.0    291.0  0.20273972602739726  74 / 365
399.0  499.0  358.0  427.0  388.0  375.0  323.0  296.0  332.0  368.0  396.0  347.0  450.0  372.0  366.0  379.0  374.0  444.0  346.0  423.0  376.0  391.0  449.0  408.0  356.0  361.0  0.2091372588223533   2,092 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790863
2    0.881636
3    0.918824
4    0.939018
5    0.953814
6    0.961611
7    0.969809
8    0.976007
9    0.981106
10   0.985204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2185204473652231
RMSE: 0.46746170684369764
LogLoss: 0.7480992247197362
Mean Per-Class Error: 0.21331046795624606
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13     14    15     16     17     18    19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0    0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   80.0   0.0   1.0    1.0   1.0   0.0   3.0   1.0   0.0    0.0    0.0   0.0    0.0    1.0   0.0    1.0    7.0    4.0   0.0   1.0   3.0   0.0    2.0   0.0    0.0   0.24528301886792453  26 / 106
0.0   0.0    60.0  0.0    1.0   0.0   6.0   0.0   0.0   0.0    5.0    0.0   0.0    0.0    2.0   0.0    1.0    0.0    3.0   1.0   1.0   0.0   2.0    0.0   0.0    0.0   0.2682926829268293   22 / 82
2.0   1.0    0.0   93.0   0.0   1.0   0.0   3.0   0.0   1.0    1.0    0.0   3.0    1.0    0.0   0.0    0.0    3.0    1.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.16964285714285715  19 / 112
0.0   3.0    1.0   0.0    73.0  5.0   1.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0    0.0   0.0    3.0    1.0    3.0   2.0   0.0   0.0   0.0    0.0   0.0    4.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0    0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0   0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   2.0    0.0   2.0    3.0   1.0   0.0   1.0   2.0   0.0    5.0    1.0   0.0    0.0    0.0   0.0    2.0    1.0    0.0   0.0   0.0   0.0   0.0    77.0  2.0    1.0   0.23                 23 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0    0.0   1.0    3.0    0.0    0.0   8.0   0.0   11.0  2.0    0.0   82.0   0.0   0.2336448598130841   25 / 107
0.0   0.0    0.0   1.0    5.0   1.0   0.0   0.0   0.0   1.0    0.0    1.0   0.0    0.0    0.0   0.0    2.0    0.0    3.0   3.0   0.0   0.0   0.0    0.0   0.0    70.0  0.19540229885057472  17 / 87
94.0  114.0  72.0  127.0  90.0  88.0  80.0  79.0  81.0  101.0  100.0  98.0  100.0  103.0  69.0  105.0  107.0  113.0  81.0  99.0  97.0  91.0  108.0  97.0  103.0  93.0  0.21244979919678714  529 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.78755
2    0.881124
3    0.916064
4    0.938554
5    0.95261
6    0.959036
7    0.966667
8    0.973092
9    0.981124
10   0.986747
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:15  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:15  1 min 51.749 sec  51056 obs/sec     1         1             10007      0.581117         1.08774             0.993997       0.294512                         0.581921           1.08135               0.993966         0.300803
    2019-07-24 15:37:17  1 min 53.534 sec  51582 obs/sec     10        10            100070     0.463468         0.733716            0.996181       0.209137                         0.467462           0.748099              0.996106         0.21245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0925247
C13         0.903681               0.903681             0.0836128
C12         0.876043               0.876043             0.0810556
C9          0.845909               0.845909             0.0782675
C7          0.804055               0.804055             0.0743949
C11         0.803203               0.803203             0.0743161
C8          0.72565                0.72565              0.0671406
C14         0.661204               0.661204             0.0611777
C10         0.628874               0.628874             0.0581864
C6          0.627807               0.627807             0.0580877
C16         0.567764               0.567764             0.0525322
C3          0.543095               0.543095             0.0502497
C4          0.509731               0.509731             0.0471627
C5          0.508656               0.508656             0.0470632
C2          0.424002               0.424002             0.0392307
C1          0.378251               0.378251             0.0349976
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_63

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007774420166128948  0.00018123607151210308  0.0         -0.00807754365882829  0.28578102588653564  0.1918621541104873   0.22491133213043213
    3        26       Softmax                      0.0   0.0   0.005476768653282376   0.01738477498292923     0.0         -0.37456131110173796  0.890531063079834    -0.4515561705228877  0.37632930278778076


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22497695991705383
RMSE: 0.47431736202362845
LogLoss: 0.7436193530622185
Mean Per-Class Error: 0.20474996249399507
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    4.0    4.0    0.0    4.0    0.0    1.0    0.0    1.0    3.0    7.0    0.0    1.0    0.0    3.0    2.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    309.0  0.0    2.0    1.0    1.0    4.0    13.0   1.0    0.0    5.0    1.0    1.0    1.0    3.0    3.0    0.0    22.0   12.0   0.0    0.0    1.0    1.0    1.0    1.0    0.0    0.19321148825065274  74 / 383
0.0    0.0    297.0  0.0    12.0   5.0    14.0   0.0    0.0    0.0    23.0   0.0    0.0    0.0    3.0    0.0    4.0    1.0    4.0    1.0    2.0    0.0    2.0    0.0    0.0    0.0    0.19293478260869565  71 / 368
4.0    23.0   0.0    319.0  0.0    5.0    0.0    8.0    1.0    6.0    0.0    6.0    3.0    7.0    2.0    1.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.20843672456575682  84 / 403
0.0    13.0   4.0    0.0    287.0  2.0    19.0   2.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    1.0    5.0    3.0    16.0   4.0    0.0    0.0    0.0    6.0    1.0    14.0   0.2526041666666667   97 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
2.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    12.0   0.0    0.0    3.0    3.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    4.0    0.0    5.0    4.0    0.0    0.0    4.0    6.0    1.0    8.0    1.0    0.0    0.0    0.0    0.0    10.0   1.0    14.0   2.0    1.0    0.0    0.0    326.0  5.0    2.0    0.17258883248730963  68 / 394
1.0    0.0    0.0    0.0    1.0    5.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    6.0    20.0   0.0    26.0   1.0    0.0    325.0  1.0    0.17091836734693877  67 / 392
4.0    0.0    0.0    0.0    13.0   0.0    1.0    0.0    1.0    13.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    28.0   3.0    0.0    0.0    0.0    7.0    1.0    294.0  0.1989100817438692   73 / 367
424.0  513.0  336.0  387.0  372.0  381.0  357.0  346.0  354.0  365.0  395.0  360.0  416.0  365.0  351.0  380.0  352.0  464.0  379.0  360.0  386.0  377.0  418.0  416.0  379.0  370.0  0.20403878836349096  2,041 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.795961
2    0.877037
3    0.912326
4    0.93302
5    0.948215
6    0.960612
7    0.968509
8    0.973408
9    0.979706
10   0.983705

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22689577994561966
RMSE: 0.47633578486779643
LogLoss: 0.7489925698541345
Mean Per-Class Error: 0.209348599639775
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20    21    22     23    24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   1.0    1.0   2.0    0.0   0.0898876404494382   8 / 89
0.0    78.0   0.0   1.0    1.0   0.0   1.0   6.0   0.0   0.0    2.0    0.0   0.0   0.0   2.0   0.0    0.0   8.0    5.0    0.0   0.0   1.0   0.0    1.0   0.0    0.0   0.2641509433962264   28 / 106
0.0    0.0    63.0  0.0    0.0   2.0   4.0   0.0   0.0   0.0    7.0    0.0   0.0   0.0   2.0   0.0    1.0   0.0    1.0    1.0   0.0   0.0   1.0    0.0   0.0    0.0   0.23170731707317074  19 / 82
1.0    4.0    0.0   91.0   0.0   1.0   0.0   3.0   0.0   2.0    0.0    3.0   2.0   2.0   0.0   1.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.1875               21 / 112
0.0    2.0    0.0   0.0    70.0  2.0   7.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    4.0    2.0   0.0   0.0   0.0    2.0   0.0    5.0   0.27835051546391754  27 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   1.0   0.0   0.0    0.0   2.0    0.0    0.0   1.0   2.0   82.0   0.0   0.0    0.0   0.10869565217391304  10 / 92
0.0    1.0    0.0   3.0    2.0   0.0   0.0   2.0   2.0   0.0    3.0    1.0   0.0   0.0   0.0   0.0    2.0   1.0    6.0    0.0   0.0   0.0   0.0    76.0  1.0    0.0   0.24                 24 / 100
0.0    0.0    0.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    6.0   0.0   6.0   1.0    0.0   91.0   0.0   0.14953271028037382  16 / 107
1.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0    0.0   0.0   0.0   0.0    2.0   1.0    68.0  0.21839080459770116  19 / 87
102.0  116.0  67.0  111.0  86.0  93.0  90.0  86.0  84.0  105.0  102.0  95.0  88.0  96.0  69.0  110.0  92.0  122.0  102.0  86.0  99.0  87.0  101.0  99.0  111.0  91.0  0.20763052208835342  517 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792369
2    0.875904
3    0.915261
4    0.932129
5    0.946185
6    0.95743
7    0.965863
8    0.969879
9    0.976707
10   0.981124
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:09  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:09  1 min 46.255 sec  175561 obs/sec    1         1             10007      0.695555         1.47982             0.991403       0.397381                         0.69488            1.47316               0.991396         0.401606
    2019-07-24 15:37:10  1 min 46.821 sec  164049 obs/sec    10        10            100070     0.474317         0.743619            0.996002       0.204039                         0.476336           0.748993              0.995957         0.207631
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0944734
C13         0.975741               0.975741             0.0921816
C9          0.851117               0.851117             0.080408
C8          0.799327               0.799327             0.0755151
C12         0.740674               0.740674             0.069974
C7          0.727043               0.727043             0.0686862
C10         0.644837               0.644837             0.0609199
C5          0.642237               0.642237             0.0606744
C6          0.612392               0.612392             0.0578548
C14         0.585358               0.585358             0.0553008
C11         0.578465               0.578465             0.0546496
C3          0.547207               0.547207             0.0516966
C4          0.54031                0.54031              0.051045
C16         0.537756               0.537756             0.0508036
C1          0.427137               0.427137             0.0403531
C2          0.375384               0.375384             0.0354638
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_39

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011146418869429908  0.00029261503368616104  0.0         -0.007281450050697913  0.5865709781646729  -0.05934363051926772  0.6880919933319092
    3        26       Softmax                 0.0   0.0   0.002249549645757025   0.000689357053488493    0.0         -0.03610399687386234   0.7327148914337158  -0.5226427887141096   0.21036428213119507


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2202820197638139
RMSE: 0.4693421137760961
LogLoss: 0.7451421036415301
Mean Per-Class Error: 0.20802839159654074
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  1.0    0.0    2.0    0.0    1.0    2.0    0.0    1.0    8.0    3.0    0.0    9.0    0.0    1.0    0.0    1.0    1.0    1.0    0.0    1.0    0.0    6.0    1.0    6.0    0.0    0.11392405063291139  45 / 395
1.0    316.0  0.0    7.0    0.0    1.0    1.0    7.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    4.0    2.0    22.0   8.0    0.0    0.0    5.0    0.0    3.0    1.0    1.0    0.17493472584856398  67 / 383
0.0    0.0    295.0  0.0    13.0   0.0    19.0   1.0    0.0    0.0    25.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    5.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.1983695652173913   73 / 368
2.0    14.0   0.0    325.0  0.0    3.0    0.0    7.0    0.0    7.0    2.0    0.0    7.0    5.0    2.0    2.0    1.0    9.0    1.0    1.0    3.0    0.0    0.0    4.0    1.0    7.0    0.1935483870967742   78 / 403
0.0    4.0    1.0    0.0    291.0  2.0    29.0   0.0    1.0    0.0    8.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    16.0   2.0    0.0    0.0    0.0    8.0    0.0    17.0   0.2421875            93 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    10.0   0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    13.0   2.0    3.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    2.0    0.0    3.0    6.0    0.0    1.0    3.0    1.0    1.0    10.0   1.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    8.0    1.0    0.0    0.0    335.0  4.0    8.0    0.14974619289340102  59 / 394
0.0    0.0    1.0    1.0    0.0    9.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    7.0    12.0   0.0    0.0    25.0   2.0    43.0   0.0    0.0    289.0  0.0    0.2627551020408163   103 / 392
0.0    2.0    0.0    0.0    11.0   1.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    36.0   4.0    0.0    0.0    0.0    1.0    1.0    293.0  0.2016348773841962   74 / 367
415.0  475.0  342.0  433.0  359.0  349.0  383.0  343.0  329.0  377.0  413.0  342.0  435.0  361.0  381.0  386.0  349.0  410.0  372.0  365.0  401.0  411.0  409.0  407.0  367.0  389.0  0.2073377986604019   2,074 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792662
2    0.877837
3    0.915425
4    0.936919
5    0.952714
6    0.963111
7    0.970009
8    0.976007
9    0.980306
10   0.984205

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22051758592228984
RMSE: 0.4695930002909859
LogLoss: 0.750929385199447
Mean Per-Class Error: 0.20608181304235493
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20     21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  ----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    1.0   1.0    1.0    0.0   0.0    0.0   2.0    1.0   3.0   0.0   0.12359550561797752  11 / 89
0.0   84.0   0.0   0.0    0.0   0.0   1.0   3.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0   7.0    3.0    0.0   0.0    4.0   0.0    1.0   1.0   0.0   0.20754716981132076  22 / 106
0.0   0.0    65.0  0.0    1.0   0.0   4.0   0.0   0.0   0.0    7.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0    2.0    0.0   1.0    0.0   1.0    0.0   0.0   0.0   0.2073170731707317   17 / 82
2.0   2.0    0.0   93.0   0.0   1.0   0.0   2.0   0.0   2.0    1.0    0.0   3.0   0.0   2.0   1.0    1.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    70.0  1.0   8.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    5.0    1.0   0.0    0.0   0.0    1.0   0.0   6.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---   ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   4.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   83.0   0.0   0.0   0.0   0.09782608695652174  9 / 92
0.0   0.0    0.0   2.0    4.0   0.0   1.0   1.0   0.0   0.0    5.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0   0.0    0.0   0.0    81.0  1.0   3.0   0.19                 19 / 100
0.0   0.0    1.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   1.0   2.0    4.0   0.0    0.0    8.0   1.0    13.0  0.0    0.0   74.0  0.0   0.308411214953271    33 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0    1.0   0.0    0.0   0.0    1.0   0.0   70.0  0.19540229885057472  17 / 87
92.0  116.0  74.0  128.0  81.0  83.0  96.0  86.0  77.0  104.0  107.0  96.0  92.0  98.0  81.0  109.0  90.0  101.0  101.0  85.0  101.0  98.0  100.0  98.0  99.0  97.0  0.20642570281124498  514 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793574
2    0.882329
3    0.916466
4    0.93494
5    0.949398
6    0.961847
7    0.969478
8    0.974699
9    0.978715
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:33  1 min  9.449 sec  137082 obs/sec    1         1             10007      0.669368         1.38101             0.992038       0.389983                         0.665382           1.36028               0.992111         0.383133
    2019-07-24 15:36:33  1 min 10.118 sec  137837 obs/sec    10        10            100070     0.469342         0.745142            0.996086       0.207338                         0.469593           0.750929              0.996071         0.206426
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.102565
C13         0.904004               0.904004             0.0927195
C12         0.834328               0.834328             0.0855731
C7          0.746589               0.746589             0.0765741
C8          0.745985               0.745985             0.0765122
C11         0.687052               0.687052             0.0704677
C9          0.676755               0.676755             0.0694116
C10         0.612978               0.612978             0.0628703
C16         0.602488               0.602488             0.0617944
C6          0.568126               0.568126             0.0582701
C14         0.562994               0.562994             0.0577437
C5          0.502298               0.502298             0.0515184
C4          0.41883                0.41883              0.0429574
C3          0.397512               0.397512             0.040771
C1          0.267756               0.267756             0.0274625
C2          0.222188               0.222188             0.0227888
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_46

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015223122412635348  0.0003887471975758672   0.0         0.024577426986954976   0.7687423229217529   0.09884084497769415  0.7527637481689453
    3        26       Softmax                 0.0   0.0   0.0018324946026600979  0.00027728104032576084  0.0         -0.015541463923717367  0.38157832622528076  -0.5459953060192966  0.23727864027023315


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21473817319220864
RMSE: 0.4633985036577143
LogLoss: 0.7332937459184753
Mean Per-Class Error: 0.21136922287663262
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    7.0    0.0    6.0    0.0    1.0    0.0    4.0    0.0    1.0    0.0    3.0    2.0    7.0    0.0    0.09113924050632911  36 / 395
0.0    310.0  0.0    13.0   4.0    1.0    5.0    11.0   2.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    1.0    16.0   7.0    0.0    0.0    5.0    0.0    1.0    2.0    0.0    0.1906005221932115   73 / 383
0.0    0.0    289.0  0.0    17.0   1.0    24.0   2.0    0.0    0.0    13.0   0.0    1.0    0.0    8.0    1.0    2.0    0.0    3.0    2.0    2.0    0.0    3.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
5.0    15.0   0.0    327.0  0.0    3.0    0.0    4.0    0.0    1.0    1.0    0.0    5.0    4.0    8.0    7.0    0.0    15.0   1.0    1.0    1.0    0.0    0.0    3.0    0.0    2.0    0.18858560794044665  76 / 403
0.0    4.0    0.0    0.0    302.0  9.0    16.0   0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    9.0    4.0    12.0   4.0    0.0    0.0    0.0    2.0    1.0    16.0   0.21354166666666666  82 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    1.0    0.0    9.0    0.0    2.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    3.0    0.0    13.0   9.0    1.0    0.0    1.0    3.0    1.0    9.0    0.0    0.0    0.0    2.0    0.0    8.0    1.0    10.0   7.0    2.0    1.0    0.0    306.0  9.0    7.0    0.22137404580152673  87 / 393
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    3.0    13.0   5.0    10.0   1.0    0.0    350.0  0.0    0.10941475826972011  43 / 393
2.0    0.0    0.0    2.0    21.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    44.0   5.0    0.0    0.0    0.0    0.0    0.0    279.0  0.23978201634877383  88 / 367
424.0  462.0  324.0  445.0  420.0  358.0  398.0  286.0  335.0  343.0  359.0  321.0  419.0  385.0  413.0  397.0  365.0  437.0  349.0  393.0  408.0  363.0  440.0  367.0  439.0  353.0  0.2099370188943317   2,100 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790063
2    0.880136
3    0.916525
4    0.938418
5    0.952914
6    0.961512
7    0.969709
8    0.976007
9    0.980306
10   0.984605

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2190502291498071
RMSE: 0.4680280217570387
LogLoss: 0.7513522275760283
Mean Per-Class Error: 0.21807110924793302
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0   0.06741573033707865  6 / 89
0.0    79.0   0.0   3.0    2.0   1.0   3.0   4.0   0.0   0.0   1.0   0.0   0.0   0.0   2.0   0.0    0.0   5.0    1.0   0.0   0.0    3.0   0.0    1.0   1.0    0.0   0.25471698113207547  27 / 106
0.0    0.0    60.0  0.0    3.0   0.0   7.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    1.0   2.0   1.0    0.0   1.0    0.0   0.0    0.0   0.2682926829268293   22 / 82
3.0    4.0    0.0   90.0   0.0   0.0   0.0   2.0   0.0   1.0   1.0   0.0   2.0   1.0   2.0   2.0    0.0   3.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.19642857142857142  22 / 112
0.0    1.0    0.0   0.0    71.0  5.0   6.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    2.0   2.0   0.0    0.0   0.0    0.0   0.0    7.0   0.26804123711340205  26 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0    0.0    0.0   5.0    5.0   0.0   0.0   1.0   1.0   0.0   4.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    3.0   0.0   1.0    0.0   0.0    69.0  6.0    3.0   0.31                 31 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0   4.0   2.0    2.0   1.0    0.0   95.0   0.0   0.11214953271028037  12 / 107
0.0    0.0    0.0   1.0    7.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    9.0   2.0   0.0    0.0   0.0    0.0   0.0    65.0  0.25287356321839083  22 / 87
104.0  111.0  67.0  121.0  98.0  82.0  97.0  74.0  79.0  97.0  96.0  87.0  91.0  99.0  88.0  111.0  90.0  109.0  86.0  99.0  106.0  82.0  112.0  88.0  125.0  91.0  0.21726907630522088  541 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782731
2    0.879518
3    0.916466
4    0.934538
5    0.951004
6    0.959438
7    0.96747
8    0.973896
9    0.979518
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:44  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:44  1 min 21.112 sec  54091 obs/sec     1         1             10007      0.587467         1.10744             0.993867       0.308807                         0.586016           1.09677               0.993881         0.315663
    2019-07-24 15:36:46  1 min 22.867 sec  52557 obs/sec     10        10            100070     0.463399         0.733294            0.996184       0.209937                         0.468028           0.751352              0.996097         0.217269
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0871031
C9          0.951607               0.951607             0.0828879
C12         0.927001               0.927001             0.0807447
C13         0.920058               0.920058             0.0801399
C11         0.852821               0.852821             0.0742834
C7          0.836033               0.836033             0.0728211
C8          0.806278               0.806278             0.0702293
C14         0.721326               0.721326             0.0628298
C10         0.64485                0.64485              0.0561684
C6          0.625339               0.625339             0.054469
C3          0.614106               0.614106             0.0534906
C4          0.583001               0.583001             0.0507812
C16         0.579012               0.579012             0.0504337
C5          0.550413               0.550413             0.0479427
C2          0.447576               0.447576             0.0389853
C1          0.421223               0.421223             0.0366898
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_53

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0010900570268859155  0.0003299260279163718   0.0         -0.017802342215304634  0.5675225257873535  0.08370933043106303  0.6676561832427979
    3        26       Softmax                 0.0   0.0   0.0022332676870484226  0.00048300588969141245  0.0         0.015129167877183556   0.7390706539154053  -0.5440353784845684  0.26598525047302246


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22602391473350145
RMSE: 0.4754197248048312
LogLoss: 0.7543750969791326
Mean Per-Class Error: 0.21284358775241094
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    7.0    7.0    0.0    3.0    0.0    0.0    0.0    2.0    2.0    7.0    0.0    1.0    0.0    2.0    1.0    6.0    0.0    0.10152284263959391  40 / 394
0.0    313.0  0.0    13.0   0.0    1.0    4.0    7.0    1.0    1.0    0.0    0.0    0.0    0.0    6.0    3.0    3.0    14.0   7.0    0.0    0.0    4.0    0.0    3.0    3.0    0.0    0.18276762402088773  70 / 383
0.0    0.0    294.0  0.0    7.0    1.0    14.0   1.0    2.0    0.0    24.0   0.0    0.0    0.0    6.0    0.0    2.0    0.0    4.0    2.0    5.0    0.0    6.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
5.0    8.0    0.0    338.0  0.0    2.0    0.0    6.0    0.0    2.0    0.0    1.0    5.0    2.0    3.0    1.0    3.0    13.0   0.0    0.0    0.0    0.0    0.0    12.0   0.0    1.0    0.15920398009950248  64 / 402
0.0    7.0    4.0    0.0    274.0  9.0    24.0   2.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    2.0    4.0    17.0   4.0    0.0    1.0    0.0    8.0    3.0    15.0   0.2864583333333333   110 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    12.0   1.0    4.0    0.0    0.0    3.0    0.0    0.0    0.0    3.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    6.0    0.0    8.0    2.0    1.0    0.0    4.0    3.0    3.0    16.0   0.0    0.0    0.0    2.0    0.0    8.0    1.0    13.0   4.0    3.0    0.0    0.0    308.0  5.0    7.0    0.2182741116751269   86 / 394
0.0    0.0    0.0    1.0    0.0    12.0   0.0    1.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    5.0    7.0    0.0    3.0    19.0   3.0    13.0   2.0    2.0    321.0  1.0    0.183206106870229    72 / 393
0.0    0.0    0.0    1.0    17.0   0.0    1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    1.0    31.0   3.0    0.0    0.0    0.0    2.0    0.0    298.0  0.1880108991825613   69 / 367
389.0  458.0  341.0  433.0  335.0  392.0  363.0  351.0  342.0  343.0  420.0  317.0  427.0  375.0  386.0  388.0  388.0  413.0  373.0  357.0  404.0  367.0  429.0  428.0  395.0  389.0  0.2118364490652804   2,119 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788164
2    0.874938
3    0.910227
4    0.930721
5    0.946316
6    0.958712
7    0.969409
8    0.975107
9    0.981605
10   0.985704

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2257419084879064
RMSE: 0.4751230456291364
LogLoss: 0.7554425119746937
Mean Per-Class Error: 0.2121449329476688
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16     17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0   0.0   0.0   1.0    1.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   82.0   0.0   4.0    0.0   0.0   2.0   2.0   0.0   0.0   0.0    0.0   0.0   0.0    2.0   0.0    2.0    6.0    1.0   0.0   0.0   3.0   0.0    1.0    1.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    61.0  0.0    1.0   0.0   5.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    3.0   0.0    1.0    0.0    2.0   1.0   1.0   0.0   2.0    0.0    0.0    0.0   0.25609756097560976  21 / 82
4.0   0.0    0.0   95.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   2.0   1.0    0.0   0.0    0.0    3.0    0.0   0.0   0.0   0.0   0.0    4.0    0.0    1.0   0.15178571428571427  17 / 112
0.0   0.0    2.0   0.0    63.0  5.0   8.0   1.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0    0.0    1.0    5.0   1.0   0.0   0.0   0.0    3.0    0.0    5.0   0.35051546391752575  34 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   1.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0   2.0   86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
0.0   2.0    0.0   4.0    1.0   0.0   0.0   2.0   0.0   0.0   7.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    3.0   0.0   0.0   0.0   0.0    74.0   2.0    3.0   0.26                 26 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   1.0    0.0   2.0    3.0    0.0    0.0   5.0   1.0   5.0   1.0    1.0    85.0   0.0   0.205607476635514    22 / 107
0.0   0.0    0.0   0.0    8.0   0.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0    1.0    2.0   0.0   0.0   0.0   0.0    1.0    0.0    71.0  0.1839080459770115   16 / 87
92.0  112.0  70.0  128.0  77.0  90.0  93.0  87.0  74.0  97.0  108.0  86.0  92.0  102.0  77.0  113.0  111.0  103.0  90.0  86.0  96.0  83.0  106.0  109.0  109.0  99.0  0.21084337349397592  525 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789157
2    0.875904
3    0.911647
4    0.931727
5    0.942972
6    0.95261
7    0.969478
8    0.974297
9    0.97992
10   0.985141
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:58  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:58  1 min 35.278 sec  125087 obs/sec    1         1             10007      0.676534         1.42887             0.991865       0.388284                         0.674926           1.41779               0.991883         0.386345
    2019-07-24 15:36:59  1 min 35.954 sec  135229 obs/sec    10        10            100070     0.47542          0.754375            0.995983       0.211836                         0.475123           0.755443              0.995978         0.210843
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.098942
C9          0.928333               0.928333             0.0918511
C13         0.900916               0.900916             0.0891384
C7          0.784294               0.784294             0.0775996
C8          0.761235               0.761235             0.0753181
C12         0.708905               0.708905             0.0701405
C11         0.693306               0.693306             0.0685971
C14         0.673661               0.673661             0.0666533
C16         0.617315               0.617315             0.0610783
C10         0.610611               0.610611             0.0604151
C6          0.500617               0.500617             0.049532
C5          0.483871               0.483871             0.0478751
C3          0.438792               0.438792             0.043415
C4          0.375924               0.375924             0.0371947
C2          0.358341               0.358341             0.0354549
C1          0.270812               0.270812             0.0267947
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_37

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.001540525923246605   0.00035305123310536146  0.0         -0.016486492022494303  0.7638325691223145  0.06544034194008252  0.7454013824462891
    3        26       Softmax                 0.0   0.0   0.0018424618755698947  0.0003243319224566221   0.0         0.004143969992539836   0.384899377822876   -0.540293016534444   0.23951101303100586


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21654349593567762
RMSE: 0.4653423427281012
LogLoss: 0.7376561537276782
Mean Per-Class Error: 0.2151765860988476
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    0.0    8.0    0.0    0.0    0.0    2.0    1.0    6.0    2.0    2.0    0.0    3.0    1.0    5.0    0.0    0.09620253164556962  38 / 395
0.0    324.0  0.0    7.0    4.0    2.0    2.0    7.0    3.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    16.0   6.0    0.0    0.0    5.0    1.0    1.0    1.0    0.0    0.15404699738903394  59 / 383
0.0    0.0    286.0  0.0    15.0   1.0    16.0   1.0    0.0    0.0    23.0   0.0    1.0    0.0    2.0    0.0    1.0    0.0    7.0    8.0    4.0    0.0    3.0    0.0    0.0    0.0    0.22282608695652173  82 / 368
7.0    19.0   0.0    322.0  0.0    1.0    0.0    2.0    0.0    4.0    1.0    1.0    7.0    5.0    5.0    6.0    0.0    14.0   2.0    1.0    1.0    0.0    0.0    4.0    0.0    1.0    0.20099255583126552  81 / 403
0.0    8.0    1.0    0.0    295.0  2.0    18.0   0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   4.0    12.0   8.0    0.0    0.0    0.0    3.0    0.0    19.0   0.2297650130548303   88 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    3.0    12.0   0.0    0.0    0.0    0.0    19.0   0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    6.0    0.0    7.0    14.0   3.0    0.0    3.0    6.0    2.0    9.0    1.0    0.0    0.0    2.0    0.0    14.0   2.0    15.0   9.0    2.0    0.0    0.0    290.0  3.0    6.0    0.2639593908629442   104 / 394
1.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    7.0    0.0    3.0    35.0   1.0    13.0   3.0    0.0    318.0  0.0    0.19083969465648856  75 / 393
2.0    0.0    0.0    0.0    18.0   0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    42.0   5.0    0.0    0.0    0.0    2.0    0.0    290.0  0.2098092643051771   77 / 367
420.0  521.0  343.0  424.0  416.0  361.0  353.0  293.0  334.0  335.0  368.0  318.0  461.0  368.0  400.0  372.0  374.0  426.0  385.0  447.0  393.0  367.0  422.0  346.0  395.0  361.0  0.21423572928121565  2,143 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785764
2    0.880136
3    0.916725
4    0.937319
5    0.954114
6    0.963711
7    0.971608
8    0.978206
9    0.981905
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22222684418071137
RMSE: 0.47140942309282635
LogLoss: 0.7556123378673069
Mean Per-Class Error: 0.22035185908314758
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18     19     20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.0   1.0    1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   82.0   0.0   1.0    2.0   0.0   2.0   2.0   1.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   6.0    3.0    0.0    0.0   3.0   1.0    1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    60.0  0.0    2.0   0.0   7.0   0.0   0.0   0.0   5.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0    2.0    1.0   0.0   1.0    0.0   0.0    0.0   0.2682926829268293   22 / 82
3.0   3.0    0.0   90.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   1.0   3.0    1.0   2.0   2.0    0.0   2.0    1.0    0.0    1.0   0.0   0.0    1.0   0.0    0.0   0.19642857142857142  22 / 112
0.0   0.0    1.0   0.0    71.0  1.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    4.0    3.0    0.0   0.0   0.0    0.0   0.0    8.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   2.0    5.0   1.0   0.0   2.0   1.0   0.0   4.0   1.0   0.0    0.0   0.0   0.0    3.0   0.0    3.0    1.0    0.0   0.0   0.0    73.0  0.0    2.0   0.27                 27 / 100
1.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    2.0   0.0    0.0    9.0    0.0   5.0   2.0    0.0   86.0   0.0   0.19626168224299065  21 / 107
1.0   0.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0    11.0   2.0    0.0   0.0   0.0    1.0   0.0    65.0  0.25287356321839083  22 / 87
99.0  121.0  72.0  121.0  96.0  82.0  89.0  77.0  75.0  93.0  90.0  87.0  106.0  96.0  81.0  103.0  99.0  109.0  100.0  109.0  99.0  85.0  108.0  92.0  110.0  91.0  0.22008032128514057  548 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.77992
2    0.875502
3    0.914056
4    0.935743
5    0.95261
6    0.961847
7    0.967871
8    0.976305
9    0.981124
10   0.98514
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:29  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:29  1 min  6.203 sec  41695 obs/sec     1         1             10007      0.586475         1.10805             0.993888       0.29931                          0.585151           1.10424               0.993899         0.297992
    2019-07-24 15:36:31  1 min  7.887 sec  53003 obs/sec     10        10            100070     0.465342         0.737656            0.996152       0.214236                         0.471409           0.755612              0.99604          0.22008
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0875246
C13         0.977284               0.977284             0.0855364
C12         0.910302               0.910302             0.0796738
C9          0.899169               0.899169             0.0786994
C7          0.803011               0.803011             0.0702832
C8          0.799173               0.799173             0.0699473
C11         0.78181                0.78181              0.0684276
C14         0.744768               0.744768             0.0651855
C10         0.713168               0.713168             0.0624197
C16         0.613108               0.613108             0.0536621
C6          0.592064               0.592064             0.0518201
C3          0.572904               0.572904             0.0501432
C5          0.569815               0.569815             0.0498728
C4          0.559845               0.559845             0.0490002
C2          0.462925               0.462925             0.0405174
C1          0.426014               0.426014             0.0372867
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_18

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011313537512478433  0.0003225624095648527  0.0         -0.05916178440283204  0.5719761848449707  -0.0650186048654387  0.6311028003692627
    3        26       Softmax                 0.0   0.0   0.0021494953338193367  0.0004428238607943058  0.0         0.03669589806892103   0.7415337562561035  -0.5392536840842911  0.2568553686141968


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22290878905799272
RMSE: 0.472132173292599
LogLoss: 0.7464331345206628
Mean Per-Class Error: 0.20955233504791337
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    10.0   0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    5.0    1.0    7.0    0.0    0.08860759493670886  35 / 395
0.0    308.0  0.0    8.0    2.0    1.0    4.0    10.0   2.0    0.0    3.0    0.0    0.0    0.0    0.0    3.0    1.0    27.0   4.0    2.0    0.0    2.0    0.0    5.0    0.0    0.0    0.193717277486911    74 / 382
0.0    0.0    290.0  0.0    19.0   0.0    9.0    1.0    1.0    0.0    17.0   0.0    0.0    0.0    10.0   0.0    0.0    0.0    1.0    4.0    8.0    0.0    5.0    2.0    1.0    0.0    0.21195652173913043  78 / 368
1.0    23.0   0.0    322.0  0.0    2.0    1.0    8.0    0.0    7.0    0.0    0.0    4.0    6.0    5.0    2.0    0.0    13.0   2.0    1.0    1.0    0.0    0.0    3.0    1.0    1.0    0.20099255583126552  81 / 403
0.0    1.0    4.0    0.0    287.0  7.0    27.0   0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    10.0   5.0    4.0    7.0    0.0    0.0    0.0    4.0    1.0    14.0   0.2506527415143603   96 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
2.0    4.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    1.0    0.0    1.0    8.0    0.0    0.0    1.0    1.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    1.0    0.0    4.0    11.0   3.0    2.0    1.0    2.0    1.0    10.0   0.0    0.0    0.0    0.0    0.0    10.0   1.0    13.0   2.0    3.0    0.0    0.0    327.0  2.0    1.0    0.1700507614213198   67 / 394
0.0    0.0    0.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    6.0    3.0    0.0    3.0    8.0    0.0    14.0   0.0    0.0    352.0  0.0    0.10432569974554708  41 / 393
3.0    0.0    0.0    0.0    20.0   0.0    0.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    26.0   5.0    0.0    0.0    0.0    1.0    1.0    287.0  0.21798365122615804  80 / 367
402.0  488.0  328.0  408.0  405.0  345.0  377.0  314.0  338.0  377.0  386.0  329.0  397.0  384.0  391.0  408.0  342.0  450.0  311.0  383.0  422.0  362.0  429.0  412.0  434.0  381.0  0.2084374687593722   2,085 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791563
2    0.878836
3    0.914326
4    0.936819
5    0.950515
6    0.961412
7    0.96811
8    0.974408
9    0.979906
10   0.984005

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22878201298534098
RMSE: 0.4783116274829005
LogLoss: 0.7590875967507471
Mean Per-Class Error: 0.21905028596177906
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   1.0    0.0    0.0   2.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0    3.0    0.0   0.10112359550561797  9 / 89
0.0   80.0   0.0   1.0    2.0   1.0   4.0   4.0   1.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    1.0   7.0    1.0   0.0   0.0    2.0   0.0    1.0    0.0    0.0   0.24528301886792453  26 / 106
0.0   0.0    59.0  0.0    3.0   0.0   4.0   0.0   0.0   0.0    6.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0    1.0   1.0   1.0    0.0   3.0    0.0    1.0    0.0   0.2804878048780488   23 / 82
1.0   5.0    0.0   87.0   0.0   0.0   0.0   4.0   0.0   2.0    0.0    0.0   2.0   3.0    1.0   0.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    1.0   0.22321428571428573  25 / 112
0.0   0.0    0.0   0.0    66.0  4.0   8.0   0.0   0.0   0.0    5.0    0.0   0.0   0.0    0.0   0.0    3.0   1.0    1.0   4.0   0.0    0.0   0.0    0.0    0.0    5.0   0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   2.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    5.0   0.0   1.0   1.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    4.0   0.0   0.0    0.0   0.0    78.0   1.0    1.0   0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0   0.0   1.0    0.0   3.0    1.0   0.0    0.0   2.0   0.0    4.0   0.0    0.0    95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   4.0    0.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    6.0   2.0   0.0    0.0   0.0    1.0    1.0    66.0  0.2413793103448276   21 / 87
90.0  117.0  64.0  111.0  93.0  75.0  95.0  86.0  77.0  106.0  103.0  91.0  90.0  106.0  77.0  122.0  90.0  108.0  78.0  92.0  102.0  81.0  108.0  105.0  124.0  99.0  0.21726907630522088  541 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.782731
2    0.875502
3    0.912048
4    0.934538
5    0.949398
6    0.960241
7    0.969478
8    0.974699
9    0.981124
10   0.984739
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:00  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:00  37.179 sec  111188 obs/sec    1         1             10007      0.68076          1.42905             0.991763       0.382285                         0.67984            1.41675               0.991765         0.392369
    2019-07-24 15:36:01  37.845 sec  134865 obs/sec    10        10            100070     0.472132         0.746433            0.996038       0.208437                         0.478312           0.759088              0.995923         0.217269
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0971117
C15         0.961695               0.961695             0.0933919
C12         0.830153               0.830153             0.0806175
C9          0.790169               0.790169             0.0767347
C8          0.758316               0.758316             0.0736414
C11         0.726177               0.726177             0.0705203
C14         0.700023               0.700023             0.0679804
C7          0.680109               0.680109             0.0660465
C10         0.634275               0.634275             0.0615955
C6          0.634075               0.634075             0.061576
C16         0.478599               0.478599             0.0464776
C3          0.472354               0.472354             0.045871
C4          0.453829               0.453829             0.0440721
C5          0.448565               0.448565             0.0435609
C2          0.421274               0.421274             0.0409106
C1          0.30781                0.30781              0.029892
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_30

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015711905611226484  0.0003469744697213173   0.0         0.03745281588842886   0.782771110534668   0.04120219392007642  0.7422449588775635
    3        26       Softmax                 0.0   0.0   0.0018110864188761648  0.00025674013886600733  0.0         0.007482496588736991  0.3835228681564331  -0.5553821070072468  0.32861077785491943


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22281345029442223
RMSE: 0.4720311963148434
LogLoss: 0.7570996712086014
Mean Per-Class Error: 0.21710393351849266
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    0.0    7.0    1.0    0.0    0.0    0.0    1.0    4.0    1.0    2.0    0.0    2.0    2.0    8.0    0.0    0.09620253164556962  38 / 395
0.0    316.0  0.0    6.0    2.0    1.0    3.0    4.0    3.0    0.0    3.0    0.0    2.0    0.0    0.0    3.0    2.0    22.0   9.0    0.0    1.0    2.0    0.0    2.0    2.0    0.0    0.17493472584856398  67 / 383
0.0    0.0    282.0  0.0    21.0   1.0    20.0   1.0    0.0    0.0    18.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    11.0   2.0    3.0    0.0    5.0    0.0    0.0    0.0    0.23369565217391305  86 / 368
4.0    23.0   0.0    328.0  0.0    1.0    0.0    1.0    0.0    4.0    1.0    0.0    8.0    3.0    4.0    4.0    0.0    10.0   3.0    0.0    1.0    0.0    0.0    8.0    0.0    0.0    0.18610421836228289  75 / 403
0.0    4.0    2.0    0.0    288.0  1.0    14.0   0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    9.0    7.0    14.0   8.0    0.0    0.0    0.0    13.0   0.0    19.0   0.25                 96 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0    3.0    0.0    10.0   2.0    3.0    0.0    0.0    3.0    0.0    0.0    4.0    1.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
1.0    3.0    0.0    6.0    9.0    1.0    9.0    1.0    9.0    0.0    7.0    1.0    0.0    0.0    2.0    0.0    8.0    2.0    5.0    7.0    3.0    0.0    0.0    308.0  5.0    7.0    0.2182741116751269   86 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    4.0    19.0   0.0    2.0    29.0   2.0    19.0   1.0    0.0    308.0  0.0    0.21628498727735368  85 / 393
1.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    35.0   6.0    0.0    0.0    0.0    6.0    0.0    295.0  0.19618528610354224  72 / 367
408.0  509.0  350.0  462.0  388.0  352.0  343.0  261.0  344.0  332.0  405.0  325.0  444.0  358.0  356.0  382.0  417.0  433.0  364.0  409.0  394.0  357.0  450.0  401.0  391.0  368.0  0.21603518944316705  2,161 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783965
2    0.872438
3    0.914726
4    0.936019
5    0.952014
6    0.964011
7    0.972008
8    0.977507
9    0.981805
10   0.985204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22947648909573412
RMSE: 0.4790370435527237
LogLoss: 0.7790139336682691
Mean Per-Class Error: 0.22879186999672094
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    2.0   3.0    0.0   0.10112359550561797  9 / 89
0.0   81.0   0.0   1.0    2.0   0.0   2.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0    1.0    9.0    2.0   0.0   1.0    2.0   0.0    1.0   1.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    57.0  0.0    5.0   0.0   7.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   2.0   0.0    0.0    0.0    4.0   1.0   1.0    0.0   2.0    0.0   0.0    0.0   0.3048780487804878   25 / 82
2.0   5.0    0.0   94.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   3.0   1.0   1.0   1.0    0.0    2.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.16071428571428573  18 / 112
0.0   2.0    0.0   0.0    72.0  1.0   4.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0    2.0    1.0    3.0   4.0   0.0    0.0   0.0    3.0   0.0    3.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0   1.0   0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
1.0   1.0    0.0   3.0    4.0   1.0   1.0   1.0   2.0   0.0   3.0    1.0   0.0   0.0   0.0   0.0    2.0    1.0    2.0   0.0   1.0    0.0   0.0    72.0  3.0    1.0   0.28                 28 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0   1.0    8.0    0.0    0.0   6.0   1.0    6.0   1.0    0.0   82.0   0.0   0.2336448598130841   25 / 107
0.0   0.0    0.0   1.0    2.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    8.0   3.0   0.0    0.0   0.0    2.0   0.0    66.0  0.2413793103448276   21 / 87
93.0  129.0  72.0  131.0  92.0  79.0  83.0  69.0  81.0  98.0  103.0  87.0  98.0  97.0  68.0  112.0  109.0  104.0  93.0  98.0  103.0  87.0  115.0  95.0  108.0  86.0  0.22730923694779118  566 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.772691
2    0.869076
3    0.912048
4    0.93253
5    0.947791
6    0.959438
7    0.968273
8    0.975904
9    0.981526
10   0.985944
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:20  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:21  57.440 sec  40844 obs/sec     1         1             10007      0.587862         1.10961             0.99386        0.296611                         0.587532           1.10846               0.993849         0.306426
    2019-07-24 15:36:22  59.169 sec  51822 obs/sec     10        10            100070     0.472031         0.7571              0.996041       0.216035                         0.479037           0.779014              0.995911         0.227309
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0866579
C9          0.995556               0.995556             0.0862728
C13         0.990578               0.990578             0.0858414
C12         0.872676               0.872676             0.0756243
C8          0.808989               0.808989             0.0701053
C7          0.795581               0.795581             0.0689434
C11         0.793776               0.793776             0.0687869
C14         0.684677               0.684677             0.0593327
C3          0.667333               0.667333             0.0578297
C10         0.649854               0.649854             0.056315
C6          0.629357               0.629357             0.0545388
C4          0.602598               0.602598             0.0522199
C5          0.583496               0.583496             0.0505645
C16         0.557509               0.557509             0.0483126
C2          0.485119               0.485119             0.0420394
C1          0.422528               0.422528             0.0366154
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_57

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0014050268316054826  0.0003631514264270663   0.0         0.02543636621578571   0.740368127822876    0.18474980420604642  0.7515213489532471
    3        26       Softmax                 0.0   0.0   0.001937302582518896   0.00029563368298113346  0.0         -0.01442705915640265  0.49526524543762207  -0.4644471500234463  0.2323475480079651


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2261105008015905
RMSE: 0.47551077884900833
LogLoss: 0.7523605606783133
Mean Per-Class Error: 0.22131019390640488
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    2.0    0.0    7.0    0.0    0.0    0.0    5.0    3.0    2.0    0.0    3.0    0.0    3.0    2.0    5.0    4.0    0.10379746835443038  41 / 395
0.0    296.0  0.0    3.0    2.0    3.0    1.0    6.0    2.0    1.0    1.0    0.0    1.0    0.0    1.0    7.0    4.0    37.0   11.0   0.0    0.0    1.0    1.0    2.0    3.0    0.0    0.22715404699738903  87 / 383
0.0    0.0    293.0  0.0    16.0   1.0    17.0   0.0    0.0    0.0    16.0   0.0    1.0    0.0    3.0    0.0    2.0    0.0    9.0    2.0    3.0    0.0    5.0    0.0    0.0    0.0    0.20380434782608695  75 / 368
6.0    19.0   0.0    321.0  0.0    1.0    0.0    8.0    0.0    5.0    0.0    0.0    7.0    0.0    0.0    3.0    1.0    14.0   5.0    1.0    2.0    0.0    0.0    2.0    1.0    7.0    0.20347394540942929  82 / 403
0.0    7.0    4.0    0.0    273.0  5.0    11.0   1.0    1.0    0.0    7.0    6.0    0.0    0.0    0.0    2.0    14.0   5.0    19.0   1.0    0.0    0.0    0.0    6.0    0.0    21.0   0.28720626631853785  110 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    24.0   5.0    0.0    0.0    0.0    10.0   0.0    0.0    3.0    2.0    318.0  0.0    0.0    0.0    0.15425531914893617  58 / 376
1.0    3.0    0.0    6.0    4.0    4.0    0.0    2.0    4.0    1.0    10.0   3.0    1.0    0.0    2.0    0.0    8.0    1.0    11.0   0.0    3.0    1.0    0.0    320.0  5.0    4.0    0.18781725888324874  74 / 394
0.0    0.0    0.0    1.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    11.0   0.0    5.0    34.0   4.0    33.0   1.0    1.0    289.0  0.0    0.26463104325699743  104 / 393
2.0    0.0    0.0    1.0    8.0    3.0    0.0    1.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    39.0   5.0    0.0    0.0    0.0    2.0    0.0    297.0  0.1907356948228883   70 / 367
397.0  444.0  332.0  410.0  339.0  408.0  333.0  304.0  327.0  339.0  408.0  366.0  489.0  338.0  347.0  382.0  427.0  481.0  417.0  379.0  417.0  362.0  387.0  397.0  382.0  391.0  0.2205338398480456   2,206 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779466
2    0.876137
3    0.913126
4    0.937619
5    0.951815
6    0.961611
7    0.968609
8    0.974908
9    0.980206
10   0.985304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.23029959990017762
RMSE: 0.47989540516676926
LogLoss: 0.7792026326051693
Mean Per-Class Error: 0.22550517207534998
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5      6     7     8     9     10     11    12     13    14    15     16     17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0    0.0    0.0    0.0   1.0    0.0   1.0   1.0   2.0    1.0   0.07865168539325842  7 / 89
0.0   77.0   0.0   1.0    2.0   1.0    1.0   2.0   1.0   0.0   1.0    0.0   0.0    0.0   0.0   2.0    2.0    9.0    3.0    0.0   0.0    1.0   1.0   1.0   1.0    0.0   0.27358490566037735  29 / 106
0.0   0.0    62.0  0.0    3.0   0.0    6.0   0.0   0.0   0.0   4.0    0.0   0.0    0.0   1.0   0.0    0.0    0.0    3.0    1.0   1.0    0.0   1.0   0.0   0.0    0.0   0.24390243902439024  20 / 82
4.0   3.0    0.0   92.0   0.0   0.0    0.0   2.0   0.0   1.0   0.0    0.0   3.0    0.0   0.0   0.0    0.0    3.0    2.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.17857142857142858  20 / 112
0.0   2.0    0.0   0.0    64.0  5.0    5.0   0.0   0.0   0.0   2.0    2.0   0.0    0.0   0.0   0.0    3.0    2.0    5.0    0.0   0.0    0.0   0.0   3.0   0.0    4.0   0.3402061855670103   33 / 97
---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0    0.0   4.0    2.0   0.0   0.0    0.0    2.0    0.0    0.0   1.0    1.0   81.0  0.0   0.0    0.0   0.11956521739130435  11 / 92
1.0   1.0    0.0   3.0    2.0   1.0    0.0   1.0   1.0   0.0   4.0    1.0   1.0    0.0   0.0   0.0    2.0    0.0    4.0    0.0   0.0    0.0   0.0   76.0  0.0    2.0   0.24                 24 / 100
0.0   0.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    5.0    0.0    0.0    6.0   2.0    11.0  1.0   0.0   79.0   0.0   0.2616822429906542   28 / 107
0.0   0.0    0.0   1.0    2.0   1.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0   0.0    0.0    0.0    6.0    2.0   0.0    0.0   0.0   1.0   0.0    73.0  0.16091954022988506  14 / 87
95.0  108.0  71.0  121.0  80.0  100.0  81.0  75.0  79.0  92.0  106.0  96.0  106.0  88.0  75.0  110.0  108.0  113.0  105.0  85.0  108.0  88.0  99.0  97.0  107.0  97.0  0.2253012048192771   561 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.774699
2    0.869076
3    0.908434
4    0.93253
5    0.945783
6    0.958233
7    0.964659
8    0.96988
9    0.978715
10   0.983936
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:03  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:03  1 min 40.249 sec  82024 obs/sec     1         1             10007      0.600266         1.16911             0.993596       0.310507                         0.59824            1.15914               0.993623         0.306426
    2019-07-24 15:37:05  1 min 41.460 sec  76272 obs/sec     10        10            100070     0.475511         0.752361            0.995982       0.220534                         0.479895           0.779203              0.995896         0.225301
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.088863
C15         0.979211               0.979211             0.0870156
C12         0.900348               0.900348             0.0800076
C9          0.86985                0.86985              0.0772975
C8          0.789221               0.789221             0.0701325
C7          0.769711               0.769711             0.0683988
C11         0.742964               0.742964             0.066022
C14         0.712385               0.712385             0.0633047
C10         0.690664               0.690664             0.0613745
C5          0.638011               0.638011             0.0566955
C16         0.632703               0.632703             0.0562239
C3          0.609518               0.609518             0.0541636
C6          0.587017               0.587017             0.0521641
C4          0.504314               0.504314             0.0448149
C1          0.415611               0.415611             0.0369325
C2          0.411749               0.411749             0.0365892
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_54

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007927117957819974  0.00018013239605352283  0.0         -0.017868553827064204  0.29287827014923096  0.10308060515857663  0.21921098232269287
    3        26       Softmax                      0.0   0.0   0.0050525300540847145  0.01552172377705574     0.0         -0.36599740282522714   0.8812804222106934   -0.5802392001637795  0.4359499216079712


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.25540736481532
RMSE: 0.5053784372283012
LogLoss: 0.8073214143993391
Mean Per-Class Error: 0.2174210673156994
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    6.0    1.0    1.0    0.0    4.0    0.0    11.0   0.0    1.0    5.0    2.0    1.0    4.0    0.0    0.09620253164556962  38 / 395
0.0    330.0  0.0    10.0   2.0    0.0    1.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    2.0    14.0   9.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.13838120104438642  53 / 383
0.0    0.0    300.0  0.0    14.0   1.0    10.0   0.0    0.0    0.0    26.0   0.0    1.0    0.0    3.0    0.0    2.0    0.0    3.0    1.0    2.0    0.0    5.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
1.0    31.0   0.0    319.0  0.0    0.0    0.0    5.0    1.0    2.0    1.0    1.0    7.0    4.0    2.0    3.0    1.0    13.0   3.0    0.0    0.0    0.0    0.0    6.0    0.0    3.0    0.20843672456575682  84 / 403
0.0    8.0    1.0    0.0    307.0  1.0    8.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    3.0    12.0   3.0    13.0   2.0    0.0    0.0    0.0    4.0    0.0    13.0   0.19633507853403143  75 / 382
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    1.0    0.0    0.0    0.0    16.0   0.0    0.0    2.0    0.0    18.0   6.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    1.0    327.0  0.0    0.0    0.0    0.13031914893617022  49 / 376
0.0    4.0    0.0    7.0    6.0    0.0    0.0    1.0    5.0    1.0    9.0    2.0    0.0    0.0    0.0    1.0    11.0   0.0    19.0   2.0    4.0    0.0    0.0    315.0  3.0    4.0    0.20050761421319796  79 / 394
0.0    1.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    1.0    11.0   0.0    14.0   19.0   1.0    45.0   2.0    0.0    287.0  0.0    0.2697201017811705   106 / 393
2.0    1.0    0.0    0.0    15.0   3.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    43.0   1.0    0.0    0.0    0.0    1.0    0.0    290.0  0.2098092643051771   77 / 367
408.0  552.0  372.0  435.0  409.0  351.0  312.0  273.0  341.0  343.0  396.0  324.0  448.0  380.0  344.0  413.0  367.0  413.0  408.0  357.0  408.0  436.0  426.0  377.0  329.0  381.0  0.21643506947915625  2,165 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783565
2    0.873138
3    0.909627
4    0.931421
5    0.949715
6    0.959512
7    0.96791
8    0.972508
9    0.977807
10   0.981206

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.25722830894829146
RMSE: 0.507176802454816
LogLoss: 0.8120551868646757
Mean Per-Class Error: 0.2210892204352759
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13     14    15     16     17     18    19    20     21     22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  -----  -----  ----  ----  -----  -----  -----  ----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0    1.0    0.0    1.0   0.0   0.0    2.0    0.0    1.0   2.0   0.0    0.10112359550561797  9 / 89
0.0   88.0   0.0   1.0    2.0   0.0   1.0   0.0   1.0   0.0   1.0    0.0   0.0    0.0    1.0   1.0    0.0    4.0    1.0   0.0   0.0    4.0    0.0    1.0   0.0   0.0    0.16981132075471697  18 / 106
0.0   0.0    63.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0   6.0    0.0   0.0    0.0    2.0   0.0    0.0    0.0    2.0   1.0   0.0    0.0    2.0    0.0   0.0   0.0    0.23170731707317074  19 / 82
1.0   4.0    0.0   91.0   0.0   0.0   0.0   2.0   1.0   0.0   1.0    1.0   3.0    1.0    0.0   0.0    0.0    3.0    1.0   0.0   0.0    0.0    0.0    2.0   0.0   1.0    0.1875               21 / 112
0.0   1.0    0.0   0.0    75.0  1.0   1.0   0.0   0.0   0.0   3.0    0.0   0.0    0.0    0.0   1.0    4.0    1.0    3.0   1.0   0.0    0.0    0.0    1.0   0.0   5.0    0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---    ---    ---   ---   ---    ---    ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   1.0    0.0   4.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    1.0    84.0   0.0   0.0   0.0    0.08695652173913043  8 / 92
0.0   2.0    0.0   3.0    2.0   0.0   0.0   1.0   2.0   0.0   4.0    1.0   0.0    0.0    0.0   0.0    2.0    0.0    8.0   0.0   1.0    0.0    0.0    73.0  0.0   1.0    0.27                 27 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0    1.0   1.0    5.0    0.0    3.0   5.0   0.0    12.0   1.0    0.0   76.0  0.0    0.2897196261682243   31 / 107
0.0   0.0    0.0   0.0    5.0   2.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0    9.0   0.0   0.0    0.0    0.0    0.0   0.0   68.0   0.21839080459770116  19 / 87
94.0  138.0  74.0  120.0  99.0  79.0  76.0  67.0  83.0  99.0  102.0  91.0  103.0  102.0  71.0  122.0  100.0  102.0  96.0  87.0  100.0  108.0  100.0  88.0  89.0  100.0  0.21967871485943774  547 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780321
2    0.871888
3    0.905622
4    0.928916
5    0.948996
6    0.957028
7    0.966265
8    0.971084
9    0.974699
10   0.978715
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:59  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:59  1 min 36.024 sec  212914 obs/sec    1         1             10007      0.731983         1.58412             0.990478       0.417875                         0.733556           1.58927               0.990412         0.426104
    2019-07-24 15:37:00  1 min 36.426 sec  230576 obs/sec    10        10            100070     0.505378         0.807321            0.995461       0.216435                         0.507177           0.812055              0.995417         0.219679
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0919093
C13         0.958111               0.958111             0.0880593
C9          0.895025               0.895025             0.0822612
C12         0.861957               0.861957             0.0792219
C8          0.820944               0.820944             0.0754524
C11         0.763426               0.763426             0.0701659
C7          0.717404               0.717404             0.0659361
C10         0.659735               0.659735             0.0606358
C14         0.646729               0.646729             0.0594404
C5          0.606781               0.606781             0.0557688
C4          0.57096                0.57096              0.0524765
C6          0.543053               0.543053             0.0499116
C16         0.522233               0.522233             0.0479981
C3          0.515792               0.515792             0.0474061
C1          0.40318                0.40318              0.037056
C2          0.39496                0.39496              0.0363005
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_40

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007541612480963522  0.0001871972344815731  0.0         -0.018537373501317234  0.2726750373840332  0.12597503687660386  0.20066851377487183
    3        26       Softmax                      0.0   0.0   0.00503097841255322    0.010332111269235611   0.0         -0.3680589084156404    0.9029364585876465  -0.5967451664503167  0.4700678586959839


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.26860638686611304
RMSE: 0.5182725025178483
LogLoss: 0.8483778802740115
Mean Per-Class Error: 0.22608038675605763
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    5.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    8.0    0.0    1.0    3.0    4.0    0.0    3.0    1.0    0.09367088607594937  37 / 395
0.0    312.0  0.0    10.0   1.0    0.0    4.0    2.0    3.0    0.0    0.0    0.0    1.0    0.0    6.0    5.0    0.0    27.0   6.0    0.0    0.0    2.0    1.0    3.0    0.0    0.0    0.185378590078329    71 / 383
0.0    2.0    290.0  0.0    27.0   0.0    9.0    1.0    0.0    0.0    22.0   0.0    1.0    0.0    2.0    1.0    6.0    0.0    0.0    5.0    0.0    0.0    2.0    0.0    0.0    0.0    0.21195652173913043  78 / 368
6.0    24.0   0.0    330.0  0.0    0.0    0.0    0.0    2.0    2.0    4.0    0.0    6.0    3.0    2.0    1.0    0.0    6.0    3.0    0.0    0.0    0.0    0.0    10.0   3.0    0.0    0.1791044776119403   72 / 402
0.0    17.0   0.0    1.0    292.0  2.0    12.0   0.0    0.0    0.0    7.0    1.0    0.0    0.0    2.0    0.0    13.0   4.0    7.0    1.0    1.0    0.0    0.0    6.0    3.0    15.0   0.23958333333333334  92 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    3.0    7.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    5.0    0.0    13.0   10.0   0.0    1.0    3.0    4.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    8.0    1.0    10.0   1.0    2.0    3.0    0.0    318.0  7.0    1.0    0.19289340101522842  76 / 394
0.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    7.0    0.0    11.0   38.0   2.0    35.0   1.0    0.0    286.0  0.0    0.272264631043257    107 / 393
0.0    2.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    48.0   0.0    0.0    0.0    0.0    5.0    0.0    294.0  0.1989100817438692   73 / 367
396.0  551.0  363.0  473.0  401.0  326.0  330.0  245.0  333.0  345.0  422.0  344.0  430.0  378.0  359.0  389.0  365.0  406.0  391.0  405.0  365.0  387.0  457.0  404.0  365.0  373.0  0.22503249025292413  2,251 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.774968
2    0.868439
3    0.902329
4    0.926722
5    0.941418
6    0.953114
7    0.962811
8    0.969809
9    0.976407
10   0.980306

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.27096813767601685
RMSE: 0.520545999577383
LogLoss: 0.8501948751753754
Mean Per-Class Error: 0.23029013279960203
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16    17     18     19     20    21    22     23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  -----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   3.0    0.0    2.0   1.0   0.10112359550561797  9 / 89
0.0   77.0   0.0   3.0    1.0   0.0   1.0   2.0   1.0   0.0   0.0    0.0   0.0   0.0   4.0   0.0    0.0   10.0   3.0    0.0    0.0   2.0   1.0    1.0    0.0   0.0   0.27358490566037735  29 / 106
0.0   1.0    58.0  0.0    6.0   0.0   2.0   1.0   0.0   0.0   6.0    0.0   0.0   0.0   1.0   1.0    3.0   0.0    0.0    2.0    0.0   0.0   1.0    0.0    0.0   0.0   0.2926829268292683   24 / 82
3.0   3.0    0.0   94.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   2.0   2.0   1.0   1.0    0.0   0.0    2.0    0.0    0.0   0.0   0.0    2.0    0.0   0.0   0.16071428571428573  18 / 112
0.0   3.0    0.0   0.0    72.0  2.0   1.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   1.0   0.0    3.0   2.0    2.0    0.0    0.0   0.0   0.0    2.0    0.0   7.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0   2.0   0.0   0.0    0.0   1.0    0.0    0.0    0.0   0.0   87.0   0.0    0.0   0.0   0.05434782608695652  5 / 92
0.0   2.0    0.0   3.0    3.0   0.0   1.0   1.0   2.0   0.0   2.0    0.0   1.0   0.0   0.0   0.0    1.0   0.0    3.0    0.0    0.0   0.0   0.0    79.0   2.0   0.0   0.21                 21 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   2.0    2.0   0.0    2.0    10.0   0.0   9.0   1.0    0.0    79.0  0.0   0.2616822429906542   28 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    9.0    0.0    0.0   0.0   0.0    1.0    0.0   71.0  0.1839080459770115   16 / 87
92.0  126.0  72.0  130.0  96.0  73.0  83.0  75.0  79.0  94.0  101.0  92.0  98.0  99.0  73.0  115.0  97.0  109.0  102.0  101.0  93.0  85.0  111.0  100.0  96.0  98.0  0.2281124497991968   568 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.771888
2    0.868273
3    0.90241
4    0.927309
5    0.942972
6    0.954217
7    0.962249
8    0.968675
9    0.976707
10   0.981124
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:33  1 min 10.191 sec  208479 obs/sec    1         1             10007      0.75595          1.72835             0.989845       0.452064                         0.758202           1.73502               0.989757         0.461446
    2019-07-24 15:36:34  1 min 10.586 sec  232720 obs/sec    10        10            100070     0.518273         0.848378            0.995227       0.225032                         0.520546           0.850195              0.995172         0.228112
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.100421
C13         0.84368                0.84368              0.0847235
C12         0.818829               0.818829             0.0822279
C9          0.745129               0.745129             0.0748269
C8          0.740706               0.740706             0.0743828
C7          0.707128               0.707128             0.0710107
C11         0.667294               0.667294             0.0670106
C6          0.632939               0.632939             0.0635606
C14         0.532871               0.532871             0.0535116
C3          0.523548               0.523548             0.0525754
C5          0.517102               0.517102             0.0519281
C4          0.509606               0.509606             0.0511754
C10         0.506849               0.506849             0.0508984
C16         0.451782               0.451782             0.0453685
C1          0.397012               0.397012             0.0398685
C2          0.363566               0.363566             0.0365098
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_64

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.000951865663296303  0.00025942362844944   0.0         -0.015349892192123349  0.24621444940567017  0.027803902052305634  0.15285176038742065
    3        26       Softmax                      0.0   0.0   0.004983337513259847  0.008318774402141571  0.0         -0.27653512761424703   0.7347033023834229   -0.8593172091667927   0.4444451332092285


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2808499830699322
RMSE: 0.5299528121162602
LogLoss: 0.8554613975019832
Mean Per-Class Error: 0.2208926871823166
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    3.0    0.0    12.0   1.0    6.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    4.0    3.0    4.0    0.0    0.11645569620253164  46 / 395
0.0    320.0  0.0    4.0    4.0    0.0    6.0    7.0    2.0    0.0    1.0    0.0    1.0    0.0    1.0    2.0    0.0    16.0   7.0    0.0    1.0    0.0    2.0    7.0    0.0    2.0    0.16449086161879894  63 / 383
0.0    0.0    293.0  0.0    9.0    0.0    13.0   0.0    0.0    0.0    27.0   1.0    0.0    0.0    9.0    0.0    2.0    0.0    4.0    1.0    4.0    0.0    5.0    0.0    0.0    0.0    0.20380434782608695  75 / 368
0.0    24.0   0.0    325.0  1.0    0.0    3.0    3.0    0.0    5.0    0.0    0.0    5.0    8.0    1.0    0.0    0.0    12.0   1.0    0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.1935483870967742   78 / 403
0.0    13.0   0.0    0.0    278.0  1.0    22.0   0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    4.0    5.0    7.0    2.0    1.0    0.0    0.0    8.0    1.0    32.0   0.2741514360313316   105 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    1.0    0.0    19.0   3.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    337.0  0.0    0.0    0.0    0.10133333333333333  38 / 375
0.0    4.0    0.0    7.0    4.0    0.0    1.0    2.0    3.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    10.0   2.0    11.0   5.0    4.0    1.0    0.0    325.0  4.0    4.0    0.1751269035532995   69 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    13.0   0.0    11.0   19.0   3.0    9.0    2.0    0.0    324.0  0.0    0.17557251908396945  69 / 393
1.0    0.0    0.0    2.0    18.0   0.0    2.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    43.0   1.0    0.0    0.0    0.0    2.0    0.0    290.0  0.2098092643051771   77 / 367
392.0  546.0  354.0  412.0  368.0  333.0  384.0  280.0  344.0  337.0  402.0  323.0  452.0  383.0  423.0  375.0  347.0  425.0  344.0  384.0  383.0  338.0  463.0  434.0  387.0  390.0  0.2198340497850645   2,199 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780166
2    0.873138
3    0.909427
4    0.929521
5    0.946016
6    0.957413
7    0.96531
8    0.973208
9    0.976907
10   0.980906

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2817185911686401
RMSE: 0.5307716940160243
LogLoss: 0.8612282152253675
Mean Per-Class Error: 0.22527218886724146
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16    17     18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0   1.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0    2.0    0.0    0.11235955056179775  10 / 89
0.0   80.0   0.0   1.0    3.0   0.0   2.0   4.0   1.0   0.0   0.0    0.0   0.0   0.0    1.0   1.0    0.0   5.0    3.0   0.0   1.0   0.0   1.0    3.0    0.0    0.0    0.24528301886792453  26 / 106
0.0   0.0    61.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0    4.0   0.0    0.0   0.0    2.0   1.0   1.0   0.0   2.0    0.0    0.0    0.0    0.25609756097560976  21 / 82
0.0   6.0    0.0   95.0   0.0   0.0   2.0   1.0   0.0   1.0   0.0    0.0   1.0   3.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0    0.15178571428571427  17 / 112
0.0   3.0    0.0   0.0    67.0  1.0   6.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   1.0   0.0   0.0   0.0    1.0    0.0    10.0   0.30927835051546393  30 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   5.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   84.0   0.0    0.0    0.0    0.08695652173913043  8 / 92
0.0   1.0    0.0   2.0    3.0   0.0   1.0   1.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   1.0   1.0   0.0   0.0    78.0   1.0    2.0    0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   0.0    5.0   0.0    1.0   3.0   1.0   1.0   2.0    0.0    90.0   0.0    0.1588785046728972   17 / 107
0.0   0.0    0.0   1.0    5.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    9.0   0.0   0.0   0.0   0.0    1.0    0.0    70.0   0.19540229885057472  17 / 87
93.0  131.0  75.0  119.0  86.0  73.0  95.0  75.0  80.0  93.0  105.0  88.0  99.0  101.0  88.0  107.0  95.0  104.0  90.0  94.0  98.0  72.0  118.0  103.0  107.0  101.0  0.22369477911646587  557 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.776305
2    0.872289
3    0.908835
4    0.926104
5    0.94498
6    0.953815
7    0.96265
8    0.969076
9    0.973092
10   0.976305
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:10  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:10  1 min 46.924 sec  142957 obs/sec    1         1             10007      0.748104         1.63286             0.990053       0.39958                          0.749864           1.64391               0.989981         0.406827
    2019-07-24 15:37:11  1 min 47.447 sec  174034 obs/sec    10        10            100070     0.529953         0.855461            0.995009       0.219834                         0.530772           0.861228              0.99498          0.223695
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0858457
C13         0.940092               0.940092             0.0807029
C12         0.92238                0.92238              0.0791824
C9          0.896785               0.896785             0.0769852
C7          0.88512                0.88512              0.0759838
C8          0.874388               0.874388             0.0750625
C11         0.778124               0.778124             0.0667986
C14         0.716882               0.716882             0.0615413
C6          0.715161               0.715161             0.0613935
C3          0.639177               0.639177             0.0548707
C16         0.634947               0.634947             0.0545075
C10         0.624683               0.624683             0.0536264
C5          0.610618               0.610618             0.052419
C4          0.551049               0.551049             0.0473052
C2          0.430517               0.430517             0.0369581
C1          0.428876               0.428876             0.0368172
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_43

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009448929470465828  0.0002416955539956689  0.0         -0.014785574504456278  0.24471598863601685  0.0574226972187762   0.1901986002922058
    3        26       Softmax                      0.0   0.0   0.005368185342621683   0.014217328280210495   0.0         -0.2567301877215781    0.7248141765594482   -0.8346913751197617  0.42489826679229736


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2840292052565786
RMSE: 0.5329439044182592
LogLoss: 0.8736328916184689
Mean Per-Class Error: 0.23050349542389445
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    0.0    7.0    0.0    7.0    0.0    0.0    0.0    2.0    0.0    2.0    1.0    4.0    3.0    6.0    0.0    0.10126582278481013  40 / 395
0.0    325.0  0.0    5.0    1.0    0.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    9.0    2.0    0.0    22.0   1.0    0.0    0.0    1.0    0.0    8.0    5.0    0.0    0.1514360313315927   58 / 383
0.0    0.0    292.0  0.0    19.0   1.0    12.0   1.0    0.0    0.0    23.0   2.0    0.0    0.0    5.0    0.0    1.0    0.0    4.0    2.0    1.0    0.0    5.0    0.0    0.0    0.0    0.20652173913043478  76 / 368
5.0    17.0   0.0    318.0  0.0    0.0    1.0    4.0    0.0    3.0    0.0    0.0    5.0    4.0    8.0    4.0    0.0    12.0   2.0    0.0    0.0    0.0    0.0    19.0   0.0    0.0    0.208955223880597    84 / 402
0.0    14.0   0.0    0.0    297.0  1.0    12.0   0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    10.0   3.0    0.0    0.0    0.0    8.0    0.0    23.0   0.2265625            87 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    1.0    0.0    17.0   1.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    337.0  0.0    1.0    0.0    0.10372340425531915  39 / 376
12.0   1.0    0.0    10.0   6.0    0.0    2.0    1.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    8.0    3.0    4.0    0.0    0.0    329.0  11.0   0.0    0.1649746192893401   65 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    0.0    7.0    18.0   1.0    72.0   2.0    0.0    277.0  1.0    0.2951653944020356   116 / 393
3.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    42.0   2.0    0.0    0.0    0.0    10.0   0.0    286.0  0.22070844686648503  81 / 367
428.0  549.0  337.0  417.0  393.0  321.0  356.0  223.0  348.0  330.0  430.0  324.0  438.0  360.0  465.0  367.0  317.0  396.0  348.0  385.0  379.0  446.0  440.0  474.0  357.0  375.0  0.22943117064880536  2,295 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.770569
2    0.862541
3    0.90143
4    0.925023
5    0.942917
6    0.954914
7    0.963611
8    0.971808
9    0.977907
10   0.983505

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.28432241651632983
RMSE: 0.5332189198784396
LogLoss: 0.8713452626240638
Mean Per-Class Error: 0.23240448999333999
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16    17     18    19    20    21     22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  -----  -----  -----  ----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0    1.0    1.0    3.0    0.0   0.10112359550561797  9 / 89
0.0    85.0   0.0   3.0    1.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0   3.0   1.0    0.0   5.0    0.0   0.0   0.0   1.0    0.0    2.0    3.0    0.0   0.19811320754716982  21 / 106
0.0    0.0    58.0  0.0    4.0   0.0   6.0   0.0   0.0   0.0   7.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0    2.0   1.0   0.0   0.0    2.0    0.0    0.0    0.0   0.2926829268292683   24 / 82
3.0    3.0    0.0   89.0   0.0   0.0   1.0   2.0   0.0   1.0   0.0    0.0   2.0   2.0   2.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0    0.0    4.0    0.0    0.0   0.20535714285714285  23 / 112
0.0    2.0    0.0   0.0    69.0  1.0   2.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0    3.0   1.0    3.0   0.0   0.0   0.0    0.0    2.0    0.0    12.0  0.28865979381443296  28 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---    ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   3.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0    86.0   0.0    0.0    0.0   0.06521739130434782  6 / 92
3.0    0.0    0.0   2.0    3.0   0.0   1.0   1.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0   1.0   0.0    0.0    81.0   4.0    0.0   0.19                 19 / 100
0.0    0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    3.0   0.0    0.0   3.0   0.0   21.0   2.0    0.0    76.0   0.0   0.2897196261682243   31 / 107
1.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   4.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    9.0   1.0   0.0   0.0    0.0    3.0    0.0    65.0  0.25287356321839083  22 / 87
100.0  132.0  67.0  116.0  90.0  76.0  94.0  57.0  87.0  92.0  102.0  89.0  99.0  96.0  94.0  104.0  90.0  102.0  84.0  89.0  96.0  105.0  112.0  114.0  105.0  98.0  0.2321285140562249   578 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.767872
2    0.859438
3    0.899197
4    0.9249
5    0.942972
6    0.95502
7    0.964659
8    0.971486
9    0.976707
10   0.982731
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:38  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:38  1 min 15.255 sec  147161 obs/sec    1         1             10007      0.754402         1.65087             0.989887       0.388483                         0.754607           1.64096               0.989854         0.391165
    2019-07-24 15:36:39  1 min 15.765 sec  178377 obs/sec    10        10            100070     0.532944         0.873633            0.994953       0.229431                         0.533219           0.871345              0.994934         0.232129
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0976827
C13         0.914765               0.914765             0.0893567
C12         0.782658               0.782658             0.0764521
C8          0.771226               0.771226             0.0753355
C7          0.756156               0.756156             0.0738633
C9          0.723462               0.723462             0.0706697
C11         0.6998                 0.6998               0.0683583
C14         0.626465               0.626465             0.0611947
C10         0.610641               0.610641             0.059649
C6          0.577491               0.577491             0.0564109
C3          0.528295               0.528295             0.0516053
C5          0.515463               0.515463             0.0503518
C4          0.509247               0.509247             0.0497446
C16         0.475065               0.475065             0.0464056
C2          0.400651               0.400651             0.0391366
C1          0.345845               0.345845             0.0337831
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_15

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight          weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  -------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012682283780236503  0.00031770451460033655  0.0         0.0241565720496979   1.1809210777282715  0.2546394938236473   0.9920251369476318
    3        26       Softmax                 0.0   0.0   0.001753564672421467   0.00020300870528444648  0.0         -0.0171712440405477  0.4566981792449951  -0.5640884360335963  0.3592393398284912


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.29200392483657817
RMSE: 0.5403738750500233
LogLoss: 0.958964179300668
Mean Per-Class Error: 0.27335206852776656
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    7.0    0.0    6.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    8.0    2.0    5.0    0.0    0.10379746835443038  41 / 395
0.0    259.0  0.0    2.0    0.0    4.0    4.0    10.0   3.0    1.0    4.0    0.0    3.0    0.0    1.0    9.0    5.0    46.0   22.0   1.0    0.0    1.0    0.0    2.0    6.0    0.0    0.3237597911227154   124 / 383
0.0    0.0    294.0  0.0    5.0    5.0    21.0   1.0    2.0    0.0    18.0   2.0    2.0    0.0    1.0    0.0    2.0    1.0    6.0    0.0    1.0    0.0    5.0    0.0    0.0    1.0    0.1989100817438692   73 / 367
6.0    14.0   0.0    304.0  0.0    1.0    1.0    8.0    0.0    10.0   0.0    0.0    10.0   2.0    9.0    5.0    0.0    15.0   1.0    2.0    0.0    0.0    0.0    13.0   1.0    1.0    0.2456575682382134   99 / 403
0.0    6.0    3.0    0.0    283.0  2.0    13.0   2.0    3.0    0.0    5.0    0.0    0.0    0.0    0.0    2.0    12.0   9.0    7.0    8.0    0.0    0.0    0.0    6.0    0.0    23.0   0.2630208333333333   101 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    41.0   3.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    325.0  0.0    0.0    0.0    0.1356382978723404   51 / 376
0.0    8.0    0.0    13.0   9.0    0.0    0.0    1.0    4.0    0.0    5.0    3.0    0.0    0.0    0.0    0.0    26.0   6.0    18.0   8.0    2.0    0.0    0.0    284.0  5.0    1.0    0.27735368956743     109 / 393
0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    14.0   0.0    6.0    77.0   4.0    42.0   2.0    0.0    241.0  0.0    0.38676844783715014  152 / 393
0.0    3.0    0.0    1.0    24.0   4.0    0.0    0.0    0.0    6.0    0.0    3.0    0.0    0.0    0.0    0.0    6.0    1.0    40.0   4.0    0.0    0.0    0.0    1.0    0.0    274.0  0.25340599455040874  93 / 367
412.0  452.0  390.0  425.0  366.0  329.0  330.0  328.0  317.0  353.0  348.0  339.0  539.0  334.0  380.0  403.0  391.0  456.0  330.0  454.0  376.0  387.0  473.0  372.0  334.0  385.0  0.2723183045086474   2,724 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.727682
2    0.839048
3    0.888034
4    0.914925
5    0.93252
6    0.945216
7    0.954714
8    0.96561
9    0.972908
10   0.978406

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.29411880353868197
RMSE: 0.5423272107673393
LogLoss: 0.964781517655567
Mean Per-Class Error: 0.2773187135363775
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20     21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0    0.0   3.0    1.0   2.0   0.0   0.07865168539325842  7 / 89
0.0   73.0   0.0   0.0    0.0   0.0   1.0   4.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   2.0    5.0    13.0   3.0   0.0    0.0    1.0   0.0    1.0   1.0   0.0   0.3113207547169811   33 / 106
0.0   0.0    61.0  0.0    2.0   1.0   5.0   0.0   1.0   0.0   6.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0    3.0   0.0    0.0    0.0   1.0    0.0   0.0   0.0   0.25609756097560976  21 / 82
4.0   3.0    0.0   88.0   0.0   0.0   0.0   4.0   0.0   2.0   0.0   0.0   3.0    1.0   0.0   2.0    0.0    3.0    0.0   0.0    0.0    0.0   0.0    1.0   0.0   1.0   0.21428571428571427  24 / 112
0.0   2.0    1.0   0.0    67.0  1.0   3.0   0.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    2.0    4.0    2.0   3.0    0.0    0.0   0.0    1.0   0.0   8.0   0.30927835051546393  30 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---   ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   6.0    1.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0    0.0   83.0   0.0   0.0   0.0   0.09782608695652174  9 / 92
0.0   2.0    0.0   3.0    4.0   0.0   0.0   1.0   2.0   0.0   3.0   1.0   0.0    0.0   0.0   0.0    3.0    2.0    4.0   2.0    1.0    0.0   0.0    71.0  1.0   0.0   0.29                 29 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   1.0    5.0    0.0    0.0   16.0   2.0    11.0  2.0    0.0   69.0  0.0   0.35514018691588783  38 / 107
0.0   0.0    0.0   1.0    6.0   2.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0    11.0  3.0    0.0    0.0   0.0    0.0   0.0   62.0  0.28735632183908044  25 / 87
94.0  117.0  81.0  124.0  91.0  70.0  77.0  84.0  72.0  96.0  87.0  90.0  115.0  91.0  76.0  115.0  102.0  119.0  89.0  107.0  101.0  90.0  124.0  90.0  95.0  93.0  0.27630522088353415  688 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.723695
2    0.841365
3    0.891165
4    0.917671
5    0.933333
6    0.94498
7    0.95261
8    0.963454
9    0.971084
10   0.976305
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:53  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:54  30.384 sec  90972 obs/sec     1         1             10007      0.640759         1.29097             0.992703       0.355893                         0.643583           1.29832               0.99262          0.357831
    2019-07-24 15:35:55  31.407 sec  90153 obs/sec     10        10            100070     0.540374         0.958964            0.99481        0.272318                         0.542327           0.964782              0.994759         0.276305
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0917905
C9          0.971591               0.971591             0.0891829
C13         0.902679               0.902679             0.0828573
C15         0.878353               0.878353             0.0806245
C11         0.830847               0.830847             0.0762639
C7          0.812669               0.812669             0.0745953
C8          0.777004               0.777004             0.0713216
C14         0.743465               0.743465             0.068243
C10         0.69005                0.69005              0.06334
C16         0.615892               0.615892             0.056533
C6          0.59586                0.59586              0.0546943
C3          0.49389                0.49389              0.0453344
C5          0.438222               0.438222             0.0402246
C4          0.427786               0.427786             0.0392667
C1          0.375935               0.375935             0.0345073
C2          0.34013                0.34013              0.0312207
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_65

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012870725994957866  0.0003641530638560653   0.0         0.009348946999637064   1.2498588562011719   0.11572089983102639  0.989893913269043
    3        26       Softmax                 0.0   0.0   0.0017581101360869629  0.00019896496087312698  0.0         -0.008332630177916984  0.45329439640045166  -0.554886586780033   0.3243875503540039


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3112217146078686
RMSE: 0.5578724895599967
LogLoss: 0.9929441335135861
Mean Per-Class Error: 0.2890057056083484
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  4.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    8.0    1.0    2.0    0.0    0.0    2.0    4.0    0.0    0.0    1.0    5.0    0.0    5.0    1.0    0.09873417721518987  39 / 395
0.0    264.0  0.0    10.0   1.0    1.0    5.0    13.0   0.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    2.0    25.0   44.0   0.0    0.0    1.0    1.0    5.0    6.0    0.0    0.31070496083550914  119 / 383
0.0    0.0    286.0  0.0    11.0   4.0    19.0   1.0    0.0    0.0    17.0   0.0    0.0    0.0    1.0    0.0    7.0    0.0    9.0    4.0    3.0    0.0    4.0    2.0    0.0    0.0    0.22282608695652173  82 / 368
4.0    21.0   0.0    287.0  0.0    1.0    0.0    10.0   2.0    6.0    0.0    2.0    4.0    10.0   17.0   4.0    0.0    16.0   4.0    2.0    0.0    0.0    0.0    11.0   1.0    1.0    0.2878411910669975   116 / 403
0.0    3.0    2.0    0.0    256.0  3.0    17.0   0.0    1.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    21.0   6.0    14.0   11.0   0.0    0.0    0.0    2.0    3.0    38.0   0.3333333333333333   128 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    13.0   0.0    0.0    0.0    0.0    10.0   5.0    5.0    0.0    0.0    3.0    0.0    0.0    1.0    3.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    12.0   1.0    9.0    14.0   0.0    0.0    1.0    9.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    24.0   3.0    11.0   13.0   1.0    0.0    0.0    267.0  13.0   8.0    0.32061068702290074  126 / 393
0.0    1.0    0.0    1.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    6.0    2.0    0.0    4.0    101.0  1.0    29.0   1.0    0.0    236.0  0.0    0.3994910941475827   157 / 393
0.0    5.0    0.0    1.0    17.0   6.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    43.0   6.0    0.0    0.0    0.0    2.0    0.0    281.0  0.23433242506811988  86 / 367
398.0  511.0  359.0  407.0  357.0  338.0  340.0  299.0  333.0  326.0  336.0  344.0  453.0  367.0  372.0  395.0  382.0  454.0  363.0  486.0  387.0  358.0  453.0  373.0  390.0  422.0  0.28791362591222636  2,880 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.712086
2    0.838548
3    0.885234
4    0.912926
5    0.931121
6    0.945516
7    0.954913
8    0.964411
9    0.971309
10   0.976707

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.313470691457527
RMSE: 0.5598845340403028
LogLoss: 1.0007676933820941
Mean Per-Class Error: 0.29622205280070113
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0    1.0    1.0   0.0    0.0   0.0   3.0    0.0   2.0    0.0    0.10112359550561797  9 / 89
0.0   70.0   0.0   2.0    0.0   0.0   2.0   5.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    2.0    9.0    10.0  0.0    0.0   1.0   1.0    2.0   1.0    0.0    0.33962264150943394  36 / 106
0.0   0.0    60.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   0.0    2.0    0.0    3.0   2.0    1.0   0.0   2.0    0.0   0.0    0.0    0.2682926829268293   22 / 82
3.0   3.0    0.0   82.0   0.0   1.0   0.0   2.0   1.0   2.0   0.0   2.0   1.0    3.0   5.0   1.0    0.0    3.0    1.0   0.0    0.0   0.0   0.0    2.0   0.0    0.0    0.26785714285714285  30 / 112
0.0   1.0    1.0   0.0    59.0  2.0   4.0   0.0   0.0   0.0   3.0   1.0   0.0    0.0   0.0   0.0    5.0    1.0    5.0   4.0    0.0   0.0   0.0    1.0   0.0    10.0   0.3917525773195876   38 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   2.0    3.0   0.0   0.0    0.0    1.0    0.0   0.0    0.0   0.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0   4.0    0.0   2.0    5.0   0.0   0.0   1.0   4.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    4.0    2.0    3.0   4.0    0.0   0.0   0.0    62.0  5.0    1.0    0.38                 38 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    1.0    0.0    0.0   26.0   1.0   8.0   1.0    0.0   67.0   0.0    0.37383177570093457  40 / 107
0.0   1.0    0.0   1.0    6.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0    9.0   2.0    0.0   0.0   0.0    1.0   0.0    64.0   0.26436781609195403  23 / 87
97.0  118.0  79.0  117.0  86.0  78.0  79.0  82.0  81.0  89.0  79.0  93.0  103.0  94.0  72.0  112.0  100.0  115.0  98.0  119.0  95.0  82.0  121.0  85.0  113.0  103.0  0.2955823293172691   736 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.704418
2    0.838956
3    0.882731
4    0.91004
5    0.925703
6    0.941365
7    0.950602
8    0.962249
9    0.970281
10   0.977912
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:11  1 min 47.582 sec  98107 obs/sec     1         1             10007      0.652859         1.33089             0.992426       0.371289                         0.650787           1.32433               0.992453         0.366667
    2019-07-24 15:37:12  1 min 48.533 sec  96873 obs/sec     10        10            100070     0.557872         0.992944            0.99447        0.287914                         0.559885           1.00077               0.994414         0.295582
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0938459
C12         0.921986               0.921986             0.0865246
C9          0.904472               0.904472             0.084881
C13         0.866166               0.866166             0.0812861
C7          0.80642                0.80642              0.0756792
C8          0.767286               0.767286             0.0720067
C11         0.73914                0.73914              0.0693653
C14         0.708459               0.708459             0.0664859
C10         0.690513               0.690513             0.0648018
C16         0.534522               0.534522             0.0501627
C6          0.526368               0.526368             0.0493974
C3          0.492738               0.492738             0.0462414
C5          0.464773               0.464773             0.043617
C4          0.43062                0.43062              0.0404119
C2          0.408181               0.408181             0.0383061
C1          0.394123               0.394123             0.0369868
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_35

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012462594672228988  0.00032414367888122797  0.0         0.0111390334054704    1.2360777854919434  -0.18012920294975085  0.9813768863677979
    3        26       Softmax                 0.0   0.0   0.0017087753202269175  0.00015657185576856136  0.0         0.015842504688040347  0.4574395418167114  -0.5415568368409726   0.3236558437347412


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3066999091034034
RMSE: 0.553804937774487
LogLoss: 0.9908963109901652
Mean Per-Class Error: 0.2809963799489652
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    1.0    9.0    0.0    3.0    0.0    0.0    4.0    10.0   0.0    1.0    2.0    4.0    1.0    4.0    0.0    0.11392405063291139  45 / 395
0.0    287.0  0.0    8.0    7.0    3.0    3.0    0.0    3.0    2.0    3.0    0.0    5.0    0.0    0.0    3.0    6.0    26.0   18.0   1.0    0.0    2.0    2.0    2.0    1.0    0.0    0.2486910994764398   95 / 382
0.0    0.0    252.0  0.0    34.0   2.0    44.0   0.0    3.0    0.0    7.0    0.0    1.0    0.0    3.0    0.0    0.0    0.0    6.0    3.0    3.0    0.0    8.0    0.0    2.0    0.0    0.31521739130434784  116 / 368
7.0    16.0   0.0    290.0  0.0    0.0    5.0    7.0    0.0    26.0   1.0    2.0    8.0    3.0    7.0    6.0    0.0    7.0    4.0    0.0    0.0    0.0    0.0    13.0   1.0    0.0    0.2803970223325062   113 / 403
0.0    9.0    4.0    0.0    266.0  3.0    34.0   1.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    8.0    5.0    10.0   10.0   1.0    0.0    0.0    14.0   0.0    16.0   0.3072916666666667   118 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    29.0   7.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    2.0    331.0  0.0    0.0    0.0    0.1196808510638298   45 / 376
2.0    3.0    0.0    5.0    17.0   0.0    13.0   5.0    10.0   3.0    5.0    3.0    0.0    0.0    2.0    0.0    8.0    2.0    19.0   3.0    1.0    0.0    0.0    268.0  13.0   12.0   0.3197969543147208   126 / 394
0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    9.0    0.0    3.0    61.0   2.0    48.0   8.0    0.0    256.0  1.0    0.3486005089058524   137 / 393
1.0    2.0    0.0    3.0    17.0   6.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    42.0   5.0    0.0    0.0    0.0    3.0    0.0    281.0  0.23433242506811988  86 / 367
408.0  477.0  323.0  417.0  419.0  333.0  419.0  198.0  334.0  358.0  332.0  320.0  524.0  354.0  391.0  398.0  324.0  471.0  333.0  416.0  393.0  397.0  513.0  373.0  373.0  405.0  0.279816055183445    2,799 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.720184
2    0.839948
3    0.887934
4    0.913726
5    0.931521
6    0.944917
7    0.955913
8    0.962111
9    0.969709
10   0.975507

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.31057587758107136
RMSE: 0.5572933496652112
LogLoss: 1.0068492472353843
Mean Per-Class Error: 0.2861200100084472
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9     10    11    12     13    14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   2.0    1.0   0.0   0.0    0.0   3.0    1.0   2.0    0.0    0.12359550561797752  11 / 89
0.0   75.0   0.0   2.0    3.0   0.0   1.0    0.0   1.0   0.0   0.0   0.0   2.0    0.0   0.0   1.0    4.0   10.0   3.0   0.0   0.0    1.0   2.0    1.0   0.0    0.0    0.29245283018867924  31 / 106
0.0   0.0    50.0  0.0    6.0   0.0   14.0   0.0   1.0   0.0   2.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0   1.0   1.0    0.0   2.0    0.0   1.0    0.0    0.3902439024390244   32 / 82
4.0   2.0    0.0   82.0   0.0   0.0   1.0    3.0   0.0   3.0   0.0   1.0   3.0    0.0   4.0   2.0    0.0   2.0    3.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0    0.26785714285714285  30 / 112
0.0   2.0    3.0   0.0    61.0  2.0   8.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    3.0   5.0   0.0    0.0   0.0    4.0   0.0    5.0    0.3711340206185567   36 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   5.0    2.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0    1.0   83.0   0.0   0.0    0.0    0.09782608695652174  9 / 92
0.0   1.0    0.0   1.0    4.0   0.0   1.0    3.0   5.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    2.0   2.0    5.0   1.0   0.0    0.0   0.0    64.0  5.0    3.0    0.36                 36 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    2.0   0.0    0.0   13.0  1.0    11.0  2.0    0.0   76.0   0.0    0.2897196261682243   31 / 107
0.0   1.0    0.0   0.0    2.0   2.0   1.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    10.0  2.0   0.0    0.0   0.0    1.0   0.0    67.0   0.22988505747126436  20 / 87
94.0  110.0  69.0  117.0  91.0  77.0  105.0  55.0  81.0  95.0  78.0  86.0  121.0  90.0  75.0  115.0  94.0  120.0  93.0  99.0  103.0  88.0  128.0  90.0  116.0  100.0  0.28473895582329317  709 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.715261
2    0.832129
3    0.885542
4    0.911245
5    0.93253
6    0.944578
7    0.953012
8    0.958635
9    0.964659
10   0.970281
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:27  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:27  1 min  3.972 sec  100070 obs/sec    1         1             10007      0.655622         1.32029             0.992361       0.36689                          0.653124           1.3077                0.992399         0.360643
    2019-07-24 15:36:28  1 min  4.910 sec  98397 obs/sec     10        10            100070     0.553805         0.990896            0.99455        0.279816                         0.557293           1.00685               0.994466         0.284739
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0876854
C13         0.950483               0.950483             0.0833435
C9          0.905713               0.905713             0.0794179
C12         0.904492               0.904492             0.0793108
C8          0.85914                0.85914              0.0753341
C7          0.825358               0.825358             0.0723719
C11         0.81593                0.81593              0.0715452
C14         0.793547               0.793547             0.0695825
C10         0.717649               0.717649             0.0629273
C16         0.636633               0.636633             0.0558234
C6          0.582631               0.582631             0.0510882
C3          0.548197               0.548197             0.0480689
C5          0.486357               0.486357             0.0426464
C4          0.48505                0.48505              0.0425318
C1          0.463228               0.463228             0.0406184
C2          0.429994               0.429994             0.0377042
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_42

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0013154661488670172  0.0003583956276997924   0.0         -0.013767522994555748  1.27880859375        -0.14238815719182152  0.9737749099731445
    3        26       Softmax                 0.0   0.0   0.0017163817185344389  0.00017374363960698247  0.0         0.029855885899486075   0.44539129734039307  -0.5455949522166196   0.35203850269317627


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3123793294712184
RMSE: 0.5589090529515678
LogLoss: 1.0034584220031542
Mean Per-Class Error: 0.2882531816080283
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    5.0    2.0    3.0    0.0    1.0    0.0    4.0    0.0    1.0    3.0    4.0    0.0    4.0    0.0    0.09113924050632911  36 / 395
0.0    291.0  0.0    6.0    1.0    1.0    1.0    10.0   7.0    1.0    1.0    0.0    2.0    1.0    0.0    7.0    2.0    29.0   15.0   0.0    0.0    3.0    2.0    2.0    1.0    0.0    0.2402088772845953   92 / 383
0.0    1.0    272.0  0.0    22.0   2.0    36.0   1.0    0.0    0.0    11.0   0.0    1.0    0.0    3.0    0.0    1.0    0.0    3.0    6.0    0.0    0.0    8.0    0.0    0.0    0.0    0.25885558583106266  95 / 367
7.0    24.0   0.0    285.0  0.0    0.0    0.0    1.0    1.0    11.0   0.0    0.0    9.0    5.0    5.0    8.0    0.0    17.0   8.0    2.0    1.0    0.0    0.0    19.0   0.0    0.0    0.29280397022332505  118 / 403
0.0    6.0    4.0    0.0    267.0  6.0    19.0   0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    13.0   5.0    7.0    14.0   1.0    0.0    0.0    18.0   0.0    20.0   0.3046875            117 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    24.0   6.0    1.0    0.0    0.0    4.0    0.0    0.0    1.0    4.0    330.0  0.0    0.0    0.0    0.12234042553191489  46 / 376
3.0    18.0   0.0    4.0    10.0   1.0    4.0    1.0    10.0   0.0    5.0    3.0    0.0    0.0    4.0    0.0    28.0   2.0    14.0   16.0   3.0    0.0    0.0    259.0  2.0    7.0    0.3426395939086294   135 / 394
0.0    0.0    0.0    1.0    0.0    21.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    2.0    5.0    7.0    0.0    7.0    59.0   1.0    24.0   4.0    0.0    257.0  0.0    0.3460559796437659   136 / 393
3.0    1.0    0.0    1.0    20.0   4.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    39.0   6.0    0.0    0.0    0.0    6.0    0.0    278.0  0.24250681198910082  89 / 367
434.0  553.0  353.0  385.0  382.0  388.0  388.0  177.0  343.0  339.0  314.0  333.0  485.0  421.0  368.0  394.0  391.0  466.0  282.0  427.0  371.0  389.0  473.0  399.0  353.0  395.0  0.2867139858042587   2,868 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.713286
2    0.830651
3    0.881236
4    0.908927
5    0.929121
6    0.941418
7    0.952014
8    0.962611
9    0.969009
10   0.974808

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3161422247679075
RMSE: 0.5622652619252834
LogLoss: 1.008449385805126
Mean Per-Class Error: 0.2968876876330838
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16    17     18    19     20    21    22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   1.0   2.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0    75.0   0.0   0.0    0.0   0.0   1.0   4.0   2.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0    2.0   12.0   3.0   0.0    0.0   2.0   2.0    1.0    0.0    0.0   0.29245283018867924  31 / 106
0.0    0.0    56.0  0.0    5.0   0.0   11.0  0.0   0.0   0.0   4.0   0.0   0.0    0.0    1.0   0.0    0.0   0.0    1.0   3.0    0.0   0.0   1.0    0.0    0.0    0.0   0.3170731707317073   26 / 82
4.0    4.0    0.0   82.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   4.0    1.0    2.0   3.0    0.0   4.0    3.0   0.0    0.0   0.0   0.0    3.0    0.0    0.0   0.26785714285714285  30 / 112
0.0    1.0    0.0   0.0    63.0  3.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   0.0    5.0   1.0    3.0   5.0    0.0   0.0   0.0    4.0    0.0    8.0   0.35051546391752575  34 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0    1.0    1.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
1.0    4.0    0.0   1.0    4.0   0.0   2.0   1.0   2.0   0.0   2.0   0.0   0.0    0.0    1.0   0.0    3.0   1.0    6.0   4.0    0.0   0.0   0.0    65.0   0.0    3.0   0.35                 35 / 100
0.0    0.0    0.0   0.0    0.0   4.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0    3.0   0.0    0.0   15.0   0.0   8.0   2.0    0.0    72.0   0.0   0.32710280373831774  35 / 107
0.0    0.0    0.0   1.0    5.0   1.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0    8.0   3.0    0.0   0.0   0.0    2.0    0.0    65.0  0.25287356321839083  22 / 87
102.0  132.0  70.0  111.0  96.0  84.0  94.0  47.0  76.0  98.0  84.0  90.0  111.0  112.0  74.0  112.0  97.0  113.0  72.0  105.0  93.0  92.0  118.0  101.0  107.0  99.0  0.2959839357429719   737 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.704016
2    0.830522
3    0.884739
4    0.908434
5    0.930924
6    0.944177
7    0.954217
8    0.964257
9    0.968273
10   0.974699
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:37  1 min 14.169 sec  90153 obs/sec     1         1             10007      0.666745         1.36225             0.9921         0.372788                         0.663263           1.35127               0.992161         0.36747
    2019-07-24 15:36:38  1 min 15.153 sec  93348 obs/sec     10        10            100070     0.558909         1.00346             0.994449       0.286714                         0.562265           1.00845               0.994367         0.295984
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0901989
C9          0.958689               0.958689             0.0864727
C12         0.953841               0.953841             0.0860354
C13         0.940578               0.940578             0.0848391
C11         0.807684               0.807684             0.0728522
C7          0.767938               0.767938             0.0692671
C14         0.713852               0.713852             0.0643886
C8          0.698299               0.698299             0.0629858
C10         0.689914               0.689914             0.0622294
C6          0.603014               0.603014             0.0543912
C16         0.599688               0.599688             0.0540912
C3          0.558954               0.558954             0.050417
C4          0.488891               0.488891             0.0440974
C5          0.475006               0.475006             0.042845
C1          0.416711               0.416711             0.0375869
C2          0.413552               0.413552             0.0373019
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_71

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0010943065054789258  0.00031147757545113564  0.0         -0.06465355058253408   1.0860934257507324  0.08103137716408063   1.0076713562011719
    3        26       Softmax                 0.0   0.0   0.001771723572416634   0.0002040465478785336   0.0         0.0032121900210663277  0.5942122936248779  -0.47007235446793294  0.27140486240386963


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.321581957161365
RMSE: 0.5670819668807721
LogLoss: 1.0255948953222602
Mean Per-Class Error: 0.29235515243789245
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
341.0  1.0    0.0    0.0    0.0    0.0    1.0    6.0    0.0    7.0    1.0    0.0    7.0    1.0    1.0    0.0    12.0   2.0    0.0    0.0    0.0    1.0    9.0    0.0    4.0    0.0    0.13451776649746192  53 / 394
2.0    249.0  0.0    9.0    4.0    2.0    13.0   6.0    1.0    8.0    7.0    0.0    7.0    0.0    0.0    3.0    2.0    31.0   24.0   0.0    0.0    0.0    7.0    3.0    5.0    0.0    0.34986945169712796  134 / 383
0.0    3.0    280.0  0.0    17.0   0.0    21.0   0.0    0.0    0.0    16.0   0.0    0.0    0.0    6.0    0.0    5.0    1.0    6.0    2.0    4.0    0.0    7.0    0.0    0.0    0.0    0.2391304347826087   88 / 368
14.0   13.0   0.0    312.0  0.0    3.0    0.0    5.0    0.0    9.0    1.0    0.0    4.0    7.0    2.0    7.0    0.0    5.0    7.0    0.0    2.0    0.0    0.0    6.0    1.0    5.0    0.22580645161290322  91 / 403
0.0    12.0   16.0   1.0    200.0  9.0    43.0   0.0    1.0    1.0    7.0    1.0    0.0    0.0    0.0    1.0    11.0   12.0   14.0   2.0    0.0    0.0    0.0    19.0   0.0    34.0   0.4791666666666667   184 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    23.0   7.0    0.0    0.0    0.0    9.0    0.0    0.0    4.0    6.0    320.0  0.0    1.0    0.0    0.14893617021276595  56 / 376
0.0    3.0    2.0    18.0   2.0    0.0    6.0    3.0    9.0    9.0    13.0   7.0    0.0    0.0    0.0    1.0    12.0   8.0    21.0   18.0   1.0    0.0    1.0    247.0  4.0    9.0    0.3730964467005076   147 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    9.0    12.0   0.0    4.0    68.0   3.0    21.0   1.0    0.0    268.0  0.0    0.31806615776081426  125 / 393
4.0    4.0    0.0    3.0    7.0    5.0    0.0    0.0    3.0    9.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    46.0   4.0    0.0    0.0    0.0    3.0    1.0    275.0  0.2506811989100817   92 / 367
435.0  436.0  338.0  474.0  281.0  389.0  443.0  243.0  350.0  361.0  382.0  312.0  458.0  361.0  376.0  363.0  362.0  486.0  361.0  413.0  398.0  354.0  462.0  346.0  418.0  401.0  0.29151254623612916  2,916 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.708487
2    0.822453
3    0.879036
4    0.905828
5    0.925122
6    0.942517
7    0.951914
8    0.961012
9    0.96721
10   0.974208

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3251661660846382
RMSE: 0.5702334312232475
LogLoss: 1.0294935195310018
Mean Per-Class Error: 0.29980112764700795
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6      7     8     9      10    11    12     13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
78.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0   0.0   0.0    1.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0    0.0   2.0    0.0   2.0    0.0    0.12359550561797752  11 / 89
2.0    66.0   0.0   1.0    2.0   0.0   5.0    1.0   0.0   2.0    2.0   0.0   1.0    0.0    0.0   1.0    2.0   9.0    5.0   0.0   0.0    0.0   5.0    1.0   1.0    0.0    0.37735849056603776  40 / 106
0.0    1.0    58.0  0.0    3.0   0.0   5.0    0.0   0.0   0.0    4.0   0.0   0.0    0.0    2.0   0.0    2.0   0.0    3.0   1.0   1.0    0.0   2.0    0.0   0.0    0.0    0.2926829268292683   24 / 82
6.0    3.0    0.0   87.0   0.0   1.0   0.0    2.0   0.0   1.0    0.0   0.0   2.0    2.0    0.0   2.0    0.0   2.0    2.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.22321428571428573  25 / 112
0.0    5.0    4.0   1.0    44.0  3.0   15.0   0.0   0.0   0.0    2.0   0.0   0.0    0.0    0.0   0.0    2.0   2.0    5.0   0.0   0.0    0.0   0.0    2.0   0.0    12.0   0.5463917525773195   53 / 97
---    ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   6.0    2.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0    2.0   78.0   0.0   0.0    0.0    0.15217391304347827  14 / 92
0.0    1.0    1.0   6.0    1.0   0.0   1.0    1.0   2.0   1.0    3.0   0.0   0.0    0.0    0.0   0.0    3.0   2.0    6.0   8.0   0.0    0.0   0.0    59.0  1.0    4.0    0.41                 41 / 100
0.0    0.0    0.0   0.0    0.0   4.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    1.0   2.0    4.0   0.0    0.0   15.0  1.0    6.0   0.0    0.0   74.0   0.0    0.308411214953271    33 / 107
0.0    0.0    0.0   1.0    1.0   2.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0    0.0    0.0   1.0    0.0   0.0    11.0  2.0   0.0    0.0   0.0    2.0   0.0    65.0   0.25287356321839083  22 / 87
109.0  110.0  73.0  130.0  60.0  92.0  108.0  67.0  77.0  106.0  92.0  78.0  102.0  100.0  75.0  104.0  93.0  119.0  98.0  92.0  103.0  81.0  116.0  78.0  124.0  103.0  0.2995983935742972   746 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.700402
2    0.825301
3    0.883936
4    0.912048
5    0.931727
6    0.944578
7    0.954217
8    0.961847
9    0.967871
10   0.975904
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:22  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:22  1 min 59.104 sec  142957 obs/sec    1         1             10007      0.72077          1.57861             0.990767       0.448066                         0.715821           1.54978               0.99087          0.441365
    2019-07-24 15:37:23  1 min 59.742 sec  145239 obs/sec    10        10            100070     0.567082         1.02559             0.994285       0.291513                         0.570233           1.02949               0.994206         0.299598
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0871039
C15         0.954174               0.954174             0.0831123
C11         0.938569               0.938569             0.081753
C9          0.93798                0.93798              0.0817017
C7          0.900674               0.900674             0.0784522
C14         0.857336               0.857336             0.0746773
C12         0.850207               0.850207             0.0740564
C8          0.828393               0.828393             0.0721563
C6          0.696766               0.696766             0.060691
C10         0.694161               0.694161             0.0604642
C16         0.635345               0.635345             0.055341
C5          0.516669               0.516669             0.0450039
C3          0.482879               0.482879             0.0420606
C4          0.444853               0.444853             0.0387484
C1          0.380998               0.380998             0.0331864
C2          0.361541               0.361541             0.0314916
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_72

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 10,007 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0013346405515619608  0.0004200190305709839  0.0         -0.0015382033006474671  0.21209585666656494  0.0017980144571901197  0.13868802785873413
    3        26       Softmax                 0.0   0.0   0.002648457505249378   0.0007969459984451532  0.0         0.00646628782688306     0.4412938356399536   -0.15262341705314358   0.13630908727645874


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3439905239662565
RMSE: 0.5865070536372572
LogLoss: 1.1020766741268506
Mean Per-Class Error: 0.2933121062991132
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    1.0    1.0    0.0    7.0    0.0    7.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    6.0    2.0    5.0    3.0    0.09873417721518987  39 / 395
0.0    289.0  0.0    2.0    3.0    2.0    4.0    5.0    14.0   1.0    0.0    0.0    3.0    0.0    2.0    3.0    0.0    29.0   13.0   0.0    0.0    0.0    5.0    3.0    1.0    4.0    0.2454308093994778   94 / 383
0.0    0.0    290.0  0.0    30.0   0.0    10.0   0.0    0.0    0.0    13.0   0.0    1.0    0.0    2.0    0.0    5.0    0.0    5.0    2.0    5.0    0.0    5.0    0.0    0.0    0.0    0.21195652173913043  78 / 368
7.0    23.0   0.0    305.0  0.0    0.0    0.0    5.0    4.0    6.0    0.0    1.0    2.0    5.0    1.0    4.0    0.0    12.0   3.0    1.0    3.0    0.0    0.0    7.0    0.0    14.0   0.24317617866004962  98 / 403
0.0    12.0   2.0    0.0    286.0  1.0    9.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    11.0   4.0    7.0    2.0    1.0    0.0    0.0    0.0    0.0    44.0   0.2552083333333333   98 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    5.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    20.0   4.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    1.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    7.0    0.0    6.0    14.0   0.0    7.0    3.0    29.0   1.0    0.0    3.0    0.0    0.0    4.0    0.0    22.0   9.0    9.0    13.0   11.0   1.0    1.0    238.0  12.0   4.0    0.39593908629441626  156 / 394
0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    9.0    0.0    8.0    76.0   2.0    17.0   3.0    0.0    275.0  0.0    0.30025445292620867  118 / 393
6.0    0.0    0.0    0.0    10.0   9.0    2.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    32.0   3.0    0.0    0.0    0.0    0.0    0.0    294.0  0.1989100817438692   73 / 367
450.0  535.0  372.0  421.0  428.0  307.0  295.0  188.0  386.0  330.0  305.0  326.0  444.0  344.0  389.0  377.0  327.0  451.0  286.0  476.0  463.0  322.0  537.0  358.0  404.0  482.0  0.2918124562631211   2,919 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.708187
2    0.818454
3    0.874038
4    0.90053
5    0.922523
6    0.935619
7    0.945816
8    0.954214
9    0.961711
10   0.969109

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3409915601892901
RMSE: 0.5839448263229071
LogLoss: 1.0847337862899669
Mean Per-Class Error: 0.29005224235260507
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10    11    12    13    14    15     16    17     18    19     20     21    22     23    24     25     Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -------------------  -----------
81.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0    0.0   2.0    1.0   2.0    0.0    0.0898876404494382   8 / 89
0.0    80.0   0.0   0.0    2.0    0.0   1.0   2.0   3.0   0.0   0.0   0.0   1.0   0.0   1.0   1.0    0.0   8.0    2.0   0.0    0.0    0.0   3.0    2.0   0.0    0.0    0.24528301886792453  26 / 106
0.0    0.0    58.0  0.0    7.0    0.0   4.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   1.0   0.0    2.0   0.0    3.0   1.0    1.0    0.0   2.0    0.0   0.0    0.0    0.2926829268292683   24 / 82
4.0    6.0    0.0   90.0   0.0    0.0   0.0   4.0   0.0   1.0   0.0   1.0   0.0   2.0   1.0   1.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    1.0   0.0    0.0    0.19642857142857142  22 / 112
0.0    4.0    1.0   0.0    71.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    3.0   1.0    1.0   1.0    0.0    0.0   0.0    0.0   0.0    13.0   0.26804123711340205  26 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---                  ---
0.0    1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   1.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0    0.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0    1.0    0.0   3.0    6.0    0.0   1.0   2.0   7.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0    4.0   5.0    4.0   1.0    3.0    0.0   0.0    55.0  6.0    1.0    0.45                 45 / 100
0.0    0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    5.0   0.0    1.0   17.0   1.0    4.0   2.0    0.0   76.0   0.0    0.2897196261682243   31 / 107
1.0    0.0    0.0   0.0    3.0    2.0   0.0   0.0   0.0   3.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0   1.0    0.0    0.0   0.0    0.0   0.0    69.0   0.20689655172413793  18 / 87
108.0  133.0  76.0  121.0  108.0  62.0  72.0  54.0  91.0  91.0  71.0  90.0  99.0  88.0  85.0  117.0  91.0  118.0  74.0  111.0  118.0  71.0  132.0  80.0  113.0  116.0  0.28714859437751006  715 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.712851
2    0.817671
3    0.878313
4    0.904016
5    0.925301
6    0.937751
7    0.94739
8    0.955422
9    0.963454
10   0.968675
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:23  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:23  1 min 59.969 sec  55287 obs/sec     1         1             10007      0.586507         1.10208             0.993888       0.291812                         0.583945           1.08473               0.993924         0.287149
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C12         1                      1                    0.0808469
C9          0.999911               0.999911             0.0808396
C15         0.989454               0.989454             0.0799943
C13         0.942827               0.942827             0.0762246
C11         0.852644               0.852644             0.0689336
C8          0.829088               0.829088             0.0670292
C7          0.816826               0.816826             0.0660378
C14         0.80706                0.80706              0.0652483
C10         0.794186               0.794186             0.0642075
C16         0.728666               0.728666             0.0589104
C6          0.70895                0.70895              0.0573164
C4          0.629865               0.629865             0.0509226
C3          0.620515               0.620515             0.0501667
C2          0.593423               0.593423             0.0479764
C5          0.555248               0.555248             0.04489
C1          0.5004                 0.5004               0.0404558
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_6

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.001099429368082383   0.0002656837459653616  0.0         -0.020735467134272767  1.1046738624572754  -0.23667082216385746  1.1619582176208496
    3        26       Softmax                 0.0   0.0   0.0017665637184948607  0.0001833497080951929  0.0         -0.017000711533560555  0.5860579013824463  -0.4675294060364851   0.23742491006851196


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3367416203045368
RMSE: 0.5802944255328814
LogLoss: 1.0835057708715092
Mean Per-Class Error: 0.31255843924785154
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    12.0   1.0    0.0    0.0    1.0    0.0    6.0    0.0    1.0    1.0    6.0    3.0    5.0    0.0    0.11392405063291139  45 / 395
0.0    274.0  0.0    8.0    1.0    0.0    0.0    7.0    8.0    2.0    3.0    0.0    4.0    0.0    9.0    3.0    5.0    43.0   9.0    0.0    0.0    1.0    0.0    1.0    4.0    1.0    0.2845953002610966   109 / 383
1.0    1.0    273.0  0.0    21.0   1.0    21.0   1.0    0.0    0.0    9.0    0.0    1.0    0.0    7.0    0.0    5.0    0.0    8.0    4.0    5.0    0.0    6.0    0.0    0.0    3.0    0.2561307901907357   94 / 367
2.0    9.0    0.0    303.0  0.0    0.0    0.0    12.0   0.0    4.0    1.0    0.0    7.0    6.0    14.0   5.0    0.0    23.0   5.0    0.0    4.0    0.0    1.0    6.0    1.0    0.0    0.24813895781637718  100 / 403
0.0    14.0   32.0   0.0    207.0  2.0    40.0   0.0    4.0    0.0    2.0    7.0    0.0    0.0    0.0    1.0    13.0   9.0    3.0    2.0    2.0    0.0    0.0    20.0   0.0    26.0   0.4609375            177 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    23.0   2.0    0.0    0.0    3.0    4.0    0.0    0.0    0.0    3.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
0.0    8.0    0.0    4.0    40.0   0.0    0.0    4.0    4.0    6.0    3.0    1.0    0.0    0.0    4.0    3.0    20.0   9.0    18.0   9.0    1.0    0.0    0.0    212.0  11.0   37.0   0.4619289340101523   182 / 394
1.0    0.0    0.0    1.0    0.0    14.0   0.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    0.0    10.0   12.0   0.0    9.0    65.0   1.0    33.0   3.0    0.0    239.0  0.0    0.39185750636132316  154 / 393
0.0    3.0    0.0    2.0    17.0   12.0   1.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    4.0    55.0   2.0    0.0    0.0    0.0    5.0    1.0    260.0  0.29155313351498635  107 / 367
416.0  531.0  417.0  420.0  347.0  344.0  369.0  294.0  323.0  327.0  236.0  325.0  503.0  366.0  433.0  391.0  429.0  504.0  296.0  438.0  379.0  379.0  455.0  308.0  367.0  406.0  0.3115065480355893   3,116 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.688493
2    0.813156
3    0.863641
4    0.894931
5    0.918324
6    0.93322
7    0.944217
8    0.953114
9    0.960312
10   0.96731

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.34072844584595074
RMSE: 0.583719492432753
LogLoss: 1.0887438163459613
Mean Per-Class Error: 0.32391384913079546
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   2.0    1.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0   0.0   2.0    2.0   2.0    0.0   0.12359550561797752  11 / 89
0.0   72.0   0.0   1.0    0.0   0.0   0.0   2.0   3.0   0.0   2.0   0.0   1.0    0.0   2.0   2.0    3.0    14.0   2.0   0.0    0.0   1.0   0.0    0.0   1.0    0.0   0.32075471698113206  34 / 106
0.0   1.0    58.0  0.0    2.0   0.0   7.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   4.0   0.0    0.0    0.0    3.0   0.0    2.0   0.0   1.0    0.0   0.0    1.0   0.2926829268292683   24 / 82
1.0   1.0    0.0   89.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   3.0    1.0   3.0   0.0    0.0    7.0    2.0   0.0    1.0   0.0   0.0    2.0   0.0    0.0   0.20535714285714285  23 / 112
0.0   7.0    8.0   0.0    48.0  1.0   10.0  0.0   1.0   0.0   0.0   2.0   0.0    0.0   0.0   0.0    3.0    3.0    1.0   0.0    0.0   0.0   0.0    5.0   0.0    8.0   0.5051546391752577   49 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0    1.0    0.0   0.0    0.0   1.0   86.0   0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   0.0    13.0  0.0   0.0   2.0   2.0   2.0   3.0   1.0   0.0    0.0   1.0   0.0    3.0    4.0    4.0   1.0    0.0   0.0   0.0    48.0  7.0    9.0   0.52                 52 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   2.0    0.0   0.0   2.0    6.0    0.0    2.0   17.0   0.0   9.0   2.0    0.0   65.0   0.0   0.3925233644859813   42 / 107
0.0   1.0    0.0   1.0    8.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0    15.0  2.0    0.0   0.0   0.0    3.0   1.0    53.0  0.39080459770114945  34 / 87
97.0  137.0  91.0  122.0  83.0  79.0  94.0  72.0  74.0  92.0  62.0  88.0  122.0  89.0  92.0  114.0  104.0  131.0  82.0  102.0  99.0  85.0  112.0  72.0  104.0  91.0  0.3224899598393574   803 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.67751
2    0.806426
3    0.861847
4    0.895984
5    0.92249
6    0.935743
7    0.946185
8    0.955422
9    0.963855
10   0.96988
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:38  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:38  15.076 sec  138986 obs/sec    1         1             10007      0.690147         1.50665             0.991536       0.418674                         0.686961           1.48562               0.991591         0.413655
    2019-07-24 15:35:39  15.696 sec  148471 obs/sec    10        10            100070     0.580294         1.08351             0.994016       0.311507                         0.583719           1.08874               0.993929         0.32249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0923408
C13         0.898022               0.898022             0.0829241
C12         0.826205               0.826205             0.0762924
C9          0.817346               0.817346             0.0754744
C11         0.803137               0.803137             0.0741624
C14         0.765384               0.765384             0.0706762
C8          0.739707               0.739707             0.0683051
C7          0.729957               0.729957             0.0674048
C6          0.629291               0.629291             0.0581093
C16         0.609863               0.609863             0.0563152
C5          0.584392               0.584392             0.0539632
C3          0.52429                0.52429              0.0484133
C4          0.516006               0.516006             0.0476484
C10         0.514845               0.514845             0.0475412
C1          0.467924               0.467924             0.0432085
C2          0.403081               0.403081             0.0372209
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_62

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008041648193284345  0.00021699647186324   0.0         -0.017723129073203836  0.2840496301651001  0.013621864923966033  0.24036920070648193
    3        26       Softmax                      0.0   0.0   0.004690006598768657   0.010245688259601593  0.0         -0.3590394074437007    0.895374059677124   -0.8775386677709398   0.6200516223907471


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3758977860375875
RMSE: 0.6131050367087091
LogLoss: 1.107122520057842
Mean Per-Class Error: 0.2679622219243711
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  5.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    2.0    2.0    0.0    7.0    0.0    1.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    8.0    1.0    4.0    0.0    0.09644670050761421  38 / 394
0.0    320.0  0.0    10.0   2.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    14.0   1.0    5.0    13.0   2.0    0.0    0.0    1.0    0.0    11.0   1.0    0.0    0.16449086161879894  63 / 383
0.0    0.0    297.0  0.0    2.0    0.0    17.0   0.0    0.0    0.0    26.0   0.0    0.0    0.0    4.0    3.0    3.0    0.0    1.0    0.0    1.0    0.0    6.0    8.0    0.0    0.0    0.19293478260869565  71 / 368
3.0    15.0   0.0    319.0  0.0    0.0    4.0    3.0    0.0    3.0    0.0    0.0    5.0    4.0    15.0   0.0    0.0    12.0   2.0    0.0    0.0    0.0    0.0    11.0   0.0    7.0    0.20843672456575682  84 / 403
0.0    9.0    2.0    1.0    250.0  3.0    20.0   0.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    14.0   4.0    21.0   1.0    0.0    0.0    0.0    24.0   0.0    29.0   0.3472584856396867   133 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    5.0    0.0    11.0   2.0    13.0   0.0    0.0    5.0    0.0    0.0    0.0    0.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    3.0    1.0    14.0   5.0    0.0    1.0    0.0    3.0    1.0    6.0    0.0    0.0    2.0    0.0    0.0    5.0    0.0    18.0   3.0    2.0    1.0    0.0    301.0  7.0    21.0   0.23604060913705585  93 / 394
1.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    5.0    13.0   0.0    12.0   47.0   0.0    20.0   6.0    0.0    274.0  0.0    0.30279898218829515  119 / 393
5.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    53.0   2.0    0.0    0.0    0.0    2.0    0.0    295.0  0.19618528610354224  72 / 367
418.0  542.0  382.0  500.0  314.0  319.0  296.0  166.0  325.0  321.0  396.0  321.0  450.0  366.0  519.0  384.0  365.0  405.0  383.0  393.0  328.0  356.0  468.0  485.0  350.0  451.0  0.2669199240227932   2,670 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.73308
2    0.83445
3    0.875337
4    0.90133
5    0.922923
6    0.939818
7    0.953714
8    0.961611
9    0.971209
10   0.976507

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3776281436383445
RMSE: 0.6145145593379742
LogLoss: 1.1057796154829427
Mean Per-Class Error: 0.27045770444921147
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12    13    14     15     16    17     18     19    20    21    22     23     24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  ----  ----  -----  -----  ----  -----  -------------------  -----------
80.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0    1.0    0.0   0.0   0.0   3.0    0.0    2.0   0.0    0.10112359550561797  9 / 89
0.0    84.0   0.0   4.0    2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   7.0    1.0    1.0   3.0    0.0    0.0   0.0   1.0   0.0    3.0    0.0   0.0    0.20754716981132076  22 / 106
0.0    0.0    58.0  0.0    1.0   0.0   8.0   0.0   0.0   0.0   6.0   0.0   0.0   0.0   2.0    2.0    1.0   0.0    1.0    0.0   0.0   0.0   2.0    1.0    0.0   0.0    0.2926829268292683   24 / 82
2.0    1.0    0.0   92.0   0.0   0.0   2.0   2.0   0.0   0.0   0.0   0.0   1.0   2.0   4.0    0.0    0.0   2.0    1.0    0.0   0.0   0.0   0.0    1.0    0.0   2.0    0.17857142857142858  20 / 112
0.0    3.0    0.0   0.0    58.0  1.0   7.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0    0.0    3.0   1.0    6.0    1.0   0.0   0.0   0.0    5.0    0.0   10.0   0.4020618556701031   39 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---   ---   ---    ---    ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   2.0   0.0   2.0   0.0   2.0    0.0    0.0   0.0    0.0    0.0   0.0   0.0   85.0   0.0    0.0   0.0    0.07608695652173914  7 / 92
0.0    1.0    0.0   5.0    2.0   0.0   0.0   0.0   2.0   0.0   2.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0    5.0    0.0   0.0   0.0   0.0    75.0   3.0   4.0    0.25                 25 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0    3.0    6.0   0.0    3.0    11.0  0.0   3.0   2.0    0.0    74.0  0.0    0.308411214953271    33 / 107
1.0    0.0    0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    11.0   1.0   0.0   0.0   0.0    1.0    0.0   72.0   0.1724137931034483   15 / 87
101.0  130.0  73.0  137.0  70.0  82.0  79.0  49.0  77.0  93.0  94.0  89.0  98.0  95.0  121.0  108.0  95.0  105.0  100.0  90.0  86.0  76.0  119.0  112.0  94.0  117.0  0.26947791164658635  671 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730522
2    0.842972
3    0.881928
4    0.906024
5    0.926908
6    0.94257
7    0.952209
8    0.962249
9    0.970683
10   0.97751
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:09  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:09  1 min 45.835 sec  250175 obs/sec    1         1             10007      0.846831         2.13535             0.987253       0.529041                         0.846683           2.12922               0.987226         0.525301
    2019-07-24 15:37:09  1 min 46.168 sec  279525 obs/sec    10        10            100070     0.613105         1.10712             0.993319       0.26692                          0.614515           1.10578               0.993271         0.269478
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.107798
C15         0.980306               0.980306             0.105675
C9          0.773034               0.773034             0.0833318
C8          0.688194               0.688194             0.0741862
C7          0.657219               0.657219             0.0708471
C14         0.619477               0.619477             0.0667786
C11         0.592098               0.592098             0.0638272
C12         0.525267               0.525267             0.0566229
C3          0.512088               0.512088             0.0552022
C10         0.497875               0.497875             0.0536701
C6          0.487957               0.487957             0.0526009
C5          0.478755               0.478755             0.051609
C16         0.464889               0.464889             0.0501142
C4          0.380181               0.380181             0.0409829
C1          0.336387               0.336387             0.036262
C2          0.282854               0.282854             0.0304911
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_14

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008022137569696497  0.00022431567776948214  0.0         -0.03209662890183296  0.2854948043823242  0.05158007668981676  0.20044821500778198
    3        26       Softmax                      0.0   0.0   0.004443937154414575   0.00757385790348053     0.0         -0.3462141651567575   0.8937277793884277  -0.7868865396364277  0.6495592594146729


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3717504534894438
RMSE: 0.6097134191482453
LogLoss: 1.0918966705653066
Mean Per-Class Error: 0.2711079932473367
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  4.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    5.0    4.0    0.0    4.0    0.0    6.0    0.0    4.0    0.0    0.0    2.0    1.0    4.0    4.0    1.0    3.0    1.0    0.11392405063291139  45 / 395
0.0    319.0  0.0    7.0    0.0    0.0    7.0    1.0    3.0    0.0    1.0    0.0    0.0    0.0    7.0    1.0    0.0    26.0   9.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.1671018276762402   64 / 383
0.0    0.0    287.0  1.0    18.0   3.0    17.0   1.0    0.0    1.0    13.0   1.0    2.0    0.0    3.0    0.0    7.0    0.0    8.0    0.0    3.0    0.0    2.0    1.0    0.0    0.0    0.22010869565217392  81 / 368
1.0    36.0   0.0    302.0  2.0    0.0    3.0    13.0   2.0    4.0    0.0    0.0    4.0    5.0    5.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.2506203473945409   101 / 403
0.0    6.0    4.0    0.0    285.0  6.0    7.0    0.0    0.0    0.0    6.0    1.0    0.0    0.0    2.0    0.0    16.0   4.0    13.0   2.0    0.0    0.0    0.0    9.0    0.0    23.0   0.2578125            99 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    27.0   10.0   2.0    0.0    1.0    5.0    0.0    0.0    2.0    0.0    325.0  0.0    0.0    0.0    0.1356382978723404   51 / 376
0.0    6.0    0.0    2.0    18.0   0.0    1.0    0.0    2.0    1.0    5.0    0.0    0.0    0.0    2.0    0.0    31.0   2.0    14.0   8.0    1.0    0.0    0.0    277.0  6.0    18.0   0.2969543147208122   117 / 394
0.0    3.0    0.0    0.0    0.0    10.0   2.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    20.0   0.0    3.0    49.0   0.0    77.0   0.0    0.0    217.0  2.0    0.44783715012722647  176 / 393
1.0    5.0    0.0    0.0    29.0   3.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    41.0   2.0    0.0    0.0    0.0    0.0    0.0    276.0  0.24795640326975477  91 / 367
400.0  592.0  362.0  404.0  413.0  351.0  303.0  222.0  362.0  317.0  361.0  306.0  451.0  359.0  444.0  353.0  435.0  429.0  330.0  402.0  399.0  451.0  466.0  391.0  285.0  415.0  0.2699190242927122   2,700 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730081
2    0.836749
3    0.882035
4    0.911227
5    0.930621
6    0.944816
7    0.955213
8    0.96541
9    0.973008
10   0.977907

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.37562554841823126
RMSE: 0.612882981015325
LogLoss: 1.106453181737604
Mean Per-Class Error: 0.2766747983169082
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12    13    14    15     16     17     18    19    20     21     22     23    24    25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  -----  -----  ----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   2.0   0.0    1.0    0.0    0.0   0.0   0.0    2.0    1.0    0.0   2.0   0.0   0.10112359550561797  9 / 89
0.0   80.0   0.0   3.0    0.0    0.0   2.0   1.0   1.0   0.0   1.0   0.0   0.0   0.0   3.0   1.0    0.0    11.0   1.0   0.0   0.0    1.0    0.0    1.0   0.0   0.0   0.24528301886792453  26 / 106
0.0   0.0    57.0  0.0    5.0    1.0   4.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   2.0   0.0    4.0    0.0    4.0   0.0   1.0    0.0    1.0    0.0   0.0   0.0   0.3048780487804878   25 / 82
1.0   6.0    0.0   89.0   0.0    0.0   2.0   3.0   0.0   2.0   0.0   0.0   1.0   3.0   1.0   0.0    0.0    3.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.20535714285714285  23 / 112
0.0   0.0    0.0   0.0    69.0   3.0   4.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    3.0    1.0    5.0   1.0   0.0    0.0    0.0    3.0   0.0   7.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---    ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   6.0   1.0   1.0   0.0    0.0    1.0    0.0   0.0   1.0    0.0    82.0   0.0   0.0   0.0   0.10869565217391304  10 / 92
0.0   3.0    0.0   2.0    7.0    0.0   1.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0    4.0    0.0    5.0   2.0   1.0    0.0    0.0    69.0  1.0   3.0   0.31                 31 / 100
0.0   2.0    0.0   0.0    0.0    2.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   4.0   0.0    5.0    0.0    0.0   12.0  0.0    21.0   0.0    0.0   59.0  0.0   0.4485981308411215   48 / 107
0.0   1.0    0.0   0.0    10.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    3.0    0.0    8.0   1.0   0.0    0.0    0.0    0.0   0.0   63.0  0.27586206896551724  24 / 87
94.0  145.0  73.0  118.0  107.0  73.0  76.0  56.0  88.0  84.0  92.0  82.0  96.0  92.0  97.0  112.0  117.0  112.0  88.0  98.0  100.0  108.0  119.0  92.0  77.0  94.0  0.27630522088353415  688 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.723695
2    0.831727
3    0.87992
4    0.91004
5    0.928916
6    0.94257
7    0.950201
8    0.963052
9    0.971887
10   0.976707
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:35:53  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:35:53  29.876 sec  263342 obs/sec    1         1             10007      0.839328         2.0822              0.987484       0.519744                         0.839728           2.0823                0.987435         0.516867
    2019-07-24 15:35:53  30.222 sec  270459 obs/sec    10        10            100070     0.609713         1.0919              0.993395       0.269919                         0.612883           1.10645               0.993307         0.276305
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.104188
C13         0.964541               0.964541             0.100493
C12         0.819587               0.819587             0.0853909
C9          0.746594               0.746594             0.077786
C8          0.701411               0.701411             0.0730784
C11         0.658442               0.658442             0.0686016
C7          0.640358               0.640358             0.0667174
C14         0.623565               0.623565             0.0649678
C10         0.55821                0.55821              0.0581587
C6          0.496299               0.496299             0.0517083
C4          0.447928               0.447928             0.0466686
C5          0.443462               0.443462             0.0462033
C16         0.441029               0.441029             0.0459498
C3          0.429127               0.429127             0.0447098
C1          0.336813               0.336813             0.0350918
C2          0.290693               0.290693             0.0302866
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_23

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight          weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  -------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008107133129442445  0.00023498531663790345  0.0         -0.0142924696508544  0.28885018825531006  0.009623265604551914  0.20048165321350098
    3        26       Softmax                      0.0   0.0   0.004398806487083325   0.007416887208819389    0.0         -0.3123166053312441  0.8706293106079102   -0.8418893521077802   0.5321502685546875


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.381374905155064
RMSE: 0.6175555887165657
LogLoss: 1.1166629192963622
Mean Per-Class Error: 0.27058152857590745
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    4.0    2.0    0.0    10.0   0.0    1.0    0.0    1.0    0.0    12.0   0.0    1.0    2.0    4.0    1.0    4.0    0.0    0.11392405063291139  45 / 395
0.0    281.0  0.0    10.0   1.0    0.0    2.0    0.0    4.0    1.0    5.0    0.0    7.0    0.0    4.0    5.0    2.0    30.0   13.0   0.0    0.0    0.0    1.0    17.0   0.0    0.0    0.26631853785900783  102 / 383
0.0    0.0    302.0  0.0    14.0   0.0    9.0    2.0    0.0    0.0    30.0   0.0    1.0    0.0    3.0    3.0    1.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
4.0    5.0    0.0    318.0  0.0    0.0    0.0    0.0    1.0    8.0    3.0    0.0    4.0    5.0    2.0    1.0    0.0    14.0   6.0    1.0    0.0    0.0    0.0    31.0   0.0    0.0    0.2109181141439206   85 / 403
0.0    6.0    3.0    1.0    283.0  0.0    14.0   0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    12.0   8.0    0.0    2.0    4.0    0.0    0.0    15.0   3.0    26.0   0.2630208333333333   101 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    19.0   10.0   0.0    0.0    0.0    5.0    0.0    0.0    1.0    1.0    338.0  0.0    0.0    0.0    0.09866666666666667  37 / 375
1.0    5.0    0.0    8.0    9.0    0.0    0.0    2.0    5.0    2.0    4.0    4.0    0.0    0.0    0.0    0.0    3.0    6.0    10.0   2.0    14.0   0.0    0.0    302.0  16.0   1.0    0.233502538071066    92 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    1.0    15.0   0.0    11.0   59.0   0.0    26.0   1.0    2.0    267.0  1.0    0.32061068702290074  126 / 393
12.0   0.0    0.0    0.0    14.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    47.0   3.0    0.0    0.0    0.0    7.0    0.0    278.0  0.24250681198910082  89 / 367
403.0  450.0  401.0  474.0  391.0  261.0  221.0  210.0  350.0  343.0  435.0  322.0  491.0  378.0  330.0  427.0  379.0  461.0  330.0  421.0  409.0  328.0  474.0  528.0  378.0  408.0  0.26941917424772566  2,695 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730581
2    0.838349
3    0.881136
4    0.908228
5    0.928921
6    0.943917
7    0.954414
8    0.962511
9    0.968709
10   0.975307

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3828396593669603
RMSE: 0.6187403812318704
LogLoss: 1.1198420055867915
Mean Per-Class Error: 0.280037253821731
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16     17     18    19     20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  ----  -----  -----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0    0.0    1.0   1.0    0.0    3.0    0.0    0.10112359550561797  9 / 89
0.0   73.0   0.0   3.0    1.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   1.0    0.0   3.0   0.0    1.0    11.0   5.0   0.0    0.0    0.0   1.0    5.0    0.0    0.0    0.3113207547169811   33 / 106
0.0   0.0    63.0  0.0    2.0   0.0   4.0   2.0   0.0   0.0   8.0    0.0   0.0    0.0   1.0   1.0    0.0    0.0    0.0   0.0    1.0    0.0   0.0    0.0    0.0    0.0    0.23170731707317074  19 / 82
3.0   0.0    0.0   93.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0   1.0    2.0   0.0   0.0    0.0    2.0    3.0   0.0    0.0    0.0   0.0    5.0    0.0    0.0    0.16964285714285715  19 / 112
0.0   1.0    1.0   0.0    64.0  0.0   5.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    3.0    3.0    0.0   2.0    0.0    0.0   0.0    3.0    0.0    13.0   0.3402061855670103   33 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   3.0    2.0   0.0   0.0    0.0    1.0    0.0   0.0    0.0    0.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   4.0    0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0   2.0    2.0   0.0    0.0   0.0   0.0    1.0    2.0    2.0   0.0    4.0    0.0   0.0    70.0   7.0    1.0    0.3                  30 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   2.0   1.0    7.0    0.0    2.0   15.0   0.0    8.0   1.0    1.0    70.0   0.0    0.34579439252336447  37 / 107
2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0    0.0    11.0  1.0    0.0    0.0   0.0    2.0    0.0    66.0   0.2413793103448276   21 / 87
93.0  105.0  84.0  136.0  90.0  52.0  56.0  50.0  78.0  98.0  112.0  92.0  109.0  96.0  72.0  121.0  102.0  116.0  87.0  104.0  100.0  75.0  117.0  127.0  107.0  111.0  0.27751004016064257  691 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.72249
2    0.833735
3    0.885542
4    0.91004
5    0.932932
6    0.946586
7    0.957028
8    0.964257
9    0.969478
10   0.974699
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:07  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:07  43.862 sec  250175 obs/sec    1         1             10007      0.84599          2.13926             0.987282       0.541238                         0.843624           2.12742               0.987319         0.529317
    2019-07-24 15:36:07  44.172 sec  299610 obs/sec    10        10            100070     0.617556         1.11666             0.993223       0.269419                         0.61874            1.11984               0.993178         0.27751
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.100886
C15         0.836559               0.836559             0.0843972
C8          0.792994               0.792994             0.0800021
C12         0.740718               0.740718             0.0747281
C11         0.713193               0.713193             0.0719512
C9          0.713147               0.713147             0.0719466
C7          0.684481               0.684481             0.0690546
C14         0.630249               0.630249             0.0635834
C6          0.587832               0.587832             0.0593041
C10         0.570678               0.570678             0.0575735
C5          0.516662               0.516662             0.052124
C4          0.514797               0.514797             0.0519359
C16         0.480601               0.480601             0.048486
C3          0.46552                0.46552              0.0469645
C1          0.347496               0.347496             0.0350576
C2          0.317242               0.317242             0.0320053
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_22

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011383391992012548  0.0003052990650758147   0.0         0.05099350189766483   2.0370426177978516  -0.37923056253668    1.3798341751098633
    3        26       Softmax                 0.0   0.0   0.0016847265377201927  0.00012002792209386826  0.0         0.010118201492192523  0.5144474506378174  -0.5901815979234878  0.3678152561187744


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4501221362387173
RMSE: 0.6709114220511656
LogLoss: 1.3661822230702345
Mean Per-Class Error: 0.3748169434516744
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  0.0    0.0    2.0    0.0    0.0    0.0    3.0    0.0    0.0    3.0    4.0    6.0    2.0    1.0    0.0    3.0    5.0    6.0    0.0    0.0    1.0    6.0    0.0    5.0    0.0    0.1189873417721519   47 / 395
0.0    267.0  0.0    10.0   1.0    0.0    1.0    6.0    0.0    15.0   0.0    0.0    7.0    0.0    2.0    1.0    8.0    38.0   20.0   0.0    0.0    3.0    0.0    0.0    4.0    0.0    0.3028720626631854   116 / 383
0.0    0.0    214.0  0.0    32.0   4.0    50.0   0.0    4.0    0.0    17.0   0.0    4.0    0.0    1.0    0.0    11.0   0.0    7.0    14.0   8.0    0.0    2.0    0.0    0.0    0.0    0.41847826086956524  154 / 368
8.0    28.0   0.0    256.0  0.0    1.0    0.0    10.0   0.0    11.0   1.0    0.0    8.0    4.0    21.0   10.0   0.0    26.0   3.0    3.0    0.0    0.0    0.0    12.0   1.0    0.0    0.36476426799007444  147 / 403
0.0    12.0   10.0   0.0    217.0  0.0    28.0   0.0    5.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    27.0   2.0    9.0    14.0   3.0    1.0    0.0    10.0   0.0    44.0   0.4348958333333333   167 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    40.0   6.0    0.0    1.0    1.0    2.0    0.0    0.0    1.0    27.0   295.0  0.0    0.0    0.0    0.2154255319148936   81 / 376
27.0   20.0   2.0    7.0    17.0   1.0    6.0    0.0    3.0    9.0    10.0   1.0    0.0    0.0    2.0    0.0    18.0   1.0    12.0   31.0   7.0    0.0    0.0    160.0  9.0    51.0   0.5939086294416244   234 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    3.0    8.0    0.0    3.0    78.0   0.0    102.0  4.0    0.0    184.0  0.0    0.5318066157760815   209 / 393
6.0    9.0    0.0    4.0    13.0   3.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    3.0    32.0   6.0    0.0    0.0    0.0    3.0    0.0    280.0  0.23705722070844687  87 / 367
456.0  576.0  322.0  400.0  357.0  285.0  392.0  117.0  329.0  364.0  258.0  320.0  557.0  406.0  321.0  430.0  429.0  482.0  268.0  518.0  435.0  472.0  444.0  263.0  296.0  506.0  0.3729881035689293   3,731 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.627012
2    0.769069
3    0.830551
4    0.86724
5    0.894332
6    0.915026
7    0.929321
8    0.943717
9    0.954614
10   0.960712

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.45253964988380047
RMSE: 0.6727106732346384
LogLoss: 1.38090870156794
Mean Per-Class Error: 0.3777959327731205
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19     20     21     22     23    24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  -----  -----  -----  -----  ----  ----  -----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    1.0    3.0    1.0   0.0    0.0    0.0    2.0    0.0   3.0   0.0    0.11235955056179775  10 / 89
0.0    67.0   0.0   2.0    1.0   0.0   0.0   2.0   0.0   4.0    0.0   0.0   2.0    0.0    1.0   0.0    6.0    14.0   4.0   0.0    0.0    2.0    0.0    0.0   1.0   0.0    0.36792452830188677  39 / 106
0.0    0.0    46.0  0.0    5.0   0.0   11.0  0.0   1.0   0.0    3.0   0.0   0.0    0.0    1.0   0.0    6.0    0.0    4.0   1.0    3.0    0.0    1.0    0.0   0.0   0.0    0.43902439024390244  36 / 82
5.0    6.0    0.0   76.0   0.0   0.0   0.0   3.0   0.0   1.0    0.0   0.0   3.0    1.0    7.0   2.0    0.0    5.0    2.0   0.0    0.0    0.0    0.0    1.0   0.0   0.0    0.32142857142857145  36 / 112
0.0    2.0    3.0   0.0    48.0  0.0   7.0   0.0   2.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    9.0    1.0    4.0   5.0    0.0    0.0    0.0    3.0   0.0   13.0   0.5051546391752577   49 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---    ---    ---    ---    ---   ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   8.0    2.0    0.0   1.0    1.0    0.0    0.0   0.0    1.0    4.0    75.0   0.0   0.0   0.0    0.18478260869565216  17 / 92
7.0    5.0    0.0   4.0    5.0   0.0   0.0   0.0   2.0   1.0    5.0   0.0   0.0    0.0    0.0   0.0    3.0    0.0    4.0   8.0    3.0    0.0    0.0    37.0  2.0   14.0   0.63                 63 / 100
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    1.0    0.0   1.0    4.0    0.0    0.0   20.0   0.0    35.0   1.0    0.0   43.0  0.0    0.5981308411214953   64 / 107
1.0    1.0    0.0   2.0    6.0   1.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    0.0    1.0    6.0   3.0    0.0    0.0    0.0    1.0   0.0   64.0   0.26436781609195403  23 / 87
111.0  136.0  70.0  117.0  84.0  57.0  91.0  29.0  76.0  100.0  67.0  85.0  126.0  106.0  65.0  120.0  123.0  121.0  72.0  121.0  114.0  118.0  113.0  65.0  82.0  121.0  0.3755020080321285   935 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.624498
2    0.761044
3    0.82249
4    0.859438
5    0.886747
6    0.91245
7    0.929719
8    0.946185
9    0.954619
10   0.961446
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:06  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:06  43.269 sec  151621 obs/sec    1         1             10007      0.741994         1.65917             0.990218       0.459762                         0.741111           1.66295               0.990213         0.460643
    2019-07-24 15:36:07  43.796 sec  173131 obs/sec    10        10            100070     0.670911         1.36618             0.992002       0.372988                         0.672711           1.38091               0.991936         0.375502
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0923385
C13         0.999022               0.999022             0.0922482
C12         0.882418               0.882418             0.0814811
C9          0.868994               0.868994             0.0802416
C11         0.844603               0.844603             0.0779894
C7          0.837971               0.837971             0.077377
C8          0.791984               0.791984             0.0731306
C14         0.770106               0.770106             0.0711105
C10         0.705753               0.705753             0.0651682
C16         0.598144               0.598144             0.0552318
C6          0.504565               0.504565             0.0465908
C3          0.498654               0.498654             0.046045
C5          0.444802               0.444802             0.0410723
C4          0.391611               0.391611             0.0361608
C1          0.383133               0.383133             0.035378
C2          0.307957               0.307957             0.0284363
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_60

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0010820815507486259  0.0002955793170258403   0.0         -0.13878672288842608   2.0891056060791016  -0.39689740038534704  1.3723478317260742
    3        26       Softmax                 0.0   0.0   0.0016774156896504932  0.00010327438940294087  0.0         -0.033904989526770526  0.5022661685943604  -0.5911452773152249   0.3624383211135864


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4716887361135593
RMSE: 0.6867959930820501
LogLoss: 1.3970135798765788
Mean Per-Class Error: 0.39540072225730205
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    3.0    0.0    0.0    0.0    1.0    1.0    0.0    3.0    0.0    12.0   1.0    8.0    1.0    1.0    0.0    2.0    0.0    0.0    1.0    5.0    0.0    5.0    0.0    0.11139240506329114  44 / 395
0.0    252.0  0.0    7.0    0.0    0.0    1.0    11.0   4.0    4.0    0.0    0.0    1.0    1.0    0.0    1.0    2.0    66.0   24.0   0.0    0.0    1.0    3.0    2.0    3.0    0.0    0.34203655352480417  131 / 383
0.0    3.0    255.0  0.0    23.0   2.0    14.0   0.0    0.0    0.0    22.0   0.0    5.0    0.0    1.0    2.0    16.0   0.0    3.0    7.0    10.0   0.0    3.0    1.0    0.0    1.0    0.3070652173913043   113 / 368
8.0    9.0    0.0    281.0  0.0    1.0    0.0    2.0    0.0    14.0   2.0    2.0    5.0    8.0    2.0    16.0   1.0    31.0   13.0   0.0    0.0    0.0    1.0    5.0    2.0    0.0    0.3027295285359802   122 / 403
0.0    36.0   63.0   0.0    115.0  1.0    33.0   1.0    11.0   3.0    3.0    0.0    0.0    0.0    0.0    0.0    17.0   6.0    10.0   5.0    1.0    0.0    0.0    21.0   3.0    55.0   0.7005208333333334   269 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    24.0   11.0   0.0    1.0    0.0    1.0    0.0    0.0    0.0    24.0   300.0  0.0    0.0    0.0    0.20212765957446807  76 / 376
30.0   16.0   0.0    6.0    41.0   0.0    1.0    6.0    28.0   14.0   7.0    3.0    0.0    0.0    3.0    0.0    20.0   7.0    30.0   24.0   2.0    0.0    0.0    130.0  7.0    19.0   0.6700507614213198   264 / 394
0.0    1.0    0.0    7.0    0.0    26.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    9.0    2.0    6.0    8.0    0.0    4.0    71.0   1.0    75.0   0.0    1.0    178.0  0.0    0.5470737913486005   215 / 393
2.0    7.0    0.0    2.0    12.0   5.0    3.0    1.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    6.0    4.0    39.0   3.0    0.0    0.0    0.0    7.0    1.0    266.0  0.27520435967302453  101 / 367
460.0  542.0  440.0  429.0  273.0  389.0  308.0  169.0  371.0  359.0  306.0  318.0  519.0  410.0  282.0  398.0  424.0  569.0  351.0  404.0  369.0  414.0  472.0  277.0  323.0  427.0  0.3939818054583625   3,941 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.606018
2    0.759772
3    0.83235
4    0.873338
5    0.902029
6    0.922923
7    0.939918
8    0.950415
9    0.956613
10   0.964211

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.470059739743514
RMSE: 0.6856090283416009
LogLoss: 1.392410636153699
Mean Per-Class Error: 0.39372184299421586
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19    20    21     22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  ----  -----  -----  ----  -----  -----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   1.0   0.0    0.0   0.0   3.0    0.0    1.0   0.0    0.0    0.0    0.0   0.0   0.0   0.0    2.0    0.0   2.0    0.0    0.11235955056179775  10 / 89
0.0    64.0   0.0   1.0    0.0   0.0   0.0   5.0   1.0   1.0    0.0   0.0   0.0    0.0    0.0   1.0    0.0    22.0   6.0   0.0   0.0   1.0    2.0    1.0   1.0    0.0    0.39622641509433965  42 / 106
0.0    1.0    49.0  0.0    3.0   2.0   7.0   0.0   0.0   0.0    6.0   0.0   0.0    0.0    1.0   1.0    5.0    0.0    1.0   1.0   3.0   0.0    2.0    0.0   0.0    0.0    0.4024390243902439   33 / 82
5.0    2.0    0.0   85.0   0.0   0.0   0.0   1.0   0.0   1.0    1.0   1.0   1.0    2.0    0.0   3.0    1.0    4.0    4.0   0.0   0.0   0.0    0.0    1.0   0.0    0.0    0.24107142857142858  27 / 112
0.0    8.0    17.0  0.0    29.0  0.0   12.0  0.0   2.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0    5.0    2.0    0.0   2.0   0.0   0.0    0.0    4.0   1.0    15.0   0.7010309278350515   68 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---   ---    ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   7.0    3.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0   6.0    74.0   0.0   0.0    0.0    0.1956521739130435   18 / 92
4.0    7.0    0.0   2.0    12.0  0.0   0.0   4.0   5.0   3.0    3.0   0.0   0.0    0.0    0.0   0.0    2.0    1.0    8.0   8.0   0.0   0.0    0.0    37.0  1.0    3.0    0.63                 63 / 100
0.0    1.0    0.0   3.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    3.0    1.0   0.0    2.0    0.0    1.0   20.0  0.0   20.0   0.0    0.0   51.0   0.0    0.5233644859813084   56 / 107
0.0    3.0    0.0   1.0    1.0   1.0   0.0   1.0   2.0   1.0    0.0   0.0   0.0    0.0    0.0   2.0    0.0    0.0    10.0  1.0   0.0   0.0    0.0    2.0   1.0    61.0   0.2988505747126437   26 / 87
108.0  131.0  89.0  125.0  63.0  80.0  88.0  42.0  84.0  100.0  82.0  88.0  118.0  114.0  48.0  110.0  109.0  132.0  99.0  92.0  97.0  102.0  117.0  72.0  100.0  100.0  0.39156626506024095  975 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.608434
2    0.762249
3    0.833735
4    0.870683
5    0.899598
6    0.920883
7    0.936145
8    0.946185
9    0.954618
10   0.963855
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:06  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:06  1 min 42.978 sec  161403 obs/sec    1         1             10007      0.748801         1.69012             0.990038       0.464561                         0.748863           1.69252               0.990007         0.473494
    2019-07-24 15:37:07  1 min 43.539 sec  165678 obs/sec    10        10            100070     0.686796         1.39701             0.991619       0.393982                         0.685609           1.39241               0.991624         0.391566
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0924244
C13         0.949814               0.949814             0.087786
C15         0.924853               0.924853             0.085479
C12         0.911313               0.911313             0.0842276
C14         0.824054               0.824054             0.0761628
C11         0.808349               0.808349             0.0747112
C7          0.771214               0.771214             0.071279
C8          0.737784               0.737784             0.0681892
C10         0.684653               0.684653             0.0632786
C16         0.589964               0.589964             0.0545271
C6          0.577392               0.577392             0.0533651
C3          0.50963                0.50963              0.0471023
C5          0.451618               0.451618             0.0417405
C4          0.393809               0.393809             0.0363975
C1          0.390116               0.390116             0.0360562
C2          0.295089               0.295089             0.0272734
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_19

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011140002504816948  0.00032234261743724346  0.0         -0.2650444347498251    2.0771799087524414  -0.19673642580701475  1.136223316192627
    3        26       Softmax                 0.0   0.0   0.0016521351138250723  8.493917994201183e-05   0.0         -0.034741876956664225  0.5056886672973633  -0.5936510639776457   0.3828160762786865


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5016182068311565
RMSE: 0.7082501018927965
LogLoss: 1.4790420218773725
Mean Per-Class Error: 0.4139810064026348
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
332.0  0.0    0.0    7.0    0.0    0.0    3.0    0.0    0.0    1.0    1.0    3.0    8.0    2.0    10.0   0.0    1.0    13.0   1.0    0.0    1.0    1.0    2.0    1.0    7.0    0.0    0.15736040609137056  62 / 394
0.0    177.0  0.0    9.0    5.0    4.0    6.0    8.0    8.0    1.0    11.0   1.0    3.0    2.0    10.0   2.0    10.0   58.0   52.0   0.0    0.0    2.0    2.0    5.0    1.0    6.0    0.5378590078328982   206 / 383
0.0    3.0    219.0  0.0    51.0   1.0    38.0   1.0    1.0    0.0    25.0   2.0    4.0    1.0    0.0    5.0    0.0    1.0    4.0    3.0    5.0    0.0    0.0    1.0    0.0    3.0    0.4048913043478261   149 / 368
3.0    18.0   0.0    258.0  0.0    0.0    1.0    4.0    7.0    11.0   0.0    8.0    4.0    14.0   12.0   10.0   4.0    23.0   5.0    3.0    1.0    0.0    1.0    9.0    2.0    5.0    0.3598014888337469   145 / 403
0.0    12.0   35.0   0.0    156.0  1.0    43.0   1.0    28.0   0.0    6.0    0.0    0.0    0.0    0.0    1.0    7.0    13.0   18.0   3.0    6.0    1.0    0.0    25.0   0.0    28.0   0.59375              228 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    7.0    16.0   0.0    1.0    1.0    16.0   0.0    0.0    1.0    19.0   313.0  0.0    0.0    0.0    0.1675531914893617   63 / 376
7.0    3.0    3.0    10.0   26.0   3.0    12.0   3.0    22.0   2.0    6.0    5.0    0.0    0.0    0.0    0.0    24.0   8.0    23.0   11.0   1.0    3.0    2.0    154.0  9.0    57.0   0.6091370558375635   240 / 394
0.0    0.0    0.0    3.0    0.0    24.0   1.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    13.0   6.0    0.0    6.0    37.0   6.0    67.0   4.0    0.0    215.0  0.0    0.4529262086513995   178 / 393
1.0    15.0   0.0    6.0    21.0   3.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    2.0    6.0    4.0    25.0   3.0    0.0    0.0    0.0    2.0    0.0    277.0  0.2452316076294278   90 / 367
418.0  361.0  350.0  443.0  368.0  452.0  459.0  158.0  393.0  314.0  350.0  338.0  389.0  416.0  384.0  374.0  339.0  590.0  309.0  335.0  344.0  435.0  475.0  289.0  396.0  524.0  0.41267619714085774  4,128 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.587324
2    0.742677
3    0.818754
4    0.857943
5    0.888533
6    0.909927
7    0.927022
8    0.938818
9    0.951215
10   0.959912

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.5024917925191639
RMSE: 0.7088665548036273
LogLoss: 1.4775741572031555
Mean Per-Class Error: 0.4189964715009803
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1     2     3      4     5      6      7     8     9     10    11    12    13     14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
-----  ----  ----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -------------
75.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   6.0    0.0   0.0   0.0   1.0   2.0    1.0   2.0    0.0    0.15730337078651685  14 / 89
0.0    44.0  0.0   1.0    0.0   1.0    2.0    3.0   3.0   1.0   3.0   1.0   0.0   1.0    2.0   0.0    8.0   17.0   13.0  0.0   0.0   1.0   2.0    0.0   0.0    3.0    0.5849056603773585   62 / 106
0.0    0.0   47.0  0.0    10.0  0.0    9.0    0.0   0.0   0.0   6.0   0.0   0.0   1.0    0.0   4.0    0.0   1.0    1.0   2.0   1.0   0.0   0.0    0.0   0.0    0.0    0.4268292682926829   35 / 82
1.0    4.0   0.0   80.0   0.0   0.0    1.0    2.0   1.0   2.0   0.0   3.0   1.0   5.0    4.0   2.0    1.0   1.0    2.0   0.0   1.0   0.0   0.0    0.0   0.0    1.0    0.2857142857142857   32 / 112
0.0    2.0   10.0  0.0    39.0  0.0    11.0   0.0   7.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   4.0    4.0   1.0   2.0   1.0   0.0    5.0   0.0    8.0    0.5979381443298969   58 / 97
---    ---   ---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   3.0   4.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   2.0   82.0   0.0   0.0    0.0    0.10869565217391304  10 / 92
3.0    2.0   0.0   1.0    9.0   1.0    1.0    1.0   6.0   1.0   4.0   1.0   0.0   0.0    0.0   0.0    4.0   2.0    7.0   2.0   0.0   0.0   0.0    40.0  3.0    12.0   0.6                  60 / 100
0.0    0.0   0.0   1.0    0.0   6.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0   1.0    3.0   4.0    2.0   0.0    0.0   4.0   1.0   17.0  2.0    0.0   65.0   0.0    0.3925233644859813   42 / 107
0.0    2.0   0.0   2.0    7.0   1.0    0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    5.0   2.0   0.0   0.0   0.0    0.0   0.0    64.0   0.26436781609195403  23 / 87
101.0  88.0  76.0  133.0  89.0  101.0  102.0  43.0  94.0  84.0  95.0  86.0  82.0  106.0  85.0  109.0  86.0  152.0  73.0  75.0  88.0  99.0  130.0  73.0  112.0  128.0  0.41847389558232934  1,042 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.581526
2    0.748594
3    0.822892
4    0.860241
5    0.89237
6    0.913253
7    0.928113
8    0.941767
9    0.954619
10   0.960241
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:36:01  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:36:01  37.933 sec  161403 obs/sec    1         1             10007      0.757588         1.72856             0.9898         0.486054                         0.755169           1.71541               0.989838         0.475502
    2019-07-24 15:36:02  38.461 sec  174034 obs/sec    10        10            100070     0.70825          1.47904             0.991085       0.412676                         0.708867           1.47757               0.991046         0.418474
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.096041
C13         0.915423               0.915423             0.0879182
C12         0.904252               0.904252             0.0868453
C9          0.86722                0.86722              0.0832887
C11         0.755085               0.755085             0.0725192
C7          0.729852               0.729852             0.0700957
C8          0.702945               0.702945             0.0675116
C14         0.642082               0.642082             0.0616662
C10         0.599928               0.599928             0.0576177
C6          0.530509               0.530509             0.0509506
C16         0.529188               0.529188             0.0508237
C3          0.517272               0.517272             0.0496793
C5          0.491982               0.491982             0.0472505
C4          0.420805               0.420805             0.0404145
C1          0.414526               0.414526             0.0398115
C2          0.391149               0.391149             0.0375663
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_59

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0012109050428534829  0.00034564174711704254  0.0         -0.06547674543298854  2.224729537963867    0.2866802431858592   1.1607327461242676
    3        26       Softmax                 0.0   0.0   0.001662836371486684   0.00010205261060036719  0.0         0.012789525933263017  0.48865461349487305  -0.5926046143153612  0.3771559000015259


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5223607211916048
RMSE: 0.7227452671526842
LogLoss: 1.5416319302670243
Mean Per-Class Error: 0.4440594542642095
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
343.0  5.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    6.0    10.0   1.0    2.0    0.0    0.0    8.0    2.0    0.0    1.0    3.0    5.0    0.0    2.0    0.0    0.13164556962025317  52 / 395
0.0    256.0  0.0    9.0    6.0    1.0    0.0    2.0    1.0    12.0   2.0    0.0    9.0    0.0    4.0    5.0    11.0   30.0   26.0   0.0    0.0    0.0    2.0    3.0    4.0    0.0    0.33159268929503916  127 / 383
0.0    0.0    256.0  0.0    22.0   6.0    15.0   1.0    0.0    0.0    25.0   0.0    1.0    1.0    1.0    2.0    8.0    0.0    2.0    7.0    7.0    0.0    2.0    2.0    0.0    10.0   0.30434782608695654  112 / 368
4.0    32.0   0.0    248.0  0.0    1.0    0.0    5.0    1.0    11.0   0.0    2.0    5.0    5.0    20.0   20.0   0.0    30.0   11.0   0.0    1.0    0.0    0.0    7.0    0.0    0.0    0.38461538461538464  155 / 403
0.0    5.0    32.0   0.0    153.0  1.0    25.0   1.0    26.0   4.0    7.0    0.0    1.0    0.0    1.0    0.0    18.0   4.0    31.0   20.0   0.0    0.0    0.0    9.0    3.0    42.0   0.6005221932114883   230 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    58.0   19.0   2.0    0.0    0.0    0.0    0.0    0.0    0.0    48.0   242.0  0.0    0.0    0.0    0.3546666666666667   133 / 375
19.0   15.0   7.0    2.0    24.0   0.0    2.0    2.0    35.0   10.0   3.0    20.0   0.0    0.0    8.0    0.0    25.0   5.0    41.0   40.0   3.0    1.0    0.0    78.0   6.0    48.0   0.8020304568527918   316 / 394
0.0    1.0    0.0    4.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    11.0   10.0   0.0    5.0    132.0  2.0    120.0  6.0    0.0    81.0   0.0    0.7938931297709924   312 / 393
1.0    15.0   0.0    0.0    20.0   1.0    0.0    0.0    19.0   4.0    2.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    45.0   6.0    0.0    0.0    0.0    5.0    1.0    240.0  0.3460490463215259   127 / 367
453.0  553.0  441.0  368.0  329.0  384.0  314.0  158.0  435.0  358.0  197.0  345.0  717.0  220.0  389.0  467.0  391.0  469.0  351.0  521.0  457.0  517.0  383.0  200.0  161.0  425.0  0.4425672298310507   4,427 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.557433
2    0.713686
3    0.803359
4    0.848645
5    0.880536
6    0.903829
7    0.922023
8    0.93452
9    0.947316
10   0.956713

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.5190017862442985
RMSE: 0.7204177859022489
LogLoss: 1.5260182261682473
Mean Per-Class Error: 0.44567236510795555
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4     5     6     7     8      9     10    11    12     13    14    15     16     17     18    19     20     21     22     23    24    25    Error                Rate
-----  -----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -----  -----  ----  ----  ----  -------------------  -------------
79.0   1.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   1.0    0.0   0.0   0.0    0.0    1.0    1.0   0.0    0.0    1.0    3.0    0.0   1.0   0.0   0.11235955056179775  10 / 89
0.0    66.0   0.0    2.0    0.0   1.0   0.0   1.0   1.0    4.0   2.0   0.0   3.0    0.0   1.0   1.0    5.0    10.0   5.0   0.0    0.0    0.0    2.0    0.0   2.0   0.0   0.37735849056603776  40 / 106
0.0    0.0    55.0   0.0    3.0   1.0   4.0   0.0   0.0    0.0   7.0   0.0   0.0    0.0   1.0   0.0    2.0    0.0    0.0   1.0    1.0    0.0    1.0    1.0   0.0   5.0   0.32926829268292684  27 / 82
2.0    12.0   0.0    69.0   0.0   0.0   0.0   1.0   1.0    4.0   0.0   1.0   2.0    1.0   7.0   4.0    0.0    6.0    1.0   0.0    0.0    0.0    0.0    1.0   0.0   0.0   0.38392857142857145  43 / 112
0.0    0.0    14.0   0.0    36.0  1.0   7.0   0.0   6.0    0.0   1.0   0.0   1.0    0.0   1.0   0.0    4.0    1.0    8.0   6.0    0.0    0.0    0.0    2.0   0.0   9.0   0.6288659793814433   61 / 97
---    ---    ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---    ---    ---   ---   ---   ---                  ---
0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   13.0   3.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0    10.0   66.0   0.0   0.0   0.0   0.2826086956521739   26 / 92
3.0    4.0    1.0    1.0    9.0   0.0   1.0   1.0   7.0    1.0   3.0   3.0   0.0    0.0   0.0   0.0    4.0    3.0    11.0  12.0   1.0    0.0    0.0    20.0  2.0   13.0  0.8                  80 / 100
0.0    0.0    0.0    0.0    0.0   4.0   0.0   1.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0   4.0    4.0    0.0    0.0   30.0   1.0    37.0   3.0    0.0   21.0  0.0   0.8037383177570093   86 / 107
0.0    4.0    0.0    0.0    9.0   1.0   0.0   0.0   6.0    0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0    0.0    13.0  3.0    0.0    0.0    0.0    2.0   0.0   47.0  0.45977011494252873  40 / 87
106.0  137.0  103.0  106.0  86.0  83.0  76.0  43.0  103.0  91.0  53.0  88.0  178.0  51.0  84.0  129.0  101.0  115.0  92.0  127.0  111.0  126.0  110.0  51.0  44.0  96.0  0.4465863453815261   1,112 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.553414
2    0.722088
3    0.808032
4    0.85261
5    0.886747
6    0.904418
7    0.923695
8    0.935341
9    0.946988
10   0.956225
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 15:37:05  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 15:37:05  1 min 42.335 sec  161403 obs/sec    1         1             10007      0.775221         1.84038             0.98932        0.53174                          0.774739           1.82764               0.989305         0.519277
    2019-07-24 15:37:06  1 min 42.888 sec  167621 obs/sec    10        10            100070     0.722745         1.54163             0.990717       0.442567                         0.720418           1.52602               0.990752         0.446586
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0902701
C12         0.975294               0.975294             0.0880399
C9          0.94827                0.94827              0.0856004
C13         0.904609               0.904609             0.0816592
C11         0.865386               0.865386             0.0781185
C7          0.820449               0.820449             0.074062
C14         0.785638               0.785638             0.0709197
C8          0.667598               0.667598             0.0602642
C10         0.663689               0.663689             0.0599113
C16         0.597076               0.597076             0.0538982
C6          0.54151                0.54151              0.0488822
C3          0.523177               0.523177             0.0472272
C1          0.471692               0.471692             0.0425797
C5          0.466181               0.466181             0.0420822
C4          0.427102               0.427102             0.0385546
C2          0.420188               0.420188             0.0379305
[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ]
                 activation  ...                model_ids              logloss
0      RectifierWithDropout  ...  DL_random_grid_model_41   0.3707619238473035
1      RectifierWithDropout  ...  DL_random_grid_model_17  0.38064600984023134
2      RectifierWithDropout  ...  DL_random_grid_model_21  0.38252103262376946
3      RectifierWithDropout  ...   DL_random_grid_model_4   0.3973996485540035
4      RectifierWithDropout  ...  DL_random_grid_model_26   0.4196552081299318
5      RectifierWithDropout  ...  DL_random_grid_model_49  0.44105858483589444
6      RectifierWithDropout  ...   DL_random_grid_model_1   0.4441029563325956
7      RectifierWithDropout  ...  DL_random_grid_model_70   0.4501992138741178
8           TanhWithDropout  ...  DL_random_grid_model_13  0.45094235488782747
9      RectifierWithDropout  ...  DL_random_grid_model_27  0.45459146551001495
10     RectifierWithDropout  ...  DL_random_grid_model_33   0.4572076181793416
11     RectifierWithDropout  ...  DL_random_grid_model_29  0.45799163527356973
12          TanhWithDropout  ...  DL_random_grid_model_25   0.4666247039105046
13          TanhWithDropout  ...  DL_random_grid_model_24    0.480978253043427
14          TanhWithDropout  ...  DL_random_grid_model_51   0.4928387874791506
15          TanhWithDropout  ...  DL_random_grid_model_45   0.5036677617546912
16     RectifierWithDropout  ...  DL_random_grid_model_28   0.5266093473098682
17     RectifierWithDropout  ...  DL_random_grid_model_11   0.5334057637383038
18     RectifierWithDropout  ...  DL_random_grid_model_66   0.5556113794203216
19          TanhWithDropout  ...  DL_random_grid_model_16   0.5562871003000159
20          TanhWithDropout  ...  DL_random_grid_model_55   0.5572656652640022
21          TanhWithDropout  ...   DL_random_grid_model_7   0.5664591586331545
22          TanhWithDropout  ...  DL_random_grid_model_10   0.5672729142024786
23     RectifierWithDropout  ...  DL_random_grid_model_48   0.5797799024067584
24          TanhWithDropout  ...  DL_random_grid_model_38   0.5815513539675672
25     RectifierWithDropout  ...   DL_random_grid_model_9   0.5842550586397437
26     RectifierWithDropout  ...  DL_random_grid_model_32   0.5884470626154495
27          TanhWithDropout  ...  DL_random_grid_model_61   0.5898143363139626
28     RectifierWithDropout  ...  DL_random_grid_model_36   0.5919725885649424
29          TanhWithDropout  ...  DL_random_grid_model_56   0.6001968405285861
.. ..                   ...  ...                      ...                  ...
42          TanhWithDropout  ...  DL_random_grid_model_47   0.7465944322705939
43     RectifierWithDropout  ...   DL_random_grid_model_5   0.7472492952628547
44          TanhWithDropout  ...   DL_random_grid_model_8     0.74789558197885
45          TanhWithDropout  ...  DL_random_grid_model_68   0.7480992247197362
46     RectifierWithDropout  ...  DL_random_grid_model_63   0.7489925698541345
47          TanhWithDropout  ...  DL_random_grid_model_39    0.750929385199447
48          TanhWithDropout  ...  DL_random_grid_model_46   0.7513522275760283
49          TanhWithDropout  ...  DL_random_grid_model_53   0.7554425119746937
50          TanhWithDropout  ...  DL_random_grid_model_37   0.7556123378673069
51          TanhWithDropout  ...  DL_random_grid_model_18   0.7590875967507471
52          TanhWithDropout  ...  DL_random_grid_model_30   0.7790139336682691
53          TanhWithDropout  ...  DL_random_grid_model_57   0.7792026326051693
54     RectifierWithDropout  ...  DL_random_grid_model_54   0.8120551868646757
55     RectifierWithDropout  ...  DL_random_grid_model_40   0.8501948751753754
56     RectifierWithDropout  ...  DL_random_grid_model_64   0.8612282152253675
57     RectifierWithDropout  ...  DL_random_grid_model_43   0.8713452626240638
58          TanhWithDropout  ...  DL_random_grid_model_15    0.964781517655567
59          TanhWithDropout  ...  DL_random_grid_model_65   1.0007676933820941
60          TanhWithDropout  ...  DL_random_grid_model_35   1.0068492472353843
61          TanhWithDropout  ...  DL_random_grid_model_42    1.008449385805126
62          TanhWithDropout  ...  DL_random_grid_model_71   1.0294935195310018
63          TanhWithDropout  ...  DL_random_grid_model_72   1.0847337862899669
64          TanhWithDropout  ...   DL_random_grid_model_6   1.0887438163459613
65     RectifierWithDropout  ...  DL_random_grid_model_62   1.1057796154829427
66     RectifierWithDropout  ...  DL_random_grid_model_14    1.106453181737604
67     RectifierWithDropout  ...  DL_random_grid_model_23   1.1198420055867915
68          TanhWithDropout  ...  DL_random_grid_model_22     1.38090870156794
69          TanhWithDropout  ...  DL_random_grid_model_60    1.392410636153699
70          TanhWithDropout  ...  DL_random_grid_model_19   1.4775741572031555
71          TanhWithDropout  ...  DL_random_grid_model_59   1.5260182261682473

[72 rows x 7 columns]

--- 123.77943658828735 seconds ---
Evalutation of best performing model:
Final acc, selected model:  86.52056439507655
Time consumed:  0.03441564665900337  hours
H2O session _sid_a1ad closed.
