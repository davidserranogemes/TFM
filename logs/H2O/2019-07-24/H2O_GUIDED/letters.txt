Starting H2O
Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "10.0.2" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)
  Starting server from /home/davidserranogemes/anaconda3/envs/h2o-cpu/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmp00_f59w0
  JVM stdout: /tmp/tmp00_f59w0/h2o_davidserranogemes_started_from_python.out
  JVM stderr: /tmp/tmp00_f59w0/h2o_davidserranogemes_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ---------------------------------------------------
H2O cluster uptime:         01 secs
H2O cluster timezone:       Europe/Madrid
H2O data parsing timezone:  UTC
H2O cluster version:        3.26.0.1
H2O cluster version age:    8 days
H2O cluster name:           H2O_from_python_davidserranogemes_m2p6gs
H2O cluster total nodes:    1
H2O cluster free memory:    3.900 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         accepting new members, healthy
H2O connection url:         http://127.0.0.1:54321
H2O connection proxy:
H2O internal security:      False
H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4
Python version:             3.7.3 final
--------------------------  ---------------------------------------------------
Leyendo  letters
Parse progress: |█████████████████████████████████████████████████████████| 100%
Parse progress: |█████████████████████████████████████████████████████████| 100%
Executing  letters with  Guided  mode.

deeplearning Grid Build progress: |███████████████████████████████████████| 100%
deeplearning prediction progress: |███████████████████████████████████████| 100%
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_41

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.001918566697710844  0.00045508763287216425  0.0         -0.008103955735923485  0.17481869459152222  0.2760168918063407   0.12201187014579773
    3        26       Softmax                      0.0   0.0   0.009952036421631979  0.04950550198554993     0.0         -0.2115699953174831    0.3936671018600464   -0.4802827566292739  0.09224486351013184


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1092982575179432
RMSE: 0.33060286979689574
LogLoss: 0.36206761781461017
Mean Per-Class Error: 0.10521904818720827
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
371.0  0.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    2.0    4.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    0.0    3.0    1.0    1.0    2.0    1.0    0.060759493670886074  24 / 395
0.0    344.0  0.0    7.0    3.0    0.0    0.0    5.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    8.0    7.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.10182767624020887   39 / 383
0.0    0.0    344.0  0.0    5.0    0.0    3.0    1.0    0.0    0.0    4.0    2.0    0.0    0.0    5.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.06521739130434782   24 / 368
0.0    10.0   0.0    366.0  0.0    1.0    1.0    2.0    0.0    1.0    2.0    0.0    6.0    3.0    2.0    0.0    0.0    4.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.09181141439205956   37 / 403
0.0    0.0    2.0    0.0    337.0  5.0    18.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    1.0    1.0    2.0    2.0    2.0    0.0    0.0    0.0    3.0    0.0    5.0    0.12239583333333333   47 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    14.0   1.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    350.0  0.0    0.0    0.0    0.06914893617021277   26 / 376
0.0    1.0    0.0    6.0    2.0    1.0    0.0    2.0    2.0    4.0    4.0    5.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    355.0  1.0    2.0    0.09438775510204081   37 / 392
0.0    0.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    1.0    0.0    6.0    1.0    0.0    371.0  0.0    0.05597964376590331   22 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    19.0   1.0    0.0    0.0    0.0    0.0    0.0    324.0  0.11716621253405994   43 / 367
398.0  437.0  372.0  435.0  389.0  426.0  387.0  297.0  348.0  372.0  344.0  390.0  419.0  378.0  408.0  360.0  363.0  392.0  414.0  376.0  394.0  373.0  380.0  401.0  403.0  347.0  0.10476856942917125   1,048 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.895231
2    0.952514
3    0.970909
4    0.980506
5    0.987704
6    0.991003
7    0.994202
8    0.995501
9    0.996501
10   0.997501

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.10929812426124301
RMSE: 0.33060266826092466
LogLoss: 0.36791690260813303
Mean Per-Class Error: 0.10233104216592542
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17    18     19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.056179775280898875  5 / 89
0.0   91.0   0.0   2.0    2.0   0.0   0.0   2.0   1.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   3.0   2.0    0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.14150943396226415   15 / 106
0.0   0.0    74.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    0.0   0.0    3.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0975609756097561    8 / 82
0.0   1.0    0.0   102.0  0.0   1.0   0.0   1.0   0.0   0.0    1.0   0.0    2.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   2.0   0.0    0.0   0.08928571428571429   10 / 112
0.0   0.0    0.0   0.0    84.0  2.0   6.0   0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   1.0   0.0    2.0   0.13402061855670103   13 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   86.0  0.0   0.0    0.0   0.06521739130434782   6 / 92
0.0   0.0    0.0   3.0    1.0   1.0   0.0   1.0   0.0   1.0    2.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   88.0  0.0    0.0   0.12                  12 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    3.0   1.0   0.0   101.0  0.0   0.056074766355140186  6 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   4.0    0.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218   10 / 87
88.0  112.0  79.0  119.0  95.0  99.0  98.0  75.0  89.0  105.0  88.0  101.0  92.0  101.0  83.0  102.0  93.0  96.0  103.0  88.0  105.0  86.0  94.0  99.0  117.0  83.0  0.10281124497991968   256 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.897189
2    0.956225
3    0.96988
4    0.978313
5    0.983936
6    0.989157
7    0.993574
8    0.994779
9    0.995984
10   0.99759
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:15  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:16  1 min  5.165 sec  28509 obs/sec     1         1             10007      0.503626         0.857786            0.995492       0.236529                         0.504147           0.855981              0.995471         0.240964
    2019-07-24 14:07:19  1 min  7.955 sec  32332 obs/sec     10        10            100070     0.330603         0.362068            0.998057       0.104769                         0.330603           0.367917              0.998052         0.102811
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0808134
C13         0.968007               0.968007             0.0782279
C8          0.952509               0.952509             0.0769754
C9          0.91077                0.91077              0.0736024
C12         0.875238               0.875238             0.0707309
C7          0.807766               0.807766             0.0652783
C10         0.795856               0.795856             0.0643158
C5          0.78367                0.78367              0.063331
C11         0.749099               0.749099             0.0605372
C6          0.712351               0.712351             0.0575675
C14         0.703763               0.703763             0.0568735
C16         0.675842               0.675842             0.054617
C4          0.641667               0.641667             0.0518552
C3          0.638206               0.638206             0.0515755
C1          0.597842               0.597842             0.0483136
C2          0.561608               0.561608             0.0453854
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_4

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0018413970311712546  0.0005157245323061943  0.0         -0.0080190055736859   0.16933929920196533  0.2769401436435729   0.12236693501472473
    3        26       Softmax                      0.0   0.0   0.009351625838899754   0.041494205594062805   0.0         -0.21391719246710642  0.3908447027206421   -0.4805655093597259  0.09110113978385925


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11065384477483979
RMSE: 0.3326467266858939
LogLoss: 0.37281170496535465
Mean Per-Class Error: 0.10871501887223035
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
368.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    1.0    4.0    0.0    0.0    0.0    0.0    1.0    3.0    2.0    1.0    3.0    1.0    1.0    4.0    1.0    0.06835443037974684  27 / 395
0.0    336.0  0.0    11.0   4.0    1.0    1.0    6.0    2.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    1.0    7.0    7.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    320.0  0.0    12.0   0.0    5.0    1.0    0.0    0.0    10.0   2.0    0.0    0.0    4.0    0.0    0.0    1.0    1.0    4.0    7.0    0.0    1.0    0.0    0.0    0.0    0.13043478260869565  48 / 368
1.0    11.0   0.0    367.0  0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    7.0    3.0    0.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    3.0    0.0    2.0    0.08933002481389578  36 / 403
0.0    4.0    3.0    0.0    329.0  5.0    14.0   1.0    0.0    0.0    3.0    3.0    0.0    0.0    0.0    1.0    2.0    3.0    3.0    6.0    0.0    0.0    0.0    2.0    0.0    5.0    0.14322916666666666  55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    10.0   0.0    5.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    350.0  0.0    0.0    0.0    0.06666666666666667  25 / 375
0.0    1.0    0.0    4.0    2.0    0.0    0.0    2.0    2.0    3.0    7.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    359.0  2.0    6.0    0.08883248730964467  35 / 394
1.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    15.0   1.0    3.0    1.0    0.0    367.0  0.0    0.06615776081424936  26 / 393
3.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    8.0    2.0    0.0    0.0    0.0    1.0    0.0    337.0  0.08174386920980926  30 / 367
403.0  422.0  342.0  434.0  395.0  402.0  364.0  339.0  339.0  376.0  394.0  359.0  393.0  380.0  415.0  361.0  368.0  380.0  384.0  418.0  425.0  357.0  381.0  400.0  396.0  376.0  0.10816754973507947  1,082 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.891833
2    0.948515
3    0.969109
4    0.977707
5    0.984505
6    0.988803
7    0.992602
8    0.994302
9    0.995701
10   0.997101

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1124488923381191
RMSE: 0.33533400116617923
LogLoss: 0.38365641275353224
Mean Per-Class Error: 0.11225202232695651
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17    18    19    20     21    22    23    24     25    Error                 Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
85.0  0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    1.0   0.0   0.0   2.0    0.0   0.0449438202247191    4 / 89
0.0   84.0  0.0   4.0    2.0   1.0   1.0   1.0   1.0   0.0    2.0    0.0   0.0   0.0    1.0   0.0    1.0   4.0   2.0   0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.20754716981132076   22 / 106
0.0   0.0   69.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    2.0    1.0   0.0   0.0    3.0   0.0    0.0   0.0   0.0   3.0   1.0    0.0   0.0   0.0   0.0    0.0   0.15853658536585366   13 / 82
1.0   1.0   0.0   101.0  0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   3.0    1.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   2.0   0.0    2.0   0.09821428571428571   11 / 112
0.0   0.0   1.0   0.0    78.0  4.0   4.0   0.0   0.0   0.0    1.0    1.0   0.0   0.0    0.0   0.0    0.0   1.0   3.0   3.0   0.0    0.0   0.0   0.0   0.0    1.0   0.1958762886597938    19 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   88.0  0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0   0.0   2.0    2.0   0.0   0.0   1.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   88.0  0.0    3.0   0.12                  12 / 100
1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   4.0   0.0    1.0   1.0   0.0   100.0  0.0   0.06542056074766354   7 / 107
2.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0   1.0   0.0    80.0  0.08045977011494253   7 / 87
95.0  97.0  75.0  124.0  97.0  96.0  91.0  85.0  83.0  111.0  100.0  94.0  82.0  102.0  92.0  103.0  98.0  95.0  88.0  99.0  108.0  78.0  94.0  99.0  111.0  93.0  0.11244979919678715   280 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.88755
2    0.951004
3    0.964257
4    0.977108
5    0.983936
6    0.98755
7    0.991566
8    0.993173
9    0.995984
10   0.99759
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:21  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:21  10.716 sec  29871 obs/sec     1         1             10007      0.494552         0.835895            0.995653       0.225632                         0.496223           0.840263              0.995612         0.236145
    2019-07-24 14:06:24  13.425 sec  33468 obs/sec     10        10            100070     0.332647         0.372812            0.998034       0.108168                         0.335334           0.383656              0.997996         0.11245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0868742
C13         0.876332               0.876332             0.0761307
C8          0.844715               0.844715             0.073384
C9          0.838466               0.838466             0.0728411
C12         0.776405               0.776405             0.0674496
C7          0.768642               0.768642             0.0667752
C10         0.747702               0.747702             0.0649561
C5          0.737229               0.737229             0.0640462
C11         0.690118               0.690118             0.0599535
C6          0.674064               0.674064             0.0585588
C16         0.664778               0.664778             0.057752
C14         0.641836               0.641836             0.055759
C3          0.592559               0.592559             0.0514781
C4          0.569487               0.569487             0.0494738
C2          0.557135               0.557135             0.0484007
C1          0.531426               0.531426             0.0461672
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_17

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate            rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  -------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.00186521131448103  0.0005514295771718025  0.0         -0.007861624829573088  0.17159992456436157  0.2767104877840492    0.11091214418411255
    3        26       Softmax                      0.0   0.0   0.008917232926732    0.03798842430114746    0.0         -0.22007915849904172   0.3934152126312256   -0.47629028532795553  0.07632243633270264


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.11046617797403248
RMSE: 0.332364525745502
LogLoss: 0.3735231849702726
Mean Per-Class Error: 0.1071619280282438
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
376.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    2.0    1.0    0.0    3.0    3.0    0.04810126582278481   19 / 395
0.0    339.0  0.0    6.0    3.0    0.0    1.0    7.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    8.0    8.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.11488250652741515   44 / 383
0.0    0.0    331.0  0.0    7.0    0.0    11.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    7.0    0.0    0.0    1.0    0.0    2.0    5.0    0.0    1.0    0.0    0.0    0.0    0.10054347826086957   37 / 368
1.0    11.0   0.0    363.0  0.0    0.0    1.0    1.0    0.0    0.0    3.0    0.0    1.0    8.0    2.0    1.0    0.0    5.0    2.0    0.0    1.0    0.0    0.0    2.0    0.0    1.0    0.09925558312655088   40 / 403
0.0    0.0    1.0    0.0    348.0  2.0    12.0   1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    3.0    2.0    2.0    0.0    0.0    0.0    5.0    0.0    4.0    0.09375               36 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    4.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    4.0    0.0    358.0  0.0    0.0    0.0    0.047872340425531915  18 / 376
0.0    1.0    0.0    4.0    7.0    0.0    0.0    0.0    2.0    4.0    6.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    357.0  3.0    5.0    0.09390862944162437   37 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    2.0    2.0    2.0    2.0    1.0    1.0    378.0  0.0    0.03816793893129771   15 / 393
2.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    9.0    1.0    0.0    0.0    0.0    2.0    0.0    335.0  0.08719346049046321   32 / 367
399.0  425.0  349.0  427.0  432.0  361.0  380.0  302.0  343.0  366.0  368.0  355.0  368.0  408.0  426.0  401.0  371.0  396.0  382.0  389.0  407.0  345.0  400.0  411.0  421.0  371.0  0.10656802959112266   1,066 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.893432
2    0.948216
3    0.969009
4    0.977407
5    0.983905
6    0.988403
7    0.992002
8    0.994502
9    0.995601
10   0.996701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1125707533879842
RMSE: 0.3355156529701471
LogLoss: 0.3838742545538186
Mean Per-Class Error: 0.10763927003999342
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0   0.0    2.0    1.0   0.0449438202247191   4 / 89
0.0   86.0   0.0   1.0    2.0    0.0   1.0   3.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0    5.0    2.0   0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    73.0  0.0    2.0    0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    0.0   2.0   0.0    0.0   1.0   0.0    0.0    0.0   0.10975609756097561  9 / 82
1.0   1.0    0.0   101.0  0.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   3.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   0.0   1.0    0.0    1.0   0.09821428571428571  11 / 112
0.0   0.0    0.0   0.0    89.0   1.0   3.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0   0.0    0.0   0.0   1.0    0.0    1.0   0.08247422680412371  8 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   89.0  0.0    0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    4.0    0.0   0.0   0.0   0.0   1.0    3.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   88.0   0.0    2.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    1.0    0.0    0.0   0.0   0.0    1.0   1.0   0.0    102.0  0.0   0.04672897196261682  5 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0    80.0  0.08045977011494253  7 / 87
91.0  101.0  77.0  116.0  112.0  77.0  94.0  74.0  85.0  107.0  95.0  91.0  78.0  106.0  92.0  114.0  100.0  104.0  94.0  91.0  104.0  75.0  99.0  100.0  121.0  92.0  0.10682730923694779  266 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.893173
2    0.95261
3    0.968675
4    0.976305
5    0.981526
6    0.987149
7    0.991165
8    0.99237
9    0.993574
10   0.995582
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:42  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:42  31.445 sec  32073 obs/sec     1         1             10007      0.499011         0.844875            0.995575       0.23233                          0.501416           0.847731              0.99552          0.236145
    2019-07-24 14:06:45  34.146 sec  33933 obs/sec     10        10            100070     0.332365         0.373523            0.998037       0.106568                         0.335516           0.383874              0.997994         0.106827
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0848374
C13         0.903499               0.903499             0.0766506
C9          0.883461               0.883461             0.0749505
C8          0.881282               0.881282             0.0747657
C12         0.814313               0.814313             0.0690842
C10         0.778183               0.778183             0.066019
C7          0.756179               0.756179             0.0641523
C5          0.752091               0.752091             0.0638055
C6          0.715084               0.715084             0.0606659
C11         0.687884               0.687884             0.0583583
C14         0.647273               0.647273             0.054913
C16         0.645376               0.645376             0.054752
C4          0.617774               0.617774             0.0524103
C3          0.602083               0.602083             0.0510792
C1          0.568562               0.568562             0.0482353
C2          0.534207               0.534207             0.0453207
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_21

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  10.0       0.0   0.0   0.0019367874153033426  0.0004983339458703995  0.0         -0.006066465839802415  0.16867303848266602  0.2788375019636896    0.11923566460609436
    3        26       Softmax                      0.0   0.0   0.010383383012131512   0.042539775371551514   0.0         -0.21607996268668472   0.39401745796203613  -0.47005253958080717  0.0968245267868042


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1123469218799742
RMSE: 0.3351819235579004
LogLoss: 0.37548492466928024
Mean Per-Class Error: 0.10952006910431547
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
372.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    1.0    2.0    0.0    0.0    1.0    0.0    1.0    3.0    3.0    0.0    1.0    1.0    1.0    2.0    2.0    0.05822784810126582  23 / 395
0.0    341.0  0.0    7.0    2.0    0.0    1.0    9.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    6.0    2.0    6.0    0.0    0.0    0.0    1.0    1.0    1.0    1.0    0.10966057441253264  42 / 383
0.0    0.0    343.0  0.0    5.0    0.0    4.0    1.0    0.0    0.0    5.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    2.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.06793478260869565  25 / 368
1.0    6.0    0.0    371.0  0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    3.0    9.0    0.0    3.0    0.0    3.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0794044665012407   32 / 403
0.0    6.0    4.0    0.0    331.0  2.0    12.0   1.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    6.0    3.0    2.0    2.0    0.0    0.0    0.0    2.0    0.0    10.0   0.13802083333333334  53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    16.0   0.0    4.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    348.0  0.0    0.0    0.0    0.072                27 / 375
0.0    1.0    0.0    4.0    2.0    0.0    0.0    0.0    2.0    3.0    6.0    1.0    0.0    0.0    2.0    0.0    3.0    0.0    3.0    1.0    1.0    0.0    0.0    358.0  1.0    6.0    0.09137055837563451  36 / 394
0.0    0.0    0.0    1.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    4.0    2.0    0.0    2.0    11.0   1.0    9.0    1.0    0.0    354.0  0.0    0.09923664122137404  39 / 393
1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    11.0   1.0    0.0    0.0    0.0    1.0    0.0    339.0  0.07629427792915532  28 / 367
386.0  421.0  410.0  434.0  382.0  361.0  323.0  329.0  352.0  366.0  374.0  352.0  414.0  398.0  398.0  428.0  399.0  389.0  407.0  391.0  397.0  359.0  375.0  402.0  377.0  379.0  0.10906727981605518  1,091 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.890933
2    0.950315
3    0.970909
4    0.979606
5    0.984905
6    0.988903
7    0.992102
8    0.994102
9    0.995701
10   0.997201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.11424905040637742
RMSE: 0.3380074709327849
LogLoss: 0.38426092352816027
Mean Per-Class Error: 0.10921624345210423
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17    18    19    20     21    22    23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  ----  ----  -----  ----  --------------------  -----------
86.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   2.0    1.0   0.033707865168539325  3 / 89
0.0   89.0   0.0   1.0    2.0   0.0   1.0   2.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    2.0    2.0   1.0   0.0   0.0    0.0   1.0   1.0   1.0    1.0   0.16037735849056603   17 / 106
0.0   0.0    75.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0   1.0   2.0   0.0    0.0   0.0   0.0   0.0    0.0   0.08536585365853659   7 / 82
1.0   0.0    0.0   102.0  0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   3.0    0.0   2.0    0.0    0.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.08928571428571429   10 / 112
0.0   1.0    1.0   0.0    83.0  1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    1.0   1.0   0.0   0.0    0.0   0.0   1.0   0.0    3.0   0.14432989690721648   14 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---   ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0    0.0   89.0  0.0   0.0    0.0   0.03260869565217391   3 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   1.0   0.0   0.0    0.0   0.0   89.0  0.0    3.0   0.11                  11 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   2.0    1.0    0.0   0.0   3.0   0.0    4.0   1.0   0.0   94.0   0.0   0.12149532710280374   13 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   2.0   0.0   0.0    0.0   0.0   1.0   0.0    80.0  0.08045977011494253   7 / 87
90.0  101.0  91.0  120.0  94.0  82.0  85.0  84.0  88.0  104.0  95.0  91.0  87.0  104.0  84.0  121.0  103.0  97.0  99.0  94.0  100.0  79.0  98.0  99.0  107.0  93.0  0.10923694779116466   272 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.890763
2    0.950201
3    0.966667
4    0.978715
5    0.984337
6    0.988353
7    0.990763
8    0.992369
9    0.993976
10   0.995984
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:47  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:48  37.032 sec  26900 obs/sec     1         1             10007      0.509563         0.874294            0.995386       0.247626                         0.511065           0.883186              0.995346         0.25261
    2019-07-24 14:06:50  39.745 sec  32939 obs/sec     10        10            100070     0.335182         0.375485            0.998004       0.109067                         0.338007           0.384261              0.997964         0.109237
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0869525
C13         0.899432               0.899432             0.0782079
C8          0.854486               0.854486             0.0742997
C9          0.822863               0.822863             0.07155
C12         0.814078               0.814078             0.0707861
C7          0.744263               0.744263             0.0647156
C10         0.716573               0.716573             0.0623078
C5          0.705742               0.705742             0.061366
C11         0.704755               0.704755             0.0612802
C6          0.655981               0.655981             0.0570392
C14         0.651258               0.651258             0.0566285
C16         0.645677               0.645677             0.0561432
C4          0.642573               0.642573             0.0558733
C3          0.583883               0.583883             0.0507701
C1          0.539608               0.539608             0.0469203
C2          0.519359               0.519359             0.0451595
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_26

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.001851750535138308  0.00046413030941039324  0.0         -0.00968613425244591  0.16954416036605835  0.18116531914597606  0.12185081839561462
    3        26       Softmax                      0.0   0.0   0.0108469105251393    0.05018720030784607     0.0         -0.20099716985744792  0.3976268768310547   -0.6536228532236922  0.18569988012313843


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12913413164945264
RMSE: 0.35935237810462956
LogLoss: 0.4220961138550121
Mean Per-Class Error: 0.11620681309285429
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
368.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    6.0    0.0    1.0    0.0    0.0    1.0    4.0    1.0    1.0    1.0    2.0    0.0    3.0    1.0    0.06598984771573604  26 / 394
0.0    349.0  0.0    5.0    1.0    0.0    2.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    10.0   5.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.08877284595300261  34 / 383
0.0    0.0    330.0  0.0    6.0    0.0    6.0    1.0    0.0    0.0    11.0   2.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    4.0    0.0    0.0    0.0    0.10326086956521739  38 / 368
0.0    14.0   0.0    358.0  0.0    2.0    0.0    5.0    0.0    3.0    0.0    0.0    7.0    4.0    1.0    2.0    0.0    2.0    1.0    2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.11166253101736973  45 / 403
0.0    6.0    2.0    0.0    323.0  6.0    18.0   0.0    0.0    0.0    3.0    3.0    0.0    0.0    0.0    0.0    2.0    3.0    5.0    2.0    1.0    0.0    0.0    3.0    0.0    7.0    0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    19.0   0.0    3.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    1.0    0.0    5.0    5.0    0.0    0.0    1.0    2.0    4.0    9.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    3.0    2.0    0.0    0.0    353.0  2.0    3.0    0.10406091370558376  41 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    2.0    4.0    2.0    13.0   1.0    0.0    356.0  0.0    0.09414758269720101  37 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    13.0   2.0    0.0    0.0    0.0    0.0    0.0    327.0  0.10655737704918032  39 / 366
393.0  450.0  360.0  419.0  382.0  392.0  369.0  309.0  338.0  381.0  375.0  360.0  432.0  376.0  394.0  394.0  375.0  416.0  400.0  391.0  409.0  379.0  384.0  393.0  378.0  354.0  0.11566530040987703  1,157 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.884335
2    0.940418
3    0.962111
4    0.974708
5    0.981706
6    0.986504
7    0.990003
8    0.992802
9    0.994602
10   0.996201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13037028391559416
RMSE: 0.361068253818574
LogLoss: 0.43136570398013513
Mean Per-Class Error: 0.11190341985618771
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   90.0   0.0   1.0    1.0   0.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0    0.0    6.0    1.0   0.0   0.0    2.0   0.0   1.0   0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    72.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    1.0   1.0   0.0    0.0   2.0   0.0    0.0    0.0    0.0   2.0   0.0    0.0   1.0   0.0   0.0    0.0   0.12195121951219512  10 / 82
0.0   1.0    0.0   102.0  0.0   1.0   0.0   2.0   0.0   1.0    0.0   0.0   3.0    1.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.08928571428571429  10 / 112
0.0   0.0    0.0   0.0    79.0  2.0   5.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0    1.0    3.0   1.0   0.0    0.0   0.0   2.0   0.0    3.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0    0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   0.0   0.0   1.0    5.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   88.0  0.0    1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   2.0    2.0    0.0    0.0   0.0   0.0    4.0   1.0   0.0   96.0   0.0   0.102803738317757    11 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   0.0   0.0   0.0    79.0  0.09195402298850575  8 / 87
91.0  105.0  77.0  119.0  91.0  91.0  96.0  73.0  81.0  110.0  96.0  93.0  101.0  98.0  84.0  113.0  100.0  109.0  98.0  93.0  100.0  86.0  94.0  96.0  106.0  89.0  0.11204819277108434  279 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.887952
2    0.941767
3    0.961446
4    0.973494
5    0.980321
6    0.984337
7    0.987952
8    0.991968
9    0.994377
10   0.995582
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:56  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:56  45.542 sec  35996 obs/sec     1         1             10007      0.522115         0.90519             0.995154       0.242127                         0.524938           0.914087              0.99509          0.249398
    2019-07-24 14:06:59  47.830 sec  39710 obs/sec     10        10            100070     0.359352         0.422096            0.997705       0.115665                         0.361068           0.431366              0.997677         0.112048
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0884814
C13         0.875246               0.875246             0.077443
C9          0.830558               0.830558             0.073489
C7          0.827259               0.827259             0.073197
C8          0.794824               0.794824             0.0703272
C12         0.756069               0.756069             0.0668981
C5          0.722592               0.722592             0.063936
C11         0.710689               0.710689             0.0628828
C10         0.691326               0.691326             0.0611695
C6          0.670356               0.670356             0.059314
C14         0.65058                0.65058              0.0575643
C16         0.604544               0.604544             0.0534909
C3          0.578796               0.578796             0.0512127
C4          0.575862               0.575862             0.0509531
C2          0.51125                0.51125              0.0452361
C1          0.501857               0.501857             0.044405
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_13

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight              weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  -----------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  10.0       0.0   0.0   0.0025783260576019984  0.000762271462008357   0.0         -0.00039262346421153893  0.2471104860305786  0.01599587699081346  0.2763347625732422
    3        26       Softmax                 0.0   0.0   0.0035183415400821946  0.0019777053967118263  0.0         -0.004187579900668526    0.3537067174911499  -0.5919582349179344  0.10189169645309448


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.12722632010043086
RMSE: 0.3566879870425003
LogLoss: 0.42557560460663757
Mean Per-Class Error: 0.12414558418197494
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    4.0    1.0    2.0    0.0    1.0    0.0    1.0    3.0    2.0    0.0    2.0    0.0    1.0    1.0    3.0    4.0    0.07341772151898734   29 / 395
0.0    310.0  1.0    14.0   11.0   1.0    2.0    20.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    10.0   3.0    0.0    0.0    0.0    1.0    4.0    1.0    3.0    0.1906005221932115    73 / 383
0.0    0.0    333.0  1.0    5.0    1.0    6.0    1.0    0.0    0.0    9.0    0.0    0.0    0.0    3.0    0.0    1.0    1.0    1.0    2.0    3.0    0.0    1.0    0.0    0.0    0.0    0.09510869565217392   35 / 368
1.0    6.0    0.0    361.0  0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    2.0    6.0    3.0    0.0    0.0    5.0    0.0    0.0    4.0    0.0    0.0    4.0    0.0    3.0    0.10199004975124377   41 / 402
0.0    4.0    3.0    0.0    331.0  6.0    8.0    2.0    1.0    0.0    3.0    1.0    0.0    0.0    0.0    1.0    8.0    3.0    1.0    1.0    1.0    0.0    0.0    3.0    0.0    7.0    0.13802083333333334   53 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    359.0  0.0    0.0    0.0    0.042666666666666665  16 / 375
0.0    0.0    0.0    6.0    4.0    0.0    0.0    4.0    2.0    2.0    11.0   0.0    0.0    0.0    0.0    1.0    7.0    0.0    1.0    4.0    1.0    0.0    0.0    340.0  6.0    4.0    0.13486005089058525   53 / 393
0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    1.0    6.0    0.0    9.0    1.0    1.0    364.0  0.0    0.0737913486005089    29 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    6.0    2.0    0.0    0.0    0.0    0.0    0.0    338.0  0.07901907356948229   29 / 367
382.0  365.0  357.0  434.0  418.0  358.0  356.0  436.0  341.0  366.0  364.0  341.0  376.0  383.0  347.0  396.0  456.0  408.0  327.0  386.0  429.0  354.0  426.0  396.0  412.0  389.0  0.1235629311206638    1,236 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.876437
2    0.939018
3    0.961712
4    0.974308
5    0.981706
6    0.985205
7    0.988404
8    0.991103
9    0.992902
10   0.994602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.12927484589632607
RMSE: 0.359548113465119
LogLoss: 0.43293783322843415
Mean Per-Class Error: 0.12739203921978692
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4      5     6     7      8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25     Error                 Rate
----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  --------------------  -----------
84.0  0.0   0.0   0.0    0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   2.0    1.0    0.056179775280898875  5 / 89
0.0   81.0  1.0   5.0    3.0    0.0   2.0   7.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    3.0    1.0   0.0   0.0    0.0   1.0    1.0   1.0    0.0    0.2358490566037736    25 / 106
0.0   0.0   74.0  0.0    2.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    3.0   0.0    0.0    0.0    0.0   2.0   0.0    0.0   1.0    0.0   0.0    0.0    0.0975609756097561    8 / 82
1.0   1.0   0.0   99.0   0.0    0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0   3.0    1.0   0.0    0.0    0.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    2.0    0.11607142857142858   13 / 112
0.0   0.0   1.0   0.0    80.0   5.0   3.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0    1.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0    0.17525773195876287   17 / 97
---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                   ---
0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   89.0   0.0   0.0    0.0    0.03260869565217391   3 / 92
0.0   0.0   0.0   2.0    2.0    0.0   0.0   3.0    0.0   0.0    5.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.0   0.0    0.0   0.0    84.0  1.0    2.0    0.16                  16 / 100
0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    3.0    0.0    0.0   1.0   0.0    3.0   1.0    0.0   98.0   0.0    0.08411214953271028   9 / 107
1.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    82.0   0.05747126436781609   5 / 87
88.0  87.0  79.0  119.0  100.0  82.0  89.0  111.0  81.0  109.0  90.0  87.0  80.0  103.0  80.0  110.0  112.0  102.0  79.0  92.0  110.0  78.0  105.0  96.0  120.0  101.0  0.12690763052208837   316 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.873092
2    0.944177
3    0.964659
4    0.973092
5    0.980723
6    0.985542
7    0.98755
8    0.991165
9    0.993574
10   0.994779
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:34  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:35  23.998 sec  22237 obs/sec     1         1             10007      0.524593         0.921811            0.995108       0.264121                         0.524808           0.92795               0.995092         0.271486
    2019-07-24 14:06:38  27.520 sec  25599 obs/sec     10        10            100070     0.356688         0.425576            0.997738       0.123563                         0.359548           0.432938              0.997697         0.126908
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.088209
C13         0.996552               0.996552             0.0879049
C9          0.897672               0.897672             0.0791828
C12         0.888597               0.888597             0.0783823
C8          0.831836               0.831836             0.0733754
C10         0.748894               0.748894             0.0660592
C7          0.728685               0.728685             0.0642766
C11         0.694081               0.694081             0.0612242
C16         0.671901               0.671901             0.0592677
C5          0.667678               0.667678             0.0588952
C6          0.631317               0.631317             0.0556878
C14         0.611459               0.611459             0.0539362
C3          0.533337               0.533337             0.0470451
C4          0.523782               0.523782             0.0462023
C1          0.465066               0.465066             0.041023
C2          0.445855               0.445855             0.0393284
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_1

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0018236852727682162  0.00044177635572850704  0.0         -0.010619523866544966  0.1687414050102234  0.1700314690893858   0.12421584129333496
    3        26       Softmax                      0.0   0.0   0.010372399491582375   0.04447615146636963     0.0         -0.19632909696782427   0.3981531858444214  -0.6487902465476979  0.17069858312606812


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13068396233618026
RMSE: 0.36150236836870137
LogLoss: 0.4269442926930082
Mean Per-Class Error: 0.12084914664464369
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    3.0    3.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    4.0    2.0    0.0    0.0    6.0    0.0    0.07088607594936709  28 / 395
0.0    359.0  0.0    2.0    1.0    0.0    1.0    2.0    2.0    0.0    1.0    1.0    0.0    0.0    0.0    3.0    1.0    3.0    4.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.06266318537859007  24 / 383
0.0    0.0    318.0  0.0    14.0   0.0    3.0    1.0    0.0    0.0    7.0    4.0    0.0    0.0    4.0    0.0    0.0    0.0    2.0    4.0    10.0   0.0    1.0    0.0    0.0    0.0    0.1358695652173913   50 / 368
1.0    14.0   0.0    354.0  0.0    0.0    1.0    1.0    0.0    2.0    2.0    0.0    5.0    5.0    0.0    1.0    0.0    6.0    2.0    1.0    1.0    0.0    0.0    4.0    0.0    2.0    0.11940298507462686  48 / 402
0.0    5.0    3.0    0.0    321.0  3.0    17.0   0.0    0.0    0.0    5.0    6.0    0.0    0.0    0.0    1.0    3.0    2.0    1.0    1.0    0.0    0.0    0.0    4.0    0.0    12.0   0.1640625            63 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    14.0   0.0    3.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    345.0  0.0    0.0    0.0    0.08244680851063829  31 / 376
0.0    0.0    0.0    4.0    5.0    0.0    0.0    0.0    2.0    4.0    3.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    0.0    365.0  2.0    2.0    0.07360406091370558  29 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    11.0   1.0    16.0   1.0    0.0    351.0  0.0    0.10459183673469388  41 / 392
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    8.0    1.0    0.0    0.0    0.0    1.0    0.0    331.0  0.09809264305177112  36 / 367
390.0  480.0  342.0  408.0  386.0  410.0  368.0  285.0  353.0  369.0  365.0  394.0  416.0  385.0  391.0  370.0  354.0  400.0  376.0  386.0  421.0  388.0  383.0  422.0  391.0  370.0  0.12026392082375287  1,203 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.879736
2    0.940218
3    0.963511
4    0.974108
5    0.981406
6    0.986904
7    0.989603
8    0.992802
9    0.994702
10   0.995901

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1325436971159868
RMSE: 0.3640655121210835
LogLoss: 0.4380809162085678
Mean Per-Class Error: 0.12065350673234634
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   0.0   0.0    3.0    0.0   0.06741573033707865  6 / 89
0.0   95.0   0.0   0.0    1.0   0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   2.0    1.0   0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.10377358490566038  11 / 106
0.0   0.0    68.0  0.0    3.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    3.0   0.0    0.0   0.0    0.0   3.0   1.0    0.0   1.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
1.0   2.0    0.0   101.0  0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   1.0   2.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.09821428571428571  11 / 112
0.0   1.0    1.0   0.0    79.0  2.0   6.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   1.0    0.0    4.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   3.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   92.0   1.0    0.0   0.08                 8 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   3.0   0.0    7.0   1.0   0.0    92.0   0.0   0.14018691588785046  15 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0    80.0  0.08045977011494253  7 / 87
92.0  120.0  73.0  114.0  93.0  99.0  94.0  69.0  88.0  106.0  93.0  98.0  92.0  102.0  85.0  106.0  90.0  100.0  95.0  89.0  105.0  88.0  95.0  103.0  110.0  91.0  0.12088353413654618  301 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.879116
2    0.940562
3    0.963454
4    0.973494
5    0.978715
6    0.984739
7    0.989157
8    0.991968
9    0.994378
10   0.995181
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:11  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:12  1.619 sec   23713 obs/sec     1         1             10007      0.521492         0.901824            0.995167       0.246726                         0.522766           0.910888              0.99513          0.247791
    2019-07-24 14:06:15  4.030 sec   36362 obs/sec     10        10            100070     0.361502         0.426944            0.997677       0.120264                         0.364066           0.438081              0.997638         0.120884
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.085741
C13         0.940991               0.940991             0.0806815
C9          0.838433               0.838433             0.0718881
C8          0.832535               0.832535             0.0713824
C12         0.820113               0.820113             0.0703173
C7          0.816902               0.816902             0.070042
C5          0.751721               0.751721             0.0644533
C11         0.747025               0.747025             0.0640507
C10         0.710275               0.710275             0.0608997
C6          0.674988               0.674988             0.0578742
C14         0.644525               0.644525             0.0552622
C16         0.63396                0.63396              0.0543564
C4          0.616667               0.616667             0.0528737
C3          0.611039               0.611039             0.0523911
C2          0.52203                0.52203              0.0447594
C1          0.501827               0.501827             0.0430271
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_49

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        256      RectifierDropout  25.0       0.0   0.0   0.0017847781702897692  0.00046383868902921677  0.0         -0.009091558761653573  0.1672736406326294   0.18260062589517426  0.1159367561340332
    3        26       Softmax                      0.0   0.0   0.009841635919734961   0.04141342639923096     0.0         -0.19528869722189407   0.39900338649749756  -0.643924766722556   0.1938544511795044


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13115469370779403
RMSE: 0.3621528595880392
LogLoss: 0.4290888522735133
Mean Per-Class Error: 0.12356380994817694
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
365.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    2.0    3.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    3.0    1.0    2.0    2.0    6.0    1.0    0.0759493670886076    30 / 395
0.0    358.0  0.0    6.0    1.0    0.0    2.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    4.0    0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.06527415143603134   25 / 383
0.0    0.0    303.0  0.0    19.0   0.0    6.0    0.0    0.0    0.0    12.0   7.0    0.0    0.0    4.0    0.0    1.0    0.0    5.0    4.0    3.0    0.0    4.0    0.0    0.0    0.0    0.1766304347826087    65 / 368
0.0    24.0   0.0    349.0  0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    4.0    6.0    0.0    0.0    0.0    6.0    2.0    1.0    1.0    0.0    0.0    3.0    0.0    2.0    0.13399503722084366   54 / 403
0.0    2.0    0.0    0.0    329.0  4.0    19.0   0.0    0.0    0.0    2.0    7.0    0.0    0.0    0.0    0.0    2.0    3.0    1.0    5.0    0.0    0.0    0.0    1.0    0.0    9.0    0.14322916666666666   55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    3.0    0.0    358.0  0.0    0.0    0.0    0.047872340425531915  18 / 376
0.0    2.0    0.0    4.0    4.0    1.0    0.0    2.0    2.0    1.0    4.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    2.0    1.0    0.0    0.0    360.0  3.0    4.0    0.08629441624365482   34 / 394
0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    2.0    9.0    2.0    4.0    1.0    0.0    370.0  0.0    0.058524173027989825  23 / 393
1.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    7.0    2.0    0.0    0.0    0.0    0.0    0.0    333.0  0.09264305177111716   34 / 367
386.0  502.0  321.0  414.0  408.0  375.0  387.0  284.0  347.0  377.0  364.0  398.0  379.0  390.0  383.0  376.0  365.0  398.0  348.0  402.0  411.0  367.0  420.0  407.0  416.0  378.0  0.1228631410576827    1,229 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877137
2    0.938119
3    0.963211
4    0.974508
5    0.981905
6    0.986504
7    0.990403
8    0.993002
9    0.994602
10   0.995201

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13443618464176563
RMSE: 0.36665540312637646
LogLoss: 0.44244872248688294
Mean Per-Class Error: 0.1230628153993521
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11     12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.06741573033707865  6 / 89
0.0   90.0   0.0   2.0    1.0   0.0   2.0    1.0   1.0   0.0    1.0   0.0    0.0   0.0    0.0   1.0    0.0   2.0    1.0   0.0   0.0    2.0   0.0    1.0   1.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    65.0  0.0    5.0   0.0   1.0    0.0   0.0   0.0    3.0   1.0    0.0   0.0    2.0   0.0    0.0   0.0    2.0   2.0   0.0    0.0   1.0    0.0   0.0    0.0   0.2073170731707317   17 / 82
0.0   4.0    0.0   99.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0   0.0    0.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    2.0   0.0    1.0   0.11607142857142858  13 / 112
0.0   0.0    0.0   0.0    81.0  2.0   5.0    0.0   0.0   0.0    1.0   1.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   3.0   0.0    0.0   0.0    0.0   0.0    2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   89.0   0.0   0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   2.0    1.0   1.0   0.0    1.0   0.0   0.0    2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    91.0  0.0    1.0   0.09                 9 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    1.0   0.0    0.0   2.0   0.0    2.0   1.0    0.0   100.0  0.0   0.06542056074766354  7 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0    0.0   0.0   2.0    0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    79.0  0.09195402298850575  8 / 87
89.0  122.0  67.0  116.0  98.0  88.0  100.0  69.0  87.0  107.0  94.0  101.0  82.0  104.0  80.0  109.0  96.0  102.0  86.0  95.0  103.0  81.0  103.0  99.0  119.0  93.0  0.12208835341365462  304 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.877912
2    0.939357
3    0.961847
4    0.972691
5    0.979116
6    0.985542
7    0.990763
8    0.993173
9    0.994378
10   0.994378
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:29  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:30  1 min 19.052 sec  30790 obs/sec     1         1             10007      0.519844         0.904096            0.995198       0.251025                         0.520388           0.904146              0.995175         0.257028
    2019-07-24 14:07:32  1 min 21.325 sec  39258 obs/sec     10        10            100070     0.362153         0.429089            0.997669       0.122863                         0.366655           0.442449              0.997605         0.122088
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0863805
C13         0.920124               0.920124             0.0794808
C8          0.850876               0.850876             0.0734991
C9          0.823866               0.823866             0.071166
C12         0.821648               0.821648             0.0709744
C7          0.772491               0.772491             0.0667282
C5          0.75551                0.75551              0.0652614
C10         0.747184               0.747184             0.0645421
C11         0.710113               0.710113             0.0613399
C14         0.682572               0.682572             0.0589609
C6          0.661527               0.661527             0.057143
C3          0.62689                0.62689              0.0541511
C16         0.600994               0.600994             0.0519142
C4          0.599065               0.599065             0.0517476
C1          0.513219               0.513219             0.0443321
C2          0.490606               0.490606             0.0423788
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_70

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013506404047234355  0.0003642025403678417  0.0         -0.009917459315128219  0.2025546431541443  0.24280737132994978  0.1591266393661499
    3        26       Softmax                      0.0   0.0   0.008519736389066916   0.037823885679244995   0.0         -0.2549018371803501    0.5187830924987793  -0.495897844910857   0.13738536834716797


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13414074234195777
RMSE: 0.36625229329242126
LogLoss: 0.4447292749561431
Mean Per-Class Error: 0.12874809209526517
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
364.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    5.0    0.0    3.0    0.0    0.0    2.0    2.0    3.0    3.0    1.0    2.0    0.0    4.0    2.0    0.07614213197969544  30 / 394
0.0    343.0  0.0    3.0    2.0    0.0    1.0    6.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    10.0   2.0    0.0    0.0    5.0    0.0    3.0    1.0    1.0    0.10443864229765012  40 / 383
0.0    0.0    306.0  0.0    14.0   0.0    10.0   0.0    0.0    0.0    14.0   2.0    0.0    0.0    4.0    0.0    0.0    1.0    2.0    6.0    6.0    0.0    2.0    0.0    0.0    0.0    0.16621253405994552  61 / 367
0.0    17.0   0.0    348.0  0.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    5.0    5.0    3.0    1.0    0.0    8.0    4.0    0.0    1.0    0.0    0.0    5.0    0.0    2.0    0.13647642679900746  55 / 403
0.0    1.0    1.0    0.0    329.0  5.0    18.0   2.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    1.0    2.0    2.0    1.0    4.0    0.0    0.0    0.0    1.0    0.0    12.0   0.14322916666666666  55 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    8.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    351.0  0.0    0.0    0.0    0.064                24 / 375
0.0    0.0    0.0    4.0    3.0    0.0    0.0    1.0    2.0    4.0    10.0   3.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    0.0    354.0  2.0    5.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    3.0    7.0    0.0    2.0    8.0    1.0    6.0    1.0    0.0    358.0  1.0    0.08673469387755102  34 / 392
1.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    7.0    4.0    0.0    0.0    0.0    1.0    0.0    334.0  0.08991825613079019  33 / 367
382.0  442.0  329.0  401.0  410.0  364.0  388.0  329.0  351.0  370.0  393.0  367.0  400.0  388.0  411.0  393.0  380.0  411.0  326.0  389.0  410.0  368.0  390.0  398.0  405.0  408.0  0.12816155153453965  1,282 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.871838
2    0.935419
3    0.959612
4    0.971509
5    0.979006
6    0.984405
7    0.988304
8    0.990503
9    0.992602
10   0.994802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1375792831617893
RMSE: 0.37091681434223134
LogLoss: 0.45190218097940776
Mean Per-Class Error: 0.13016889747028493
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22     23    24     25     Error                 Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   1.0    0.0   1.0    0.0   2.0    0.0    0.07865168539325842   7 / 89
0.0   89.0   0.0   0.0    1.0   0.0   1.0    2.0   1.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    1.0   5.0    0.0   0.0   0.0    4.0   0.0    1.0   0.0    0.0    0.16037735849056603   17 / 106
0.0   0.0    66.0  0.0    2.0   0.0   3.0    0.0   0.0   0.0    3.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0    1.0   3.0   1.0    0.0   1.0    0.0   0.0    0.0    0.1951219512195122    16 / 82
0.0   2.0    0.0   99.0   0.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0   1.0   2.0   1.0   0.0    0.0   0.0    2.0   0.0   1.0    0.0   0.0    2.0   0.0    1.0    0.11607142857142858   13 / 112
0.0   0.0    0.0   0.0    78.0  3.0   6.0    0.0   0.0   0.0    1.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   2.0   0.0    0.0   0.0    0.0   0.0    5.0    0.1958762886597938    19 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0    0.0   90.0   0.0   0.0    0.0    0.021739130434782608  2 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0    0.0   0.0   1.0    6.0    3.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    85.0  0.0    2.0    0.15                  15 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   3.0    2.0   0.0    0.0   2.0   0.0    2.0   1.0    0.0   96.0   0.0    0.102803738317757     11 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   1.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0    0.0   0.0    81.0   0.06896551724137931   6 / 87
86.0  110.0  69.0  112.0  92.0  87.0  101.0  80.0  85.0  107.0  103.0  97.0  89.0  98.0  90.0  110.0  98.0  102.0  75.0  91.0  105.0  82.0  101.0  96.0  114.0  110.0  0.13012048192771083   324 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86988
2    0.933333
3    0.959036
4    0.971084
5    0.97751
6    0.986747
7    0.98996
8    0.990361
9    0.99237
10   0.994378
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:58  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:58  1 min 47.422 sec  59565 obs/sec     1         1             10007      0.537698         0.950953            0.994859       0.259522                         0.537933           0.947066              0.994844         0.260643
    2019-07-24 14:07:59  1 min 48.743 sec  68541 obs/sec     10        10            100070     0.366252         0.444729            0.997615       0.128162                         0.370917           0.451902              0.997549         0.13012
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0841621
C13         0.935013               0.935013             0.0786926
C8          0.890766               0.890766             0.0749687
C9          0.867066               0.867066             0.0729741
C7          0.833505               0.833505             0.0701495
C12         0.799394               0.799394             0.0672786
C10         0.792393               0.792393             0.0666894
C11         0.757824               0.757824             0.06378
C5          0.719431               0.719431             0.0605488
C6          0.665148               0.665148             0.0559802
C14         0.663956               0.663956             0.0558799
C3          0.625045               0.625045             0.052605
C4          0.618368               0.618368             0.0520431
C1          0.602672               0.602672             0.0507221
C16         0.599791               0.599791             0.0504796
C2          0.511469               0.511469             0.0430463
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_27

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0014033002294695507  0.0003651805454865098  0.0         -0.00831710155967258  0.2039540410041809  0.23750827076287254   0.13971394300460815
    3        26       Softmax                      0.0   0.0   0.008030223617582193   0.03090183436870575    0.0         -0.25973281329097975  0.5098414421081543  -0.49091682207700593  0.18555498123168945


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13713053931332897
RMSE: 0.37031140856491174
LogLoss: 0.4509278741627477
Mean Per-Class Error: 0.13283041097795328
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    4.0    2.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    1.0    2.0    2.0    0.0    5.0    0.0    0.07341772151898734  29 / 395
1.0    340.0  0.0    5.0    3.0    0.0    1.0    4.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    1.0    9.0    8.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    326.0  1.0    9.0    0.0    2.0    2.0    0.0    0.0    9.0    5.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    2.0    5.0    0.0    4.0    0.0    0.0    0.0    0.11171662125340599  41 / 367
1.0    20.0   0.0    352.0  0.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    5.0    5.0    1.0    2.0    0.0    2.0    1.0    0.0    3.0    0.0    0.0    3.0    0.0    1.0    0.12655086848635236  51 / 403
0.0    0.0    0.0    0.0    317.0  3.0    9.0    0.0    0.0    0.0    8.0    7.0    0.0    0.0    0.0    1.0    9.0    3.0    9.0    3.0    0.0    0.0    0.0    3.0    0.0    12.0   0.17447916666666666  67 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    357.0  0.0    0.0    0.0    0.05053191489361702  19 / 376
0.0    1.0    0.0    3.0    3.0    0.0    0.0    1.0    4.0    4.0    12.0   6.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    1.0    0.0    0.0    351.0  1.0    2.0    0.10913705583756345  43 / 394
0.0    0.0    0.0    1.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    13.0   1.0    17.0   1.0    0.0    348.0  0.0    0.11450381679389313  45 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    13.0   1.0    0.0    0.0    0.0    2.0    1.0    324.0  0.11475409836065574  42 / 366
404.0  459.0  359.0  406.0  387.0  405.0  328.0  330.0  363.0  381.0  377.0  393.0  396.0  377.0  397.0  358.0  354.0  404.0  389.0  368.0  424.0  374.0  438.0  398.0  380.0  354.0  0.13256023193042088  1,326 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86744
2    0.936819
3    0.958712
4    0.971608
5    0.979506
6    0.984505
7    0.989603
8    0.992402
9    0.993902
10   0.995701

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1390078499950653
RMSE: 0.37283756516084227
LogLoss: 0.45858436469774183
Mean Per-Class Error: 0.13274913853688244
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11     12    13     14    15     16    17     18     19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
85.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   1.0    0.0   2.0    0.0   0.0449438202247191   4 / 89
0.0   88.0   0.0   2.0    2.0   0.0   1.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0    0.0   5.0    2.0    0.0   0.0    1.0   0.0    1.0   1.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    71.0  0.0    1.0   0.0   0.0   1.0   0.0   0.0    2.0   1.0    0.0   0.0    1.0   0.0    0.0   0.0    1.0    2.0   1.0    0.0   1.0    0.0   0.0    0.0   0.13414634146341464  11 / 82
1.0   3.0    0.0   97.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0    2.0   1.0    0.0   2.0    0.0   0.0    0.0    0.0   2.0    0.0   0.0    1.0   0.0    1.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    79.0  2.0   2.0   0.0   0.0   0.0    2.0   2.0    0.0   0.0    0.0   0.0    3.0   1.0    3.0    0.0   0.0    0.0   0.0    1.0   0.0    2.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   2.0    0.0   87.0   0.0   0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    4.0   3.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0    85.0  0.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0    4.0   0.0    7.0   1.0    0.0   92.0   0.0   0.14018691588785046  15 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0    1.0   1.0    78.0  0.10344827586206896  9 / 87
97.0  114.0  77.0  108.0  94.0  95.0  89.0  85.0  86.0  108.0  93.0  101.0  84.0  103.0  87.0  100.0  92.0  101.0  100.0  86.0  107.0  84.0  108.0  97.0  108.0  86.0  0.13373493975903614  333 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.866265
2    0.939357
3    0.958634
4    0.969478
5    0.97751
6    0.981928
7    0.986345
8    0.991968
9    0.993976
10   0.995984
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:59  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:59  48.037 sec  60283 obs/sec     1         1             10007      0.532157         0.921913            0.994966       0.244527                         0.532588           0.922707              0.994946         0.245783
    2019-07-24 14:07:00  49.480 sec  63738 obs/sec     10        10            100070     0.370311         0.450928            0.997563       0.13256                          0.372838           0.458584              0.997523         0.133735
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0803039
C8          0.971043               0.971043             0.0779786
C15         0.958857               0.958857             0.077
C9          0.930905               0.930905             0.0747554
C12         0.923732               0.923732             0.0741793
C7          0.831246               0.831246             0.0667523
C11         0.812077               0.812077             0.065213
C5          0.805088               0.805088             0.0646517
C10         0.76812                0.76812              0.061683
C6          0.710573               0.710573             0.0570618
C14         0.670394               0.670394             0.0538353
C4          0.668013               0.668013             0.0536441
C16         0.654115               0.654115             0.052528
C1          0.612145               0.612145             0.0491577
C3          0.595724               0.595724             0.047839
C2          0.540659               0.540659             0.0434171
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_33

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0012749529560096562  0.00035297556314617395  0.0         -0.003723402453853275  0.20103412866592407  0.26188661404293817  0.14966344833374023
    3        26       Softmax                      0.0   0.0   0.0074421230017728355  0.03779295086860657     0.0         -0.24580019338179027   0.5154263973236084   -0.4743255347705612  0.13538354635238647


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13521117570253444
RMSE: 0.3677107228549834
LogLoss: 0.44898907220646117
Mean Per-Class Error: 0.12769122951952927
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    3.0    3.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    2.0    1.0    3.0    2.0    4.0    0.0    0.07088607594936709  28 / 395
0.0    344.0  0.0    6.0    2.0    0.0    2.0    2.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    3.0    0.0    6.0    10.0   0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.09947643979057591  38 / 382
0.0    0.0    315.0  0.0    17.0   0.0    7.0    0.0    0.0    0.0    5.0    2.0    0.0    0.0    5.0    0.0    0.0    1.0    5.0    1.0    5.0    0.0    3.0    1.0    0.0    0.0    0.14168937329700274  52 / 367
1.0    15.0   0.0    356.0  0.0    2.0    1.0    2.0    0.0    4.0    2.0    0.0    4.0    4.0    2.0    1.0    0.0    4.0    0.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    0.11662531017369727  47 / 403
0.0    5.0    2.0    0.0    322.0  3.0    20.0   1.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    2.0    3.0    4.0    4.0    0.0    0.0    0.0    4.0    0.0    10.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    2.0    0.0    0.0    2.0    0.0    1.0    4.0    1.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    1.0    0.0    4.0    5.0    0.0    0.0    1.0    2.0    3.0    7.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    1.0    4.0    1.0    0.0    0.0    356.0  3.0    4.0    0.09644670050761421  38 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    3.0    0.0    8.0    1.0    0.0    370.0  0.0    0.05612244897959184  22 / 392
0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    11.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    8.0    7.0    0.0    0.0    0.0    0.0    0.0    331.0  0.09809264305177112  36 / 367
401.0  458.0  351.0  428.0  392.0  378.0  388.0  300.0  341.0  378.0  350.0  365.0  402.0  374.0  431.0  384.0  337.0  386.0  383.0  379.0  416.0  368.0  397.0  410.0  431.0  375.0  0.12716185144456663  1,272 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.872838
2    0.937319
3    0.960012
4    0.971309
5    0.979906
6    0.985205
7    0.988503
8    0.991703
9    0.994402
10   0.996301

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13885424404104182
RMSE: 0.37263151241010445
LogLoss: 0.46036548904583335
Mean Per-Class Error: 0.1277306178761848
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9      10    11    12    13    14    15     16    17    18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0    0.0   1.0   0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   90.0   0.0   1.0    1.0   0.0   1.0    1.0   1.0   0.0    1.0   0.0   0.0   0.0   1.0   1.0    0.0   3.0   3.0   0.0   0.0    1.0   0.0   1.0    0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    69.0  0.0    4.0   0.0   1.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0   3.0   1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.15853658536585366  13 / 82
1.0   2.0    0.0   98.0   0.0   1.0   0.0    1.0   0.0   2.0    1.0   0.0   1.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0   0.0   2.0    0.0    0.0   0.125                14 / 112
0.0   0.0    0.0   0.0    79.0  2.0   7.0    0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0   2.0   0.0    0.0   0.0   2.0    0.0    2.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   1.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0    0.0   0.0   0.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   90.0   1.0    1.0   0.1                  10 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0    2.0   1.0   0.0    102.0  0.0   0.04672897196261682  5 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0    0.0   0.0   4.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   3.0   0.0    0.0   0.0   0.0    0.0    77.0  0.11494252873563218  10 / 87
91.0  115.0  76.0  122.0  93.0  93.0  100.0  74.0  82.0  109.0  90.0  93.0  90.0  99.0  90.0  108.0  89.0  97.0  96.0  89.0  102.0  78.0  98.0  105.0  122.0  89.0  0.12771084337349398  318 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.872289
2    0.936546
3    0.957831
4    0.971888
5    0.978715
6    0.983534
7    0.986747
8    0.990361
9    0.993173
10   0.995582
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:06  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:07  55.881 sec  56857 obs/sec     1         1             10007      0.537334         0.922609            0.994867       0.258422                         0.537742           0.929617              0.994847         0.261044
    2019-07-24 14:07:08  57.325 sec  62779 obs/sec     10        10            100070     0.367711         0.448989            0.997596       0.127162                         0.372632           0.460365              0.997526         0.127711
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0866566
C15         0.951304               0.951304             0.0824369
C12         0.83669                0.83669              0.0725047
C8          0.836028               0.836028             0.0724474
C9          0.835609               0.835609             0.0724111
C7          0.749183               0.749183             0.0649217
C10         0.729289               0.729289             0.0631978
C11         0.715152               0.715152             0.0619727
C5          0.712531               0.712531             0.0617456
C14         0.651359               0.651359             0.0564445
C6          0.646363               0.646363             0.0560116
C16         0.636388               0.636388             0.0551472
C4          0.613624               0.613624             0.0531746
C3          0.602427               0.602427             0.0522043
C1          0.536097               0.536097             0.0464564
C2          0.487752               0.487752             0.0422669
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_29

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013138374789036789  0.00037287059240043163  0.0         -0.010891372521356857  0.20414316654205322  0.2494804749922887    0.14941006898880005
    3        26       Softmax                      0.0   0.0   0.009155681877823204   0.048589155077934265    0.0         -0.2432290570193848    0.5151629447937012   -0.49123818233452854  0.1462762951850891


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13539780342014607
RMSE: 0.3679644050993874
LogLoss: 0.4490970283180805
Mean Per-Class Error: 0.13049401313071599
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    2.0    5.0    1.0    0.0    0.0    0.0    3.0    3.0    0.0    1.0    2.0    1.0    1.0    4.0    2.0    0.08354430379746836  33 / 395
0.0    327.0  0.0    5.0    1.0    6.0    2.0    3.0    2.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    2.0    11.0   10.0   0.0    0.0    2.0    0.0    4.0    2.0    0.0    0.1462140992167102   56 / 383
0.0    0.0    317.0  0.0    8.0    1.0    5.0    1.0    0.0    0.0    10.0   2.0    0.0    0.0    4.0    0.0    1.0    1.0    5.0    2.0    7.0    0.0    4.0    0.0    0.0    0.0    0.13858695652173914  51 / 368
0.0    10.0   0.0    363.0  0.0    0.0    0.0    3.0    0.0    0.0    2.0    0.0    3.0    5.0    1.0    0.0    0.0    7.0    2.0    0.0    2.0    0.0    0.0    3.0    0.0    2.0    0.09925558312655088  40 / 403
0.0    6.0    0.0    1.0    320.0  7.0    13.0   1.0    0.0    0.0    6.0    6.0    0.0    0.0    0.0    0.0    6.0    3.0    3.0    1.0    0.0    0.0    0.0    3.0    0.0    8.0    0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    10.0   1.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    351.0  0.0    0.0    0.0    0.064                24 / 375
0.0    1.0    0.0    4.0    4.0    3.0    0.0    0.0    2.0    1.0    8.0    3.0    0.0    0.0    2.0    0.0    0.0    0.0    8.0    1.0    1.0    0.0    0.0    351.0  1.0    3.0    0.10687022900763359  42 / 393
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    1.0    0.0    2.0    17.0   1.0    7.0    1.0    1.0    352.0  0.0    0.10432569974554708  41 / 393
2.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    20.0   1.0    0.0    0.0    0.0    3.0    0.0    316.0  0.13896457765667575  51 / 367
390.0  453.0  331.0  442.0  386.0  414.0  370.0  286.0  327.0  373.0  398.0  371.0  395.0  396.0  399.0  394.0  346.0  403.0  432.0  385.0  411.0  365.0  398.0  409.0  381.0  348.0  0.12976107167849646  1,298 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.870239
2    0.93412
3    0.960412
4    0.971309
5    0.979606
6    0.985404
7    0.989303
8    0.992102
9    0.993902
10   0.995901

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13783113447322956
RMSE: 0.3712561574886396
LogLoss: 0.462440378107918
Mean Per-Class Error: 0.13092424693983917
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0   1.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   84.0   0.0   1.0    1.0   1.0   1.0   1.0   1.0   0.0    1.0    0.0   0.0   0.0    0.0   2.0    1.0   5.0    2.0    0.0   0.0    2.0   0.0   2.0    1.0    0.0   0.20754716981132076  22 / 106
0.0   0.0    66.0  0.0    2.0   0.0   1.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0    2.0   0.0    1.0   0.0    2.0    1.0   2.0    0.0   1.0   0.0    0.0    0.0   0.1951219512195122   16 / 82
0.0   2.0    0.0   100.0  0.0   0.0   0.0   2.0   0.0   0.0    1.0    0.0   0.0   3.0    0.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.10714285714285714  12 / 112
0.0   1.0    0.0   0.0    77.0  4.0   3.0   0.0   0.0   0.0    2.0    1.0   0.0   0.0    0.0   0.0    2.0   1.0    2.0    0.0   0.0    0.0   0.0   1.0    0.0    3.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0    1.0   0.0    0.0   0.0    0.0    0.0   1.0    1.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   1.0   0.0   0.0   0.0   0.0    2.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   88.0   0.0    2.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   2.0    1.0   0.0    0.0    4.0   0.0    3.0   1.0   1.0    94.0   0.0   0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   1.0    0.0    77.0  0.11494252873563218  10 / 87
89.0  117.0  69.0  119.0  91.0  97.0  91.0  70.0  77.0  111.0  101.0  94.0  83.0  110.0  84.0  111.0  94.0  102.0  106.0  90.0  103.0  85.0  96.0  106.0  105.0  89.0  0.13052208835341367  325 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869478
2    0.936546
3    0.958635
4    0.968273
5    0.977108
6    0.983936
7    0.988353
8    0.989558
9    0.99237
10   0.993976
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:02  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:02  50.992 sec  60283 obs/sec     1         1             10007      0.53288          0.929298            0.994953       0.250025                         0.535164           0.931866              0.994897         0.25743
    2019-07-24 14:07:03  52.462 sec  62193 obs/sec     10        10            100070     0.367964         0.449097            0.997594       0.129761                         0.371256           0.46244               0.997544         0.130522
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0887738
C13         0.891496               0.891496             0.0791415
C9          0.835771               0.835771             0.0741945
C7          0.795162               0.795162             0.0705895
C8          0.782856               0.782856             0.0694971
C12         0.753588               0.753588             0.0668988
C11         0.723031               0.723031             0.0641862
C5          0.718176               0.718176             0.0637552
C10         0.693324               0.693324             0.061549
C6          0.650086               0.650086             0.0577106
C14         0.638547               0.638547             0.0566862
C16         0.617128               0.617128             0.0547847
C4          0.597686               0.597686             0.0530588
C3          0.555996               0.555996             0.0493578
C2          0.529581               0.529581             0.0470129
C1          0.482163               0.482163             0.0428034
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_25

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0020064464368942936  0.0005364601965993643  0.0         -0.001943230053093714  0.3413727283477783  0.02676547453719539  0.38405585289001465
    3        26       Softmax                 0.0   0.0   0.0030902278497775956  0.0012823366560041904  0.0         -0.009811940665477218  0.4416677951812744  -0.527845035120271   0.16781198978424072


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.13697665694806008
RMSE: 0.3701035759730782
LogLoss: 0.4586621512243419
Mean Per-Class Error: 0.1311608285522131
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    3.0    1.0    6.0    0.0    2.0    0.0    0.0    2.0    5.0    0.0    1.0    1.0    2.0    2.0    3.0    0.0    0.09367088607594937  37 / 395
0.0    336.0  1.0    4.0    4.0    0.0    1.0    10.0   1.0    1.0    5.0    0.0    0.0    0.0    0.0    2.0    0.0    7.0    5.0    0.0    0.0    3.0    1.0    2.0    0.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    324.0  1.0    6.0    1.0    6.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    4.0    0.0    1.0    1.0    4.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    0.11716621253405994  43 / 367
0.0    13.0   0.0    351.0  0.0    1.0    0.0    11.0   1.0    4.0    0.0    0.0    7.0    3.0    1.0    1.0    0.0    3.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    1.0    0.12903225806451613  52 / 403
0.0    1.0    0.0    0.0    328.0  7.0    16.0   1.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    5.0    2.0    8.0    2.0    1.0    0.0    0.0    4.0    0.0    3.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    15.0   0.0    6.0    0.0    0.0    0.0    0.0    0.0    4.0    1.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    0.0    0.0    4.0    7.0    1.0    0.0    2.0    6.0    6.0    10.0   2.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    3.0    1.0    0.0    0.0    341.0  2.0    2.0    0.13451776649746192  53 / 394
0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    4.0    0.0    3.0    4.0    1.0    9.0    1.0    1.0    366.0  0.0    0.06870229007633588  27 / 393
0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    1.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    24.0   3.0    0.0    0.0    0.0    0.0    0.0    316.0  0.13896457765667575  51 / 367
378.0  448.0  354.0  409.0  396.0  393.0  379.0  354.0  353.0  379.0  394.0  359.0  427.0  364.0  404.0  380.0  382.0  376.0  400.0  367.0  416.0  391.0  374.0  396.0  396.0  334.0  0.13056083175047486  1,306 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869439
2    0.93242
3    0.959212
4    0.969409
5    0.977907
6    0.983305
7    0.987204
8    0.989603
9    0.991903
10   0.993802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.13977676024187308
RMSE: 0.3738673029857961
LogLoss: 0.46447969672298445
Mean Per-Class Error: 0.13091035753630478
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17    18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0   0.0    0.0   1.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   90.0   1.0   2.0    3.0   0.0   1.0   4.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0   0.0    0.0   1.0   1.0   0.0    0.0   0.1509433962264151   16 / 106
0.0   0.0    71.0  0.0    1.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0   3.0    0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.13414634146341464  11 / 82
0.0   1.0    0.0   95.0   0.0   0.0   0.0   5.0   1.0   3.0    0.0    0.0   3.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    77.0  4.0   5.0   0.0   1.0   0.0    3.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0   4.0    0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   2.0    0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    5.0    2.0   0.0   0.0   0.0   0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0   84.0  1.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    1.0   0.0   0.0   0.0   1.0    1.0   0.0   1.0    0.0   0.0    4.0   1.0   0.0   98.0   0.0   0.08411214953271028  9 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0    1.0   0.0    0.0   0.0   0.0   0.0    77.0  0.11494252873563218  10 / 87
87.0  112.0  77.0  112.0  91.0  91.0  93.0  90.0  84.0  108.0  100.0  96.0  97.0  98.0  86.0  109.0  95.0  91.0  106.0  84.0  108.0  88.0  95.0  96.0  113.0  83.0  0.13092369477911647  326 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.869076
2    0.938956
3    0.962651
4    0.970683
5    0.978715
6    0.982731
7    0.985141
8    0.988755
9    0.991566
10   0.992771
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:54  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:54  43.252 sec  49786 obs/sec     1         1             10007      0.540384         0.955459            0.994811       0.263021                         0.539302           0.953617              0.994818         0.272289
    2019-07-24 14:06:56  45.197 sec  47359 obs/sec     10        10            100070     0.370104         0.458662            0.997566       0.130561                         0.373867           0.46448               0.997509         0.130924
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0911558
C13         0.932418               0.932418             0.0849953
C8          0.863761               0.863761             0.0787369
C9          0.845626               0.845626             0.0770837
C12         0.795779               0.795779             0.0725399
C7          0.739188               0.739188             0.0673813
C10         0.736667               0.736667             0.0671515
C11         0.683546               0.683546             0.0623092
C16         0.653296               0.653296             0.0595518
C14         0.626013               0.626013             0.0570647
C5          0.606412               0.606412             0.055278
C6          0.597932               0.597932             0.054505
C2          0.492496               0.492496             0.0448939
C4          0.482456               0.482456             0.0439787
C3          0.475999               0.475999             0.0433901
C1          0.438635               0.438635             0.0399842
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_24

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0019595928793876283  0.0005265488289296627  0.0         0.01519610183439113    0.3339526653289795   0.0014388620506444667  0.37112295627593994
    3        26       Softmax                 0.0   0.0   0.003161248817692607   0.0012868959456682205  0.0         0.0013197023207567327  0.44980382919311523  -0.5510012966274285    0.17629176378250122


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14111021730312356
RMSE: 0.37564639929476706
LogLoss: 0.4712028289144654
Mean Per-Class Error: 0.13413970804313086
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
365.0  0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    1.0    3.0    4.0    2.0    1.0    0.0    2.0    3.0    3.0    0.0759493670886076   30 / 395
0.0    332.0  0.0    5.0    2.0    1.0    1.0    9.0    1.0    0.0    1.0    2.0    0.0    0.0    0.0    1.0    1.0    12.0   5.0    0.0    0.0    6.0    0.0    3.0    0.0    0.0    0.13089005235602094  50 / 382
0.0    0.0    323.0  1.0    8.0    2.0    6.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    7.0    0.0    1.0    1.0    3.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.12228260869565218  45 / 368
1.0    17.0   0.0    345.0  0.0    1.0    0.0    8.0    0.0    4.0    1.0    0.0    6.0    4.0    2.0    0.0    0.0    6.0    3.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    0.14392059553349876  58 / 403
0.0    3.0    5.0    0.0    326.0  4.0    9.0    2.0    0.0    0.0    4.0    3.0    0.0    0.0    0.0    1.0    9.0    3.0    4.0    2.0    1.0    0.0    0.0    2.0    0.0    6.0    0.15104166666666666  58 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    7.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    4.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    0.0    0.0    5.0    4.0    0.0    0.0    2.0    2.0    2.0    10.0   0.0    0.0    0.0    2.0    1.0    0.0    0.0    1.0    3.0    1.0    0.0    0.0    355.0  2.0    4.0    0.09898477157360407  39 / 394
0.0    1.0    0.0    1.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    6.0    0.0    1.0    11.0   2.0    12.0   1.0    2.0    345.0  0.0    0.12213740458015267  48 / 393
0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    2.0    17.0   4.0    0.0    0.0    0.0    0.0    0.0    321.0  0.12534059945504086  46 / 367
394.0  498.0  347.0  410.0  385.0  387.0  357.0  324.0  328.0  367.0  383.0  359.0  429.0  364.0  398.0  373.0  393.0  402.0  382.0  394.0  403.0  363.0  395.0  413.0  380.0  375.0  0.13355993202039387  1,336 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.86644
2    0.929621
3    0.956113
4    0.96791
5    0.977207
6    0.982105
7    0.987004
8    0.989403
9    0.991603
10   0.993602

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14532882728575902
RMSE: 0.38122018215954806
LogLoss: 0.4824550719430528
Mean Per-Class Error: 0.1393292299847066
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0    1.0    1.0   0.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   86.0   0.0   2.0    2.0   0.0   1.0   3.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0    4.0    1.0   0.0   0.0    4.0   0.0    1.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    69.0  0.0    2.0   1.0   2.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   3.0   0.0    0.0    0.0    2.0   0.0   1.0    0.0   1.0    0.0    0.0    0.0   0.15853658536585366  13 / 82
1.0   1.0    0.0   93.0   0.0   1.0   0.0   5.0   0.0   2.0    0.0   0.0   2.0   1.0   1.0   0.0    0.0    1.0    1.0   0.0   1.0    0.0   0.0    2.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   0.0    2.0   0.0    78.0  2.0   1.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0   0.0   0.0    3.0    1.0    2.0   2.0   0.0    0.0   0.0    1.0    0.0    2.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0    88.0   0.0    2.0   0.12                 12 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0    0.0   3.0   0.0    3.0   1.0    0.0    94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    1.0    3.0   2.0   0.0    0.0   0.0    0.0    0.0    75.0  0.13793103448275862  12 / 87
90.0  116.0  75.0  111.0  94.0  91.0  88.0  87.0  81.0  111.0  96.0  92.0  98.0  95.0  86.0  104.0  102.0  105.0  99.0  93.0  100.0  80.0  102.0  101.0  106.0  87.0  0.1393574297188755   347 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.860643
2    0.927711
3    0.955422
4    0.969076
5    0.979116
6    0.983132
7    0.988353
8    0.98996
9    0.991566
10   0.993976
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:52  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:52  41.003 sec  49786 obs/sec     1         1             10007      0.536112         0.942594            0.994892       0.249525                         0.535753           0.946918              0.994886         0.254618
    2019-07-24 14:06:54  43.003 sec  46157 obs/sec     10        10            100070     0.375646         0.471203            0.997492       0.13356                          0.38122            0.482455              0.99741          0.139357
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0920853
C15         0.997678               0.997678             0.0918715
C9          0.855277               0.855277             0.0787585
C8          0.808078               0.808078             0.0744122
C12         0.792017               0.792017             0.0729331
C10         0.723567               0.723567             0.0666299
C7          0.720944               0.720944             0.0663884
C11         0.686181               0.686181             0.0631872
C16         0.641241               0.641241             0.0590489
C14         0.598191               0.598191             0.0550846
C6          0.58553                0.58553              0.0539187
C5          0.573529               0.573529             0.0528136
C3          0.552732               0.552732             0.0508985
C4          0.473006               0.473006             0.0435569
C2          0.43593                0.43593              0.0401428
C1          0.415592               0.415592             0.0382699
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_51

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.0023061428276633933  0.0006585444789379835  0.0         -0.0007859076025695799  0.3101464509963989   -0.04773767114213077  0.3808706998825073
    3        26       Softmax                 0.0   0.0   0.002648124018046124   0.0011373711749911308  0.0         0.002695216261022674    0.30954229831695557  -0.5681073625299906   0.12705814838409424


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.14061463077395417
RMSE: 0.3749861741103986
LogLoss: 0.481546531068661
Mean Per-Class Error: 0.13909386980471128
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
366.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    1.0    5.0    0.0    1.0    0.0    0.0    0.0    3.0    1.0    1.0    2.0    2.0    2.0    3.0    3.0    0.07341772151898734   29 / 395
0.0    340.0  0.0    6.0    3.0    0.0    1.0    7.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    10.0   9.0    0.0    0.0    0.0    1.0    1.0    2.0    1.0    0.1122715404699739    43 / 383
0.0    1.0    309.0  1.0    10.0   0.0    10.0   1.0    0.0    0.0    15.0   2.0    0.0    0.0    3.0    0.0    1.0    1.0    4.0    2.0    6.0    0.0    2.0    0.0    0.0    0.0    0.16032608695652173   59 / 368
1.0    17.0   0.0    340.0  0.0    0.0    0.0    8.0    1.0    3.0    0.0    0.0    3.0    6.0    4.0    1.0    0.0    7.0    1.0    0.0    2.0    0.0    0.0    5.0    0.0    3.0    0.15422885572139303   62 / 402
0.0    5.0    1.0    0.0    323.0  3.0    19.0   1.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    1.0    6.0    3.0    4.0    1.0    1.0    0.0    0.0    2.0    0.0    9.0    0.1566579634464752    60 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    6.0    0.0    6.0    0.0    0.0    2.0    0.0    0.0    2.0    1.0    353.0  0.0    0.0    0.0    0.058666666666666666  22 / 375
0.0    2.0    1.0    4.0    4.0    0.0    0.0    2.0    2.0    2.0    8.0    1.0    0.0    0.0    0.0    0.0    7.0    0.0    1.0    4.0    1.0    0.0    0.0    346.0  6.0    3.0    0.1218274111675127    48 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    7.0    0.0    1.0    2.0    1.0    15.0   1.0    1.0    356.0  0.0    0.09414758269720101   37 / 393
2.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    20.0   2.0    0.0    0.0    0.0    0.0    0.0    322.0  0.1226158038147139    45 / 367
402.0  475.0  334.0  398.0  393.0  352.0  370.0  308.0  333.0  365.0  378.0  355.0  393.0  386.0  405.0  409.0  405.0  420.0  377.0  377.0  400.0  372.0  408.0  419.0  391.0  378.0  0.1383584924522643    1,384 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.861641
2    0.923323
3    0.950815
4    0.964611
5    0.975008
6    0.981805
7    0.986504
8    0.988403
9    0.991103
10   0.992702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1418668821034773
RMSE: 0.37665220310450503
LogLoss: 0.48957418078915466
Mean Per-Class Error: 0.13968662977658083
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
84.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    0.0    2.0    0.0   0.056179775280898875  5 / 89
0.0   90.0   0.0   3.0    2.0   0.0   1.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    3.0    1.0   0.0   0.0    0.0   1.0    1.0    1.0    0.0   0.1509433962264151    16 / 106
0.0   0.0    66.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0    3.0   1.0   2.0    0.0   1.0    0.0    0.0    0.0   0.1951219512195122    16 / 82
1.0   1.0    0.0   95.0   0.0   0.0   0.0   3.0   1.0   1.0    0.0   0.0   0.0   3.0    1.0   1.0    0.0    1.0    0.0   0.0   1.0    0.0   0.0    2.0    0.0    1.0   0.15178571428571427   17 / 112
0.0   0.0    0.0   0.0    79.0  2.0   5.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0    2.0   0.0   0.0    0.0   0.0    0.0    0.0    4.0   0.18556701030927836   18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    1.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   1.0   0.0   1.0    5.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0    1.0   0.0   0.0    0.0   0.0    85.0   1.0    1.0   0.15                  15 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   2.0    2.0    0.0    0.0   0.0   0.0    6.0   1.0    0.0    96.0   0.0   0.102803738317757     11 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0    2.0   0.0   0.0    0.0   0.0    0.0    0.0    77.0  0.11494252873563218   10 / 87
94.0  124.0  68.0  112.0  95.0  78.0  92.0  80.0  81.0  110.0  96.0  92.0  84.0  103.0  89.0  116.0  100.0  105.0  93.0  83.0  101.0  85.0  102.0  100.0  112.0  95.0  0.1389558232931727    346 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.861044
2    0.9249
3    0.950602
4    0.963855
5    0.974297
6    0.982329
7    0.986747
8    0.989157
9    0.991566
10   0.991968
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:33  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:34  1 min 22.936 sec  28348 obs/sec     1         1             10007      0.518812         0.92248             0.995216       0.248326                         0.517349           0.923512              0.995231         0.257028
    2019-07-24 14:07:37  1 min 26.317 sec  27289 obs/sec     10        10            100070     0.374986         0.481547            0.997501       0.138358                         0.376652           0.489574              0.997472         0.138956
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0833698
C13         0.997834               0.997834             0.0831892
C9          0.907427               0.907427             0.075652
C8          0.891324               0.891324             0.0743095
C12         0.884031               0.884031             0.0737015
C7          0.804769               0.804769             0.0670934
C11         0.802677               0.802677             0.066919
C10         0.781798               0.781798             0.0651784
C16         0.719134               0.719134             0.059954
C14         0.705423               0.705423             0.0588109
C5          0.696068               0.696068             0.058031
C6          0.656919               0.656919             0.0547672
C3          0.59307                0.59307              0.0494441
C4          0.569624               0.569624             0.0474894
C1          0.497046               0.497046             0.0414386
C2          0.487612               0.487612             0.0406521
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_45

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  25.0       0.0   0.0   0.002398787607575059  0.0006503614131361246  0.0         -0.0006142171381320338  0.30349087715148926  0.019133824088214953  0.37348222732543945
    3        26       Softmax                 0.0   0.0   0.003038135480210258  0.0014447509311139584  0.0         0.006406621062133411    0.31438565254211426  -0.5483927571239599   0.1504671573638916


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1440847127554698
RMSE: 0.3795849216650601
LogLoss: 0.491393256636767
Mean Per-Class Error: 0.14838117995297545
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    5.0    5.0    2.0    4.0    1.0    0.0    0.0    0.0    1.0    4.0    2.0    1.0    0.0    1.0    0.0    3.0    2.0    0.09113924050632911  36 / 395
0.0    291.0  0.0    13.0   3.0    1.0    1.0    26.0   2.0    0.0    4.0    0.0    0.0    0.0    1.0    2.0    1.0    12.0   18.0   0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.23821989528795812  91 / 382
0.0    0.0    322.0  1.0    4.0    0.0    6.0    2.0    0.0    0.0    16.0   2.0    0.0    0.0    2.0    0.0    2.0    0.0    5.0    1.0    3.0    0.0    2.0    0.0    0.0    0.0    0.125                46 / 368
1.0    6.0    0.0    349.0  0.0    0.0    0.0    15.0   0.0    3.0    1.0    0.0    5.0    3.0    1.0    2.0    0.0    6.0    2.0    0.0    1.0    0.0    0.0    5.0    0.0    3.0    0.13399503722084366  54 / 403
0.0    4.0    3.0    0.0    323.0  3.0    12.0   2.0    0.0    0.0    4.0    3.0    0.0    0.0    0.0    1.0    5.0    3.0    7.0    3.0    1.0    0.0    0.0    6.0    0.0    4.0    0.15885416666666666  61 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    0.0    0.0    0.0    13.0   1.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    0.0    0.0    7.0    3.0    0.0    0.0    4.0    2.0    2.0    7.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    1.0    1.0    0.0    0.0    355.0  4.0    2.0    0.09898477157360407  39 / 394
0.0    0.0    0.0    1.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    1.0    21.0   2.0    17.0   1.0    3.0    335.0  0.0    0.1475826972010178   58 / 393
1.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    30.0   2.0    0.0    0.0    0.0    2.0    0.0    302.0  0.1771117166212534   65 / 367
382.0  354.0  365.0  425.0  400.0  370.0  325.0  448.0  348.0  378.0  381.0  370.0  431.0  378.0  405.0  369.0  354.0  391.0  457.0  387.0  409.0  377.0  375.0  432.0  363.0  329.0  0.1477556732980106   1,478 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.852244
2    0.921224
3    0.951815
4    0.96641
5    0.975507
6    0.983205
7    0.987104
8    0.989503
9    0.991903
10   0.993702

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.14795047990628754
RMSE: 0.38464331517171535
LogLoss: 0.5060255286901109
Mean Per-Class Error: 0.14866615482155024
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7      8     9      10    11    12    13     14    15     16    17    18     19    20     21    22    23     24     25    Error                Rate
----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0   0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    2.0    0.0   0.0898876404494382   8 / 89
0.0   77.0  0.0   4.0    2.0   0.0   1.0   11.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    0.0   3.0   3.0    0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.27358490566037735  29 / 106
0.0   0.0   70.0  0.0    1.0   0.0   1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0   3.0    1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.14634146341463414  12 / 82
1.0   1.0   0.0   92.0   0.0   0.0   0.0   8.0    0.0   1.0    1.0   0.0   1.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   1.0    0.0   0.0   2.0    0.0    1.0   0.17857142857142858  20 / 112
0.0   0.0   0.0   0.0    80.0  1.0   5.0   0.0    0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0   2.0    2.0   0.0    0.0   0.0   2.0    0.0    1.0   0.17525773195876287  17 / 97
---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   4.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    1.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0   0.0   3.0    2.0   0.0   0.0   2.0    0.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   87.0   1.0    1.0   0.13                 13 / 100
0.0   0.0   0.0   0.0    0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0   0.0    6.0   0.0    5.0   1.0   0.0    90.0   0.0   0.1588785046728972   17 / 107
1.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   5.0    0.0   0.0    0.0   0.0   0.0    0.0    74.0  0.14942528735632185  13 / 87
88.0  91.0  76.0  112.0  98.0  90.0  84.0  129.0  84.0  107.0  98.0  96.0  97.0  100.0  82.0  100.0  90.0  93.0  108.0  96.0  106.0  88.0  91.0  101.0  103.0  82.0  0.1497991967871486   373 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.850201
2    0.920482
3    0.953815
4    0.96506
5    0.973896
6    0.982731
7    0.985944
8    0.988755
9    0.991968
10   0.993173
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:21  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:22  1 min 10.825 sec  26265 obs/sec     1         1             10007      0.525012         0.928386            0.995102       0.254324                         0.524591           0.929                 0.995096         0.263454
    2019-07-24 14:07:25  1 min 14.140 sec  27514 obs/sec     10        10            100070     0.379585         0.491393            0.997439       0.147756                         0.384643           0.506026              0.997364         0.149799
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0881209
C15         0.971045               0.971045             0.0855694
C9          0.904194               0.904194             0.0796784
C8          0.85106                0.85106              0.0749962
C12         0.820267               0.820267             0.0722827
C11         0.752277               0.752277             0.0662914
C10         0.720654               0.720654             0.0635047
C7          0.717292               0.717292             0.0632085
C5          0.662774               0.662774             0.0584043
C14         0.63346                0.63346              0.0558211
C16         0.621289               0.621289             0.0547486
C6          0.618151               0.618151             0.0544721
C3          0.591571               0.591571             0.0521298
C4          0.569179               0.569179             0.0501566
C1          0.459562               0.459562             0.040497
C2          0.455264               0.455264             0.0401183
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_77

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  10.0       0.0   0.0   0.0018830063056896051  0.0005778765771538019  0.0         -0.003423726829169027  0.337898850440979   0.007084973815052416  0.35224413871765137
    3        26       Softmax                 0.0   0.0   0.0028518960481191103  0.0009215814061462879  0.0         -0.007937257137541565  0.4413362741470337  -0.5436202124955004   0.12620383501052856


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1472957872320976
RMSE: 0.3837913329298847
LogLoss: 0.4906256934153729
Mean Per-Class Error: 0.14419265199713677
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
370.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    3.0    1.0    4.0    0.0    0.0    0.0    0.0    1.0    2.0    1.0    1.0    0.0    2.0    0.0    4.0    1.0    0.06329113924050633  25 / 395
0.0    320.0  0.0    9.0    2.0    0.0    2.0    5.0    4.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    1.0    19.0   11.0   0.0    0.0    2.0    0.0    2.0    3.0    0.0    0.16449086161879894  63 / 383
0.0    0.0    313.0  0.0    10.0   1.0    6.0    0.0    0.0    0.0    13.0   7.0    0.0    0.0    4.0    0.0    1.0    0.0    4.0    1.0    5.0    0.0    3.0    0.0    0.0    0.0    0.14945652173913043  55 / 368
1.0    12.0   0.0    358.0  0.0    2.0    0.0    1.0    1.0    4.0    2.0    0.0    6.0    3.0    2.0    0.0    0.0    4.0    2.0    0.0    1.0    0.0    0.0    2.0    0.0    2.0    0.11166253101736973  45 / 403
0.0    6.0    4.0    0.0    301.0  7.0    20.0   0.0    0.0    0.0    2.0    8.0    0.0    0.0    0.0    2.0    3.0    4.0    9.0    1.0    1.0    0.0    0.0    2.0    0.0    14.0   0.21614583333333334  83 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    2.0    0.0    0.0    1.0    0.0    0.0    4.0    2.0    352.0  0.0    0.0    0.0    0.06382978723404255  24 / 376
0.0    0.0    0.0    2.0    7.0    2.0    0.0    1.0    5.0    4.0    8.0    2.0    0.0    0.0    2.0    0.0    3.0    4.0    4.0    1.0    1.0    0.0    0.0    342.0  4.0    2.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    2.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    15.0   1.0    23.0   1.0    1.0    337.0  0.0    0.14249363867684478  56 / 393
1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    4.0    0.0    3.0    0.0    0.0    0.0    0.0    3.0    0.0    24.0   4.0    0.0    0.0    0.0    0.0    0.0    319.0  0.1284153005464481   47 / 366
402.0  406.0  342.0  438.0  369.0  417.0  372.0  291.0  353.0  374.0  379.0  388.0  421.0  367.0  385.0  370.0  336.0  439.0  435.0  392.0  405.0  384.0  417.0  390.0  380.0  351.0  0.14365690292912126  1,437 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.856343
2    0.923923
3    0.952714
4    0.96721
5    0.976607
6    0.982605
7    0.986504
8    0.989303
9    0.991603
10   0.994202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1526302314815179
RMSE: 0.3906791925371991
LogLoss: 0.5116003870038963
Mean Per-Class Error: 0.14577957298725816
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5      6     7     8     9      10    11    12    13    14    15     16    17     18     19    20     21    22     23    24     25    Error                 Rate
----  ----  ----  -----  ----  -----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  --------------------  -----------
84.0  0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   1.0    0.0   3.0    0.0   0.056179775280898875  5 / 89
0.0   84.0  0.0   3.0    2.0   0.0    2.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   5.0    3.0    0.0   0.0    2.0   0.0    1.0   2.0    0.0   0.20754716981132076   22 / 106
0.0   0.0   69.0  0.0    3.0   0.0    1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0    0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.15853658536585366   13 / 82
1.0   1.0   0.0   100.0  0.0   1.0    0.0   0.0   1.0   2.0    0.0   0.0   3.0   1.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.10714285714285714   12 / 112
0.0   0.0   1.0   0.0    71.0  5.0    7.0   0.0   0.0   0.0    1.0   2.0   0.0   0.0   0.0   0.0    0.0   1.0    3.0    1.0   0.0    0.0   0.0    0.0   0.0    5.0   0.26804123711340205   26 / 97
---   ---   ---   ---    ---   ---    ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---                   ---
0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   2.0    1.0   86.0   0.0   0.0    0.0   0.06521739130434782   6 / 92
0.0   0.0   0.0   1.0    4.0   0.0    0.0   1.0   0.0   1.0    3.0   1.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   0.0    85.0  1.0    1.0   0.15                  15 / 100
0.0   0.0   0.0   0.0    0.0   3.0    1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    3.0   0.0    7.0   1.0    0.0   91.0   0.0   0.14953271028037382   16 / 107
0.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0   0.0   1.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    5.0    2.0   0.0    0.0   0.0    0.0   0.0    75.0  0.13793103448275862   12 / 87
89.0  94.0  73.0  119.0  87.0  103.0  97.0  76.0  83.0  110.0  97.0  99.0  94.0  99.0  80.0  100.0  85.0  112.0  108.0  94.0  101.0  92.0  100.0  98.0  114.0  86.0  0.1465863453815261    365 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.853414
2    0.922088
3    0.951406
4    0.965462
5    0.974297
6    0.981526
7    0.985944
8    0.988755
9    0.991566
10   0.992771
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:08:08  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:08:08  1 min 57.214 sec  42402 obs/sec     1         1             10007      0.534836         0.942825            0.994917       0.251924                         0.534411           0.940769              0.994911         0.252209
    2019-07-24 14:08:10  1 min 59.225 sec  45198 obs/sec     10        10            100070     0.383791         0.490626            0.997383       0.143657                         0.390679           0.5116                0.99728          0.146586
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.089501
C13         0.949381               0.949381             0.0849705
C12         0.872624               0.872624             0.0781007
C9          0.854667               0.854667             0.0764935
C8          0.839017               0.839017             0.0750929
C11         0.739106               0.739106             0.0661507
C10         0.705555               0.705555             0.0631478
C7          0.702382               0.702382             0.0628639
C5          0.658554               0.658554             0.0589412
C16         0.6326                 0.6326               0.0566184
C6          0.618388               0.618388             0.0553463
C14         0.605249               0.605249             0.0541704
C3          0.543289               0.543289             0.0486249
C4          0.496247               0.496247             0.0444146
C2          0.481364               0.481364             0.0430826
C1          0.474639               0.474639             0.0424807
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_28

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013100677315946996  0.00034900091122835875  0.0         -0.016236826790617442  0.20317327976226807  0.1317866691573084   0.14202988147735596
    3        26       Softmax                      0.0   0.0   0.009508635576926631   0.040244728326797485    0.0         -0.25700920366893765   0.5308525562286377   -0.6441014958915192  0.25749075412750244


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16235623489603554
RMSE: 0.402934529292335
LogLoss: 0.5206151540936423
Mean Per-Class Error: 0.15307038952712398
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    7.0    4.0    0.0    3.0    0.0    1.0    0.0    0.0    2.0    5.0    0.0    3.0    2.0    1.0    1.0    3.0    0.0    0.08354430379746836  33 / 395
0.0    334.0  0.0    5.0    3.0    1.0    1.0    1.0    2.0    0.0    2.0    0.0    0.0    0.0    1.0    3.0    3.0    18.0   7.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.1279373368146214   49 / 383
0.0    0.0    308.0  0.0    16.0   0.0    7.0    0.0    0.0    0.0    18.0   2.0    2.0    0.0    4.0    0.0    0.0    0.0    6.0    1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.16304347826086957  60 / 368
2.0    15.0   0.0    348.0  0.0    1.0    0.0    5.0    0.0    7.0    2.0    0.0    7.0    2.0    2.0    0.0    0.0    4.0    2.0    1.0    0.0    0.0    0.0    3.0    0.0    2.0    0.13647642679900746  55 / 403
0.0    4.0    0.0    0.0    315.0  4.0    11.0   0.0    0.0    0.0    5.0    2.0    0.0    0.0    0.0    0.0    9.0    5.0    10.0   2.0    0.0    0.0    0.0    6.0    0.0    11.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    15.0   0.0    1.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    4.0    5.0    1.0    0.0    2.0    2.0    6.0    11.0   2.0    0.0    0.0    2.0    0.0    4.0    2.0    1.0    1.0    1.0    0.0    0.0    343.0  1.0    5.0    0.12944162436548223  51 / 394
0.0    0.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    17.0   1.0    11.0   1.0    0.0    347.0  0.0    0.11704834605597965  46 / 393
0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    11.0   0.0    3.0    0.0    0.0    0.0    0.0    3.0    1.0    23.0   3.0    0.0    0.0    0.0    0.0    0.0    314.0  0.1444141689373297   53 / 367
388.0  450.0  336.0  428.0  381.0  390.0  352.0  294.0  330.0  395.0  408.0  377.0  415.0  379.0  397.0  372.0  326.0  444.0  426.0  372.0  401.0  366.0  414.0  414.0  385.0  363.0  0.15245426372088375  1,525 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.847546
2    0.919824
3    0.948216
4    0.964111
5    0.973408
6    0.979906
7    0.985204
8    0.988503
9    0.991802
10   0.994202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16361171328534985
RMSE: 0.4044894476810858
LogLoss: 0.5235758340894358
Mean Per-Class Error: 0.15894653453696558
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11     12    13     14    15     16    17     18     19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   1.0    0.0   1.0    0.0    2.0    0.0   0.06741573033707865  6 / 89
0.0   88.0   0.0   0.0    2.0   1.0   1.0   0.0   1.0   0.0    1.0    0.0    0.0   0.0    0.0   1.0    1.0   6.0    2.0    0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.16981132075471697  18 / 106
0.0   0.0    66.0  0.0    3.0   0.0   3.0   0.0   0.0   0.0    3.0    1.0    0.0   0.0    1.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.1951219512195122   16 / 82
2.0   3.0    0.0   93.0   0.0   0.0   0.0   2.0   0.0   3.0    1.0    0.0    3.0   1.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0    2.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    74.0  2.0   3.0   0.0   0.0   0.0    2.0    1.0    0.0   0.0    0.0   0.0    3.0   1.0    4.0    1.0   0.0    0.0   0.0    2.0    0.0    4.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    4.0   0.0    0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   87.0   0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   1.0    4.0    2.0    0.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   0.0    84.0   0.0    2.0   0.16                 16 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0    1.0   0.0    0.0    4.0   0.0    3.0   1.0    0.0    96.0   0.0   0.102803738317757    11 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0    2.0    0.0   0.0    0.0   0.0    0.0   0.0    4.0    1.0   0.0    0.0   0.0    0.0    0.0    73.0  0.16091954022988506  14 / 87
90.0  115.0  72.0  112.0  89.0  91.0  90.0  75.0  77.0  118.0  105.0  103.0  93.0  100.0  80.0  104.0  82.0  110.0  105.0  89.0  101.0  82.0  103.0  100.0  114.0  90.0  0.15903614457831325  396 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840964
2    0.924498
3    0.951406
4    0.96747
5    0.977108
6    0.981928
7    0.985944
8    0.98996
9    0.992771
10   0.994377
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:00  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:00  49.686 sec  61771 obs/sec     1         1             10007      0.569872         1.02554             0.994229       0.276317                         0.571335           1.02607               0.994184         0.280321
    2019-07-24 14:07:01  50.785 sec  81225 obs/sec     10        10            100070     0.402935         0.520615            0.997115       0.152454                         0.404489           0.523576              0.997085         0.159036
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0901473
C15         0.980901               0.980901             0.0884256
C9          0.815533               0.815533             0.0735181
C8          0.780721               0.780721             0.0703799
C7          0.778724               0.778724             0.0701998
C12         0.777851               0.777851             0.0701212
C10         0.694677               0.694677             0.0626233
C5          0.684746               0.684746             0.061728
C11         0.68306                0.68306              0.061576
C4          0.614517               0.614517             0.055397
C6          0.611773               0.611773             0.0551496
C3          0.605317               0.605317             0.0545677
C14         0.559958               0.559958             0.0504787
C16         0.556129               0.556129             0.0501335
C2          0.494065               0.494065             0.0445386
C1          0.454987               0.454987             0.0410158
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_11

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  25.0       0.0   0.0   0.0013389758160542442  0.00036399310920387506  0.0         -0.009020114306039773  0.20028316974639893  0.13860902551951396  0.15109699964523315
    3        26       Softmax                      0.0   0.0   0.01006086612971138    0.04222080111503601     0.0         -0.23334585232529237   0.5237770080566406   -0.6225810854001984  0.2588735818862915


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1634144969951025
RMSE: 0.4042455899513345
LogLoss: 0.5263749654005496
Mean Per-Class Error: 0.1517199505179906
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    6.0    1.0    5.0    0.0    4.0    0.0    0.0    1.0    5.0    0.0    1.0    2.0    2.0    2.0    5.0    0.0    0.10126582278481013  40 / 395
0.0    336.0  0.0    6.0    3.0    1.0    1.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    2.0    1.0    2.0    15.0   8.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.1227154046997389   47 / 383
0.0    0.0    305.0  0.0    18.0   0.0    8.0    2.0    0.0    0.0    17.0   0.0    0.0    0.0    6.0    0.0    2.0    0.0    3.0    2.0    0.0    0.0    4.0    0.0    0.0    0.0    0.16893732970027248  62 / 367
1.0    27.0   0.0    340.0  0.0    1.0    0.0    5.0    0.0    3.0    0.0    0.0    7.0    2.0    3.0    0.0    0.0    8.0    1.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.15632754342431762  63 / 403
0.0    4.0    0.0    0.0    330.0  3.0    16.0   1.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    0.0    3.0    4.0    5.0    0.0    1.0    0.0    0.0    2.0    0.0    10.0   0.140625             54 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    16.0   2.0    3.0    0.0    0.0    9.0    0.0    0.0    2.0    0.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    2.0    0.0    5.0    3.0    1.0    0.0    2.0    2.0    3.0    7.0    1.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    2.0    1.0    0.0    0.0    352.0  2.0    4.0    0.1065989847715736   42 / 394
1.0    0.0    0.0    2.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    6.0    0.0    2.0    17.0   0.0    24.0   0.0    0.0    331.0  0.0    0.15776081424936386  62 / 393
2.0    0.0    0.0    0.0    19.0   0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    28.0   1.0    0.0    0.0    0.0    3.0    0.0    302.0  0.1771117166212534   65 / 367
386.0  475.0  337.0  406.0  428.0  387.0  347.0  314.0  337.0  367.0  386.0  366.0  430.0  391.0  429.0  387.0  362.0  435.0  393.0  360.0  385.0  381.0  392.0  423.0  362.0  337.0  0.15105468359492152  1,511 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.848945
2    0.921424
3    0.948515
4    0.963611
5    0.974008
6    0.980106
7    0.985104
8    0.988503
9    0.992102
10   0.993802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16542141804081487
RMSE: 0.406720319188524
LogLoss: 0.5321941225185999
Mean Per-Class Error: 0.14770785951200394
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22    23     24    25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   1.0   0.0    3.0   0.0   0.10112359550561797  9 / 89
0.0   85.0   0.0   0.0    2.0    1.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    2.0   1.0    0.0   8.0    3.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.19811320754716982  21 / 106
0.0   0.0    66.0  0.0    4.0    0.0   3.0   1.0   0.0   0.0    2.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    1.0   2.0   0.0   0.0   1.0   0.0    0.0   0.0   0.1951219512195122   16 / 82
1.0   4.0    0.0   97.0   0.0    1.0   0.0   2.0   0.0   0.0    0.0   0.0   3.0   1.0    0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.13392857142857142  15 / 112
0.0   0.0    0.0   0.0    81.0   2.0   5.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0   1.0    0.0   3.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   87.0  0.0    0.0   0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    2.0    1.0   0.0   1.0   0.0   1.0    2.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   0.0   0.0   0.0   88.0   0.0   1.0   0.12                 12 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   2.0    3.0   0.0    0.0   5.0   0.0   8.0   0.0   0.0    87.0  0.0   0.18691588785046728  20 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   76.0  0.12643678160919541  11 / 87
90.0  114.0  70.0  112.0  101.0  96.0  93.0  77.0  78.0  105.0  95.0  97.0  96.0  102.0  90.0  109.0  95.0  109.0  94.0  86.0  99.0  87.0  98.0  108.0  99.0  90.0  0.14779116465863454  368 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.852209
2    0.923293
3    0.946586
4    0.961847
5    0.971888
6    0.97992
7    0.986345
8    0.989157
9    0.99237
10   0.993976
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:32  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:32  21.584 sec  59565 obs/sec     1         1             10007      0.567753         1.02165             0.994272       0.269919                         0.565552           1.0113                0.994301         0.26988
    2019-07-24 14:06:33  22.771 sec  75297 obs/sec     10        10            100070     0.404246         0.526375            0.997096       0.151055                         0.40672            0.532194              0.997052         0.147791
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0881977
C15         0.97363                0.97363              0.0858719
C9          0.846908               0.846908             0.0746953
C8          0.83225                0.83225              0.0734026
C12         0.806097               0.806097             0.0710959
C7          0.763788               0.763788             0.0673644
C5          0.729289               0.729289             0.0643216
C11         0.710476               0.710476             0.0626623
C14         0.663955               0.663955             0.0585593
C10         0.652889               0.652889             0.0575833
C6          0.648162               0.648162             0.0571664
C3          0.596675               0.596675             0.0526253
C16         0.575022               0.575022             0.0507156
C4          0.569161               0.569161             0.0501987
C1          0.490508               0.490508             0.0432617
C2          0.479355               0.479355             0.042278
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_16

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017070602000330837  0.0004324407782405615  0.0         -0.004209490395403748  0.4529823064804077  0.008486764105631978  0.49388444423675537
    3        26       Softmax                 0.0   0.0   0.0022787009647100395  0.0006349170580506325  0.0         0.0029337591432093946  0.4135693311691284  -0.4868295891834352   0.20253753662109375


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.15968105944004968
RMSE: 0.3996011254239028
LogLoss: 0.5437627407516878
Mean Per-Class Error: 0.16074258105760628
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    8.0    5.0    3.0    3.0    1.0    1.0    0.0    1.0    4.0    2.0    1.0    1.0    1.0    1.0    2.0    6.0    1.0    0.10886075949367088  43 / 395
0.0    310.0  0.0    11.0   3.0    2.0    5.0    3.0    2.0    0.0    3.0    1.0    1.0    0.0    0.0    3.0    1.0    24.0   5.0    0.0    0.0    3.0    0.0    3.0    3.0    0.0    0.1906005221932115   73 / 383
0.0    0.0    311.0  1.0    10.0   0.0    12.0   2.0    0.0    0.0    18.0   2.0    0.0    0.0    2.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    4.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
1.0    14.0   0.0    352.0  0.0    0.0    0.0    6.0    0.0    5.0    0.0    0.0    6.0    3.0    2.0    2.0    1.0    2.0    1.0    0.0    1.0    0.0    0.0    5.0    0.0    2.0    0.12655086848635236  51 / 403
0.0    1.0    0.0    0.0    309.0  5.0    7.0    2.0    1.0    0.0    9.0    6.0    0.0    0.0    0.0    1.0    12.0   4.0    4.0    6.0    0.0    0.0    0.0    9.0    0.0    8.0    0.1953125            75 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    2.0    8.0    0.0    0.0    2.0    0.0    14.0   3.0    3.0    0.0    0.0    5.0    0.0    0.0    4.0    1.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    0.0    0.0    8.0    3.0    1.0    0.0    0.0    2.0    3.0    9.0    4.0    0.0    0.0    2.0    0.0    3.0    0.0    1.0    7.0    1.0    0.0    0.0    343.0  3.0    3.0    0.1272264631043257   50 / 393
0.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    0.0    17.0   1.0    8.0    1.0    1.0    348.0  1.0    0.11224489795918367  44 / 392
1.0    0.0    0.0    0.0    15.0   2.0    0.0    0.0    1.0    17.0   0.0    1.0    0.0    0.0    0.0    0.0    11.0   0.0    16.0   7.0    0.0    0.0    0.0    2.0    0.0    294.0  0.1989100817438692   73 / 367
378.0  432.0  339.0  442.0  371.0  414.0  365.0  342.0  346.0  393.0  383.0  373.0  421.0  383.0  377.0  369.0  407.0  439.0  335.0  386.0  405.0  360.0  374.0  432.0  396.0  341.0  0.159852044386684    1,599 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840148
2    0.914626
3    0.942817
4    0.958712
5    0.971309
6    0.979206
7    0.983505
8    0.987404
9    0.989903
10   0.992302

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16184521828583792
RMSE: 0.4022999108697862
LogLoss: 0.5550230129676826
Mean Per-Class Error: 0.16144113643272756
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    1.0    1.0    0.0   0.0   0.0    0.0   0.0   0.0    3.0    1.0   0.0898876404494382   8 / 89
0.0   81.0   0.0   5.0    3.0   0.0   3.0   2.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    6.0    1.0   0.0   0.0    2.0   0.0   2.0    1.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    67.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   1.0   0.0    0.0    0.0    3.0   0.0   0.0    0.0   1.0   0.0    0.0    0.0   0.18292682926829268  15 / 82
1.0   2.0    0.0   96.0   0.0   0.0   0.0   3.0   0.0   1.0    0.0   0.0   2.0   0.0   2.0   1.0    0.0    1.0    0.0   0.0   0.0    0.0   0.0   1.0    0.0    2.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    71.0  4.0   2.0   0.0   1.0   0.0    2.0   2.0   0.0   0.0   0.0   0.0    3.0    2.0    2.0   3.0   0.0    0.0   0.0   4.0    0.0    1.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   1.0    1.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   0.0   0.0   0.0    5.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   0.0   85.0   2.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0    0.0    0.0   4.0   0.0    2.0   1.0   0.0    97.0   0.0   0.09345794392523364  10 / 107
1.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0   0.0   0.0    1.0    0.0    1.0   2.0   0.0    0.0   0.0   0.0    0.0    73.0  0.16091954022988506  14 / 87
90.0  108.0  70.0  125.0  83.0  98.0  90.0  86.0  85.0  109.0  96.0  95.0  97.0  98.0  74.0  104.0  107.0  106.0  85.0  92.0  103.0  79.0  96.0  108.0  119.0  87.0  0.1610441767068273   401 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838956
2    0.912851
3    0.94257
4    0.959839
5    0.96988
6    0.97992
7    0.983534
8    0.987952
9    0.98996
10   0.992771
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:40  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:40  29.231 sec  45694 obs/sec     1         1             10007      0.543923         0.969906            0.994741       0.259722                         0.542555           0.967021              0.994755         0.265462
    2019-07-24 14:06:42  31.067 sec  49588 obs/sec     10        10            100070     0.399601         0.543763            0.997161       0.159852                         0.4023             0.555023              0.997116         0.161044
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0870222
C15         0.973981               0.973981             0.084758
C9          0.883596               0.883596             0.0768924
C12         0.863938               0.863938             0.0751818
C7          0.83832                0.83832              0.0729525
C8          0.825503               0.825503             0.0718371
C11         0.758066               0.758066             0.0659686
C10         0.718401               0.718401             0.0625169
C14         0.655804               0.655804             0.0570695
C6          0.65488                0.65488              0.0569891
C16         0.636578               0.636578             0.0553965
C5          0.630178               0.630178             0.0548395
C3          0.577656               0.577656             0.0502689
C4          0.542463               0.542463             0.0472063
C1          0.477613               0.477613             0.0415629
C2          0.454344               0.454344             0.039538
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_55

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.001723295485220433   0.0004489866551011801  0.0         0.019605795593292896  0.4445396661758423  0.018632187015917526  0.49380016326904297
    3        26       Softmax                 0.0   0.0   0.0022861701888289713  0.0007308607455343008  0.0         -0.01221022572160389  0.4143334627151489  -0.48030718758184465  0.1564692258834839


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16300276645898662
RMSE: 0.403736010852372
LogLoss: 0.5463858697054583
Mean Per-Class Error: 0.1602121699797118
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    4.0    2.0    5.0    1.0    0.0    0.0    1.0    2.0    0.0    0.0    1.0    3.0    1.0    2.0    3.0    4.0    0.09113924050632911  36 / 395
0.0    320.0  0.0    7.0    5.0    1.0    1.0    3.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    26.0   6.0    0.0    0.0    3.0    0.0    4.0    2.0    2.0    0.16449086161879894  63 / 383
0.0    0.0    302.0  1.0    14.0   0.0    8.0    1.0    0.0    0.0    18.0   1.0    1.0    0.0    14.0   0.0    2.0    0.0    0.0    0.0    2.0    0.0    3.0    1.0    0.0    0.0    0.1793478260869565   66 / 368
1.0    21.0   0.0    336.0  0.0    1.0    0.0    10.0   0.0    2.0    0.0    0.0    3.0    6.0    3.0    0.0    0.0    7.0    0.0    1.0    1.0    0.0    0.0    8.0    0.0    3.0    0.1662531017369727   67 / 403
0.0    5.0    3.0    0.0    322.0  3.0    14.0   1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    6.0    3.0    4.0    3.0    1.0    0.0    0.0    3.0    0.0    11.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.0    0.0    0.0    12.0   0.0    5.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    1.0    0.0    5.0    7.0    1.0    0.0    5.0    3.0    1.0    12.0   0.0    0.0    0.0    2.0    0.0    5.0    0.0    5.0    7.0    1.0    0.0    0.0    333.0  3.0    3.0    0.1548223350253807   61 / 394
1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    1.0    23.0   2.0    15.0   1.0    1.0    340.0  0.0    0.13486005089058525  53 / 393
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    17.0   4.0    0.0    0.0    0.0    3.0    0.0    313.0  0.14713896457765668  54 / 367
385.0  450.0  340.0  409.0  431.0  386.0  357.0  320.0  358.0  361.0  386.0  363.0  412.0  374.0  399.0  378.0  380.0  452.0  331.0  385.0  395.0  383.0  406.0  415.0  376.0  371.0  0.1595521343596921   1,596 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840448
2    0.917425
3    0.945816
4    0.961112
5    0.970309
6    0.976907
7    0.982605
8    0.986004
9    0.989603
10   0.991902

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16572227779958715
RMSE: 0.40709001191332017
LogLoss: 0.5596959661020128
Mean Per-Class Error: 0.15655576432663268
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0    1.0   2.0    1.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   2.0    2.0    1.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   8.0    1.0   0.0   0.0    3.0   0.0    1.0   1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    68.0  0.0    2.0    0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    7.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.17073170731707318  14 / 82
1.0   4.0    0.0   95.0   0.0    0.0   0.0   4.0   0.0   0.0    0.0   0.0   1.0   2.0    0.0   0.0    0.0   2.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0    1.0   0.15178571428571427  17 / 112
0.0   0.0    1.0   0.0    79.0   2.0   4.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    2.0   2.0   0.0    0.0   0.0    0.0   0.0    4.0   0.18556701030927836  18 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   89.0   0.0   0.0    0.0   0.03260869565217391  3 / 92
0.0   0.0    0.0   3.0    2.0    0.0   0.0   2.0   0.0   1.0    4.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    2.0   1.0   0.0    0.0   0.0    82.0  1.0    1.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   5.0   0.0    5.0   1.0    0.0   94.0   0.0   0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0   1.0   0.0    0.0   0.0    0.0   0.0    72.0  0.1724137931034483   15 / 87
90.0  111.0  76.0  116.0  102.0  90.0  88.0  85.0  89.0  106.0  94.0  93.0  91.0  100.0  81.0  106.0  96.0  115.0  81.0  93.0  100.0  88.0  101.0  99.0  110.0  89.0  0.15622489959839359  389 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.843775
2    0.921285
3    0.946586
4    0.959438
5    0.96747
6    0.975502
7    0.981526
8    0.985141
9    0.990362
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:39  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:39  1 min 28.609 sec  40028 obs/sec     1         1             10007      0.54586          0.986694            0.994706       0.258522                         0.544442           0.975618              0.994718         0.264659
    2019-07-24 14:07:41  1 min 30.320 sec  51903 obs/sec     10        10            100070     0.403736         0.546386            0.997104       0.159552                         0.40709            0.559696              0.997047         0.156225
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0924943
C13         0.875207               0.875207             0.0809516
C12         0.811396               0.811396             0.0750495
C9          0.805005               0.805005             0.0744584
C8          0.761784               0.761784             0.0704607
C7          0.761013               0.761013             0.0703893
C11         0.742135               0.742135             0.0686433
C14         0.684629               0.684629             0.0633243
C10         0.677225               0.677225             0.0626394
C16         0.66588                0.66588              0.0615901
C6          0.616716               0.616716             0.0570427
C5          0.578557               0.578557             0.0535132
C4          0.519719               0.519719             0.048071
C3          0.503443               0.503443             0.0465656
C2          0.408628               0.408628             0.0377958
C1          0.400142               0.400142             0.0370109
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_66

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0010022081248166614  0.0002533405786380172  0.0         -0.018752911627441193  0.24708104133605957  0.2596386780954881    0.19940823316574097
    3        26       Softmax                      0.0   0.0   0.005917799342919002   0.028279133141040802   0.0         -0.29415564111658254   0.7044203281402588   -0.47765456679522295  0.21260017156600952


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.16921982840533312
RMSE: 0.4113633775694345
LogLoss: 0.5509136346802287
Mean Per-Class Error: 0.15821151708483655
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    6.0    4.0    1.0    4.0    0.0    0.0    1.0    0.0    1.0    6.0    0.0    1.0    2.0    1.0    3.0    4.0    0.0    0.09113924050632911  36 / 395
0.0    331.0  0.0    7.0    2.0    1.0    0.0    3.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    3.0    5.0    13.0   11.0   0.0    0.0    2.0    1.0    1.0    1.0    0.0    0.13577023498694518  52 / 383
0.0    0.0    307.0  0.0    14.0   0.0    7.0    2.0    0.0    0.0    21.0   0.0    0.0    0.0    7.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
2.0    18.0   0.0    351.0  0.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    7.0    5.0    1.0    0.0    2.0    7.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.12903225806451613  52 / 403
0.0    2.0    0.0    0.0    328.0  2.0    8.0    2.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    8.0    4.0    15.0   0.0    0.0    0.0    0.0    2.0    0.0    6.0    0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    1.0    0.0    17.0   4.0    4.0    0.0    0.0    1.0    0.0    0.0    1.0    5.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    1.0    0.0    5.0    4.0    0.0    0.0    4.0    5.0    5.0    8.0    2.0    0.0    0.0    2.0    0.0    0.0    2.0    2.0    1.0    1.0    0.0    0.0    345.0  3.0    4.0    0.12436548223350254  49 / 394
0.0    0.0    0.0    4.0    1.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    3.0    13.0   0.0    21.0   0.0    0.0    334.0  0.0    0.15012722646310434  59 / 393
2.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    1.0    8.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    12.0   2.0    0.0    0.0    0.0    3.0    0.0    320.0  0.12806539509536785  47 / 367
396.0  459.0  343.0  438.0  407.0  377.0  353.0  341.0  341.0  365.0  380.0  365.0  416.0  391.0  388.0  384.0  357.0  433.0  415.0  348.0  383.0  395.0  399.0  411.0  369.0  349.0  0.1576527041887434   1,577 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842347
2    0.916525
3    0.945316
4    0.960112
5    0.972308
6    0.979206
7    0.984405
8    0.988204
9    0.990703
10   0.992802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17284605050522175
RMSE: 0.4157475802758469
LogLoss: 0.5601947049540118
Mean Per-Class Error: 0.1599808045004108
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   1.0   0.0   1.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   83.0   0.0   2.0    2.0   1.0   0.0   3.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    2.0   4.0    4.0    0.0   0.0   1.0   1.0   1.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    64.0  0.0    5.0   0.0   1.0   1.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0    1.0   1.0   0.0   1.0   0.0    0.0    0.0   0.21951219512195122  18 / 82
1.0   4.0    0.0   96.0   0.0   0.0   0.0   3.0   0.0   1.0    0.0   0.0   3.0   1.0    0.0   0.0    1.0   1.0    0.0    0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    81.0  1.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    5.0    0.0   0.0   0.0   0.0   0.0    0.0    2.0   0.16494845360824742  16 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   5.0   1.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    1.0   0.0   0.0   2.0   0.0   1.0    2.0   2.0   0.0   0.0    0.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   0.0   87.0   0.0    1.0   0.13                 13 / 100
0.0   0.0    0.0   2.0    1.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    2.0   0.0    0.0    4.0   0.0   5.0   0.0   0.0    89.0   0.0   0.16822429906542055  18 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0    77.0  0.11494252873563218  10 / 87
89.0  111.0  71.0  123.0  99.0  90.0  86.0  94.0  83.0  105.0  97.0  96.0  93.0  101.0  78.0  110.0  97.0  107.0  104.0  82.0  95.0  90.0  98.0  102.0  102.0  87.0  0.1598393574297189   398 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840161
2    0.914056
3    0.948594
4    0.960241
5    0.972691
6    0.979116
7    0.984337
8    0.988353
9    0.98996
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:50  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:50  1 min 39.422 sec  112438 obs/sec    1         1             10007      0.601315         1.12865             0.993575       0.311407                         0.602309           1.12373               0.993536         0.318876
    2019-07-24 14:07:51  1 min 40.273 sec  108418 obs/sec    10        10            100070     0.411363         0.550914            0.996993       0.157653                         0.415748           0.560195              0.99692          0.159839
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0821028
C8          0.989065               0.989065             0.081205
C15         0.976626               0.976626             0.0801837
C9          0.91718                0.91718              0.075303
C12         0.858561               0.858561             0.0704903
C11         0.81052                0.81052              0.066546
C5          0.758223               0.758223             0.0622522
C10         0.7575                 0.7575               0.0621928
C7          0.755388               0.755388             0.0620195
C14         0.732275               0.732275             0.0601218
C4          0.707139               0.707139             0.058058
C6          0.700255               0.700255             0.0574929
C16         0.642209               0.642209             0.0527272
C3          0.565108               0.565108             0.046397
C2          0.521881               0.521881             0.0428479
C1          0.487924               0.487924             0.0400599
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_7

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0016737019793140462  0.000435151276178658  0.0         -0.011961577174787408  0.45306408405303955  -0.08302943927778407  0.4810023307800293
    3        26       Softmax                 0.0   0.0   0.002210378403036045   0.000587796326726675  0.0         0.0009072404871077658  0.41282618045806885  -0.4898343720729112   0.18395477533340454


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1629544872123079
RMSE: 0.40367621581201424
LogLoss: 0.55559628053822
Mean Per-Class Error: 0.15969338188761356
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    4.0    3.0    1.0    5.0    1.0    0.0    0.0    0.0    4.0    3.0    1.0    1.0    0.0    2.0    2.0    7.0    1.0    0.09367088607594937  37 / 395
0.0    328.0  0.0    4.0    6.0    1.0    1.0    5.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    2.0    0.0    14.0   10.0   0.0    0.0    3.0    0.0    2.0    4.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    312.0  1.0    8.0    2.0    8.0    1.0    0.0    0.0    15.0   1.0    0.0    0.0    7.0    0.0    3.0    0.0    3.0    1.0    4.0    0.0    2.0    0.0    0.0    0.0    0.15217391304347827  56 / 368
1.0    22.0   0.0    335.0  0.0    0.0    0.0    6.0    2.0    3.0    0.0    0.0    4.0    4.0    5.0    1.0    0.0    9.0    1.0    1.0    2.0    0.0    0.0    5.0    0.0    2.0    0.1687344913151365   68 / 403
0.0    2.0    1.0    0.0    322.0  2.0    12.0   1.0    0.0    0.0    5.0    3.0    0.0    0.0    0.0    1.0    4.0    3.0    11.0   1.0    0.0    0.0    0.0    3.0    0.0    13.0   0.16145833333333334  62 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    12.0   0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0    9.0    0.0    4.0    0.0    0.0    2.0    0.0    0.0    4.0    2.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    2.0    0.0    4.0    3.0    1.0    0.0    2.0    2.0    2.0    9.0    1.0    0.0    0.0    2.0    0.0    4.0    1.0    4.0    2.0    2.0    1.0    0.0    346.0  4.0    2.0    0.1218274111675127   48 / 394
0.0    1.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    12.0   1.0    12.0   1.0    1.0    349.0  0.0    0.11195928753180662  44 / 393
2.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    31.0   3.0    0.0    0.0    0.0    4.0    0.0    299.0  0.1830601092896175   67 / 366
387.0  508.0  339.0  400.0  414.0  371.0  337.0  287.0  341.0  382.0  381.0  359.0  409.0  376.0  414.0  369.0  355.0  459.0  406.0  375.0  403.0  374.0  390.0  410.0  416.0  341.0  0.15895231430570828  1,590 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.841048
2    0.911627
3    0.943617
4    0.960112
5    0.969109
6    0.976907
7    0.981706
8    0.985904
9    0.989003
10   0.991303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.16499433686957207
RMSE: 0.4061949493403039
LogLoss: 0.5661978368565771
Mean Per-Class Error: 0.16256142440350455
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   1.0   0.0    3.0    0.0   0.07865168539325842  7 / 89
0.0   85.0   0.0   0.0    2.0   0.0   1.0   3.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0   1.0    0.0   6.0    2.0    0.0   0.0    3.0   0.0   1.0    1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    68.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    2.0    1.0   0.0    0.0   1.0   0.0    0.0    0.0   0.17073170731707318  14 / 82
1.0   2.0    0.0   93.0   0.0   0.0   0.0   4.0   1.0   1.0    0.0   0.0   0.0   2.0   2.0   0.0    0.0   2.0    1.0    0.0   1.0    0.0   0.0   1.0    0.0    1.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    73.0  1.0   4.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0   0.0   0.0    1.0   1.0    4.0    0.0   0.0    0.0   0.0   2.0    0.0    7.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0   2.0    1.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   2.0    2.0   0.0   0.0   1.0   0.0   0.0    3.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   0.0   88.0   1.0    1.0   0.12                 12 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    3.0   0.0    5.0   1.0   0.0    95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    6.0    0.0   0.0    0.0   0.0   2.0    0.0    72.0  0.1724137931034483   15 / 87
89.0  124.0  73.0  110.0  94.0  86.0  85.0  78.0  83.0  109.0  93.0  93.0  86.0  99.0  85.0  107.0  88.0  119.0  106.0  88.0  102.0  88.0  99.0  102.0  118.0  86.0  0.16224899598393575  404 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837751
2    0.913655
3    0.943373
4    0.959438
5    0.96747
6    0.976305
7    0.981928
8    0.986345
9    0.990763
10   0.991968
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:25  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:26  15.017 sec  41870 obs/sec     1         1             10007      0.552748         0.993912            0.99457        0.273518                         0.552971           0.995793              0.994551         0.280321
    2019-07-24 14:06:28  16.858 sec  49102 obs/sec     10        10            100070     0.403676         0.555596            0.997104       0.158952                         0.406195           0.566198              0.99706          0.162249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0881306
C13         0.993889               0.993889             0.0875921
C12         0.859208               0.859208             0.0757226
C9          0.827513               0.827513             0.0729292
C8          0.811118               0.811118             0.0714844
C7          0.76031                0.76031              0.0670066
C11         0.740732               0.740732             0.0652812
C10         0.686889               0.686889             0.060536
C5          0.657015               0.657015             0.0579032
C14         0.650923               0.650923             0.0573663
C16         0.648882               0.648882             0.0571864
C6          0.619132               0.619132             0.0545645
C3          0.600173               0.600173             0.0528936
C4          0.539661               0.539661             0.0475607
C2          0.48228                0.48228              0.0425037
C1          0.469064               0.469064             0.0413389
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_10

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.001520331300810085  0.0003984738141298294  0.0         -0.0142695921961149    0.4446958303451538  0.05515618775619825  0.45939457416534424
    3        26       Softmax                 0.0   0.0   0.002520388405733124  0.0006741364486515522  0.0         -0.017607411298425947  0.5667269229888916  -0.5299676155177683  0.18414628505706787


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17080983453822915
RMSE: 0.41329146439072406
LogLoss: 0.567330761247155
Mean Per-Class Error: 0.16360463920030707
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    1.0    0.0    0.0    0.0    2.0    1.0    5.0    2.0    1.0    5.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    3.0    1.0    1.0    2.0    3.0    4.0    0.09113924050632911  36 / 395
0.0    340.0  4.0    4.0    2.0    0.0    2.0    7.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    8.0    1.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    309.0  1.0    5.0    0.0    7.0    1.0    0.0    0.0    25.0   1.0    0.0    0.0    3.0    0.0    2.0    0.0    10.0   1.0    1.0    0.0    2.0    0.0    0.0    0.0    0.16032608695652173  59 / 368
2.0    21.0   0.0    327.0  0.0    1.0    0.0    7.0    0.0    5.0    3.0    0.0    7.0    4.0    3.0    0.0    0.0    10.0   2.0    0.0    2.0    0.0    0.0    4.0    0.0    4.0    0.1865671641791045   75 / 402
0.0    9.0    2.0    0.0    303.0  6.0    17.0   2.0    1.0    0.0    4.0    9.0    0.0    0.0    0.0    1.0    7.0    3.0    12.0   4.0    0.0    0.0    0.0    0.0    0.0    4.0    0.2109375            81 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    14.0   0.0    12.0   0.0    0.0    0.0    0.0    0.0    1.0    0.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    1.0    0.0    4.0    6.0    2.0    0.0    0.0    2.0    3.0    11.0   4.0    0.0    0.0    2.0    0.0    5.0    1.0    4.0    2.0    1.0    0.0    0.0    338.0  4.0    4.0    0.14213197969543148  56 / 394
0.0    0.0    0.0    1.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    4.0    0.0    1.0    5.0    4.0    21.0   1.0    1.0    343.0  0.0    0.1272264631043257   50 / 393
1.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    7.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    34.0   2.0    0.0    0.0    0.0    0.0    0.0    307.0  0.16348773841961853  60 / 367
385.0  473.0  349.0  403.0  370.0  374.0  358.0  342.0  328.0  368.0  403.0  360.0  420.0  374.0  392.0  394.0  396.0  374.0  412.0  361.0  412.0  392.0  400.0  411.0  404.0  348.0  0.16295111466560033  1,630 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837049
2    0.911427
3    0.940118
4    0.955713
5    0.968509
6    0.977007
7    0.982105
8    0.985804
9    0.988903
10   0.991903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1726359321466135
RMSE: 0.41549480399472327
LogLoss: 0.5731047740635555
Mean Per-Class Error: 0.16046837355910248
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17    18     19    20     21    22     23     24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  -----  -----  ----  --------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0   1.0    0.0   1.0    0.0   0.0    1.0    2.0    0.0   0.07865168539325842   7 / 89
0.0   89.0   1.0   1.0    1.0   0.0   1.0   4.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0    4.0   0.0    0.0   0.0    1.0   0.0    2.0    0.0    0.0   0.16037735849056603   17 / 106
0.0   0.0    69.0  0.0    1.0   0.0   1.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    1.0   0.0    0.0    0.0   3.0    1.0   0.0    0.0   1.0    0.0    0.0    0.0   0.15853658536585366   13 / 82
1.0   1.0    0.0   94.0   0.0   1.0   0.0   3.0   0.0   3.0    1.0   0.0   3.0   1.0    0.0   0.0    0.0    1.0   0.0    0.0   1.0    0.0   0.0    2.0    0.0    0.0   0.16071428571428573   18 / 112
0.0   2.0    1.0   0.0    70.0  4.0   4.0   0.0   0.0   0.0    2.0   4.0   0.0   0.0    0.0   0.0    2.0    1.0   4.0    2.0   0.0    0.0   0.0    0.0    0.0    1.0   0.27835051546391754   27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    2.0   0.0    0.0    0.0   0.0    0.0   0.0    0.0   88.0   0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   1.0    4.0   3.0   0.0   0.0    0.0   0.0    1.0    1.0   1.0    0.0   0.0    0.0   0.0    81.0   2.0    1.0   0.19                  19 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0    7.0   1.0    0.0    94.0   0.0   0.12149532710280374   13 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   7.0    0.0   0.0    0.0   0.0    0.0    0.0    74.0  0.14942528735632185   13 / 87
89.0  115.0  78.0  115.0  86.0  91.0  86.0  86.0  75.0  107.0  97.0  99.0  92.0  100.0  82.0  111.0  105.0  90.0  104.0  84.0  106.0  90.0  100.0  102.0  116.0  84.0  0.1598393574297189    398 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.840161
2    0.913655
3    0.94257
4    0.955422
5    0.968273
6    0.974699
7    0.981124
8    0.985542
9    0.989157
10   0.991968
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:31  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:31  20.241 sec  82024 obs/sec     1         1             10007      0.582593         1.0742              0.993969       0.282315                         0.582001           1.07078               0.993964         0.285141
    2019-07-24 14:06:32  21.354 sec  82770 obs/sec     10        10            100070     0.413291         0.567331            0.996965       0.162951                         0.415495           0.573105              0.996924         0.159839
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0955605
C13         0.954776               0.954776             0.0912389
C12         0.817204               0.817204             0.0780924
C9          0.815016               0.815016             0.0778833
C11         0.748562               0.748562             0.0715329
C8          0.746237               0.746237             0.0713108
C7          0.699592               0.699592             0.0668533
C6          0.646273               0.646273             0.0617582
C10         0.638838               0.638838             0.0610477
C14         0.604768               0.604768             0.0577919
C16         0.582444               0.582444             0.0556586
C5          0.539703               0.539703             0.0515743
C3          0.478826               0.478826             0.0457569
C4          0.446034               0.446034             0.0426232
C1          0.37682                0.37682              0.0360091
C2          0.369483               0.369483             0.035308
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_9

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        256      RectifierDropout  50.0       0.0   0.0   0.001726621660282035  0.000431346008554101  0.0         -0.009836955602175568  0.17959988117218018  0.12520516491602013  0.11846014857292175
    3        26       Softmax                      0.0   0.0   0.008466826132733401  0.030541256070137024  0.0         -0.17915759783649648   0.4039691686630249   -0.9439712582774583  0.3893284797668457


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17681376366978532
RMSE: 0.4204922872892978
LogLoss: 0.5639236278966883
Mean Per-Class Error: 0.15841773177927923
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    2.0    6.0    0.0    0.0    0.0    0.0    0.0    10.0   1.0    1.0    3.0    2.0    2.0    3.0    0.0    0.08607594936708861  34 / 395
0.0    330.0  0.0    3.0    3.0    1.0    2.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    7.0    2.0    17.0   6.0    0.0    0.0    3.0    0.0    2.0    1.0    0.0    0.13838120104438642  53 / 383
0.0    0.0    297.0  0.0    12.0   0.0    12.0   1.0    0.0    0.0    23.0   0.0    0.0    0.0    7.0    0.0    3.0    0.0    1.0    4.0    2.0    0.0    5.0    0.0    0.0    0.0    0.1907356948228883   70 / 367
1.0    21.0   0.0    347.0  0.0    2.0    1.0    4.0    0.0    4.0    1.0    0.0    7.0    4.0    1.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    0.0    5.0    0.0    0.0    0.13895781637717122  56 / 403
0.0    4.0    1.0    0.0    312.0  4.0    19.0   0.0    0.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    6.0    4.0    7.0    6.0    0.0    0.0    0.0    4.0    0.0    12.0   0.1875               72 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    0.0    0.0    0.0    12.0   1.0    1.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    348.0  0.0    0.0    0.0    0.07446808510638298  28 / 376
0.0    2.0    0.0    6.0    6.0    0.0    0.0    2.0    2.0    2.0    7.0    4.0    0.0    0.0    2.0    0.0    4.0    2.0    1.0    5.0    1.0    1.0    0.0    340.0  3.0    4.0    0.13705583756345177  54 / 394
1.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    3.0    0.0    3.0    8.0    2.0    11.0   1.0    0.0    355.0  0.0    0.09669211195928754  38 / 393
1.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    0.0    4.0    0.0    19.0   3.0    0.0    0.0    0.0    0.0    0.0    314.0  0.14207650273224043  52 / 366
398.0  467.0  323.0  421.0  396.0  388.0  369.0  322.0  343.0  362.0  384.0  360.0  419.0  387.0  387.0  382.0  377.0  430.0  329.0  379.0  399.0  377.0  416.0  400.0  403.0  385.0  0.15755273417974608  1,576 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.842447
2    0.912926
3    0.944517
4    0.961112
5    0.973208
6    0.979306
7    0.984205
8    0.987204
9    0.991003
10   0.993202

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.18003179535270206
RMSE: 0.424301538239849
LogLoss: 0.5753192832669145
Mean Per-Class Error: 0.16530951717703013
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    1.0   1.0    1.0   2.0    0.0    0.0898876404494382   8 / 89
0.0   83.0   0.0   0.0    2.0   1.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   2.0    0.0   7.0    2.0   0.0   0.0    3.0   0.0    1.0   0.0    0.0    0.2169811320754717   23 / 106
0.0   0.0    62.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0    5.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    1.0   2.0   1.0    0.0   1.0    0.0   0.0    0.0    0.24390243902439024  20 / 82
1.0   4.0    0.0   96.0   0.0   0.0   1.0   2.0   0.0   2.0    0.0   0.0   3.0   1.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0    0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    72.0  3.0   5.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    2.0   1.0    3.0   3.0   0.0    0.0   0.0    2.0   0.0    5.0    0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   87.0   0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0    0.0   3.0    3.0   0.0   0.0   1.0   0.0   0.0    3.0   3.0   0.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    82.0  1.0    2.0    0.18                 18 / 100
1.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0   0.0    0.0   2.0   0.0    3.0   1.0    0.0   97.0   0.0    0.09345794392523364  10 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   1.0   0.0    0.0   0.0    0.0   0.0    76.0   0.12643678160919541  11 / 87
93.0  112.0  66.0  113.0  89.0  91.0  95.0  78.0  83.0  106.0  98.0  95.0  96.0  101.0  83.0  109.0  98.0  110.0  79.0  91.0  100.0  87.0  102.0  97.0  115.0  103.0  0.1646586345381526   410 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835341
2    0.914056
3    0.94257
4    0.961044
5    0.971486
6    0.977912
7    0.981928
8    0.985141
9    0.98996
10   0.993173
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:29  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:29  18.369 sec  50035 obs/sec     1         1             10007      0.589817         1.0724              0.993816       0.277817                         0.591359           1.07951               0.993769         0.289558
    2019-07-24 14:06:31  20.077 sec  53887 obs/sec     10        10            100070     0.420492         0.563924            0.996857       0.157553                         0.424302           0.575319              0.996792         0.164659
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0872299
C13         0.938504               0.938504             0.0818656
C8          0.855778               0.855778             0.0746494
C12         0.848475               0.848475             0.0740124
C9          0.843558               0.843558             0.0735835
C7          0.803173               0.803173             0.0700607
C11         0.748373               0.748373             0.0652804
C5          0.72066                0.72066              0.0628631
C10         0.692997               0.692997             0.06045
C6          0.672651               0.672651             0.0586753
C14         0.650315               0.650315             0.0567269
C4          0.616849               0.616849             0.0538077
C16         0.604681               0.604681             0.0527463
C3          0.601345               0.601345             0.0524553
C2          0.444096               0.444096             0.0387385
C1          0.422506               0.422506             0.0368551
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_74

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009528673638783403  0.0002432226319797337  0.0         -0.016082119373322712  0.23758703470230103  0.23020401053554762   0.19285261631011963
    3        26       Softmax                      0.0   0.0   0.006636831427315953   0.022872179746627808   0.0         -0.2916381660882577    0.7334733009338379   -0.47654980453604756  0.24404442310333252


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17458047625627343
RMSE: 0.41782828561057644
LogLoss: 0.5735391842106211
Mean Per-Class Error: 0.16597961419507667
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    1.0    0.0    0.0    3.0    2.0    0.0    3.0    2.0    1.0    4.0    0.0    3.0    0.0    0.0    2.0    5.0    0.0    3.0    2.0    1.0    1.0    3.0    0.0    0.09113924050632911  36 / 395
0.0    333.0  0.0    4.0    2.0    1.0    1.0    8.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    1.0    2.0    8.0    9.0    0.0    0.0    3.0    0.0    4.0    1.0    0.0    0.13054830287206268  50 / 383
0.0    0.0    311.0  0.0    21.0   0.0    6.0    3.0    0.0    0.0    12.0   2.0    0.0    1.0    3.0    0.0    1.0    0.0    1.0    4.0    1.0    0.0    2.0    0.0    0.0    0.0    0.15489130434782608  57 / 368
1.0    29.0   0.0    335.0  0.0    0.0    0.0    6.0    1.0    2.0    3.0    0.0    5.0    7.0    2.0    1.0    0.0    3.0    5.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.1687344913151365   68 / 403
0.0    9.0    1.0    0.0    327.0  2.0    9.0    0.0    0.0    0.0    3.0    1.0    0.0    0.0    0.0    2.0    10.0   4.0    1.0    2.0    0.0    0.0    0.0    4.0    1.0    7.0    0.1462140992167102   56 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    7.0    0.0    0.0    1.0    0.0    10.0   0.0    2.0    0.0    0.0    7.0    0.0    0.0    2.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    4.0    0.0    5.0    5.0    0.0    0.0    0.0    2.0    2.0    7.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    4.0    6.0    1.0    0.0    0.0    342.0  5.0    2.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    7.0    0.0    8.0    17.0   0.0    9.0    1.0    0.0    337.0  1.0    0.14249363867684478  56 / 393
4.0    0.0    0.0    0.0    20.0   0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    25.0   3.0    0.0    0.0    0.0    1.0    1.0    297.0  0.1907356948228883   70 / 367
396.0  485.0  370.0  405.0  424.0  342.0  307.0  371.0  341.0  343.0  373.0  369.0  397.0  416.0  395.0  422.0  395.0  394.0  380.0  390.0  382.0  362.0  394.0  414.0  379.0  357.0  0.16525042487253824  1,653 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83475
2    0.910127
3    0.942517
4    0.960212
5    0.969109
6    0.976507
7    0.982505
8    0.986004
9    0.989503
10   0.991003

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.177262882121222
RMSE: 0.4210259874654081
LogLoss: 0.5803105919011736
Mean Per-Class Error: 0.16801626029949096
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12    13     14    15     16     17     18    19    20    21    22    23     24     25    Error                 Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  ----  -----  -----  ----  --------------------  -----------
81.0  0.0    0.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0   0.0   1.0   1.0   1.0    2.0    0.0   0.0898876404494382    8 / 89
0.0   85.0   0.0   2.0    1.0    1.0   1.0   3.0   1.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0    0.0    3.0    2.0   0.0   0.0   3.0   0.0   1.0    1.0    0.0   0.19811320754716982   21 / 106
0.0   0.0    67.0  0.0    5.0    0.0   3.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    2.0   0.0    0.0    0.0    1.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.18292682926829268   15 / 82
1.0   4.0    0.0   94.0   0.0    0.0   0.0   3.0   1.0   0.0   2.0   0.0   1.0   3.0    0.0   1.0    0.0    0.0    1.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.16071428571428573   18 / 112
0.0   2.0    0.0   0.0    81.0   2.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0    3.0    1.0    1.0   1.0   0.0   0.0   0.0   2.0    0.0    2.0   0.16494845360824742   16 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---   ---    ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0    2.0    0.0   0.0   0.0   0.0   88.0  0.0    0.0    0.0   0.043478260869565216  4 / 92
0.0   1.0    0.0   3.0    2.0    0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    0.0   0.0    1.0    2.0    1.0   0.0   0.0   0.0   0.0   84.0   2.0    0.0   0.16                  16 / 100
0.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    2.0    0.0    0.0   4.0   0.0   2.0   1.0   0.0    94.0   0.0   0.12149532710280374   13 / 107
1.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    3.0   1.0   0.0   0.0   0.0   1.0    1.0    71.0  0.1839080459770115    16 / 87
92.0  115.0  80.0  117.0  101.0  79.0  78.0  89.0  84.0  96.0  97.0  94.0  86.0  111.0  86.0  123.0  103.0  101.0  87.0  91.0  94.0  82.0  95.0  103.0  114.0  92.0  0.1670682730923695    416 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.832932
2    0.914458
3    0.944177
4    0.958233
5    0.96747
6    0.973092
7    0.983534
8    0.98755
9    0.988755
10   0.990361
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:08:03  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:08:03  1 min 52.317 sec  111188 obs/sec    1         1             10007      0.592661         1.10405             0.993758       0.292712                         0.594592           1.10872               0.9937           0.293976
    2019-07-24 14:08:04  1 min 53.029 sec  127640 obs/sec    10        10            100070     0.417828         0.573539            0.996898       0.16525                          0.421026           0.580311              0.996841         0.167068
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0906212
C13         0.924653               0.924653             0.0837931
C9          0.811372               0.811372             0.0735275
C8          0.748775               0.748775             0.0678549
C12         0.72816                0.72816              0.0659867
C10         0.723673               0.723673             0.0655801
C7          0.705573               0.705573             0.0639398
C5          0.698491               0.698491             0.0632981
C11         0.679659               0.679659             0.0615915
C6          0.664226               0.664226             0.060193
C4          0.639805               0.639805             0.0579799
C3          0.595077               0.595077             0.0539266
C2          0.569714               0.569714             0.0516282
C16         0.534015               0.534015             0.0483931
C14         0.527781               0.527781             0.0478282
C1          0.483971               0.483971             0.0438581
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_73

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.000977864885925328  0.000245368923060596  0.0         -0.007472341723769205  0.23479217290878296  0.22851117337064952   0.19932788610458374
    3        26       Softmax                      0.0   0.0   0.006523885074364863  0.018918819725513458  0.0         -0.30435658922739933   0.7258796691894531   -0.48526279777111025  0.25419092178344727


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17580179546857036
RMSE: 0.41928724696628966
LogLoss: 0.5783756365096131
Mean Per-Class Error: 0.165212579530786
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    6.0    1.0    2.0    0.0    6.0    0.0    0.0    0.0    4.0    0.0    1.0    3.0    2.0    1.0    4.0    3.0    0.09113924050632911  36 / 395
0.0    338.0  0.0    4.0    4.0    0.0    0.0    2.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    5.0    12.0   6.0    0.0    0.0    2.0    1.0    1.0    2.0    0.0    0.1174934725848564   45 / 383
0.0    0.0    316.0  0.0    6.0    0.0    5.0    0.0    0.0    0.0    24.0   1.0    1.0    0.0    7.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.13896457765667575  51 / 367
4.0    13.0   0.0    344.0  0.0    0.0    1.0    1.0    1.0    4.0    0.0    0.0    7.0    4.0    0.0    2.0    0.0    11.0   1.0    1.0    0.0    0.0    0.0    6.0    0.0    3.0    0.14640198511166252  59 / 403
0.0    4.0    10.0   0.0    315.0  1.0    15.0   2.0    0.0    0.0    2.0    4.0    0.0    0.0    0.0    0.0    3.0    3.0    9.0    3.0    0.0    0.0    0.0    3.0    0.0    10.0   0.1796875            69 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    15.0   2.0    1.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    349.0  0.0    0.0    0.0    0.07180851063829788  27 / 376
0.0    1.0    0.0    6.0    7.0    0.0    0.0    0.0    3.0    2.0    4.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    4.0    3.0    0.0    0.0    0.0    354.0  3.0    3.0    0.10152284263959391  40 / 394
0.0    0.0    0.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    2.0    6.0    0.0    2.0    8.0    0.0    6.0    0.0    0.0    355.0  0.0    0.09669211195928754  38 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    32.0   3.0    0.0    0.0    0.0    5.0    0.0    293.0  0.2016348773841962   74 / 367
392.0  476.0  372.0  426.0  409.0  343.0  346.0  312.0  336.0  364.0  368.0  364.0  412.0  397.0  391.0  423.0  370.0  425.0  398.0  372.0  384.0  353.0  401.0  424.0  394.0  351.0  0.16425072478256522  1,643 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835749
2    0.910727
3    0.939618
4    0.956013
5    0.96791
6    0.975807
7    0.980806
8    0.985104
9    0.988603
10   0.991403

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17664889741844167
RMSE: 0.42029620200335105
LogLoss: 0.583302044743455
Mean Per-Class Error: 0.1672132300091649
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13     14    15     16    17     18     19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0   2.0   1.0   0.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   85.0   0.0   1.0    3.0    0.0   0.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   1.0    1.0   3.0    3.0    0.0   0.0   2.0   1.0   1.0    1.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    70.0  0.0    0.0    0.0   1.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    2.0    0.0   0.0   0.0   1.0   0.0    0.0    0.0   0.14634146341463414  12 / 82
3.0   1.0    0.0   94.0   0.0    0.0   1.0   1.0   0.0   2.0    0.0   0.0   3.0   1.0    0.0   2.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   2.0    0.0    1.0   0.16071428571428573  18 / 112
0.0   0.0    4.0   0.0    78.0   1.0   4.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    3.0    1.0   0.0   0.0   0.0   1.0    0.0    3.0   0.1958762886597938   19 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   0.0    0.0   0.0    0.0   0.0    0.0    0.0   1.0   0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   3.0    3.0    0.0   0.0   0.0   0.0   0.0    2.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   87.0   1.0    1.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    2.0   1.0    1.0   0.0    0.0    1.0   0.0   3.0   0.0   0.0    97.0   0.0   0.09345794392523364  10 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    6.0    0.0   0.0   0.0   0.0   2.0    0.0    69.0  0.20689655172413793  18 / 87
95.0  111.0  84.0  117.0  100.0  80.0  88.0  75.0  80.0  110.0  92.0  95.0  87.0  108.0  83.0  118.0  92.0  106.0  104.0  88.0  97.0  81.0  98.0  102.0  111.0  88.0  0.16626506024096385  414 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.833735
2    0.91245
3    0.939759
4    0.955823
5    0.96988
6    0.975904
7    0.980723
8    0.984739
9    0.988353
10   0.991566
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:08:02  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:08:02  1 min 51.441 sec  95304 obs/sec     1         1             10007      0.593287         1.10361             0.993744       0.295111                         0.595058           1.11302               0.993691         0.30241
    2019-07-24 14:08:03  1 min 52.196 sec  118566 obs/sec    10        10            100070     0.419287         0.578376            0.996876       0.164251                         0.420296           0.583302              0.996852         0.166265
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0874731
C15         0.969633               0.969633             0.0848167
C12         0.898027               0.898027             0.0785532
C9          0.837552               0.837552             0.0732632
C7          0.800431               0.800431             0.0700162
C8          0.790536               0.790536             0.0691506
C5          0.739476               0.739476             0.0646842
C6          0.694388               0.694388             0.0607402
C11         0.681652               0.681652             0.0596262
C10         0.648901               0.648901             0.0567614
C14         0.638994               0.638994             0.0558948
C4          0.599049               0.599049             0.0524007
C16         0.595089               0.595089             0.0520543
C3          0.564139               0.564139             0.049347
C2          0.49735                0.49735              0.0435047
C1          0.476875               0.476875             0.0417138
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_61

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms         mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -----------------  -------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  25.0       0.0   0.0   0.0017026840268670185  0.0004178981762379408  0.0         0.005849595345204239    0.474234938621521  -0.0370100178295081  0.4984903335571289
    3        26       Softmax                 0.0   0.0   0.0021456825865103523  0.0005883367266505957  0.0         -0.0032409957080272553  0.408237099647522  -0.4929250295070938  0.18508249521255493


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1675327676182201
RMSE: 0.4093076686530807
LogLoss: 0.5706591416851323
Mean Per-Class Error: 0.1691834664652469
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    2.0    3.0    0.0    5.0    0.0    1.0    0.0    0.0    2.0    2.0    3.0    3.0    0.0    1.0    1.0    4.0    4.0    0.08607594936708861  34 / 395
0.0    340.0  0.0    3.0    4.0    1.0    1.0    2.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    21.0   3.0    0.0    0.0    0.0    1.0    2.0    0.0    0.0    0.1122715404699739   43 / 383
0.0    0.0    308.0  0.0    4.0    1.0    19.0   1.0    0.0    0.0    12.0   2.0    0.0    0.0    4.0    0.0    1.0    2.0    0.0    5.0    3.0    0.0    5.0    0.0    0.0    1.0    0.16304347826086957  60 / 368
2.0    24.0   0.0    346.0  0.0    1.0    0.0    4.0    0.0    1.0    2.0    0.0    4.0    2.0    2.0    1.0    0.0    2.0    0.0    2.0    4.0    0.0    0.0    4.0    0.0    1.0    0.13930348258706468  56 / 402
0.0    12.0   1.0    0.0    291.0  2.0    15.0   1.0    1.0    0.0    9.0    1.0    0.0    0.0    0.0    1.0    11.0   3.0    1.0    7.0    0.0    0.0    0.0    5.0    0.0    23.0   0.2421875            93 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    3.0    0.0    0.0    7.0    0.0    0.0    9.0    1.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    4.0    0.0    5.0    2.0    1.0    0.0    2.0    5.0    1.0    9.0    2.0    0.0    0.0    2.0    0.0    5.0    3.0    2.0    6.0    2.0    0.0    0.0    334.0  4.0    5.0    0.15228426395939088  60 / 394
0.0    0.0    0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    5.0    0.0    3.0    13.0   4.0    11.0   2.0    1.0    348.0  0.0    0.11450381679389313  45 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    12.0   6.0    0.0    0.0    0.0    0.0    0.0    319.0  0.1307901907356948   48 / 367
396.0  528.0  330.0  424.0  359.0  350.0  393.0  281.0  344.0  360.0  373.0  342.0  398.0  379.0  386.0  388.0  379.0  445.0  274.0  444.0  432.0  357.0  422.0  397.0  409.0  413.0  0.16814955513345997  1,682 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83185
2    0.907328
3    0.941418
4    0.958512
5    0.968809
6    0.975607
7    0.980506
8    0.983305
9    0.986504
10   0.989203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1706809462560016
RMSE: 0.41313550592511605
LogLoss: 0.584054697892087
Mean Per-Class Error: 0.16671855790296788
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19     20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  -----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0    1.0    0.0   0.0    0.0   2.0    1.0    0.07865168539325842  7 / 89
0.0   89.0   0.0   1.0    2.0   1.0   1.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   1.0    0.0    7.0    1.0   0.0    0.0    0.0   1.0    1.0   0.0    0.0    0.16037735849056603  17 / 106
0.0   0.0    67.0  0.0    1.0   0.0   4.0   0.0   0.0   0.0    1.0   1.0   0.0   0.0    2.0   0.0    1.0    0.0    0.0   3.0    0.0    0.0   2.0    0.0   0.0    0.0    0.18292682926829268  15 / 82
1.0   3.0    0.0   99.0   0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   1.0    1.0   1.0    0.0    0.0    0.0   0.0    0.0    0.0   0.0    1.0   0.0    1.0    0.11607142857142858  13 / 112
0.0   3.0    0.0   0.0    69.0  0.0   6.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    2.0    1.0    1.0   2.0    0.0    0.0   0.0    1.0   0.0    8.0    0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---    ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0    4.0    0.0   86.0   0.0   0.0    0.0    0.06521739130434782  6 / 92
0.0   2.0    0.0   3.0    1.0   1.0   0.0   1.0   2.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    1.0    3.0    0.0   0.0    1.0    0.0   0.0    78.0  2.0    2.0    0.22                 22 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    2.0    0.0    1.0   2.0    2.0    3.0   2.0    0.0   94.0   0.0    0.12149532710280374  13 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   2.0    0.0    0.0   0.0    0.0   0.0    77.0   0.11494252873563218  10 / 87
92.0  133.0  68.0  122.0  86.0  77.0  98.0  65.0  86.0  105.0  91.0  94.0  87.0  103.0  78.0  112.0  101.0  111.0  72.0  105.0  111.0  79.0  108.0  88.0  115.0  103.0  0.1650602409638554   411 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83494
2    0.905221
3    0.942972
4    0.957831
5    0.96988
6    0.974297
7    0.977912
8    0.982731
9    0.986747
10   0.990362
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:46  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:46  1 min 35.055 sec  49539 obs/sec     1         1             10007      0.54988          0.995038            0.994627       0.26592                          0.549776           0.990389              0.994614         0.274297
    2019-07-24 14:07:48  1 min 36.828 sec  51635 obs/sec     10        10            100070     0.409308         0.570659            0.997023       0.16815                          0.413136           0.584055              0.996959         0.16506
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0865857
C15         0.962948               0.962948             0.0833775
C12         0.876536               0.876536             0.0758955
C9          0.871334               0.871334             0.075445
C8          0.846165               0.846165             0.0732658
C7          0.794025               0.794025             0.0687512
C11         0.768542               0.768542             0.0665447
C14         0.684827               0.684827             0.0592962
C10         0.668195               0.668195             0.0578561
C5          0.647934               0.647934             0.0561019
C6          0.645115               0.645115             0.0558577
C16         0.632506               0.632506             0.054766
C3          0.622553               0.622553             0.0539042
C4          0.55065                0.55065              0.0476784
C2          0.503023               0.503023             0.0435546
C1          0.474901               0.474901             0.0411197
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_48

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.001029010759339144  0.0002721358323469758  0.0         -0.010236303124173673  0.2354830503463745  0.2642915820588041   0.1961537003517151
    3        26       Softmax                      0.0   0.0   0.007221200523627676  0.03508521616458893    0.0         -0.26801767593832876   0.7225255966186523  -0.4697698735210579  0.18249177932739258


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17625476001020043
RMSE: 0.4198270596450405
LogLoss: 0.5774013555183233
Mean Per-Class Error: 0.1670278154868045
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    1.0    6.0    0.0    2.0    0.0    0.0    0.0    4.0    1.0    1.0    1.0    2.0    3.0    5.0    2.0    0.09367088607594937  37 / 395
0.0    327.0  0.0    10.0   2.0    0.0    2.0    2.0    2.0    0.0    2.0    1.0    0.0    0.0    1.0    1.0    0.0    21.0   9.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.1462140992167102   56 / 383
0.0    0.0    303.0  1.0    14.0   0.0    8.0    3.0    0.0    0.0    19.0   0.0    2.0    0.0    6.0    0.0    1.0    1.0    0.0    2.0    4.0    1.0    3.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
0.0    13.0   0.0    344.0  0.0    0.0    1.0    3.0    0.0    6.0    0.0    1.0    6.0    4.0    0.0    2.0    1.0    12.0   0.0    0.0    1.0    0.0    0.0    4.0    0.0    5.0    0.14640198511166252  59 / 403
0.0    9.0    4.0    1.0    299.0  3.0    22.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    14.0   1.0    1.0    0.0    0.0    8.0    0.0    11.0   0.22135416666666666  85 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    0.0    7.0    1.0    3.0    0.0    0.0    8.0    0.0    0.0    6.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    2.0    0.0    3.0    6.0    0.0    0.0    1.0    2.0    3.0    6.0    0.0    0.0    0.0    2.0    1.0    5.0    0.0    2.0    2.0    1.0    0.0    0.0    353.0  2.0    3.0    0.10406091370558376  41 / 394
0.0    0.0    0.0    3.0    0.0    5.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    10.0   0.0    7.0    2.0    0.0    354.0  1.0    0.09693877551020408  38 / 392
1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    3.0    1.0    15.0   2.0    0.0    0.0    0.0    3.0    0.0    331.0  0.09809264305177112  36 / 367
399.0  449.0  344.0  425.0  404.0  352.0  348.0  300.0  337.0  365.0  365.0  358.0  406.0  392.0  363.0  378.0  359.0  477.0  353.0  363.0  410.0  360.0  411.0  449.0  431.0  405.0  0.16625012496251124  1,663 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.83375
2    0.909627
3    0.939018
4    0.956713
5    0.96801
6    0.976107
7    0.981006
8    0.985305
9    0.988703
10   0.992002

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17886503504328108
RMSE: 0.4229243845456077
LogLoss: 0.5902465690017524
Mean Per-Class Error: 0.1678429972347176
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    1.0    3.0    0.0    0.0898876404494382   8 / 89
0.0   84.0   0.0   3.0    1.0   0.0   1.0   1.0   1.0   0.0    0.0   0.0   0.0   0.0    1.0   0.0    0.0   9.0    2.0   0.0   0.0    2.0   0.0    1.0    0.0    0.0    0.20754716981132076  22 / 106
0.0   0.0    65.0  0.0    3.0   0.0   3.0   0.0   0.0   0.0    3.0   0.0   1.0   0.0    4.0   0.0    0.0   0.0    0.0   1.0   0.0    1.0   1.0    0.0    0.0    0.0    0.2073170731707317   17 / 82
0.0   1.0    0.0   95.0   0.0   0.0   1.0   2.0   0.0   2.0    0.0   0.0   2.0   2.0    0.0   2.0    0.0   2.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    1.0    0.15178571428571427  17 / 112
0.0   2.0    0.0   0.0    79.0  1.0   5.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    4.0   0.0   0.0    0.0   0.0    2.0    0.0    2.0    0.18556701030927836  18 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   2.0    0.0   87.0   0.0    0.0    0.0    0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0   0.0   0.0    0.0   0.0    89.0   0.0    1.0    0.11                 11 / 100
0.0   0.0    0.0   2.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0   0.0    0.0   1.0   0.0    3.0   1.0    0.0    97.0   0.0    0.09345794392523364  10 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    81.0   0.06896551724137931  6 / 87
95.0  111.0  72.0  120.0  97.0  79.0  92.0  75.0  82.0  110.0  86.0  95.0  92.0  103.0  75.0  109.0  92.0  118.0  85.0  82.0  102.0  82.0  101.0  113.0  120.0  102.0  0.16626506024096385  414 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.833735
2    0.914859
3    0.938554
4    0.954217
5    0.965462
6    0.974699
7    0.979518
8    0.984337
9    0.988353
10   0.991165
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:29  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:29  1 min 17.915 sec  104239 obs/sec    1         1             10007      0.604102         1.15078             0.993514       0.309807                         0.603816           1.14246               0.993503         0.313253
    2019-07-24 14:07:29  1 min 18.654 sec  122334 obs/sec    10        10            100070     0.419827         0.577401            0.996868       0.16625                          0.422924           0.590247              0.996813         0.166265
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0911124
C13         0.941294               0.941294             0.0857635
C9          0.848439               0.848439             0.0773033
C8          0.80293                0.80293              0.0731569
C7          0.796616               0.796616             0.0725816
C12         0.746344               0.746344             0.0680012
C11         0.697013               0.697013             0.0635065
C5          0.690012               0.690012             0.0628686
C10         0.669546               0.669546             0.0610039
C6          0.619684               0.619684             0.0564609
C14         0.597993               0.597993             0.0544846
C4          0.582726               0.582726             0.0530935
C16         0.542664               0.542664             0.0494434
C3          0.541269               0.541269             0.0493163
C1          0.480133               0.480133             0.0437461
C2          0.418795               0.418795             0.0381574
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_38

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0015110077772249042  0.0003900033188983798  0.0         0.004684071892796737   0.4283638000488281  -0.00821054125603251  0.48101699352264404
    3        26       Softmax                 0.0   0.0   0.0026417151427897178  0.0010687005706131458  0.0         -0.027055866843458995  0.5648767948150635  -0.5130643717593824   0.18709558248519897


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17088790941620458
RMSE: 0.4133859085844661
LogLoss: 0.5745935408964344
Mean Per-Class Error: 0.16435587300776283
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
367.0  0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    2.0    4.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    4.0    1.0    1.0    0.0    6.0    3.0    0.07088607594936709  28 / 395
0.0    311.0  0.0    7.0    3.0    4.0    2.0    12.0   1.0    0.0    3.0    1.0    0.0    0.0    4.0    2.0    3.0    9.0    6.0    1.0    0.0    9.0    0.0    3.0    2.0    0.0    0.18798955613577023  72 / 383
0.0    3.0    300.0  1.0    12.0   1.0    22.0   1.0    0.0    0.0    13.0   0.0    0.0    0.0    2.0    0.0    1.0    2.0    5.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
3.0    8.0    0.0    335.0  0.0    0.0    0.0    6.0    0.0    11.0   4.0    0.0    6.0    2.0    3.0    6.0    0.0    7.0    6.0    0.0    2.0    0.0    0.0    3.0    0.0    0.0    0.16666666666666666  67 / 402
0.0    8.0    1.0    0.0    311.0  5.0    17.0   2.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    5.0    2.0    5.0    4.0    1.0    0.0    0.0    7.0    0.0    12.0   0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    0.0    0.0    0.0    13.0   1.0    5.0    0.0    0.0    0.0    0.0    0.0    9.0    4.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    2.0    0.0    5.0    3.0    2.0    0.0    1.0    1.0    2.0    6.0    0.0    0.0    0.0    2.0    0.0    2.0    1.0    4.0    2.0    2.0    0.0    0.0    353.0  4.0    1.0    0.10178117048346055  40 / 393
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    6.0    0.0    0.0    11.0   4.0    14.0   1.0    0.0    349.0  1.0    0.11195928753180662  44 / 393
3.0    0.0    0.0    0.0    13.0   2.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    38.0   6.0    0.0    0.0    0.0    1.0    0.0    288.0  0.21525885558583105  79 / 367
402.0  441.0  338.0  404.0  400.0  372.0  380.0  333.0  325.0  387.0  365.0  348.0  408.0  377.0  389.0  401.0  375.0  431.0  377.0  383.0  424.0  391.0  371.0  422.0  415.0  344.0  0.16335099470158954  1,634 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.836649
2    0.909527
3    0.940618
4    0.957413
5    0.96761
6    0.974708
7    0.980406
8    0.984405
9    0.987404
10   0.989903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17695892565905846
RMSE: 0.42066486145036935
LogLoss: 0.5912952108749503
Mean Per-Class Error: 0.1694649746049441
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16    17     18    19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0   1.0    0.0   1.0   0.0    2.0    1.0   0.06741573033707865  6 / 89
0.0   80.0   0.0   2.0    2.0   0.0   1.0   5.0   0.0   0.0    0.0   0.0   0.0   0.0   2.0   1.0    0.0   3.0    4.0   0.0   0.0    4.0   0.0   1.0    1.0    0.0   0.24528301886792453  26 / 106
0.0   2.0    64.0  0.0    3.0   0.0   8.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   2.0   0.0    1.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   0.21951219512195122  18 / 82
2.0   2.0    0.0   88.0   0.0   0.0   0.0   2.0   0.0   4.0    2.0   0.0   3.0   1.0   0.0   2.0    0.0   2.0    2.0   0.0   1.0    0.0   0.0   1.0    0.0    0.0   0.21428571428571427  24 / 112
0.0   0.0    0.0   0.0    74.0  2.0   5.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    1.0   2.0   0.0    0.0   0.0   3.0    0.0    5.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   3.0    1.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   3.0    1.0   1.0   0.0   1.0   0.0   1.0    2.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    1.0   0.0   1.0    0.0   0.0   87.0   0.0    0.0   0.13                 13 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    2.0   0.0    0.0   2.0   2.0    4.0   1.0   0.0    94.0   0.0   0.12149532710280374  13 / 107
2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    8.0   2.0   0.0    0.0   0.0   1.0    0.0    68.0  0.21839080459770116  19 / 87
94.0  112.0  71.0  108.0  92.0  84.0  94.0  88.0  74.0  115.0  93.0  86.0  89.0  99.0  77.0  118.0  99.0  110.0  98.0  84.0  108.0  95.0  91.0  107.0  118.0  86.0  0.16907630522088354  421 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.830924
2    0.908032
3    0.941767
4    0.959036
5    0.967068
6    0.974699
7    0.978715
8    0.982731
9    0.985542
10   0.989157
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:13  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:13  1 min  2.431 sec  80701 obs/sec     1         1             10007      0.589652         1.1053              0.99382        0.290513                         0.589525           1.10405               0.993807         0.300402
    2019-07-24 14:07:14  1 min  3.597 sec  78733 obs/sec     10        10            100070     0.413386         0.574594            0.996962       0.163351                         0.420665           0.591295              0.996847         0.169076
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0898314
C15         0.998551               0.998551             0.0897013
C12         0.985737               0.985737             0.0885502
C9          0.905562               0.905562             0.081348
C8          0.833484               0.833484             0.0748731
C11         0.756286               0.756286             0.0679382
C10         0.740175               0.740175             0.066491
C6          0.673051               0.673051             0.0604611
C7          0.663844               0.663844             0.059634
C16         0.655557               0.655557             0.0588896
C14         0.63864                0.63864              0.05737
C5          0.566411               0.566411             0.0508815
C4          0.505421               0.505421             0.0454027
C3          0.464722               0.464722             0.0417467
C1          0.39461                0.39461              0.0354484
C2          0.349908               0.349908             0.0314328
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_36

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.000984081982863927   0.00024295999901369214  0.0         -0.01627753929053455  0.23516815900802612  0.24696205358078288   0.20066899061203003
    3        26       Softmax                      0.0   0.0   0.0067851595503130874  0.0251346156001091      0.0         -0.31913324900478285  0.7284646034240723   -0.49508664502813704  0.2467619776725769


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1733647948980498
RMSE: 0.41637098229589653
LogLoss: 0.5751054196291422
Mean Per-Class Error: 0.16182254679295058
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                 Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  --------------------  --------------
350.0  0.0    0.0    0.0    0.0    0.0    2.0    3.0    0.0    3.0    4.0    1.0    6.0    0.0    4.0    0.0    0.0    3.0    5.0    1.0    2.0    2.0    1.0    5.0    3.0    0.0    0.11392405063291139   45 / 395
0.0    339.0  0.0    6.0    1.0    0.0    3.0    2.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    11.0   12.0   0.0    0.0    2.0    0.0    1.0    1.0    0.0    0.11488250652741515   44 / 383
0.0    0.0    321.0  0.0    9.0    1.0    0.0    0.0    0.0    0.0    20.0   2.0    0.0    0.0    4.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.12771739130434784   47 / 368
0.0    21.0   0.0    349.0  0.0    0.0    0.0    3.0    0.0    1.0    3.0    1.0    7.0    4.0    2.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    0.0    4.0    0.0    2.0    0.13399503722084366   54 / 403
0.0    10.0   2.0    0.0    307.0  8.0    14.0   0.0    0.0    0.0    3.0    4.0    0.0    0.0    0.0    1.0    10.0   4.0    8.0    2.0    0.0    0.0    0.0    5.0    0.0    6.0    0.20052083333333334   77 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                   ---
0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    5.0    0.0    353.0  0.0    0.0    0.0    0.061170212765957445  23 / 376
1.0    2.0    0.0    5.0    9.0    0.0    0.0    2.0    1.0    1.0    9.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    10.0   0.0    1.0    0.0    0.0    344.0  2.0    3.0    0.12468193384223919   49 / 393
0.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    0.0    5.0    27.0   2.0    28.0   1.0    0.0    315.0  0.0    0.1984732824427481    78 / 393
1.0    1.0    0.0    0.0    15.0   0.0    0.0    0.0    1.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    0.0    37.0   2.0    0.0    0.0    0.0    3.0    0.0    291.0  0.20708446866485014   76 / 367
386.0  487.0  377.0  417.0  391.0  386.0  311.0  320.0  348.0  360.0  405.0  361.0  411.0  380.0  387.0  371.0  352.0  440.0  444.0  387.0  386.0  388.0  430.0  407.0  344.0  327.0  0.1613515945216435    1,614 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.838648
2    0.914426
3    0.941917
4    0.957313
5    0.969409
6    0.975207
7    0.980506
8    0.984605
9    0.987804
10   0.989803

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17857260113157378
RMSE: 0.42257851475385466
LogLoss: 0.5949565101169434
Mean Per-Class Error: 0.17207049471682587
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20    21    22     23    24     25    Error                 Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  -----  ----  --------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   3.0   0.0   0.0    0.0    0.0   3.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   0.0   0.0   0.0    1.0   2.0    0.0   0.12359550561797752   11 / 89
0.0   86.0   0.0   1.0    1.0   0.0   1.0   1.0   1.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    1.0   4.0    4.0    0.0   0.0   2.0   0.0    1.0   1.0    0.0   0.18867924528301888   20 / 106
0.0   0.0    69.0  0.0    3.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0    0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.15853658536585366   13 / 82
0.0   3.0    0.0   98.0   0.0   0.0   0.0   2.0   0.0   0.0    1.0    1.0   3.0   1.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0    1.0   0.0    1.0   0.125                 14 / 112
0.0   1.0    0.0   0.0    72.0  5.0   4.0   0.0   0.0   0.0    1.0    1.0   0.0   0.0   0.0   0.0    3.0   1.0    4.0    0.0   0.0   0.0   0.0    1.0   0.0    4.0   0.25773195876288657   25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---    ---   ---                   ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0    0.0   2.0   0.0   88.0   0.0   0.0    0.0   0.043478260869565216  4 / 92
0.0   0.0    0.0   3.0    4.0   0.0   0.0   1.0   0.0   1.0    3.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0    82.0  0.0    1.0   0.18                  18 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   5.0    0.0   0.0    1.0    7.0   0.0   6.0   1.0    0.0   87.0   0.0   0.18691588785046728   20 / 107
1.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   2.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    9.0    0.0   0.0   0.0   0.0    1.0   0.0    69.0  0.20689655172413793   18 / 87
90.0  126.0  82.0  118.0  92.0  89.0  78.0  80.0  78.0  105.0  100.0  93.0  93.0  99.0  80.0  109.0  93.0  107.0  117.0  89.0  97.0  86.0  105.0  99.0  102.0  83.0  0.1714859437751004    427 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.828514
2    0.914458
3    0.938153
4    0.955422
5    0.967068
6    0.974297
7    0.978313
8    0.981124
9    0.984337
10   0.987148
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:10  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:10  59.713 sec        105336 obs/sec    1         1             10007      0.593021         1.11133             0.993751       0.282615                         0.593668           1.11628               0.99372          0.284337
    2019-07-24 14:07:11  1 min  0.454 sec  122484 obs/sec    10        10            100070     0.416371         0.575105            0.996919       0.161352                         0.422579           0.594957              0.996818         0.171486
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0850923
C13         0.925985               0.925985             0.0787942
C12         0.878686               0.878686             0.0747694
C8          0.856522               0.856522             0.0728835
C7          0.834784               0.834784             0.0710337
C11         0.788839               0.788839             0.0671242
C9          0.770544               0.770544             0.0655673
C5          0.735616               0.735616             0.0625952
C10         0.700103               0.700103             0.0595734
C6          0.696999               0.696999             0.0593092
C14         0.679331               0.679331             0.0578058
C3          0.631891               0.631891             0.053769
C16         0.61494                0.61494              0.0523266
C4          0.588978               0.588978             0.0501175
C1          0.525028               0.525028             0.0446758
C2          0.523699               0.523699             0.0445628
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_32

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  10.0       0.0   0.0   0.0009989502935354722  0.00025864713825285435  0.0         -0.00531211872352344  0.2294600009918213  0.2567921222096061   0.18721020221710205
    3        26       Softmax                      0.0   0.0   0.005443105779319852   0.016036882996559143    0.0         -0.28783045554342396  0.7100660800933838  -0.4984172160571227  0.2163238525390625


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17750661705756707
RMSE: 0.4213153415881827
LogLoss: 0.5850980311210161
Mean Per-Class Error: 0.1716989388001366
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    5.0    2.0    5.0    1.0    1.0    1.0    0.0    2.0    5.0    4.0    2.0    2.0    3.0    6.0    2.0    0.0    0.11392405063291139  45 / 395
0.0    329.0  0.0    6.0    3.0    0.0    0.0    6.0    1.0    0.0    4.0    0.0    0.0    0.0    4.0    3.0    1.0    11.0   12.0   0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.1387434554973822   53 / 382
0.0    0.0    305.0  0.0    16.0   0.0    9.0    1.0    0.0    0.0    16.0   2.0    1.0    0.0    4.0    0.0    2.0    0.0    2.0    2.0    2.0    0.0    5.0    0.0    0.0    0.0    0.16893732970027248  62 / 367
2.0    20.0   0.0    350.0  0.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    7.0    3.0    3.0    1.0    0.0    8.0    2.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.1315136476426799   53 / 403
0.0    7.0    1.0    0.0    320.0  5.0    15.0   0.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0    0.0    3.0    3.0    8.0    2.0    0.0    0.0    0.0    5.0    0.0    10.0   0.16666666666666666  64 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    2.0    0.0    0.0    1.0    9.0    0.0    0.0    0.0    0.0    9.0    0.0    5.0    0.0    0.0    4.0    0.0    0.0    3.0    0.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    2.0    0.0    4.0    6.0    1.0    0.0    3.0    2.0    1.0    3.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0    9.0    1.0    1.0    0.0    0.0    350.0  2.0    5.0    0.1116751269035533   44 / 394
1.0    0.0    0.0    3.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    2.0    14.0   1.0    23.0   1.0    1.0    329.0  0.0    0.1628498727735369   64 / 393
0.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    32.0   3.0    0.0    0.0    0.0    2.0    0.0    297.0  0.1907356948228883   70 / 367
391.0  476.0  346.0  431.0  422.0  378.0  345.0  328.0  340.0  344.0  389.0  351.0  411.0  379.0  409.0  401.0  316.0  430.0  421.0  374.0  402.0  374.0  398.0  431.0  375.0  341.0  0.1709487153853844   1,710 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.829051
2    0.907728
3    0.940318
4    0.956713
5    0.969209
6    0.976407
7    0.981706
8    0.986504
9    0.989403
10   0.993802

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.179506223725125
RMSE: 0.42368174816142956
LogLoss: 0.5950610895256595
Mean Per-Class Error: 0.1738113848760846
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9      10    11    12    13    14    15     16    17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   1.0    1.0    0.0   1.0    0.0   1.0   2.0    2.0    0.0   0.11235955056179775  10 / 89
0.0   86.0   0.0   2.0    2.0    0.0   0.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0   2.0   1.0    0.0   6.0    3.0    0.0   0.0    0.0   1.0   1.0    0.0    0.0   0.18867924528301888  20 / 106
0.0   0.0    62.0  0.0    3.0    0.0   5.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   2.0   0.0    1.0   0.0    2.0    1.0   1.0    0.0   2.0   0.0    0.0    0.0   0.24390243902439024  20 / 82
1.0   4.0    0.0   96.0   0.0    0.0   0.0   1.0   0.0   0.0    1.0   0.0   3.0   1.0   0.0   1.0    0.0   1.0    1.0    0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.14285714285714285  16 / 112
0.0   0.0    0.0   0.0    77.0   3.0   5.0   0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0    3.0    0.0   0.0    0.0   0.0   2.0    0.0    5.0   0.20618556701030927  20 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0    0.0   0.0   3.0   0.0   0.0   0.0    0.0   1.0    0.0    0.0   0.0    0.0   87.0  0.0    0.0    0.0   0.05434782608695652  5 / 92
0.0   0.0    0.0   2.0    3.0    1.0   0.0   2.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    3.0    0.0   0.0    0.0   0.0   86.0   0.0    1.0   0.14                 14 / 100
1.0   0.0    0.0   1.0    0.0    2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0    0.0    3.0   0.0    8.0   1.0   0.0    89.0   0.0   0.16822429906542055  18 / 107
0.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    4.0    1.0   0.0    0.0   0.0   1.0    0.0    72.0  0.1724137931034483   15 / 87
89.0  116.0  70.0  123.0  100.0  84.0  86.0  82.0  82.0  103.0  96.0  93.0  91.0  99.0  85.0  114.0  83.0  111.0  110.0  88.0  103.0  83.0  98.0  104.0  109.0  88.0  0.17309236947791165  431 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826908
2    0.904418
3    0.939357
4    0.954619
5    0.968675
6    0.974699
7    0.978715
8    0.983534
9    0.986345
10   0.991566
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:06  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:06  54.938 sec  98107 obs/sec     1         1             10007      0.599838         1.13463             0.993605       0.295711                         0.596323           1.12368               0.993664         0.291165
    2019-07-24 14:07:06  55.664 sec  123390 obs/sec    10        10            100070     0.421315         0.585098            0.996845       0.170949                         0.423682           0.595061              0.996801         0.173092
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0910119
C13         0.947095               0.947095             0.086197
C8          0.831711               0.831711             0.0756956
C9          0.792092               0.792092             0.0720898
C12         0.789485               0.789485             0.0718525
C7          0.778091               0.778091             0.0708155
C11         0.735662               0.735662             0.066954
C5          0.658157               0.658157             0.0599002
C6          0.616291               0.616291             0.0560899
C3          0.604494               0.604494             0.0550162
C10         0.592277               0.592277             0.0539043
C14         0.570298               0.570298             0.0519039
C16         0.563792               0.563792             0.0513118
C4          0.545106               0.545106             0.0496112
C2          0.483672               0.483672             0.0440199
C1          0.479348               0.479348             0.0436264
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_56

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  10.0       0.0   0.0   0.0014348316157395402  0.00041440362110733986  0.0         0.013350254479973955   0.4325380325317383  0.036608016812408946  0.43985652923583984
    3        26       Softmax                 0.0   0.0   0.002482348659703768   0.0009961696341633797   0.0         -0.004389057325126417  0.5699658393859863  -0.5315288588726724   0.2246401309967041


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.1740148734553312
RMSE: 0.41715090010130773
LogLoss: 0.5966015699339889
Mean Per-Class Error: 0.16539019316307735
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    2.0    6.0    0.0    5.0    0.0    3.0    1.0    0.0    1.0    4.0    1.0    3.0    0.0    3.0    2.0    0.09113924050632911  36 / 395
0.0    307.0  0.0    7.0    7.0    3.0    1.0    6.0    2.0    0.0    1.0    0.0    0.0    0.0    3.0    3.0    1.0    32.0   3.0    0.0    0.0    1.0    0.0    4.0    2.0    0.0    0.19843342036553524  76 / 383
0.0    0.0    314.0  1.0    15.0   1.0    7.0    1.0    0.0    0.0    9.0    1.0    0.0    0.0    1.0    0.0    2.0    0.0    6.0    1.0    6.0    0.0    3.0    0.0    0.0    0.0    0.14673913043478262  54 / 368
1.0    12.0   0.0    348.0  0.0    0.0    0.0    6.0    0.0    3.0    2.0    0.0    2.0    6.0    9.0    3.0    0.0    4.0    1.0    0.0    2.0    0.0    0.0    2.0    0.0    2.0    0.13647642679900746  55 / 403
0.0    4.0    2.0    0.0    301.0  6.0    15.0   1.0    2.0    0.0    4.0    1.0    0.0    0.0    0.0    1.0    9.0    5.0    3.0    8.0    0.0    0.0    0.0    6.0    0.0    15.0   0.21409921671018275  82 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    4.0    0.0    0.0    1.0    3.0    0.0    0.0    5.0    0.0    4.0    1.0    1.0    0.0    1.0    4.0    0.0    0.0    2.0    0.0    350.0  0.0    0.0    0.0    0.06914893617021277  26 / 376
0.0    2.0    0.0    4.0    9.0    0.0    0.0    3.0    2.0    1.0    11.0   0.0    0.0    0.0    2.0    0.0    4.0    5.0    11.0   6.0    1.0    0.0    0.0    324.0  6.0    3.0    0.17766497461928935  70 / 394
1.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    1.0    2.0    0.0    1.0    10.0   0.0    13.0   1.0    0.0    358.0  1.0    0.089058524173028    35 / 393
1.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    5.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    15.0   6.0    0.0    0.0    0.0    1.0    0.0    322.0  0.12021857923497267  44 / 366
393.0  414.0  351.0  435.0  420.0  348.0  360.0  317.0  337.0  359.0  380.0  351.0  386.0  374.0  395.0  388.0  421.0  472.0  314.0  383.0  411.0  368.0  423.0  392.0  421.0  390.0  0.16465060481855442  1,647 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.835349
2    0.907928
3    0.937919
4    0.954914
5    0.96571
6    0.972208
7    0.977707
8    0.981306
9    0.984605
10   0.987504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1772859051395473
RMSE: 0.42105332814210994
LogLoss: 0.6061789928003813
Mean Per-Class Error: 0.1628373302913862
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19    20     21    22     23    24     25     Error                 Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  --------------------  -----------
83.0  0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0    0.0   0.0   1.0    0.0   1.0    0.0   2.0    1.0    0.06741573033707865   6 / 89
0.0   84.0  0.0   0.0    3.0   1.0   1.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0   2.0   1.0    0.0    9.0    0.0   0.0   0.0    1.0   0.0    1.0   1.0    0.0    0.20754716981132076   22 / 106
0.0   0.0   69.0  0.0    1.0   0.0   2.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0   1.0   0.0    0.0    0.0    3.0   1.0   1.0    0.0   1.0    0.0   0.0    0.0    0.15853658536585366   13 / 82
1.0   2.0   0.0   94.0   0.0   0.0   0.0   4.0   0.0   0.0    0.0   0.0   1.0   2.0   2.0   2.0    0.0    0.0    0.0   0.0   1.0    0.0   0.0    1.0   0.0    2.0    0.16071428571428573   18 / 112
0.0   0.0   0.0   0.0    71.0  4.0   6.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0    1.0    2.0   4.0   0.0    0.0   0.0    1.0   0.0    5.0    0.26804123711340205   26 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                   ---
0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   1.0    0.0   88.0   0.0   0.0    0.0    0.043478260869565216  4 / 92
0.0   0.0   0.0   3.0    5.0   0.0   0.0   2.0   0.0   0.0    5.0   0.0   0.0   0.0   0.0   0.0    0.0    2.0    4.0   0.0   0.0    0.0   0.0    76.0  2.0    1.0    0.24                  24 / 100
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    1.0    0.0    0.0   1.0   0.0    5.0   1.0    0.0   97.0   0.0    0.09345794392523364   10 / 107
0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   2.0   0.0    0.0   0.0    0.0   0.0    77.0   0.11494252873563218   10 / 87
93.0  97.0  74.0  116.0  93.0  86.0  92.0  86.0  83.0  103.0  95.0  91.0  82.0  99.0  83.0  112.0  104.0  119.0  84.0  88.0  107.0  81.0  108.0  92.0  122.0  100.0  0.16224899598393575   404 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.837751
2    0.907229
3    0.935341
4    0.955422
5    0.965863
6    0.971486
7    0.978313
8    0.981928
9    0.985542
10   0.988354
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:41  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:41  1 min 30.482 sec  78179 obs/sec     1         1             10007      0.589613         1.11443             0.993821       0.292412                         0.587997           1.10272               0.993839         0.296787
    2019-07-24 14:07:42  1 min 31.662 sec  77694 obs/sec     10        10            100070     0.417151         0.596602            0.996907       0.164651                         0.421053           0.606179              0.996841         0.162249
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0909327
C12         0.934949               0.934949             0.0850174
C13         0.911076               0.911076             0.0828466
C8          0.824759               0.824759             0.0749976
C7          0.801022               0.801022             0.0728391
C9          0.792789               0.792789             0.0720905
C14         0.706576               0.706576             0.0642509
C11         0.700841               0.700841             0.0637294
C10         0.684751               0.684751             0.0622663
C6          0.649121               0.649121             0.0590264
C16         0.644163               0.644163             0.0585755
C5          0.605877               0.605877             0.0550941
C3          0.514379               0.514379             0.0467739
C1          0.436837               0.436837             0.0397228
C4          0.420547               0.420547             0.0382415
C2          0.369452               0.369452             0.0335953
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_69

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.001971957194399465   0.0004648669855669141  0.0         0.008924334632951059   0.4221317768096924   0.08900290417965685  0.5021240711212158
    3        26       Softmax                 0.0   0.0   0.0021324794404161086  0.0005562298465520144  0.0         -0.001291709526248916  0.29000115394592285  -0.5985595625675064  0.21992474794387817


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17222240684183912
RMSE: 0.4149968757012987
LogLoss: 0.5977667333204535
Mean Per-Class Error: 0.1744983919524391
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    4.0    1.0    1.0    1.0    2.0    1.0    5.0    2.0    0.08860759493670886  35 / 395
0.0    328.0  0.0    4.0    3.0    0.0    2.0    14.0   3.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0    0.0    13.0   5.0    0.0    0.0    2.0    0.0    4.0    1.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    299.0  1.0    14.0   0.0    12.0   3.0    0.0    0.0    22.0   0.0    0.0    0.0    3.0    0.0    1.0    0.0    6.0    2.0    1.0    0.0    4.0    0.0    0.0    0.0    0.1875               69 / 368
1.0    20.0   0.0    340.0  0.0    0.0    0.0    14.0   0.0    2.0    0.0    0.0    6.0    2.0    2.0    2.0    0.0    2.0    1.0    2.0    1.0    0.0    0.0    6.0    0.0    2.0    0.15632754342431762  63 / 403
0.0    7.0    1.0    0.0    316.0  3.0    16.0   1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    4.0    3.0    13.0   6.0    0.0    0.0    0.0    1.0    0.0    10.0   0.17493472584856398  67 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    17.0   0.0    0.0    0.0    0.0    16.0   0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    6.0    0.0    3.0    5.0    0.0    0.0    6.0    2.0    1.0    13.0   0.0    0.0    0.0    0.0    0.0    7.0    0.0    2.0    7.0    2.0    0.0    0.0    334.0  4.0    2.0    0.15228426395939088  60 / 394
0.0    0.0    0.0    2.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    13.0   0.0    2.0    15.0   2.0    17.0   1.0    1.0    333.0  0.0    0.15267175572519084  60 / 393
0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    17.0   5.0    0.0    0.0    0.0    1.0    0.0    311.0  0.15027322404371585  55 / 366
392.0  522.0  334.0  408.0  409.0  353.0  363.0  422.0  329.0  377.0  397.0  334.0  452.0  358.0  388.0  386.0  366.0  372.0  352.0  412.0  387.0  376.0  385.0  395.0  375.0  359.0  0.1737478756373088   1,738 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826252
2    0.90103
3    0.935519
4    0.953414
5    0.96631
6    0.974607
7    0.980906
8    0.984904
9    0.987304
10   0.989603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17699087763685248
RMSE: 0.42070283768576183
LogLoss: 0.6159185964080546
Mean Per-Class Error: 0.17411840876574963
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7      8     9      10    11    12     13    14    15     16    17    18    19    20    21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   1.0   1.0   3.0    0.0   0.0898876404494382   8 / 89
0.0   85.0   0.0   2.0    2.0   0.0   1.0   6.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   4.0   2.0   0.0   0.0   2.0   0.0   1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    64.0  0.0    2.0   0.0   4.0   1.0    0.0   0.0    4.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0   3.0   1.0   0.0   0.0   2.0   0.0   0.0    0.0   0.21951219512195122  18 / 82
1.0   3.0    0.0   95.0   0.0   0.0   0.0   6.0    0.0   0.0    0.0   0.0   3.0    0.0   0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    1.0   0.15178571428571427  17 / 112
0.0   1.0    0.0   0.0    74.0  2.0   5.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    1.0   1.0   4.0   3.0   0.0   0.0   0.0   0.0   0.0    5.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   2.0    0.0   1.0    3.0   0.0   0.0   3.0    0.0   0.0    5.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0   1.0   0.0   0.0   0.0   0.0   82.0  2.0    0.0   0.18                 18 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    4.0   0.0   0.0   2.0   0.0   4.0   1.0   0.0   93.0   0.0   0.1308411214953271   14 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0   0.0   1.0   0.0    76.0  0.12643678160919541  11 / 87
90.0  124.0  67.0  114.0  95.0  83.0  95.0  108.0  78.0  108.0  98.0  89.0  102.0  97.0  80.0  112.0  94.0  94.0  89.0  92.0  97.0  85.0  99.0  96.0  111.0  93.0  0.17349397590361446  432 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.826506
2    0.902008
3    0.935341
4    0.953414
5    0.96747
6    0.9751
7    0.979518
8    0.985141
9    0.986747
10   0.990763
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:55  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:55  1 min 44.231 sec  31971 obs/sec     1         1             10007      0.545189         0.982114            0.994717       0.272318                         0.547568           0.98529               0.994657         0.279518
    2019-07-24 14:07:58  1 min 47.215 sec  30885 obs/sec     10        10            100070     0.414997         0.597767            0.996939       0.173748                         0.420703           0.615919              0.996846         0.173494
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0899884
C13         0.983331               0.983331             0.0884883
C9          0.878156               0.878156             0.0790238
C12         0.876727               0.876727             0.0788952
C8          0.794941               0.794941             0.0715354
C7          0.767162               0.767162             0.0690357
C11         0.745793               0.745793             0.0671127
C10         0.661142               0.661142             0.0594951
C14         0.66025                0.66025              0.0594148
C6          0.617476               0.617476             0.0555657
C16         0.603123               0.603123             0.0542741
C3          0.576558               0.576558             0.0518835
C5          0.565984               0.565984             0.050932
C4          0.534579               0.534579             0.0481059
C2          0.43471                0.43471              0.0391188
C1          0.412617               0.412617             0.0371307
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_2

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.001994413209445156   0.00046902697067707777  0.0         0.007252379574273604  0.41771769523620605  0.016823042977520238  0.4801490306854248
    3        26       Softmax                 0.0   0.0   0.0022468711893347624  0.0007869747933000326   0.0         0.000802924170906148  0.28998684883117676  -0.626825501351759    0.25275540351867676


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17360543777047927
RMSE: 0.41665985860228877
LogLoss: 0.6030092805359588
Mean Per-Class Error: 0.1752732618983053
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    5.0    1.0    4.0    0.0    2.0    0.0    0.0    1.0    3.0    2.0    4.0    0.0    1.0    2.0    4.0    3.0    0.08607594936708861  34 / 395
0.0    320.0  0.0    4.0    3.0    0.0    2.0    9.0    3.0    0.0    2.0    0.0    1.0    0.0    1.0    2.0    0.0    19.0   10.0   0.0    0.0    2.0    0.0    4.0    1.0    0.0    0.16449086161879894  63 / 383
0.0    0.0    295.0  0.0    12.0   2.0    13.0   0.0    0.0    0.0    21.0   0.0    0.0    0.0    5.0    0.0    2.0    0.0    6.0    1.0    8.0    0.0    2.0    0.0    0.0    0.0    0.19618528610354224  72 / 367
2.0    16.0   0.0    339.0  0.0    0.0    0.0    4.0    1.0    5.0    2.0    0.0    7.0    4.0    2.0    2.0    0.0    8.0    1.0    0.0    1.0    0.0    0.0    9.0    0.0    0.0    0.1588089330024814   64 / 403
0.0    11.0   1.0    0.0    299.0  3.0    11.0   0.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    1.0    9.0    4.0    15.0   7.0    0.0    0.0    0.0    6.0    0.0    10.0   0.22135416666666666  85 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    5.0    0.0    0.0    2.0    0.0    347.0  0.0    0.0    0.0    0.07712765957446809  29 / 376
0.0    1.0    0.0    3.0    6.0    1.0    0.0    4.0    3.0    3.0    7.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    6.0    5.0    1.0    0.0    0.0    340.0  3.0    2.0    0.13705583756345177  54 / 394
0.0    0.0    0.0    3.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    1.0    7.0    3.0    9.0    1.0    1.0    355.0  0.0    0.09669211195928754  38 / 393
1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    8.0    0.0    29.0   3.0    0.0    0.0    0.0    0.0    0.0    311.0  0.15258855585831063  56 / 367
395.0  449.0  324.0  416.0  394.0  336.0  345.0  329.0  342.0  360.0  415.0  351.0  449.0  360.0  385.0  397.0  393.0  421.0  387.0  381.0  412.0  362.0  408.0  420.0  424.0  348.0  0.1743476956912926   1,744 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.825652
2    0.90093
3    0.93322
4    0.953114
5    0.96521
6    0.973408
7    0.978906
8    0.983305
9    0.986904
10   0.989503

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.1782421080740311
RMSE: 0.42218729028007357
LogLoss: 0.6171209586413773
Mean Per-Class Error: 0.17909064101627692
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16     17     18     19    20     21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  -----  -----  -----  ----  -----  ----  ----  -----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0    0.0   0.0   0.0    0.0    0.0    1.0    0.0   2.0    0.0   0.0   0.0    2.0    0.0   0.07865168539325842  7 / 89
0.0   83.0   0.0   0.0    2.0   0.0   1.0   6.0   1.0   0.0    0.0    0.0   0.0    0.0   1.0   1.0    0.0    6.0    2.0    0.0   0.0    2.0   0.0   1.0    0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    63.0  0.0    1.0   0.0   5.0   0.0   0.0   0.0    4.0    0.0   0.0    0.0   2.0   0.0    0.0    0.0    3.0    1.0   2.0    0.0   1.0   0.0    0.0    0.0   0.23170731707317074  19 / 82
2.0   3.0    0.0   93.0   0.0   0.0   0.0   3.0   1.0   1.0    1.0    0.0   3.0    0.0   0.0   2.0    0.0    1.0    0.0    0.0   0.0    0.0   0.0   2.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   2.0    1.0   0.0    69.0  2.0   5.0   0.0   0.0   0.0    2.0    0.0   0.0    0.0   0.0   0.0    2.0    1.0    4.0    3.0   0.0    0.0   0.0   2.0    0.0    4.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---    ---    ---    ---   ---    ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   4.0    0.0   0.0   0.0    0.0    2.0    0.0    0.0   0.0    0.0   85.0  0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   1.0    3.0   0.0   0.0   2.0   1.0   1.0    3.0    1.0   0.0    0.0   0.0   0.0    1.0    1.0    0.0    0.0   0.0    0.0   0.0   85.0   0.0    1.0   0.15                 15 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   0.0   1.0    4.0    0.0    0.0    1.0   0.0    2.0   1.0   0.0    97.0   0.0   0.09345794392523364  10 / 107
1.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   2.0    0.0    1.0   0.0    0.0   0.0   0.0    1.0    0.0    6.0    1.0   0.0    0.0   0.0   0.0    0.0    72.0  0.1724137931034483   15 / 87
89.0  110.0  66.0  117.0  88.0  75.0  91.0  91.0  83.0  105.0  103.0  96.0  101.0  98.0  76.0  114.0  100.0  111.0  101.0  87.0  104.0  81.0  96.0  101.0  122.0  84.0  0.17751004016064256  442 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.82249
2    0.89759
3    0.932932
4    0.949398
5    0.963855
6    0.973092
7    0.978715
8    0.983133
9    0.985944
10   0.988353
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:15  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:16  5.349 sec   26543 obs/sec     1         1             10007      0.546071         0.997728            0.994701       0.269819                         0.544585           0.992695              0.994716         0.273092
    2019-07-24 14:06:20  9.408 sec   22915 obs/sec     10        10            100070     0.41666          0.603009            0.996915       0.174348                         0.422187           0.617121              0.996824         0.17751
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0898223
C15         0.975381               0.975381             0.0876109
C9          0.886009               0.886009             0.0795834
C12         0.865414               0.865414             0.0777334
C8          0.798871               0.798871             0.0717564
C7          0.759156               0.759156             0.0681891
C11         0.745578               0.745578             0.0669695
C10         0.669014               0.669014             0.0600923
C6          0.639341               0.639341             0.0574271
C14         0.63695                0.63695              0.0572123
C5          0.581749               0.581749             0.052254
C3          0.581148               0.581148             0.0522
C16         0.578859               0.578859             0.0519945
C4          0.553288               0.553288             0.0496976
C2          0.433617               0.433617             0.0389484
C1          0.428722               0.428722             0.0385088
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_76

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 11,034 weights/biases, 137.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        16       Input        0.0
    2        256      TanhDropout  50.0       0.0   0.0   0.0020251304202787423  0.00046655419282615185  0.0         -0.006509537962473999  0.42928576469421387  0.0048766897106395125  0.49478137493133545
    3        26       Softmax                 0.0   0.0   0.0021793324575845384  0.0005547457840293646   0.0         -0.004924655585170386  0.28977108001708984  -0.5964376712557322    0.2681349515914917


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.17419947440854003
RMSE: 0.41737210545092734
LogLoss: 0.6045859357493772
Mean Per-Class Error: 0.17710739007771462
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
363.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    2.0    2.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    5.0    1.0    1.0    0.0    2.0    2.0    6.0    3.0    0.0810126582278481   32 / 395
0.0    319.0  0.0    7.0    6.0    2.0    2.0    3.0    5.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    0.0    13.0   17.0   0.0    0.0    2.0    0.0    2.0    2.0    0.0    0.1671018276762402   64 / 383
0.0    0.0    298.0  1.0    22.0   0.0    16.0   2.0    0.0    0.0    8.0    1.0    0.0    0.0    7.0    0.0    1.0    0.0    2.0    3.0    3.0    0.0    4.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
1.0    22.0   0.0    338.0  0.0    0.0    1.0    4.0    2.0    2.0    0.0    0.0    5.0    7.0    2.0    2.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    7.0    0.0    3.0    0.16129032258064516  65 / 403
0.0    4.0    1.0    0.0    328.0  3.0    17.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    4.0    3.0    2.0    6.0    0.0    0.0    0.0    3.0    1.0    11.0   0.14583333333333334  56 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    2.0    5.0    0.0    0.0    0.0    0.0    14.0   0.0    4.0    0.0    0.0    3.0    0.0    0.0    1.0    2.0    341.0  0.0    0.0    0.0    0.09066666666666667  34 / 375
0.0    2.0    0.0    7.0    8.0    1.0    0.0    4.0    3.0    1.0    6.0    2.0    0.0    0.0    0.0    0.0    8.0    1.0    4.0    3.0    1.0    0.0    0.0    333.0  7.0    3.0    0.1548223350253807   61 / 394
0.0    1.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    3.0    0.0    2.0    9.0    1.0    18.0   1.0    1.0    347.0  0.0    0.11704834605597965  46 / 393
1.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    5.0    0.0    3.0    0.0    0.0    0.0    0.0    5.0    1.0    21.0   3.0    0.0    0.0    0.0    0.0    0.0    313.0  0.14713896457765668  54 / 367
411.0  492.0  332.0  420.0  439.0  366.0  382.0  300.0  344.0  342.0  319.0  350.0  422.0  379.0  407.0  368.0  355.0  433.0  359.0  388.0  389.0  370.0  414.0  412.0  419.0  391.0  0.17614715585324403  1,762 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.823853
2    0.902029
3    0.93482
4    0.954014
5    0.96511
6    0.973008
7    0.979106
8    0.984305
9    0.987404
10   0.990603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.17787645981429467
RMSE: 0.4217540276207148
LogLoss: 0.6206257469302342
Mean Per-Class Error: 0.18299572065352
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12    13     14    15     16    17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0    0.07865168539325842  7 / 89
0.0   85.0   0.0   1.0    3.0    0.0   1.0   2.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   4.0    4.0   0.0   0.0   2.0   0.0    1.0   1.0    0.0    0.19811320754716982  21 / 106
0.0   0.0    64.0  0.0    5.0    0.0   4.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0    1.0   1.0   0.0   0.0   1.0    0.0   0.0    0.0    0.21951219512195122  18 / 82
1.0   4.0    0.0   93.0   0.0    0.0   0.0   3.0   1.0   0.0   0.0   0.0   2.0   2.0    0.0   2.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    2.0   0.0    1.0    0.16964285714285715  19 / 112
0.0   0.0    0.0   0.0    81.0   2.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0   3.0   0.0   0.0   0.0    0.0   0.0    4.0    0.16494845360824742  16 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0    1.0   0.0    0.0   1.0    0.0   0.0   0.0   1.0   84.0   0.0   0.0    0.0    0.08695652173913043  8 / 92
0.0   0.0    0.0   3.0    4.0    0.0   0.0   2.0   0.0   0.0   3.0   1.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0   0.0   0.0   0.0   0.0    80.0  2.0    2.0    0.2                  20 / 100
0.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    1.0   0.0    0.0   2.0   0.0   6.0   1.0    0.0   94.0   0.0    0.12149532710280374  13 / 107
1.0   0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0    0.0   0.0    75.0   0.13793103448275862  12 / 87
98.0  120.0  70.0  117.0  106.0  85.0  94.0  76.0  87.0  97.0  83.0  93.0  94.0  103.0  90.0  107.0  90.0  106.0  84.0  90.0  98.0  83.0  103.0  96.0  119.0  101.0  0.1823293172690763   454 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.817671
2    0.902811
3    0.938554
4    0.953815
5    0.964659
6    0.971084
7    0.976305
8    0.982329
9    0.986345
10   0.990362
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:08:04  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:08:05  1 min 54.025 sec  27874 obs/sec     1         1             10007      0.549856         0.993684            0.994627       0.272718                         0.55163            0.999856              0.994578         0.281526
    2019-07-24 14:08:08  1 min 56.932 sec  31193 obs/sec     10        10            100070     0.417372         0.604586            0.996904       0.176147                         0.421754           0.620626              0.99683          0.182329
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0894512
C13         0.925792               0.925792             0.0828133
C12         0.901423               0.901423             0.0806334
C9          0.862333               0.862333             0.0771367
C7          0.783378               0.783378             0.0700741
C11         0.768416               0.768416             0.0687358
C8          0.757719               0.757719             0.0677789
C10         0.676117               0.676117             0.0604795
C14         0.645341               0.645341             0.0577265
C16         0.61                   0.61                 0.0545653
C6          0.60261                0.60261              0.0539042
C5          0.602145               0.602145             0.0538626
C3          0.600704               0.600704             0.0537338
C4          0.536126               0.536126             0.0479571
C2          0.455183               0.455183             0.0407167
C1          0.451988               0.451988             0.0404309
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_58

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009293387453510604  0.00023141235578805208  0.0         -0.012017851519686928  0.24000048637390137  0.09528813328175864  0.20953989028930664
    3        26       Softmax                      0.0   0.0   0.007039996278273555   0.025046370923519135    0.0         -0.3147601110044539    0.7401742935180664   -0.6200876037793436  0.39375734329223633


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2032673255916717
RMSE: 0.45085177785129305
LogLoss: 0.6446852232574691
Mean Per-Class Error: 0.18059706896830494
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    8.0    3.0    0.0    5.0    0.0    0.0    0.0    2.0    0.0    4.0    0.0    1.0    3.0    2.0    1.0    4.0    0.0    0.08607594936708861  34 / 395
0.0    331.0  0.0    5.0    3.0    0.0    1.0    9.0    2.0    0.0    1.0    1.0    1.0    0.0    0.0    5.0    0.0    17.0   3.0    0.0    0.0    1.0    0.0    2.0    0.0    0.0    0.13350785340314136  51 / 382
0.0    0.0    307.0  0.0    10.0   0.0    3.0    0.0    0.0    0.0    28.0   0.0    1.0    0.0    3.0    0.0    7.0    0.0    3.0    2.0    1.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
1.0    23.0   0.0    346.0  0.0    1.0    0.0    2.0    0.0    1.0    2.0    0.0    5.0    6.0    3.0    0.0    0.0    2.0    1.0    2.0    1.0    0.0    0.0    7.0    0.0    0.0    0.141439205955335    57 / 403
0.0    12.0   0.0    0.0    312.0  2.0    13.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    4.0    3.0    14.0   5.0    0.0    0.0    0.0    2.0    1.0    11.0   0.185378590078329    71 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    15.0   0.0    2.0    0.0    0.0    4.0    0.0    0.0    1.0    1.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    3.0    1.0    2.0    7.0    0.0    0.0    2.0    2.0    1.0    10.0   2.0    0.0    2.0    0.0    0.0    0.0    0.0    7.0    2.0    2.0    0.0    0.0    344.0  4.0    3.0    0.12690355329949238  50 / 394
0.0    0.0    0.0    3.0    0.0    5.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    3.0    5.0    0.0    9.0    23.0   1.0    13.0   1.0    1.0    325.0  0.0    0.17091836734693877  67 / 392
1.0    0.0    0.0    1.0    11.0   0.0    0.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    24.0   2.0    0.0    0.0    0.0    1.0    0.0    307.0  0.16348773841961853  60 / 367
399.0  519.0  362.0  413.0  407.0  321.0  318.0  318.0  342.0  356.0  409.0  333.0  445.0  389.0  410.0  404.0  340.0  402.0  428.0  391.0  399.0  370.0  397.0  406.0  379.0  346.0  0.17984604618614417  1,799 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.820154
2    0.896531
3    0.93342
4    0.952614
5    0.963411
6    0.973508
7    0.980606
8    0.985704
9    0.988304
10   0.990303

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20359968204004736
RMSE: 0.45122021457382355
LogLoss: 0.6429154886238515
Mean Per-Class Error: 0.18525066021191294
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17     18     19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
83.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0    0.0   0.0    2.0   1.0   0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0   85.0   0.0   0.0    3.0   0.0   1.0   4.0   1.0   0.0    0.0    0.0   0.0   0.0    0.0   2.0    0.0   7.0    1.0    0.0   0.0    1.0   0.0   1.0   0.0    0.0   0.19811320754716982  21 / 106
0.0   0.0    63.0  0.0    2.0   0.0   2.0   0.0   0.0   0.0    6.0    0.0   0.0   0.0    3.0   0.0    2.0   0.0    2.0    1.0   0.0    0.0   1.0   0.0   0.0    0.0   0.23170731707317074  19 / 82
1.0   4.0    0.0   98.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   2.0   2.0    1.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.125                14 / 112
0.0   2.0    0.0   0.0    76.0  2.0   3.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0    2.0   1.0    4.0    2.0   0.0    0.0   0.0   0.0   0.0    5.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   4.0   0.0    0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0   86.0  0.0   0.0    0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   1.0    4.0   0.0   0.0   1.0   0.0   0.0    5.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0    0.0   0.0    0.0   0.0   84.0  1.0    1.0   0.16                 16 / 100
0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   1.0    3.0   0.0    0.0    6.0   0.0    3.0   1.0   0.0   91.0   0.0   0.14953271028037382  16 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   5.0    0.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    4.0    0.0   0.0    0.0   0.0   0.0   0.0    74.0  0.14942528735632185  13 / 87
95.0  121.0  76.0  118.0  95.0  71.0  82.0  85.0  81.0  101.0  103.0  90.0  98.0  102.0  83.0  117.0  96.0  101.0  108.0  92.0  100.0  83.0  97.0  96.0  110.0  89.0  0.18393574297188756  458 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816064
2    0.898795
3    0.93253
4    0.956225
5    0.96747
6    0.9751
7    0.980321
8    0.98514
9    0.986345
10   0.987952
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:44  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:44  1 min 33.009 sec  88557 obs/sec     1         1             10007      0.661767         1.32821             0.992215       0.349195                         0.65746            1.31073               0.992298         0.350201
    2019-07-24 14:07:44  1 min 33.675 sec  131325 obs/sec    10        10            100070     0.450852         0.644685            0.996387       0.179846                         0.45122            0.642915              0.996372         0.183936
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0944263
C13         0.945111               0.945111             0.0892433
C9          0.781839               0.781839             0.0738262
C7          0.776393               0.776393             0.0733118
C8          0.724843               0.724843             0.0684442
C12         0.719708               0.719708             0.0679593
C11         0.672364               0.672364             0.0634888
C5          0.65532                0.65532              0.0618794
C6          0.618                  0.618                0.0583554
C14         0.615371               0.615371             0.0581071
C10         0.5833                 0.5833               0.0550789
C4          0.572626               0.572626             0.0540709
C3          0.539108               0.539108             0.0509059
C16         0.521032               0.521032             0.0491991
C2          0.445385               0.445385             0.042056
C1          0.419877               0.419877             0.0396474
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_52

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009267231420153621  0.00022038083989173174  0.0         -0.01632658819733024  0.2341511845588684  0.13251698648623422  0.18449294567108154
    3        26       Softmax                      0.0   0.0   0.006849447955923656   0.023727327585220337    0.0         -0.2976941740404737   0.7438766956329346  -0.6007045161684983  0.3188166618347168


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20050669266082075
RMSE: 0.4477797367688948
LogLoss: 0.6407908565189794
Mean Per-Class Error: 0.17801835658950516
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
360.0  0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    5.0    2.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    1.0    1.0    2.0    0.0    9.0    1.0    0.08860759493670886  35 / 395
0.0    321.0  0.0    3.0    7.0    1.0    1.0    8.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    5.0    1.0    18.0   7.0    0.0    0.0    6.0    0.0    1.0    1.0    0.0    0.1618798955613577   62 / 383
0.0    1.0    305.0  0.0    14.0   0.0    9.0    0.0    0.0    0.0    19.0   0.0    3.0    0.0    4.0    0.0    1.0    0.0    6.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.17119565217391305  63 / 368
3.0    15.0   0.0    341.0  0.0    0.0    0.0    3.0    0.0    2.0    0.0    0.0    3.0    5.0    3.0    2.0    0.0    10.0   7.0    0.0    1.0    0.0    0.0    5.0    0.0    2.0    0.1517412935323383   61 / 402
0.0    9.0    5.0    0.0    301.0  5.0    9.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    9.0    4.0    13.0   4.0    0.0    0.0    0.0    6.0    0.0    14.0   0.21614583333333334  83 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    6.0    1.0    0.0    0.0    0.0    9.0    0.0    0.0    2.0    0.0    350.0  0.0    1.0    0.0    0.06666666666666667  25 / 375
0.0    2.0    1.0    4.0    7.0    1.0    0.0    1.0    2.0    1.0    11.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    5.0    7.0    1.0    0.0    0.0    339.0  4.0    6.0    0.13959390862944163  55 / 394
0.0    0.0    0.0    2.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    3.0    11.0   2.0    29.0   1.0    0.0    323.0  0.0    0.178117048346056    70 / 393
1.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    3.0    0.0    26.0   3.0    0.0    0.0    0.0    0.0    0.0    305.0  0.16666666666666666  61 / 366
413.0  460.0  350.0  413.0  395.0  351.0  358.0  349.0  344.0  356.0  384.0  337.0  398.0  391.0  377.0  396.0  369.0  434.0  379.0  383.0  383.0  388.0  430.0  396.0  392.0  377.0  0.17734679596121164  1,774 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.822653
2    0.89983
3    0.93162
4    0.950915
5    0.96581
6    0.973308
7    0.979106
8    0.983605
9    0.987404
10   0.989903

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20287274693384022
RMSE: 0.45041397284480444
LogLoss: 0.643377556465585
Mean Per-Class Error: 0.18297881665870988
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23    24     25    Error                 Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  --------------------  -----------
81.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   0.0    0.0   0.0    0.0   0.0    1.0   0.0   0.0   1.0   1.0    0.0   3.0    0.0   0.0898876404494382    8 / 89
0.0    79.0   0.0   0.0    3.0   1.0   1.0   5.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    1.0   7.0    2.0   0.0   0.0   4.0   0.0    1.0   0.0    0.0   0.25471698113207547   27 / 106
0.0    0.0    68.0  0.0    3.0   0.0   1.0   0.0   0.0   0.0    3.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.17073170731707318   14 / 82
3.0    0.0    0.0   96.0   0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0   3.0    0.0   1.0    0.0   2.0    4.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.14285714285714285   16 / 112
0.0    0.0    0.0   0.0    72.0  3.0   3.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   0.0    3.0   1.0    4.0   1.0   0.0   0.0   0.0    2.0   0.0    6.0   0.25773195876288657   25 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                   ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   88.0   0.0   1.0    0.0   0.043478260869565216  4 / 92
0.0    0.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0    84.0  1.0    2.0   0.16                  16 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    6.0   0.0    0.0   1.0   0.0   8.0   1.0    0.0   89.0   0.0   0.16822429906542055   18 / 107
1.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   5.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0    0.0   0.0    72.0  0.1724137931034483    15 / 87
100.0  102.0  74.0  117.0  91.0  82.0  88.0  89.0  85.0  103.0  97.0  89.0  87.0  105.0  81.0  114.0  99.0  104.0  96.0  85.0  93.0  93.0  104.0  99.0  115.0  98.0  0.18313253012048192   456 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816867
2    0.9
3    0.936145
4    0.950602
5    0.964257
6    0.973494
7    0.980723
8    0.98514
9    0.988353
10   0.990763
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:37  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:37  1 min 26.447 sec  104239 obs/sec    1         1             10007      0.652038         1.28101             0.992443       0.326502                         0.652666           1.28043               0.99241          0.328112
    2019-07-24 14:07:38  1 min 27.099 sec  137837 obs/sec    10        10            100070     0.44778          0.640791            0.996436       0.177347                         0.450414           0.643378              0.996385         0.183133
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0917154
C13         0.899714               0.899714             0.0825177
C9          0.847698               0.847698             0.077747
C8          0.81826                0.81826              0.0750471
C7          0.804213               0.804213             0.0737587
C11         0.784372               0.784372             0.071939
C12         0.720507               0.720507             0.0660817
C6          0.678766               0.678766             0.0622534
C5          0.667224               0.667224             0.0611947
C10         0.609089               0.609089             0.0558628
C4          0.571577               0.571577             0.0524225
C14         0.567696               0.567696             0.0520665
C3          0.546359               0.546359             0.0501096
C16         0.500879               0.500879             0.0459384
C2          0.458097               0.458097             0.0420146
C1          0.428838               0.428838             0.0393311
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_3

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009335820649312154  0.0002307899994775653  0.0         -0.016251853964547536  0.2372545599937439  0.10808778039608645  0.18184936046600342
    3        26       Softmax                      0.0   0.0   0.0062345130816958355  0.014384564012289047   0.0         -0.2884666332644464    0.7424917221069336  -0.600091036543044   0.3837423324584961


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20465317231842997
RMSE: 0.4523860876711727
LogLoss: 0.6518094871449844
Mean Per-Class Error: 0.18415730462747962
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    7.0    2.0    1.0    0.0    5.0    0.0    1.0    0.0    7.0    0.0    1.0    1.0    2.0    4.0    5.0    0.0    0.09620253164556962  38 / 395
0.0    323.0  0.0    10.0   2.0    3.0    4.0    7.0    1.0    0.0    3.0    1.0    0.0    0.0    5.0    3.0    0.0    10.0   7.0    0.0    0.0    1.0    0.0    2.0    1.0    0.0    0.1566579634464752   60 / 383
0.0    1.0    307.0  1.0    10.0   0.0    11.0   0.0    0.0    0.0    18.0   0.0    1.0    0.0    4.0    0.0    2.0    0.0    7.0    1.0    2.0    0.0    3.0    0.0    0.0    0.0    0.16576086956521738  61 / 368
2.0    14.0   0.0    337.0  0.0    3.0    2.0    5.0    0.0    3.0    0.0    0.0    6.0    4.0    5.0    0.0    0.0    6.0    4.0    0.0    1.0    0.0    0.0    5.0    0.0    6.0    0.16377171215880892  66 / 403
0.0    5.0    1.0    0.0    315.0  4.0    15.0   0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    1.0    2.0    4.0    11.0   5.0    0.0    0.0    0.0    2.0    0.0    11.0   0.17754569190600522  68 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    3.0    13.0   0.0    0.0    0.0    0.0    13.0   1.0    2.0    0.0    0.0    1.0    0.0    0.0    4.0    0.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    2.0    0.0    5.0    5.0    0.0    0.0    4.0    2.0    1.0    8.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    7.0    1.0    1.0    0.0    0.0    342.0  8.0    2.0    0.1319796954314721   52 / 394
0.0    0.0    0.0    0.0    0.0    12.0   0.0    2.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    5.0    9.0    0.0    3.0    24.0   2.0    30.0   1.0    0.0    302.0  0.0    0.23155216284987276  91 / 393
0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    41.0   3.0    0.0    0.0    0.0    0.0    0.0    290.0  0.2098092643051771   77 / 367
396.0  495.0  361.0  428.0  394.0  390.0  377.0  328.0  327.0  357.0  400.0  349.0  425.0  379.0  399.0  379.0  325.0  413.0  419.0  385.0  379.0  375.0  394.0  419.0  352.0  358.0  0.183444966510047    1,835 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.816555
2    0.897931
3    0.930421
4    0.949415
5    0.963311
6    0.971808
7    0.978506
8    0.982405
9    0.987304
10   0.990203

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20651368458539093
RMSE: 0.4544377675605219
LogLoss: 0.6585132129375803
Mean Per-Class Error: 0.18452846029992123
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20    21    22    23     24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   1.0   1.0    3.0   0.0   0.07865168539325842  7 / 89
0.0   84.0   0.0   3.0    1.0   0.0   0.0   2.0   0.0   0.0    2.0    0.0   0.0   0.0   2.0   1.0    0.0   5.0    4.0    0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.20754716981132076  22 / 106
0.0   0.0    63.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   2.0   0.0    1.0   0.0    3.0    0.0   1.0   0.0   1.0   0.0    0.0   0.0   0.23170731707317074  19 / 82
2.0   2.0    0.0   95.0   0.0   1.0   1.0   2.0   0.0   1.0    0.0    0.0   3.0   1.0   1.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    0.0   1.0   0.15178571428571427  17 / 112
0.0   0.0    0.0   0.0    73.0  3.0   4.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    1.0   1.0    4.0    3.0   0.0   0.0   0.0   2.0    0.0   4.0   0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   1.0   0.0   0.0    0.0    0.0   5.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   85.0  0.0    0.0   0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   1.0   0.0   0.0    4.0    1.0   0.0   0.0   0.0   0.0    1.0   1.0    2.0    0.0   0.0   0.0   0.0   82.0   2.0   1.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   1.0   0.0   0.0    0.0    1.0   0.0   0.0   1.0   3.0    3.0   0.0    0.0    7.0   0.0   8.0   1.0   0.0    80.0  0.0   0.2523364485981308   27 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0    2.0   0.0   0.0   0.0   0.0    0.0   69.0  0.20689655172413793  18 / 87
94.0  118.0  71.0  121.0  90.0  95.0  97.0  80.0  75.0  100.0  104.0  92.0  98.0  99.0  85.0  109.0  85.0  103.0  110.0  93.0  98.0  85.0  99.0  104.0  96.0  89.0  0.18473895582329317  460 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.815261
2    0.897189
3    0.926908
4    0.948594
5    0.961044
6    0.970683
7    0.978715
8    0.982731
9    0.986345
10   0.989157
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:20  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:20  9.569 sec   97155 obs/sec     1         1             10007      0.639087         1.22312             0.992743       0.317605                         0.641963           1.23696               0.992657         0.319679
    2019-07-24 14:06:21  10.305 sec  123238 obs/sec    10        10            100070     0.452386         0.651809            0.996364       0.183445                         0.454438           0.658513              0.99632          0.184739
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0877405
C15         0.987294               0.987294             0.0866257
C9          0.890631               0.890631             0.0781444
C8          0.880081               0.880081             0.0772187
C12         0.831418               0.831418             0.0729491
C5          0.776212               0.776212             0.0681052
C11         0.771337               0.771337             0.0676775
C7          0.770876               0.770876             0.067637
C10         0.630355               0.630355             0.0553077
C6          0.626705               0.626705             0.0549874
C3          0.623667               0.623667             0.0547209
C4          0.612211               0.612211             0.0537157
C14         0.607009               0.607009             0.0532592
C16         0.538465               0.538465             0.0472452
C1          0.473452               0.473452             0.0415409
C2          0.377533               0.377533             0.0331249
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_44

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  25.0       0.0   0.0   0.0009534173316012584  0.00022713403450325131  0.0         -0.009683250139971733  0.2376195192337036  0.14251021573348913  0.19096797704696655
    3        26       Softmax                      0.0   0.0   0.006492593339002129   0.023176319897174835    0.0         -0.2801258366676288    0.7179093360900879  -0.5921639076328834  0.37581419944763184


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.20582991252107943
RMSE: 0.4536848162778642
LogLoss: 0.6595609385432798
Mean Per-Class Error: 0.1852795830428957
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    7.0    1.0    3.0    0.0    2.0    0.0    0.0    1.0    6.0    2.0    4.0    0.0    1.0    1.0    3.0    0.0    0.10152284263959391  40 / 394
1.0    321.0  0.0    7.0    2.0    1.0    5.0    3.0    2.0    1.0    1.0    0.0    0.0    0.0    2.0    1.0    0.0    17.0   13.0   0.0    0.0    4.0    1.0    1.0    0.0    0.0    0.1618798955613577   62 / 383
0.0    0.0    300.0  0.0    24.0   0.0    8.0    0.0    0.0    0.0    11.0   0.0    1.0    0.0    6.0    0.0    2.0    0.0    5.0    2.0    5.0    0.0    4.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
3.0    15.0   0.0    344.0  0.0    0.0    1.0    4.0    0.0    0.0    1.0    0.0    7.0    2.0    3.0    1.0    0.0    12.0   2.0    1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.14427860696517414  58 / 402
0.0    14.0   0.0    0.0    311.0  2.0    11.0   1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    8.0    7.0    0.0    0.0    0.0    3.0    0.0    14.0   0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    1.0    0.0    20.0   0.0    1.0    0.0    0.0    1.0    0.0    1.0    1.0    0.0    344.0  0.0    0.0    0.0    0.0851063829787234   32 / 376
0.0    3.0    0.0    5.0    11.0   0.0    0.0    2.0    2.0    1.0    7.0    0.0    0.0    0.0    2.0    0.0    5.0    0.0    9.0    3.0    1.0    0.0    0.0    337.0  3.0    3.0    0.1446700507614213   57 / 394
1.0    0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    0.0    9.0    0.0    4.0    23.0   0.0    12.0   1.0    0.0    327.0  0.0    0.16581632653061223  65 / 392
1.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    16.0   0.0    3.0    0.0    0.0    0.0    0.0    2.0    1.0    31.0   3.0    0.0    0.0    0.0    2.0    0.0    297.0  0.1907356948228883   70 / 367
399.0  512.0  342.0  437.0  421.0  403.0  322.0  317.0  333.0  359.0  399.0  344.0  440.0  373.0  377.0  361.0  355.0  409.0  410.0  371.0  401.0  374.0  423.0  400.0  369.0  352.0  0.18444466660001999  1,845 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.815555
2    0.895731
3    0.928421
4    0.948016
5    0.961212
6    0.971209
7    0.978606
8    0.982305
9    0.985704
10   0.988403

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.20750194596402782
RMSE: 0.4555238149252219
LogLoss: 0.6628326322700461
Mean Per-Class Error: 0.1865542378805879
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16     17    18     19    20     21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  -----  ----  -----  ----  -----  ----  -----  ----  ----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   1.0   0.0    0.0   0.0    0.0    0.0   1.0    0.0   1.0    0.0   1.0    1.0   2.0   0.0   0.0898876404494382   8 / 89
1.0   84.0   0.0   2.0    1.0   0.0   0.0   2.0   1.0   0.0    0.0    0.0   0.0   0.0    2.0   0.0    0.0    3.0   5.0    0.0   0.0    3.0   1.0    1.0   0.0   0.0   0.20754716981132076  22 / 106
0.0   0.0    62.0  0.0    4.0   0.0   3.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0    3.0   0.0    1.0    0.0   3.0    1.0   1.0    0.0   2.0    0.0   0.0   0.0   0.24390243902439024  20 / 82
2.0   4.0    0.0   96.0   0.0   0.0   0.0   1.0   0.0   0.0    1.0    0.0   3.0   1.0    0.0   0.0    0.0    2.0   0.0    0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.14285714285714285  16 / 112
0.0   2.0    0.0   0.0    75.0  1.0   1.0   1.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    3.0    1.0   2.0    3.0   0.0    0.0   0.0    1.0   0.0   6.0   0.2268041237113402   22 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---    ---   ---    ---   ---    ---   ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   5.0   0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0    0.0   85.0   0.0   0.0   0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   2.0    4.0   0.0   0.0   1.0   0.0   0.0    4.0    0.0   0.0   0.0    0.0   0.0    1.0    0.0   4.0    0.0   0.0    0.0   0.0    80.0  2.0   1.0   0.2                  20 / 100
1.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    2.0   0.0    5.0    0.0   1.0    5.0   0.0    3.0   1.0    0.0   86.0  0.0   0.19626168224299065  21 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   4.0    0.0    2.0   0.0   0.0    0.0   0.0    0.0    0.0   5.0    1.0   0.0    0.0   0.0    0.0   0.0   72.0  0.1724137931034483   15 / 87
95.0  127.0  70.0  125.0  98.0  97.0  76.0  85.0  78.0  102.0  100.0  93.0  98.0  100.0  80.0  103.0  100.0  98.0  102.0  89.0  100.0  88.0  101.0  95.0  99.0  91.0  0.1859437751004016   463 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.814056
2    0.896787
3    0.927711
4    0.948193
5    0.959839
6    0.971486
7    0.978715
8    0.980723
9    0.983936
10   0.987149
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:20  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:20  1 min  9.596 sec  113715 obs/sec    1         1             10007      0.649435         1.26931             0.992502       0.326402                         0.649731           1.26585               0.992478         0.329719
    2019-07-24 14:07:21  1 min 10.369 sec  118989 obs/sec    10        10            100070     0.453685         0.659561            0.996341       0.184445                         0.455524           0.662833              0.996303         0.185944
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0906154
C13         0.969432               0.969432             0.0878455
C7          0.84685                0.84685              0.0767377
C8          0.82892                0.82892              0.075113
C12         0.779849               0.779849             0.0706663
C5          0.77665                0.77665              0.0703765
C9          0.758599               0.758599             0.0687407
C10         0.672218               0.672218             0.0609134
C11         0.652366               0.652366             0.0591145
C14         0.613771               0.613771             0.0556171
C6          0.589139               0.589139             0.0533851
C4          0.58889                0.58889              0.0533625
C3          0.588024               0.588024             0.0532841
C16         0.528632               0.528632             0.0479022
C2          0.438745               0.438745             0.039757
C1          0.403562               0.403562             0.036569
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_20

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  50.0       0.0   0.0   0.0012333846134708892  0.00035416323225945234  0.0         -0.014763648900554927  0.2098677158355713  0.09921030847988006  0.13147401809692383
    3        26       Softmax                      0.0   0.0   0.006379869708185792   0.014423929154872894    0.0         -0.2021773110910705    0.5239672660827637  -0.8791570861634046  0.39132213592529297


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22203095113673227
RMSE: 0.471201603495502
LogLoss: 0.6955219651267769
Mean Per-Class Error: 0.19069034439488547
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    3.0    1.0    6.0    2.0    3.0    0.0    3.0    0.0    6.0    0.0    2.0    0.0    1.0    2.0    7.0    0.0    0.10379746835443038  41 / 395
0.0    317.0  0.0    5.0    2.0    1.0    4.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    2.0    4.0    0.0    24.0   13.0   0.0    0.0    1.0    1.0    3.0    2.0    0.0    0.17232375979112272  66 / 383
0.0    0.0    304.0  1.0    13.0   0.0    10.0   0.0    0.0    0.0    22.0   0.0    2.0    0.0    5.0    0.0    1.0    0.0    5.0    1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.17391304347826086  64 / 368
2.0    20.0   0.0    332.0  0.0    0.0    1.0    5.0    0.0    3.0    0.0    0.0    7.0    2.0    4.0    2.0    0.0    7.0    6.0    1.0    0.0    0.0    0.0    9.0    0.0    2.0    0.1761786600496278   71 / 403
0.0    7.0    2.0    0.0    307.0  1.0    12.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    6.0    5.0    15.0   2.0    0.0    0.0    0.0    9.0    0.0    14.0   0.20052083333333334  77 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    1.0    0.0    14.0   5.0    1.0    0.0    0.0    7.0    0.0    0.0    2.0    0.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    4.0    0.0    5.0    7.0    0.0    0.0    0.0    2.0    2.0    8.0    1.0    0.0    0.0    2.0    0.0    5.0    3.0    5.0    3.0    1.0    0.0    0.0    340.0  4.0    2.0    0.13705583756345177  54 / 394
0.0    0.0    0.0    2.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    7.0    22.0   1.0    21.0   1.0    0.0    326.0  0.0    0.1683673469387755   66 / 392
0.0    0.0    0.0    0.0    14.0   1.0    0.0    0.0    0.0    8.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    35.0   1.0    0.0    0.0    0.0    2.0    0.0    302.0  0.1771117166212534   65 / 367
390.0  469.0  366.0  417.0  395.0  350.0  329.0  290.0  341.0  348.0  400.0  338.0  437.0  383.0  388.0  378.0  351.0  469.0  430.0  394.0  380.0  369.0  398.0  435.0  401.0  357.0  0.19004298710386883  1,901 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.809957
2    0.893432
3    0.928322
4    0.947716
5    0.961212
6    0.970509
7    0.978406
8    0.981905
9    0.985104
10   0.988603

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22364291802491118
RMSE: 0.47290899550009746
LogLoss: 0.7002936621126064
Mean Per-Class Error: 0.19777608939657873
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16    17     18     19    20    21    22    23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  ----  -----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   1.0    3.0    0.0   0.0898876404494382   8 / 89
0.0   82.0   0.0   1.0    1.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   2.0   2.0    0.0   9.0    3.0    0.0   0.0   1.0   1.0   2.0    0.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    63.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0   5.0   0.0   0.0   0.0   2.0   0.0    0.0   0.0    3.0    1.0   0.0   0.0   2.0   0.0    0.0    0.0   0.23170731707317074  19 / 82
2.0   4.0    0.0   93.0   0.0   0.0   1.0   2.0   0.0   1.0   0.0   0.0   3.0   1.0   2.0   0.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    76.0  1.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    2.0   1.0    4.0    0.0   0.0   0.0   0.0   2.0    0.0    7.0   0.21649484536082475  21 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---   ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   4.0   0.0   1.0   0.0    0.0   2.0    0.0    0.0   0.0   0.0   84.0  0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   1.0    0.0   2.0    3.0   0.0   0.0   0.0   0.0   0.0   4.0   1.0   0.0   0.0   0.0   0.0    1.0   2.0    1.0    0.0   0.0   0.0   0.0   83.0   1.0    1.0   0.17                 17 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    3.0   0.0    0.0    5.0   1.0   7.0   1.0   0.0    88.0   0.0   0.17757009345794392  19 / 107
0.0   0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    7.0    0.0   0.0   0.0   0.0   0.0    0.0    72.0  0.1724137931034483   15 / 87
93.0  115.0  78.0  116.0  92.0  83.0  84.0  75.0  83.0  98.0  99.0  92.0  99.0  98.0  81.0  110.0  93.0  118.0  103.0  92.0  93.0  87.0  98.0  107.0  109.0  94.0  0.19718875502008032  491 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.802811
2    0.89237
3    0.928514
4    0.948594
5    0.962651
6    0.972691
7    0.976707
8    0.980321
9    0.984337
10   0.98755
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:46  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:46  35.746 sec  79420 obs/sec     1         1             10007      0.657631         1.27081             0.992315       0.310207                         0.658639           1.27232               0.99227          0.321285
    2019-07-24 14:06:47  36.597 sec  105336 obs/sec    10        10            100070     0.471202         0.695522            0.996054       0.190043                         0.472909           0.700294              0.996015         0.197189
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0879052
C13         0.964094               0.964094             0.0847489
C8          0.865674               0.865674             0.0760972
C9          0.822893               0.822893             0.0723365
C11         0.821564               0.821564             0.0722197
C12         0.819599               0.819599             0.072047
C7          0.805493               0.805493             0.070807
C14         0.67839                0.67839              0.059634
C6          0.675396               0.675396             0.0593708
C5          0.668078               0.668078             0.0587275
C10         0.643779               0.643779             0.0565915
C3          0.605547               0.605547             0.0532307
C16         0.581603               0.581603             0.0511259
C4          0.563595               0.563595             0.0495429
C2          0.452822               0.452822             0.0398054
C1          0.407368               0.407368             0.0358097
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_50

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013742722370011506  0.00037054484710097313  0.0         -0.012920229689484586  0.7105631828308105  0.012646287982008531  0.7535614967346191
    3        26       Softmax                 0.0   0.0   0.0019873051186060854  0.0003792508505284786   0.0         0.00550316611802023    0.5019514560699463  -0.4835996683442868   0.2622779607772827


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21426803443162618
RMSE: 0.4628909530673787
LogLoss: 0.709296571734733
Mean Per-Class Error: 0.2052408555400789
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    4.0    2.0    2.0    7.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    1.0    0.0    3.0    0.0    5.0    1.0    0.09620253164556962  38 / 395
0.0    306.0  0.0    8.0    3.0    3.0    0.0    9.0    5.0    1.0    1.0    1.0    0.0    0.0    0.0    4.0    0.0    15.0   16.0   0.0    0.0    3.0    1.0    4.0    3.0    0.0    0.2010443864229765   77 / 383
0.0    0.0    301.0  1.0    10.0   1.0    13.0   1.0    0.0    0.0    22.0   0.0    2.0    0.0    2.0    0.0    1.0    0.0    6.0    0.0    4.0    0.0    4.0    0.0    0.0    0.0    0.18206521739130435  67 / 368
1.0    30.0   0.0    325.0  0.0    2.0    0.0    7.0    0.0    2.0    1.0    0.0    5.0    1.0    4.0    4.0    0.0    11.0   0.0    0.0    1.0    0.0    0.0    6.0    0.0    3.0    0.1935483870967742   78 / 403
0.0    7.0    3.0    0.0    293.0  4.0    14.0   0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    3.0    7.0    6.0    16.0   4.0    0.0    1.0    0.0    2.0    0.0    16.0   0.23697916666666666  91 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    6.0    0.0    0.0    0.0    0.0    2.0    8.0    0.0    0.0    2.0    0.0    13.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    10.0   333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    4.0    0.0    7.0    4.0    0.0    1.0    2.0    11.0   0.0    11.0   3.0    0.0    2.0    1.0    1.0    8.0    1.0    4.0    6.0    1.0    0.0    0.0    316.0  8.0    3.0    0.19796954314720813  78 / 394
0.0    0.0    0.0    2.0    0.0    13.0   1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    7.0    4.0    0.0    6.0    23.0   0.0    22.0   2.0    2.0    310.0  0.0    0.21119592875318066  83 / 393
2.0    2.0    0.0    1.0    9.0    6.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    1.0    37.0   2.0    0.0    0.0    0.0    3.0    0.0    295.0  0.19398907103825136  71 / 366
391.0  511.0  337.0  434.0  374.0  388.0  349.0  296.0  342.0  341.0  393.0  357.0  450.0  348.0  378.0  405.0  362.0  411.0  354.0  395.0  408.0  389.0  405.0  412.0  387.0  386.0  0.20413875837248827  2,042 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.795861
2    0.883535
3    0.920624
4    0.942317
5    0.955413
6    0.96521
7    0.973208
8    0.979606
9    0.982405
10   0.985104

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21664311284439564
RMSE: 0.46544936657427693
LogLoss: 0.7151995295455077
Mean Per-Class Error: 0.210839201441444
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13    14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0   0.0   3.0    0.0   0.07865168539325842  7 / 89
0.0   78.0   0.0   4.0    2.0   0.0   0.0   5.0   1.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0    0.0    4.0    5.0   0.0   0.0    2.0   1.0   2.0   1.0    0.0   0.2641509433962264   28 / 106
0.0   0.0    64.0  0.0    3.0   0.0   2.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0   2.0   0.0    0.0    0.0    3.0   0.0   0.0    0.0   2.0   0.0   0.0    0.0   0.21951219512195122  18 / 82
1.0   6.0    0.0   90.0   0.0   0.0   0.0   4.0   0.0   0.0   1.0    0.0   2.0   1.0   1.0   2.0    0.0    3.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0   0.19642857142857142  22 / 112
0.0   0.0    0.0   0.0    69.0  4.0   4.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   1.0    1.0    2.0    5.0   2.0   0.0    1.0   0.0   1.0   0.0    4.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   1.0    0.0   3.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    2.0   85.0  0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   1.0    0.0   3.0    2.0   0.0   0.0   1.0   3.0   0.0   6.0    2.0   0.0   0.0   0.0   0.0    2.0    1.0    0.0   0.0   0.0    0.0   0.0   75.0  3.0    1.0   0.25                 25 / 100
0.0   0.0    0.0   0.0    0.0   3.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   6.0    1.0    0.0    1.0   3.0   0.0    7.0   1.0   0.0   84.0   0.0   0.21495327102803738  23 / 107
1.0   1.0    0.0   1.0    3.0   2.0   0.0   0.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0    0.0    0.0    6.0   0.0   0.0    0.0   0.0   0.0   0.0    71.0  0.1839080459770115   16 / 87
90.0  119.0  69.0  122.0  88.0  89.0  89.0  85.0  81.0  95.0  104.0  99.0  94.0  96.0  73.0  118.0  100.0  100.0  86.0  94.0  103.0  97.0  97.0  97.0  110.0  95.0  0.21044176706827308  524 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789558
2    0.883132
3    0.92008
4    0.941767
5    0.954618
6    0.96506
7    0.973494
8    0.981526
9    0.983133
10   0.986345
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:32  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:32  1 min 21.510 sec  73043 obs/sec     1         1             10007      0.603666         1.1488              0.993524       0.324703                         0.601917           1.13936               0.993544         0.325703
    2019-07-24 14:07:33  1 min 22.512 sec  89428 obs/sec     10        10            100070     0.462891         0.709297            0.996192       0.204139                         0.465449           0.7152                0.99614          0.210442
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0866399
C13         0.981053               0.981053             0.0849983
C9          0.963267               0.963267             0.0834574
C12         0.959046               0.959046             0.0830916
C8          0.813073               0.813073             0.0704445
C7          0.797073               0.797073             0.0690583
C11         0.773353               0.773353             0.0670032
C10         0.711162               0.711162             0.061615
C14         0.700857               0.700857             0.0607221
C6          0.692375               0.692375             0.0599873
C16         0.641376               0.641376             0.0555687
C3          0.581715               0.581715             0.0503997
C5          0.571562               0.571562             0.0495201
C4          0.504836               0.504836             0.0437389
C1          0.429353               0.429353             0.0371991
C2          0.421927               0.421927             0.0365558
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_75

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007657941453089734  0.0001872815191745758  0.0         -0.024535579463645263  0.28531205654144287  0.2510789916452389    0.21889138221740723
    3        26       Softmax                      0.0   0.0   0.005349608933871563   0.014607846736907959   0.0         -0.37487062718859165   0.8941574096679688   -0.46937918456734073  0.41360533237457275


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21936021842712822
RMSE: 0.4683590699742327
LogLoss: 0.7121337188881912
Mean Per-Class Error: 0.2044842656635617
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    3.0    2.0    6.0    0.0    10.0   0.0    5.0    1.0    1.0    0.0    1.0    0.0    2.0    6.0    5.0    0.0    0.11645569620253164  46 / 395
0.0    329.0  0.0    8.0    1.0    2.0    6.0    1.0    0.0    0.0    3.0    0.0    1.0    0.0    1.0    6.0    2.0    8.0    7.0    1.0    0.0    0.0    4.0    2.0    1.0    0.0    0.1409921671018277   54 / 383
0.0    0.0    286.0  0.0    25.0   2.0    14.0   2.0    0.0    0.0    19.0   0.0    0.0    0.0    4.0    0.0    3.0    0.0    8.0    1.0    0.0    0.0    3.0    0.0    0.0    0.0    0.22070844686648503  81 / 367
3.0    22.0   0.0    319.0  0.0    1.0    0.0    8.0    1.0    5.0    2.0    0.0    3.0    3.0    3.0    3.0    0.0    16.0   0.0    0.0    4.0    0.0    0.0    10.0   0.0    0.0    0.20843672456575682  84 / 403
0.0    15.0   0.0    0.0    295.0  2.0    22.0   1.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    17.0   6.0    0.0    0.0    0.0    3.0    0.0    11.0   0.23177083333333334  89 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    15.0   4.0    2.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    2.0    3.0    4.0    12.0   0.0    0.0    2.0    2.0    1.0    2.0    1.0    0.0    0.0    2.0    0.0    5.0    3.0    1.0    4.0    3.0    0.0    0.0    332.0  8.0    7.0    0.15736040609137056  62 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    19.0   0.0    1.0    14.0   1.0    19.0   1.0    0.0    326.0  0.0    0.17048346055979643  67 / 393
0.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    14.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    1.0    26.0   2.0    0.0    0.0    0.0    2.0    0.0    309.0  0.15803814713896458  58 / 367
385.0  502.0  324.0  422.0  417.0  348.0  388.0  304.0  338.0  353.0  396.0  335.0  417.0  370.0  402.0  411.0  375.0  405.0  314.0  374.0  386.0  348.0  449.0  420.0  414.0  406.0  0.20373887833649906  2,038 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796261
2    0.884635
3    0.919924
4    0.941018
5    0.954913
6    0.964211
7    0.972108
8    0.977407
9    0.981306
10   0.985204

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22120602680774376
RMSE: 0.47032544775691626
LogLoss: 0.7197794981526966
Mean Per-Class Error: 0.20694598691751492
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17    18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0   0.0    1.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0    3.0    0.0    0.0898876404494382   8 / 89
0.0   84.0   0.0   2.0    1.0   0.0   3.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   2.0    1.0    3.0   3.0   0.0   0.0   0.0   3.0    1.0    1.0    0.0    0.20754716981132076  22 / 106
0.0   0.0    60.0  0.0    7.0   0.0   2.0   1.0   0.0   0.0    5.0   0.0   0.0   0.0    1.0   0.0    1.0    0.0   3.0   1.0   0.0   0.0   1.0    0.0    0.0    0.0    0.2682926829268293   22 / 82
2.0   4.0    0.0   89.0   0.0   0.0   0.0   2.0   1.0   2.0    1.0   0.0   1.0   2.0    0.0   2.0    0.0    2.0   0.0   0.0   2.0   0.0   0.0    2.0    0.0    0.0    0.20535714285714285  23 / 112
0.0   2.0    0.0   0.0    73.0  2.0   6.0   0.0   0.0   0.0    2.0   0.0   0.0   0.0    0.0   1.0    0.0    1.0   4.0   3.0   0.0   0.0   0.0    1.0    0.0    2.0    0.24742268041237114  24 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0   1.0    0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0   86.0   0.0    0.0    0.0    0.06521739130434782  6 / 92
0.0   0.0    1.0   2.0    8.0   0.0   0.0   1.0   0.0   0.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0    2.0   1.0   0.0   1.0   0.0   0.0    80.0   1.0    1.0    0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   3.0    7.0    0.0   0.0   3.0   0.0   5.0   1.0    0.0    87.0   0.0    0.18691588785046728  20 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    0.0    0.0   5.0   1.0   0.0   0.0   0.0    0.0    0.0    74.0   0.14942528735632185  13 / 87
97.0  127.0  69.0  116.0  99.0  79.0  97.0  73.0  78.0  102.0  96.0  89.0  89.0  100.0  79.0  119.0  102.0  97.0  82.0  88.0  99.0  79.0  114.0  105.0  112.0  103.0  0.20642570281124498  514 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.793574
2    0.884739
3    0.917269
4    0.939357
5    0.955823
6    0.96506
7    0.971486
8    0.977108
9    0.979518
10   0.984739
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:08:04  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:08:04  1 min 53.108 sec  185314 obs/sec    1         1             10007      0.688465         1.46587             0.991578       0.387784                         0.689493           1.47195               0.991529         0.38996
    2019-07-24 14:08:04  1 min 53.594 sec  192442 obs/sec    10        10            100070     0.468359         0.712134            0.996102       0.203739                         0.470325           0.719779              0.996058         0.206426
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.093974
C13         0.914434               0.914434             0.0859331
C8          0.85458                0.85458              0.0803083
C7          0.769061               0.769061             0.0722718
C9          0.767644               0.767644             0.0721386
C11         0.711846               0.711846             0.066895
C12         0.688313               0.688313             0.0646836
C6          0.66676                0.66676              0.0626582
C4          0.60067                0.60067              0.0564474
C14         0.598746               0.598746             0.0562666
C16         0.578974               0.578974             0.0544086
C5          0.563914               0.563914             0.0529933
C10         0.563499               0.563499             0.0529543
C3          0.51334                0.51334              0.0482406
C1          0.438302               0.438302             0.041189
C2          0.411152               0.411152             0.0386376
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_31

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  -------------------  ------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007677072997580581  0.00017819274216890335  0.0         -0.026128304567919258  0.28692829608917236  0.21949739152245995  0.248803973197937
    3        26       Softmax                      0.0   0.0   0.004854957418361804   0.011163178831338882    0.0         -0.40397775060297975   0.8610029220581055   -0.4594246372534286  0.3682239055633545


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22013881313269912
RMSE: 0.4691895279444109
LogLoss: 0.7148193160906404
Mean Per-Class Error: 0.20313686874356443
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    3.0    6.0    0.0    1.0    0.0    2.0    1.0    4.0    2.0    6.0    0.0    2.0    3.0    2.0    1.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    332.0  0.0    4.0    3.0    1.0    6.0    5.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    15.0   3.0    0.0    2.0    1.0    0.0    3.0    0.0    0.0    0.13089005235602094  50 / 382
0.0    0.0    294.0  0.0    10.0   0.0    11.0   1.0    0.0    0.0    26.0   0.0    1.0    0.0    4.0    0.0    4.0    2.0    8.0    3.0    1.0    0.0    3.0    0.0    0.0    0.0    0.20108695652173914  74 / 368
1.0    17.0   0.0    321.0  0.0    2.0    0.0    10.0   1.0    6.0    0.0    1.0    4.0    5.0    6.0    3.0    0.0    9.0    3.0    0.0    0.0    0.0    0.0    8.0    0.0    6.0    0.20347394540942929  82 / 403
0.0    7.0    1.0    0.0    304.0  1.0    16.0   1.0    0.0    0.0    8.0    0.0    0.0    0.0    1.0    1.0    5.0    3.0    10.0   7.0    0.0    0.0    0.0    8.0    0.0    11.0   0.20833333333333334  80 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    0.0    2.0    0.0    7.0    3.0    2.0    1.0    0.0    0.0    0.0    0.0    8.0    1.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    0.0    0.0    8.0    3.0    0.0    0.0    0.0    9.0    2.0    9.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    4.0    13.0   4.0    2.0    0.0    326.0  5.0    6.0    0.17048346055979643  67 / 393
0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    18.0   0.0    3.0    27.0   4.0    38.0   1.0    0.0    294.0  0.0    0.25190839694656486  99 / 393
1.0    0.0    0.0    0.0    19.0   1.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    11.0   1.0    21.0   3.0    0.0    0.0    0.0    4.0    0.0    297.0  0.1885245901639344   69 / 366
418.0  490.0  366.0  401.0  396.0  351.0  335.0  308.0  350.0  351.0  410.0  320.0  394.0  359.0  408.0  394.0  364.0  460.0  358.0  391.0  416.0  396.0  432.0  402.0  365.0  368.0  0.20243926821953415  2,025 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.797561
2    0.888633
3    0.921024
4    0.943017
5    0.955813
6    0.96531
7    0.972508
8    0.977707
9    0.981706
10   0.985904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22300189000870443
RMSE: 0.4722307592784532
LogLoss: 0.7230390377855231
Mean Per-Class Error: 0.2036461220007953
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12    13     14    15     16     17     18    19    20     21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  ----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    0.0    1.0    1.0   0.0   0.0    2.0   1.0    1.0   2.0   0.0   0.10112359550561797  9 / 89
0.0   88.0   0.0   0.0    2.0   0.0   1.0   2.0   1.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0    0.0    5.0    2.0   0.0   1.0    1.0   0.0    2.0   0.0   0.0   0.16981132075471697  18 / 106
0.0   0.0    62.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0   6.0    0.0   0.0   0.0    1.0   0.0    2.0    0.0    3.0   1.0   0.0    0.0   1.0    0.0   0.0   0.0   0.24390243902439024  20 / 82
1.0   2.0    0.0   90.0   0.0   0.0   0.0   4.0   0.0   1.0   0.0    1.0   2.0   2.0    1.0   2.0    0.0    2.0    1.0   0.0   0.0    0.0   0.0    2.0   0.0   1.0   0.19642857142857142  22 / 112
0.0   0.0    0.0   0.0    74.0  0.0   3.0   0.0   0.0   0.0   4.0    0.0   0.0   0.0    0.0   0.0    2.0    1.0    3.0   4.0   0.0    0.0   0.0    2.0   0.0   4.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   3.0   0.0    0.0   0.0    0.0    0.0    0.0   0.0   2.0    0.0   86.0   0.0   0.0   0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    2.0   0.0   0.0   0.0   3.0   0.0   4.0    0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   3.0   1.0    0.0   0.0    80.0  3.0   1.0   0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   1.0    7.0    0.0    0.0   7.0   2.0    11.0  1.0    0.0   78.0  0.0   0.27102803738317754  29 / 107
1.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0   0.0    0.0   0.0    2.0    0.0    3.0   1.0   0.0    0.0   0.0    1.0   0.0   71.0  0.1839080459770115   16 / 87
98.0  116.0  78.0  112.0  96.0  79.0  81.0  83.0  83.0  94.0  105.0  87.0  87.0  102.0  79.0  115.0  102.0  118.0  92.0  94.0  106.0  94.0  102.0  98.0  98.0  91.0  0.2036144578313253   507 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796385
2    0.889157
3    0.920482
4    0.939759
5    0.955823
6    0.96747
7    0.973494
8    0.975502
9    0.979518
10   0.984739
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:05  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:05  54.383 sec  200140 obs/sec    1         1             10007      0.695727         1.46237             0.991395       0.388483                         0.695831           1.46221               0.991373         0.390361
    2019-07-24 14:07:06  54.805 sec  218017 obs/sec    10        10            100070     0.46919          0.714819            0.996087       0.202439                         0.472231           0.723039              0.996026         0.203614
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0980421
C13         0.861448               0.861448             0.0844582
C8          0.790072               0.790072             0.0774603
C7          0.762083               0.762083             0.0747162
C12         0.75873                0.75873              0.0743875
C9          0.72596                0.72596              0.0711746
C11         0.660966               0.660966             0.0648025
C14         0.647655               0.647655             0.0634974
C5          0.63671                0.63671              0.0624244
C10         0.569012               0.569012             0.0557872
C16         0.567665               0.567665             0.0556551
C3          0.520818               0.520818             0.0510621
C4          0.490265               0.490265             0.0480666
C6          0.488546               0.488546             0.0478981
C1          0.372205               0.372205             0.0364918
C2          0.347562               0.347562             0.0340757
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_67

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms         mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -----------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015716367935283415  0.0003595622256398201  0.0         -0.014133825079607476  0.75227952003479   -0.09229674692659094  0.7391037940979004
    3        26       Softmax                 0.0   0.0   0.0019094796619426163  0.0004044589586555958  0.0         -0.015427443757228222  0.385636568069458  -0.5848417125657789   0.2693350315093994


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21371071739980277
RMSE: 0.4622885650757574
LogLoss: 0.7256915479091308
Mean Per-Class Error: 0.20989172472275897
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
362.0  0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    2.0    2.0    0.0    4.0    0.0    2.0    0.0    1.0    1.0    3.0    1.0    3.0    0.0    2.0    2.0    5.0    1.0    0.08354430379746836  33 / 395
0.0    315.0  0.0    11.0   2.0    6.0    2.0    5.0    2.0    0.0    0.0    0.0    2.0    0.0    1.0    2.0    3.0    16.0   8.0    0.0    0.0    4.0    1.0    1.0    1.0    0.0    0.17539267015706805  67 / 382
0.0    0.0    293.0  0.0    26.0   1.0    10.0   1.0    0.0    0.0    18.0   0.0    0.0    0.0    4.0    0.0    1.0    0.0    6.0    2.0    0.0    0.0    6.0    0.0    0.0    0.0    0.20380434782608695  75 / 368
4.0    26.0   0.0    320.0  0.0    1.0    0.0    5.0    0.0    4.0    0.0    0.0    4.0    12.0   8.0    4.0    0.0    5.0    4.0    1.0    0.0    0.0    0.0    5.0    0.0    0.0    0.20595533498759305  83 / 403
0.0    7.0    0.0    0.0    303.0  4.0    16.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    4.0    9.0    7.0    0.0    0.0    0.0    6.0    0.0    22.0   0.2109375            81 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    26.0   0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    6.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
1.0    4.0    0.0    7.0    15.0   0.0    1.0    5.0    7.0    0.0    10.0   2.0    0.0    0.0    2.0    0.0    8.0    0.0    14.0   1.0    5.0    0.0    0.0    307.0  4.0    1.0    0.22081218274111675  87 / 394
0.0    0.0    0.0    0.0    0.0    3.0    0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    8.0    0.0    4.0    13.0   4.0    20.0   1.0    3.0    334.0  0.0    0.15012722646310434  59 / 393
2.0    0.0    0.0    1.0    15.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    27.0   5.0    0.0    0.0    0.0    1.0    0.0    300.0  0.18256130790190736  67 / 367
430.0  520.0  333.0  407.0  436.0  363.0  362.0  333.0  334.0  355.0  381.0  322.0  459.0  384.0  390.0  372.0  370.0  382.0  306.0  390.0  401.0  374.0  440.0  374.0  390.0  395.0  0.2088373487953614   2,089 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791163
2    0.880636
3    0.914926
4    0.936619
5    0.950715
6    0.961712
7    0.971109
8    0.977907
9    0.981905
10   0.985205

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2165650840162213
RMSE: 0.46536553806252273
LogLoss: 0.7343619834311332
Mean Per-Class Error: 0.21617709226000745
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10    11    12    13     14    15     16    17    18    19    20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.0   1.0   0.0   1.0    0.0   1.0    0.0   2.0    0.0   0.06741573033707865  6 / 89
0.0    82.0   0.0   2.0    2.0    0.0   1.0   3.0   1.0   0.0   0.0   0.0   1.0   0.0    1.0   0.0    0.0   7.0   2.0   0.0   0.0    3.0   0.0    1.0   0.0    0.0   0.22641509433962265  24 / 106
0.0    0.0    62.0  0.0    6.0    0.0   2.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0   3.0   1.0   0.0    0.0   2.0    0.0   0.0    0.0   0.24390243902439024  20 / 82
2.0    6.0    0.0   90.0   0.0    0.0   0.0   2.0   0.0   0.0   0.0   0.0   1.0   3.0    3.0   2.0    0.0   1.0   2.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.19642857142857142  22 / 112
0.0    1.0    0.0   0.0    72.0   2.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   1.0   3.0   3.0   0.0    0.0   0.0    1.0   0.0    9.0   0.25773195876288657  25 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   6.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0    1.0   84.0   0.0   0.0    0.0   0.08695652173913043  8 / 92
1.0    0.0    0.0   2.0    5.0    0.0   0.0   2.0   2.0   0.0   4.0   2.0   0.0   0.0    0.0   0.0    2.0   0.0   5.0   0.0   2.0    0.0   0.0    71.0  2.0    0.0   0.29                 29 / 100
0.0    0.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    2.0   0.0   0.0   1.0   2.0    6.0   1.0    0.0   93.0   0.0   0.1308411214953271   14 / 107
1.0    0.0    0.0   0.0    6.0    0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   6.0   2.0   0.0    0.0   0.0    0.0   0.0    69.0  0.20689655172413793  18 / 87
104.0  130.0  68.0  116.0  100.0  81.0  89.0  89.0  80.0  99.0  98.0  90.0  97.0  103.0  82.0  110.0  91.0  93.0  82.0  95.0  103.0  86.0  109.0  87.0  109.0  99.0  0.21485943775100402  535 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785141
2    0.87751
3    0.912851
4    0.936546
5    0.948996
6    0.960241
7    0.96747
8    0.976707
9    0.982731
10   0.986345
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:51  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:51  1 min 40.488 sec  58180 obs/sec     1         1             10007      0.581704         1.08116             0.993986       0.293512                         0.580328           1.07455               0.993999         0.302811
    2019-07-24 14:07:53  1 min 42.021 sec  60246 obs/sec     10        10            100070     0.462289         0.725692            0.996202       0.208837                         0.465366           0.734362              0.996141         0.214859
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0909081
C13         0.947034               0.947034             0.0860931
C9          0.903264               0.903264             0.082114
C12         0.888697               0.888697             0.0807897
C8          0.777872               0.777872             0.0707148
C7          0.774733               0.774733             0.0704295
C11         0.765865               0.765865             0.0696234
C14         0.709291               0.709291             0.0644803
C10         0.652487               0.652487             0.0593164
C16         0.576021               0.576021             0.052365
C6          0.574146               0.574146             0.0521945
C3          0.571905               0.571905             0.0519908
C5          0.514138               0.514138             0.0467393
C4          0.51237                0.51237              0.0465786
C2          0.430759               0.430759             0.0391594
C1          0.401539               0.401539             0.0365031
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_5

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007623109117957938  0.00017306715017184615  0.0         -0.013949696246911003  0.2866189479827881  0.17442998922207784  0.2970670461654663
    3        26       Softmax                      0.0   0.0   0.0048346473556823465  0.012230843305587769    0.0         -0.3938744567612258    0.8665852546691895  -0.479997054172527   0.32798802852630615


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22137140502280486
RMSE: 0.47050122744027445
LogLoss: 0.7284707576940517
Mean Per-Class Error: 0.19887192099482107
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    3.0    3.0    1.0    5.0    0.0    3.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    6.0    1.0    5.0    3.0    0.09113924050632911  36 / 395
0.0    319.0  0.0    11.0   0.0    1.0    4.0    7.0    2.0    0.0    1.0    0.0    0.0    0.0    10.0   11.0   1.0    7.0    3.0    0.0    0.0    0.0    2.0    3.0    0.0    1.0    0.1671018276762402   64 / 383
0.0    0.0    288.0  0.0    17.0   0.0    40.0   0.0    0.0    0.0    10.0   0.0    0.0    0.0    5.0    0.0    1.0    0.0    0.0    5.0    1.0    0.0    0.0    1.0    0.0    0.0    0.21739130434782608  80 / 368
0.0    18.0   0.0    324.0  0.0    1.0    1.0    8.0    1.0    6.0    0.0    1.0    4.0    7.0    10.0   2.0    0.0    9.0    1.0    2.0    1.0    0.0    0.0    3.0    1.0    2.0    0.19402985074626866  78 / 402
0.0    12.0   0.0    0.0    289.0  2.0    18.0   3.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    2.0    6.0    6.0    5.0    6.0    1.0    0.0    0.0    8.0    0.0    17.0   0.24739583333333334  95 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    8.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    2.0    0.0    16.0   1.0    2.0    0.0    0.0    0.0    0.0    0.0    8.0    2.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    2.0    0.0    6.0    6.0    0.0    1.0    4.0    1.0    1.0    6.0    1.0    0.0    0.0    0.0    2.0    11.0   4.0    13.0   3.0    2.0    0.0    0.0    328.0  2.0    1.0    0.16751269035532995  66 / 394
0.0    0.0    0.0    0.0    0.0    7.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    2.0    6.0    2.0    16.0   1.0    0.0    353.0  0.0    0.10178117048346055  40 / 393
0.0    0.0    0.0    1.0    12.0   0.0    2.0    0.0    0.0    16.0   0.0    0.0    0.0    0.0    0.0    0.0    7.0    0.0    30.0   2.0    0.0    0.0    0.0    3.0    1.0    293.0  0.2016348773841962   74 / 367
387.0  515.0  328.0  415.0  358.0  371.0  419.0  312.0  331.0  373.0  423.0  343.0  428.0  379.0  409.0  396.0  366.0  372.0  311.0  379.0  398.0  369.0  422.0  405.0  412.0  382.0  0.1978406478056583   1,979 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.802159
2    0.878836
3    0.914526
4    0.935519
5    0.951914
6    0.961612
7    0.968709
8    0.976007
9    0.980006
10   0.984005

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22566676028644655
RMSE: 0.4750439561624235
LogLoss: 0.7345964317820817
Mean Per-Class Error: 0.20470234506057283
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13     14    15     16    17    18    19    20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0    0.0   3.0    0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   83.0   0.0   4.0    0.0   0.0   0.0   2.0   1.0   0.0    1.0    0.0   0.0   0.0    3.0   5.0    0.0   3.0   2.0   0.0   0.0    0.0   1.0    1.0   0.0    0.0   0.2169811320754717   23 / 106
0.0   0.0    59.0  0.0    4.0   0.0   10.0  0.0   0.0   0.0    3.0    0.0   0.0   0.0    3.0   0.0    0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0    0.0   0.2804878048780488   23 / 82
0.0   4.0    0.0   91.0   0.0   1.0   0.0   3.0   0.0   2.0    0.0    1.0   2.0   2.0    4.0   0.0    0.0   2.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.1875               21 / 112
0.0   3.0    0.0   0.0    65.0  2.0   4.0   1.0   0.0   0.0    3.0    0.0   0.0   0.0    0.0   0.0    3.0   2.0   2.0   3.0   0.0    0.0   0.0    3.0   0.0    6.0   0.32989690721649484  32 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   2.0    0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   4.0    2.0   0.0   1.0   3.0   0.0   0.0    2.0    1.0   0.0   0.0    0.0   0.0    2.0   1.0   3.0   0.0   0.0    0.0   0.0    80.0  0.0    1.0   0.2                  20 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   3.0    0.0   0.0   0.0   2.0   0.0    4.0   1.0    0.0   95.0   0.0   0.11214953271028037  12 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   6.0   1.0   0.0    0.0   0.0    2.0   0.0    68.0  0.21839080459770116  19 / 87
91.0  131.0  66.0  122.0  79.0  93.0  98.0  80.0  80.0  102.0  105.0  93.0  93.0  101.0  89.0  111.0  99.0  94.0  76.0  91.0  100.0  81.0  108.0  95.0  113.0  99.0  0.2036144578313253   507 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.796385
2    0.879116
3    0.918072
4    0.937349
5    0.954618
6    0.961446
7    0.970281
8    0.977108
9    0.981124
10   0.985542
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:24  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:24  13.513 sec  188811 obs/sec    1         1             10007      0.702034         1.51324             0.991243       0.408377                         0.702505           1.51717               0.991206         0.42008
    2019-07-24 14:06:25  13.945 sec  212012 obs/sec    10        10            100070     0.470501         0.728471            0.996067       0.197841                         0.475044           0.734596              0.995979         0.203614
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0866182
C13         0.96462                0.96462              0.0835537
C9          0.872722               0.872722             0.0755936
C7          0.849537               0.849537             0.0735854
C12         0.821506               0.821506             0.0711574
C8          0.789567               0.789567             0.0683909
C10         0.762544               0.762544             0.0660502
C11         0.723356               0.723356             0.0626558
C5          0.718566               0.718566             0.0622409
C4          0.663493               0.663493             0.0574706
C6          0.638624               0.638624             0.0553165
C14         0.635629               0.635629             0.055057
C3          0.60156                0.60156              0.052106
C16         0.601061               0.601061             0.0520628
C2          0.471411               0.471411             0.0408328
C1          0.430721               0.430721             0.0373083
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_34

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight              weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  -----------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013203322639583348  0.00035902054514735937  0.0         0.0006881729175347573    0.7362632751464844  -0.02233366879362895  0.7709023952484131
    3        26       Softmax                 0.0   0.0   0.0019484051929864038  0.0003728829324245453   0.0         -0.00012616425545694746  0.5016806125640869  -0.45377560221026286  0.21169453859329224


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21604585892398065
RMSE: 0.46480733527342344
LogLoss: 0.7211809252112973
Mean Per-Class Error: 0.216686986518763
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    3.0    4.0    0.0    4.0    0.0    2.0    2.0    2.0    0.0    2.0    0.0    2.0    2.0    6.0    0.0    0.09620253164556962  38 / 395
0.0    306.0  0.0    4.0    1.0    6.0    2.0    17.0   2.0    1.0    3.0    0.0    0.0    0.0    1.0    1.0    2.0    23.0   7.0    0.0    0.0    2.0    2.0    1.0    1.0    1.0    0.2010443864229765   77 / 383
0.0    0.0    292.0  0.0    8.0    4.0    17.0   0.0    0.0    0.0    21.0   1.0    0.0    0.0    13.0   1.0    2.0    0.0    1.0    0.0    6.0    1.0    0.0    1.0    0.0    0.0    0.20652173913043478  76 / 368
4.0    19.0   0.0    322.0  0.0    3.0    0.0    7.0    0.0    5.0    0.0    1.0    6.0    10.0   3.0    2.0    0.0    4.0    5.0    1.0    4.0    0.0    0.0    7.0    0.0    0.0    0.20099255583126552  81 / 403
0.0    5.0    1.0    1.0    279.0  2.0    27.0   1.0    2.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    5.0    4.0    11.0   5.0    0.0    0.0    1.0    8.0    4.0    17.0   0.2734375            105 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    0.0    0.0    11.0   2.0    1.0    0.0    4.0    1.0    0.0    0.0    4.0    1.0    336.0  0.0    0.0    0.0    0.10638297872340426  40 / 376
0.0    3.0    0.0    12.0   12.0   2.0    0.0    2.0    5.0    0.0    6.0    6.0    0.0    1.0    2.0    1.0    6.0    6.0    6.0    7.0    2.0    0.0    0.0    300.0  5.0    8.0    0.23469387755102042  92 / 392
0.0    0.0    0.0    2.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    3.0    10.0   0.0    2.0    10.0   1.0    13.0   1.0    0.0    336.0  0.0    0.1450381679389313   57 / 393
3.0    0.0    0.0    1.0    18.0   0.0    0.0    0.0    3.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    2.0    26.0   5.0    0.0    0.0    0.0    1.0    0.0    292.0  0.20435967302452315  75 / 367
408.0  453.0  350.0  420.0  374.0  393.0  348.0  342.0  323.0  362.0  401.0  332.0  434.0  362.0  418.0  368.0  403.0  421.0  302.0  366.0  402.0  371.0  431.0  389.0  412.0  418.0  0.21563530940717784  2,157 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.784365
2    0.880136
3    0.915925
4    0.938518
5    0.953614
6    0.963711
7    0.971808
8    0.977707
9    0.981606
10   0.985304

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22193823487874112
RMSE: 0.47110321043136727
LogLoss: 0.7376598158754849
Mean Per-Class Error: 0.2183767189913089
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   1.0    1.0   3.0    0.0    0.07865168539325842  7 / 89
0.0   80.0   0.0   1.0    1.0   1.0   1.0   6.0   1.0   0.0    0.0    0.0   0.0   0.0   1.0   0.0    1.0    8.0    1.0   0.0   0.0    1.0   2.0    1.0   0.0    0.0    0.24528301886792453  26 / 106
0.0   0.0    61.0  0.0    1.0   1.0   7.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   6.0   0.0    0.0    0.0    0.0   0.0   1.0    1.0   0.0    0.0   0.0    0.0    0.25609756097560976  21 / 82
2.0   2.0    0.0   92.0   0.0   0.0   0.0   2.0   0.0   1.0    0.0    0.0   2.0   1.0   1.0   2.0    0.0    0.0    3.0   0.0   2.0    0.0   0.0    2.0   0.0    0.0    0.17857142857142858  20 / 112
0.0   2.0    0.0   0.0    65.0  1.0   8.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   0.0   0.0    0.0    1.0    4.0   3.0   0.0    0.0   1.0    1.0   0.0    7.0    0.32989690721649484  32 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   2.0   1.0   0.0   0.0    2.0    0.0    0.0   0.0   1.0    1.0   83.0   0.0   0.0    0.0    0.09782608695652174  9 / 92
0.0   1.0    0.0   4.0    4.0   0.0   0.0   1.0   1.0   0.0    1.0    4.0   0.0   0.0   0.0   0.0    1.0    3.0    1.0   0.0   1.0    0.0   0.0    75.0  2.0    1.0    0.25                 25 / 100
0.0   0.0    0.0   0.0    0.0   3.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   1.0   1.0    2.0    0.0    0.0   4.0   0.0    5.0   1.0    0.0   90.0   0.0    0.1588785046728972   17 / 107
1.0   0.0    0.0   1.0    6.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0    1.0    5.0   2.0   0.0    0.0   0.0    0.0   0.0    69.0   0.20689655172413793  18 / 87
99.0  113.0  72.0  119.0  90.0  88.0  84.0  81.0  69.0  105.0  100.0  88.0  96.0  96.0  88.0  108.0  106.0  110.0  80.0  87.0  105.0  88.0  108.0  93.0  117.0  100.0  0.21807228915662652  543 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.781928
2    0.876707
3    0.91486
4    0.937349
5    0.955422
6    0.962651
7    0.971486
8    0.97751
9    0.981526
10   0.986345
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:08  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:08  57.475 sec  84805 obs/sec     1         1             10007      0.604807         1.1569              0.993499       0.317505                         0.603191           1.13921               0.993517         0.319277
    2019-07-24 14:07:09  58.579 sec  83880 obs/sec     10        10            100070     0.464807         0.721181            0.99616        0.215635                         0.471103           0.73766               0.996045         0.218072
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0879502
C13         0.945192               0.945192             0.0831298
C9          0.936207               0.936207             0.0823396
C12         0.886366               0.886366             0.077956
C11         0.8279                 0.8279               0.072814
C8          0.802824               0.802824             0.0706086
C7          0.766531               0.766531             0.0674166
C10         0.739249               0.739249             0.0650171
C16         0.681408               0.681408             0.05993
C14         0.675114               0.675114             0.0593764
C6          0.621196               0.621196             0.0546343
C5          0.609101               0.609101             0.0535705
C3          0.496655               0.496655             0.0436809
C4          0.478295               0.478295             0.0420662
C1          0.469592               0.469592             0.0413008
C2          0.434439               0.434439             0.038209
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_68

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0016023054471645537  0.0003392202779650688  0.0         -0.02990993556127819  0.744727373123169   -0.032966024176210744  0.7480545043945312
    3        26       Softmax                 0.0   0.0   0.0018786243921777685  0.0002664931816980243  0.0         0.007270679986320899  0.3886159658432007  -0.5573648908939169    0.260540246963501


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2141245677618358
RMSE: 0.4627359590110064
LogLoss: 0.7228638646179896
Mean Per-Class Error: 0.21136793793244874
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    0.0    7.0    0.0    0.0    0.0    1.0    1.0    9.0    1.0    1.0    0.0    2.0    3.0    6.0    0.0    0.09113924050632911  36 / 395
0.0    292.0  0.0    16.0   2.0    2.0    0.0    9.0    7.0    0.0    4.0    0.0    1.0    0.0    0.0    2.0    0.0    23.0   14.0   0.0    0.0    5.0    0.0    2.0    4.0    0.0    0.23759791122715404  91 / 383
0.0    0.0    294.0  0.0    17.0   1.0    13.0   0.0    0.0    0.0    18.0   0.0    0.0    0.0    7.0    0.0    3.0    0.0    5.0    3.0    1.0    0.0    5.0    0.0    0.0    1.0    0.20108695652173914  74 / 368
5.0    8.0    0.0    326.0  0.0    2.0    0.0    9.0    0.0    6.0    0.0    2.0    7.0    4.0    3.0    2.0    0.0    13.0   2.0    1.0    1.0    0.0    0.0    9.0    0.0    3.0    0.19106699751861042  77 / 403
0.0    6.0    2.0    0.0    298.0  5.0    10.0   2.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    11.0   3.0    7.0    6.0    0.0    0.0    0.0    6.0    0.0    22.0   0.22395833333333334  86 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    19.0   1.0    3.0    0.0    0.0    3.0    0.0    0.0    1.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    1.0    0.0    9.0    11.0   3.0    1.0    2.0    6.0    1.0    11.0   1.0    0.0    0.0    0.0    0.0    11.0   4.0    11.0   6.0    2.0    0.0    0.0    309.0  4.0    1.0    0.21573604060913706  85 / 394
1.0    0.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    9.0    0.0    3.0    26.0   1.0    58.0   3.0    1.0    284.0  0.0    0.27735368956743     109 / 393
1.0    0.0    0.0    0.0    13.0   1.0    0.0    0.0    0.0    9.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    26.0   5.0    0.0    0.0    0.0    2.0    0.0    301.0  0.17534246575342466  64 / 365
400.0  386.0  372.0  445.0  405.0  398.0  277.0  308.0  345.0  361.0  388.0  367.0  461.0  368.0  377.0  365.0  379.0  459.0  368.0  410.0  370.0  425.0  439.0  390.0  348.0  392.0  0.2106368089573128   2,107 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789363
2    0.885134
3    0.918125
4    0.941118
5    0.956413
6    0.96541
7    0.972408
8    0.978406
9    0.983405
10   0.986904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2185333320479376
RMSE: 0.46747548817872536
LogLoss: 0.7393378660694017
Mean Per-Class Error: 0.2154115991320827
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10    11     12     13     14    15     16     17     18    19    20    21     22     23    24     25     Error                Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  -----  -----  -----  ----  ----  ----  -----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    1.0    0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.0    1.0    1.0   3.0    0.0    0.0898876404494382   8 / 89
0.0   78.0  0.0   3.0    1.0   0.0   0.0   3.0   2.0   0.0    1.0   0.0    0.0    0.0    0.0   0.0    0.0    8.0    4.0   0.0   0.0   3.0    0.0    2.0   1.0    0.0    0.2641509433962264   28 / 106
0.0   0.0   61.0  0.0    3.0   0.0   4.0   0.0   0.0   0.0    4.0   0.0    0.0    0.0    2.0   0.0    1.0    0.0    3.0   1.0   1.0   0.0    2.0    0.0   0.0    0.0    0.25609756097560976  21 / 82
3.0   0.0   0.0   89.0   0.0   1.0   0.0   3.0   0.0   2.0    0.0   1.0    3.0    1.0    1.0   1.0    0.0    2.0    1.0   0.0   0.0   0.0    0.0    2.0   0.0    2.0    0.20535714285714285  23 / 112
0.0   1.0   1.0   0.0    70.0  2.0   3.0   0.0   0.0   0.0    1.0   0.0    0.0    0.0    0.0   0.0    3.0    1.0    3.0   3.0   0.0   0.0    0.0    1.0   0.0    8.0    0.27835051546391754  27 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---    ---    ---    ---   ---   ---   ---    ---    ---   ---    ---    ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    4.0    0.0    0.0   0.0    0.0    1.0    0.0   0.0   0.0   0.0    87.0   0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0   1.0   0.0   4.0    4.0   1.0   0.0   1.0   1.0   0.0    4.0   1.0    0.0    0.0    0.0   0.0    2.0    1.0    2.0   1.0   1.0   0.0    0.0    76.0  0.0    0.0    0.24                 24 / 100
0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    0.0   1.0    4.0    0.0    0.0   7.0   0.0   17.0   2.0    0.0   76.0   0.0    0.2897196261682243   31 / 107
1.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0   0.0   3.0    0.0   1.0    0.0    0.0    0.0   0.0    1.0    0.0    3.0   2.0   0.0   0.0    0.0    1.0   0.0    71.0   0.1839080459770115   16 / 87
92.0  94.0  78.0  126.0  92.0  93.0  65.0  80.0  82.0  102.0  94.0  106.0  102.0  102.0  77.0  100.0  102.0  118.0  89.0  98.0  95.0  100.0  111.0  92.0  100.0  100.0  0.21606425702811244  538 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783936
2    0.87992
3    0.916867
4    0.938956
5    0.953815
6    0.962249
7    0.970683
8    0.976707
9    0.981928
10   0.986747
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:53  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:53  1 min 42.287 sec  48342 obs/sec     1         1             10007      0.584597         1.10102             0.993924       0.30061                          0.583347           1.09001               0.993936         0.295181
    2019-07-24 14:07:55  1 min 43.832 sec  58180 obs/sec     10        10            100070     0.462736         0.722864            0.996193       0.210637                         0.467475           0.739338              0.996106         0.216064
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0910686
C13         0.901092               0.901092             0.0820612
C12         0.900514               0.900514             0.0820086
C9          0.859632               0.859632             0.0782855
C11         0.832253               0.832253             0.0757921
C7          0.793101               0.793101             0.0722266
C8          0.764834               0.764834             0.0696524
C10         0.683643               0.683643             0.0622585
C14         0.677095               0.677095             0.0616621
C6          0.641447               0.641447             0.0584157
C16         0.591483               0.591483             0.0538655
C3          0.543013               0.543013             0.0494515
C4          0.493107               0.493107             0.0449065
C5          0.487276               0.487276             0.0443755
C2          0.430953               0.430953             0.0392463
C1          0.381288               0.381288             0.0347234
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_72

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015256586023895125  0.000340881641022861    0.0         -0.008222328062210238  0.7692244052886963   0.057272885172083225  0.8401219844818115
    3        26       Softmax                 0.0   0.0   0.0018114980011537578  0.00028019596356898546  0.0         0.0030763583378599765  0.38704144954681396  -0.554003779847933    0.23532718420028687


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21676797738036088
RMSE: 0.46558348057073595
LogLoss: 0.737201616885427
Mean Per-Class Error: 0.21529216160557135
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
359.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    3.0    0.0    5.0    0.0    2.0    0.0    0.0    1.0    1.0    0.0    1.0    2.0    4.0    1.0    5.0    7.0    0.09113924050632911  36 / 395
0.0    306.0  0.0    8.0    2.0    0.0    4.0    9.0    5.0    1.0    4.0    0.0    0.0    0.0    1.0    0.0    1.0    21.0   12.0   0.0    0.0    5.0    0.0    2.0    1.0    1.0    0.2010443864229765   77 / 383
0.0    0.0    287.0  0.0    13.0   1.0    26.0   1.0    0.0    0.0    20.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    4.0    4.0    5.0    0.0    4.0    0.0    0.0    0.0    0.22010869565217392  81 / 368
3.0    24.0   0.0    323.0  0.0    0.0    1.0    7.0    0.0    8.0    1.0    2.0    7.0    3.0    0.0    3.0    0.0    6.0    0.0    0.0    1.0    0.0    0.0    10.0   0.0    4.0    0.19851116625310175  80 / 403
0.0    7.0    2.0    0.0    290.0  4.0    15.0   3.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    4.0    9.0    4.0    9.0    4.0    0.0    0.0    0.0    5.0    0.0    24.0   0.24479166666666666  94 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    1.0    0.0    16.0   1.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    346.0  0.0    0.0    0.0    0.0797872340425532   30 / 376
0.0    5.0    0.0    11.0   7.0    0.0    0.0    2.0    5.0    0.0    11.0   1.0    0.0    0.0    0.0    1.0    10.0   0.0    5.0    3.0    3.0    0.0    0.0    308.0  16.0   6.0    0.2182741116751269   86 / 394
0.0    0.0    0.0    3.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    4.0    0.0    4.0    13.0   2.0    12.0   4.0    1.0    341.0  0.0    0.13231552162849872  52 / 393
2.0    1.0    0.0    0.0    8.0    0.0    0.0    0.0    0.0    16.0   0.0    1.0    0.0    0.0    0.0    0.0    2.0    0.0    27.0   7.0    0.0    0.0    0.0    1.0    0.0    302.0  0.1771117166212534   65 / 367
393.0  493.0  324.0  430.0  369.0  356.0  370.0  319.0  341.0  361.0  412.0  344.0  434.0  362.0  360.0  372.0  349.0  415.0  324.0  379.0  406.0  377.0  465.0  386.0  439.0  423.0  0.21423572928121565  2,143 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.785764
2    0.876837
3    0.914626
4    0.938019
5    0.952314
6    0.963311
7    0.971908
8    0.977107
9    0.982105
10   0.985804

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21912493602085448
RMSE: 0.4681078252078836
LogLoss: 0.744336616249661
Mean Per-Class Error: 0.2195406891916586
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   2.0    1.0   3.0    1.0    0.0898876404494382   8 / 89
0.0   81.0   0.0   2.0    1.0   0.0   2.0   1.0   1.0   0.0    1.0    0.0   0.0   0.0   1.0   0.0    1.0   8.0    2.0   0.0   0.0    4.0   0.0    1.0   0.0    0.0    0.2358490566037736   25 / 106
0.0   0.0    59.0  0.0    2.0   0.0   9.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0    2.0   2.0   1.0    0.0   2.0    0.0   0.0    0.0    0.2804878048780488   23 / 82
2.0   5.0    0.0   91.0   0.0   0.0   0.0   4.0   0.0   2.0    0.0    1.0   3.0   1.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    1.0    0.1875               21 / 112
0.0   2.0    0.0   0.0    70.0  2.0   5.0   0.0   0.0   0.0    1.0    0.0   0.0   0.0   0.0   0.0    3.0   1.0    3.0   1.0   0.0    0.0   0.0    2.0   0.0    7.0    0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   3.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   87.0   0.0   0.0    0.0    0.05434782608695652  5 / 92
0.0   2.0    0.0   5.0    2.0   0.0   0.0   1.0   2.0   0.0    6.0    1.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0   0.0   1.0    0.0   0.0    70.0  6.0    2.0    0.3                  30 / 100
0.0   0.0    0.0   1.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   1.0   1.0    1.0   0.0    0.0   4.0   0.0    3.0   2.0    0.0   93.0   0.0    0.1308411214953271   14 / 107
1.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0    0.0    1.0   0.0   0.0   0.0   0.0    0.0   0.0    5.0   2.0   0.0    0.0   0.0    0.0   0.0    73.0   0.16091954022988506  14 / 87
92.0  120.0  64.0  120.0  85.0  85.0  97.0  79.0  80.0  102.0  106.0  93.0  97.0  94.0  73.0  106.0  90.0  104.0  83.0  90.0  103.0  85.0  123.0  91.0  126.0  102.0  0.21927710843373494  546 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780723
2    0.871888
3    0.91486
4    0.937751
5    0.949799
6    0.959438
7    0.971084
8    0.976707
9    0.983133
10   0.986345
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:08:00  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:08:00  1 min 49.696 sec  58864 obs/sec     1         1             10007      0.583165         1.09739             0.993957       0.296411                         0.578989           1.0753                0.994027         0.296787
    2019-07-24 14:08:02  1 min 51.301 sec  58214 obs/sec     10        10            100070     0.465583         0.737202            0.996148       0.214236                         0.468108           0.744337              0.996096         0.219277
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0908239
C13         0.962088               0.962088             0.0873806
C9          0.900056               0.900056             0.0817466
C12         0.841771               0.841771             0.0764529
C11         0.788091               0.788091             0.0715775
C7          0.775914               0.775914             0.0704715
C8          0.736065               0.736065             0.0668523
C14         0.671009               0.671009             0.0609437
C10         0.635619               0.635619             0.0577294
C6          0.627398               0.627398             0.0569827
C3          0.589703               0.589703             0.0535591
C16         0.568015               0.568015             0.0515893
C4          0.542925               0.542925             0.0493106
C5          0.516703               0.516703             0.046929
C2          0.450619               0.450619             0.040927
C1          0.404345               0.404345             0.0367242
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_39

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  --------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.001205290698180761  0.0003377969842404127  0.0         -0.011679573861101744  0.5951406955718994  -0.08641051997300317  0.713188886642456
    3        26       Softmax                 0.0   0.0   0.002210156777017311  0.0004206151934340596  0.0         -0.03417712843796695   0.7364704608917236  -0.49907856375149084  0.2173808217048645


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2204049420887309
RMSE: 0.4694730472441745
LogLoss: 0.7414892993833394
Mean Per-Class Error: 0.20836346632276165
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    5.0    1.0    0.0    9.0    0.0    0.0    0.0    1.0    3.0    2.0    0.0    2.0    0.0    5.0    2.0    4.0    0.0    0.09873417721518987  39 / 395
1.0    310.0  0.0    8.0    6.0    1.0    1.0    5.0    2.0    1.0    6.0    0.0    4.0    0.0    0.0    3.0    1.0    19.0   5.0    0.0    0.0    4.0    1.0    3.0    1.0    1.0    0.1906005221932115   73 / 383
0.0    0.0    298.0  0.0    15.0   0.0    18.0   1.0    0.0    0.0    20.0   0.0    0.0    0.0    1.0    0.0    2.0    0.0    5.0    1.0    4.0    0.0    1.0    1.0    1.0    0.0    0.19021739130434784  70 / 368
2.0    13.0   0.0    311.0  0.0    1.0    0.0    9.0    0.0    3.0    1.0    0.0    7.0    6.0    12.0   3.0    3.0    10.0   2.0    2.0    1.0    0.0    0.0    11.0   0.0    6.0    0.228287841191067    92 / 403
0.0    5.0    1.0    0.0    293.0  1.0    18.0   1.0    2.0    0.0    7.0    1.0    0.0    0.0    0.0    0.0    5.0    4.0    15.0   5.0    0.0    0.0    0.0    9.0    0.0    17.0   0.23697916666666666  91 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    4.0    0.0    1.0    0.0    0.0    1.0    8.0    0.0    0.0    0.0    0.0    11.0   5.0    4.0    0.0    1.0    1.0    0.0    0.0    7.0    0.0    333.0  0.0    0.0    0.0    0.11436170212765957  43 / 376
0.0    2.0    0.0    3.0    5.0    0.0    0.0    7.0    2.0    1.0    11.0   1.0    0.0    0.0    0.0    0.0    10.0   1.0    0.0    7.0    0.0    0.0    0.0    334.0  3.0    7.0    0.15228426395939088  60 / 394
1.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    16.0   0.0    1.0    21.0   3.0    30.0   0.0    1.0    310.0  0.0    0.20918367346938777  82 / 392
1.0    4.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    0.0    7.0    1.0    25.0   6.0    0.0    0.0    0.0    2.0    3.0    300.0  0.18256130790190736  67 / 367
427.0  461.0  351.0  394.0  361.0  368.0  359.0  347.0  331.0  374.0  404.0  337.0  429.0  357.0  400.0  357.0  378.0  424.0  338.0  367.0  402.0  398.0  413.0  426.0  395.0  405.0  0.2077376786963911   2,078 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.792262
2    0.878836
3    0.916425
4    0.937619
5    0.952214
6    0.963511
7    0.970709
8    0.976707
9    0.980306
10   0.984505

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22033988950347114
RMSE: 0.469403759575348
LogLoss: 0.7479332064680267
Mean Per-Class Error: 0.2085754009435257
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   2.0   0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0    0.0   2.0    2.0    2.0    0.0   0.11235955056179775  10 / 89
0.0   82.0   0.0   2.0    1.0   0.0   1.0   2.0   1.0   0.0    0.0    0.0   1.0   0.0   0.0   0.0    0.0   9.0    1.0   0.0   0.0    2.0   1.0    2.0    1.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    65.0  0.0    2.0   0.0   4.0   0.0   0.0   0.0    7.0    0.0   0.0   0.0   1.0   0.0    0.0   0.0    1.0   0.0   0.0    0.0   1.0    0.0    1.0    0.0   0.2073170731707317   17 / 82
2.0   3.0    0.0   90.0   0.0   1.0   0.0   1.0   0.0   0.0    1.0    0.0   3.0   0.0   4.0   2.0    1.0   1.0    1.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0   0.19642857142857142  22 / 112
0.0   1.0    0.0   0.0    70.0  1.0   5.0   0.0   0.0   0.0    4.0    0.0   0.0   0.0   0.0   0.0    1.0   2.0    4.0   3.0   0.0    0.0   0.0    1.0    0.0    5.0   0.27835051546391754  27 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    0.0    0.0   2.0   1.0   1.0   0.0    1.0   0.0    0.0   0.0   1.0    0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   1.0    3.0   0.0   0.0   3.0   1.0   0.0    4.0    1.0   0.0   0.0   0.0   0.0    2.0   1.0    0.0   0.0   0.0    0.0   0.0    81.0   0.0    3.0   0.19                 19 / 100
0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   1.0    6.0   0.0    0.0   4.0   1.0    10.0  0.0    0.0    84.0   0.0   0.21495327102803738  23 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   5.0    0.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    5.0   2.0   0.0    0.0   0.0    1.0    0.0    70.0  0.19540229885057472  17 / 87
99.0  116.0  76.0  114.0  84.0  84.0  90.0  89.0  77.0  105.0  101.0  90.0  92.0  96.0  83.0  106.0  98.0  111.0  87.0  84.0  102.0  93.0  104.0  101.0  112.0  96.0  0.20883534136546184  520 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.791165
2    0.878313
3    0.916867
4    0.938153
5    0.949799
6    0.963052
7    0.968675
8    0.974699
9    0.977108
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:14  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:14  1 min  3.716 sec  135229 obs/sec    1         1             10007      0.661009         1.36126             0.992236       0.379086                         0.65783            1.3493                0.992289         0.385944
    2019-07-24 14:07:15  1 min  4.318 sec  151391 obs/sec    10        10            100070     0.469473         0.741489            0.996083       0.207738                         0.469404           0.747933              0.996074         0.208835
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.101589
C13         0.872311               0.872311             0.0886171
C12         0.822144               0.822144             0.0835207
C8          0.781055               0.781055             0.0793465
C11         0.761758               0.761758             0.0773862
C7          0.710711               0.710711             0.0722003
C9          0.708967               0.708967             0.0720232
C10         0.634364               0.634364             0.0644444
C6          0.629127               0.629127             0.0639123
C16         0.604263               0.604263             0.0613864
C14         0.576213               0.576213             0.0585368
C5          0.485371               0.485371             0.0493083
C3          0.409167               0.409167             0.0415668
C4          0.377915               0.377915             0.038392
C1          0.247569               0.247569             0.0251502
C2          0.222661               0.222661             0.0226199
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_18

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011953124022738848  0.0003858060808852315   0.0         -0.05796212796514855  0.5798065662384033  -0.06358553430257546  0.6099061965942383
    3        26       Softmax                 0.0   0.0   0.0022157316691916026  0.00048712408170104027  0.0         0.03172519879591654   0.7409031391143799  -0.5496162246964709   0.2503070831298828


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2207963162186949
RMSE: 0.4698896851588625
LogLoss: 0.7390457939462316
Mean Per-Class Error: 0.20121867129169985
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    11.0   2.0    0.0    4.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    8.0    1.0    5.0    0.0    0.09620253164556962  38 / 395
0.0    306.0  0.0    8.0    1.0    0.0    3.0    5.0    2.0    0.0    2.0    1.0    1.0    0.0    0.0    2.0    0.0    37.0   7.0    1.0    0.0    2.0    0.0    3.0    0.0    1.0    0.19895287958115182  76 / 382
0.0    0.0    296.0  0.0    12.0   2.0    8.0    3.0    1.0    0.0    19.0   0.0    0.0    0.0    9.0    0.0    2.0    1.0    1.0    4.0    4.0    0.0    6.0    0.0    0.0    0.0    0.1956521739130435   72 / 368
1.0    14.0   0.0    336.0  0.0    3.0    0.0    4.0    0.0    7.0    1.0    0.0    3.0    7.0    3.0    2.0    0.0    13.0   3.0    0.0    1.0    0.0    0.0    2.0    0.0    3.0    0.1662531017369727   67 / 403
0.0    4.0    6.0    2.0    282.0  2.0    34.0   1.0    1.0    0.0    5.0    1.0    0.0    0.0    0.0    0.0    4.0    9.0    6.0    7.0    0.0    0.0    0.0    1.0    0.0    18.0   0.26370757180156656  101 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    1.0    0.0    2.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    8.0    6.0    0.0    0.0    2.0    11.0   0.0    0.0    0.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    0.0    0.0    1.0    7.0    1.0    1.0    1.0    3.0    1.0    6.0    1.0    0.0    0.0    0.0    0.0    10.0   2.0    14.0   3.0    1.0    0.0    0.0    336.0  4.0    2.0    0.14720812182741116  58 / 394
0.0    0.0    0.0    1.0    2.0    9.0    0.0    3.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    3.0    3.0    0.0    3.0    7.0    0.0    11.0   0.0    0.0    348.0  0.0    0.11450381679389313  45 / 393
3.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    0.0    16.0   0.0    1.0    0.0    0.0    0.0    0.0    4.0    1.0    31.0   7.0    0.0    0.0    0.0    1.0    0.0    289.0  0.2125340599455041   78 / 367
391.0  452.0  338.0  426.0  374.0  349.0  372.0  344.0  355.0  373.0  386.0  329.0  398.0  393.0  382.0  370.0  337.0  500.0  351.0  413.0  389.0  356.0  429.0  414.0  405.0  377.0  0.20023992802159352  2,003 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.79976
2    0.877537
3    0.915125
4    0.939218
5    0.951914
6    0.962611
7    0.970009
8    0.976107
9    0.979706
10   0.984105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22675164884033394
RMSE: 0.4761844693397024
LogLoss: 0.7479535708868551
Mean Per-Class Error: 0.21223356939682075
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   1.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   2.0    1.0    2.0    0.0   0.10112359550561797  9 / 89
0.0   78.0   0.0   0.0    1.0   0.0   2.0   2.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0   1.0    0.0   14.0   4.0   0.0   0.0   2.0   0.0    1.0    0.0    0.0   0.2641509433962264   28 / 106
0.0   0.0    60.0  0.0    3.0   1.0   3.0   1.0   0.0   0.0    5.0   0.0   0.0   0.0    3.0   0.0    1.0   0.0    1.0   1.0   0.0   0.0   3.0    0.0    0.0    0.0   0.2682926829268293   22 / 82
1.0   4.0    0.0   92.0   0.0   0.0   0.0   3.0   0.0   2.0    1.0   0.0   1.0   3.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    1.0   0.17857142857142858  20 / 112
0.0   0.0    2.0   0.0    66.0  2.0   11.0  0.0   0.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    1.0   1.0    1.0   4.0   0.0   0.0   0.0    1.0    0.0    4.0   0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0   2.0    0.0   0.0    1.0   2.0    0.0   0.0   0.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   0.0    0.0   1.0    2.0   0.0   1.0   1.0   1.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    2.0   1.0    5.0   0.0   0.0   0.0   0.0    79.0   1.0    2.0   0.21                 21 / 100
0.0   0.0    0.0   1.0    1.0   3.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   3.0    1.0   0.0    0.0   1.0   0.0   3.0   0.0    0.0    92.0   0.0   0.14018691588785046  15 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   4.0    0.0   1.0   0.0   0.0    0.0   0.0    1.0   0.0    8.0   3.0   0.0   0.0   0.0    1.0    0.0    67.0  0.22988505747126436  20 / 87
88.0  109.0  67.0  116.0  84.0  78.0  98.0  97.0  84.0  107.0  99.0  91.0  88.0  101.0  75.0  108.0  90.0  125.0  90.0  96.0  98.0  79.0  111.0  102.0  112.0  97.0  0.21124497991967872  526 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.788755
2    0.871888
3    0.909639
4    0.938153
5    0.950602
6    0.963855
7    0.971888
8    0.976707
9    0.980321
10   0.985944
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:45  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:45  34.259 sec  125087 obs/sec    1         1             10007      0.684661         1.42927             0.991669       0.391982                         0.683552           1.41731               0.991674         0.397992
    2019-07-24 14:06:46  34.910 sec  139373 obs/sec    10        10            100070     0.46989          0.739046            0.996076       0.20024                          0.476184           0.747954              0.99596          0.211245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0992244
C15         0.942122               0.942122             0.0934815
C9          0.828875               0.828875             0.0822447
C12         0.793316               0.793316             0.0787163
C8          0.72351                0.72351              0.0717899
C11         0.684702               0.684702             0.0679391
C14         0.670444               0.670444             0.0665244
C7          0.639451               0.639451             0.0634491
C10         0.623317               0.623317             0.0618483
C6          0.619014               0.619014             0.0614213
C16         0.493505               0.493505             0.0489678
C4          0.45298                0.45298              0.0449466
C3          0.449125               0.449125             0.0445642
C5          0.447763               0.447763             0.044429
C2          0.397405               0.397405             0.0394322
C1          0.312636               0.312636             0.0310211
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_46

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.001555921254777104   0.0003344087162986398  0.0         0.019516684493908087   0.77166748046875    0.056483149886337874  0.7382247447967529
    3        26       Softmax                 0.0   0.0   0.0018763107779635063  0.0002950010821223259  0.0         -0.012971800095598405  0.3808070421218872  -0.5472417401864157   0.2579258680343628


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2172730007897431
RMSE: 0.46612552042314
LogLoss: 0.7405354675416124
Mean Per-Class Error: 0.2138763539309072
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
361.0  1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    2.0    0.0    6.0    1.0    2.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    2.0    2.0    7.0    0.0    0.08607594936708861  34 / 395
1.0    321.0  0.0    9.0    2.0    0.0    6.0    6.0    1.0    0.0    4.0    0.0    1.0    0.0    0.0    2.0    0.0    17.0   7.0    0.0    0.0    2.0    0.0    1.0    3.0    0.0    0.1618798955613577   62 / 383
0.0    1.0    293.0  0.0    20.0   2.0    9.0    1.0    0.0    0.0    21.0   0.0    1.0    0.0    5.0    0.0    1.0    0.0    6.0    2.0    2.0    0.0    4.0    0.0    0.0    0.0    0.20380434782608695  75 / 368
4.0    20.0   0.0    326.0  0.0    4.0    0.0    3.0    1.0    1.0    5.0    0.0    6.0    4.0    3.0    7.0    0.0    8.0    5.0    1.0    1.0    0.0    0.0    3.0    0.0    1.0    0.19106699751861042  77 / 403
0.0    7.0    1.0    0.0    289.0  8.0    19.0   2.0    1.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    5.0    3.0    15.0   5.0    0.0    0.0    0.0    1.0    0.0    21.0   0.24739583333333334  95 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    1.0    8.0    0.0    0.0    2.0    0.0    22.0   1.0    0.0    0.0    0.0    5.0    0.0    0.0    2.0    4.0    330.0  0.0    0.0    0.0    0.12234042553191489  46 / 376
0.0    3.0    0.0    8.0    6.0    1.0    0.0    1.0    7.0    1.0    11.0   3.0    0.0    0.0    2.0    1.0    8.0    3.0    18.0   3.0    3.0    0.0    0.0    304.0  7.0    3.0    0.22646310432569974  89 / 393
1.0    0.0    0.0    4.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    6.0    0.0    3.0    21.0   1.0    17.0   2.0    0.0    329.0  0.0    0.1628498727735369   64 / 393
0.0    0.0    0.0    1.0    14.0   5.0    0.0    0.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    0.0    6.0    0.0    37.0   5.0    0.0    0.0    0.0    0.0    0.0    289.0  0.2125340599455041   78 / 367
416.0  515.0  359.0  452.0  388.0  383.0  317.0  289.0  337.0  347.0  410.0  353.0  463.0  378.0  375.0  388.0  365.0  409.0  368.0  401.0  386.0  375.0  389.0  371.0  402.0  367.0  0.21273617914625612  2,128 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787264
2    0.877737
3    0.917625
4    0.936319
5    0.951715
6    0.961012
7    0.96751
8    0.973708
9    0.978806
10   0.983105

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.21926895968283122
RMSE: 0.468261635928923
LogLoss: 0.750021825024201
Mean Per-Class Error: 0.21682531766532992
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16    17     18    19    20    21    22     23    24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
83.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0   0.06741573033707865  6 / 89
1.0    83.0   0.0   1.0    2.0   0.0   2.0   3.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   1.0    0.0   7.0    1.0   0.0   0.0   2.0   0.0    1.0   1.0    0.0   0.2169811320754717   23 / 106
0.0    0.0    62.0  0.0    2.0   0.0   5.0   0.0   0.0   0.0   5.0    0.0   0.0    0.0   2.0   0.0    0.0   0.0    3.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0   0.24390243902439024  20 / 82
3.0    2.0    0.0   92.0   0.0   1.0   0.0   2.0   1.0   1.0   2.0    0.0   3.0    1.0   0.0   2.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.17857142857142858  20 / 112
0.0    1.0    0.0   0.0    70.0  5.0   7.0   0.0   0.0   0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   1.0    2.0   3.0   0.0   0.0   0.0    0.0   0.0    7.0   0.27835051546391754  27 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   5.0    0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0    1.0    0.0   4.0    3.0   0.0   0.0   1.0   2.0   0.0   4.0    2.0   0.0    0.0   0.0   0.0    2.0   1.0    6.0   0.0   1.0   0.0   0.0    69.0  4.0    0.0   0.31                 31 / 100
1.0    0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0    0.0   5.0   0.0   6.0   1.0    0.0   90.0   0.0   0.1588785046728972   17 / 107
0.0    0.0    0.0   0.0    3.0   1.0   0.0   0.0   0.0   3.0   0.0    1.0   0.0    0.0   0.0   0.0    1.0   0.0    9.0   2.0   0.0   0.0   0.0    0.0   0.0    67.0  0.22988505747126436  20 / 87
104.0  120.0  76.0  123.0  92.0  87.0  78.0  79.0  82.0  95.0  106.0  97.0  102.0  95.0  77.0  114.0  91.0  102.0  94.0  98.0  98.0  84.0  103.0  88.0  114.0  91.0  0.21646586345381527  539 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783534
2    0.881124
3    0.919679
4    0.936546
5    0.948996
6    0.958233
7    0.963855
8    0.96988
9    0.975904
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:25  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:25  1 min 14.377 sec  54983 obs/sec     1         1             10007      0.588369         1.11104             0.993848       0.304709                         0.588106           1.10503               0.993837         0.307631
    2019-07-24 14:07:27  1 min 15.942 sec  58417 obs/sec     10        10            100070     0.466126         0.740535            0.996139       0.212736                         0.468262           0.750022              0.996093         0.216466
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0869856
C9          0.958853               0.958853             0.0834064
C12         0.93165                0.93165              0.0810401
C13         0.928009               0.928009             0.0807234
C11         0.855541               0.855541             0.0744198
C7          0.805476               0.805476             0.0700648
C8          0.793129               0.793129             0.0689908
C14         0.717781               0.717781             0.0624366
C10         0.653146               0.653146             0.0568143
C3          0.608212               0.608212             0.0529056
C6          0.601876               0.601876             0.0523545
C4          0.591325               0.591325             0.0514367
C16         0.572726               0.572726             0.0498189
C5          0.566643               0.566643             0.0492898
C2          0.479553               0.479553             0.0417142
C1          0.432239               0.432239             0.0375985
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_12

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.001115321211045739   0.0003143957583233714  0.0         -0.009112578344002031  0.557847261428833   -0.031470180889048405  0.5909576416015625
    3        26       Softmax                 0.0   0.0   0.0022672097990065455  0.0006765234284102917  0.0         -0.02302262718953548   0.7329137325286865  -0.5336628239472332    0.2604454755783081


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2232141295188538
RMSE: 0.4724554259597976
LogLoss: 0.7515182261524133
Mean Per-Class Error: 0.2143555229831031
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  1.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    2.0    5.0    0.0    3.0    1.0    6.0    0.0    0.0    0.0    2.0    0.0    2.0    0.0    3.0    2.0    4.0    2.0    0.09367088607594937  37 / 395
0.0    304.0  0.0    6.0    3.0    4.0    5.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    26.0   15.0   2.0    0.0    4.0    0.0    6.0    0.0    1.0    0.206266318537859    79 / 383
0.0    0.0    283.0  1.0    17.0   0.0    26.0   1.0    0.0    0.0    22.0   0.0    0.0    0.0    10.0   0.0    0.0    2.0    1.0    2.0    0.0    0.0    3.0    0.0    0.0    0.0    0.23097826086956522  85 / 368
2.0    13.0   0.0    335.0  0.0    1.0    0.0    5.0    0.0    4.0    3.0    0.0    2.0    8.0    6.0    5.0    0.0    11.0   2.0    0.0    1.0    0.0    0.0    3.0    0.0    2.0    0.1687344913151365   68 / 403
0.0    7.0    1.0    0.0    293.0  7.0    29.0   1.0    0.0    0.0    6.0    3.0    0.0    0.0    0.0    0.0    1.0    5.0    6.0    1.0    1.0    0.0    0.0    4.0    0.0    18.0   0.2349869451697128   90 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    3.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    10.0   3.0    5.0    0.0    0.0    2.0    0.0    0.0    2.0    5.0    333.0  0.0    1.0    0.0    0.11436170212765957  43 / 376
0.0    4.0    1.0    5.0    11.0   0.0    0.0    0.0    0.0    2.0    9.0    4.0    0.0    0.0    2.0    0.0    8.0    2.0    2.0    7.0    3.0    0.0    0.0    325.0  2.0    7.0    0.1751269035532995   69 / 394
0.0    0.0    0.0    1.0    0.0    8.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    6.0    0.0    1.0    33.0   0.0    27.0   3.0    0.0    311.0  0.0    0.20865139949109415  82 / 393
2.0    0.0    0.0    1.0    16.0   0.0    0.0    0.0    2.0    15.0   0.0    0.0    0.0    0.0    0.0    1.0    3.0    1.0    30.0   4.0    0.0    0.0    0.0    5.0    0.0    287.0  0.21798365122615804  80 / 367
399.0  469.0  333.0  429.0  416.0  352.0  425.0  285.0  317.0  374.0  368.0  339.0  399.0  390.0  389.0  389.0  371.0  443.0  277.0  410.0  396.0  383.0  422.0  425.0  368.0  435.0  0.21293611916425073  2,130 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787064
2    0.879436
3    0.917825
4    0.939318
5    0.953614
6    0.962911
7    0.968509
8    0.974808
9    0.979606
10   0.984405

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22430636562800318
RMSE: 0.47360992982411504
LogLoss: 0.751239927491444
Mean Per-Class Error: 0.21109129393836107
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16     17     18    19    20    21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  ----  ----  -----  -----  -----  -----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    1.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   1.0   0.0   1.0    0.0    2.0    0.0    0.07865168539325842  7 / 89
0.0   79.0   0.0   1.0    2.0   2.0   1.0   1.0   0.0   0.0    0.0   0.0   0.0   1.0    0.0   0.0    2.0    7.0    5.0   0.0   0.0   3.0   0.0    2.0    0.0    0.0    0.25471698113207547  27 / 106
0.0   0.0    59.0  0.0    1.0   0.0   10.0  1.0   0.0   0.0    4.0   0.0   0.0   0.0    4.0   0.0    0.0    0.0    0.0   1.0   0.0   0.0   2.0    0.0    0.0    0.0    0.2804878048780488   23 / 82
2.0   2.0    0.0   93.0   0.0   0.0   0.0   0.0   0.0   1.0    1.0   0.0   1.0   3.0    2.0   2.0    0.0    3.0    0.0   0.0   0.0   0.0   0.0    1.0    0.0    1.0    0.16964285714285715  19 / 112
0.0   1.0    0.0   0.0    69.0  3.0   8.0   0.0   0.0   0.0    3.0   2.0   0.0   0.0    0.0   0.0    1.0    1.0    1.0   0.0   0.0   0.0   0.0    0.0    0.0    8.0    0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---   ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   4.0   0.0   0.0    0.0   0.0   2.0   0.0    1.0   0.0    0.0    0.0    0.0   0.0   0.0   2.0   83.0   0.0    0.0    0.0    0.09782608695652174  9 / 92
0.0   1.0    0.0   1.0    4.0   0.0   0.0   0.0   0.0   0.0    3.0   1.0   0.0   0.0    0.0   0.0    2.0    2.0    1.0   1.0   0.0   0.0   0.0    79.0   2.0    3.0    0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.0    2.0    0.0    0.0   9.0   0.0   6.0   2.0    0.0    86.0   0.0    0.19626168224299065  21 / 107
0.0   0.0    0.0   1.0    4.0   0.0   0.0   0.0   1.0   4.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    6.0   1.0   0.0   0.0   0.0    1.0    0.0    69.0   0.20689655172413793  18 / 87
97.0  112.0  70.0  114.0  95.0  83.0  90.0  76.0  73.0  110.0  97.0  88.0  86.0  104.0  82.0  109.0  103.0  114.0  75.0  95.0  96.0  89.0  104.0  105.0  109.0  114.0  0.20963855421686747  522 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790361
2    0.879518
3    0.918474
4    0.938554
5    0.950602
6    0.962651
7    0.969076
8    0.974699
9    0.979116
10   0.985141
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:34  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:34  22.879 sec  129961 obs/sec    1         1             10007      0.666597         1.39884             0.992105       0.382685                         0.664041           1.38414               0.992143         0.380321
    2019-07-24 14:06:34  23.454 sec  156604 obs/sec    10        10            100070     0.472455         0.751518            0.996034       0.212936                         0.47361            0.75124               0.996003         0.209639
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0942889
C13         0.95066                0.95066              0.0896367
C9          0.898042               0.898042             0.0846754
C8          0.856135               0.856135             0.0807241
C12         0.853012               0.853012             0.0804296
C7          0.816954               0.816954             0.0770297
C11         0.776552               0.776552             0.0732203
C16         0.663138               0.663138             0.0625266
C6          0.632727               0.632727             0.0596592
C14         0.622807               0.622807             0.0587238
C10         0.602876               0.602876             0.0568446
C5          0.471009               0.471009             0.0444109
C4          0.421249               0.421249             0.0397191
C3          0.404319               0.404319             0.0381228
C1          0.326853               0.326853             0.0308186
C2          0.309365               0.309365             0.0291697
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_37

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015926359075137952  0.00036108726635575294  0.0         -0.012496330870455097  0.7728195190429688  0.0925072295361774   0.7581021785736084
    3        26       Softmax                 0.0   0.0   0.0018708950267584722  0.00029462401289492846  0.0         0.0033066131503093087  0.3835740089416504  -0.5538015073354419  0.256412148475647


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21552029986128066
RMSE: 0.46424163951683683
LogLoss: 0.7338572505061229
Mean Per-Class Error: 0.2110487617180863
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    10.0   0.0    0.0    0.0    2.0    2.0    5.0    4.0    0.0    0.0    3.0    1.0    7.0    0.0    0.09873417721518987  39 / 395
0.0    306.0  0.0    13.0   4.0    3.0    1.0    4.0    3.0    0.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0    22.0   14.0   0.0    0.0    6.0    0.0    3.0    1.0    0.0    0.2010443864229765   77 / 383
0.0    0.0    290.0  0.0    15.0   2.0    19.0   1.0    0.0    0.0    20.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    10.0   3.0    3.0    0.0    4.0    0.0    0.0    0.0    0.21195652173913043  78 / 368
6.0    14.0   0.0    341.0  0.0    2.0    0.0    2.0    0.0    4.0    0.0    2.0    6.0    5.0    2.0    5.0    0.0    12.0   0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.15384615384615385  62 / 403
0.0    4.0    0.0    0.0    300.0  4.0    19.0   0.0    1.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    11.0   4.0    8.0    6.0    0.0    1.0    0.0    1.0    0.0    21.0   0.21671018276762402  83 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    10.0   0.0    0.0    1.0    0.0    22.0   0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    339.0  0.0    0.0    0.0    0.09840425531914894  37 / 376
0.0    3.0    0.0    8.0    11.0   2.0    0.0    2.0    7.0    1.0    7.0    3.0    0.0    0.0    4.0    0.0    8.0    4.0    7.0    3.0    2.0    0.0    0.0    311.0  6.0    5.0    0.21065989847715735  83 / 394
0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    5.0    0.0    2.0    29.0   1.0    30.0   2.0    0.0    311.0  0.0    0.20865139949109415  82 / 393
0.0    0.0    0.0    0.0    15.0   1.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    0.0    0.0    0.0    7.0    1.0    36.0   6.0    0.0    0.0    0.0    2.0    0.0    296.0  0.19346049046321526  71 / 367
408.0  472.0  353.0  468.0  409.0  387.0  349.0  283.0  345.0  337.0  374.0  350.0  459.0  355.0  384.0  380.0  327.0  460.0  377.0  394.0  381.0  402.0  423.0  365.0  384.0  377.0  0.2101369589123263   2,102 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789863
2    0.880536
3    0.916525
4    0.937019
5    0.951315
6    0.964111
7    0.973108
8    0.978407
9    0.982605
10   0.986504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22095946075242592
RMSE: 0.47006325186343373
LogLoss: 0.7548544581204413
Mean Per-Class Error: 0.22296900268586012
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18    19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0   0.0   1.0    1.0   3.0    0.0   0.11235955056179775  10 / 89
0.0   79.0   0.0   3.0    2.0   0.0   1.0   1.0   1.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   9.0    3.0   0.0   0.0   4.0   0.0    1.0   0.0    0.0   0.25471698113207547  27 / 106
0.0   0.0    61.0  0.0    2.0   0.0   7.0   0.0   0.0   0.0   5.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0   1.0   1.0   0.0   1.0    0.0   0.0    0.0   0.25609756097560976  21 / 82
3.0   4.0    0.0   94.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   2.0   2.0    2.0   1.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0   0.16071428571428573  18 / 112
0.0   0.0    0.0   0.0    72.0  2.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    3.0   1.0    3.0   3.0   0.0   0.0   0.0    0.0   0.0    9.0   0.25773195876288657  25 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   85.0   0.0   0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   4.0    4.0   1.0   0.0   1.0   2.0   0.0   3.0   2.0   0.0    0.0   1.0   0.0    2.0   1.0    2.0   0.0   0.0   0.0   0.0    74.0  0.0    3.0   0.26                 26 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   1.0    1.0   0.0    0.0   10.0  0.0   11.0  1.0    0.0   80.0   0.0   0.2523364485981308   27 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    2.0   0.0    8.0   2.0   0.0   0.0   0.0    1.0   0.0    68.0  0.21839080459770116  19 / 87
96.0  114.0  77.0  135.0  96.0  90.0  83.0  73.0  82.0  93.0  90.0  93.0  105.0  93.0  77.0  105.0  86.0  122.0  96.0  96.0  97.0  93.0  105.0  92.0  103.0  98.0  0.22289156626506024  555 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.777108
2    0.877912
3    0.912851
4    0.931325
5    0.946586
6    0.959438
7    0.971888
8    0.978313
9    0.983133
10   0.988353
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:11  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:11  1 min  0.718 sec  50540 obs/sec     1         1             10007      0.588157         1.11368             0.993852       0.308108                         0.587086           1.11133               0.993858         0.310442
    2019-07-24 14:07:13  1 min  2.272 sec  58214 obs/sec     10        10            100070     0.464242         0.733857            0.99617        0.210137                         0.470063           0.754854              0.996063         0.222892
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0867713
C15         0.992604               0.992604             0.0861295
C12         0.91824                0.91824              0.0796768
C9          0.900955               0.900955             0.078177
C8          0.798177               0.798177             0.0692589
C7          0.796876               0.796876             0.069146
C11         0.793909               0.793909             0.0688885
C10         0.730535               0.730535             0.0633894
C14         0.725054               0.725054             0.0629139
C16         0.601791               0.601791             0.0522181
C3          0.599702               0.599702             0.0520369
C6          0.589715               0.589715             0.0511704
C4          0.584059               0.584059             0.0506796
C5          0.571324               0.571324             0.0495745
C2          0.469231               0.469231             0.0407158
C1          0.452378               0.452378             0.0392534
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_47

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0016122776084444013  0.0003523225896060467  0.0         0.01214717975676649   0.7561666965484619   -0.050639074161940495  0.6923582553863525
    3        26       Softmax                 0.0   0.0   0.0018495020654322265  0.000267244060523808   0.0         0.013273625439908825  0.38219428062438965  -0.5605943615811294    0.2912003993988037


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21890212162880573
RMSE: 0.46786976994544727
LogLoss: 0.7506097968847424
Mean Per-Class Error: 0.2175855580521181
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    8.0    0.0    6.0    0.0    1.0    0.0    4.0    1.0    1.0    0.0    4.0    1.0    7.0    1.0    0.10379746835443038  41 / 395
0.0    326.0  0.0    4.0    2.0    1.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    0.0    23.0   4.0    0.0    0.0    7.0    1.0    3.0    2.0    0.0    0.14882506527415143  57 / 383
0.0    0.0    300.0  0.0    12.0   0.0    15.0   1.0    0.0    0.0    19.0   0.0    0.0    0.0    3.0    0.0    0.0    0.0    7.0    3.0    3.0    0.0    5.0    0.0    0.0    0.0    0.18478260869565216  68 / 368
3.0    23.0   0.0    327.0  0.0    1.0    0.0    3.0    0.0    6.0    0.0    1.0    5.0    4.0    5.0    4.0    1.0    6.0    2.0    1.0    2.0    0.0    0.0    8.0    0.0    1.0    0.18858560794044665  76 / 403
0.0    7.0    2.0    0.0    301.0  5.0    9.0    0.0    3.0    0.0    5.0    1.0    0.0    0.0    0.0    1.0    11.0   4.0    4.0    3.0    0.0    0.0    0.0    10.0   2.0    16.0   0.21614583333333334  83 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    3.0    0.0    0.0    0.0    0.0    10.0   1.0    3.0    0.0    0.0    8.0    0.0    0.0    0.0    6.0    342.0  0.0    0.0    0.0    0.09042553191489362  34 / 376
0.0    8.0    1.0    5.0    9.0    1.0    0.0    2.0    4.0    1.0    11.0   0.0    0.0    0.0    0.0    1.0    10.0   1.0    12.0   5.0    1.0    1.0    0.0    310.0  8.0    3.0    0.2131979695431472   84 / 394
0.0    0.0    0.0    2.0    0.0    6.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    8.0    0.0    3.0    27.0   1.0    34.0   1.0    0.0    307.0  0.0    0.21683673469387754  85 / 392
0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   3.0    25.0   7.0    0.0    0.0    0.0    4.0    0.0    297.0  0.1907356948228883   70 / 367
404.0  528.0  364.0  451.0  390.0  358.0  329.0  248.0  348.0  349.0  369.0  336.0  436.0  331.0  393.0  369.0  381.0  486.0  296.0  403.0  393.0  395.0  465.0  393.0  380.0  408.0  0.21653503948815356  2,166 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.783465
2    0.877237
3    0.917025
4    0.937819
5    0.951615
6    0.961711
7    0.969609
8    0.976207
9    0.980706
10   0.984705

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22330220863558312
RMSE: 0.47254863097419203
LogLoss: 0.7599364400672126
Mean Per-Class Error: 0.22688881630030416
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19    20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0   0.0   2.0    1.0   3.0    0.0    0.10112359550561797  9 / 89
0.0   82.0   0.0   1.0    1.0   0.0   1.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   3.0   0.0    0.0    10.0   1.0   0.0   0.0   4.0   0.0    1.0   1.0    0.0    0.22641509433962265  24 / 106
0.0   0.0    64.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0    5.0   0.0   0.0    0.0   2.0   0.0    0.0    0.0    3.0   1.0   0.0   0.0   2.0    0.0   0.0    0.0    0.21951219512195122  18 / 82
2.0   4.0    0.0   92.0   0.0   0.0   0.0   2.0   0.0   2.0    0.0   0.0   2.0    2.0   0.0   1.0    1.0    2.0    1.0   0.0   0.0   0.0   0.0    1.0   0.0    0.0    0.17857142857142858  20 / 112
0.0   2.0    0.0   0.0    71.0  4.0   3.0   0.0   1.0   0.0    1.0   1.0   0.0    0.0   0.0   0.0    3.0    1.0    0.0   1.0   0.0   0.0   0.0    1.0   0.0    8.0    0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   3.0    0.0   2.0   0.0    0.0    1.0    0.0   0.0   0.0   1.0   85.0   0.0   0.0    0.0    0.07608695652173914  7 / 92
0.0   2.0    0.0   2.0    5.0   0.0   0.0   1.0   1.0   0.0    5.0   0.0   0.0    0.0   0.0   0.0    2.0    1.0    4.0   0.0   0.0   0.0   0.0    72.0  4.0    1.0    0.28                 28 / 100
0.0   0.0    0.0   2.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   1.0    4.0    0.0    0.0   5.0   0.0   10.0  1.0    0.0   84.0   0.0    0.21495327102803738  23 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0   0.0    2.0    1.0    2.0   3.0   0.0   0.0   0.0    2.0   0.0    71.0   0.1839080459770115   16 / 87
96.0  125.0  79.0  127.0  90.0  84.0  76.0  63.0  86.0  101.0  96.0  89.0  101.0  91.0  78.0  106.0  100.0  122.0  72.0  92.0  99.0  94.0  115.0  91.0  110.0  107.0  0.22610441767068273  563 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773896
2    0.875904
3    0.917269
4    0.936948
5    0.950602
6    0.962249
7    0.969478
8    0.977108
9    0.981526
10   0.98755
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:27  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:27  1 min 16.151 sec  60283 obs/sec     1         1             10007      0.58901          1.11014             0.993834       0.303409                         0.589442           1.10801               0.993809         0.313253
    2019-07-24 14:07:28  1 min 17.791 sec  56472 obs/sec     10        10            100070     0.46787          0.75061             0.99611        0.216535                         0.472549           0.759936              0.996021         0.226104
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.091734
C13         0.941728               0.941728             0.0863885
C12         0.863444               0.863444             0.0792071
C9          0.849083               0.849083             0.0778897
C7          0.79225                0.79225              0.0726763
C11         0.768227               0.768227             0.0704725
C8          0.763145               0.763145             0.0700063
C14         0.698015               0.698015             0.0640316
C10         0.677886               0.677886             0.0621852
C6          0.579272               0.579272             0.0531389
C3          0.567465               0.567465             0.0520558
C16         0.55368                0.55368              0.0507913
C5          0.517651               0.517651             0.0474861
C4          0.497478               0.497478             0.0456356
C2          0.437746               0.437746             0.0401562
C1          0.394019               0.394019             0.0361449
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_63

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  10.0       0.0   0.0   0.0007878553799400834  0.00018137029837816954  0.0         -0.004352586502136546  0.2812230587005615  0.2046334377363993   0.22187358140945435
    3        26       Softmax                      0.0   0.0   0.0051995330185701065  0.01587318629026413     0.0         -0.37851708258089134   0.8890976905822754  -0.4661840690973041  0.3395165205001831


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22775391308351658
RMSE: 0.4772356997161011
LogLoss: 0.7516472111126189
Mean Per-Class Error: 0.20993292115375647
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
357.0  0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    10.0   6.0    0.0    5.0    0.0    0.0    0.0    2.0    1.0    3.0    0.0    1.0    0.0    2.0    2.0    5.0    0.0    0.09620253164556962  38 / 395
1.0    314.0  0.0    2.0    1.0    1.0    8.0    11.0   1.0    0.0    5.0    1.0    1.0    0.0    1.0    2.0    0.0    16.0   11.0   0.0    0.0    2.0    1.0    3.0    1.0    0.0    0.1801566579634465   69 / 383
1.0    0.0    295.0  0.0    15.0   3.0    10.0   1.0    0.0    0.0    23.0   1.0    0.0    0.0    4.0    0.0    4.0    0.0    6.0    1.0    2.0    0.0    2.0    0.0    0.0    0.0    0.1983695652173913   73 / 368
9.0    28.0   0.0    309.0  0.0    2.0    0.0    5.0    1.0    5.0    0.0    4.0    4.0    7.0    6.0    1.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    10.0   0.0    2.0    0.23325062034739455  94 / 403
0.0    8.0    4.0    0.0    298.0  1.0    17.0   0.0    0.0    0.0    5.0    2.0    0.0    0.0    0.0    0.0    7.0    4.0    15.0   4.0    0.0    0.0    0.0    4.0    1.0    14.0   0.22395833333333334  86 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    7.0    1.0    343.0  0.0    0.0    0.0    0.08776595744680851  33 / 376
0.0    3.0    0.0    7.0    5.0    0.0    0.0    3.0    6.0    1.0    5.0    1.0    0.0    0.0    1.0    0.0    10.0   0.0    16.0   3.0    1.0    0.0    0.0    325.0  5.0    2.0    0.1751269035532995   69 / 394
0.0    0.0    0.0    0.0    1.0    5.0    0.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    6.0    0.0    7.0    23.0   1.0    20.0   1.0    0.0    323.0  1.0    0.1760204081632653   69 / 392
3.0    0.0    0.0    0.0    12.0   0.0    1.0    0.0    1.0    20.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    26.0   3.0    0.0    0.0    0.0    8.0    0.0    291.0  0.20708446866485014  76 / 367
433.0  519.0  333.0  372.0  377.0  353.0  355.0  312.0  351.0  379.0  406.0  354.0  428.0  343.0  378.0  380.0  351.0  446.0  381.0  373.0  386.0  362.0  438.0  433.0  387.0  373.0  0.2092372288313506   2,093 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.790763
2    0.874238
3    0.908827
4    0.93202
5    0.948715
6    0.959112
7    0.96851
8    0.974408
9    0.980106
10   0.984205

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2309848647767919
RMSE: 0.4806088480009413
LogLoss: 0.7615855281285917
Mean Per-Class Error: 0.21715155530124822
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10     11    12    13    14    15     16    17     18     19    20    21    22     23     24     25    Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  ----  ----  ----  -----  ----  -----  -----  ----  ----  ----  -----  -----  -----  ----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    1.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   1.0    1.0    3.0    0.0   0.07865168539325842  7 / 89
0.0    81.0   0.0   1.0    1.0   0.0   2.0   6.0   0.0   0.0    1.0    0.0   0.0   0.0   1.0   0.0    0.0   6.0    4.0    0.0   0.0   1.0   0.0    2.0    0.0    0.0   0.2358490566037736   25 / 106
0.0    0.0    62.0  0.0    0.0   0.0   3.0   0.0   0.0   0.0    7.0    0.0   0.0   0.0   2.0   0.0    2.0   0.0    3.0    1.0   1.0   0.0   1.0    0.0    0.0    0.0   0.24390243902439024  20 / 82
4.0    6.0    0.0   86.0   0.0   0.0   0.0   3.0   0.0   2.0    0.0    1.0   2.0   2.0   0.0   1.0    0.0   2.0    0.0    0.0   0.0   0.0   0.0    2.0    0.0    1.0   0.23214285714285715  26 / 112
0.0    1.0    0.0   0.0    72.0  1.0   6.0   0.0   0.0   0.0    2.0    0.0   0.0   0.0   0.0   0.0    1.0   1.0    5.0    2.0   0.0   0.0   0.0    2.0    0.0    4.0   0.25773195876288657  25 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---   ---   ---   ---    ---   ---    ---    ---   ---   ---   ---    ---    ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   3.0   0.0   0.0   0.0    0.0   2.0    0.0    0.0   2.0   0.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0    1.0    0.0   3.0    2.0   0.0   0.0   2.0   1.0   0.0    1.0    1.0   0.0   0.0   1.0   0.0    2.0   0.0    6.0    0.0   0.0   0.0   0.0    78.0   2.0    0.0   0.22                 22 / 100
0.0    0.0    0.0   0.0    1.0   1.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0   0.0   0.0   1.0    3.0   0.0    0.0    6.0   0.0   5.0   1.0    0.0    88.0   0.0   0.17757009345794392  19 / 107
1.0    0.0    0.0   0.0    4.0   0.0   0.0   0.0   0.0   6.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0   0.0    6.0    1.0   0.0   0.0   0.0    3.0    0.0    66.0  0.2413793103448276   21 / 87
109.0  121.0  67.0  107.0  90.0  80.0  89.0  81.0  82.0  109.0  105.0  91.0  90.0  91.0  73.0  113.0  92.0  116.0  103.0  91.0  99.0  80.0  105.0  105.0  112.0  89.0  0.21566265060240963  537 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.784337
2    0.873092
3    0.908835
4    0.927309
5    0.946586
6    0.957028
7    0.96747
8    0.970281
9    0.976707
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:48  1 min 37.258 sec  175561 obs/sec    1         1             10007      0.698093         1.50267             0.99134        0.402579                         0.697607           1.49502               0.991328         0.409639
    2019-07-24 14:07:49  1 min 37.782 sec  176802 obs/sec    10        10            100070     0.477236         0.751647            0.995953       0.209237                         0.480609           0.761586              0.995884         0.215663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0942498
C13         0.932787               0.932787             0.0879151
C9          0.874279               0.874279             0.0824007
C8          0.767611               0.767611             0.0723472
C12         0.757789               0.757789             0.0714215
C7          0.698721               0.698721             0.0658543
C11         0.664558               0.664558             0.0626345
C6          0.641536               0.641536             0.0604647
C10         0.63534                0.63534              0.0598807
C14         0.620555               0.620555             0.0584872
C5          0.607483               0.607483             0.0572552
C3          0.546732               0.546732             0.0515294
C4          0.535465               0.535465             0.0504675
C16         0.513361               0.513361             0.0483842
C1          0.432107               0.432107             0.040726
C2          0.381772               0.381772             0.035982
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_53

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias              bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ---------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  10.0       0.0   0.0   0.0011937382308815359  0.00034699554089456797  0.0         -0.025104361956209686  0.5731160640716553  -0.009468687298661203  0.6354873180389404
    3        26       Softmax                 0.0   0.0   0.0022645984678932177  0.0005639772862195969   0.0         0.019067845571323863   0.7305858135223389  -0.5481619170373362    0.2696099281311035


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22830029937940946
RMSE: 0.4778078059004577
LogLoss: 0.7625031740160808
Mean Per-Class Error: 0.21368866085063123
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    8.0    6.0    2.0    3.0    2.0    0.0    0.0    2.0    1.0    7.0    0.0    2.0    0.0    0.0    1.0    7.0    0.0    0.10913705583756345  43 / 394
0.0    286.0  0.0    12.0   1.0    1.0    5.0    4.0    2.0    2.0    0.0    0.0    0.0    0.0    6.0    3.0    2.0    32.0   16.0   0.0    0.0    1.0    0.0    5.0    3.0    2.0    0.25326370757180156  97 / 383
0.0    1.0    303.0  0.0    8.0    1.0    13.0   0.0    0.0    0.0    15.0   0.0    0.0    0.0    10.0   0.0    0.0    0.0    1.0    4.0    7.0    0.0    5.0    0.0    0.0    0.0    0.1766304347826087   65 / 368
5.0    4.0    0.0    332.0  0.0    3.0    0.0    5.0    0.0    4.0    0.0    3.0    8.0    2.0    6.0    1.0    0.0    14.0   1.0    0.0    0.0    0.0    0.0    9.0    0.0    5.0    0.17412935323383086  70 / 402
0.0    4.0    7.0    0.0    267.0  8.0    29.0   1.0    1.0    0.0    6.0    1.0    0.0    0.0    0.0    0.0    1.0    3.0    13.0   2.0    0.0    0.0    0.0    5.0    3.0    33.0   0.3046875            117 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    0.0    2.0    0.0    8.0    2.0    3.0    3.0    0.0    0.0    0.0    0.0    2.0    3.0    338.0  0.0    0.0    0.0    0.10106382978723404  38 / 376
0.0    2.0    0.0    6.0    4.0    3.0    1.0    5.0    2.0    3.0    10.0   2.0    0.0    0.0    2.0    0.0    6.0    1.0    15.0   4.0    3.0    0.0    0.0    306.0  5.0    14.0   0.2233502538071066   88 / 394
0.0    0.0    0.0    0.0    0.0    8.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    1.0    11.0   6.0    0.0    3.0    38.0   2.0    26.0   2.0    0.0    291.0  1.0    0.2595419847328244   102 / 393
0.0    0.0    0.0    2.0    15.0   0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    19.0   3.0    0.0    0.0    0.0    1.0    0.0    313.0  0.14713896457765668  54 / 367
394.0  437.0  344.0  436.0  342.0  394.0  376.0  349.0  341.0  349.0  404.0  330.0  409.0  376.0  396.0  400.0  333.0  406.0  352.0  406.0  407.0  372.0  424.0  407.0  351.0  468.0  0.21293611916425073  2,130 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.787064
2    0.873038
3    0.910927
4    0.930321
5    0.945116
6    0.957513
7    0.96681
8    0.973908
9    0.981006
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22965806218674176
RMSE: 0.47922652491983553
LogLoss: 0.7674094893962412
Mean Per-Class Error: 0.2146242699278925
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13     14    15     16    17     18    19    20    21    22     23     24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  -----  ----  -----  ----  -----  ----  ----  ----  ----  -----  -----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0   1.0    0.0   0.0    1.0   1.0    1.0   0.0   0.0   0.0   0.0    1.0    3.0   0.0    0.10112359550561797  9 / 89
0.0   76.0   0.0   4.0    1.0   0.0   2.0   0.0   1.0   0.0    0.0   0.0   0.0   0.0    2.0   0.0    1.0   11.0   4.0   0.0   0.0   1.0   0.0    2.0    1.0   0.0    0.2830188679245283   30 / 106
0.0   1.0    66.0  0.0    1.0   0.0   1.0   0.0   0.0   0.0    4.0   0.0   0.0   0.0    4.0   0.0    0.0   0.0    1.0   1.0   2.0   0.0   1.0    0.0    0.0   0.0    0.1951219512195122   16 / 82
3.0   0.0    0.0   93.0   0.0   0.0   0.0   1.0   0.0   2.0    0.0   1.0   3.0   1.0    0.0   0.0    0.0   3.0    0.0   0.0   0.0   0.0   0.0    3.0    0.0   2.0    0.16964285714285715  19 / 112
0.0   0.0    2.0   0.0    62.0  4.0   7.0   0.0   0.0   0.0    2.0   1.0   0.0   0.0    0.0   0.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0    2.0    0.0   13.0   0.36082474226804123  35 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---    ---   ---    ---   ---    ---   ---   ---   ---   ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   2.0   0.0   0.0    0.0   0.0   0.0   1.0    1.0   1.0    0.0   0.0    0.0   0.0   0.0   2.0   84.0   0.0    0.0   0.0    0.08695652173913043  8 / 92
0.0   1.0    0.0   2.0    2.0   0.0   0.0   3.0   0.0   0.0    4.0   1.0   0.0   0.0    0.0   0.0    1.0   1.0    4.0   0.0   0.0   0.0   0.0    73.0   2.0   6.0    0.27                 27 / 100
0.0   0.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0    0.0   3.0    5.0   0.0    0.0   9.0   0.0   9.0   1.0    0.0    75.0  0.0    0.29906542056074764  32 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0    0.0    0.0   75.0   0.13793103448275862  12 / 87
95.0  107.0  73.0  123.0  73.0  89.0  94.0  91.0  76.0  104.0  98.0  91.0  88.0  103.0  82.0  113.0  95.0  101.0  90.0  97.0  98.0  87.0  104.0  101.0  94.0  123.0  0.21566265060240963  537 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.784337
2    0.8751
3    0.911647
4    0.932129
5    0.946185
6    0.957028
7    0.966265
8    0.971084
9    0.978715
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:38  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:38  1 min 27.195 sec  140943 obs/sec    1         1             10007      0.67711          1.43445             0.991851       0.376887                         0.676792           1.42816               0.991838         0.381124
    2019-07-24 14:07:39  1 min 27.804 sec  150481 obs/sec    10        10            100070     0.477808         0.762503            0.995942       0.212936                         0.479227           0.767409              0.995908         0.215663
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0997012
C9          0.931458               0.931458             0.0928675
C13         0.854964               0.854964             0.0852409
C7          0.724364               0.724364             0.0722199
C8          0.721311               0.721311             0.0719156
C12         0.706018               0.706018             0.0703909
C14         0.684971               0.684971             0.0682924
C11         0.674845               0.674845             0.0672828
C16         0.667113               0.667113             0.066512
C10         0.621034               0.621034             0.0619179
C6          0.490542               0.490542             0.0489077
C5          0.476565               0.476565             0.0475141
C3          0.419387               0.419387             0.0418134
C4          0.410784               0.410784             0.0409557
C2          0.337117               0.337117             0.033611
C1          0.309497               0.309497             0.0308572
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_30

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  ------------------
    1        16       Input        0.0
    2        128      TanhDropout  50.0       0.0   0.0   0.0015497487198103954  0.00036774331238120794  0.0         0.03358085924332954   0.7693169116973877   0.020711400896075087  0.7529306411743164
    3        26       Softmax                 0.0   0.0   0.0018314817240165072  0.0003287602448835969   0.0         0.007383930527020346  0.38434159755706787  -0.5484945181875429   0.2844499349594116


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.21946263215879
RMSE: 0.4684683897113977
LogLoss: 0.7502551528284388
Mean Per-Class Error: 0.21115172949982136
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    0.0    9.0    0.0    3.0    0.0    0.0    3.0    4.0    0.0    2.0    0.0    2.0    1.0    7.0    1.0    0.09873417721518987  39 / 395
0.0    321.0  0.0    8.0    4.0    0.0    4.0    9.0    3.0    0.0    1.0    0.0    1.0    0.0    0.0    4.0    0.0    21.0   2.0    0.0    1.0    0.0    1.0    2.0    1.0    0.0    0.1618798955613577   62 / 383
0.0    1.0    284.0  0.0    13.0   1.0    24.0   1.0    0.0    0.0    17.0   0.0    1.0    0.0    4.0    0.0    2.0    0.0    10.0   3.0    3.0    0.0    4.0    0.0    0.0    0.0    0.22826086956521738  84 / 368
3.0    15.0   0.0    334.0  1.0    0.0    0.0    6.0    0.0    4.0    0.0    0.0    7.0    5.0    3.0    5.0    0.0    13.0   3.0    0.0    1.0    0.0    0.0    3.0    0.0    0.0    0.17121588089330025  69 / 403
0.0    9.0    0.0    0.0    292.0  1.0    18.0   1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    8.0    7.0    9.0    7.0    0.0    0.0    0.0    8.0    0.0    22.0   0.23958333333333334  92 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    15.0   0.0    10.0   0.0    0.0    7.0    0.0    0.0    0.0    0.0    337.0  0.0    0.0    0.0    0.10372340425531915  39 / 376
6.0    5.0    0.0    7.0    11.0   1.0    0.0    1.0    7.0    0.0    5.0    1.0    0.0    0.0    2.0    0.0    8.0    5.0    2.0    4.0    1.0    0.0    0.0    320.0  4.0    4.0    0.18781725888324874  74 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    4.0    12.0   0.0    2.0    20.0   3.0    32.0   1.0    0.0    313.0  0.0    0.2035623409669211   80 / 393
2.0    0.0    0.0    1.0    12.0   0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    1.0    24.0   6.0    0.0    0.0    0.0    5.0    0.0    302.0  0.1771117166212534   65 / 367
417.0  544.0  323.0  457.0  382.0  326.0  374.0  299.0  334.0  340.0  348.0  326.0  462.0  350.0  408.0  404.0  389.0  471.0  300.0  403.0  394.0  384.0  419.0  397.0  380.0  372.0  0.210036988903329    2,101 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.789963
2    0.873138
3    0.912426
4    0.936319
5    0.952814
6    0.964611
7    0.972508
8    0.977407
9    0.983105
10   0.986904

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22613415612474444
RMSE: 0.47553565179147655
LogLoss: 0.7700299254514598
Mean Per-Class Error: 0.2219619729082887
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13    14    15     16     17     18    19    20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  ----  -------------------  -----------
79.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   4.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   1.0    1.0    3.0    0.0   0.11235955056179775  10 / 89
0.0   82.0   0.0   2.0    3.0   0.0   3.0   3.0   1.0   0.0    1.0   0.0   0.0    0.0   0.0   0.0    0.0    7.0    0.0   0.0   1.0    0.0   1.0    1.0    1.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    57.0  0.0    3.0   0.0   7.0   0.0   0.0   0.0    3.0   0.0   0.0    0.0   2.0   0.0    1.0    0.0    4.0   2.0   1.0    0.0   2.0    0.0    0.0    0.0   0.3048780487804878   25 / 82
2.0   2.0    0.0   94.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   0.0   3.0    1.0   0.0   2.0    0.0    3.0    1.0   0.0   0.0    0.0   0.0    1.0    0.0    0.0   0.16071428571428573  18 / 112
0.0   2.0    0.0   0.0    71.0  1.0   7.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0    1.0    2.0    3.0   3.0   0.0    0.0   0.0    2.0    0.0    5.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0   0.0   4.0    0.0   1.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
1.0   1.0    0.0   3.0    6.0   0.0   0.0   1.0   1.0   0.0    1.0   1.0   0.0    0.0   0.0   0.0    2.0    2.0    0.0   0.0   0.0    0.0   0.0    79.0   1.0    1.0   0.21                 21 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   1.0    5.0    0.0    0.0   4.0   1.0    13.0  1.0    0.0    80.0   0.0   0.2523364485981308   27 / 107
0.0   0.0    0.0   1.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   0.0   0.0    2.0    0.0    4.0   3.0   0.0    0.0   0.0    1.0    0.0    70.0  0.19540229885057472  17 / 87
97.0  130.0  66.0  133.0  91.0  69.0  97.0  78.0  76.0  101.0  82.0  85.0  105.0  93.0  82.0  118.0  101.0  118.0  73.0  95.0  100.0  91.0  111.0  101.0  106.0  91.0  0.22088353413654618  550 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779116
2    0.874297
3    0.914458
4    0.934538
5    0.953012
6    0.963454
7    0.96988
8    0.974699
9    0.982329
10   0.984739
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:03  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:03  52.690 sec  54983 obs/sec     1         1             10007      0.586368         1.11094             0.993891       0.291613                         0.587452           1.11482               0.993851         0.295181
    2019-07-24 14:07:05  54.310 sec  56664 obs/sec     10        10            100070     0.468468         0.750255            0.996101       0.210037                         0.475536           0.77003               0.995971         0.220884
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0870706
C15         0.99587                0.99587              0.086711
C13         0.990695               0.990695             0.0862604
C12         0.893892               0.893892             0.0778317
C11         0.847253               0.847253             0.0737709
C7          0.835039               0.835039             0.0727074
C8          0.790845               0.790845             0.0688593
C14         0.690826               0.690826             0.0601506
C10         0.658732               0.658732             0.0573562
C6          0.628213               0.628213             0.0546989
C3          0.599128               0.599128             0.0521665
C5          0.563159               0.563159             0.0490346
C16         0.562743               0.562743             0.0489984
C4          0.555667               0.555667             0.0483823
C2          0.47332                0.47332              0.0412122
C1          0.399548               0.399548             0.0347889
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_8

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.00130901922793214    0.0003668839344754815  0.0         0.028834696786816494   0.750870943069458    0.1558685977077229    0.8442778587341309
    3        26       Softmax                 0.0   0.0   0.0018772012344925315  0.00036526785697788    0.0         -0.006236944224138614  0.49789535999298096  -0.44757322173111014  0.21487575769424438


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2296585287142866
RMSE: 0.4792270116701339
LogLoss: 0.7694127819212833
Mean Per-Class Error: 0.2241861388036232
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
353.0  1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    2.0    1.0    13.0   0.0    1.0    0.0    1.0    0.0    4.0    0.0    1.0    2.0    1.0    2.0    5.0    4.0    0.10406091370558376  41 / 394
0.0    298.0  0.0    5.0    2.0    2.0    1.0    7.0    3.0    0.0    2.0    0.0    2.0    0.0    0.0    1.0    1.0    29.0   17.0   0.0    0.0    6.0    0.0    3.0    2.0    1.0    0.2198952879581152   84 / 382
0.0    0.0    288.0  1.0    22.0   1.0    8.0    2.0    0.0    0.0    22.0   0.0    3.0    0.0    8.0    0.0    2.0    0.0    4.0    1.0    4.0    0.0    2.0    0.0    0.0    0.0    0.21739130434782608  80 / 368
2.0    23.0   0.0    305.0  0.0    1.0    0.0    10.0   2.0    8.0    0.0    0.0    3.0    10.0   5.0    4.0    0.0    12.0   5.0    1.0    1.0    0.0    0.0    10.0   0.0    1.0    0.24317617866004962  98 / 403
0.0    6.0    1.0    0.0    294.0  3.0    11.0   1.0    2.0    0.0    8.0    3.0    0.0    0.0    0.0    0.0    9.0    4.0    6.0    7.0    2.0    0.0    0.0    11.0   2.0    14.0   0.234375             90 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    0.0    7.0    5.0    9.0    0.0    0.0    7.0    0.0    0.0    7.0    0.0    335.0  0.0    0.0    0.0    0.10904255319148937  41 / 376
0.0    3.0    0.0    10.0   7.0    1.0    6.0    4.0    2.0    2.0    7.0    3.0    0.0    0.0    0.0    0.0    11.0   1.0    11.0   4.0    3.0    0.0    0.0    303.0  11.0   5.0    0.23096446700507614  91 / 394
0.0    1.0    0.0    2.0    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    7.0    0.0    3.0    32.0   1.0    34.0   1.0    0.0    302.0  0.0    0.23155216284987276  91 / 393
0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    0.0    0.0    3.0    1.0    33.0   7.0    0.0    0.0    0.0    5.0    0.0    294.0  0.1989100817438692   73 / 367
419.0  499.0  333.0  390.0  396.0  347.0  331.0  318.0  331.0  397.0  357.0  336.0  441.0  355.0  447.0  358.0  364.0  476.0  329.0  407.0  402.0  388.0  421.0  396.0  405.0  360.0  0.22353294011796462  2,236 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.776467
2    0.872438
3    0.911027
4    0.93422
5    0.950115
6    0.963011
7    0.971709
8    0.976507
9    0.981206
10   0.985404

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2330461234119638
RMSE: 0.48274850948704523
LogLoss: 0.7743365436824863
Mean Per-Class Error: 0.22832410664803998
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12    13    14    15     16     17     18    19     20     21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  -----  ----  -----  -----  ----  -----  -----  -----  ----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   2.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0    0.0   1.0    1.0    3.0    1.0   0.10112359550561797  9 / 89
0.0   78.0   0.0   2.0    1.0   0.0   1.0   1.0   1.0   0.0    1.0   0.0   0.0   0.0   0.0   0.0    1.0    12.0   3.0   0.0    0.0    4.0   0.0    1.0    0.0    0.0   0.2641509433962264   28 / 106
0.0   0.0    58.0  0.0    4.0   1.0   3.0   0.0   0.0   0.0    6.0   0.0   0.0   0.0   3.0   0.0    0.0    0.0    3.0   1.0    2.0    0.0   1.0    0.0    0.0    0.0   0.2926829268292683   24 / 82
1.0   1.0    0.0   83.0   0.0   1.0   0.0   6.0   1.0   2.0    0.0   0.0   2.0   3.0   2.0   3.0    0.0    3.0    3.0   0.0    0.0    0.0   0.0    0.0    0.0    1.0   0.25892857142857145  29 / 112
0.0   3.0    0.0   0.0    69.0  2.0   3.0   0.0   1.0   0.0    1.0   1.0   0.0   0.0   0.0   0.0    1.0    2.0    1.0   3.0    0.0    0.0   0.0    2.0    1.0    7.0   0.28865979381443296  28 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---    ---   ---    ---    ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0   1.0   0.0   0.0    0.0    1.0    0.0   0.0    3.0    0.0   85.0   0.0    0.0    0.0   0.07608695652173914  7 / 92
0.0   0.0    0.0   3.0    3.0   0.0   2.0   1.0   1.0   1.0    3.0   1.0   0.0   0.0   0.0   0.0    2.0    1.0    2.0   1.0    1.0    0.0   0.0    74.0   2.0    2.0   0.26                 26 / 100
0.0   1.0    0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    3.0    0.0    0.0   7.0    0.0    10.0  1.0    0.0    83.0   0.0   0.22429906542056074  24 / 107
0.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0    5.0   2.0    0.0    0.0   0.0    2.0    0.0    71.0  0.1839080459770115   16 / 87
98.0  119.0  71.0  106.0  89.0  83.0  75.0  78.0  75.0  114.0  85.0  91.0  97.0  93.0  95.0  100.0  101.0  127.0  87.0  101.0  105.0  93.0  105.0  100.0  107.0  95.0  0.2289156626506024   570 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.771084
2    0.871084
3    0.911647
4    0.938153
5    0.951406
6    0.964257
7    0.973494
8    0.977912
9    0.981526
10   0.986345
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:28  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:28  17.031 sec  75810 obs/sec     1         1             10007      0.603198         1.16072             0.993533       0.316005                         0.598134           1.14093               0.993625         0.307631
    2019-07-24 14:06:29  18.103 sec  84518 obs/sec     10        10            100070     0.479227         0.769413            0.995918       0.223533                         0.482749           0.774337              0.995847         0.228916
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.087072
C15         0.912468               0.912468             0.0794504
C12         0.900368               0.900368             0.0783968
C9          0.883293               0.883293             0.0769101
C8          0.814405               0.814405             0.0709119
C11         0.792312               0.792312             0.0689882
C7          0.754452               0.754452             0.0656917
C14         0.687544               0.687544             0.0598659
C6          0.684172               0.684172             0.0595722
C16         0.66526                0.66526              0.0579255
C5          0.64678                0.64678              0.0563164
C4          0.617679               0.617679             0.0537825
C3          0.617178               0.617178             0.0537389
C10         0.615823               0.615823             0.0536209
C1          0.458706               0.458706             0.0399404
C2          0.434308               0.434308             0.0378161
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_57

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  25.0       0.0   0.0   0.0013921497931050908  0.0003683858085423708  0.0         0.023474518907278252  0.7413852214813232   0.18925803588130463   0.7200427055358887
    3        26       Softmax                 0.0   0.0   0.0019458062486312254  0.0003629598068073392  0.0         -0.0141344956008512   0.49580180644989014  -0.45631850404645896  0.23985439538955688


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.22461605750799937
RMSE: 0.47393676530524553
LogLoss: 0.7538698664113247
Mean Per-Class Error: 0.22009872104451708
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    5.0    5.0    0.0    4.0    0.0    1.0    0.0    2.0    3.0    3.0    0.0    4.0    0.0    2.0    0.0    5.0    2.0    0.10126582278481013  40 / 395
0.0    305.0  0.0    3.0    4.0    3.0    2.0    3.0    3.0    1.0    1.0    0.0    1.0    0.0    1.0    5.0    2.0    32.0   10.0   0.0    0.0    2.0    1.0    1.0    2.0    1.0    0.20365535248041775  78 / 383
0.0    0.0    292.0  0.0    16.0   0.0    13.0   0.0    0.0    0.0    19.0   1.0    1.0    0.0    4.0    0.0    2.0    0.0    9.0    3.0    3.0    0.0    5.0    0.0    0.0    0.0    0.20652173913043478  76 / 368
3.0    21.0   0.0    313.0  0.0    0.0    0.0    13.0   0.0    6.0    1.0    0.0    3.0    5.0    1.0    4.0    3.0    16.0   6.0    0.0    1.0    0.0    0.0    2.0    2.0    3.0    0.22332506203473945  90 / 403
0.0    15.0   3.0    0.0    290.0  2.0    7.0    2.0    2.0    0.0    2.0    1.0    0.0    0.0    0.0    2.0    11.0   3.0    15.0   2.0    0.0    0.0    0.0    3.0    0.0    23.0   0.24281984334203655  93 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    1.0    0.0    0.0    17.0   0.0    0.0    1.0    0.0    22.0   6.0    0.0    0.0    0.0    7.0    0.0    0.0    2.0    4.0    316.0  0.0    0.0    0.0    0.1595744680851064   60 / 376
0.0    5.0    0.0    7.0    8.0    2.0    0.0    1.0    3.0    1.0    7.0    2.0    0.0    0.0    2.0    0.0    8.0    1.0    10.0   1.0    4.0    0.0    0.0    324.0  6.0    2.0    0.17766497461928935  70 / 394
0.0    0.0    0.0    2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    6.0    0.0    5.0    19.0   3.0    31.0   3.0    1.0    313.0  0.0    0.2035623409669211   80 / 393
2.0    0.0    0.0    1.0    11.0   8.0    0.0    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    5.0    0.0    38.0   5.0    0.0    0.0    0.0    3.0    0.0    290.0  0.2098092643051771   77 / 367
397.0  472.0  340.0  401.0  402.0  383.0  302.0  327.0  321.0  339.0  367.0  346.0  446.0  360.0  380.0  386.0  411.0  495.0  388.0  374.0  413.0  376.0  379.0  399.0  420.0  379.0  0.21913425972208336  2,192 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780866
2    0.875137
3    0.914026
4    0.936019
5    0.951714
6    0.962311
7    0.970009
8    0.975907
9    0.980306
10   0.985504

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.22900388657630202
RMSE: 0.4785435054164898
LogLoss: 0.7800664464377595
Mean Per-Class Error: 0.22876355581484273
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13    14    15     16     17     18    19    20     21    22    23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  -----  ----  ----  -----  ----  ----  ----  -----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    1.0   0.0   1.0    0.0   1.0   0.0   2.0    0.0   0.07865168539325842  7 / 89
0.0   81.0   0.0   1.0    3.0   1.0   1.0   1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   2.0    1.0    8.0    2.0   0.0   0.0    1.0   1.0   1.0   0.0    0.0   0.2358490566037736   25 / 106
0.0   0.0    58.0  0.0    5.0   0.0   5.0   0.0   0.0   0.0   5.0   0.0   0.0   0.0   2.0   0.0    0.0    0.0    3.0   2.0   1.0    0.0   1.0   0.0   0.0    0.0   0.2926829268292683   24 / 82
2.0   5.0    0.0   89.0   0.0   0.0   0.0   5.0   0.0   0.0   1.0   0.0   2.0   1.0   0.0   1.0    1.0    3.0    2.0   0.0   0.0    0.0   0.0   0.0   0.0    0.0   0.20535714285714285  23 / 112
0.0   4.0    0.0   0.0    71.0  2.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    3.0    1.0    4.0   0.0   0.0    0.0   0.0   1.0   0.0    9.0   0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---    ---   ---   ---    ---   ---   ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   4.0   3.0   0.0   0.0    0.0    2.0    0.0   0.0   0.0    1.0   80.0  0.0   0.0    0.0   0.13043478260869565  12 / 92
0.0   1.0    0.0   3.0    3.0   1.0   0.0   1.0   1.0   0.0   2.0   1.0   0.0   0.0   0.0   0.0    2.0    1.0    2.0   0.0   1.0    0.0   0.0   80.0  0.0    1.0   0.2                  20 / 100
0.0   0.0    0.0   1.0    0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    2.0    0.0    0.0   3.0   1.0    12.0  1.0   0.0   84.0   0.0   0.21495327102803738  23 / 107
0.0   0.0    0.0   1.0    4.0   2.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0    1.0    0.0    7.0   3.0   0.0    0.0   0.0   1.0   0.0    67.0  0.22988505747126436  20 / 87
94.0  126.0  68.0  115.0  98.0  86.0  71.0  82.0  74.0  94.0  94.0  92.0  96.0  95.0  85.0  116.0  102.0  124.0  93.0  83.0  107.0  92.0  92.0  99.0  117.0  95.0  0.22690763052208834  565 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773092
2    0.872691
3    0.909639
4    0.935341
5    0.949799
6    0.962249
7    0.967872
8    0.973092
9    0.977109
10   0.981928
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:42  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:43  1 min 31.805 sec  89348 obs/sec     1         1             10007      0.607835         1.18232             0.993434       0.314106                         0.606548           1.1779                0.993445         0.317269
    2019-07-24 14:07:44  1 min 32.855 sec  88323 obs/sec     10        10            100070     0.473937         0.75387             0.996008       0.219134                         0.478544           0.780066              0.995919         0.226908
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0903204
C15         0.983633               0.983633             0.0888421
C12         0.865566               0.865566             0.0781782
C9          0.851803               0.851803             0.0769352
C8          0.777316               0.777316             0.0702074
C11         0.733482               0.733482             0.0662484
C7          0.722865               0.722865             0.0652894
C14         0.677578               0.677578             0.0611991
C10         0.656119               0.656119             0.0592609
C5          0.633224               0.633224             0.057193
C16         0.618188               0.618188             0.0558349
C3          0.611888               0.611888             0.0552659
C6          0.586744               0.586744             0.0529949
C4          0.498744               0.498744             0.0450467
C1          0.452467               0.452467             0.040867
C2          0.402085               0.402085             0.0363164
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_54

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight           weight_rms          mean_bias           bias_rms
--  -------  -------  ----------------  ---------  ----  ----  --------------------  ----------------------  ----------  --------------------  ------------------  ------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.000780695539106091  0.00019593426259234548  0.0         -0.01974218823454521  0.2940789461135864  0.0870986713056727  0.23098629713058472
    3        26       Softmax                      0.0   0.0   0.004506706952130257  0.009416535496711731    0.0         -0.3653244932714498   0.8781418800354004  -0.594740950503207  0.4337807893753052


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2582500772026449
RMSE: 0.508183113850357
LogLoss: 0.8139455353284453
Mean Per-Class Error: 0.2203163634504512
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    5.0    1.0    1.0    0.0    4.0    0.0    11.0   0.0    1.0    5.0    3.0    1.0    4.0    0.0    0.10126582278481013  40 / 395
0.0    328.0  2.0    7.0    1.0    0.0    1.0    1.0    2.0    0.0    1.0    0.0    1.0    0.0    2.0    3.0    3.0    9.0    11.0   0.0    0.0    7.0    1.0    3.0    0.0    0.0    0.14360313315926893  55 / 383
0.0    0.0    298.0  0.0    11.0   1.0    14.0   0.0    0.0    1.0    26.0   0.0    1.0    0.0    1.0    0.0    2.0    0.0    6.0    1.0    2.0    0.0    4.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
1.0    33.0   0.0    319.0  0.0    0.0    1.0    3.0    1.0    6.0    1.0    1.0    7.0    4.0    3.0    2.0    1.0    9.0    2.0    0.0    0.0    0.0    0.0    6.0    0.0    3.0    0.20843672456575682  84 / 403
0.0    11.0   5.0    0.0    294.0  1.0    7.0    0.0    0.0    0.0    7.0    1.0    0.0    0.0    0.0    4.0    13.0   3.0    15.0   3.0    0.0    0.0    0.0    5.0    0.0    13.0   0.23036649214659685  88 / 382
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    19.0   0.0    0.0    2.0    0.0    17.0   5.0    0.0    0.0    0.0    1.0    0.0    0.0    3.0    1.0    327.0  0.0    0.0    0.0    0.13031914893617022  49 / 376
0.0    5.0    0.0    7.0    5.0    0.0    0.0    0.0    8.0    1.0    9.0    2.0    0.0    0.0    0.0    1.0    13.0   0.0    13.0   1.0    5.0    0.0    0.0    315.0  3.0    6.0    0.20050761421319796  79 / 394
0.0    0.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    12.0   0.0    12.0   19.0   2.0    44.0   1.0    0.0    294.0  0.0    0.25190839694656486  99 / 393
2.0    1.0    0.0    0.0    18.0   0.0    0.0    0.0    1.0    15.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    41.0   1.0    0.0    0.0    0.0    1.0    0.0    286.0  0.22070844686648503  81 / 367
403.0  555.0  372.0  424.0  387.0  322.0  336.0  293.0  344.0  363.0  415.0  324.0  441.0  360.0  354.0  426.0  372.0  391.0  405.0  361.0  404.0  421.0  430.0  377.0  346.0  377.0  0.2194341697490753   2,195 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.780566
2    0.872438
3    0.910227
4    0.931421
5    0.948016
6    0.959612
7    0.96751
8    0.972608
9    0.977607
10   0.981606

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.26049464062576094
RMSE: 0.5103867559270724
LogLoss: 0.8210004931725702
Mean Per-Class Error: 0.22808634280326207
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10     11    12     13    14    15     16    17    18     19    20     21     22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  ----  -----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  -------------------  -----------
80.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   1.0    1.0   0.0   0.0    1.0   0.0   1.0    0.0   0.0    2.0    0.0    1.0   2.0   0.0    0.10112359550561797  9 / 89
0.0   84.0   1.0   1.0    1.0   0.0   1.0   0.0   1.0   0.0    1.0    0.0   0.0    0.0   2.0   1.0    0.0   4.0   3.0    0.0   0.0    4.0    1.0    1.0   0.0   0.0    0.20754716981132076  22 / 106
0.0   0.0    63.0  0.0    2.0   0.0   6.0   0.0   0.0   0.0    5.0    0.0   0.0    0.0   1.0   0.0    0.0   0.0   3.0    1.0   0.0    0.0    1.0    0.0   0.0   0.0    0.23170731707317074  19 / 82
1.0   7.0    0.0   91.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0    1.0   3.0    1.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    0.0    0.0    2.0   0.0   1.0    0.1875               21 / 112
0.0   2.0    1.0   0.0    71.0  1.0   1.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0   0.0   1.0    4.0   1.0   3.0    1.0   0.0    0.0    0.0    2.0   0.0   6.0    0.26804123711340205  26 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---   ---    ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0    1.0    0.0   4.0    0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    1.0    84.0   0.0   0.0   0.0    0.08695652173913043  8 / 92
0.0   3.0    0.0   3.0    2.0   0.0   0.0   0.0   2.0   0.0    4.0    1.0   0.0    0.0   0.0   0.0    2.0   0.0   6.0    0.0   1.0    0.0    0.0    75.0  0.0   1.0    0.25                 25 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   0.0    0.0   0.0   0.0    5.0   0.0   3.0    5.0   0.0    14.0   1.0    0.0   77.0  0.0    0.2803738317757009   30 / 107
0.0   0.0    0.0   0.0    5.0   0.0   0.0   0.0   0.0   4.0    0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   9.0    0.0   0.0    0.0    0.0    1.0   0.0   68.0   0.21839080459770116  19 / 87
92.0  137.0  78.0  119.0  93.0  71.0  80.0  69.0  86.0  106.0  105.0  90.0  100.0  94.0  72.0  120.0  98.0  93.0  100.0  86.0  100.0  107.0  108.0  92.0  92.0  102.0  0.22690763052208834  565 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.773092
2    0.867872
3    0.906024
4    0.928113
5    0.945382
6    0.960241
7    0.965462
8    0.971084
9    0.9751
10   0.979518
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:39  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:39  1 min 27.878 sec  200140 obs/sec    1         1             10007      0.730704         1.5778              0.990511       0.410877                         0.733005           1.58454               0.990426         0.423293
    2019-07-24 14:07:39  1 min 28.300 sec  219934 obs/sec    10        10            100070     0.508183         0.813946            0.995411       0.219434                         0.510387           0.821                 0.995358         0.226908
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0922542
C13         0.944223               0.944223             0.0871085
C9          0.922545               0.922545             0.0851087
C12         0.86632                0.86632              0.0799217
C8          0.79591                0.79591              0.073426
C7          0.74443                0.74443              0.0686768
C11         0.722532               0.722532             0.0666567
C10         0.631366               0.631366             0.0582462
C5          0.628542               0.628542             0.0579856
C14         0.618571               0.618571             0.0570657
C6          0.578524               0.578524             0.0533712
C4          0.577481               0.577481             0.053275
C16         0.526771               0.526771             0.0485968
C3          0.515445               0.515445             0.047552
C1          0.410357               0.410357             0.0378571
C2          0.356599               0.356599             0.0328978
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_64

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009432786909826518  0.00026766920927911997  0.0         -0.015493701545295835  0.24582618474960327  0.022896649661789205  0.16113585233688354
    3        26       Softmax                      0.0   0.0   0.005252661122295439   0.01180347055196762     0.0         -0.2823094832123598    0.7374505996704102   -0.845853072161657    0.4306640625


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.278769339542595
RMSE: 0.527986116808572
LogLoss: 0.8519287949202505
Mean Per-Class Error: 0.22130491144595557
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    3.0    0.0    12.0   1.0    6.0    0.0    0.0    0.0    6.0    0.0    2.0    0.0    1.0    4.0    6.0    0.0    0.11139240506329114  44 / 395
0.0    324.0  0.0    4.0    2.0    0.0    6.0    3.0    3.0    0.0    1.0    0.0    1.0    0.0    4.0    6.0    0.0    15.0   4.0    0.0    0.0    1.0    1.0    6.0    2.0    0.0    0.15404699738903394  59 / 383
0.0    0.0    289.0  1.0    9.0    0.0    16.0   0.0    0.0    0.0    32.0   0.0    0.0    0.0    8.0    0.0    2.0    0.0    4.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    0.21467391304347827  79 / 368
3.0    31.0   0.0    317.0  0.0    0.0    3.0    8.0    0.0    4.0    0.0    0.0    4.0    6.0    3.0    0.0    0.0    10.0   1.0    1.0    0.0    0.0    0.0    11.0   0.0    1.0    0.21339950372208435  86 / 403
0.0    12.0   0.0    0.0    269.0  1.0    17.0   0.0    2.0    0.0    9.0    1.0    0.0    0.0    0.0    0.0    7.0    6.0    10.0   4.0    1.0    0.0    0.0    12.0   2.0    30.0   0.29765013054830286  114 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    13.0   0.0    0.0    0.0    0.0    20.0   4.0    2.0    0.0    1.0    2.0    0.0    0.0    1.0    2.0    330.0  0.0    0.0    0.0    0.12                 45 / 375
0.0    4.0    0.0    5.0    1.0    0.0    1.0    2.0    2.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    10.0   1.0    9.0    4.0    4.0    1.0    0.0    340.0  4.0    1.0    0.13705583756345177  54 / 394
0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    15.0   0.0    10.0   35.0   2.0    21.0   1.0    1.0    303.0  0.0    0.22900763358778625  90 / 393
1.0    0.0    0.0    2.0    14.0   0.0    2.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    0.0    54.0   2.0    0.0    0.0    0.0    2.0    0.0    282.0  0.23160762942779292  85 / 367
394.0  546.0  336.0  407.0  335.0  344.0  375.0  287.0  342.0  334.0  401.0  325.0  449.0  381.0  426.0  385.0  380.0  427.0  353.0  403.0  388.0  374.0  416.0  459.0  368.0  368.0  0.2202339298210537   2,203 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.779766
2    0.875437
3    0.910527
4    0.929621
5    0.945316
6    0.955613
7    0.96551
8    0.973408
9    0.978307
10   0.982205

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2808861116654225
RMSE: 0.5299868976356137
LogLoss: 0.8593714432305715
Mean Per-Class Error: 0.23044998450673018
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12    13     14    15     16     17     18    19     20    21    22     23     24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  -----  ----  ----  -----  -----  -----  ----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0   1.0    0.0   0.0    0.0    0.0    1.0   0.0    0.0   0.0   0.0    2.0    3.0    0.0   0.12359550561797752  11 / 89
0.0   82.0   0.0   0.0    1.0   0.0   2.0   2.0   1.0   0.0   0.0   0.0   0.0   0.0    4.0   3.0    0.0    4.0    3.0   0.0    0.0   1.0   0.0    2.0    1.0    0.0   0.22641509433962265  24 / 106
0.0   0.0    61.0  0.0    2.0   0.0   3.0   0.0   0.0   0.0   7.0   0.0   0.0   0.0    4.0   0.0    0.0    0.0    2.0   1.0    1.0   0.0   1.0    0.0    0.0    0.0   0.25609756097560976  21 / 82
2.0   6.0    0.0   90.0   0.0   0.0   2.0   4.0   0.0   2.0   0.0   0.0   1.0   3.0    0.0   0.0    0.0    1.0    0.0   0.0    0.0   0.0   0.0    1.0    0.0    0.0   0.19642857142857142  22 / 112
0.0   3.0    0.0   0.0    64.0  1.0   4.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    0.0   0.0    4.0    1.0    3.0   1.0    0.0   0.0   0.0    2.0    0.0    10.0  0.3402061855670103   33 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---    ---   ---   ---    ---    ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   4.0   1.0    0.0   0.0    1.0    0.0    0.0   0.0    0.0   0.0   84.0   0.0    0.0    0.0   0.08695652173913043  8 / 92
0.0   2.0    0.0   1.0    1.0   0.0   1.0   1.0   0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0    2.0   1.0    1.0   0.0   0.0    82.0   2.0    1.0   0.18                 18 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    6.0    0.0    1.0   11.0   1.0   6.0   1.0    0.0    81.0   0.0   0.24299065420560748  26 / 107
0.0   0.0    0.0   1.0    4.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0    12.0  1.0    0.0   0.0   0.0    1.0    0.0    66.0  0.2413793103448276   21 / 87
93.0  136.0  73.0  114.0  76.0  78.0  90.0  77.0  80.0  93.0  99.0  88.0  98.0  100.0  88.0  110.0  108.0  104.0  90.0  101.0  99.0  84.0  101.0  113.0  101.0  96.0  0.22931726907630523  571 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.770683
2    0.873494
3    0.911245
4    0.926908
5    0.944177
6    0.953414
7    0.963454
8    0.971486
9    0.976707
10   0.980723
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:49  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:49  1 min 37.877 sec  149358 obs/sec    1         1             10007      0.749113         1.63691             0.990027       0.402779                         0.751342           1.64742               0.989941         0.411647
    2019-07-24 14:07:49  1 min 38.333 sec  197766 obs/sec    10        10            100070     0.527986         0.851929            0.995046       0.220234                         0.529987           0.859371              0.994995         0.229317
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0899635
C13         0.930462               0.930462             0.0837077
C12         0.877668               0.877668             0.0789581
C9          0.852106               0.852106             0.0766585
C7          0.846966               0.846966             0.0761961
C8          0.804617               0.804617             0.0723861
C11         0.736902               0.736902             0.0662943
C14         0.690468               0.690468             0.0621169
C6          0.669622               0.669622             0.0602415
C16         0.629713               0.629713             0.0566512
C3          0.598357               0.598357             0.0538303
C10         0.581233               0.581233             0.0522897
C5          0.541714               0.541714             0.0487345
C4          0.516712               0.516712             0.0464852
C1          0.426971               0.426971             0.0384118
C2          0.412108               0.412108             0.0370746
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_40

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  25.0       0.0   0.0   0.0007503641039647846  0.00019317882834002376  0.0         -0.018119759133117697  0.2764641046524048  0.09976628020472945  0.21135711669921875
    3        26       Softmax                      0.0   0.0   0.005465410952078505   0.015261836349964142    0.0         -0.37082256389042484   0.9104270935058594  -0.600631312946067   0.46475744247436523


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2731543489576365
RMSE: 0.5226417022756953
LogLoss: 0.8559768146873462
Mean Per-Class Error: 0.2347950571151482
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    3.0    0.0    8.0    1.0    2.0    0.0    0.0    0.0    7.0    1.0    0.0    3.0    4.0    0.0    4.0    0.0    0.09367088607594937  37 / 395
0.0    286.0  0.0    8.0    1.0    1.0    6.0    2.0    3.0    0.0    1.0    0.0    0.0    0.0    13.0   7.0    1.0    30.0   15.0   0.0    0.0    3.0    1.0    5.0    0.0    0.0    0.25326370757180156  97 / 383
0.0    0.0    290.0  0.0    28.0   5.0    11.0   2.0    0.0    0.0    16.0   4.0    0.0    0.0    3.0    0.0    3.0    0.0    0.0    3.0    0.0    0.0    3.0    0.0    0.0    0.0    0.21195652173913043  78 / 368
6.0    16.0   0.0    323.0  0.0    1.0    0.0    1.0    1.0    6.0    5.0    0.0    5.0    3.0    4.0    2.0    0.0    11.0   5.0    0.0    4.0    0.0    0.0    8.0    1.0    0.0    0.19651741293532338  79 / 402
0.0    15.0   0.0    0.0    290.0  2.0    12.0   0.0    0.0    0.0    8.0    1.0    0.0    0.0    3.0    0.0    10.0   4.0    6.0    0.0    1.0    1.0    0.0    8.0    0.0    23.0   0.24479166666666666  94 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    0.0    0.0    5.0    8.0    1.0    0.0    0.0    11.0   0.0    0.0    0.0    0.0    341.0  0.0    0.0    0.0    0.09308510638297872  35 / 376
0.0    4.0    0.0    12.0   10.0   0.0    0.0    1.0    2.0    1.0    7.0    2.0    1.0    0.0    0.0    0.0    10.0   1.0    9.0    3.0    3.0    2.0    0.0    317.0  7.0    2.0    0.19543147208121828  77 / 394
0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    10.0   15.0   0.0    10.0   31.0   2.0    33.0   1.0    0.0    284.0  0.0    0.27735368956743     109 / 393
0.0    4.0    0.0    0.0    17.0   0.0    0.0    0.0    0.0    4.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0    53.0   0.0    0.0    0.0    0.0    3.0    0.0    283.0  0.22888283378746593  84 / 367
398.0  448.0  363.0  448.0  409.0  360.0  333.0  265.0  329.0  371.0  406.0  352.0  435.0  383.0  397.0  379.0  356.0  411.0  393.0  393.0  375.0  381.0  454.0  408.0  355.0  401.0  0.23372988103568929  2,338 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.76627
2    0.861142
3    0.90133
4    0.926022
5    0.941218
6    0.954414
7    0.962311
8    0.969109
9    0.976207
10   0.981805

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2757156852073394
RMSE: 0.5250863597612676
LogLoss: 0.8602636191203691
Mean Per-Class Error: 0.24086508086900194
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1     2     3      4     5     6     7     8     9      10     11    12     13     14    15     16     17     18     19    20    21    22     23     24    25     Error                Rate
----  ----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  ----  -----  -----  -----  -----  ----  ----  ----  -----  -----  ----  -----  -------------------  -----------
80.0  0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0    0.0   2.0    0.0    0.0   0.0    0.0    0.0    1.0    0.0   0.0   1.0   2.0    0.0    2.0   0.0    0.10112359550561797  9 / 89
0.0   66.0  0.0   1.0    1.0   0.0   3.0   1.0   1.0   0.0    0.0    0.0   0.0    0.0    9.0   0.0    1.0    12.0   6.0    0.0   0.0   2.0   1.0    2.0    0.0   0.0    0.37735849056603776  40 / 106
0.0   0.0   59.0  0.0    6.0   3.0   4.0   1.0   0.0   0.0    4.0    0.0   0.0    0.0    1.0   0.0    2.0    0.0    0.0    1.0   0.0   0.0   1.0    0.0    0.0   0.0    0.2804878048780488   23 / 82
3.0   2.0   0.0   92.0   0.0   0.0   0.0   1.0   1.0   1.0    2.0    0.0   2.0    2.0    1.0   0.0    0.0    1.0    3.0    0.0   0.0   0.0   0.0    1.0    0.0   0.0    0.17857142857142858  20 / 112
0.0   2.0   0.0   0.0    70.0  1.0   3.0   0.0   0.0   0.0    3.0    0.0   0.0    0.0    1.0   0.0    3.0    2.0    1.0    0.0   0.0   0.0   0.0    1.0    0.0   10.0   0.27835051546391754  27 / 97
---   ---   ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---   ---    ---    ---    ---    ---   ---   ---   ---    ---    ---   ---    ---                  ---
0.0   0.0   0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0    0.0    0.0   1.0    2.0    0.0   0.0    0.0    1.0    0.0    0.0   0.0   0.0   87.0   0.0    0.0   0.0    0.05434782608695652  5 / 92
0.0   2.0   0.0   3.0    4.0   0.0   0.0   1.0   0.0   0.0    2.0    1.0   1.0    0.0    0.0   0.0    2.0    0.0    4.0    0.0   0.0   0.0   0.0    79.0   1.0   0.0    0.21                 21 / 100
0.0   0.0   0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0    1.0   3.0    6.0    0.0    2.0    8.0   0.0   7.0   1.0    0.0    78.0  0.0    0.27102803738317754  29 / 107
0.0   1.0   0.0   0.0    5.0   0.0   0.0   0.0   0.0   1.0    0.0    1.0   0.0    0.0    0.0   0.0    0.0    0.0    13.0   0.0   0.0   0.0   0.0    1.0    0.0   65.0   0.25287356321839083  22 / 87
92.0  97.0  75.0  124.0  96.0  84.0  85.0  72.0  75.0  103.0  100.0  94.0  100.0  105.0  85.0  107.0  101.0  109.0  106.0  95.0  92.0  83.0  114.0  101.0  92.0  103.0  0.2393574297188755   596 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.760643
2    0.857831
3    0.903213
4    0.928514
5    0.940964
6    0.954619
7    0.961847
8    0.967872
9    0.975904
10   0.981526
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:15  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:15  1 min  4.389 sec  208479 obs/sec    1         1             10007      0.75869          1.72768             0.989771       0.439068                         0.760803           1.73368               0.989686         0.448594
    2019-07-24 14:07:15  1 min  4.749 sec  252702 obs/sec    10        10            100070     0.522642         0.855977            0.995146       0.23373                          0.525086           0.860264              0.995087         0.239357
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.105241
C13         0.832437               0.832437             0.0876065
C12         0.762233               0.762233             0.0802181
C9          0.70493                0.70493              0.0741876
C8          0.690722               0.690722             0.0726923
C7          0.689521               0.689521             0.0725659
C11         0.653929               0.653929             0.0688201
C6          0.606051               0.606051             0.0637814
C14         0.511157               0.511157             0.0537947
C3          0.491816               0.491816             0.0517593
C10         0.487862               0.487862             0.0513431
C4          0.467761               0.467761             0.0492277
C5          0.455333               0.455333             0.0479197
C16         0.43423                0.43423              0.0456988
C1          0.376379               0.376379             0.0396105
C2          0.337636               0.337636             0.0355332
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_43

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  -------------------  -------------------
    1        16       Input             0.0
    2        64       RectifierDropout  50.0       0.0   0.0   0.0009488074297507865  0.0002460666000843048  0.0         -0.013391629153403528  0.24294531345367432  0.06388094765102802  0.16940253973007202
    3        26       Softmax                      0.0   0.0   0.005439105547198919   0.013064566999673843   0.0         -0.2546607145493978    0.7272849082946777   -0.8256721922214317  0.4161839485168457


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.28752611051776356
RMSE: 0.5362146123687451
LogLoss: 0.8795805292047558
Mean Per-Class Error: 0.23415997863529145
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
354.0  1.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    11.0   2.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    3.0    3.0    7.0    0.0    0.10379746835443038  41 / 395
0.0    317.0  0.0    4.0    4.0    0.0    1.0    1.0    2.0    0.0    1.0    0.0    0.0    0.0    6.0    2.0    0.0    26.0   4.0    0.0    0.0    1.0    0.0    10.0   4.0    0.0    0.17232375979112272  66 / 383
0.0    0.0    297.0  0.0    22.0   0.0    9.0    2.0    0.0    0.0    20.0   0.0    0.0    0.0    3.0    0.0    2.0    0.0    5.0    2.0    1.0    0.0    5.0    0.0    0.0    0.0    0.19293478260869565  71 / 368
4.0    17.0   0.0    316.0  0.0    2.0    0.0    4.0    1.0    5.0    0.0    0.0    4.0    5.0    6.0    5.0    0.0    13.0   3.0    0.0    0.0    0.0    0.0    17.0   0.0    0.0    0.21393034825870647  86 / 402
0.0    12.0   1.0    0.0    311.0  1.0    15.0   0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    3.0    5.0    12.0   2.0    1.0    0.0    0.0    5.0    0.0    15.0   0.19010416666666666  73 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    16.0   0.0    2.0    0.0    0.0    10.0   0.0    0.0    1.0    0.0    338.0  0.0    1.0    0.0    0.10106382978723404  38 / 376
2.0    2.0    0.0    12.0   10.0   0.0    0.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    8.0    2.0    14.0   4.0    6.0    0.0    0.0    316.0  10.0   1.0    0.19796954314720813  78 / 394
0.0    1.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    16.0   0.0    10.0   24.0   2.0    70.0   1.0    0.0    262.0  0.0    0.3333333333333333   131 / 393
1.0    0.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    1.0    49.0   2.0    0.0    0.0    0.0    3.0    0.0    284.0  0.22615803814713897  83 / 367
404.0  510.0  359.0  422.0  444.0  320.0  344.0  218.0  350.0  338.0  415.0  324.0  426.0  340.0  449.0  376.0  326.0  443.0  395.0  395.0  388.0  430.0  443.0  453.0  343.0  348.0  0.2332300309907028   2,333 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.76677
2    0.864341
3    0.904329
4    0.927822
5    0.943717
6    0.956513
7    0.96551
8    0.973008
9    0.980406
10   0.984605

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.28728424309929673
RMSE: 0.5359890326296768
LogLoss: 0.874911588066789
Mean Per-Class Error: 0.23220827147331807
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4      5     6     7     8     9     10    11    12    13    14    15     16    17     18     19    20     21     22     23     24    25    Error                Rate
----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  ----  -----  -----  -----  -----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    1.0    0.0   0.0    0.0    1.0    1.0    3.0   0.0   0.07865168539325842  7 / 89
0.0   81.0   0.0   2.0    3.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   4.0   1.0    0.0   6.0    3.0    0.0   0.0    1.0    0.0    3.0    1.0   0.0   0.2358490566037736   25 / 106
0.0   0.0    61.0  0.0    5.0    0.0   4.0   1.0   0.0   0.0   4.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0    3.0    1.0   0.0    0.0    2.0    0.0    0.0   0.0   0.25609756097560976  21 / 82
3.0   2.0    0.0   89.0   0.0    0.0   0.0   3.0   1.0   1.0   0.0   0.0   1.0   3.0   1.0   1.0    0.0   2.0    2.0    0.0   0.0    0.0    0.0    3.0    0.0   0.0   0.20535714285714285  23 / 112
0.0   2.0    0.0   0.0    74.0   1.0   4.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    3.0    0.0   0.0    0.0    0.0    2.0    0.0   8.0   0.23711340206185566  23 / 97
---   ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---   ---    ---    ---    ---    ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    0.0   2.0    0.0    0.0   0.0    0.0    86.0   0.0    0.0   0.0   0.06521739130434782  6 / 92
0.0   0.0    0.0   3.0    4.0    0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    2.0   2.0    3.0    1.0   2.0    0.0    0.0    76.0   4.0   1.0   0.24                 24 / 100
0.0   1.0    0.0   0.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    7.0   0.0    1.0    4.0   1.0    20.0   1.0    0.0    70.0  0.0   0.34579439252336447  37 / 107
0.0   0.0    0.0   0.0    5.0    0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    11.0   1.0   0.0    0.0    0.0    1.0    0.0   65.0  0.25287356321839083  22 / 87
97.0  120.0  74.0  116.0  102.0  74.0  87.0  62.0  89.0  91.0  96.0  89.0  93.0  88.0  93.0  107.0  93.0  114.0  101.0  91.0  102.0  101.0  114.0  112.0  95.0  89.0  0.2325301204819277   579 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.76747
2    0.867068
3    0.908835
4    0.928916
5    0.94498
6    0.957028
7    0.964659
8    0.971486
9    0.97992
10   0.985944
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:20  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:20  1 min  9.002 sec  158841 obs/sec    1         1             10007      0.754566         1.64505             0.989883       0.376387                         0.754121           1.63333               0.989867         0.37751
    2019-07-24 14:07:20  1 min  9.471 sec  194310 obs/sec    10        10            100070     0.536215         0.879581            0.994891       0.23323                          0.535989           0.874912              0.994881         0.23253
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0970567
C13         0.892224               0.892224             0.0865963
C8          0.793448               0.793448             0.0770094
C12         0.765637               0.765637             0.0743102
C9          0.759779               0.759779             0.0737417
C7          0.72682                0.72682              0.0705427
C11         0.724758               0.724758             0.0703427
C14         0.665917               0.665917             0.0646317
C10         0.607643               0.607643             0.0589759
C6          0.593974               0.593974             0.0576491
C5          0.532437               0.532437             0.0516765
C3          0.508135               0.508135             0.0493179
C16         0.495695               0.495695             0.0481105
C4          0.478802               0.478802             0.0464709
C2          0.417789               0.417789             0.0405492
C1          0.340198               0.340198             0.0330185
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_78

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 5,530 weights/biases, 71.4 KB, 10,007 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        128      RectifierDropout  10.0       0.0   0.0   0.0013764401724358777  0.00045904202852398157  0.0         -0.005105073421962203  0.13007867336273193  0.4098064868208035    0.10002267360687256
    3        26       Softmax                      0.0   0.0   0.003818863218122295   0.006470350548624992    0.0         -0.050024636240384376  0.45051801204681396  -0.07446241943651709  0.08959561586380005


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.2838719999280463
RMSE: 0.5327963963166852
LogLoss: 0.9175343314511725
Mean Per-Class Error: 0.25483463694710334
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
358.0  0.0    0.0    0.0    0.0    0.0    2.0    7.0    0.0    2.0    5.0    0.0    2.0    1.0    1.0    0.0    0.0    0.0    2.0    0.0    1.0    0.0    3.0    1.0    7.0    3.0    0.09367088607594937  37 / 395
1.0    306.0  0.0    6.0    4.0    0.0    4.0    5.0    6.0    0.0    0.0    0.0    1.0    0.0    3.0    4.0    2.0    25.0   9.0    0.0    0.0    0.0    3.0    3.0    1.0    0.0    0.2010443864229765   77 / 383
0.0    0.0    298.0  0.0    16.0   2.0    21.0   0.0    0.0    0.0    16.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    7.0    0.0    1.0    0.0    4.0    0.0    0.0    0.0    0.19021739130434784  70 / 368
4.0    22.0   0.0    327.0  1.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    3.0    7.0    6.0    2.0    1.0    11.0   1.0    0.0    2.0    0.0    0.0    9.0    0.0    0.0    0.18858560794044665  76 / 403
0.0    15.0   1.0    0.0    300.0  1.0    17.0   1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    8.0    4.0    9.0    3.0    2.0    0.0    0.0    4.0    0.0    19.0   0.21875              84 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    2.0    0.0    0.0    0.0    0.0    0.0    15.0   0.0    0.0    4.0    0.0    8.0    5.0    0.0    0.0    0.0    4.0    0.0    0.0    4.0    2.0    331.0  0.0    0.0    0.0    0.1196808510638298   45 / 376
5.0    5.0    0.0    6.0    9.0    0.0    2.0    0.0    13.0   2.0    1.0    0.0    0.0    0.0    4.0    0.0    8.0    2.0    9.0    3.0    2.0    0.0    0.0    317.0  3.0    3.0    0.19543147208121828  77 / 394
0.0    0.0    0.0    3.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    1.0    11.0   0.0    11.0   35.0   0.0    61.0   4.0    1.0    259.0  0.0    0.3392857142857143   133 / 392
0.0    0.0    0.0    0.0    19.0   0.0    1.0    0.0    0.0    17.0   0.0    1.0    0.0    0.0    0.0    2.0    6.0    1.0    29.0   6.0    0.0    0.0    0.0    3.0    0.0    282.0  0.23160762942779292  85 / 367
441.0  474.0  359.0  443.0  444.0  229.0  363.0  213.0  338.0  348.0  352.0  308.0  391.0  419.0  426.0  487.0  381.0  488.0  278.0  427.0  394.0  394.0  428.0  444.0  329.0  405.0  0.25312406278116567  2,532 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.746876
2    0.851745
3    0.894732
4    0.920424
5    0.937919
6    0.950215
7    0.958812
8    0.96631
9    0.972708
10   0.978007

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.28424528437908286
RMSE: 0.5331465880778783
LogLoss: 0.910590359807663
Mean Per-Class Error: 0.25649905714057436
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10    11    12    13     14    15     16     17     18    19     20     21    22     23     24    25     Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  -----  -----  ----  -----  -----  ----  -----  -------------------  -----------
82.0   0.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0    0.0   0.0    0.0    0.0    1.0   0.0    0.0    0.0   0.0    1.0    3.0   0.0    0.07865168539325842  7 / 89
0.0    84.0   0.0   0.0    3.0    0.0   1.0   2.0   2.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    1.0    6.0    0.0   0.0    0.0    0.0   3.0    2.0    0.0   0.0    0.20754716981132076  22 / 106
0.0    0.0    63.0  0.0    1.0    1.0   7.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0    1.0   0.0    0.0    0.0    3.0   0.0    0.0    0.0   2.0    0.0    0.0   0.0    0.23170731707317074  19 / 82
3.0    6.0    0.0   92.0   0.0    0.0   0.0   1.0   0.0   1.0   0.0   0.0   1.0   3.0    1.0   0.0    1.0    2.0    0.0   0.0    0.0    0.0   0.0    1.0    0.0   0.0    0.17857142857142858  20 / 112
0.0    3.0    0.0   0.0    72.0   1.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    2.0    1.0    1.0   1.0    0.0    0.0   0.0    1.0    0.0   10.0   0.25773195876288657  25 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---    ---    ---   ---    ---    ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0   1.0   0.0   2.0   2.0    0.0   0.0    0.0    1.0    0.0   0.0    2.0    0.0   83.0   0.0    0.0   0.0    0.09782608695652174  9 / 92
1.0    2.0    0.0   3.0    4.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0    2.0    1.0    3.0   0.0    2.0    0.0   0.0    77.0   2.0   1.0    0.23                 23 / 100
0.0    0.0    0.0   1.0    0.0    1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    1.0   1.0    5.0    0.0    2.0   5.0    0.0    18.0  3.0    0.0    70.0  0.0    0.34579439252336447  37 / 107
0.0    0.0    0.0   0.0    4.0    0.0   0.0   0.0   0.0   4.0   0.0   1.0   0.0   0.0    0.0   1.0    1.0    0.0    6.0   2.0    0.0    0.0   0.0    0.0    0.0   68.0   0.21839080459770116  19 / 87
104.0  121.0  75.0  127.0  101.0  52.0  91.0  59.0  79.0  91.0  83.0  85.0  89.0  111.0  86.0  131.0  106.0  122.0  65.0  103.0  100.0  91.0  109.0  106.0  91.0  112.0  0.25341365461847387  631 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.746586
2    0.853414
3    0.897189
4    0.923695
5    0.936948
6    0.948996
7    0.957831
8    0.963855
9    0.971084
10   0.978715
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:08:10  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:08:10  1 min 59.441 sec  59922 obs/sec     1         1             10007      0.532796         0.917534            0.994956       0.253124                         0.533147           0.91059               0.994935         0.253414
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0785335
C12         0.94902                0.94902              0.0745299
C15         0.896814               0.896814             0.07043
C9          0.870291               0.870291             0.068347
C11         0.857014               0.857014             0.0673043
C14         0.829343               0.829343             0.0651312
C8          0.81184                0.81184              0.0637566
C16         0.78165                0.78165              0.0613857
C7          0.776386               0.776386             0.0609723
C10         0.775834               0.775834             0.060929
C6          0.763476               0.763476             0.0599585
C4          0.738888               0.738888             0.0580274
C5          0.714194               0.714194             0.0560882
C3          0.706898               0.706898             0.0555152
C2          0.633927               0.633927             0.0497845
C1          0.627842               0.627842             0.0493066
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_15

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  -------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012522977561957305  0.00032871426083147526  0.0         0.0333885614340943    1.2023415565490723  0.27240004883673546  1.0590734481811523
    3        26       Softmax                 0.0   0.0   0.0017441441793310402  0.00019486085511744022  0.0         -0.01727011811639246  0.4542548656463623  -0.5529188418507107  0.3418060541152954


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.297506987791187
RMSE: 0.54544201139185
LogLoss: 0.9688204077898511
Mean Per-Class Error: 0.2703448160337743
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
352.0  0.0    0.0    3.0    0.0    0.0    4.0    0.0    0.0    2.0    2.0    0.0    4.0    2.0    2.0    0.0    1.0    1.0    7.0    1.0    0.0    1.0    8.0    1.0    4.0    0.0    0.10886075949367088  43 / 395
0.0    263.0  0.0    9.0    1.0    4.0    0.0    12.0   1.0    2.0    0.0    0.0    1.0    0.0    1.0    4.0    8.0    46.0   22.0   0.0    0.0    0.0    1.0    1.0    7.0    0.0    0.3133159268929504   120 / 383
0.0    0.0    289.0  0.0    9.0    4.0    18.0   0.0    2.0    0.0    20.0   1.0    0.0    0.0    1.0    0.0    3.0    1.0    5.0    0.0    7.0    0.0    6.0    1.0    0.0    0.0    0.2125340599455041   78 / 367
6.0    13.0   0.0    316.0  0.0    1.0    0.0    2.0    0.0    12.0   0.0    0.0    10.0   2.0    13.0   3.0    0.0    8.0    1.0    2.0    0.0    0.0    0.0    13.0   1.0    0.0    0.21588089330024815  87 / 403
0.0    7.0    2.0    0.0    279.0  1.0    10.0   2.0    3.0    0.0    4.0    0.0    0.0    0.0    1.0    2.0    16.0   6.0    7.0    9.0    0.0    0.0    0.0    12.0   1.0    22.0   0.2734375            105 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    9.0    0.0    0.0    0.0    0.0    30.0   6.0    0.0    0.0    0.0    3.0    0.0    0.0    2.0    1.0    325.0  0.0    0.0    0.0    0.1356382978723404   51 / 376
0.0    5.0    1.0    10.0   10.0   0.0    0.0    0.0    2.0    0.0    6.0    1.0    0.0    0.0    2.0    0.0    24.0   2.0    13.0   9.0    4.0    0.0    0.0    296.0  7.0    1.0    0.24681933842239187  97 / 393
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    3.0    10.0   0.0    4.0    80.0   3.0    31.0   4.0    0.0    250.0  0.0    0.3638676844783715   143 / 393
2.0    6.0    0.0    0.0    22.0   0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    1.0    31.0   6.0    0.0    0.0    0.0    3.0    1.0    287.0  0.21798365122615804  80 / 367
409.0  422.0  403.0  460.0  389.0  298.0  282.0  293.0  322.0  352.0  336.0  335.0  472.0  374.0  382.0  400.0  420.0  480.0  307.0  483.0  379.0  369.0  465.0  399.0  370.0  402.0  0.2692192342297311   2,693 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730781
2    0.843247
3    0.888334
4    0.914026
5    0.93322
6    0.946016
7    0.955114
8    0.964811
9    0.971709
10   0.977607

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.2971053577133574
RMSE: 0.545073717687211
LogLoss: 0.9698413227088473
Mean Per-Class Error: 0.276778533971189
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20    21    22     23    24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  ----  -----  ----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    1.0    1.0   0.0    0.0   0.0   3.0    1.0   2.0    0.0    0.0898876404494382   8 / 89
0.0   70.0   0.0   1.0    1.0   0.0   0.0   5.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    3.0    17.0   4.0   0.0    0.0   0.0   1.0    1.0   2.0    0.0    0.33962264150943394  36 / 106
0.0   0.0    58.0  0.0    2.0   1.0   5.0   0.0   1.0   0.0   5.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0    3.0   0.0    3.0   0.0   2.0    0.0   0.0    0.0    0.2926829268292683   24 / 82
4.0   4.0    0.0   89.0   0.0   0.0   0.0   2.0   0.0   1.0   0.0   0.0   3.0    1.0   4.0   1.0    0.0    2.0    1.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0    0.20535714285714285  23 / 112
0.0   2.0    1.0   0.0    66.0  1.0   4.0   0.0   1.0   0.0   1.0   0.0   0.0    0.0   0.0   0.0    5.0    3.0    1.0   4.0    0.0   0.0   0.0    2.0   0.0    6.0    0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---   ---    ---   ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   6.0    1.0   0.0   0.0    0.0    0.0    0.0   0.0    0.0   0.0   83.0   0.0   0.0    0.0    0.09782608695652174  9 / 92
0.0   2.0    0.0   2.0    4.0   0.0   0.0   0.0   1.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    4.0    2.0    3.0   2.0    2.0   0.0   0.0    74.0  1.0    0.0    0.26                 26 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   1.0    5.0    0.0    0.0   18.0   1.0   9.0   2.0    0.0   70.0   0.0    0.34579439252336447  37 / 107
1.0   1.0    0.0   0.0    6.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0    6.0   3.0    0.0   0.0   0.0    0.0   1.0    68.0   0.21839080459770116  19 / 87
95.0  104.0  82.0  129.0  94.0  65.0  70.0  77.0  72.0  98.0  88.0  93.0  104.0  95.0  77.0  118.0  107.0  130.0  78.0  116.0  95.0  83.0  121.0  93.0  105.0  101.0  0.2755020080321285   686 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.724498
2    0.840964
3    0.887149
4    0.912048
5    0.931325
6    0.945381
7    0.955422
8    0.963454
9    0.971888
10   0.977108
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:39  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:39  28.003 sec  99079 obs/sec     1         1             10007      0.646098         1.30114             0.992581       0.355093                         0.645122           1.29939               0.992584         0.346988
    2019-07-24 14:06:40  28.963 sec  96128 obs/sec     10        10            100070     0.545442         0.96882             0.994712       0.269219                         0.545074           0.969841              0.994706         0.275502
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.089286
C12         0.995909               0.995909             0.0889208
C15         0.978                  0.978                0.0873218
C13         0.930036               0.930036             0.0830392
C11         0.835932               0.835932             0.0746371
C7          0.823807               0.823807             0.0735545
C8          0.777381               0.777381             0.0694093
C14         0.743965               0.743965             0.0664257
C10         0.704081               0.704081             0.0628646
C16         0.638376               0.638376             0.0569981
C6          0.579969               0.579969             0.0517832
C3          0.499615               0.499615             0.0446086
C5          0.475834               0.475834             0.0424853
C4          0.441823               0.441823             0.0394487
C1          0.408998               0.408998             0.0365178
C2          0.366232               0.366232             0.0326994
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_65

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight             weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ----------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012729454359146075  0.0003599261399358511   0.0         0.008644688076884677    1.2598519325256348   0.12217556752507533  1.1196494102478027
    3        26       Softmax                 0.0   0.0   0.001732599415565626   0.00017084676073864102  0.0         -0.0071933389593648546  0.45055925846099854  -0.5582974166195165  0.33023273944854736


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.31258300310057213
RMSE: 0.5590912296759556
LogLoss: 1.000293556634505
Mean Per-Class Error: 0.28739691607683737
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
356.0  1.0    0.0    3.0    0.0    0.0    0.0    4.0    0.0    2.0    2.0    0.0    10.0   0.0    3.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    7.0    0.0    4.0    0.0    0.09873417721518987  39 / 395
0.0    268.0  0.0    4.0    1.0    1.0    5.0    21.0   1.0    0.0    5.0    0.0    1.0    0.0    1.0    0.0    3.0    20.0   42.0   0.0    0.0    0.0    4.0    2.0    4.0    0.0    0.3002610966057441   115 / 383
0.0    0.0    291.0  0.0    9.0    5.0    23.0   1.0    0.0    0.0    15.0   0.0    0.0    0.0    1.0    1.0    3.0    0.0    8.0    2.0    3.0    0.0    5.0    1.0    0.0    0.0    0.20923913043478262  77 / 368
5.0    35.0   0.0    281.0  0.0    1.0    0.0    18.0   1.0    6.0    0.0    2.0    3.0    4.0    15.0   7.0    0.0    14.0   1.0    1.0    0.0    0.0    0.0    7.0    0.0    2.0    0.3027295285359802   122 / 403
0.0    5.0    0.0    0.0    257.0  5.0    21.0   1.0    2.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    18.0   6.0    17.0   8.0    0.0    0.0    0.0    5.0    2.0    32.0   0.3307291666666667   127 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    2.0    19.0   0.0    0.0    0.0    0.0    13.0   4.0    7.0    0.0    0.0    1.0    0.0    0.0    2.0    9.0    319.0  0.0    0.0    0.0    0.15159574468085107  57 / 376
1.0    12.0   0.0    6.0    19.0   0.0    0.0    3.0    8.0    3.0    6.0    4.0    0.0    0.0    0.0    0.0    18.0   4.0    10.0   22.0   2.0    0.0    0.0    258.0  7.0    10.0   0.3435114503816794   135 / 393
0.0    0.0    0.0    1.0    0.0    3.0    0.0    1.0    0.0    0.0    1.0    0.0    2.0    0.0    1.0    7.0    1.0    0.0    6.0    96.0   2.0    18.0   4.0    0.0    250.0  0.0    0.3638676844783715   143 / 393
0.0    5.0    0.0    0.0    27.0   7.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    0.0    55.0   3.0    0.0    0.0    0.0    2.0    0.0    263.0  0.28337874659400547  104 / 367
398.0  505.0  347.0  379.0  382.0  340.0  378.0  362.0  333.0  338.0  381.0  349.0  467.0  339.0  368.0  397.0  373.0  421.0  387.0  481.0  396.0  331.0  477.0  324.0  362.0  388.0  0.2864140757772668   2,865 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.713586
2    0.830151
3    0.882135
4    0.910927
5    0.928322
6    0.943117
7    0.953614
8    0.963711
9    0.970809
10   0.975407

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3138766662936697
RMSE: 0.5602469690178339
LogLoss: 1.004129925832914
Mean Per-Class Error: 0.29413578102258947
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17    18    19     20     21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  ----  ----  -----  -----  ----  -----  ----  -----  ----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   0.0   0.0    0.0   0.0   1.0   0.0    0.0    0.0   3.0    0.0   2.0    0.0   0.0898876404494382   8 / 89
0.0   70.0   0.0   0.0    0.0   0.0   3.0   9.0   0.0   0.0   2.0   0.0   0.0    0.0   1.0   0.0    1.0   7.0   8.0   0.0    0.0    0.0   3.0    1.0   1.0    0.0   0.33962264150943394  36 / 106
0.0   0.0    61.0  0.0    1.0   1.0   8.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   1.0    1.0   0.0   2.0   0.0    1.0    0.0   2.0    0.0   0.0    0.0   0.25609756097560976  21 / 82
3.0   6.0    0.0   82.0   0.0   1.0   0.0   4.0   0.0   1.0   0.0   2.0   1.0    2.0   5.0   1.0    0.0   2.0   0.0   0.0    0.0    0.0   0.0    2.0   0.0    0.0   0.26785714285714285  30 / 112
0.0   1.0    0.0   0.0    62.0  3.0   5.0   0.0   0.0   0.0   2.0   0.0   0.0    0.0   0.0   0.0    3.0   2.0   6.0   3.0    0.0    0.0   0.0    1.0   0.0    9.0   0.36082474226804123  35 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---   ---   ---    ---    ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   1.0   2.0   0.0   0.0   0.0   0.0   4.0    1.0   1.0   0.0    0.0   0.0   0.0   0.0    0.0    2.0   81.0   0.0   0.0    0.0   0.11956521739130435  11 / 92
0.0   5.0    0.0   1.0    8.0   0.0   0.0   1.0   3.0   2.0   4.0   1.0   0.0    0.0   0.0   0.0    3.0   1.0   1.0   4.0    0.0    0.0   0.0    60.0  3.0    3.0   0.4                  40 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   2.0    1.0   0.0   0.0   24.0   1.0    4.0   1.0    0.0   71.0   0.0   0.3364485981308411   36 / 107
0.0   1.0    0.0   0.0    10.0  3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    0.0   0.0   12.0  1.0    0.0    0.0   0.0    0.0   0.0    58.0  0.3333333333333333   29 / 87
97.0  125.0  75.0  103.0  99.0  75.0  93.0  98.0  76.0  94.0  97.0  94.0  107.0  93.0  72.0  122.0  96.0  99.0  98.0  114.0  101.0  74.0  118.0  72.0  103.0  95.0  0.2927710843373494   729 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.707229
2    0.83253
3    0.882329
4    0.91245
5    0.926908
6    0.939759
7    0.951807
8    0.962249
9    0.96747
10   0.972289
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:49  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:49  1 min 38.459 sec  105336 obs/sec    1         1             10007      0.650634         1.3256              0.992478       0.36709                          0.648155           1.32183               0.992514         0.363855
    2019-07-24 14:07:50  1 min 39.306 sec  108771 obs/sec    10        10            100070     0.559091         1.00029             0.994446       0.286414                         0.560247           1.00413               0.994407         0.292771
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.089568
C12         0.980308               0.980308             0.0878042
C9          0.96854                0.96854              0.0867502
C13         0.898662               0.898662             0.0804913
C7          0.867748               0.867748             0.0777225
C8          0.80389                0.80389              0.0720028
C11         0.766573               0.766573             0.0686604
C14         0.732989               0.732989             0.0656524
C10         0.704439               0.704439             0.0630952
C16         0.59692                0.59692              0.053465
C6          0.550492               0.550492             0.0493065
C3          0.525984               0.525984             0.0471114
C5          0.478355               0.478355             0.0428453
C4          0.459544               0.459544             0.0411605
C2          0.426255               0.426255             0.0381788
C1          0.403999               0.403999             0.0361854
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_42

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms           mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  -------------------  --------------------  -------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0013445206861035786  0.00033758406061679125  0.0         -0.015054339622679436  1.3137273788452148   -0.07124124608793998  1.02256441116333
    3        26       Softmax                 0.0   0.0   0.0017552057690688972  0.00018206099048256874  0.0         0.026405006116196825   0.44545578956604004  -0.5382204997785329   0.34667015075683594


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.313735507079383
RMSE: 0.5601209753967289
LogLoss: 1.000570137396812
Mean Per-Class Error: 0.29008757119551787
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  2.0    0.0    4.0    0.0    0.0    0.0    2.0    0.0    2.0    4.0    0.0    7.0    0.0    3.0    0.0    1.0    0.0    3.0    0.0    1.0    0.0    4.0    0.0    7.0    0.0    0.10126582278481013  40 / 395
0.0    292.0  0.0    5.0    0.0    1.0    3.0    7.0    11.0   1.0    1.0    0.0    6.0    0.0    0.0    1.0    5.0    27.0   17.0   0.0    0.0    1.0    1.0    3.0    1.0    0.0    0.23759791122715404  91 / 383
0.0    0.0    272.0  0.0    22.0   4.0    25.0   2.0    2.0    0.0    12.0   1.0    1.0    0.0    3.0    0.0    1.0    1.0    7.0    4.0    2.0    0.0    7.0    1.0    0.0    0.0    0.25885558583106266  95 / 367
5.0    23.0   0.0    303.0  0.0    0.0    0.0    4.0    0.0    15.0   0.0    0.0    7.0    5.0    3.0    4.0    0.0    15.0   7.0    0.0    1.0    0.0    0.0    11.0   0.0    0.0    0.24813895781637718  100 / 403
0.0    7.0    3.0    0.0    267.0  8.0    16.0   1.0    4.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    11.0   6.0    14.0   9.0    1.0    0.0    0.0    12.0   1.0    23.0   0.3046875            117 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    1.0    0.0    29.0   2.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    2.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
1.0    17.0   0.0    7.0    15.0   1.0    1.0    0.0    17.0   2.0    4.0    2.0    0.0    0.0    7.0    0.0    17.0   2.0    12.0   19.0   4.0    0.0    0.0    254.0  3.0    9.0    0.3553299492385787   140 / 394
0.0    0.0    0.0    1.0    0.0    27.0   0.0    3.0    0.0    0.0    0.0    0.0    2.0    1.0    7.0    5.0    8.0    0.0    9.0    80.0   2.0    40.0   0.0    0.0    208.0  0.0    0.4707379134860051   185 / 393
0.0    1.0    0.0    0.0    17.0   4.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    5.0    0.0    55.0   3.0    0.0    0.0    0.0    8.0    2.0    270.0  0.26430517711171664  97 / 367
424.0  569.0  353.0  419.0  382.0  431.0  340.0  248.0  356.0  342.0  321.0  323.0  512.0  401.0  373.0  378.0  362.0  409.0  365.0  444.0  396.0  382.0  440.0  364.0  291.0  378.0  0.2889133260021993   2,890 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.711087
2    0.828751
3    0.881935
4    0.911527
5    0.929821
6    0.942717
7    0.954814
8    0.963411
9    0.971409
10   0.977507

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3197384614195406
RMSE: 0.5654542080659941
LogLoss: 1.0169489471456439
Mean Per-Class Error: 0.2968223669171568
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10    11    12     13    14    15     16    17     18    19     20    21    22     23    24    25    Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  ----  ----  -------------------  -----------
82.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0    1.0   0.0    0.0   0.0   1.0    0.0   3.0   0.0   0.07865168539325842  7 / 89
0.0   75.0   0.0   1.0    0.0   0.0   1.0   4.0   2.0   0.0   1.0   0.0   1.0    0.0   0.0   0.0    5.0   11.0   3.0   0.0    0.0   1.0   0.0    1.0   0.0   0.0   0.29245283018867924  31 / 106
0.0   0.0    56.0  0.0    5.0   0.0   8.0   0.0   1.0   0.0   3.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    3.0   2.0    1.0   0.0   2.0    0.0   0.0   0.0   0.3170731707317073   26 / 82
2.0   5.0    0.0   84.0   0.0   0.0   0.0   2.0   0.0   4.0   0.0   0.0   3.0    1.0   0.0   2.0    0.0   5.0    2.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0   0.25                 28 / 112
0.0   1.0    1.0   0.0    66.0  4.0   4.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    4.0   1.0    2.0   4.0    0.0   0.0   0.0    4.0   0.0   5.0   0.31958762886597936  31 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   5.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   1.0   85.0   0.0   0.0   0.0   0.07608695652173914  7 / 92
0.0   4.0    0.0   2.0    6.0   0.0   0.0   0.0   5.0   0.0   1.0   0.0   0.0    0.0   1.0   0.0    3.0   0.0    6.0   5.0    1.0   0.0   0.0    63.0  1.0   2.0   0.37                 37 / 100
0.0   0.0    0.0   0.0    0.0   5.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0   3.0   1.0    3.0   0.0    1.0   23.0   0.0   13.0  0.0    0.0   56.0  0.0   0.4766355140186916   51 / 107
0.0   0.0    0.0   0.0    6.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    1.0   0.0    13.0  1.0    0.0   0.0   0.0    3.0   1.0   60.0  0.3103448275862069   27 / 87
97.0  148.0  69.0  115.0  94.0  92.0  83.0  64.0  80.0  99.0  82.0  91.0  119.0  96.0  68.0  113.0  98.0  101.0  95.0  117.0  97.0  91.0  115.0  91.0  82.0  93.0  0.2967871485943775   739 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.703213
2    0.830924
3    0.879116
4    0.908032
5    0.928916
6    0.94498
7    0.954217
8    0.960642
9    0.970281
10   0.975904
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:19  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:19  1 min  8.080 sec  109967 obs/sec    1         1             10007      0.665743         1.36846             0.992124       0.371788                         0.663239           1.35924               0.992162         0.373092
    2019-07-24 14:07:20  1 min  8.910 sec  111065 obs/sec    10        10            100070     0.560121         1.00057             0.994425       0.288913                         0.565454           1.01695               0.994303         0.296787
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.087946
C12         0.987816               0.987816             0.0868745
C15         0.981929               0.981929             0.0863567
C9          0.966494               0.966494             0.0849992
C7          0.7888                 0.7888               0.0693718
C11         0.78304                0.78304              0.0688652
C8          0.755698               0.755698             0.0664606
C10         0.723683               0.723683             0.063645
C14         0.706867               0.706867             0.0621661
C16         0.621652               0.621652             0.0546718
C6          0.601492               0.601492             0.0528988
C3          0.595204               0.595204             0.0523458
C5          0.495163               0.495163             0.0435476
C4          0.484003               0.484003             0.0425661
C1          0.442441               0.442441             0.0389109
C2          0.436335               0.436335             0.0383739
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_35

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 2,778 weights/biases, 38.4 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        64       TanhDropout  50.0       0.0   0.0   0.0012509466259302826  0.00033307168632745743  0.0         -0.010007462512476195  1.2702202796936035  -0.29317984979154543  1.0342340469360352
    3        26       Softmax                 0.0   0.0   0.00172959452251794    0.00015983072808012366  0.0         0.01831325570035985    0.4558058977127075  -0.537329999164701    0.3145923614501953


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.31353365716748566
RMSE: 0.5599407621949716
LogLoss: 1.0110983079710674
Mean Per-Class Error: 0.2868615915263983
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
346.0  1.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    4.0    3.0    1.0    13.0   0.0    0.0    0.0    1.0    4.0    4.0    0.0    2.0    1.0    4.0    1.0    4.0    0.0    0.1240506329113924   49 / 395
0.0    284.0  0.0    3.0    2.0    1.0    4.0    4.0    3.0    1.0    2.0    0.0    6.0    0.0    2.0    7.0    5.0    42.0   12.0   1.0    0.0    1.0    0.0    1.0    1.0    0.0    0.25654450261780104  98 / 382
0.0    1.0    255.0  0.0    23.0   2.0    45.0   0.0    0.0    0.0    16.0   0.0    1.0    0.0    2.0    0.0    0.0    0.0    10.0   3.0    5.0    0.0    4.0    0.0    1.0    0.0    0.3070652173913043   113 / 368
5.0    9.0    0.0    281.0  1.0    0.0    2.0    10.0   0.0    30.0   4.0    3.0    10.0   1.0    8.0    9.0    0.0    12.0   6.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.3027295285359802   122 / 403
0.0    15.0   0.0    0.0    244.0  3.0    38.0   1.0    2.0    0.0    8.0    0.0    0.0    0.0    0.0    0.0    9.0    6.0    11.0   8.0    1.0    0.0    0.0    15.0   1.0    22.0   0.3645833333333333   140 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    39.0   3.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    5.0    320.0  0.0    0.0    0.0    0.14893617021276595  56 / 376
5.0    9.0    0.0    8.0    11.0   0.0    13.0   4.0    15.0   1.0    7.0    7.0    0.0    0.0    2.0    0.0    8.0    3.0    15.0   1.0    2.0    0.0    0.0    270.0  9.0    4.0    0.3147208121827411   124 / 394
0.0    1.0    0.0    0.0    0.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    3.0    11.0   0.0    3.0    35.0   1.0    48.0   8.0    0.0    275.0  0.0    0.30025445292620867  118 / 393
2.0    4.0    0.0    3.0    11.0   2.0    1.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    46.0   5.0    0.0    0.0    0.0    6.0    0.0    282.0  0.23160762942779292  85 / 367
403.0  513.0  333.0  397.0  350.0  359.0  440.0  217.0  329.0  355.0  378.0  326.0  574.0  347.0  355.0  405.0  321.0  489.0  348.0  344.0  397.0  391.0  477.0  371.0  414.0  370.0  0.2859142257322803   2,860 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.714086
2    0.835649
3    0.884035
4    0.910427
5    0.928521
6    0.943217
7    0.953214
8    0.961412
9    0.968809
10   0.975507

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.31676460096568093
RMSE: 0.5628184440525035
LogLoss: 1.0294196317167335
Mean Per-Class Error: 0.2909884113542925
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9     10    11    12     13    14    15     16    17     18    19    20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  ----  ----  ----  -----  ----  -----  ----  -------------------  -----------
77.0  0.0    0.0   0.0    0.0   0.0   0.0    1.0   0.0   0.0   0.0   0.0   3.0    0.0   0.0   0.0    0.0   1.0    1.0   0.0   0.0   0.0   3.0    1.0   2.0    0.0   0.1348314606741573   12 / 89
0.0   76.0   0.0   1.0    0.0   0.0   1.0    2.0   1.0   0.0   0.0   0.0   2.0    0.0   1.0   1.0    3.0   15.0   1.0   0.0   0.0   1.0   0.0    1.0   0.0    0.0   0.2830188679245283   30 / 106
0.0   1.0    55.0  0.0    4.0   0.0   10.0   0.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   0.0    0.0   0.0    4.0   1.0   1.0   0.0   2.0    0.0   0.0    0.0   0.32926829268292684  27 / 82
3.0   1.0    0.0   79.0   0.0   0.0   0.0    5.0   0.0   5.0   1.0   1.0   3.0    0.0   2.0   3.0    0.0   3.0    4.0   0.0   0.0   0.0   0.0    2.0   0.0    0.0   0.29464285714285715  33 / 112
0.0   3.0    0.0   0.0    58.0  2.0   11.0   0.0   0.0   0.0   4.0   0.0   0.0    0.0   0.0   0.0    1.0   1.0    4.0   5.0   0.0   0.0   0.0    1.0   0.0    7.0   0.4020618556701031   39 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---   ---   ---   ---    ---   ---    ---   ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   8.0    1.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0   3.0   78.0   0.0   0.0    0.0   0.15217391304347827  14 / 92
1.0   4.0    0.0   2.0    3.0   0.0   2.0    3.0   3.0   0.0   3.0   2.0   0.0    0.0   0.0   0.0    2.0   1.0    5.0   0.0   0.0   0.0   0.0    66.0  2.0    1.0   0.34                 34 / 100
0.0   1.0    0.0   0.0    0.0   1.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0   0.0   0.0    4.0   0.0    0.0   5.0   0.0   11.0  3.0    0.0   79.0   0.0   0.2616822429906542   28 / 107
0.0   1.0    0.0   1.0    3.0   1.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0   0.0    9.0   3.0   0.0   0.0   0.0    2.0   0.0    66.0  0.2413793103448276   21 / 87
95.0  130.0  71.0  110.0  80.0  80.0  109.0  65.0  76.0  96.0  90.0  87.0  134.0  88.0  66.0  122.0  90.0  126.0  88.0  81.0  98.0  89.0  121.0  89.0  118.0  91.0  0.2899598393574297   722 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.71004
2    0.826506
3    0.876305
4    0.906426
5    0.926104
6    0.939759
7    0.949799
8    0.958634
9    0.967068
10   0.973092
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:09  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:09  58.730 sec  90153 obs/sec     1         1             10007      0.65236          1.31316             0.992437       0.344097                         0.649443           1.29738               0.992485         0.34257
    2019-07-24 14:07:10  59.591 sec  105336 obs/sec    10        10            100070     0.559941         1.0111              0.994428       0.285914                         0.562818           1.02942               0.994356         0.28996
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0875122
C13         0.954059               0.954059             0.0834918
C9          0.933237               0.933237             0.0816696
C12         0.912003               0.912003             0.0798114
C8          0.868078               0.868078             0.0759674
C11         0.821462               0.821462             0.0718879
C14         0.77306                0.77306              0.0676522
C7          0.772353               0.772353             0.0675902
C10         0.69789                0.69789              0.0610738
C16         0.639839               0.639839             0.0559937
C6          0.577432               0.577432             0.0505323
C3          0.561619               0.561619             0.0491485
C5          0.530658               0.530658             0.046439
C4          0.488634               0.488634             0.0427614
C2          0.458337               0.458337             0.0401101
C1          0.438321               0.438321             0.0383584
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_71

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011486979773280837  0.00034171680454164743  0.0         -0.09290564178536442  1.1034326553344727  0.03957763342919568   1.1162700653076172
    3        26       Softmax                 0.0   0.0   0.001787679790560595   0.0002153895329684019   0.0         0.004247744105948816  0.5891740322113037  -0.47207006884586583  0.281557559967041


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3335562536626264
RMSE: 0.5775432915917441
LogLoss: 1.0701015179545263
Mean Per-Class Error: 0.30533432172092173
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
351.0  0.0    0.0    0.0    0.0    0.0    0.0    7.0    1.0    2.0    4.0    1.0    7.0    0.0    2.0    0.0    1.0    2.0    1.0    0.0    1.0    1.0    8.0    0.0    5.0    0.0    0.10913705583756345  43 / 394
0.0    250.0  0.0    22.0   8.0    2.0    0.0    28.0   2.0    6.0    12.0   0.0    2.0    0.0    1.0    0.0    4.0    25.0   14.0   0.0    1.0    2.0    0.0    3.0    1.0    0.0    0.3472584856396867   133 / 383
0.0    3.0    263.0  0.0    34.0   2.0    24.0   3.0    0.0    0.0    4.0    2.0    0.0    0.0    2.0    0.0    6.0    0.0    6.0    3.0    4.0    0.0    9.0    0.0    2.0    1.0    0.28532608695652173  105 / 368
10.0   13.0   0.0    301.0  0.0    2.0    0.0    6.0    0.0    12.0   0.0    1.0    2.0    10.0   10.0   7.0    0.0    15.0   4.0    4.0    2.0    0.0    0.0    3.0    0.0    1.0    0.2531017369727047   102 / 403
0.0    18.0   7.0    0.0    236.0  9.0    15.0   3.0    1.0    1.0    7.0    0.0    0.0    0.0    0.0    0.0    12.0   5.0    7.0    8.0    0.0    0.0    0.0    20.0   0.0    35.0   0.3854166666666667   148 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
1.0    0.0    0.0    0.0    0.0    0.0    0.0    20.0   0.0    0.0    0.0    0.0    15.0   12.0   0.0    0.0    1.0    2.0    0.0    0.0    0.0    11.0   314.0  0.0    0.0    0.0    0.16489361702127658  62 / 376
0.0    24.0   2.0    13.0   10.0   1.0    0.0    1.0    18.0   8.0    6.0    6.0    0.0    0.0    0.0    1.0    28.0   5.0    7.0    12.0   2.0    0.0    0.0    226.0  3.0    21.0   0.4263959390862944   168 / 394
0.0    0.0    0.0    0.0    0.0    6.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    11.0   11.0   0.0    5.0    49.0   4.0    45.0   3.0    0.0    253.0  0.0    0.356234096692112    140 / 393
2.0    7.0    0.0    2.0    19.0   8.0    0.0    0.0    0.0    7.0    1.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    41.0   7.0    0.0    0.0    0.0    8.0    0.0    261.0  0.2888283378746594   106 / 367
435.0  507.0  302.0  477.0  388.0  350.0  349.0  370.0  359.0  354.0  302.0  328.0  416.0  394.0  407.0  375.0  450.0  418.0  283.0  432.0  398.0  411.0  437.0  333.0  344.0  384.0  0.3041087673697891   3,042 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.695891
2    0.814456
3    0.868539
4    0.90003
5    0.920424
6    0.93252
7    0.946216
8    0.955813
9    0.964611
10   0.970609

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.33607053434968676
RMSE: 0.5797159083117236
LogLoss: 1.0736698928023571
Mean Per-Class Error: 0.3117114224051045
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7      8     9     10    11    12    13     14    15     16     17     18    19    20     21    22     23    24     25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  ----  -------------------  -----------
78.0   0.0    0.0   0.0    0.0    0.0   0.0   1.0    1.0   1.0   2.0   0.0   1.0   0.0    0.0   0.0    0.0    0.0    1.0   0.0   0.0    0.0   2.0    0.0   2.0    0.0   0.12359550561797752  11 / 89
0.0    63.0   0.0   5.0    5.0    0.0   0.0   12.0   0.0   2.0   3.0   0.0   1.0   0.0    1.0   0.0    1.0    7.0    4.0   0.0   1.0    1.0   0.0    0.0   0.0    0.0   0.4056603773584906   43 / 106
0.0    2.0    54.0  0.0    7.0    0.0   7.0   0.0    0.0   0.0   1.0   0.0   0.0   0.0    1.0   0.0    1.0    0.0    2.0   1.0   1.0    0.0   3.0    0.0   2.0    0.0   0.34146341463414637  28 / 82
4.0    3.0    0.0   84.0   0.0    0.0   0.0   2.0    0.0   2.0   0.0   1.0   1.0   3.0    2.0   3.0    0.0    5.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    1.0   0.25                 28 / 112
0.0    3.0    1.0   0.0    60.0   1.0   3.0   1.0    0.0   0.0   2.0   0.0   0.0   0.0    0.0   0.0    4.0    1.0    2.0   2.0   0.0    0.0   0.0    5.0   0.0    12.0  0.38144329896907214  37 / 97
---    ---    ---   ---    ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---   ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   2.0    0.0   0.0   0.0   0.0   4.0   1.0    0.0   0.0    1.0    0.0    0.0   0.0   0.0    1.0   83.0   0.0   0.0    0.0   0.09782608695652174  9 / 92
0.0    6.0    0.0   4.0    4.0    0.0   0.0   1.0    5.0   0.0   1.0   1.0   0.0   0.0    0.0   0.0    3.0    3.0    0.0   3.0   0.0    0.0   0.0    60.0  1.0    8.0   0.4                  40 / 100
0.0    0.0    0.0   0.0    0.0    5.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    3.0    0.0    0.0   11.0  2.0    16.0  2.0    0.0   66.0   0.0   0.38317757009345793  41 / 107
0.0    0.0    0.0   1.0    6.0    2.0   0.0   0.0    0.0   2.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0    10.0  2.0   0.0    0.0   0.0    4.0   0.0    60.0  0.3103448275862069   27 / 87
105.0  123.0  62.0  130.0  102.0  80.0  86.0  101.0  85.0  93.0  77.0  88.0  88.0  104.0  79.0  103.0  112.0  107.0  74.0  92.0  103.0  96.0  118.0  86.0  100.0  96.0  0.3112449799196787   775 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.688755
2    0.813253
3    0.874297
4    0.906426
5    0.926908
6    0.935341
7    0.948193
8    0.956627
9    0.965863
10   0.971486
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:59  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:08:00  1 min 48.837 sec  145028 obs/sec    1         1             10007      0.729231         1.61556             0.990549       0.446466                         0.723702           1.58667               0.990668         0.436546
    2019-07-24 14:08:00  1 min 49.483 sec  142549 obs/sec    10        10            100070     0.577543         1.0701              0.994072       0.304109                         0.579716           1.07367               0.994012         0.311245
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.0906345
C15         0.936801               0.936801             0.0849065
C9          0.909084               0.909084             0.0823944
C11         0.864578               0.864578             0.0783606
C12         0.825124               0.825124             0.0747847
C7          0.805598               0.805598             0.0730149
C14         0.788552               0.788552             0.07147
C8          0.759721               0.759721             0.0688569
C6          0.652843               0.652843             0.0591701
C10         0.614081               0.614081             0.0556569
C16         0.607257               0.607257             0.0550385
C3          0.516988               0.516988             0.046857
C5          0.50721                0.50721              0.0459707
C4          0.45889                0.45889              0.0415913
C1          0.413189               0.413189             0.0374491
C2          0.373411               0.373411             0.0338439
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_6

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  25.0       0.0   0.0   0.0011009816536216022  0.00028096616733819246  0.0         -0.007718754029610864  1.106266975402832   -0.18338863066680725  1.034560203552246
    3        26       Softmax                 0.0   0.0   0.0017635763831024703  0.00019336328841745853  0.0         -0.019897608279769392  0.5844011306762695  -0.47588598481047456  0.25038790702819824


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.3381906152396032
RMSE: 0.5815415851335166
LogLoss: 1.0839569665661228
Mean Per-Class Error: 0.3107774020614812
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  2.0    0.0    10.0   0.0    0.0    0.0    0.0    0.0    4.0    0.0    1.0    15.0   1.0    0.0    0.0    1.0    0.0    1.0    0.0    1.0    1.0    4.0    1.0    5.0    0.0    0.1189873417721519   47 / 395
1.0    274.0  0.0    10.0   4.0    1.0    1.0    5.0    11.0   1.0    9.0    0.0    1.0    0.0    12.0   0.0    6.0    29.0   6.0    0.0    0.0    0.0    0.0    5.0    7.0    0.0    0.2845953002610966   109 / 383
1.0    0.0    270.0  0.0    17.0   1.0    24.0   2.0    0.0    0.0    15.0   0.0    1.0    0.0    4.0    0.0    5.0    0.0    6.0    5.0    6.0    0.0    3.0    2.0    0.0    5.0    0.26430517711171664  97 / 367
5.0    17.0   0.0    292.0  0.0    1.0    0.0    18.0   0.0    8.0    1.0    0.0    8.0    2.0    10.0   4.0    1.0    28.0   2.0    0.0    0.0    0.0    1.0    3.0    2.0    0.0    0.27543424317617865  111 / 403
0.0    13.0   28.0   0.0    186.0  2.0    50.0   0.0    4.0    0.0    11.0   2.0    0.0    0.0    0.0    0.0    16.0   4.0    5.0    9.0    1.0    0.0    0.0    29.0   1.0    23.0   0.515625             198 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    8.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    14.0   13.0   0.0    0.0    1.0    3.0    0.0    0.0    0.0    2.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
0.0    17.0   0.0    1.0    32.0   0.0    2.0    4.0    4.0    3.0    9.0    10.0   0.0    0.0    0.0    1.0    19.0   6.0    13.0   12.0   1.0    0.0    0.0    230.0  11.0   19.0   0.41624365482233505  164 / 394
0.0    0.0    0.0    1.0    0.0    10.0   0.0    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    11.0   5.0    0.0    8.0    95.0   2.0    36.0   6.0    0.0    216.0  0.0    0.45038167938931295  177 / 393
1.0    10.0   0.0    5.0    11.0   11.0   1.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    1.0    5.0    0.0    38.0   2.0    0.0    0.0    0.0    19.0   1.0    260.0  0.29155313351498635  107 / 367
431.0  611.0  395.0  418.0  301.0  346.0  410.0  267.0  338.0  322.0  300.0  341.0  474.0  368.0  409.0  381.0  401.0  445.0  244.0  496.0  368.0  365.0  456.0  396.0  343.0  377.0  0.30970708787363793  3,098 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.690293
2    0.809457
3    0.86494
4    0.896731
5    0.917225
6    0.93182
7    0.944517
8    0.954414
9    0.962211
10   0.969409

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3404003540534894
RMSE: 0.5834383892524466
LogLoss: 1.0841083880360163
Mean Per-Class Error: 0.31504560539838555
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6      7     8     9     10    11    12     13    14    15     16    17     18    19     20    21    22     23    24     25    Error                Rate
----  -----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  ----  -----  ----  -----  ----  ----  -----  ----  -----  ----  -------------------  -----------
75.0  0.0    0.0   1.0    0.0   0.0   0.0    0.0   0.0   2.0   0.0   1.0   4.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0   0.0   2.0    1.0   2.0    0.0   0.15730337078651685  14 / 89
0.0   71.0   0.0   2.0    0.0   0.0   1.0    3.0   5.0   0.0   2.0   0.0   0.0    0.0   5.0   0.0    1.0   10.0   0.0   0.0    0.0   0.0   0.0    2.0   4.0    0.0   0.330188679245283    35 / 106
0.0   0.0    55.0  0.0    3.0   0.0   8.0    2.0   0.0   0.0   3.0   0.0   0.0    0.0   1.0   0.0    1.0   0.0    3.0   0.0    2.0   0.0   1.0    1.0   0.0    2.0   0.32926829268292684  27 / 82
1.0   2.0    0.0   87.0   0.0   1.0   0.0    2.0   0.0   1.0   0.0   0.0   4.0    0.0   4.0   1.0    0.0   7.0    2.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.22321428571428573  25 / 112
0.0   5.0    7.0   0.0    42.0  1.0   12.0   0.0   0.0   0.0   6.0   0.0   0.0    0.0   0.0   0.0    4.0   1.0    2.0   4.0    0.0   0.0   0.0    5.0   0.0    8.0   0.5670103092783505   55 / 97
---   ---    ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---   ---    ---   ---    ---   ---   ---    ---   ---    ---   ---                  ---
0.0   1.0    0.0   0.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   4.0    2.0   0.0   0.0    0.0   1.0    0.0   0.0    0.0   0.0   84.0   0.0   0.0    0.0   0.08695652173913043  8 / 92
0.0   2.0    0.0   1.0    10.0  0.0   0.0    2.0   2.0   1.0   4.0   1.0   0.0    0.0   0.0   0.0    2.0   4.0    5.0   1.0    0.0   0.0   0.0    54.0  5.0    6.0   0.46                 46 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   2.0    2.0   0.0    1.0   25.0   0.0   11.0  3.0    0.0   61.0   0.0   0.42990654205607476  46 / 107
0.0   2.0    0.0   3.0    3.0   2.0   0.0    0.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   0.0    0.0   0.0    9.0   2.0    0.0   0.0   0.0    7.0   1.0    57.0  0.3448275862068966   30 / 87
98.0  145.0  83.0  119.0  66.0  84.0  101.0  75.0  78.0  92.0  79.0  92.0  116.0  92.0  92.0  111.0  94.0  105.0  71.0  119.0  93.0  84.0  112.0  94.0  102.0  93.0  0.314859437751004    784 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.685141
2    0.807229
3    0.859036
4    0.895984
5    0.919277
6    0.936546
7    0.948193
8    0.958635
9    0.965863
10   0.972289
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:25  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:25  14.055 sec  140943 obs/sec    1         1             10007      0.690674         1.50265             0.991523       0.423473                         0.689035           1.48604               0.99154          0.423293
    2019-07-24 14:06:25  14.717 sec  139958 obs/sec    10        10            100070     0.581542         1.08396             0.99399        0.309707                         0.583438           1.08411               0.993935         0.314859
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0884204
C13         0.967039               0.967039             0.0855061
C12         0.874908               0.874908             0.0773598
C9          0.872765               0.872765             0.0771703
C11         0.841559               0.841559             0.074411
C8          0.794912               0.794912             0.0702865
C14         0.794023               0.794023             0.0702079
C7          0.76889                0.76889              0.0679856
C6          0.636651               0.636651             0.056293
C16         0.634534               0.634534             0.0561058
C5          0.579736               0.579736             0.0512605
C3          0.552062               0.552062             0.0488135
C10         0.534286               0.534286             0.0472418
C4          0.525088               0.525088             0.0464285
C1          0.49833                0.49833              0.0440626
C2          0.434819               0.434819             0.0384469
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_14

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008020210353265611  0.00021494051907211542  0.0         -0.03318691665026563  0.28841984272003174  0.040435861791478483  0.19797074794769287
    3        26       Softmax                      0.0   0.0   0.004253967236274128   0.008133988827466965    0.0         -0.3501003276668108   0.8918857574462891   -0.8093413022493041   0.6528055667877197


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.36713257492022766
RMSE: 0.6059146597667263
LogLoss: 1.0800889860579308
Mean Per-Class Error: 0.26299543138517795
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
348.0  1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    4.0    3.0    0.0    9.0    0.0    8.0    0.0    4.0    0.0    1.0    2.0    2.0    5.0    3.0    0.0    1.0    1.0    0.1189873417721519   47 / 395
0.0    311.0  0.0    14.0   0.0    0.0    6.0    1.0    3.0    0.0    3.0    0.0    0.0    0.0    5.0    2.0    0.0    26.0   8.0    0.0    0.0    1.0    0.0    1.0    2.0    0.0    0.18798955613577023  72 / 383
0.0    0.0    285.0  1.0    23.0   2.0    13.0   1.0    0.0    0.0    17.0   0.0    5.0    0.0    6.0    0.0    7.0    0.0    2.0    0.0    2.0    0.0    3.0    1.0    0.0    0.0    0.22554347826086957  83 / 368
2.0    23.0   0.0    320.0  0.0    0.0    0.0    7.0    3.0    3.0    0.0    2.0    6.0    4.0    3.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    0.0    18.0   0.0    0.0    0.20595533498759305  83 / 403
0.0    5.0    5.0    0.0    270.0  5.0    9.0    0.0    0.0    0.0    12.0   1.0    0.0    0.0    1.0    1.0    15.0   5.0    8.0    4.0    0.0    0.0    0.0    13.0   0.0    30.0   0.296875             114 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    2.0    0.0    42.0   3.0    1.0    0.0    0.0    5.0    0.0    0.0    1.0    2.0    318.0  0.0    0.0    0.0    0.15425531914893617  58 / 376
0.0    7.0    0.0    2.0    15.0   0.0    1.0    0.0    1.0    1.0    8.0    0.0    0.0    0.0    0.0    0.0    23.0   1.0    18.0   6.0    3.0    0.0    0.0    300.0  1.0    7.0    0.23857868020304568  94 / 394
0.0    1.0    0.0    1.0    0.0    9.0    3.0    5.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    26.0   0.0    1.0    55.0   1.0    68.0   0.0    0.0    221.0  1.0    0.43765903307888043  172 / 393
0.0    5.0    0.0    0.0    10.0   2.0    1.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0    3.0    9.0    0.0    36.0   2.0    0.0    0.0    0.0    3.0    0.0    292.0  0.20435967302452315  75 / 367
390.0  554.0  355.0  445.0  360.0  328.0  312.0  242.0  350.0  312.0  435.0  316.0  529.0  330.0  388.0  385.0  442.0  406.0  303.0  421.0  387.0  451.0  432.0  426.0  272.0  432.0  0.26182145356393083  2,619 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.738179
2    0.843447
3    0.888333
4    0.913226
5    0.93172
6    0.946216
7    0.958312
8    0.96631
9    0.972508
10   0.977907

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3698023001457954
RMSE: 0.6081137230368966
LogLoss: 1.0922626078323237
Mean Per-Class Error: 0.2698414090268336
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16     17     18    19     20    21     22     23     24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  -----  ----  -----  -----  -----  ----  -----  -------------------  -----------
78.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   2.0    0.0   1.0    0.0   2.0   0.0    1.0    0.0    0.0   0.0    0.0   3.0    1.0    0.0    1.0   0.0    0.12359550561797752  11 / 89
0.0   78.0   0.0   5.0    0.0   0.0   2.0   1.0   1.0   0.0   1.0    0.0   0.0    0.0   2.0   1.0    0.0    11.0   2.0   0.0    0.0   1.0    0.0    1.0    0.0   0.0    0.2641509433962264   28 / 106
0.0   0.0    56.0  0.0    6.0   1.0   4.0   1.0   0.0   0.0   5.0    0.0   0.0    0.0   2.0   0.0    3.0    0.0    1.0   0.0    1.0   0.0    2.0    0.0    0.0   0.0    0.3170731707317073   26 / 82
2.0   4.0    0.0   93.0   0.0   0.0   0.0   2.0   1.0   1.0   0.0    2.0   2.0    2.0   0.0   0.0    0.0    2.0    0.0   0.0    0.0   0.0    0.0    1.0    0.0   0.0    0.16964285714285715  19 / 112
0.0   0.0    1.0   0.0    62.0  3.0   4.0   0.0   0.0   0.0   6.0    0.0   0.0    0.0   0.0   0.0    4.0    1.0    2.0   3.0    0.0   0.0    0.0    2.0    0.0   9.0    0.36082474226804123  35 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---    ---   ---    ---    ---    ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   7.0    1.0   1.0   0.0    0.0    1.0    0.0   0.0    0.0   1.0    81.0   0.0    0.0   0.0    0.11956521739130435  11 / 92
0.0   2.0    0.0   2.0    7.0   0.0   1.0   0.0   0.0   0.0   2.0    0.0   0.0    0.0   0.0   0.0    2.0    0.0    5.0   1.0    2.0   0.0    0.0    74.0   0.0   2.0    0.26                 26 / 100
0.0   1.0    0.0   0.0    0.0   2.0   1.0   2.0   0.0   0.0   0.0    0.0   0.0    1.0   0.0   0.0    8.0    0.0    0.0   11.0   1.0   19.0   0.0    0.0    61.0  0.0    0.42990654205607476  46 / 107
0.0   0.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   3.0   0.0    0.0   0.0    0.0   0.0   1.0    3.0    0.0    7.0   1.0    0.0   0.0    0.0    0.0    0.0   70.0   0.19540229885057472  17 / 87
87.0  128.0  72.0  127.0  86.0  70.0  80.0  60.0  84.0  88.0  114.0  93.0  118.0  84.0  78.0  117.0  117.0  104.0  80.0  104.0  99.0  112.0  111.0  100.0  74.0  103.0  0.26947791164658635  671 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.730522
2    0.835743
3    0.883936
4    0.910843
5    0.928916
6    0.940562
7    0.953012
8    0.963855
9    0.970683
10   0.976707
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:38  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:38  27.589 sec  277972 obs/sec    1         1             10007      0.840678         2.0896              0.987443       0.511347                         0.839956           2.08176               0.987429         0.506024
    2019-07-24 14:06:39  27.868 sec  331357 obs/sec    10        10            100070     0.605915         1.08009             0.993477       0.261821                         0.608114           1.09226               0.993411         0.269478
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.104947
C15         0.939263               0.939263             0.0985731
C12         0.815408               0.815408             0.0855749
C9          0.772687               0.772687             0.0810914
C8          0.657436               0.657436             0.0689961
C7          0.639297               0.639297             0.0670925
C11         0.617896               0.617896             0.0648465
C14         0.59198                0.59198              0.0621267
C10         0.543686               0.543686             0.0570584
C6          0.536367               0.536367             0.0562903
C4          0.470157               0.470157             0.0493417
C16         0.46077                0.46077              0.0483566
C3          0.430022               0.430022             0.0451297
C5          0.428506               0.428506             0.0449705
C1          0.339422               0.339422             0.0356214
C2          0.285696               0.285696             0.029983
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_62

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias            bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  -------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0007932398644356908  0.00020168640185147524  0.0         -0.018508233172468636  0.2786095142364502  0.0672139995286329   0.17484819889068604
    3        26       Softmax                      0.0   0.0   0.004376825446482913   0.008214734494686127    0.0         -0.359763859294337     0.895366907119751   -0.8511507389706351  0.641761302947998


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.37736384248121674
RMSE: 0.6142994729618582
LogLoss: 1.1146376073148563
Mean Per-Class Error: 0.28003768168449383
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
355.0  4.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    3.0    2.0    0.0    9.0    0.0    1.0    0.0    0.0    0.0    6.0    0.0    0.0    0.0    6.0    0.0    6.0    0.0    0.09898477157360407  39 / 394
0.0    317.0  0.0    10.0   1.0    2.0    2.0    0.0    2.0    0.0    0.0    0.0    1.0    0.0    25.0   1.0    2.0    9.0    1.0    0.0    0.0    0.0    1.0    9.0    0.0    0.0    0.17232375979112272  66 / 383
0.0    0.0    297.0  0.0    6.0    0.0    16.0   0.0    0.0    0.0    27.0   0.0    1.0    0.0    4.0    2.0    1.0    0.0    4.0    0.0    2.0    0.0    6.0    2.0    0.0    0.0    0.19293478260869565  71 / 368
1.0    18.0   0.0    316.0  0.0    0.0    4.0    1.0    0.0    9.0    0.0    0.0    6.0    5.0    16.0   0.0    0.0    9.0    4.0    0.0    0.0    0.0    0.0    9.0    0.0    5.0    0.21588089330024815  87 / 403
0.0    9.0    5.0    1.0    267.0  2.0    25.0   0.0    0.0    0.0    2.0    0.0    1.0    0.0    1.0    0.0    8.0    5.0    18.0   0.0    1.0    0.0    0.0    16.0   0.0    22.0   0.3028720626631854   116 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0    4.0    0.0    18.0   1.0    12.0   0.0    0.0    1.0    0.0    0.0    0.0    0.0    334.0  0.0    0.0    0.0    0.11170212765957446  42 / 376
2.0    3.0    1.0    15.0   6.0    0.0    0.0    1.0    4.0    2.0    7.0    0.0    0.0    1.0    2.0    0.0    0.0    0.0    16.0   2.0    1.0    2.0    0.0    295.0  9.0    25.0   0.2512690355329949   99 / 394
1.0    0.0    0.0    1.0    0.0    6.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0    2.0    10.0   0.0    11.0   69.0   1.0    44.0   7.0    0.0    235.0  0.0    0.4020356234096692   158 / 393
6.0    2.0    0.0    0.0    12.0   0.0    0.0    0.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    47.0   1.0    0.0    0.0    0.0    2.0    0.0    292.0  0.20435967302452315  75 / 367
440.0  540.0  395.0  510.0  344.0  269.0  321.0  151.0  332.0  354.0  400.0  312.0  472.0  386.0  515.0  400.0  309.0  368.0  351.0  435.0  357.0  375.0  471.0  452.0  308.0  436.0  0.2789163251024693   2,790 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.721084
2    0.828252
3    0.869039
4    0.898231
5    0.923623
6    0.940618
7    0.952914
8    0.963211
9    0.969609
10   0.976307

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.37909713733692935
RMSE: 0.615708646469196
LogLoss: 1.1115407487229036
Mean Per-Class Error: 0.28786907531665007
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9      10     11    12     13    14     15     16    17    18    19     20    21    22     23     24    25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  -----  -----  ----  -----  ----  -----  -----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -------------------  -----------
79.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   2.0    0.0    0.0   2.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0    0.0   0.0   2.0    0.0    3.0   0.0    0.11235955056179775  10 / 89
0.0    82.0   0.0   4.0    1.0   0.0   0.0   0.0   1.0   0.0    0.0    0.0   0.0    0.0   10.0   0.0    1.0   3.0   0.0   0.0    0.0   0.0   1.0    3.0    0.0   0.0    0.22641509433962265  24 / 106
0.0    0.0    61.0  0.0    1.0   0.0   7.0   0.0   0.0   0.0    6.0    0.0   0.0    0.0   2.0    1.0    0.0   0.0   2.0   0.0    0.0   0.0   2.0    0.0    0.0   0.0    0.25609756097560976  21 / 82
1.0    2.0    0.0   92.0   0.0   0.0   2.0   1.0   0.0   1.0    0.0    0.0   2.0    3.0   3.0    0.0    0.0   1.0   1.0   0.0    0.0   0.0   0.0    1.0    0.0   2.0    0.17857142857142858  20 / 112
0.0    3.0    0.0   0.0    60.0  1.0   9.0   0.0   0.0   0.0    1.0    0.0   0.0    0.0   0.0    0.0    2.0   1.0   6.0   0.0    0.0   0.0   0.0    5.0    0.0   9.0    0.38144329896907214  37 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---    ---    ---   ---    ---   ---    ---    ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    2.0    0.0   4.0    0.0   1.0    0.0    0.0   0.0   0.0   0.0    0.0   0.0   85.0   0.0    0.0   0.0    0.07608695652173914  7 / 92
1.0    1.0    0.0   5.0    2.0   0.0   0.0   0.0   2.0   0.0    3.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   6.0   0.0    0.0   0.0   0.0    72.0   4.0   4.0    0.28                 28 / 100
0.0    0.0    0.0   0.0    0.0   1.0   0.0   0.0   0.0   0.0    0.0    0.0   0.0    0.0   4.0    2.0    5.0   0.0   2.0   19.0   0.0   15.0  2.0    0.0    57.0  0.0    0.4672897196261682   50 / 107
1.0    1.0    0.0   0.0    2.0   0.0   0.0   0.0   0.0   1.0    0.0    0.0   0.0    0.0   0.0    0.0    0.0   0.0   10.0  0.0    0.0   0.0   0.0    1.0    0.0   71.0   0.1839080459770115   16 / 87
106.0  129.0  79.0  147.0  78.0  67.0  81.0  38.0  75.0  101.0  100.0  87.0  103.0  98.0  117.0  112.0  87.0  93.0  88.0  108.0  94.0  88.0  117.0  106.0  78.0  113.0  0.2863453815261044   713 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.713655
2    0.834538
3    0.876707
4    0.905622
5    0.928916
6    0.945381
7    0.953414
8    0.963454
9    0.968675
10   0.976707
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:48  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:48  1 min 36.886 sec  285914 obs/sec    1         1             10007      0.850617         2.14729             0.987139       0.529941                         0.849777           2.13688               0.987133         0.525301
    2019-07-24 14:07:48  1 min 37.169 sec  327026 obs/sec    10        10            100070     0.614299         1.11464             0.993293       0.278916                         0.615709           1.11154               0.993245         0.286345
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.107132
C15         0.934037               0.934037             0.100066
C9          0.804269               0.804269             0.0861633
C7          0.710345               0.710345             0.076101
C8          0.691949               0.691949             0.0741301
C14         0.615358               0.615358             0.0659248
C11         0.611477               0.611477             0.065509
C3          0.540223               0.540223             0.0578754
C6          0.520034               0.520034             0.0557126
C16         0.50745                0.50745              0.0543643
C12         0.494637               0.494637             0.0529917
C10         0.482042               0.482042             0.0516423
C5          0.4738                 0.4738               0.0507594
C4          0.40353                0.40353              0.0432312
C1          0.289288               0.289288             0.0309922
C2          0.255801               0.255801             0.0274046
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_23

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms
--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -------------------
    1        16       Input             0.0
    2        32       RectifierDropout  50.0       0.0   0.0   0.0008307982482165244  0.0002382179955020547  0.0         -0.012984000587493938  0.29387366771698    0.009693732800694101  0.19779694080352783
    3        26       Softmax                      0.0   0.0   0.004386652347630633   0.007210252806544304   0.0         -0.31063890741391403   0.8703172206878662  -0.848467770850173    0.5730986595153809


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.37792301664233924
RMSE: 0.6147544360493377
LogLoss: 1.1082572337847294
Mean Per-Class Error: 0.2718758906720564
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
350.0  0.0    0.0    1.0    0.0    0.0    2.0    0.0    0.0    3.0    2.0    0.0    10.0   0.0    1.0    0.0    2.0    0.0    11.0   0.0    1.0    2.0    3.0    1.0    6.0    0.0    0.11392405063291139  45 / 395
0.0    283.0  0.0    9.0    2.0    1.0    2.0    0.0    3.0    0.0    4.0    0.0    4.0    0.0    2.0    5.0    3.0    32.0   11.0   0.0    0.0    0.0    1.0    21.0   0.0    0.0    0.26109660574412535  100 / 383
0.0    0.0    302.0  0.0    8.0    0.0    9.0    3.0    0.0    0.0    32.0   0.0    0.0    0.0    2.0    3.0    3.0    0.0    1.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0    0.1793478260869565   66 / 368
4.0    13.0   0.0    313.0  0.0    1.0    1.0    0.0    1.0    10.0   0.0    1.0    3.0    5.0    2.0    1.0    1.0    11.0   4.0    0.0    0.0    0.0    0.0    32.0   0.0    0.0    0.22332506203473945  90 / 403
0.0    7.0    2.0    1.0    275.0  0.0    16.0   0.0    0.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    13.0   8.0    7.0    2.0    2.0    0.0    1.0    13.0   4.0    28.0   0.2838541666666667   109 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    15.0   4.0    0.0    0.0    0.0    10.0   0.0    0.0    3.0    2.0    340.0  0.0    0.0    0.0    0.09333333333333334  35 / 375
1.0    3.0    0.0    11.0   9.0    0.0    1.0    2.0    3.0    1.0    2.0    4.0    1.0    0.0    0.0    0.0    3.0    8.0    18.0   4.0    14.0   0.0    0.0    293.0  15.0   1.0    0.2563451776649746   101 / 394
0.0    0.0    0.0    1.0    0.0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0    2.0    17.0   0.0    11.0   49.0   1.0    39.0   1.0    2.0    263.0  0.0    0.33078880407124683  130 / 393
4.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    1.0    4.0    0.0    2.0    0.0    0.0    0.0    0.0    4.0    1.0    40.0   2.0    0.0    0.0    0.0    6.0    0.0    289.0  0.2125340599455041   78 / 367
405.0  459.0  387.0  440.0  356.0  265.0  260.0  207.0  360.0  328.0  421.0  324.0  499.0  362.0  336.0  440.0  403.0  475.0  360.0  394.0  403.0  347.0  480.0  518.0  377.0  397.0  0.2708187543736879   2,709 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.729181
2    0.841647
3    0.883135
4    0.911726
5    0.929821
6    0.945616
7    0.955413
8    0.963511
9    0.970809
10   0.976007

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.3794755732905528
RMSE: 0.6160158872062902
LogLoss: 1.1153187395899737
Mean Per-Class Error: 0.28277087674376306
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9     10     11    12     13    14    15     16     17     18    19    20     21    22     23     24     25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  ----  -----  ----  -----  ----  ----  -----  -----  -----  ----  ----  -----  ----  -----  -----  -----  -----  -------------------  -----------
81.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   2.0    0.0   0.0   0.0    0.0    0.0    1.0   0.0   0.0    1.0   1.0    0.0    3.0    0.0    0.0898876404494382   8 / 89
0.0   73.0   0.0   4.0    1.0   1.0   0.0   0.0   1.0   0.0   0.0    0.0   1.0    0.0   2.0   0.0    2.0    10.0   3.0   0.0   0.0    0.0   1.0    7.0    0.0    0.0    0.3113207547169811   33 / 106
0.0   0.0    62.0  0.0    2.0   0.0   3.0   2.0   0.0   0.0   7.0    0.0   0.0    0.0   1.0   1.0    1.0    0.0    1.0   0.0   1.0    0.0   1.0    0.0    0.0    0.0    0.24390243902439024  20 / 82
2.0   2.0    0.0   92.0   0.0   0.0   1.0   0.0   1.0   2.0   0.0    0.0   1.0    2.0   0.0   0.0    0.0    2.0    2.0   0.0   0.0    0.0   0.0    5.0    0.0    0.0    0.17857142857142858  20 / 112
0.0   2.0    1.0   0.0    59.0  0.0   3.0   0.0   0.0   0.0   3.0    0.0   0.0    0.0   0.0   0.0    4.0    3.0    1.0   2.0   0.0    0.0   1.0    3.0    0.0    15.0   0.3917525773195876   38 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---   ---    ---   ---    ---   ---   ---    ---    ---    ---   ---   ---    ---   ---    ---    ---    ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   4.0    0.0   0.0   0.0    0.0    2.0    0.0   0.0   0.0    1.0   85.0   0.0    0.0    0.0    0.07608695652173914  7 / 92
0.0   2.0    0.0   3.0    4.0   0.0   0.0   0.0   0.0   0.0   1.0    2.0   1.0    0.0   0.0   0.0    1.0    4.0    5.0   0.0   4.0    0.0   0.0    65.0   7.0    1.0    0.35                 35 / 100
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0   1.0   1.0    7.0    0.0    2.0   12.0  1.0    9.0   1.0    1.0    72.0   0.0    0.32710280373831774  35 / 107
2.0   0.0    0.0   0.0    3.0   0.0   0.0   0.0   0.0   1.0   0.0    2.0   0.0    0.0   0.0   0.0    1.0    0.0    10.0  1.0   0.0    0.0   0.0    1.0    0.0    66.0   0.2413793103448276   21 / 87
99.0  104.0  80.0  129.0  78.0  57.0  62.0  52.0  87.0  92.0  108.0  91.0  110.0  90.0  69.0  120.0  116.0  125.0  91.0  96.0  102.0  79.0  119.0  121.0  105.0  108.0  0.28032128514056226  698 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.719679
2    0.836145
3    0.882329
4    0.916867
5    0.93253
6    0.947791
7    0.95743
8    0.962651
9    0.970281
10   0.973896
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:51  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:51  40.480 sec  263342 obs/sec    1         1             10007      0.841628         2.11451             0.987413       0.528841                         0.839068           2.10483               0.987455         0.5249
    2019-07-24 14:06:51  40.758 sec  329177 obs/sec    10        10            100070     0.614754         1.10826             0.993284       0.270819                         0.616016           1.11532               0.993238         0.280321
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.100535
C15         0.825869               0.825869             0.0830286
C9          0.768632               0.768632             0.0772743
C12         0.749886               0.749886             0.0753897
C8          0.735651               0.735651             0.0739586
C7          0.735571               0.735571             0.0739506
C11         0.718258               0.718258             0.07221
C14         0.617018               0.617018             0.0620319
C6          0.606322               0.606322             0.0609565
C10         0.593858               0.593858             0.0597034
C3          0.502422               0.502422             0.0505109
C4          0.496306               0.496306             0.0498961
C5          0.480486               0.480486             0.0483056
C16         0.440591               0.440591             0.0442948
C1          0.362419               0.362419             0.0364358
C2          0.313507               0.313507             0.0315184
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_60

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.001114257746507974   0.00031005730852484703  0.0         -0.1513689173370949   2.089493751525879   -0.48753702029255624  1.6314301490783691
    3        26       Softmax                 0.0   0.0   0.0016829625096411642  0.00010651117190718651  0.0         -0.03226682055027105  0.5021581649780273  -0.5823092186293616   0.3665313720703125


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4717647004454523
RMSE: 0.6868512942736967
LogLoss: 1.4045148716684692
Mean Per-Class Error: 0.39241232785884367
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
349.0  0.0    0.0    5.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    2.0    8.0    1.0    9.0    0.0    1.0    5.0    1.0    0.0    0.0    0.0    8.0    0.0    5.0    0.0    0.11645569620253164  46 / 395
0.0    226.0  0.0    9.0    0.0    1.0    1.0    14.0   8.0    7.0    2.0    0.0    1.0    0.0    1.0    4.0    3.0    75.0   20.0   0.0    0.0    0.0    3.0    3.0    2.0    3.0    0.40992167101827676  157 / 383
0.0    2.0    239.0  0.0    33.0   1.0    21.0   1.0    0.0    0.0    22.0   0.0    3.0    1.0    0.0    1.0    14.0   1.0    8.0    3.0    11.0   0.0    4.0    0.0    2.0    1.0    0.35054347826086957  129 / 368
8.0    9.0    0.0    270.0  0.0    0.0    0.0    9.0    0.0    23.0   1.0    7.0    4.0    6.0    5.0    17.0   0.0    35.0   6.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.33002481389578164  133 / 403
0.0    17.0   15.0   0.0    182.0  3.0    33.0   2.0    4.0    5.0    3.0    1.0    0.0    0.0    0.0    0.0    14.0   12.0   19.0   4.0    1.0    0.0    0.0    12.0   3.0    54.0   0.5260416666666666   202 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    10.0   0.0    0.0    4.0    0.0    23.0   14.0   0.0    1.0    0.0    2.0    0.0    0.0    0.0    22.0   300.0  0.0    0.0    0.0    0.20212765957446807  76 / 376
29.0   15.0   0.0    5.0    49.0   1.0    0.0    8.0    31.0   16.0   11.0   3.0    0.0    0.0    4.0    0.0    16.0   8.0    43.0   14.0   4.0    0.0    0.0    87.0   21.0   29.0   0.7791878172588832   307 / 394
0.0    0.0    0.0    7.0    0.0    18.0   1.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    3.0    1.0    10.0   0.0    4.0    76.0   1.0    41.0   3.0    0.0    224.0  0.0    0.4300254452926209   169 / 393
3.0    4.0    0.0    5.0    14.0   10.0   0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    3.0    0.0    6.0    3.0    39.0   5.0    0.0    0.0    0.0    7.0    0.0    266.0  0.27520435967302453  101 / 367
467.0  518.0  381.0  417.0  358.0  356.0  280.0  232.0  383.0  373.0  295.0  328.0  471.0  407.0  302.0  395.0  419.0  579.0  362.0  380.0  384.0  367.0  481.0  212.0  437.0  419.0  0.3910826751974408   3,912 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.608917
2    0.758272
3    0.829551
4    0.868739
5    0.90083
6    0.919524
7    0.93392
8    0.946416
9    0.954514
10   0.961711

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4708220637643483
RMSE: 0.6861647497243999
LogLoss: 1.4023380941020622
Mean Per-Class Error: 0.39131937691489765
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4     5     6     7     8     9     10    11    12     13     14    15     16     17     18    19    20     21    22     23    24     25     Error                Rate
-----  -----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  ----  -----  -----  -----  ----  ----  -----  ----  -----  ----  -----  -----  -------------------  -----------
80.0   0.0    0.0   1.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0    1.0   0.0    0.0    1.0    0.0   0.0   0.0    0.0   3.0    0.0   2.0    0.0    0.10112359550561797  9 / 89
0.0    55.0   0.0   2.0    0.0   0.0   0.0   6.0   3.0   1.0   1.0   0.0   0.0    0.0    0.0   2.0    1.0    25.0   5.0   0.0   0.0    0.0   2.0    1.0   0.0    2.0    0.4811320754716981   51 / 106
0.0    1.0    46.0  0.0    7.0   1.0   6.0   1.0   0.0   0.0   5.0   0.0   0.0    0.0    0.0   0.0    5.0    0.0    3.0   0.0   4.0    0.0   2.0    0.0   1.0    0.0    0.43902439024390244  36 / 82
4.0    2.0    0.0   81.0   0.0   0.0   0.0   4.0   0.0   2.0   0.0   3.0   3.0    2.0    1.0   4.0    0.0    5.0    1.0   0.0   0.0    0.0   0.0    0.0   0.0    0.0    0.2767857142857143   31 / 112
0.0    6.0    5.0   0.0    44.0  1.0   11.0  0.0   1.0   0.0   2.0   0.0   0.0    0.0    0.0   0.0    2.0    5.0    1.0   1.0   0.0    0.0   0.0    3.0   1.0    14.0   0.5463917525773195   53 / 97
---    ---    ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---   ---    ---    ---    ---   ---   ---    ---   ---    ---   ---    ---    ---                  ---
0.0    0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   4.0    3.0    0.0   0.0    0.0    0.0    0.0   0.0   0.0    5.0   78.0   0.0   0.0    0.0    0.15217391304347827  14 / 92
6.0    3.0    0.0   0.0    17.0  1.0   0.0   4.0   5.0   2.0   5.0   0.0   0.0    0.0    1.0   0.0    1.0    1.0    13.0  6.0   0.0    0.0   0.0    26.0  3.0    6.0    0.74                 74 / 100
0.0    0.0    0.0   3.0    0.0   3.0   1.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0    2.0   0.0    4.0    0.0    0.0   15.0  0.0    12.0  0.0    0.0   65.0   0.0    0.3925233644859813   42 / 107
0.0    1.0    0.0   2.0    2.0   3.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0    1.0   0.0    1.0    1.0    8.0   2.0   0.0    0.0   0.0    1.0   0.0    64.0   0.26436781609195403  23 / 87
114.0  118.0  77.0  121.0  85.0  82.0  71.0  57.0  82.0  99.0  80.0  93.0  103.0  105.0  61.0  109.0  107.0  147.0  95.0  79.0  101.0  85.0  128.0  58.0  127.0  106.0  0.3887550200803213   968 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.611245
2    0.757831
3    0.831727
4    0.867871
5    0.895582
6    0.918875
7    0.931325
8    0.945783
9    0.953414
10   0.960241
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:45  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:45  1 min 34.329 sec  181945 obs/sec    1         1             10007      0.744229         1.67641             0.990159       0.460562                         0.743683           1.67694               0.990145         0.459839
    2019-07-24 14:07:46  1 min 34.808 sec  192442 obs/sec    10        10            100070     0.686851         1.40451             0.991618       0.391083                         0.686165           1.40234               0.991611         0.388755
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C9          1                      1                    0.0899706
C13         0.987967               0.987967             0.088888
C15         0.947828               0.947828             0.0852767
C12         0.927623               0.927623             0.0834588
C11         0.836226               0.836226             0.0752357
C14         0.835544               0.835544             0.0751744
C7          0.801187               0.801187             0.0720832
C8          0.741244               0.741244             0.0666902
C10         0.722215               0.722215             0.0649781
C6          0.613693               0.613693             0.0552143
C16         0.607706               0.607706             0.0546757
C3          0.527648               0.527648             0.0474728
C5          0.450242               0.450242             0.0405086
C4          0.414652               0.414652             0.0373064
C1          0.410965               0.410965             0.0369748
C2          0.290001               0.290001             0.0260916
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_22

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms          mean_bias             bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  ------------------  --------------------  ------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.00112920918081727    0.000313169090077281    0.0         0.07676387563697062   2.119868278503418   -0.41424399720962063  1.2356271743774414
    3        26       Softmax                 0.0   0.0   0.0016674133281552573  0.00010364700574427843  0.0         0.010527013276189861  0.5061395168304443  -0.5974172660159952   0.3856625556945801


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.47882647128905736
RMSE: 0.6919728833480814
LogLoss: 1.432041529997054
Mean Per-Class Error: 0.39193944452158813
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
335.0  0.0    0.0    4.0    0.0    0.0    0.0    3.0    0.0    4.0    3.0    2.0    7.0    2.0    0.0    0.0    2.0    10.0   2.0    0.0    3.0    0.0    3.0    5.0    8.0    2.0    0.1518987341772152   60 / 395
1.0    247.0  0.0    16.0   0.0    0.0    5.0    9.0    4.0    21.0   2.0    0.0    7.0    0.0    0.0    2.0    7.0    45.0   12.0   0.0    0.0    1.0    0.0    0.0    2.0    2.0    0.35509138381201044  136 / 383
0.0    3.0    235.0  0.0    29.0   3.0    39.0   0.0    3.0    0.0    16.0   0.0    7.0    0.0    1.0    2.0    10.0   0.0    8.0    5.0    4.0    0.0    3.0    0.0    0.0    0.0    0.36141304347826086  133 / 368
4.0    11.0   0.0    243.0  0.0    4.0    0.0    4.0    0.0    37.0   0.0    0.0    14.0   0.0    22.0   8.0    0.0    29.0   5.0    0.0    1.0    0.0    0.0    14.0   0.0    7.0    0.3970223325062035   160 / 403
0.0    24.0   10.0   0.0    209.0  6.0    31.0   1.0    8.0    2.0    4.0    0.0    0.0    0.0    0.0    0.0    18.0   5.0    8.0    4.0    0.0    0.0    0.0    11.0   0.0    43.0   0.4557291666666667   175 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    2.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    2.0    0.0    31.0   17.0   0.0    0.0    1.0    2.0    0.0    0.0    0.0    36.0   284.0  0.0    0.0    0.0    0.24468085106382978  92 / 376
37.0   19.0   0.0    6.0    22.0   0.0    2.0    3.0    15.0   21.0   3.0    2.0    0.0    0.0    16.0   0.0    6.0    2.0    16.0   26.0   3.0    0.0    0.0    135.0  2.0    58.0   0.6573604060913706   259 / 394
0.0    1.0    0.0    0.0    0.0    5.0    0.0    3.0    0.0    0.0    0.0    0.0    2.0    4.0    0.0    6.0    12.0   0.0    6.0    106.0  0.0    86.0   2.0    0.0    160.0  0.0    0.5928753180661578   233 / 393
0.0    8.0    0.0    2.0    13.0   1.0    0.0    0.0    3.0    1.0    0.0    1.0    0.0    0.0    0.0    5.0    0.0    7.0    45.0   4.0    0.0    0.0    0.0    9.0    1.0    267.0  0.2724795640326976   100 / 367
439.0  567.0  359.0  409.0  333.0  305.0  375.0  106.0  343.0  407.0  249.0  326.0  616.0  410.0  369.0  423.0  362.0  483.0  281.0  483.0  414.0  431.0  453.0  286.0  280.0  494.0  0.3903828851344597   3,905 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.609617
2    0.762871
3    0.828152
4    0.86554
5    0.892732
6    0.912826
7    0.930321
8    0.942617
9    0.952114
10   0.959612

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.476255304034963
RMSE: 0.690112529979686
LogLoss: 1.4297408811190933
Mean Per-Class Error: 0.39772160072820956
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0     1      2     3      4     5     6     7     8     9      10    11    12     13     14    15     16     17     18    19     20     21    22     23    24    25     Error                Rate
----  -----  ----  -----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  ----  -----  -----  -----  ----  -----  -----  ----  -----  ----  ----  -----  -------------------  -----------
75.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    0.0   1.0   1.0    0.0    0.0   0.0    0.0    4.0    0.0   0.0    0.0    0.0   1.0    2.0   4.0   1.0    0.15730337078651685  14 / 89
1.0   60.0   0.0   3.0    0.0   0.0   4.0   5.0   2.0   5.0    0.0   0.0   1.0    0.0    0.0   0.0    4.0    17.0   2.0   0.0    0.0    1.0   0.0    0.0   0.0   1.0    0.4339622641509434   46 / 106
0.0   1.0    48.0  0.0    6.0   0.0   9.0   0.0   1.0   0.0    3.0   0.0   0.0    0.0    1.0   1.0    4.0    0.0    4.0   2.0    1.0    0.0   1.0    0.0   0.0   0.0    0.4146341463414634   34 / 82
1.0   4.0    0.0   76.0   0.0   1.0   0.0   1.0   0.0   6.0    0.0   0.0   5.0    0.0    6.0   1.0    0.0    7.0    1.0   0.0    0.0    0.0   0.0    1.0   0.0   2.0    0.32142857142857145  36 / 112
0.0   8.0    3.0   0.0    54.0  3.0   7.0   0.0   1.0   1.0    1.0   0.0   0.0    0.0    0.0   0.0    3.0    1.0    0.0   0.0    0.0    0.0   0.0    5.0   0.0   10.0   0.44329896907216493  43 / 97
---   ---    ---   ---    ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---   ---    ---    ---    ---   ---    ---    ---   ---    ---   ---   ---    ---                  ---
0.0   0.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0    1.0   0.0   6.0    4.0    0.0   0.0    1.0    0.0    0.0   0.0    0.0    6.0   74.0   0.0   0.0   0.0    0.1956521739130435   18 / 92
7.0   3.0    0.0   3.0    8.0   0.0   0.0   3.0   3.0   3.0    0.0   1.0   0.0    0.0    3.0   0.0    1.0    0.0    3.0   8.0    2.0    0.0   0.0    31.0  1.0   20.0   0.69                 69 / 100
0.0   0.0    0.0   0.0    0.0   1.0   0.0   2.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0   4.0    5.0    0.0    1.0   23.0   0.0    24.0  1.0    0.0   45.0  0.0    0.5794392523364486   62 / 107
0.0   0.0    0.0   1.0    5.0   1.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0    0.0   2.0    0.0    0.0    9.0   2.0    0.0    0.0   0.0    5.0   1.0   61.0   0.2988505747126437   26 / 87
99.0  136.0  76.0  126.0  86.0  62.0  90.0  32.0  72.0  105.0  58.0  88.0  139.0  105.0  77.0  126.0  102.0  126.0  68.0  118.0  106.0  96.0  116.0  75.0  80.0  126.0  0.39477911646586344  983 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.605221
2    0.757028
3    0.824096
4    0.861446
5    0.885944
6    0.906426
7    0.926506
8    0.938956
9    0.950201
10   0.959438
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:50  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:51  39.834 sec  164049 obs/sec    1         1             10007      0.75476          1.71445             0.989878       0.481556                         0.752467           1.70857               0.989911         0.473494
    2019-07-24 14:06:51  40.418 sec  158841 obs/sec    10        10            100070     0.691973         1.43204             0.991492       0.390383                         0.690113           1.42974               0.991514         0.394779
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C13         1                      1                    0.089294
C15         0.974345               0.974345             0.0870031
C12         0.880398               0.880398             0.0786142
C7          0.868708               0.868708             0.0775703
C9          0.864537               0.864537             0.077198
C11         0.853989               0.853989             0.076256
C14         0.770461               0.770461             0.0687975
C8          0.764564               0.764564             0.0682709
C10         0.646077               0.646077             0.0576907
C16         0.597081               0.597081             0.0533157
C3          0.589373               0.589373             0.0526275
C6          0.555801               0.555801             0.0496297
C5          0.488765               0.488765             0.0436438
C1          0.473778               0.473778             0.0423055
C4          0.461767               0.461767             0.041233
C2          0.409322               0.409322             0.03655
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_19

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms          mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  ------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.001124110130945155   0.0002952816430479288  0.0         -0.25067555995201474  2.0352230072021484  -0.1354173316259134  1.0084857940673828
    3        26       Softmax                 0.0   0.0   0.0016671102759853685  9.244985994882882e-05  0.0         -0.03683161141984433  0.5061538219451904  -0.5968545256789606  0.38985729217529297


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.4919959789958015
RMSE: 0.7014242503619343
LogLoss: 1.4642692959631531
Mean Per-Class Error: 0.40934389445008323
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
339.0  0.0    0.0    9.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    6.0    14.0   1.0    4.0    0.0    1.0    6.0    0.0    0.0    1.0    3.0    2.0    0.0    6.0    0.0    0.13959390862944163  55 / 394
2.0    161.0  0.0    5.0    10.0   1.0    3.0    6.0    11.0   0.0    2.0    0.0    3.0    0.0    6.0    7.0    10.0   67.0   70.0   1.0    1.0    2.0    1.0    0.0    0.0    14.0   0.5796344647519582   222 / 383
0.0    0.0    223.0  0.0    46.0   0.0    46.0   0.0    0.0    0.0    21.0   0.0    7.0    0.0    0.0    4.0    2.0    2.0    5.0    6.0    1.0    0.0    1.0    0.0    0.0    4.0    0.39402173913043476  145 / 368
3.0    18.0   0.0    257.0  0.0    1.0    2.0    5.0    4.0    6.0    0.0    5.0    3.0    13.0   22.0   13.0   2.0    29.0   2.0    3.0    3.0    0.0    0.0    7.0    1.0    4.0    0.36228287841191065  146 / 403
0.0    8.0    40.0   0.0    172.0  1.0    51.0   0.0    18.0   0.0    2.0    0.0    0.0    0.0    0.0    0.0    8.0    10.0   13.0   2.0    4.0    2.0    0.0    18.0   0.0    35.0   0.5520833333333334   212 / 384
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    1.0    0.0    0.0    0.0    0.0    0.0    12.0   0.0    0.0    0.0    0.0    12.0   6.0    0.0    0.0    0.0    14.0   0.0    0.0    0.0    17.0   313.0  0.0    1.0    0.0    0.1675531914893617   63 / 376
15.0   3.0    20.0   9.0    23.0   4.0    9.0    1.0    27.0   2.0    5.0    18.0   0.0    0.0    3.0    0.0    25.0   4.0    21.0   12.0   5.0    0.0    0.0    129.0  3.0    56.0   0.6725888324873096   265 / 394
0.0    1.0    1.0    3.0    1.0    16.0   1.0    5.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    11.0   10.0   0.0    5.0    59.0   6.0    91.0   6.0    0.0    176.0  0.0    0.5521628498727735   217 / 393
1.0    12.0   1.0    5.0    28.0   3.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    8.0    1.0    29.0   4.0    0.0    0.0    0.0    5.0    0.0    266.0  0.27520435967302453  101 / 367
437.0  335.0  404.0  434.0  408.0  330.0  439.0  165.0  382.0  306.0  272.0  326.0  433.0  377.0  378.0  437.0  370.0  604.0  353.0  449.0  381.0  469.0  472.0  237.0  284.0  521.0  0.4078776367089873   4,080 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.592122
2    0.741378
3    0.814256
4    0.856643
5    0.882335
6    0.904429
7    0.922023
8    0.938319
9    0.949015
10   0.958712

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.4928067572589065
RMSE: 0.7020019638568731
LogLoss: 1.4580971543143912
Mean Per-Class Error: 0.4171933587903067
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1     2     3      4     5     6      7     8     9     10    11    12    13    14    15     16     17     18    19     20    21     22     23    24    25     Error                Rate
-----  ----  ----  -----  ----  ----  -----  ----  ----  ----  ----  ----  ----  ----  ----  -----  -----  -----  ----  -----  ----  -----  -----  ----  ----  -----  -------------------  -------------
76.0   0.0   0.0   1.0    0.0   0.0   0.0    0.0   0.0   0.0   0.0   1.0   3.0   0.0   0.0   0.0    0.0    3.0    0.0   0.0    0.0   1.0    2.0    0.0   2.0   0.0    0.14606741573033707  13 / 89
1.0    35.0  0.0   0.0    1.0   0.0   1.0    3.0   4.0   0.0   1.0   0.0   1.0   0.0   1.0   2.0    9.0    22.0   19.0  0.0    0.0   0.0    1.0    0.0   0.0   5.0    0.6698113207547169   71 / 106
0.0    0.0   46.0  0.0    11.0  0.0   11.0   0.0   0.0   0.0   5.0   0.0   0.0   0.0   0.0   3.0    1.0    1.0    0.0   2.0    0.0   0.0    1.0    0.0   0.0   1.0    0.43902439024390244  36 / 82
1.0    5.0   0.0   78.0   0.0   0.0   1.0    3.0   0.0   1.0   0.0   2.0   1.0   3.0   8.0   3.0    0.0    3.0    0.0   0.0    1.0   0.0    0.0    1.0   0.0   1.0    0.30357142857142855  34 / 112
0.0    1.0   13.0  0.0    43.0  1.0   12.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    3.0    3.0    4.0   1.0    1.0   0.0    0.0    4.0   0.0   8.0    0.5567010309278351   54 / 97
---    ---   ---   ---    ---   ---   ---    ---   ---   ---   ---   ---   ---   ---   ---   ---    ---    ---    ---   ---    ---   ---    ---    ---   ---   ---    ---                  ---
0.0    0.0   0.0   0.0    0.0   0.0   0.0    2.0   0.0   0.0   0.0   0.0   4.0   3.0   0.0   0.0    0.0    2.0    0.0   0.0    0.0   3.0    77.0   0.0   1.0   0.0    0.16304347826086957  15 / 92
4.0    2.0   5.0   1.0    6.0   1.0   0.0    1.0   7.0   1.0   3.0   3.0   0.0   0.0   0.0   0.0    4.0    1.0    5.0   1.0    2.0   0.0    0.0    42.0  2.0   9.0    0.58                 58 / 100
0.0    1.0   1.0   1.0    0.0   4.0   0.0    3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0    5.0    0.0    0.0   15.0   2.0   26.0   2.0    0.0   43.0  0.0    0.5981308411214953   64 / 107
0.0    1.0   0.0   2.0    8.0   1.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    2.0    0.0    6.0   1.0    0.0   0.0    0.0    1.0   0.0   63.0   0.27586206896551724  24 / 87
105.0  74.0  89.0  135.0  91.0  73.0  100.0  45.0  90.0  81.0  73.0  87.0  98.0  89.0  79.0  127.0  106.0  150.0  92.0  109.0  99.0  108.0  128.0  68.0  70.0  124.0  0.41606425702811245  1,036 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.583936
2    0.745783
3    0.820482
4    0.861446
5    0.88755
6    0.908835
7    0.927309
8    0.944578
9    0.954618
10   0.964659
Scoring History: 
    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:06:46  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:06:46  34.997 sec  166783 obs/sec    1         1             10007      0.759952         1.72468             0.989736       0.482855                         0.757155           1.70815               0.989785         0.473494
    2019-07-24 14:06:46  35.567 sec  163513 obs/sec    10        10            100070     0.701424         1.46427             0.991256       0.407878                         0.702002           1.4581                0.991219         0.416064
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0959261
C12         0.926594               0.926594             0.0888845
C13         0.915195               0.915195             0.0877911
C9          0.862576               0.862576             0.0827435
C11         0.753582               0.753582             0.0722882
C7          0.727322               0.727322             0.0697691
C8          0.706618               0.706618             0.0677831
C14         0.656                  0.656                0.0629276
C10         0.623407               0.623407             0.059801
C16         0.564973               0.564973             0.0541957
C6          0.543861               0.543861             0.0521705
C3          0.495981               0.495981             0.0475775
C5          0.490898               0.490898             0.0470899
C1          0.403874               0.403874             0.0387421
C4          0.387297               0.387297             0.0371519
C2          0.366512               0.366512             0.0351581
Model Details
=============
H2ODeepLearningEstimator :  Deep Learning
Model Key:  DL_random_grid_model_59

Status of Neuron Layers: predicting C17, 26-class classification, multinomial distribution, CrossEntropy loss, 1,402 weights/biases, 21.9 KB, 100,070 training samples, mini-batch size 1

    layer    units    type         dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight           weight_rms           mean_bias            bias_rms
--  -------  -------  -----------  ---------  ----  ----  ---------------------  ----------------------  ----------  --------------------  -------------------  -------------------  -------------------
    1        16       Input        0.0
    2        32       TanhDropout  50.0       0.0   0.0   0.0011791950704491683  0.0003382085124030709   0.0         -0.0649922538032115   2.166304588317871    0.13805129361021212  1.0477800369262695
    3        26       Softmax                 0.0   0.0   0.0016735901664595497  0.00010367089998908341  0.0         0.018255307340653486  0.49172890186309814  -0.5876729161598203  0.37770557403564453


ModelMetricsMultinomial: deeplearning
** Reported on train data. **

MSE: 0.5160705147979565
RMSE: 0.7183804805240441
LogLoss: 1.5275293555204437
Mean Per-Class Error: 0.44445492201995446
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19     20     21     22     23     24     25     Error                Rate
-----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------------------  --------------
342.0  2.0    0.0    7.0    0.0    0.0    0.0    0.0    0.0    2.0    2.0    7.0    9.0    1.0    2.0    0.0    0.0    6.0    2.0    0.0    4.0    2.0    5.0    0.0    2.0    0.0    0.1341772151898734   53 / 395
1.0    213.0  0.0    9.0    8.0    1.0    2.0    11.0   0.0    21.0   1.0    0.0    8.0    1.0    3.0    7.0    9.0    27.0   52.0   0.0    1.0    0.0    2.0    1.0    4.0    1.0    0.44386422976501305  170 / 383
0.0    0.0    247.0  0.0    24.0   6.0    17.0   3.0    0.0    0.0    34.0   0.0    1.0    1.0    1.0    0.0    2.0    0.0    3.0    6.0    11.0   0.0    1.0    0.0    0.0    11.0   0.328804347826087    121 / 368
5.0    37.0   0.0    230.0  0.0    2.0    0.0    8.0    1.0    26.0   0.0    1.0    5.0    5.0    17.0   15.0   0.0    34.0   2.0    1.0    3.0    0.0    1.0    9.0    1.0    0.0    0.4292803970223325   173 / 403
0.0    9.0    26.0   0.0    186.0  1.0    18.0   1.0    27.0   1.0    9.0    0.0    1.0    0.0    0.0    0.0    18.0   5.0    31.0   20.0   0.0    0.0    0.0    5.0    1.0    24.0   0.5143603133159269   197 / 383
---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---    ---                  ---
0.0    0.0    0.0    0.0    0.0    0.0    0.0    5.0    0.0    0.0    1.0    0.0    50.0   10.0   0.0    0.0    0.0    0.0    0.0    0.0    2.0    32.0   275.0  0.0    0.0    0.0    0.26666666666666666  100 / 375
24.0   17.0   1.0    2.0    50.0   2.0    0.0    0.0    31.0   10.0   3.0    7.0    0.0    0.0    12.0   0.0    31.0   7.0    29.0   48.0   1.0    0.0    0.0    80.0   4.0    35.0   0.7969543147208121   314 / 394
0.0    0.0    0.0    2.0    0.0    12.0   0.0    2.0    0.0    0.0    1.0    0.0    3.0    1.0    0.0    10.0   14.0   0.0    3.0    117.0  0.0    112.0  8.0    1.0    106.0  1.0    0.7302798982188295   287 / 393
0.0    14.0   0.0    3.0    57.0   4.0    0.0    0.0    15.0   4.0    3.0    0.0    0.0    0.0    0.0    2.0    1.0    2.0    45.0   9.0    0.0    0.0    0.0    8.0    0.0    200.0  0.4550408719346049   167 / 367
457.0  575.0  394.0  356.0  442.0  371.0  288.0  196.0  430.0  378.0  252.0  329.0  635.0  264.0  319.0  452.0  416.0  453.0  356.0  524.0  475.0  442.0  434.0  186.0  232.0  347.0  0.442667199840048    4,428 / 10,003

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.557333
2    0.714586
3    0.803659
4    0.853344
5    0.887634
6    0.905728
7    0.920824
8    0.93532
9    0.946816
10   0.956013

ModelMetricsMultinomial: deeplearning
** Reported on validation data. **

MSE: 0.5140861990606
RMSE: 0.7169980467620536
LogLoss: 1.5196261423086912
Mean Per-Class Error: 0.44510667285654476
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class

0      1      2     3      4      5     6     7     8     9     10    11    12     13    14    15     16     17     18    19     20     21     22     23    24    25    Error                Rate
-----  -----  ----  -----  -----  ----  ----  ----  ----  ----  ----  ----  -----  ----  ----  -----  -----  -----  ----  -----  -----  -----  -----  ----  ----  ----  -------------------  -------------
79.0   1.0    0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    0.0   0.0   0.0    0.0    1.0    1.0   0.0    0.0    1.0    3.0    0.0   1.0   0.0   0.11235955056179775  10 / 89
1.0    52.0   0.0   1.0    0.0    1.0   1.0   2.0   0.0   8.0   1.0   0.0   4.0    1.0   2.0   2.0    4.0    9.0    14.0  0.0    0.0    0.0    1.0    1.0   1.0   0.0   0.5094339622641509   54 / 106
0.0    0.0    54.0  0.0    1.0    0.0   6.0   1.0   0.0   0.0   8.0   0.0   0.0    0.0   1.0   0.0    1.0    0.0    0.0   3.0    1.0    0.0    1.0    0.0   0.0   5.0   0.34146341463414637  28 / 82
2.0    12.0   0.0   68.0   0.0    1.0   0.0   1.0   0.0   3.0   0.0   1.0   2.0    1.0   5.0   5.0    0.0    8.0    1.0   0.0    1.0    0.0    0.0    1.0   0.0   0.0   0.39285714285714285  44 / 112
0.0    1.0    10.0  0.0    44.0   1.0   5.0   0.0   5.0   0.0   3.0   0.0   0.0    0.0   0.0   0.0    5.0    2.0    7.0   6.0    0.0    0.0    0.0    2.0   0.0   6.0   0.5463917525773195   53 / 97
---    ---    ---   ---    ---    ---   ---   ---   ---   ---   ---   ---   ---    ---   ---   ---    ---    ---    ---   ---    ---    ---    ---    ---   ---   ---   ---                  ---
0.0    0.0    0.0   0.0    0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0   10.0   1.0   0.0   0.0    0.0    0.0    0.0   0.0    1.0    7.0    72.0   0.0   0.0   0.0   0.21739130434782608  20 / 92
4.0    3.0    0.0   2.0    16.0   1.0   0.0   0.0   7.0   1.0   1.0   2.0   0.0    0.0   1.0   0.0    6.0    3.0    8.0   12.0   1.0    0.0    0.0    23.0  1.0   8.0   0.77                 77 / 100
0.0    0.0    0.0   0.0    0.0    3.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0    1.0   0.0   4.0    6.0    0.0    0.0   25.0   0.0    37.0   3.0    0.0   25.0  0.0   0.7663551401869159   82 / 107
0.0    5.0    0.0   1.0    18.0   1.0   0.0   0.0   3.0   0.0   1.0   0.0   0.0    0.0   0.0   1.0    0.0    0.0    15.0  3.0    0.0    0.0    0.0    2.0   0.0   37.0  0.5747126436781609   50 / 87
107.0  142.0  90.0  105.0  113.0  82.0  69.0  54.0  96.0  97.0  69.0  89.0  142.0  60.0  65.0  127.0  107.0  121.0  99.0  126.0  115.0  111.0  121.0  51.0  60.0  72.0  0.44497991967871486  1,108 / 2,490

See the whole table with table.as_data_frame()
Top-10 Hit Ratios: 
k    hit_ratio
---  -----------
1    0.55502
2    0.717269
3    0.810843
4    0.85502
5    0.892771
6    0.905622
7    0.921687
8    0.935341
9    0.948594
10   0.956627
Scoring History: 
    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_classification_error
--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  -----------------  --------------------  ---------------  ---------------------------------
    2019-07-24 14:07:44  0.000 sec                           0         0             0          nan              nan                 nan            nan                              nan                nan                   nan              nan
    2019-07-24 14:07:44  1 min 33.759 sec  175561 obs/sec    1         1             10007      0.77188          1.80634             0.989412       0.527642                         0.771622           1.79491               0.989391         0.528112
    2019-07-24 14:07:45  1 min 34.238 sec  191704 obs/sec    10        10            100070     0.71838          1.52753             0.990829       0.442667                         0.716998           1.51963               0.99084          0.44498
Variable Importances: 
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  ------------
C15         1                      1                    0.0913765
C12         0.947474               0.947474             0.0865768
C9          0.924653               0.924653             0.0844916
C13         0.906982               0.906982             0.0828769
C11         0.857549               0.857549             0.0783599
C7          0.79953                0.79953              0.0730583
C14         0.779076               0.779076             0.0711892
C10         0.683999               0.683999             0.0625014
C8          0.671309               0.671309             0.0613419
C16         0.572721               0.572721             0.0523332
C6          0.535848               0.535848             0.0489639
C3          0.521258               0.521258             0.0476307
C5          0.456063               0.456063             0.0416734
C1          0.452984               0.452984             0.0413921
C4          0.418794               0.418794             0.0382679
C2          0.415493               0.415493             0.0379663
[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ]
                 activation  ...                model_ids              logloss
0      RectifierWithDropout  ...  DL_random_grid_model_41  0.36791690260813303
1      RectifierWithDropout  ...   DL_random_grid_model_4  0.38365641275353224
2      RectifierWithDropout  ...  DL_random_grid_model_17   0.3838742545538186
3      RectifierWithDropout  ...  DL_random_grid_model_21  0.38426092352816027
4      RectifierWithDropout  ...  DL_random_grid_model_26  0.43136570398013513
5           TanhWithDropout  ...  DL_random_grid_model_13  0.43293783322843415
6      RectifierWithDropout  ...   DL_random_grid_model_1   0.4380809162085678
7      RectifierWithDropout  ...  DL_random_grid_model_49  0.44244872248688294
8      RectifierWithDropout  ...  DL_random_grid_model_70  0.45190218097940776
9      RectifierWithDropout  ...  DL_random_grid_model_27  0.45858436469774183
10     RectifierWithDropout  ...  DL_random_grid_model_33  0.46036548904583335
11     RectifierWithDropout  ...  DL_random_grid_model_29    0.462440378107918
12          TanhWithDropout  ...  DL_random_grid_model_25  0.46447969672298445
13          TanhWithDropout  ...  DL_random_grid_model_24   0.4824550719430528
14          TanhWithDropout  ...  DL_random_grid_model_51  0.48957418078915466
15          TanhWithDropout  ...  DL_random_grid_model_45   0.5060255286901109
16          TanhWithDropout  ...  DL_random_grid_model_77   0.5116003870038963
17     RectifierWithDropout  ...  DL_random_grid_model_28   0.5235758340894358
18     RectifierWithDropout  ...  DL_random_grid_model_11   0.5321941225185999
19          TanhWithDropout  ...  DL_random_grid_model_16   0.5550230129676826
20          TanhWithDropout  ...  DL_random_grid_model_55   0.5596959661020128
21     RectifierWithDropout  ...  DL_random_grid_model_66   0.5601947049540118
22          TanhWithDropout  ...   DL_random_grid_model_7   0.5661978368565771
23          TanhWithDropout  ...  DL_random_grid_model_10   0.5731047740635555
24     RectifierWithDropout  ...   DL_random_grid_model_9   0.5753192832669145
25     RectifierWithDropout  ...  DL_random_grid_model_74   0.5803105919011736
26     RectifierWithDropout  ...  DL_random_grid_model_73    0.583302044743455
27          TanhWithDropout  ...  DL_random_grid_model_61    0.584054697892087
28     RectifierWithDropout  ...  DL_random_grid_model_48   0.5902465690017524
29          TanhWithDropout  ...  DL_random_grid_model_38   0.5912952108749503
.. ..                   ...  ...                      ...                  ...
48          TanhWithDropout  ...  DL_random_grid_model_72    0.744336616249661
49          TanhWithDropout  ...  DL_random_grid_model_39   0.7479332064680267
50          TanhWithDropout  ...  DL_random_grid_model_18   0.7479535708868551
51          TanhWithDropout  ...  DL_random_grid_model_46    0.750021825024201
52          TanhWithDropout  ...  DL_random_grid_model_12    0.751239927491444
53          TanhWithDropout  ...  DL_random_grid_model_37   0.7548544581204413
54          TanhWithDropout  ...  DL_random_grid_model_47   0.7599364400672126
55     RectifierWithDropout  ...  DL_random_grid_model_63   0.7615855281285917
56          TanhWithDropout  ...  DL_random_grid_model_53   0.7674094893962412
57          TanhWithDropout  ...  DL_random_grid_model_30   0.7700299254514598
58          TanhWithDropout  ...   DL_random_grid_model_8   0.7743365436824863
59          TanhWithDropout  ...  DL_random_grid_model_57   0.7800664464377595
60     RectifierWithDropout  ...  DL_random_grid_model_54   0.8210004931725702
61     RectifierWithDropout  ...  DL_random_grid_model_64   0.8593714432305715
62     RectifierWithDropout  ...  DL_random_grid_model_40   0.8602636191203691
63     RectifierWithDropout  ...  DL_random_grid_model_43    0.874911588066789
64     RectifierWithDropout  ...  DL_random_grid_model_78    0.910590359807663
65          TanhWithDropout  ...  DL_random_grid_model_15   0.9698413227088473
66          TanhWithDropout  ...  DL_random_grid_model_65    1.004129925832914
67          TanhWithDropout  ...  DL_random_grid_model_42   1.0169489471456439
68          TanhWithDropout  ...  DL_random_grid_model_35   1.0294196317167335
69          TanhWithDropout  ...  DL_random_grid_model_71   1.0736698928023571
70          TanhWithDropout  ...   DL_random_grid_model_6   1.0841083880360163
71     RectifierWithDropout  ...  DL_random_grid_model_14   1.0922626078323237
72     RectifierWithDropout  ...  DL_random_grid_model_62   1.1115407487229036
73     RectifierWithDropout  ...  DL_random_grid_model_23   1.1153187395899737
74          TanhWithDropout  ...  DL_random_grid_model_60   1.4023380941020622
75          TanhWithDropout  ...  DL_random_grid_model_22   1.4297408811190933
76          TanhWithDropout  ...  DL_random_grid_model_19   1.4580971543143912
77          TanhWithDropout  ...  DL_random_grid_model_59   1.5196261423086912

[78 rows x 7 columns]

--- 123.77845287322998 seconds ---
Evalutation of best performing model:
Final acc, selected model:  87.02091464024817
Time consumed:  0.03441793223222097  hours
H2O session _sid_a84a closed.
