Leyendo  mnist
Executing  mnist with  Convolutional  arquitecture.

>>> Imports:
#coding=utf-8

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.datasets import fashion_mnist
except:
    pass

try:
    from keras.datasets import cifar10
except:
    pass

try:
    from keras.datasets import imdb
except:
    pass

try:
    from keras import backend as K
except:
    pass

try:
    import numpy as np
except:
    pass

try:
    import sys
except:
    pass

try:
    import time
except:
    pass

try:
    import urllib.request
except:
    pass

try:
    import os
except:
    pass

try:
    from sklearn.model_selection import StratifiedKFold
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation, Flatten
except:
    pass

try:
    from keras.layers.convolutional import Convolution2D, MaxPooling2D
except:
    pass

try:
    from keras.optimizers import SGD, Adam
except:
    pass

try:
    from keras.models import Sequential
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'Dropout': hp.uniform('Dropout', 0, 0.5),
        'Dropout_1': hp.uniform('Dropout_1', 0, 0.5),
        'Dropout_2': hp.choice('Dropout_2', ['two','three']),
        'Dropout_3': hp.uniform('Dropout_3', 0, 0.5),
        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),
        'batch_size': hp.choice('batch_size', [64, 128]),
    }

>>> Data
  1: 
  2: (X_train, y_train), (X_test, y_test) = mnist.load_data()
  3: 
  4: X_train = X_train.reshape(X_train.shape+(1,))
  5: X_test = X_test.reshape(X_test.shape+(1,))
  6: 
  7: nb_classes = len(np.unique(y_train))
  8: y_train = np_utils.to_categorical(y_train, nb_classes)
  9: y_test = np_utils.to_categorical(y_test, nb_classes)
 10: 
 11: 
 12: 
 13: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3: 	nb_classes = y_train.shape[1]
   4: 
   5: 	num_epoch=1*100
   6: 	num_epoch=1*1
   7: 
   8: 	model = Sequential()
   9: 
  10: 	model.add(Convolution2D(32, 3, 3, border_mode='same',
  11: 	                        input_shape=X_train.shape[1:]))
  12: 	model.add(Activation('relu'))
  13: 	model.add(Convolution2D(32, 3, 3))
  14: 	model.add(Activation('relu'))
  15: 	model.add(MaxPooling2D(pool_size=(2, 2)))
  16: 	model.add(Dropout(space['Dropout']))
  17: 
  18: 	model.add(Convolution2D(64, 3, 3, border_mode='same'))
  19: 	model.add(Activation('relu'))
  20: 	model.add(Convolution2D(64, 3, 3))
  21: 	model.add(Activation('relu'))
  22: 	model.add(MaxPooling2D(pool_size=(2, 2)))
  23: 	model.add(Dropout(space['Dropout_1']))
  24: 
  25: 	if space['Dropout_2'] == 'three':
  26: 		model.add(Convolution2D(128, 3, 3, border_mode='same'))
  27: 		model.add(Activation('relu'))
  28: 		model.add(Convolution2D(128, 3, 3))
  29: 		model.add(Activation('relu'))
  30: 		model.add(MaxPooling2D(pool_size=(2, 2)))
  31: 		model.add(Dropout(space['Dropout_3']))
  32: 
  33: 	model.add(Flatten())
  34: 	model.add(Dense(512))
  35: 	model.add(Activation('relu'))
  36: 	model.add(Dropout(0.5))
  37: 	model.add(Dense(nb_classes))
  38: 	model.add(Activation('softmax'))
  39: 
  40: 	 # let's train the model using SGD + momentum (how original).
  41: 	#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
  42: 	
  43: 	model.compile(loss='categorical_crossentropy',
  44: 	              optimizer=space['optimizer'],
  45: 	              metrics=['accuracy'])
  46: 
  47: 	result = model.fit(X_train, y_train,
  48: 	          batch_size=space['batch_size'],
  49: 	          nb_epoch=num_epoch,
  50: 	          verbose=2,
  51: 	          validation_split=0.1)
  52: 	validation_acc = np.amax(result.history['val_acc']) 
  53: 	print('Best validation acc of epoch:', validation_acc)
  54: 	return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}
  55: 
Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz

    8192/11490434 [..............................] - ETA: 2:42
   40960/11490434 [..............................] - ETA: 1:05
  106496/11490434 [..............................] - ETA: 37s 
  245760/11490434 [..............................] - ETA: 21s
  417792/11490434 [>.............................] - ETA: 16s
  458752/11490434 [>.............................] - ETA: 17s
  860160/11490434 [=>............................] - ETA: 10s
  958464/11490434 [=>............................] - ETA: 10s
 1015808/11490434 [=>............................] - ETA: 11s
 1327104/11490434 [==>...........................] - ETA: 9s 
 1515520/11490434 [==>...........................] - ETA: 8s
 1556480/11490434 [===>..........................] - ETA: 8s
 1761280/11490434 [===>..........................] - ETA: 7s
 1974272/11490434 [====>.........................] - ETA: 7s
 1990656/11490434 [====>.........................] - ETA: 7s
 2195456/11490434 [====>.........................] - ETA: 6s
 2211840/11490434 [====>.........................] - ETA: 6s
 2424832/11490434 [=====>........................] - ETA: 6s
 2457600/11490434 [=====>........................] - ETA: 6s
 2686976/11490434 [======>.......................] - ETA: 6s
 2891776/11490434 [======>.......................] - ETA: 5s
 2924544/11490434 [======>.......................] - ETA: 5s
 3137536/11490434 [=======>......................] - ETA: 5s
 3170304/11490434 [=======>......................] - ETA: 5s
 3383296/11490434 [=======>......................] - ETA: 5s
 3432448/11490434 [=======>......................] - ETA: 5s
 3620864/11490434 [========>.....................] - ETA: 5s
 3678208/11490434 [========>.....................] - ETA: 5s
 3883008/11490434 [=========>....................] - ETA: 4s
 4005888/11490434 [=========>....................] - ETA: 4s
 4145152/11490434 [=========>....................] - ETA: 4s
 4341760/11490434 [==========>...................] - ETA: 4s
 4390912/11490434 [==========>...................] - ETA: 4s
 4562944/11490434 [==========>...................] - ETA: 4s
 4636672/11490434 [===========>..................] - ETA: 4s
 4792320/11490434 [===========>..................] - ETA: 4s
 4898816/11490434 [===========>..................] - ETA: 3s
 5054464/11490434 [============>.................] - ETA: 3s
 5136384/11490434 [============>.................] - ETA: 3s
 5259264/11490434 [============>.................] - ETA: 3s
 5398528/11490434 [=============>................] - ETA: 3s
 5521408/11490434 [=============>................] - ETA: 3s
 5660672/11490434 [=============>................] - ETA: 3s
 5783552/11490434 [==============>...............] - ETA: 3s
 5922816/11490434 [==============>...............] - ETA: 3s
 6078464/11490434 [==============>...............] - ETA: 3s
 6184960/11490434 [===============>..............] - ETA: 3s
 6340608/11490434 [===============>..............] - ETA: 2s
 6430720/11490434 [===============>..............] - ETA: 2s
 6545408/11490434 [================>.............] - ETA: 2s
 6684672/11490434 [================>.............] - ETA: 2s
 6807552/11490434 [================>.............] - ETA: 2s
 6946816/11490434 [=================>............] - ETA: 2s
 7069696/11490434 [=================>............] - ETA: 2s
 7208960/11490434 [=================>............] - ETA: 2s
 7331840/11490434 [==================>...........] - ETA: 2s
 7471104/11490434 [==================>...........] - ETA: 2s
 7593984/11490434 [==================>...........] - ETA: 2s
 7733248/11490434 [===================>..........] - ETA: 2s
 7856128/11490434 [===================>..........] - ETA: 2s
 7995392/11490434 [===================>..........] - ETA: 1s
 8101888/11490434 [====================>.........] - ETA: 1s
 8257536/11490434 [====================>.........] - ETA: 1s
 8355840/11490434 [====================>.........] - ETA: 1s
 8519680/11490434 [=====================>........] - ETA: 1s
 8617984/11490434 [=====================>........] - ETA: 1s
 8773632/11490434 [=====================>........] - ETA: 1s
 8880128/11490434 [======================>.......] - ETA: 1s
 9035776/11490434 [======================>.......] - ETA: 1s
 9142272/11490434 [======================>.......] - ETA: 1s
 9281536/11490434 [=======================>......] - ETA: 1s
 9371648/11490434 [=======================>......] - ETA: 1s
 9469952/11490434 [=======================>......] - ETA: 1s
 9633792/11490434 [========================>.....] - ETA: 0s
 9732096/11490434 [========================>.....] - ETA: 0s
 9887744/11490434 [========================>.....] - ETA: 0s
 9994240/11490434 [=========================>....] - ETA: 0s
10149888/11490434 [=========================>....] - ETA: 0s
10256384/11490434 [=========================>....] - ETA: 0s
10412032/11490434 [==========================>...] - ETA: 0s
10518528/11490434 [==========================>...] - ETA: 0s
10674176/11490434 [==========================>...] - ETA: 0s
10780672/11490434 [===========================>..] - ETA: 0s
10936320/11490434 [===========================>..] - ETA: 0s
11042816/11490434 [===========================>..] - ETA: 0s
11198464/11490434 [============================>.] - ETA: 0s
11304960/11490434 [============================>.] - ETA: 0s
11460608/11490434 [============================>.] - ETA: 0s
11493376/11490434 [==============================] - 6s 1us/step
  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]                                                    Train on 54000 samples, validate on 6000 samples
  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]                                                    Epoch 1/1
  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]                                                     - 48s - loss: 1.1763 - acc: 0.6055 - val_loss: 0.1160 - val_acc: 0.9683

  0%|          | 0/10 [00:49<?, ?it/s, best loss: ?]                                                    Best validation acc of epoch:
  0%|          | 0/10 [00:49<?, ?it/s, best loss: ?]                                                    0.9683333330154419
  0%|          | 0/10 [00:49<?, ?it/s, best loss: ?] 10%|█         | 1/10 [00:49<07:22, 49.15s/it, best loss: -0.9683333330154419]                                                                              Train on 54000 samples, validate on 6000 samples
 10%|█         | 1/10 [00:49<07:22, 49.15s/it, best loss: -0.9683333330154419]                                                                              Epoch 1/1
 10%|█         | 1/10 [00:49<07:22, 49.15s/it, best loss: -0.9683333330154419]                                                                               - 47s - loss: 14.5197 - acc: 0.0988 - val_loss: 14.5143 - val_acc: 0.0995

 10%|█         | 1/10 [01:37<07:22, 49.15s/it, best loss: -0.9683333330154419]                                                                              Best validation acc of epoch:
 10%|█         | 1/10 [01:37<07:22, 49.15s/it, best loss: -0.9683333330154419]                                                                              0.09949999998013179
 10%|█         | 1/10 [01:37<07:22, 49.15s/it, best loss: -0.9683333330154419] 20%|██        | 2/10 [01:37<06:30, 48.77s/it, best loss: -0.9683333330154419]                                                                              Train on 54000 samples, validate on 6000 samples
 20%|██        | 2/10 [01:37<06:30, 48.77s/it, best loss: -0.9683333330154419]                                                                              Epoch 1/1
 20%|██        | 2/10 [01:37<06:30, 48.77s/it, best loss: -0.9683333330154419]                                                                               - 49s - loss: 0.3113 - acc: 0.9058 - val_loss: 0.0377 - val_acc: 0.9890

 20%|██        | 2/10 [02:26<06:30, 48.77s/it, best loss: -0.9683333330154419]                                                                              Best validation acc of epoch:
 20%|██        | 2/10 [02:26<06:30, 48.77s/it, best loss: -0.9683333330154419]                                                                              0.989
 20%|██        | 2/10 [02:26<06:30, 48.77s/it, best loss: -0.9683333330154419] 30%|███       | 3/10 [02:26<05:43, 49.12s/it, best loss: -0.989]                                                                              Train on 54000 samples, validate on 6000 samples
 30%|███       | 3/10 [02:27<05:43, 49.12s/it, best loss: -0.989]                                                                 Epoch 1/1
 30%|███       | 3/10 [02:27<05:43, 49.12s/it, best loss: -0.989]                                                                  - 46s - loss: 3.3261 - acc: 0.6705 - val_loss: 0.0875 - val_acc: 0.9778

 30%|███       | 3/10 [03:13<05:43, 49.12s/it, best loss: -0.989]                                                                 Best validation acc of epoch:
 30%|███       | 3/10 [03:13<05:43, 49.12s/it, best loss: -0.989]                                                                 0.9778333330154418
 30%|███       | 3/10 [03:13<05:43, 49.12s/it, best loss: -0.989] 40%|████      | 4/10 [03:13<04:49, 48.30s/it, best loss: -0.989]                                                                 Train on 54000 samples, validate on 6000 samples
 40%|████      | 4/10 [03:13<04:49, 48.30s/it, best loss: -0.989]                                                                 Epoch 1/1
 40%|████      | 4/10 [03:13<04:49, 48.30s/it, best loss: -0.989]                                                                  - 48s - loss: 0.3600 - acc: 0.8942 - val_loss: 0.0456 - val_acc: 0.9875

 40%|████      | 4/10 [04:02<04:49, 48.30s/it, best loss: -0.989]                                                                 Best validation acc of epoch:
 40%|████      | 4/10 [04:02<04:49, 48.30s/it, best loss: -0.989]                                                                 0.9874999995231628
 40%|████      | 4/10 [04:02<04:49, 48.30s/it, best loss: -0.989] 50%|█████     | 5/10 [04:02<04:02, 48.43s/it, best loss: -0.989]                                                                 Train on 54000 samples, validate on 6000 samples
 50%|█████     | 5/10 [04:02<04:02, 48.43s/it, best loss: -0.989]                                                                 Epoch 1/1
 50%|█████     | 5/10 [04:02<04:02, 48.43s/it, best loss: -0.989]                                                                  - 45s - loss: 1.0525 - acc: 0.7705 - val_loss: 0.1181 - val_acc: 0.9652

 50%|█████     | 5/10 [04:47<04:02, 48.43s/it, best loss: -0.989]                                                                 Best validation acc of epoch:
 50%|█████     | 5/10 [04:47<04:02, 48.43s/it, best loss: -0.989]                                                                 0.9651666663487752
 50%|█████     | 5/10 [04:47<04:02, 48.43s/it, best loss: -0.989] 60%|██████    | 6/10 [04:47<03:09, 47.45s/it, best loss: -0.989]                                                                 Train on 54000 samples, validate on 6000 samples
 60%|██████    | 6/10 [04:47<03:09, 47.45s/it, best loss: -0.989]                                                                 Epoch 1/1
 60%|██████    | 6/10 [04:47<03:09, 47.45s/it, best loss: -0.989]                                                                  - 46s - loss: 14.2902 - acc: 0.1132 - val_loss: 14.4257 - val_acc: 0.1050

 60%|██████    | 6/10 [05:33<03:09, 47.45s/it, best loss: -0.989]                                                                 Best validation acc of epoch:
 60%|██████    | 6/10 [05:33<03:09, 47.45s/it, best loss: -0.989]                                                                 0.10500000003973643
 60%|██████    | 6/10 [05:33<03:09, 47.45s/it, best loss: -0.989] 70%|███████   | 7/10 [05:33<02:21, 47.10s/it, best loss: -0.989]                                                                 Train on 54000 samples, validate on 6000 samples
 70%|███████   | 7/10 [05:33<02:21, 47.10s/it, best loss: -0.989]                                                                 Epoch 1/1
 70%|███████   | 7/10 [05:33<02:21, 47.10s/it, best loss: -0.989]                                                                  - 45s - loss: 1.1369 - acc: 0.8145 - val_loss: 0.0693 - val_acc: 0.9798

 70%|███████   | 7/10 [06:18<02:21, 47.10s/it, best loss: -0.989]                                                                 Best validation acc of epoch:
 70%|███████   | 7/10 [06:18<02:21, 47.10s/it, best loss: -0.989]                                                                 0.9798333334922791
 70%|███████   | 7/10 [06:18<02:21, 47.10s/it, best loss: -0.989] 80%|████████  | 8/10 [06:18<01:32, 46.50s/it, best loss: -0.989]                                                                 Train on 54000 samples, validate on 6000 samples
 80%|████████  | 8/10 [06:19<01:32, 46.50s/it, best loss: -0.989]                                                                 Epoch 1/1
 80%|████████  | 8/10 [06:19<01:32, 46.50s/it, best loss: -0.989]                                                                  - 48s - loss: 0.4278 - acc: 0.8736 - val_loss: 0.0435 - val_acc: 0.9888

 80%|████████  | 8/10 [07:07<01:32, 46.50s/it, best loss: -0.989]                                                                 Best validation acc of epoch:
 80%|████████  | 8/10 [07:07<01:32, 46.50s/it, best loss: -0.989]                                                                 0.9888333328564962
 80%|████████  | 8/10 [07:07<01:32, 46.50s/it, best loss: -0.989] 90%|█████████ | 9/10 [07:07<00:47, 47.21s/it, best loss: -0.989]                                                                 Train on 54000 samples, validate on 6000 samples
 90%|█████████ | 9/10 [07:08<00:47, 47.21s/it, best loss: -0.989]                                                                 Epoch 1/1
 90%|█████████ | 9/10 [07:08<00:47, 47.21s/it, best loss: -0.989]                                                                  - 50s - loss: 0.3640 - acc: 0.8872 - val_loss: 0.0601 - val_acc: 0.9825

 90%|█████████ | 9/10 [07:58<00:47, 47.21s/it, best loss: -0.989]                                                                 Best validation acc of epoch:
 90%|█████████ | 9/10 [07:58<00:47, 47.21s/it, best loss: -0.989]                                                                 0.9825
 90%|█████████ | 9/10 [07:58<00:47, 47.21s/it, best loss: -0.989]100%|██████████| 10/10 [07:58<00:00, 48.29s/it, best loss: -0.989]
--- 485.2712473869324 seconds ---
Evalutation of best performing model:

   32/10000 [..............................] - ETA: 2s
  288/10000 [..............................] - ETA: 1s
  544/10000 [>.............................] - ETA: 1s
  800/10000 [=>............................] - ETA: 1s
 1088/10000 [==>...........................] - ETA: 1s
 1376/10000 [===>..........................] - ETA: 1s
 1664/10000 [===>..........................] - ETA: 1s
 1952/10000 [====>.........................] - ETA: 1s
 2240/10000 [=====>........................] - ETA: 1s
 2528/10000 [======>.......................] - ETA: 1s
 2816/10000 [=======>......................] - ETA: 1s
 3104/10000 [========>.....................] - ETA: 1s
 3392/10000 [=========>....................] - ETA: 1s
 3680/10000 [==========>...................] - ETA: 1s
 3968/10000 [==========>...................] - ETA: 1s
 4256/10000 [===========>..................] - ETA: 1s
 4544/10000 [============>.................] - ETA: 1s
 4832/10000 [=============>................] - ETA: 0s
 5120/10000 [==============>...............] - ETA: 0s
 5408/10000 [===============>..............] - ETA: 0s
 5696/10000 [================>.............] - ETA: 0s
 5984/10000 [================>.............] - ETA: 0s
 6272/10000 [=================>............] - ETA: 0s
 6560/10000 [==================>...........] - ETA: 0s
 6848/10000 [===================>..........] - ETA: 0s
 7136/10000 [====================>.........] - ETA: 0s
 7424/10000 [=====================>........] - ETA: 0s
 7712/10000 [======================>.......] - ETA: 0s
 8000/10000 [=======================>......] - ETA: 0s
 8288/10000 [=======================>......] - ETA: 0s
 8576/10000 [========================>.....] - ETA: 0s
 8864/10000 [=========================>....] - ETA: 0s
 9152/10000 [==========================>...] - ETA: 0s
 9440/10000 [===========================>..] - ETA: 0s
 9728/10000 [============================>.] - ETA: 0s
10000/10000 [==============================] - 2s 182us/step
[0.04885369356677984, 0.985]
Time consumed:  0.1353650462627411  hours
{'Dropout': 0.07257182360582609, 'Dropout_1': 0.23634271098298437, 'Dropout_2': 1, 'Dropout_3': 0.144331267951273, 'batch_size': 0, 'optimizer': 1}
