Leyendo  fashion
Executing  fashion with  Convolutional  arquitecture.

>>> Imports:
#coding=utf-8

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.datasets import fashion_mnist
except:
    pass

try:
    from keras.datasets import cifar10
except:
    pass

try:
    from keras.datasets import imdb
except:
    pass

try:
    from keras import backend as K
except:
    pass

try:
    import numpy as np
except:
    pass

try:
    import sys
except:
    pass

try:
    import time
except:
    pass

try:
    import urllib.request
except:
    pass

try:
    import os
except:
    pass

try:
    from sklearn.model_selection import StratifiedKFold
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation, Flatten
except:
    pass

try:
    from keras.layers.convolutional import Convolution2D, MaxPooling2D
except:
    pass

try:
    from keras.optimizers import SGD, Adam
except:
    pass

try:
    from keras.models import Sequential
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'Dropout': hp.uniform('Dropout', 0, 0.5),
        'Dropout_1': hp.uniform('Dropout_1', 0, 0.5),
        'Dropout_2': hp.choice('Dropout_2', ['two','three']),
        'Dropout_3': hp.uniform('Dropout_3', 0, 0.5),
        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),
        'batch_size': hp.choice('batch_size', [64, 128]),
    }

>>> Data
  1: 
  2: (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()
  3: 
  4: X_train = X_train.reshape(X_train.shape+(1,))
  5: X_test = X_test.reshape(X_test.shape+(1,))
  6: nb_classes = len(np.unique(y_train))
  7: 
  8: y_train = np_utils.to_categorical(y_train, nb_classes)
  9: y_test = np_utils.to_categorical(y_test, nb_classes)
 10: 
 11: 
 12: 
 13: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3: 	nb_classes = y_train.shape[1]
   4: 
   5: 	num_epoch=1*100
   6: 	num_epoch=1*1
   7: 
   8: 	model = Sequential()
   9: 
  10: 	model.add(Convolution2D(32, 3, 3, border_mode='same',
  11: 	                        input_shape=X_train.shape[1:]))
  12: 	model.add(Activation('relu'))
  13: 	model.add(Convolution2D(32, 3, 3))
  14: 	model.add(Activation('relu'))
  15: 	model.add(MaxPooling2D(pool_size=(2, 2)))
  16: 	model.add(Dropout(space['Dropout']))
  17: 
  18: 	model.add(Convolution2D(64, 3, 3, border_mode='same'))
  19: 	model.add(Activation('relu'))
  20: 	model.add(Convolution2D(64, 3, 3))
  21: 	model.add(Activation('relu'))
  22: 	model.add(MaxPooling2D(pool_size=(2, 2)))
  23: 	model.add(Dropout(space['Dropout_1']))
  24: 
  25: 	if space['Dropout_2'] == 'three':
  26: 		model.add(Convolution2D(128, 3, 3, border_mode='same'))
  27: 		model.add(Activation('relu'))
  28: 		model.add(Convolution2D(128, 3, 3))
  29: 		model.add(Activation('relu'))
  30: 		model.add(MaxPooling2D(pool_size=(2, 2)))
  31: 		model.add(Dropout(space['Dropout_3']))
  32: 
  33: 	model.add(Flatten())
  34: 	model.add(Dense(512))
  35: 	model.add(Activation('relu'))
  36: 	model.add(Dropout(0.5))
  37: 	model.add(Dense(nb_classes))
  38: 	model.add(Activation('softmax'))
  39: 
  40: 	 # let's train the model using SGD + momentum (how original).
  41: 	#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
  42: 	
  43: 	model.compile(loss='categorical_crossentropy',
  44: 	              optimizer=space['optimizer'],
  45: 	              metrics=['accuracy'])
  46: 
  47: 	result = model.fit(X_train, y_train,
  48: 	          batch_size=space['batch_size'],
  49: 	          nb_epoch=num_epoch,
  50: 	          verbose=2,
  51: 	          validation_split=0.1)
  52: 	validation_acc = np.amax(result.history['val_acc']) 
  53: 	print('Best validation acc of epoch:', validation_acc)
  54: 	return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}
  55: 
Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz

 8192/29515 [=======>......................] - ETA: 0s
32768/29515 [=================================] - 0s 1us/step
Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz

    8192/26421880 [..............................] - ETA: 0s
   16384/26421880 [..............................] - ETA: 1:25
   98304/26421880 [..............................] - ETA: 34s 
  212992/26421880 [..............................] - ETA: 27s
  434176/26421880 [..............................] - ETA: 21s
  843776/26421880 [..............................] - ETA: 12s
  901120/26421880 [>.............................] - ETA: 13s
 1286144/26421880 [>.............................] - ETA: 10s
 1392640/26421880 [>.............................] - ETA: 10s
 1712128/26421880 [>.............................] - ETA: 9s 
 1851392/26421880 [=>............................] - ETA: 9s
 2007040/26421880 [=>............................] - ETA: 9s
 2121728/26421880 [=>............................] - ETA: 9s
 2334720/26421880 [=>............................] - ETA: 9s
 2441216/26421880 [=>............................] - ETA: 9s
 2539520/26421880 [=>............................] - ETA: 9s
 2654208/26421880 [==>...........................] - ETA: 9s
 2736128/26421880 [==>...........................] - ETA: 10s
 2916352/26421880 [==>...........................] - ETA: 9s 
 2990080/26421880 [==>...........................] - ETA: 10s
 3096576/26421880 [==>...........................] - ETA: 10s
 3178496/26421880 [==>...........................] - ETA: 10s
 3284992/26421880 [==>...........................] - ETA: 10s
 3399680/26421880 [==>...........................] - ETA: 10s
 3514368/26421880 [==>...........................] - ETA: 10s
 3629056/26421880 [===>..........................] - ETA: 10s
 3743744/26421880 [===>..........................] - ETA: 10s
 3833856/26421880 [===>..........................] - ETA: 10s
 3940352/26421880 [===>..........................] - ETA: 10s
 4030464/26421880 [===>..........................] - ETA: 10s
 4145152/26421880 [===>..........................] - ETA: 10s
 4235264/26421880 [===>..........................] - ETA: 10s
 4349952/26421880 [===>..........................] - ETA: 10s
 4440064/26421880 [====>.........................] - ETA: 10s
 4571136/26421880 [====>.........................] - ETA: 10s
 4661248/26421880 [====>.........................] - ETA: 10s
 4784128/26421880 [====>.........................] - ETA: 10s
 4898816/26421880 [====>.........................] - ETA: 10s
 5013504/26421880 [====>.........................] - ETA: 10s
 5144576/26421880 [====>.........................] - ETA: 10s
 5275648/26421880 [====>.........................] - ETA: 10s
 5382144/26421880 [=====>........................] - ETA: 10s
 5513216/26421880 [=====>........................] - ETA: 10s
 5652480/26421880 [=====>........................] - ETA: 10s
 5758976/26421880 [=====>........................] - ETA: 10s
 5890048/26421880 [=====>........................] - ETA: 10s
 6029312/26421880 [=====>........................] - ETA: 10s
 6144000/26421880 [=====>........................] - ETA: 10s
 6250496/26421880 [======>.......................] - ETA: 10s
 6381568/26421880 [======>.......................] - ETA: 9s 
 6520832/26421880 [======>.......................] - ETA: 9s
 6643712/26421880 [======>.......................] - ETA: 9s
 6758400/26421880 [======>.......................] - ETA: 9s
 6914048/26421880 [======>.......................] - ETA: 9s
 7061504/26421880 [=======>......................] - ETA: 9s
 7184384/26421880 [=======>......................] - ETA: 9s
 7340032/26421880 [=======>......................] - ETA: 9s
 7487488/26421880 [=======>......................] - ETA: 9s
 7610368/26421880 [=======>......................] - ETA: 9s
 7725056/26421880 [=======>......................] - ETA: 9s
 7847936/26421880 [=======>......................] - ETA: 9s
 7962624/26421880 [========>.....................] - ETA: 8s
 8126464/26421880 [========>.....................] - ETA: 8s
 8257536/26421880 [========>.....................] - ETA: 8s
 8396800/26421880 [========>.....................] - ETA: 8s
 8527872/26421880 [========>.....................] - ETA: 8s
 8683520/26421880 [========>.....................] - ETA: 8s
 8806400/26421880 [========>.....................] - ETA: 8s
 8945664/26421880 [=========>....................] - ETA: 8s
 9093120/26421880 [=========>....................] - ETA: 8s
 9248768/26421880 [=========>....................] - ETA: 8s
 9404416/26421880 [=========>....................] - ETA: 8s
 9543680/26421880 [=========>....................] - ETA: 7s
 9691136/26421880 [==========>...................] - ETA: 7s
 9846784/26421880 [==========>...................] - ETA: 7s
 9986048/26421880 [==========>...................] - ETA: 7s
10149888/26421880 [==========>...................] - ETA: 7s
10313728/26421880 [==========>...................] - ETA: 7s
10485760/26421880 [==========>...................] - ETA: 7s
10665984/26421880 [===========>..................] - ETA: 7s
10829824/26421880 [===========>..................] - ETA: 7s
10985472/26421880 [===========>..................] - ETA: 7s
11132928/26421880 [===========>..................] - ETA: 7s
11288576/26421880 [===========>..................] - ETA: 6s
11419648/26421880 [===========>..................] - ETA: 6s
11591680/26421880 [============>.................] - ETA: 6s
11747328/26421880 [============>.................] - ETA: 6s
11911168/26421880 [============>.................] - ETA: 6s
12066816/26421880 [============>.................] - ETA: 6s
12214272/26421880 [============>.................] - ETA: 6s
12402688/26421880 [=============>................] - ETA: 6s
12566528/26421880 [=============>................] - ETA: 6s
12722176/26421880 [=============>................] - ETA: 6s
12894208/26421880 [=============>................] - ETA: 6s
13066240/26421880 [=============>................] - ETA: 5s
13254656/26421880 [==============>...............] - ETA: 5s
13410304/26421880 [==============>...............] - ETA: 5s
13574144/26421880 [==============>...............] - ETA: 5s
13729792/26421880 [==============>...............] - ETA: 5s
13910016/26421880 [==============>...............] - ETA: 5s
14073856/26421880 [==============>...............] - ETA: 5s
14229504/26421880 [===============>..............] - ETA: 5s
14393344/26421880 [===============>..............] - ETA: 5s
14573568/26421880 [===============>..............] - ETA: 5s
14745600/26421880 [===============>..............] - ETA: 5s
14917632/26421880 [===============>..............] - ETA: 4s
15097856/26421880 [================>.............] - ETA: 4s
15286272/26421880 [================>.............] - ETA: 4s
15466496/26421880 [================>.............] - ETA: 4s
15638528/26421880 [================>.............] - ETA: 4s
15818752/26421880 [================>.............] - ETA: 4s
15998976/26421880 [=================>............] - ETA: 4s
16187392/26421880 [=================>............] - ETA: 4s
16375808/26421880 [=================>............] - ETA: 4s
16564224/26421880 [=================>............] - ETA: 4s
16728064/26421880 [=================>............] - ETA: 4s
16850944/26421880 [==================>...........] - ETA: 3s
16932864/26421880 [==================>...........] - ETA: 3s
17145856/26421880 [==================>...........] - ETA: 3s
17219584/26421880 [==================>...........] - ETA: 3s
17424384/26421880 [==================>...........] - ETA: 3s
17506304/26421880 [==================>...........] - ETA: 3s
17612800/26421880 [==================>...........] - ETA: 3s
17735680/26421880 [===================>..........] - ETA: 3s
17842176/26421880 [===================>..........] - ETA: 3s
17948672/26421880 [===================>..........] - ETA: 3s
18087936/26421880 [===================>..........] - ETA: 3s
18186240/26421880 [===================>..........] - ETA: 3s
18292736/26421880 [===================>..........] - ETA: 3s
18407424/26421880 [===================>..........] - ETA: 3s
18530304/26421880 [====================>.........] - ETA: 3s
18636800/26421880 [====================>.........] - ETA: 3s
18743296/26421880 [====================>.........] - ETA: 3s
18857984/26421880 [====================>.........] - ETA: 3s
18989056/26421880 [====================>.........] - ETA: 3s
19095552/26421880 [====================>.........] - ETA: 3s
19210240/26421880 [====================>.........] - ETA: 3s
19324928/26421880 [====================>.........] - ETA: 3s
19480576/26421880 [=====================>........] - ETA: 2s
19595264/26421880 [=====================>........] - ETA: 2s
19718144/26421880 [=====================>........] - ETA: 2s
19832832/26421880 [=====================>........] - ETA: 2s
19972096/26421880 [=====================>........] - ETA: 2s
20094976/26421880 [=====================>........] - ETA: 2s
20234240/26421880 [=====================>........] - ETA: 2s
20340736/26421880 [======================>.......] - ETA: 2s
20488192/26421880 [======================>.......] - ETA: 2s
20611072/26421880 [======================>.......] - ETA: 2s
20758528/26421880 [======================>.......] - ETA: 2s
20905984/26421880 [======================>.......] - ETA: 2s
21037056/26421880 [======================>.......] - ETA: 2s
21143552/26421880 [=======================>......] - ETA: 2s
21299200/26421880 [=======================>......] - ETA: 2s
21438464/26421880 [=======================>......] - ETA: 2s
21585920/26421880 [=======================>......] - ETA: 2s
21749760/26421880 [=======================>......] - ETA: 2s
21889024/26421880 [=======================>......] - ETA: 1s
22044672/26421880 [========================>.....] - ETA: 1s
22159360/26421880 [========================>.....] - ETA: 1s
22323200/26421880 [========================>.....] - ETA: 1s
22355968/26421880 [========================>.....] - ETA: 1s
22503424/26421880 [========================>.....] - ETA: 1s
22609920/26421880 [========================>.....] - ETA: 1s
22716416/26421880 [========================>.....] - ETA: 1s
22839296/26421880 [========================>.....] - ETA: 1s
22945792/26421880 [=========================>....] - ETA: 1s
23068672/26421880 [=========================>....] - ETA: 1s
23166976/26421880 [=========================>....] - ETA: 1s
23298048/26421880 [=========================>....] - ETA: 1s
23412736/26421880 [=========================>....] - ETA: 1s
23535616/26421880 [=========================>....] - ETA: 1s
23650304/26421880 [=========================>....] - ETA: 1s
23789568/26421880 [==========================>...] - ETA: 1s
23912448/26421880 [==========================>...] - ETA: 1s
24027136/26421880 [==========================>...] - ETA: 1s
24141824/26421880 [==========================>...] - ETA: 1s
24248320/26421880 [==========================>...] - ETA: 0s
24387584/26421880 [==========================>...] - ETA: 0s
24535040/26421880 [==========================>...] - ETA: 0s
24657920/26421880 [==========================>...] - ETA: 0s
24813568/26421880 [===========================>..] - ETA: 0s
24903680/26421880 [===========================>..] - ETA: 0s
25034752/26421880 [===========================>..] - ETA: 0s
25157632/26421880 [===========================>..] - ETA: 0s
25288704/26421880 [===========================>..] - ETA: 0s
25403392/26421880 [===========================>..] - ETA: 0s
25518080/26421880 [===========================>..] - ETA: 0s
25649152/26421880 [============================>.] - ETA: 0s
25804800/26421880 [============================>.] - ETA: 0s
25935872/26421880 [============================>.] - ETA: 0s
26075136/26421880 [============================>.] - ETA: 0s
26206208/26421880 [============================>.] - ETA: 0s
26378240/26421880 [============================>.] - ETA: 0s
26427392/26421880 [==============================] - 12s 0us/step
Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz

8192/5148 [===============================================] - 0s 0us/step
Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz

   8192/4422102 [..............................] - ETA: 0s
  40960/4422102 [..............................] - ETA: 6s
 106496/4422102 [..............................] - ETA: 5s
 294912/4422102 [=>............................] - ETA: 2s
 368640/4422102 [=>............................] - ETA: 3s
 917504/4422102 [=====>........................] - ETA: 1s
1015808/4422102 [=====>........................] - ETA: 1s
1449984/4422102 [========>.....................] - ETA: 0s
1671168/4422102 [==========>...................] - ETA: 0s
1802240/4422102 [===========>..................] - ETA: 0s
2162688/4422102 [=============>................] - ETA: 0s
2310144/4422102 [==============>...............] - ETA: 0s
2457600/4422102 [===============>..............] - ETA: 0s
2621440/4422102 [================>.............] - ETA: 0s
2850816/4422102 [==================>...........] - ETA: 0s
2998272/4422102 [===================>..........] - ETA: 0s
3162112/4422102 [====================>.........] - ETA: 0s
3350528/4422102 [=====================>........] - ETA: 0s
3571712/4422102 [=======================>......] - ETA: 0s
3727360/4422102 [========================>.....] - ETA: 0s
3784704/4422102 [========================>.....] - ETA: 0s
3973120/4422102 [=========================>....] - ETA: 0s
4022272/4422102 [==========================>...] - ETA: 0s
4268032/4422102 [===========================>..] - ETA: 0s
4415488/4422102 [============================>.] - ETA: 0s
4423680/4422102 [==============================] - 1s 0us/step
  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]                                                    Train on 54000 samples, validate on 6000 samples
  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]                                                    Epoch 1/1
  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]                                                     - 64s - loss: 1.2535 - acc: 0.5410 - val_loss: 0.6160 - val_acc: 0.7707

  0%|          | 0/10 [01:05<?, ?it/s, best loss: ?]                                                    Best validation acc of epoch:
  0%|          | 0/10 [01:05<?, ?it/s, best loss: ?]                                                    0.7706666671435038
  0%|          | 0/10 [01:05<?, ?it/s, best loss: ?] 10%|█         | 1/10 [01:05<09:45, 65.01s/it, best loss: -0.7706666671435038]                                                                              Train on 54000 samples, validate on 6000 samples
 10%|█         | 1/10 [01:05<09:45, 65.01s/it, best loss: -0.7706666671435038]                                                                              Epoch 1/1
 10%|█         | 1/10 [01:05<09:45, 65.01s/it, best loss: -0.7706666671435038]                                                                               - 64s - loss: 1.5028 - acc: 0.7447 - val_loss: 0.3582 - val_acc: 0.8700

 10%|█         | 1/10 [02:09<09:45, 65.01s/it, best loss: -0.7706666671435038]                                                                              Best validation acc of epoch:
 10%|█         | 1/10 [02:09<09:45, 65.01s/it, best loss: -0.7706666671435038]                                                                              0.8699999998410543
 10%|█         | 1/10 [02:09<09:45, 65.01s/it, best loss: -0.7706666671435038] 20%|██        | 2/10 [02:09<08:39, 64.94s/it, best loss: -0.8699999998410543]                                                                              Train on 54000 samples, validate on 6000 samples
 20%|██        | 2/10 [02:10<08:39, 64.94s/it, best loss: -0.8699999998410543]                                                                              Epoch 1/1
 20%|██        | 2/10 [02:10<08:39, 64.94s/it, best loss: -0.8699999998410543]                                                                               - 69s - loss: 0.6277 - acc: 0.7764 - val_loss: 0.3546 - val_acc: 0.8715

 20%|██        | 2/10 [03:19<08:39, 64.94s/it, best loss: -0.8699999998410543]                                                                              Best validation acc of epoch:
 20%|██        | 2/10 [03:19<08:39, 64.94s/it, best loss: -0.8699999998410543]                                                                              0.8715
 20%|██        | 2/10 [03:19<08:39, 64.94s/it, best loss: -0.8699999998410543] 30%|███       | 3/10 [03:19<07:45, 66.43s/it, best loss: -0.8715]                                                                              Train on 54000 samples, validate on 6000 samples
 30%|███       | 3/10 [03:20<07:45, 66.43s/it, best loss: -0.8715]                                                                  Epoch 1/1
 30%|███       | 3/10 [03:20<07:45, 66.43s/it, best loss: -0.8715]                                                                   - 62s - loss: 13.2847 - acc: 0.1749 - val_loss: 12.9375 - val_acc: 0.1973

 30%|███       | 3/10 [04:21<07:45, 66.43s/it, best loss: -0.8715]                                                                  Best validation acc of epoch:
 30%|███       | 3/10 [04:21<07:45, 66.43s/it, best loss: -0.8715]                                                                  0.19733333321412405
 30%|███       | 3/10 [04:21<07:45, 66.43s/it, best loss: -0.8715] 40%|████      | 4/10 [04:21<06:31, 65.19s/it, best loss: -0.8715]                                                                  Train on 54000 samples, validate on 6000 samples
 40%|████      | 4/10 [04:22<06:31, 65.19s/it, best loss: -0.8715]                                                                  Epoch 1/1
 40%|████      | 4/10 [04:22<06:31, 65.19s/it, best loss: -0.8715]                                                                   - 67s - loss: 0.7477 - acc: 0.7398 - val_loss: 0.4426 - val_acc: 0.8482

 40%|████      | 4/10 [05:29<06:31, 65.19s/it, best loss: -0.8715]                                                                  Best validation acc of epoch:
 40%|████      | 4/10 [05:29<06:31, 65.19s/it, best loss: -0.8715]                                                                  0.8481666663487752
 40%|████      | 4/10 [05:29<06:31, 65.19s/it, best loss: -0.8715] 50%|█████     | 5/10 [05:29<05:29, 65.99s/it, best loss: -0.8715]                                                                  Train on 54000 samples, validate on 6000 samples
 50%|█████     | 5/10 [05:30<05:29, 65.99s/it, best loss: -0.8715]                                                                  Epoch 1/1
 50%|█████     | 5/10 [05:30<05:29, 65.99s/it, best loss: -0.8715]                                                                   - 61s - loss: 1.2954 - acc: 0.6502 - val_loss: 0.5661 - val_acc: 0.8065

 50%|█████     | 5/10 [06:31<05:29, 65.99s/it, best loss: -0.8715]                                                                  Best validation acc of epoch:
 50%|█████     | 5/10 [06:31<05:29, 65.99s/it, best loss: -0.8715]                                                                  0.8064999996821086
 50%|█████     | 5/10 [06:31<05:29, 65.99s/it, best loss: -0.8715] 60%|██████    | 6/10 [06:31<04:18, 64.62s/it, best loss: -0.8715]                                                                  Train on 54000 samples, validate on 6000 samples
 60%|██████    | 6/10 [06:31<04:18, 64.62s/it, best loss: -0.8715]                                                                  Epoch 1/1
 60%|██████    | 6/10 [06:31<04:18, 64.62s/it, best loss: -0.8715]                                                                   - 61s - loss: 10.2527 - acc: 0.3176 - val_loss: 0.6207 - val_acc: 0.7797

 60%|██████    | 6/10 [07:33<04:18, 64.62s/it, best loss: -0.8715]                                                                  Best validation acc of epoch:
 60%|██████    | 6/10 [07:33<04:18, 64.62s/it, best loss: -0.8715]                                                                  0.7796666661898295
 60%|██████    | 6/10 [07:33<04:18, 64.62s/it, best loss: -0.8715] 70%|███████   | 7/10 [07:33<03:11, 63.79s/it, best loss: -0.8715]                                                                  Train on 54000 samples, validate on 6000 samples
 70%|███████   | 7/10 [07:33<03:11, 63.79s/it, best loss: -0.8715]                                                                  Epoch 1/1
 70%|███████   | 7/10 [07:33<03:11, 63.79s/it, best loss: -0.8715]                                                                   - 61s - loss: 5.3913 - acc: 0.4962 - val_loss: 0.5372 - val_acc: 0.8053

 70%|███████   | 7/10 [08:34<03:11, 63.79s/it, best loss: -0.8715]                                                                  Best validation acc of epoch:
 70%|███████   | 7/10 [08:34<03:11, 63.79s/it, best loss: -0.8715]                                                                  0.8053333334922791
 70%|███████   | 7/10 [08:34<03:11, 63.79s/it, best loss: -0.8715] 80%|████████  | 8/10 [08:34<02:06, 63.09s/it, best loss: -0.8715]                                                                  Train on 54000 samples, validate on 6000 samples
 80%|████████  | 8/10 [08:35<02:06, 63.09s/it, best loss: -0.8715]                                                                  Epoch 1/1
 80%|████████  | 8/10 [08:35<02:06, 63.09s/it, best loss: -0.8715]                                                                   - 67s - loss: 0.7888 - acc: 0.7275 - val_loss: 0.3662 - val_acc: 0.8650

 80%|████████  | 8/10 [09:42<02:06, 63.09s/it, best loss: -0.8715]                                                                  Best validation acc of epoch:
 80%|████████  | 8/10 [09:42<02:06, 63.09s/it, best loss: -0.8715]                                                                  0.865
 80%|████████  | 8/10 [09:42<02:06, 63.09s/it, best loss: -0.8715] 90%|█████████ | 9/10 [09:42<01:04, 64.57s/it, best loss: -0.8715]                                                                  Train on 54000 samples, validate on 6000 samples
 90%|█████████ | 9/10 [09:43<01:04, 64.57s/it, best loss: -0.8715]                                                                  Epoch 1/1
 90%|█████████ | 9/10 [09:43<01:04, 64.57s/it, best loss: -0.8715]                                                                   - 70s - loss: 0.7110 - acc: 0.7514 - val_loss: 0.3914 - val_acc: 0.8578

 90%|█████████ | 9/10 [10:53<01:04, 64.57s/it, best loss: -0.8715]                                                                  Best validation acc of epoch:
 90%|█████████ | 9/10 [10:53<01:04, 64.57s/it, best loss: -0.8715]                                                                  0.8578333331743876
 90%|█████████ | 9/10 [10:53<01:04, 64.57s/it, best loss: -0.8715]100%|██████████| 10/10 [10:53<00:00, 66.45s/it, best loss: -0.8715]
--- 667.7770256996155 seconds ---
Evalutation of best performing model:

   32/10000 [..............................] - ETA: 2s
  256/10000 [..............................] - ETA: 2s
  448/10000 [>.............................] - ETA: 2s
  576/10000 [>.............................] - ETA: 2s
  704/10000 [=>............................] - ETA: 2s
  864/10000 [=>............................] - ETA: 2s
 1024/10000 [==>...........................] - ETA: 2s
 1184/10000 [==>...........................] - ETA: 2s
 1344/10000 [===>..........................] - ETA: 2s
 1536/10000 [===>..........................] - ETA: 2s
 1728/10000 [====>.........................] - ETA: 2s
 1920/10000 [====>.........................] - ETA: 2s
 2112/10000 [=====>........................] - ETA: 2s
 2304/10000 [=====>........................] - ETA: 2s
 2496/10000 [======>.......................] - ETA: 2s
 2688/10000 [=======>......................] - ETA: 2s
 2880/10000 [=======>......................] - ETA: 2s
 3072/10000 [========>.....................] - ETA: 2s
 3264/10000 [========>.....................] - ETA: 2s
 3456/10000 [=========>....................] - ETA: 2s
 3648/10000 [=========>....................] - ETA: 1s
 3840/10000 [==========>...................] - ETA: 1s
 4032/10000 [===========>..................] - ETA: 1s
 4224/10000 [===========>..................] - ETA: 1s
 4416/10000 [============>.................] - ETA: 1s
 4608/10000 [============>.................] - ETA: 1s
 4800/10000 [=============>................] - ETA: 1s
 4992/10000 [=============>................] - ETA: 1s
 5184/10000 [==============>...............] - ETA: 1s
 5376/10000 [===============>..............] - ETA: 1s
 5568/10000 [===============>..............] - ETA: 1s
 5760/10000 [================>.............] - ETA: 1s
 5952/10000 [================>.............] - ETA: 1s
 6144/10000 [=================>............] - ETA: 1s
 6336/10000 [==================>...........] - ETA: 1s
 6528/10000 [==================>...........] - ETA: 1s
 6720/10000 [===================>..........] - ETA: 0s
 6912/10000 [===================>..........] - ETA: 0s
 7104/10000 [====================>.........] - ETA: 0s
 7264/10000 [====================>.........] - ETA: 0s
 7424/10000 [=====================>........] - ETA: 0s
 7584/10000 [=====================>........] - ETA: 0s
 7744/10000 [======================>.......] - ETA: 0s
 7904/10000 [======================>.......] - ETA: 0s
 8032/10000 [=======================>......] - ETA: 0s
 8128/10000 [=======================>......] - ETA: 0s
 8256/10000 [=======================>......] - ETA: 0s
 8416/10000 [========================>.....] - ETA: 0s
 8576/10000 [========================>.....] - ETA: 0s
 8736/10000 [=========================>....] - ETA: 0s
 8896/10000 [=========================>....] - ETA: 0s
 9088/10000 [==========================>...] - ETA: 0s
 9280/10000 [==========================>...] - ETA: 0s
 9472/10000 [===========================>..] - ETA: 0s
 9664/10000 [===========================>..] - ETA: 0s
 9856/10000 [============================>.] - ETA: 0s
10000/10000 [==============================] - 3s 311us/step
[0.3852279534816742, 0.8612]
Time consumed:  0.1864739943875207  hours
{'Dropout': 0.07257182360582609, 'Dropout_1': 0.23634271098298437, 'Dropout_2': 1, 'Dropout_3': 0.144331267951273, 'batch_size': 0, 'optimizer': 1}
